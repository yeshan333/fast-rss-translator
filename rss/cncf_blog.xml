<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>CNCF - Blog</title>
    <link>http://rsshub.rssforever.com/cncf</link>
    <description>CNCF - Blog - Powered by RSSHub</description>
    <managingEditor>contact@rsshub.app (RSSHub)</managingEditor>
    <item>
      <title>【Continued security improvements to CNCF projects with OSTIF audits】通过 OSTIF 审核持续改进 CNCF 项目的安全性</title>
      <link>https://www.cncf.io/blog/2024/12/12/continued-security-improvements-to-cncf-projects-with-ostif-audits/</link>
      <description>【&lt;p&gt;The &lt;a href=&#34;https://ostif.org/&#34;&gt;Open Source Technology Improvement Fund, Inc&lt;/a&gt; (OSTIF) is thrilled to mark another successful year of helping CNCF projects with security audits. Since this partnership began in 2021, a total of 13 projects have graduated following an OSTIF security audit. The CNCF continues to demonstrate a strong commitment to the maturity and growth of projects, investing multiple millions of dollars over the last three years in these engagements.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p class=&#34;is-style-default has-gray-200-background-color has-background&#34;&gt;“CNCF is a prime example of a foundation fostering good security practices and providing value to projects. The foundation sponsors security audits, which has resulted in significant security improvements. OSTIF is grateful for the opportunity to collaborate on these audits.”&amp;nbsp;– Amir Montazery, Managing Director, OSTIF&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1344&#34; height=&#34;568&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/12/Screenshot-2024-12-11-at-09.28.10.jpg&#34; alt=&#34;2024 year in review&#34; class=&#34;wp-image-122021&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/12/Screenshot-2024-12-11-at-09.28.10.jpg 1344w, https://www.cncf.io/wp-content/uploads/2024/12/Screenshot-2024-12-11-at-09.28.10-300x127.jpg 300w, https://www.cncf.io/wp-content/uploads/2024/12/Screenshot-2024-12-11-at-09.28.10-1024x433.jpg 1024w, https://www.cncf.io/wp-content/uploads/2024/12/Screenshot-2024-12-11-at-09.28.10-768x325.jpg 768w, https://www.cncf.io/wp-content/uploads/2024/12/Screenshot-2024-12-11-at-09.28.10-900x380.jpg 900w, https://www.cncf.io/wp-content/uploads/2024/12/Screenshot-2024-12-11-at-09.28.10-473x200.jpg 473w, https://www.cncf.io/wp-content/uploads/2024/12/Screenshot-2024-12-11-at-09.28.10-946x400.jpg 946w&#34; sizes=&#34;auto, (max-width: 1344px) 100vw, 1344px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1296&#34; height=&#34;594&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/12/Screenshot-2024-12-11-at-09.28.18.jpg&#34; alt=&#34;impact at a glance&#34; class=&#34;wp-image-122022&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/12/Screenshot-2024-12-11-at-09.28.18.jpg 1296w, https://www.cncf.io/wp-content/uploads/2024/12/Screenshot-2024-12-11-at-09.28.18-300x138.jpg 300w, https://www.cncf.io/wp-content/uploads/2024/12/Screenshot-2024-12-11-at-09.28.18-1024x469.jpg 1024w, https://www.cncf.io/wp-content/uploads/2024/12/Screenshot-2024-12-11-at-09.28.18-768x352.jpg 768w, https://www.cncf.io/wp-content/uploads/2024/12/Screenshot-2024-12-11-at-09.28.18-900x413.jpg 900w, https://www.cncf.io/wp-content/uploads/2024/12/Screenshot-2024-12-11-at-09.28.18-436x200.jpg 436w, https://www.cncf.io/wp-content/uploads/2024/12/Screenshot-2024-12-11-at-09.28.18-873x400.jpg 873w&#34; sizes=&#34;auto, (max-width: 1296px) 100vw, 1296px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://ostif.org/wp-content/uploads/2024/12/2024-CNCF_OSTIF-Impact-Report.pdf&#34;&gt;Have a look at the full report!&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Check out OSTIF’s blog post &lt;a href=&#34;https://ostif.org/2024-cncf-ostif-impactreport/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;a href=&#34;https://ostif.org/&#34;&gt;开源技术改进基金&lt;/a&gt; (OSTIF) 很高兴迎来帮助 CNCF 项目进行安全审计的又一个成功的一年。自 2021 年开始这种合作关系以来，共有 13 个项目通过 OSTIF 安全审核已毕业。 CNCF 继续表现出对项目成熟和发展的坚定承诺，在过去三年中在这些项目上投资了数百万美元。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p class=&#34;is-style-default has-gray-200-background-color has-background&#34;&gt;​​“CNCF 是促进良好安全实践并为项目提供价值的基金会的典型例子。该基金会赞助安全审计，从而显着提高了安全性。 OSTIF 非常感谢有机会就这些审计进行合作。” – Amir Montazery，OSTIF 董事总经理&lt;/p&gt;&#xA;&lt;/块引用&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“1344”高度=“568”src=“https://www.cncf.io/ wp-content/uploads/2024/12/Screenshot-2024-12-11-at-09.28.10.jpg&#34; alt=&#34;2024 年回顾&#34;类=“wp-image-122021”srcset=“https://www.cncf.io/wp-content/uploads/2024/12/Screenshot-2024-12-11-at-09.28.10.jpg 1344w， https://www.cncf.io/wp-content/uploads/2024/12/Screenshot-2024-12-11-at-09.28.10-300x127.jpg 300w， https://www.cncf.io/wp-content/uploads/2024/12/Screenshot-2024-12-11-at-09.28.10-1024x433.jpg 1024w， https://www.cncf.io/wp-content/uploads/2024/12/Screenshot-2024-12-11-at-09.28.10-768x325.jpg 768w， https://www.cncf.io/wp-content/uploads/2024/12/Screenshot-2024-12-11-at-09.28.10-900x380.jpg 900w， https://www.cncf.io/wp-content/uploads/2024/12/Screenshot-2024-12-11-at-09.28.10-473x200.jpg 473w， https://www.cncf.io/wp-content/uploads/2024/12/Screenshot-2024-12-11-at-09.28.10-946x400.jpg 946w“尺寸=”自动，（最大宽度：1344px ) 100vw，1344px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“1296”高度=“594”src=“https://www.cncf.io/ wp-content/uploads/2024/12/Screenshot-2024-12-11-at-09.28.18.jpg&#34; alt=&#34;影响一览&#34;类=“wp-image-122022”srcset=“https://www.cncf.io/wp-content/uploads/2024/12/Screenshot-2024-12-11-at-09.28.18.jpg 1296w， https://www.cncf.io/wp-content/uploads/2024/12/Screenshot-2024-12-11-at-09.28.18-300x138.jpg 300w， https://www.cncf.io/wp-content/uploads/2024/12/Screenshot-2024-12-11-at-09.28.18-1024x469.jpg 1024w， https://www.cncf.io/wp-content/uploads/2024/12/Screenshot-2024-12-11-at-09.28.18-768x352.jpg 768w， https://www.cncf.io/wp-content/uploads/2024/12/Screenshot-2024-12-11-at-09.28.18-900x413.jpg 900w， https://www.cncf.io/wp-content/uploads/2024/12/Screenshot-2024-12-11-at-09.28.18-436x200.jpg 436w， https://www.cncf.io/wp-content/uploads/2024/12/Screenshot-2024-12-11-at-09.28.18-873x400.jpg 873w“尺寸=”自动，（最大宽度：1296px）100vw，1296px“referrerpolicy =“no-referrer”&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://ostif.org/wp-content/uploads/2024/12/2024-CNCF_OSTIF-Impact-Report.pdf&#34;&gt;查看完整报告！&lt;/a&gt;&lt; /p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在&lt;a href=&#34;https://ostif.org/2024-cncf-ostif-impactreport/&#34;&gt;此处&lt;/a&gt;查看 OSTIF 的博客文章。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Wed, 11 Dec 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Kubestronaut in Orbit: David Mukuzi】在轨道上的 Kubetronaut：David Mukuzi</title>
      <link>https://www.cncf.io/blog/2024/12/17/kubestronaut-in-orbit-david-mukuzi/</link>
      <description>【&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1650&#34; height=&#34;866&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/12/Kubestronaut-in-Orbit-12-1.jpg&#34; alt=&#34;kubestronaut &#34; class=&#34;wp-image-122044&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/12/Kubestronaut-in-Orbit-12-1.jpg 1650w, https://www.cncf.io/wp-content/uploads/2024/12/Kubestronaut-in-Orbit-12-1-300x157.jpg 300w, https://www.cncf.io/wp-content/uploads/2024/12/Kubestronaut-in-Orbit-12-1-1024x537.jpg 1024w, https://www.cncf.io/wp-content/uploads/2024/12/Kubestronaut-in-Orbit-12-1-768x403.jpg 768w, https://www.cncf.io/wp-content/uploads/2024/12/Kubestronaut-in-Orbit-12-1-194x102.jpg 194w, https://www.cncf.io/wp-content/uploads/2024/12/Kubestronaut-in-Orbit-12-1-388x204.jpg 388w, https://www.cncf.io/wp-content/uploads/2024/12/Kubestronaut-in-Orbit-12-1-776x408.jpg 776w, https://www.cncf.io/wp-content/uploads/2024/12/Kubestronaut-in-Orbit-12-1-1552x816.jpg 1552w, https://www.cncf.io/wp-content/uploads/2024/12/Kubestronaut-in-Orbit-12-1-900x472.jpg 900w, https://www.cncf.io/wp-content/uploads/2024/12/Kubestronaut-in-Orbit-12-1-381x200.jpg 381w, https://www.cncf.io/wp-content/uploads/2024/12/Kubestronaut-in-Orbit-12-1-762x400.jpg 762w, https://www.cncf.io/wp-content/uploads/2024/12/Kubestronaut-in-Orbit-12-1-590x310.jpg 590w, https://www.cncf.io/wp-content/uploads/2024/12/Kubestronaut-in-Orbit-12-1-1180x620.jpg 1180w&#34; sizes=&#34;auto, (max-width: 1650px) 100vw, 1650px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Get to know David&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This week’s Kubestronaut in Orbit, David Mukuzi, is a DevOps Engineer in Nairobi, Kenya. David is driven by a deep-rooted enthusiasm for continuous learning and exploration of emerging technologies. He enjoys working with collaborative teams to build reliable, high-performing, and accessible solutions. David is focused on understanding and addressing customer challenges, with innovation as well as a practical approach to problem solving.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you’d like to be a Kubestronaut like David, get more details on the &lt;a href=&#34;https://www.cncf.io/training/kubestronaut/&#34;&gt;CNCF Kubestronaut&lt;/a&gt; page.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;When did you get started with Kubernetes and/or cloud-native? What was your first project?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;I started working with Kubernetes in 2018 – the company I worked for was running Kubernetes workloads both on bare metal and in the cloud.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;What are the primary CNCF projects you work on or use today?&amp;nbsp; What projects have you enjoyed the most in your career?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;I get to interact with a majority of the &lt;a href=&#34;https://www.cncf.io/projects/&#34;&gt;Graduated CNCF projects &lt;/a&gt;daily, I’ve enjoyed &lt;a href=&#34;https://www.cncf.io/projects/kubernetes/&#34;&gt;Kubernetes&lt;/a&gt; and &lt;a href=&#34;https://www.cncf.io/projects/coredns/&#34;&gt;CoreDNS&lt;/a&gt; the most.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;How have the certs or CNCF helped you in your career?&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The practical and hands-on aspects of the certifications helped me to put the knowledge into practice and contributing to different projects have provided additional practice and learning.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;What are some other books/sites/courses you recommend for people who want to work with k8s?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.oreilly.com/library/view/networking-and-kubernetes/9781492081647/&#34;&gt;Networking and Kubernetes&lt;/a&gt; by James Strong and Vallery Lancey was helpful.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;What do you do in your free time?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;I enjoy cooking and working out.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;What would you tell someone who is just starting their K8s certification journey? Any tips or tricks?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Practice breaking things and get hands-on experience.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Today the Cloud native ecosystem is way more than Kubernetes. Do you plan to get other cloud native certifications from the CNCF ?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Now that I have all the Kubernetes certs I’m planning to take the&lt;a href=&#34;https://www.cncf.io/training/certification/pca/&#34;&gt; Prometheus Certified Associate (PCA)&lt;/a&gt; and the&lt;a href=&#34;https://www.cncf.io/training/certification/ica/&#34;&gt; Istio Certified Associate (ICA)&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“1650”高度=“866”src=“https://www.cncf.io/ wp-content/uploads/2024/12/Kubestronaut-in-Orbit-12-1.jpg&#34; alt=&#34;kubestronaut&#34; class=&#34;wp-image-122044&#34; srcset =“https://www.cncf.io/wp-content/uploads/2024/12/Kubestronaut-in-Orbit-12-1.jpg 1650w，https://www.cncf.io/wp-content/ uploads/2024/12/Kubestronaut-in-Orbit-12-1-300x157.jpg 300w, https://www.cncf.io/wp-content/uploads/2024/12/Kubestronaut-in-Orbit-12-1-1024x537.jpg 1024w，https://www.cncf.io/wp-content/uploads /2024/12/Kubestronaut-in-Orbit-12-1-768x403.jpg 768w, https://www.cncf.io/wp-content/uploads/2024/12/Kubestronaut-in-Orbit-12-1-194x102.jpg 194w，https://www.cncf.io/wp-content/uploads /2024/12/Kubestronaut-in-Orbit-12-1-388x204.jpg 388w, https://www.cncf.io/wp-content/uploads/2024/12/Kubestronaut-in-Orbit-12-1-776x408.jpg 776w，https://www.cncf.io/wp-content/uploads /2024/12/Kubestronaut-in-Orbit-12-1-1552x816.jpg 1552w, https://www.cncf.io/wp-content/uploads/2024/12/Kubestronaut-in-Orbit-12-1-900x472.jpg 900w，https://www.cncf.io/wp-content/uploads /2024/12/Kubestronaut-in-Orbit-12-1-381x200.jpg 381w, https://www.cncf.io/wp-content/uploads/2024/12/Kubestronaut-in-Orbit-12-1-762x400.jpg 762w，https://www.cncf.io/wp-content/uploads /2024/12/Kubestronaut-in-Orbit-12-1-590x310.jpg 590w, https://www.cncf.io/wp-content/uploads/2024/12/Kubestronaut-in-Orbit-12-1-1180x620.jpg 1180w“尺寸=”自动，（最大宽度：1650px）100vw，1650px “referrerpolicy =“no-referrer”&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;了解大卫&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;本周 Orbit 的 Kubetronaut David Mukuzi 是肯尼亚内罗毕的一名 DevOps 工程师。 David 对不断学习和探索新兴技术有着根深蒂固的热情。他喜欢与协作团队合作构建可靠、高性能且易于访问的解决方案。 David 专注于通过创新和解决问题的实用方法来理解和解决客户挑战。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您想成为像 David 这样的 Kubetronaut，请在 &lt;a href=&#34;https://www.cncf.io/training/kubestronaut/&#34;&gt;CNCF Kubestronaut&lt;/a&gt; 页面获取更多详细信息。&lt; /p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;您什么时候开始使用 Kubernetes 和/或云原生？您的第一个项目是什么？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我于 2018 年开始使用 Kubernetes - 我工作的公司在裸机和云中运行 Kubernetes 工作负载。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;您现在从事或使用的主要 CNCF 项目是什么？  在您的职业生涯中，您最喜欢哪些项目？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我每天都可以与大多数&lt;a href=&#34;https://www.cncf.io/projects/&#34;&gt;毕业的 CNCF 项目&lt;/a&gt;进行互动，我很享受&lt;a href=&#34;https ://www.cncf.io/projects/kubernetes/&#34;&gt;Kubernetes&lt;/a&gt; 和 &lt;a href=&#34;https://www.cncf.io/projects/coredns/&#34;&gt;CoreDNS&lt;/a&gt; 最多。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;证书或 CNCF 对您的职业生涯有何帮助？ &lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;实用又手感认证的各个方面帮助我将知识付诸实践，并为不同的项目做出贡献，提供了额外的实践和学习。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;您为想要使用 k8s 的人推荐了哪些其他书籍/网站/课程？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.oreilly.com/library/view/networking-and-kubernetes/9781492081647/&#34;&gt;James Strong 和 Vallery Lancey 的《网络和 Kubernetes》&lt;/a&gt; 很有帮助。&lt;/ p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;你空闲时间做什么？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我喜欢烹饪和锻炼。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;您会对刚刚开始 K8s 认证之旅的人说些什么？有什么提示或技巧吗？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;练习打破事物并获得实践经验。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;如今，云原生生态系统的意义远不止 Kubernetes。您是否计划获得 CNCF 的其他云原生认证？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;现在我已经拥有所有 Kubernetes 证书，我计划参加&lt;a href=&#34;https://www.cncf.io/training/certification/pca/&#34;&gt;Prometheus Certified Associate (PCA)&lt;/a &gt; 和&lt;a href=&#34;https://www.cncf.io/training/certification/ica/&#34;&gt;Istio 认证工程师 (ICA)&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Mon, 16 Dec 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Reconsidering Kubernetes deployments: when operators are overkill】重新考虑 Kubernetes 部署：当操作员矫枉过正时</title>
      <link>https://www.cncf.io/blog/2024/12/13/reconsidering-kubernetes-deployments-when-operators-are-overkill/</link>
      <description>【&lt;p&gt;&lt;em&gt;Member post &lt;a href=&#34;https://devtron.ai/blog/reconsidering-kubernetes-deployments-when-operators-are-overkill/&#34;&gt;originally published&lt;/a&gt; on the Devtron blog by Prakarsh&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;em&gt;TL:DR: Kubernetes Operators are powerful but can be overkill for simple deployments. Explore alternatives like Helm, ArgoCD, and Devtron to streamline your Kubernetes deployments without sacrificing efficiency.&lt;/em&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In the ever-evolving landscape of container orchestration, Kubernetes stands out as a powerful tool for managing and deploying applications at scale. One of Kubernetes’ key features is its extensibility, allowing users to automate complex tasks through custom controllers called Operators. While Kubernetes Operators offer tremendous flexibility and functionality, there are scenarios where their use may be unnecessary or even detrimental to deployment workflows. In this article, we’ll explore the concept of when Kubernetes Operators might be overkill and alternative approaches to streamline deployments effectively.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;what-are-kubernetes-operators&#34;&gt;What are Kubernetes Operators?&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Out of the box, Kubernetes comes with several different features that make it quite versatile for deploying and scaling applications. However, Kubernetes can fall short in a few areas where it may only provide some basic functionality. In actual use cases, a more advanced implementation of a feature might be required. Kubernetes provides a very powerful functionality called Kubernetes Operators, which helps to extend the functionality of Kubernetes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes Operators offer a very powerful solution to enable the automation of complex clusters and systems based on a set of rules and principles. Kubernetes was designed with automation and extensibility in mind, and Kubernetes operators play a huge role in fulfilling this design principle.&amp;nbsp;&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;the-promise-of-kubernetes-operators&#34;&gt;The Promise of Kubernetes Operators&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes Operators are custom controllers that extend the Kubernetes API to manage complex applications and services. They encapsulate operational knowledge and automate tasks such as deployment, scaling, and lifecycle management. Kubernetes Operators excel at managing stateful applications, databases, and middleware, providing a declarative way to define and manage application-specific logic.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Some of the common use cases where Kubernetes Operators are used include:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Providing the ability to deploy an application on demand&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Backup an application state or restart from the backed-up state&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Managing application updates including it’s dependencies and configurations&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Expose services to applications that do not support the Kubernetes API&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;pitfalls-of-kubernetes-operators&#34;&gt;Pitfalls of Kubernetes Operators&amp;nbsp;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;While Kubernetes Operators can help extend the functionality of Kubernetes, there are some potential pitfalls. The power of the Kubernetes Operators comes with inherent complexity. Developing and maintaining Operators requires significant effort and expertise. Kubernetes Operators need to be carefully designed, tested, and updated to ensure they function correctly and adapt to changing requirements. Moreover, managing a proliferation of multiple Operators within a Kubernetes environment can lead to operational overhead and complexity, potentially outweighing the benefits they provide.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;scenarios-when-kubernetes-operators-should-be-avoided&#34;&gt;Scenarios when Kubernetes Operators should be avoided&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;While Kubernetes Operators offer a solution to manage complex applications, there are situations where their use may not be justified. In some situations, adding the Kubernetes Operators might make the problems worse. Let’s take a look at some of the situations where using a Kubernetes Operator might not be the best solution:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;1.&amp;nbsp;&lt;strong&gt;Simplicity Requirements:&amp;nbsp;&lt;/strong&gt;For straightforward deployments or applications with minimal operational complexity, leveraging built-in Kubernetes resources or simpler deployment tools may be more appropriate than developing custom Operators.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;2.&amp;nbsp;&lt;strong&gt;Resource Constraints:&lt;/strong&gt;&amp;nbsp;Organizations with limited resources or expertise may find it challenging to develop and maintain custom Kubernetes Operators effectively. In such cases, using off-the-shelf solutions or managed services may prove to be more cost-effective and efficient.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;3.&amp;nbsp;&lt;strong&gt;Overhead vs. Benefit:&amp;nbsp;&lt;/strong&gt;Assessing the trade-offs between the benefits of using Kubernetes Operators and the associated overhead is crucial. If the complexity introduced by the Operators outweighs the benefits they provide, alternative deployment approaches should be considered.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;streamline-deployments-without-kubernetes-operators&#34;&gt;Streamline Deployments without Kubernetes Operators&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;While Kubernetes Operators offer advanced automation capabilities, there are alternative approaches to streamline deployments without the complexity of custom Operators:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;1.&amp;nbsp;&lt;strong&gt;Helm Charts:&lt;/strong&gt;&amp;nbsp;Helm is a package manager for Kubernetes that simplifies the deployment and management of applications. Helm charts provide a templated approach to defining application configurations, making it easy to deploy applications consistently across environments.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;2.&lt;strong&gt;&amp;nbsp;ArgoCD:&lt;/strong&gt;&amp;nbsp;ArgoCD is a declarative, GitOps continuous delivery tool for Kubernetes. It automates the deployment of applications from Git repositories, ensuring that the desired state of applications is always maintained in the cluster.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;3.&amp;nbsp;&lt;strong&gt;Devtron:&lt;/strong&gt;&amp;nbsp;Devtron is a Kubernetes-native CI/CD platform that simplifies the deployment and management of applications on Kubernetes. It provides end-to-end automation for building, deploying, and monitoring applications, reducing the need for custom scripting or complex Kubernetes Operator configurations. Additionally, it has native integrations with ArgoCD for GitOps based deployments and Helm as well for Kubernetes deployments.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-fixed-layout&#34;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;&lt;strong&gt;Features&lt;/strong&gt;&lt;/th&gt;&lt;th&gt;Operators&lt;/th&gt;&lt;th&gt;Helm&lt;/th&gt;&lt;th&gt;ArgoCD&lt;/th&gt;&lt;th&gt;Devtron&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;Ideal for Stateful Application Lifecycle Management&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;td&gt;❌&lt;/td&gt;&lt;td&gt;❌&lt;/td&gt;&lt;td&gt;❌&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Stateless Applications&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Full Lifecycle Management&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;td&gt;❌&lt;/td&gt;&lt;td&gt;❌&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Supports GitOps&lt;/td&gt;&lt;td&gt;❌&lt;/td&gt;&lt;td&gt;❌&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Built-in Rollback Support&lt;/td&gt;&lt;td&gt;❌&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Customization&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;td&gt;❌&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Complex Application Management&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;td&gt;❌&lt;/td&gt;&lt;td&gt;❌&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Declarative Approach&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;UI Provided&lt;/td&gt;&lt;td&gt;❌&lt;/td&gt;&lt;td&gt;❌&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Security and Policy Management&lt;/td&gt;&lt;td&gt;❌&lt;/td&gt;&lt;td&gt;❌&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Low Learning Curve&lt;/td&gt;&lt;td&gt;❌&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Both CI/CD Pipelines Management&lt;/td&gt;&lt;td&gt;❌&lt;/td&gt;&lt;td&gt;❌&lt;/td&gt;&lt;td&gt;❌&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Suitable for Large Teams&lt;/td&gt;&lt;td&gt;❌&lt;/td&gt;&lt;td&gt;❌&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;conclusion-finding-the-right-balance&#34;&gt;Conclusion: Finding the Right Balance&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;While Kubernetes Operators offer powerful automation capabilities, they are not always the best fit for every deployment scenario. Organizations must carefully evaluate their deployment requirements, operational capabilities, and resource constraints to determine whether using a Kubernetes Operator is justified. By considering alternative approaches such as Helm, ArgoCD, and Devtron, organizations can streamline their Kubernetes deployments effectively without falling into the trap of Operator overkill.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In conclusion, while Kubernetes Operators have their place in complex deployment scenarios, it’s essential to reconsider their use when they introduce unnecessary complexity or overhead. By taking a pragmatic approach and exploring alternative deployment strategies, organizations can streamline their Kubernetes deployments effectively and achieve their automation goals without unnecessary complexity.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you have any queries, don’t hesitate to&amp;nbsp;&lt;a href=&#34;https://rebrand.ly/devtron-demo?ref=blog&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;connect with us&lt;/a&gt;. Connect with our growing&amp;nbsp;&lt;a href=&#34;https://rebrand.ly/Devtron-Discord?ref=devtron.ai&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;Discord Community&lt;/a&gt;&amp;nbsp;for support, discussions and shared knowledge.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;成员帖子&lt;a href=&#34;https://devtron.ai/blog/reconsidering-kubernetes-deployments-when-operators-are-overkill/&#34;&gt;最初发布&lt;/a&gt;在 Devtron 博客上普拉卡什&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;em&gt;TL:DR：Kubernetes Operator 功能强大，但对于简单部署来说可能有些过头了。探索 Helm、ArgoCD 和 Devtron 等替代方案，以在不牺牲效率的情况下简化 Kubernetes 部署。&lt;/em&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在不断发展的容器编排领域，Kubernetes 作为大规模管理和部署应用程序的强大工具脱颖而出。 Kubernetes 的主要功能之一是其可扩展性，允许用户通过称为 Operator 的自定义控制器自动执行复杂的任务。虽然 Kubernetes Operator 提供了巨大的灵活性和功能，但在某些情况下，它们的使用可能是不必要的，甚至不利于部署工作流程。在本文中，我们将探讨 Kubernetes Operator 何时可能过度杀伤力的概念以及有效简化部署的替代方法。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;what-are-kubernetes-operators&#34;&gt;什么是 Kubernetes Operator？&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes 开箱即用，具有多种不同的功能，使其非常适合部署和扩展应用程序。然而，Kubernetes 在某些领域可能存在不足，它可能只提供一些基本功能。在实际用例中，可能需要更高级的功能实现。 Kubernetes 提供了一个非常强大的功能，称为 Kubernetes Operators，它有助于扩展 Kubernetes 的功能。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes Operators 提供了一个非常强大的解决方案，可以根据一组规则和原则实现复杂集群和系统的自动化。 Kubernetes 的设计考虑了自动化和可扩展性，而 Kubernetes 操作员在实现这一设计原则方面发挥了巨大作用。  &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;the-promise-of-kubernetes-operators&#34;&gt;Kubernetes Operator 的承诺&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes Operator 是自定义控制器，可扩展 Kubernetes API 以管理复杂的应用程序和服务。它们封装了操作知识并自动执行部署、扩展和生命周期管理等任务。 Kubernetes Operator 擅长管理有状态应用程序、数据库和中间件，提供一种声明式方式来定义和管理特定于应用程序的逻辑。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;使用 Kubernetes Operator 的一些常见用例包括：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;提供按需部署应用程序的能力&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;备份应用程序状态或从备份状态重新启动&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;管理应用更新，包括其依赖项和配置&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;向不支持 Kubernetes API 的应用程序公开服务&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;pitfalls-of-kubernetes-operators&#34;&gt;PitfaKubernetes Operators lls&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;虽然 Kubernetes Operator 可以帮助扩展 Kubernetes 的功能，但也存在一些潜在的陷阱。 Kubernetes Operator 的强大功能伴随着固有的复杂性。开发和维护 Operator 需要大量的努力和专业知识。 Kubernetes Operator 需要仔细设计、测试和更新，以确保它们正常运行并适应不断变化的需求。此外，管理 Kubernetes 环境中多个 Operator 的激增可能会导致运营开销和复杂性，可能会超过它们提供的好处。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;scenarios-when-kubernetes-operators-should-be-avoided&#34;&gt;应避免使用 Kubernetes Operator 的场景&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;虽然 Kubernetes Operator 提供了管理复杂应用程序的解决方案，但在某些情况下，它们的使用可能不合理。在某些情况下，添加 Kubernetes Operator 可能会使问题变得更糟。让我们看一下使用 Kubernetes Operator 可能不是最佳解决方案的一些情况：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;1. &lt;strong&gt;简单性要求：&lt;/strong&gt;对于简单的部署或操作复杂性最低的应用程序，利用内置 Kubernetes 资源或更简单的部署工具可能比开发自定义 Operator 更合适。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;2. &lt;strong&gt;资源限制&lt;/strong&gt;：资源或专业知识有限的组织可能会发现有效开发和维护自定义 Kubernetes Operator 具有挑战性。在这种情况下，使用现成的解决方案或托管服务可能会更具成本效益和效率。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;3. &lt;strong&gt;开销与收益：&lt;/strong&gt;评估使用 Kubernetes Operator 的收益与相关开销之间的权衡至关重要。如果运营商带来的复杂性超过了它们提供的好处，则应考虑替代部署方法。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;streamline-deployments-without-kubernetes-operators&#34;&gt;无需 Kubernetes Operator 即可简化部署&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;虽然 Kubernetes Operator 提供了高级自动化功能，但还有其他方法可以简化部署，而无需自定义 Operator 的复杂性：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;1. &lt;strong&gt;Helm Charts&lt;/strong&gt;：Helm 是 Kubernetes 的包管理器，可简化应用程序的部署和管理。 Helm 图表提供了一种模板化方法来定义应用程序配置，从而可以轻松跨环境一致地部署应用程序。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;2.&lt;strong&gt;ArgoCD：&lt;/strong&gt;ArgoCD 是一款用于 Kubernetes 的声明式 GitOps 持续交付工具。它自动从 Git 存储库部署应用程序，确保集群中始终维护应用程序的所需状态。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;3. &lt;strong&gt;Devtron：&lt;/strong&gt; Devtron 是 Kubernetes 原生的 CI/CD 平台，可简化 Kubernetes 上应用程序的部署和管理。它为构建、部署和监控应用程序提供端到端自动化，减少了对自定义脚本或复杂 Kubernetes Operator 配置的需求。此外，它还与 ArgoCD 进行原生集成，以实现基于 GitOps 的部署，并与 Helm 以及 Kubernetes 部署进行原生集成。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-fixed-layout&#34;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;&lt;strong&gt;功能&lt;/strong&gt;&lt;/th&gt;&lt;th&gt;运算符&lt; /th&gt;&lt;th&gt;Helm&lt;/th&gt;&lt;th&gt;ArgoCD&lt;/th&gt;&lt;th&gt;Devtron&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;有状态应用程序生命周期的理想选择管理&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;td&gt;❌&lt;/td&gt;&lt;td&gt;❌&lt;/td&gt;&lt;td&gt;❌&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;无状态应用程序&lt; /td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;完整生命周期管理&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;td&gt;❌&lt;/td&gt;&lt;td&gt;❌&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;支持GitOps&lt;/td&gt;&lt;td&gt;❌&lt;/td&gt;&lt;td&gt;❌&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;内置回滚支持&lt;/td&gt;&lt;td&gt;❌&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;定制&lt;/ td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;td&gt;❌&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;复杂应用管理&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;td&gt;❌&lt;/td&gt;&lt;td&gt;❌&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;声明式方法&lt; /td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;用户界面提供&lt;/td&gt;&lt;td&gt;❌&lt;/td&gt;&lt;td&gt;❌&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;安全和策略管理&lt;/td&gt;&lt;td&gt;❌&lt;/td&gt;&lt;td&gt;❌&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;学习程度低曲线&lt;/td&gt;&lt;td&gt;❌&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;均为 CI/ CD管道管理&lt;/td&gt;&lt;td&gt;❌&lt;/td&gt;&lt;td&gt;❌&lt;/td&gt;&lt;td&gt;❌&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;适合大型团队&lt;/td&gt;&lt;td&gt;❌&lt;/td&gt;&lt;td&gt;❌&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;td&gt;✅&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt; /图&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;conclusion-finding-the-right-balance&#34;&gt;结论：找到正确的平衡&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;虽然 Kubernetes Operator 提供强大的自动化功能，但它们并不总是最适合每种部署场景。组织必须仔细评估其部署要求、操作能力和资源限制，以确定使用 Kubernetes Operator 是否合理。通过考虑 Helm、ArgoCD 和 Devtron 等替代方法，组织可以有效地简化其 Kubernetes 部署，而不会陷入 Operator 过度杀伤的陷阱。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;总之，虽然 Kubernetes Operator 在复杂的部署场景中占有一席之地，但当它们引入不必要的复杂性或开销时，有必要重新考虑它们的使用。通过采取务实的方法并探索替代部署策略，组织可以有效地简化其 Kubernetes 部署并实现其自动化目标，而无需不必要的复杂性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您有任何疑问，请随时&lt;a href=&#34;https://rebrand.ly/devtron-demo?ref=blog&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;与我们联系&lt;/a&gt;。与我们不断成长的&lt;a href=&#34;https://rebrand.ly/Devtron-Discord?ref=devtron.ai&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34; 联系&gt;Discord 社区&lt;/a&gt;提供支持、讨论和共享知识。&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Thu, 12 Dec 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Announcing Linkerd 2.17: Egress, rate limiting, and federated services】宣布 Linkerd 2.17：出口、速率限制和联合服务</title>
      <link>https://www.cncf.io/blog/2024/12/05/announcing-linkerd-2-17-egress-rate-limiting-and-federated-services/</link>
      <description>【&lt;p&gt;&lt;em&gt;Project post originally published on the &lt;a href=&#34;https://linkerd.io/2024/12/05/announcing-linkerd-2.17/&#34;&gt;Linkerd blog&lt;/a&gt; by William Morgan&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Today we’re happy to announce the release of Linkerd 2.17, a new version of Linkerd that introduces several major new features to the project: egress traffic visibility and control; rate limiting; and&amp;nbsp;&lt;em&gt;federated services,&lt;/em&gt;&amp;nbsp;a powerful new multicluster primitive that combines services running in multiple clusters into a single logical service. This release also updates Linkerd to support OpenTelemetry for distributed tracing.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Linkerd 2.17 is our first major release since our&amp;nbsp;&lt;a href=&#34;https://linkerd.io/2024/10/23/making-linkerd-sustainable/&#34;&gt;announcement of Linkerd’s sustainability in October&lt;/a&gt;. Not unrelatedly, it is one of the first Linkerd releases in years to introduce multiple significant features at once. Despite this, we worked hard to stay true to Linkerd’s core design principle of&amp;nbsp;&lt;em&gt;simplicity&lt;/em&gt;. For example, these new features are designed to avoid configuration when possible; and when not possible, to make it minimal, consistent, and principled. After all, Linkerd’s simplicity—our rejection of the status quo that says, “the service mesh is complex and must be complex”—is key to its popularity, and it’s our duty to live up to that reputation in this and every release.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Read on for more!&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;egress-visibility-and-control&#34;&gt;Egress visibility and control&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Linkerd 2.17 introduces visibility and control for egress traffic leaving the Kubernetes cluster from meshed pods. Kubernetes itself provides no mechanisms for understanding egress traffic, and only rudimentary ones for restricting it, limited to IP ranges and ports. With the 2.17 release, Linkerd now gives you full L7 (i.e. application-layer) visibility and control of all egress traffic: you can view the source, destination, and traffic levels of all traffic leaving your cluster, including the hostnames, and, with configuration, the full HTTP paths or gRPC methods. You also can deploy&amp;nbsp;&lt;em&gt;egress security policies&lt;/em&gt;&amp;nbsp;that allow or disallow that traffic with that same level of granularity, allowing you to allowlist or blocklist egress by DNS domain rather than IP range and port.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Linkerd’s egress functionality does not require changes from the application and only minimal configuration to get started. For more advanced usage, egress configuration is built on Gateway API resources, allowing you to configure egress visibility and policies with the same extensible and Kubernetes-native configuration primitives used for almost every other aspect of Linkerd, including dynamic traffic routing, zero trust authorization policies, and more.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For example, enabling basic egress metrics across the entire cluster is as simple as adding this configuration:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;&lt;a href=&#34;https://linkerd.io/2024/12/05/announcing-linkerd-2.17/#&#34;&gt;&lt;/a&gt;&lt;code&gt;apiVersion: policy.linkerd.io/v1alpha1&#xA;kind: EgressNetwork&#xA;metadata:&#xA;  namespace: linkerd-egress&#xA;  name: all-egress-traffic&#xA;spec:&#xA;  trafficPolicy: Allow&#xA;&lt;/code&gt;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;See&amp;nbsp;&lt;a href=&#34;https://linkerd.io/2.17/features/egress/&#34;&gt;egress docs&lt;/a&gt;&amp;nbsp;for more.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;rate-limiting&#34;&gt;Rate limiting&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Rate limiting is a reliability mechanism that protects services from being overloaded. In contrast to&amp;nbsp;&lt;a href=&#34;https://linkerd.io/2/reference/circuit-breaking/&#34;&gt;Linkerd’s circuit breaking feature&lt;/a&gt;, which is client-side behavior designed to protect clients from failing services, rate limiting is server-side behavior: it is enforced by the service receiving the traffic and designed to protect it from misbehaving clients.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Just as with egress, Linkerd’s rate limiting feature is designed to require minimal configuration, while still being flexible and configurable to a wide variety of scenarios. For example, a basic rate limit of 100 requests per second for a Server named “web-http” can be enabled with this configuration:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;&lt;a href=&#34;https://linkerd.io/2024/12/05/announcing-linkerd-2.17/#&#34;&gt;&lt;/a&gt;&lt;code&gt;apiVersion: policy.linkerd.io/v1alpha1&#xA;kind: HTTPLocalRateLimitPolicy&#xA;metadata:&#xA;  namespace: emojivoto&#xA;  name: web-rlpolicy&#xA;spec:&#xA;  targetRef:&#xA;    group: policy.linkerd.io&#xA;    kind: Server&#xA;    name: web-http&#xA;  total:&#xA;    requestsPerSecond: 100&#xA;&lt;/code&gt;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Linkerd’s rate limiting feature also provides&amp;nbsp;&lt;em&gt;per-client&lt;/em&gt;&amp;nbsp;rate limit policies that allow you to ensure rate limits are distributed “fairly” across multiple clients. Combined with retries, timeouts, circuit breaking, latency-aware load balancing, and dynamic traffic routing, rate limiting extends Linkerd’s already wide arsenal of in-cluster distributed system reliability features.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;See&amp;nbsp;&lt;a href=&#34;https://linkerd.io/2.17/features/rate-limiting/&#34;&gt;rate limiting docs&lt;/a&gt;&amp;nbsp;for more.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;federated-services&#34;&gt;Federated services&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In Linkerd 2.17 we’ve shipped an exciting new multicluster feature:&amp;nbsp;&lt;em&gt;federated services&lt;/em&gt;. A federated service is a logical union of the replicas of the same service across multiple clusters. Meshed clients talking to a federated service will automatically load balance across all endpoints in all clusters, taking full advantage of Linkerd’s best-in-class latency-aware load balancing.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;With federated services, not only is application code decoupled from cluster deployment decisions—service&amp;nbsp;&lt;em&gt;Foo&lt;/em&gt;&amp;nbsp;talking to service&amp;nbsp;&lt;em&gt;Bar&lt;/em&gt;&amp;nbsp;needs only to call “Bar”, not to specify which cluster(s) it is on—but failure handling is transparent and automatic as well. Linkerd will transparently handle a wide variety of situations, including:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;An entire cluster is down&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;A cluster is up but the service on that cluster is down, or failing in some way (including L7 failures, e.g. returning 5xx response codes)&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;A cluster is slow, or the service is slow&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In all these cases, Linkerd will automatically load balance across all service endpoints on all clusters, using its default latency-aware (latency EWMA) balancing to send individual requests to the best endpoint.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Federated services were designed to capture a recent trend we see in multicluster Kubernetes adoption:&amp;nbsp;&lt;em&gt;planned large-scale multicluster&lt;/em&gt;&amp;nbsp;Kubernetes. Linkerd’s original multicluster functionality, released in the good ol’ days of Linkerd 2.8, was designed for the ad-hoc, pair-to-pair connectivity that was common at the time. However, modern Kubernetes platforms are often much more intentional in their multicluster usage, sometimes ranging into the hundreds or thousands of clusters. Federated services join features such as&amp;nbsp;&lt;a href=&#34;https://linkerd.io/2/tasks/pod-to-pod-multicluster/&#34;&gt;flat network / pod-to-pod multicluster&lt;/a&gt;&amp;nbsp;(introduced in Linkerd 2.14) in the toolbox for this new class of Kubernetes adoption.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;See&amp;nbsp;&lt;a href=&#34;https://linkerd.io/2.17/features/multicluster/#federated-services&#34;&gt;federated services docs&lt;/a&gt;&amp;nbsp;for more.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;linkerd-day-at-kubecon-london&#34;&gt;Linkerd Day at KubeCon London&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We’re delighted to report that&amp;nbsp;&lt;a href=&#34;https://events.linuxfoundation.org/kubecon-cloudnativecon-europe/co-located-events/linkerd-day/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;the CNCF is hosting Linkerd Day&lt;/a&gt;&amp;nbsp;at KubeCon London next April! Many of the Linkerd maintainers will be in attendance, and we’re expecting a great lineup of Linkerd talks as well as plenty of Linkerd users. Come see us in London!&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;how-to-get-linkerd-217&#34;&gt;How to get Linkerd 2.17&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The&amp;nbsp;&lt;a href=&#34;https://github.com/linkerd/linkerd2/releases/tag/edge-24.11.8&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;edge-24.11.8&lt;/a&gt;&amp;nbsp;release is the corresponding edge release for Linkerd 2.17. See the&amp;nbsp;&lt;a href=&#34;https://linkerd.io/releases/&#34;&gt;Linkerd releases page&lt;/a&gt;&amp;nbsp;for more.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://buoyant.io/?__hstc=249056664.5dad504b3803eb06e8ad542f84a8c351.1733415865270.1733415865270.1733415865270.1&amp;amp;__hssc=249056664.1.1733415865270&amp;amp;__hsfp=2110343318&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Buoyant&lt;/a&gt;, the creators of Linkerd, has additionally released&amp;nbsp;&lt;a href=&#34;https://buoyant.io/blog/announcing-linkerd-2-17/?__hstc=249056664.5dad504b3803eb06e8ad542f84a8c351.1733415865270.1733415865270.1733415865270.1&amp;amp;__hssc=249056664.1.1733415865270&amp;amp;__hsfp=2110343318&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Buoyant Enterprise for Linkerd 2.17.0&lt;/a&gt;&amp;nbsp;and published a&amp;nbsp;&lt;a href=&#34;https://docs.buoyant.io/release-notes/buoyant-enterprise-linkerd/enterprise-2.17.0/?__hstc=249056664.5dad504b3803eb06e8ad542f84a8c351.1733415865270.1733415865270.1733415865270.1&amp;amp;__hssc=249056664.1.1733415865270&amp;amp;__hsfp=2110343318&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Linkerd 2.17 changelog&lt;/a&gt;&amp;nbsp;with additional guidance and content.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;linkerd-is-for-everyone&#34;&gt;Linkerd is for everyone&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Linkerd is a graduated project of the&amp;nbsp;&lt;a href=&#34;https://cncf.io/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Cloud Native Computing Foundation&lt;/a&gt;. Linkerd is&amp;nbsp;&lt;a href=&#34;https://linkerd.io/2019/10/03/linkerds-commitment-to-open-governance/&#34;&gt;committed to open governance.&lt;/a&gt;&amp;nbsp;If you have feature requests, questions, or comments, we’d love to have you join our rapidly-growing community! Linkerd is hosted on&amp;nbsp;&lt;a href=&#34;https://github.com/linkerd/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;GitHub&lt;/a&gt;, and we have a thriving community on&amp;nbsp;&lt;a href=&#34;https://slack.linkerd.io/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Slack&lt;/a&gt;,&amp;nbsp;&lt;a href=&#34;https://twitter.com/linkerd&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Twitter&lt;/a&gt;, and the&amp;nbsp;&lt;a href=&#34;https://linkerd.io/community/get-involved/&#34;&gt;mailing lists&lt;/a&gt;. Come and join the fun!&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;项目帖子最初由 William Morgan 在 &lt;a href=&#34;https://linkerd.io/2024/12/05/announcing-linkerd-2.17/&#34;&gt;Linkerd 博客&lt;/a&gt;上发布&lt;/a&gt;嗯&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;今天，我们很高兴地宣布发布 Linkerd 2.17，这是 Linkerd 的新版本，为该项目引入了几个主要的新功能：出口流量可见性和控制；速率限制；联合服务是一种强大的新多集群原语，它将多个集群中运行的服务组合成单个逻辑服务。此版本还更新了 Linkerd 以支持 OpenTelemetry 进行分布式跟踪。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Linkerd 2.17 是我们自&lt;a href=&#34;https://linkerd.io/2024/10/23/making-linkerd-sustainable/&#34;&gt;10 月宣布 Linkerd 可持续发展&lt;/a&gt;以来的第一个主要版本。并非不相关的是，它是多年来第一个同时引入多个重要功能的 Linkerd 版本之一。尽管如此，我们还是努力忠于 Linkerd 的核心设计原则：&lt;em&gt;简单&lt;/em&gt;。例如，这些新功能旨在尽可能避免配置；当不可能时，使其最小化、一致且有原则。毕竟，Linkerd 的简单性——我们对“服务网格很复杂而且必须很复杂”的现状的拒绝——是其受欢迎的关键，我们有责任在这个版本和每个版本中不辜负这一声誉。&lt; /p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;继续阅读以了解更多信息！&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;egress-visibility-and-control&#34;&gt;出口可见性和控制&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Linkerd 2.17 引入了对从网状 Pod 离开 Kubernetes 集群的出口流量的可见性和控制。 Kubernetes 本身没有提供了解出口流量的机制，仅提供基本的限制机制，仅限于 IP 范围和端口。在 2.17 版本中，Linkerd 现在为您提供对所有出口流量的完整 L7（即应用程序层）可见性和控制：您可以查看离开集群的所有流量的源、目的地和流量级别（包括主机名），并且，配置、完整的 HTTP 路径或 gRPC 方法。您还可以部署&lt;em&gt;出口安全策略&lt;/em&gt;，以相同的粒度允许或禁止该流量，从而允许您按 DNS 域而不是 IP 范围和端口将出口列入允许或阻止列表。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Linkerd 的出口功能不需要对应用程序进行更改，只需最少的配置即可启动。对于更高级的使用，出口配置基于网关 API 资源，允许您使用用于 Linkerd 几乎所有其他方面的相同可扩展和 Kubernetes 原生配置原语来配置出口可见性和策略，包括动态流量路由、零信任授权策略等等。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;例如，在整个集群中启用基本出口指标就像添加以下配置一样简单：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;代码类s=&#34;&#34;&gt;&lt;a href=&#34;https://linkerd.io/2024/12/05/announcing-linkerd-2.17/#&#34;&gt;&lt;/a&gt;&lt;code&gt;api版本：policy.linkerd.io/v1alpha1&#xA;种类：出口网络&#xA;元数据：&#xA;  命名空间：linkerd-egress&#xA;  名称：所有出口流量&#xA;规格：&#xA;  流量策略：允许&#xA;&lt;/code&gt;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;请参阅&lt;a href=&#34;https://linkerd.io/2.17/features/egress/&#34;&gt;egress 文档&lt;/a&gt;了解更多信息。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;rate-limiting&#34;&gt;速率限制&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;速率限制是一种防止服务过载的可靠性机制。与 &lt;a href=&#34;https://linkerd.io/2/reference/circum-writing/&#34;&gt;Linkerd 的熔断功能&lt;/a&gt;（旨在保护客户端免受失败服务影响的客户端行为）相比，限制是服务器端行为：它由接收流量的服务强制执行，旨在保护其免受行为不当的客户端的影响。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;与出口一样，Linkerd 的速率限制功能旨在需要最少的配置，同时仍然灵活且可配置到各种场景。例如，可以使用以下配置启用名为“web-http”的服务器每秒 100 个请求的基本速率限制：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;&lt;a href=&#34;https://linkerd.io/2024/12/05/announcing-linkerd-2.17/#&#34;&gt;&lt;/a &gt;&lt;code&gt;api版本：policy.linkerd.io/v1alpha1&#xA;种类：HTTPLocalRateLimitPolicy&#xA;元数据：&#xA;  命名空间：表情符号&#xA;  名称：web-rlpolicy&#xA;规格：&#xA;  目标参考：&#xA;    组：policy.linkerd.io&#xA;    种类：服务器&#xA;    名称：web-http&#xA;  全部的：&#xA;    每秒请求数：100&#xA;&lt;/code&gt;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Linkerd 的速率限制功能还提供&lt;em&gt;每个客户端&lt;/em&gt;的速率限制策略，使您能够确保速率限制在多个客户端之间“公平”分配。与重试、超时、断路、延迟感知负载平衡和动态流量路由相结合，速率限制扩展了 Linkerd 已经广泛的集群内分布式系统可靠性功能。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;请参阅&lt;a href=&#34;https://linkerd.io/2.17/features/rate-limiting/&#34;&gt;速率限制文档&lt;/a&gt;了解更多信息。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;federated-services&#34;&gt;联合服务&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在 Linkerd 2.17 中，我们推出了一项令人兴奋的新多集群功能：&lt;em&gt;联合服务&lt;/em&gt;。联合服务是跨多个集群的同一服务的副本的逻辑联合。与联合服务通信的网状客户端将自动在所有集群中的所有端点之间进行负载平衡，充分利用 Linkerd 一流的延迟感知负载平衡。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;借助联合服务，应用程序代码不仅可以与集群部署决策分离，服务 &lt;em&gt;Foo&lt;/em&gt; 与服务 &lt;em&gt;Bar&lt;/em&gt; 通信只需调用“Bar”，而不需要指定哪个服务它所在的集群 - 但故障处理也是透明且自动的。 Linkerd 将透明地处理各种情况，包括：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul cl屁股=“wp-block-list”&gt;&#xA;&lt;li&gt;整个集群已关闭&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;集群已启动，但该集群上的服务已关闭，或以某种方式出现故障（包括 L7 故障，例如返回 5xx 响应代码）&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;集群速度慢，或者服务速度慢&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在所有这些情况下，Linkerd 将自动在所有集群上的所有服务端点之间进行负载平衡，使用其默认的延迟感知（延迟 EWMA）平衡将各个请求发送到最佳端点。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;联合服务旨在捕捉我们在多集群 Kubernetes 采用方面看到的最新趋势：&lt;em&gt;计划的大规模多集群&lt;/em&gt; Kubernetes。 Linkerd 最初的多集群功能在 Linkerd 2.8 的美好时光中发布，专为当时常见的临时、对对连接而设计。然而，现代 Kubernetes 平台在多集群使用方面通常更加有意，有时会涉及数百或数千个集群。联合服务加入了诸如&lt;a href=&#34;https://linkerd.io/2/tasks/pod-to-pod-multicluster/&#34;&gt;扁平网络/pod-to-pod 多集群&lt;/a&gt;（在 Linkerd 中引入）等功能2.14）在用于此类新 Kubernetes 采用的工具箱中。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;有关详细信息，请参阅&lt;a href=&#34;https://linkerd.io/2.17/features/multicluster/#federated-services&#34;&gt;联合服务文档&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;linkerd-day-at-kubecon-london&#34;&gt;KubeCon 伦敦 Linkerd 日&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们很高兴地报告&lt;a href=&#34;https://events.linuxfoundation.org/kubecon-cloudnativecon-europe/co- located-events/linkerd-day/&#34; target=&#34;_blank&#34; rel=&#34; noreferrer noopener&#34;&gt;CNCF 将于明年四月在伦敦 KubeCon 举办 Linkerd Day&lt;/a&gt;！许多 Linkerd 维护者都将出席，我们期待 Linkerd 演讲的精彩阵容以及大量 Linkerd 用户。来伦敦见我们吧！&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;how-to-get-linkerd-217&#34;&gt;如何获取 Linkerd 2.17&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/linkerd/linkerd2/releases/tag/edge-24.11.8&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;edge-24.11.8&lt;/ a&gt; 版本是 Linkerd 2.17 的相应边缘版本。请参阅&lt;a href=&#34;https://linkerd.io/releases/&#34;&gt;Linkerd 版本页面&lt;/a&gt;了解更多信息。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;一href=&#34;https://buoyant.io/?__hstc=249056664.5dad504b3803eb06e8ad542f84a8c351.173341586 5270.1733415865270.1733415865270.1&amp;__hssc=249056664.1.1733415865270&amp;__hsfp=2110343318&#34; Linkerd 的创建者 target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Buoyant&lt;/a&gt; 还发布了&lt;a href=&#34;https://buoyant.io/blog/announcing-linkerd-2-17/?__hstc=249056664.5dad504b3803eb06e8ad542f84a8 c351.1733415865270.1733415865270.1733415865270.1&amp;__hssc=249056664.1.1733415865270&amp;__hsfp=2110343318&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Buoyant Enterprise for Linkerd 2.17.0&lt;/a&gt; 并发布了 &lt;a href=&#34;https://docs.buoyant.io/release-notes/buoyant-企业-linkerd/enterprise-2.17.0/?__hstc=249056664.5dad504b3803eb06e8ad542f84a8c351.173 3415865270.1733415865270.1733415865270.1&amp;__hssc=249056664.1.1733415865270&amp;__hsfp=2110343318&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Linkerd 2.17 变更日志&lt;/a&gt;，包含更多指导和内容。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;linkerd-is-for-everyone&#34;&gt;Linkerd 适合所有人&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Linkerd 是&lt;a href=&#34;https://cncf.io/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;云原生计算基金会&lt;/a&gt;的毕业项目。 Linkerd &lt;a href=&#34;https://linkerd.io/2019/10/03/linkerds-commitment-to-open-governance/&#34;&gt;致力于开放治理。&lt;/a&gt;如果您有功能请求、疑问，或评论，我们很高兴您加入我们快速发展的社区！ Linkerd 托管在 &lt;a href=&#34;https://github.com/linkerd/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;GitHub&lt;/a&gt; 上，我们在 &lt;a href=&#34; 上拥有一个蓬勃发展的社区https://slack.linkerd.io/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Slack&lt;/a&gt;，&lt;a href=&#34;https://twitter.com/linkerd&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Twitter&lt;/a&gt; 和&lt;a href=&#34;https://linkerd.io/community/get-involved/&#34;&gt;邮件列表&lt;/a&gt;。快来加入乐趣吧！&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Wed, 04 Dec 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Understanding k0s: a lightweight Kubernetes distribution for the community】了解 k0s：面向社区的轻量级 Kubernetes 发行版</title>
      <link>https://www.cncf.io/blog/2024/12/06/understanding-k0s-a-lightweight-kubernetes-distribution-for-the-community/</link>
      <description>【&lt;p&gt;&lt;em&gt;Ambassador post by Prithvi Raj, CNCF Ambassador and Community Manager at Mirantis&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As Kubernetes continues to grow as the de-facto orchestration platform for containerized applications and is massively adopted by large, medium as well as small enterprises, the need for a&amp;nbsp;lightweight, flexible, and easy-to-manage Kubernetes distribution has become more evident in the community.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;One such distribution, &lt;strong&gt;k0s&lt;/strong&gt;, has emerged as a powerful yet minimal solution, catering to developers and enterprises seeking to deploy Kubernetes clusters with ease and efficiency. In this blog, we’ll take an in-depth look at k0s, its features, benefits, and how it compares to other Kubernetes distributions.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Introducing k0s&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The idea and aim was to reduce the complexity of setting up and managing Kubernetes clusters which are often a hassle, by providing an easy-to-use, lightweight, simpler installation process while maintaining full compatibility with Kubernetes APIs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;k0s is an open-source, single-binary Kubernetes distribution designed to be lightweight, simple to deploy, and highly flexible. Unlike other Kubernetes distributions, k0s aims to reduce the complexity of setting up and managing Kubernetes clusters by providing an easy-to-use installation process while maintaining full compatibility with Kubernetes APIs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;P.S: k0s is a “Certified Kubernetes” tool that has achieved the Software Conformance badge ensuring that every vendor’s version of Kubernetes supports the required APIs, as do open source community versions.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;What does it mean?&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Consistency: Users want consistency when interacting with any installation of Kubernetes.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Timely updates: To remain certified, vendors need to provide the latest version of Kubernetes yearly or more frequently, so you can be sure that you’ll always have access to the latest features the community has been working hard to deliver.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Confirmability: Any end user can confirm that their distribution or platform remains conformant by running the identical open source conformance application (Sonobuoy) that was used to certify.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Maintained by folks from Mirantis and Replicated, k0s is designed to run on a wide range of environments, from bare-metal servers to cloud-based platforms, and even on edge devices. The key differentiator of k0s is its minimalistic approach, where it consolidates multiple Kubernetes components into a single binary, making the installation and operational overhead much lower than traditional Kubernetes setups. When k0s is running, there will be the “real” binaries of apiserver, etcd, kubelet, containerd, runc and so on. k0s even ships its own statically linked versions of IP tables, for example. Which is one reason why the k0s binary is substantially bigger compared to the k3s binary.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Key Features of k0s&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Single Binary Architecture:&lt;/strong&gt; One of the most notable features of k0s is its single binary architecture. Unlike other Kubernetes distributions that require multiple components (e.g., kube-apiserver, kube-scheduler, etc.) to be installed and configured separately, k0s consolidates these into a single executable file. This simplicity reduces the number of dependencies and simplifies upgrades and patching.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Zero Dependencies:&lt;/strong&gt; k0s does not require any external dependencies, which makes it easier to deploy and maintain. This is a significant advantage over other Kubernetes distributions that require multiple services and components to be installed and configured.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Lightweight and Efficient:&lt;/strong&gt; k0s is optimized to consume fewer system resources than some other Kubernetes distributions. This lightweight design makes it an ideal choice for use cases where system resources are limited, such as on edge devices or in small-scale cloud environments.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Multi-Node Clusters:&lt;/strong&gt; Despite its minimalistic design, k0s supports multi-node clusters, which can scale from a single node to hundreds of nodes. This scalability ensures that k0s can be used for both small development environments and large production systems.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Compatibility with Kubernetes Ecosystem:&lt;/strong&gt; k0s is fully compliant with the Kubernetes API, meaning that it can work with any Kubernetes-compatible tools, services, and applications. Developers can use the same kubectl commands, Helm charts, and other Kubernetes-native resources to manage k0s clusters.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Support for Edge and IoT:&lt;/strong&gt; With its lightweight footprint, k0s is particularly well-suited for edge and Internet of Things (IoT) deployments. It can be run on low-powered devices with minimal configuration, allowing for Kubernetes to be deployed in environments where other distributions might be too heavy.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Built-in High Availability (HA) Support:&lt;/strong&gt; k0s includes native support for high availability, allowing for the creation of highly resilient Kubernetes clusters. This feature makes it suitable for both development and production environments that require minimal downtime and fault tolerance.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;How k0s Compares to Other Kubernetes Distributions&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;While there are numerous Kubernetes distributions available, including well-known ones like &lt;strong&gt;k3s, OpenShift, Rancher, EKS, GKE, and AKS,&lt;/strong&gt; k0s sets itself apart in several ways:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;k3s vs. k0s:&lt;/strong&gt; Both k3s and k0s are lightweight Kubernetes distributions, but k0s has a simpler, more minimalistic approach. k3s requires fewer resources, but k0s offers a more comprehensive feature set with a single binary and no external dependencies. While k3s is also optimized for edge environments, k0s provides greater flexibility for running large-scale Kubernetes clusters.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Managed vs. Self-Managed:&lt;/strong&gt; Unlike managed Kubernetes services like Amazon’s EKS or Google’s GKE, k0s is a self-managed solution. This gives users full control over their clusters and configuration, making it a good choice for developers or teams who want flexibility without the overhead of managing complex Kubernetes clusters.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To power the management of k0s clusters there is &lt;a href=&#34;https://k0smotron.io/?utm_source=paid-search&amp;amp;utm_medium=google&amp;amp;utm_campaign=2025q4-brand-global&amp;amp;utm_content=k0smotron&amp;amp;gad_source=1&amp;amp;gclid=CjwKCAiA3ZC6BhBaEiwAeqfvytfVY2MMumfhLV9FpxghjanA9lUK3UOvHYgwrE0K84v2JPVAHfcSCxoCZoYQAvD_BwE&#34;&gt;k0smotron&lt;/a&gt;, for efficient management of k0s Kubernetes clusters. It enables you to run Kubernetes control planes within a management cluster and with the integration of Cluster API it streamlines various cluster operations, providing support for tasks such as provisioning, scaling, and upgrading clusters.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Ease of Use:&lt;/strong&gt; k0s emphasizes simplicity and ease of use with its single binary, whereas some other distributions require more complicated setups. For users looking for a Kubernetes distribution that requires minimal setup, k0s is an appealing option.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Use Cases for k0s&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Edge and IoT Deployments:&lt;/strong&gt; Due to its minimal resource usage, k0s is particularly well-suited for edge computing and Internet of Things (IoT) environments where resources may be limited. It can be deployed on devices with lower processing power and less memory, providing a robust Kubernetes solution even in constrained environments.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Development Environments:&lt;/strong&gt; Developers can quickly set up a local Kubernetes cluster using k0s to test their applications. Its simplicity and quick deployment process make it a perfect fit for rapid development and testing.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Small to Medium-Sized Enterprises (SMEs):&lt;/strong&gt; k0s’ low operational overhead and scalability make it ideal for small and medium-sized businesses that want the power of Kubernetes without the complexity and cost of more heavyweight distributions.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Production Systems:&lt;/strong&gt; For production systems that need high availability and scalability, k0s can be configured to meet these demands, offering an efficient, reliable, and easy-to-manage Kubernetes solution.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Installing k0s&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Installing k0s is a straightforward process, especially compared to other Kubernetes distributions. The installation process typically involves the following steps:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Download the k0s Binary:&lt;/strong&gt; First, download the appropriate binary for your system from the official&lt;a href=&#34;https://github.com/k0sproject/k0s&#34;&gt; k0s GitHub repository&lt;/a&gt;.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Run the k0s Server:&lt;/strong&gt; Start the k0s server using a single command. The server will initialize the Kubernetes control plane and worker nodes.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Join Worker Nodes:&lt;/strong&gt; After setting up the control plane, worker nodes can be easily added to the cluster with a simple join command, allowing for quick expansion of the cluster.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Access the Cluster:&lt;/strong&gt; Use kubectl to manage and interact with your k0s cluster, just like you would with any other Kubernetes setup.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;k0s community&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The k0s community discussions will commence on the Kubernetes Slack Workspace. Join the &lt;a href=&#34;https://kubernetes.slack.com/archives/C0809EA06QZ&#34;&gt;#k0s-users&lt;/a&gt; &amp;amp; &lt;a href=&#34;https://kubernetes.slack.com/archives/C07VAPJUECS&#34;&gt;#k0s-dev&lt;/a&gt; channels to ask your questions, share your user stories and discuss your contributions with the maintainers.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Join the k0s community office hours on every last Tuesday of the month at 3 PM EET/ 1 PM GMT.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To get an invite please fill out the &lt;a href=&#34;https://forms.gle/sKwq26McSusRDyoE9&#34;&gt;invitation form&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Here are the &lt;a href=&#34;https://docs.google.com/document/d/1K7kc4nARFsM60RpzWF7xREF9FHySDuWSu9_6dstkLlg/edit?usp=sharing&#34;&gt;meeting notes&lt;/a&gt; for the community office hours.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;k0s is a lightweight, efficient, and highly flexible Kubernetes distribution that stands out for its simplicity and ease of use. Its single binary architecture, compatibility with the Kubernetes ecosystem, and focus on minimalism make it a compelling choice for developers, edge deployments, and small to medium-sized enterprises looking to harness the power of Kubernetes without the complexity and overhead of traditional setups. Whether you are just starting out with Kubernetes or managing large-scale clusters, k0s offers a scalable and manageable solution that can fit a variety of use cases.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For those interested in a more streamlined Kubernetes experience, k0s represents an exciting alternative to other Kubernetes distributions, offering both power and flexibility in a compact package.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;CNCF 大使兼 Mirantis 社区经理 Prithvi Raj 担任大使职务&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;随着 Kubernetes 作为容器化应用程序事实上的编排平台不断发展，并被大中小型企业广泛采用，对轻量级、灵活且易于管理的 Kubernetes 发行版的需求已成为在社区中更为明显。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这样的发行版 &lt;strong&gt;k0s&lt;/strong&gt; 已成为一种功能强大但又极简的解决方案，可满足寻求轻松高效地部署 Kubernetes 集群的开发人员和企业的需求。在本博客中，我们将深入了解 k0s、它的功能、优点以及它与其他 Kubernetes 发行版的比较。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;k0s 简介&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这个想法和目标是通过提供易于使用、轻量级、更简单的安装过程，同时保持与 Kubernetes API 的完全兼容性，降低设置和管理 Kubernetes 集群的复杂性（这通常是一件麻烦事）。&lt;/p &gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;k0s 是一个开源的单二进制 Kubernetes 发行版，旨在轻量级、易于部署且高度灵活。与其他 Kubernetes 发行版不同，k0s 旨在通过提供易于使用的安装过程来降低设置和管理 Kubernetes 集群的复杂性，同时保持与 Kubernetes API 的完全兼容性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;P.S：k0s 是一款“经过认证的 Kubernetes”工具，已获得软件一致性徽章，确保每个供应商的 Kubernetes 版本都支持所需的 API，开源社区版本也是如此。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这是什么意思？&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;一致性：用户在与任何 Kubernetes 安装交互时都希望保持一致性。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;及时更新：为了保持认证，供应商需要每年或更频繁地提供最新版本的 Kubernetes，这样您就可以确保您始终能够访问社区一直在努力提供的最新功能。&lt; /里&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;可确认性：任何最终用户都可以通过运行用于认证的相同开源一致性应用程序 (Sonobuoy) 来确认其发行版或平台保持一致性。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;k0s 由 Mirantis 和 Replicated 的人员维护，旨在在各种环境中运行，从裸机服务器到基于云的平台，甚至边缘设备。 k0s 的主要区别在于其简约的方法，它将多个 Kubernetes 组件整合到一个二进制文件中，从而使安装和操作开销远低于传统的 Kubernetes 设置。当 k0s 运行时，会有 apiserver、etcd、kubelet、containerd、runc 等“真正的”二进制文件。例如，k0s 甚至发布了自己的静态链接版本的 IP 表。这就是 k0s 二进制文件比 k3s 二进制文件大得多的原因之一。&lt;/p&gt;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;k0s 的主要特性&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;&lt;strong&gt;单一二进制架构：&lt;/strong&gt;k0s 最显着的功能之一是其单一二进制架构。与其他需要单独安装和配置多个组件（例如 kube-apiserver、kube-scheduler 等）的 Kubernetes 发行版不同，k0s 将这些组件整合到一个可执行文件中。这种简单性减少了依赖项的数量并简化了升级和修补。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;零依赖&lt;/strong&gt;：k0s 不需要任何外部依赖，这使得部署和维护更加容易。与其他需要安装和配置多个服务和组件的 Kubernetes 发行版相比，这是一个显着的优势。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;轻量级且高效&lt;/strong&gt;：k0s 经过优化，比其他一些 Kubernetes 发行版消耗更少的系统资源。这种轻量级设计使其成为系统资源有限的用例（例如边缘设备或小型云环境）的理想选择。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;多节点集群&lt;/strong&gt;：尽管 k0s 设计简约，但它支持多节点集群，可以从单个节点扩展到数百个节点。这种可扩展性确保 k0s 可用于小型开发环境和大型生产系统。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;与 Kubernetes 生态系统的兼容性&lt;/strong&gt;：k0s 完全符合 Kubernetes API，这意味着它可以与任何 Kubernetes 兼容的工具、服务和应用程序配合使用。开发人员可以使用相同的 kubectl 命令、Helm 图表和其他 Kubernetes 原生资源来管理 k0s 集群。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;支持边缘和物联网&lt;/strong&gt;：k0s 占地面积小，特别适合边缘和物联网 (IoT) 部署。它可以以最少的配置在低功耗设备上运行，从而允许 Kubernetes 部署在其他发行版可能过于繁重的环境中。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;内置高可用性 (HA) 支持：&lt;/strong&gt;k0s 包含对高可用性的本机支持，允许创建高度弹性的 Kubernetes 集群。此功能使其适用于需要最短停机时间和容错能力的开发和生产环境。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;k0s 与其他 Kubernetes 发行版相比如何&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;虽然有许多可用的 Kubernetes 发行版，包括 &lt;strong&gt;k3s、OpenShift、Rancher、EKS、GKE 和 AKS 等知名发行版，&lt;/strong&gt;k0s 在以下几个方面脱颖而出：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;k3s 与 k0s：&lt;/strong&gt;k3s 和 k0s 都是轻量级 Kubernetes 发行版，但 k0s 具有更简单、更简约的方法。 k3s 需要更少的资源，但 k0s 通过单个二进制文件提供了更全面的功能集，并且无需外部依赖。虽然 k3s 也针对边缘环境进行了优化，但 k0s 为运行大规模 Kubernetes 集群提供了更大的灵活性。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;托管与自我管理：&lt;/strong&gt;与 Amazon 的 EKS 或 Google 的 GKE 等托管 Kubernetes 服务不同，k0s 是一种自我管理的解决方案。这使用户可以完全控制其集群和配置，对于想要灵活性且无需管理复杂 Kubernetes 集群开销的开发人员或团队来说，这是一个不错的选择。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;为了支持 k0s 集群的管理，有 &lt;a href=&#34;https://k0smotron.io/?utm_source=paid-search&amp;utm_medium=google&amp;utm_campaign=2025q4-brand-global&amp;utm_content=k0smotron&amp;g ad_source=1&amp;gclid=CjwKCAiA3ZC6BhBaEiwAeqfvytfVY2MMumfhLV9FpxghjanA9lUK3UOvHYgwrE0K84v2JPVAHfcSCxoCZoYQAvD_BwE&#34;&gt;k0smotron&lt;/a&gt;,用于高效管理 k0s Kubernetes 集群。它使您能够在管理集群中运行 Kubernetes 控制平面，并通过集群 API 的集成简化各种集群操作，为配置、扩展和升级集群等任务提供支持。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;易于使用：&lt;/strong&gt; k0s 强调其单一二进制文件的简单性和易用性，而其他一些发行版则需要更复杂的设置。对于寻找需要最少设置的 Kubernetes 发行版的用户来说，k0s 是一个有吸引力的选择。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;k0s 用例&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;&lt;strong&gt;边缘和物联网部署：&lt;/strong&gt;由于资源使用量极少，k0s 特别适合资源可能有限的边缘计算和物联网 (IoT) 环境。它可以部署在处理能力较低和内存较少的设备上，即使在受限环境中也能提供强大的 Kubernetes 解决方案。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;开发环境&lt;/strong&gt;：开发人员可以使用 k0s 快速设置本地 Kubernetes 集群来测试他们的应用程序。其简单性和快速的部署过程使其非常适合快速开发和测试。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;中小型企业 (SME)：&lt;/strong&gt;k0s 的低运营开销和可扩展性使其成为中小型企业的理想之选，这些企业既希望获得 Kubernetes 的强大功能，又不想承受更多复杂性和成本重量级发行版。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;生产系统&lt;/strong&gt;：对于需要高可用性和可扩展性的生产系统，可以配置 k0s 来满足这些需求，提供高效、可靠且易于管理的 Kubernetes 解决方案。&lt;/li &gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;安装 k0s&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;安装 k0s 是一个简单的过程，特别是与其他 Kubernetes 发行版相比。安装过程通常涉及以下步骤：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;&lt;strong&gt;下载 k0s 二进制文件：&lt;/strong&gt; 首先，从官方&lt;a href=&#34;https://github.com/k0sproject/k0s&#34;&gt;k0s GitHub 存储库&lt;/a&gt;下载适合您系统的二进制文件。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;运行 k0s 服务器：&lt;/strong&gt;使用单个命令启动 k0s 服务器。服务器将初始化 Kubernetes 控制平面和工作节点。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;加入工作节点&lt;/strong&gt;：设置控制平面后，可以通过简单的加入命令轻松将工作节点添加到集群中，从而实现集群的快速扩展。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;访问集群&lt;/strong&gt;：使用 kubectl 管理 k0s 集群并与之交互，就像使用任何其他 Kubernetes 设置一样。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;k0s 社区&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;k0s 社区讨论将在 Kubernetes Slack Workspace 上开始。加入 &lt;a href=&#34;https://kubernetes.slack.com/archives/C0809EA06QZ&#34;&gt;#k0s-users&lt;/a&gt; 和 &lt;a href=&#34;https://kubernetes.slack.com/archives/C07VAPJUECS&#34; &gt;#k0s-dev&lt;/a&gt; 提出问题、分享您的用户故事并与维护人员讨论您的贡献的渠道。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;每月最后一个星期二下午 3 点（美国东部时间）/下午 1 点（格林威治标准时间）加入 k0s 社区办公时间。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;要获得邀请，请填写&lt;a href=&#34;https://forms.gle/sKwq26McSusRDyoE9&#34;&gt;邀请表&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;以下是社区办公时间的&lt;a href=&#34;https://docs.google.com/document/d/1K7kc4nARFsM60RpzWF7xREF9FHySDuWSu9_6dstkLlg/edit?usp=sharing&#34;&gt;会议记录&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;结论&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;k0s 是一个轻量级、高效且高度灵活的 Kubernetes 发行版，以其简单性和易用性而脱颖而出。它的单一二进制架构、与 Kubernetes 生态系统的兼容性以及对极简主义的关注，使其成为开发人员、边缘部署和希望利用 Kubernetes 的强大功能而无需传统设置的复杂性和开销的中小型企业的绝佳选择。无论您是刚刚开始使用 Kubernetes 还是管理大型集群，k0s 都提供了适合各种用例的可扩展且可管理的解决方案。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;对于那些对更简化的 Kubernetes 体验感兴趣的人来说，k0s 是其他 Kubernetes 发行版的一个令人兴奋的替代方案，它在一个紧凑的包中提供了强大的功能和灵活性。&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Thu, 05 Dec 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【What is authorization? Examples and definitions】什么是授权？示例和定义</title>
      <link>https://www.cncf.io/blog/2024/12/09/what-is-authorization-examples-and-definitions/</link>
      <description>【&lt;p&gt;&lt;em&gt;Member post originally published on &lt;a href=&#34;https://www.cerbos.dev/blog/what-is-authorization&#34;&gt;Cerbos’s blog&lt;/a&gt; by Omu Inetimi&lt;br&gt;&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://www.cerbos.dev/_next/image?url=https%3A%2F%2Fstylish-appliance-1c1cc1c30d.media.strapiapp.com%2Fwhat_is_authorization_examples_and_definitions_91d9086507.png&amp;amp;w=3840&amp;amp;q=75&#34; alt=&#34;What is authorization? Examples and definitions&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;When building a secure application, there are plenty of factors to be considered. Who is allowed into the application, how users are allowed in, measures in place to avoid bad actors, etc. But one particularly important factor stands out within the walls of any application: authorization.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In this article, we’ll see what authorization is all about, and explore several key authorization design patterns, how they work, and possible scenarios where they may be implemented.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 class=&#34;wp-block-heading&#34;&gt;What is authorization?&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;By definition, authorization is the control of someone’s access to a resource. It’s the process of checking and deciding if someone or something is worthy of carrying out a certain task or seeing certain information. It controls what a user can or cannot do within a system.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Think of where you are right now on this website. You can access this particular webpage and read this article. An editor wrote and posted this article due to their access rights but you can only view it, you can’t post. You are free to only read because you don’t have the rights of an editor, that’s authorization at work.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Consider these three components of an authorization mechanism:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Rules: Also known as policies, these effectively specify who can do what under which conditions. For example, a rule that only “editors” can create new articles on this blog.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Contextual details: This encompasses information about the user, the resource they are trying to access, and the specific circumstances of the request. Details might include the user’s department, the time of day, the type of device they’re using, or the specific resource they want to interact with.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Checker: Properly referred to as a “policy decision point”, this is the thing that uses the rules and details to decide if something is allowed.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Authorization is continuously working behind the scenes in every secure system, constantly ensuring you can only do what you have access to do—nothing more, nothing less.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 class=&#34;wp-block-heading&#34;&gt;Types of authorization paradigms&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;There are a number of authorization paradigms, each with its own strong points and limitations. We’ll go over a few of the most common ones below.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Role-Based Access Control (RBAC)&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In&amp;nbsp;&lt;a href=&#34;https://www.cerbos.dev/features-benefits-and-use-cases/rbac&#34;&gt;RBAC&lt;/a&gt;, permissions are assigned based on a user’s role in an organization. Each “role” (e.g. managers, employees, etc.) has specific access rights given to them. The user then inherits the permissions of that role. This is particularly useful in large organizations as it logically models broad business groups.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Advantages&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Easy to manage: When a user’s job changes, you can just change their role, and their permissions update automatically.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Simple to understand: It’s clear why someone can or can’t do something, as it’s based on their role.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Limitations&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Complexity: If you have lots of roles and permissions, it can get complicated.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Flexibility: Sometimes users need to do things outside their normal role, and RBAC might not be flexible enough to hand this easily.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Attribute-Based Access Control (ABAC)&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;ABAC is more flexible. It’s considered a more fine-grained approach to authorization, which just means it can handle more complexity by considering more factors. Factors could include user attributes (such as department, role, and clearance level), resource attributes (such as document classification, owner, and creation date), and environmental attributes(such as time of day, location, network, device, IP). It can combine all these to decide access privileges.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Advantages&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Very flexible: It can handle all sorts of complex situations.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Smart decisions: Because it looks at so many factors, it can make more nuanced choices about who gets access privileges.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Limitations&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Harder implementation: With so many factors to consider, it takes more work to set up everything correctly.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Speed: Checking all those details can take time, introducing latency—especially in big systems.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Discretionary Access Control (DAC)&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In this system, the resource owner controls access to their own resources. they get to grant or revoke access to or from whomever they please. This is often used in file systems such as those on your personal computer. DAC allows you to set permissions on your files or folders, ultimately allowing you to decide who can view or edit them.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Advantages&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;User control: Owners can control who can access their resources.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Simpler implementation: It’s easier to set up and understand who is in charge of what.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Limitations&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Risk: It could lead to security risks if permissions are not managed carefully by individual users.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Difficulty in tracking: In larger organizations, it can become difficult to manage and track every user’s permissions.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Mandatory Access Control (MAC)&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In MAC access is based on a system of classification and labels governed by a central authority. The system defines access levels (such as top secret, secret, and confidential) that users can only get if they have the right clearance level. It is a very strict system and is mainly used in environments where data security is critical.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Advantages&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Very secure: Due to the sheer strictness of the system it is very difficult to gain unauthorized access.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Centralized control: This simplifies absolute control and makes it easy to ensure rules are followed from that single point.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Limitations&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Less flexibility: It is not adaptable to changes in user roles because of its rigid security.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Hard to manage: It takes a lot of work to get all the rules right and keep them updated.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Relationship-Based Access Control (ReBAC)&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This is a more recent approach that’s usually used where access decisions are dependent on the interaction between users and resources within the system. It’s especially useful for social networks and team projects (think Facebook and Google Docs).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In ReBAC, your permissions might change based on your relationship to other users or to the data itself. For example, on Facebook, you might be able to see posts from your friends, or friends of friends, but not from people you’re not connected to.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Advantages&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Good for social networks: It matches how we think about connections in the real world.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Can handle complex relationships: It’s good at dealing with the complicated ways people and data can be connected.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Limitations&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Can get complicated: As more people join and more connections are made, it can become hard to manage.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Needs frequent updates: As relationships change, the system needs to keep up, which can be a lot of work.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Real-world examples of Authorization&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To better illustrate these concepts, here are some examples of real-world scenarios where these paradigms would be implemented.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Corporate networks&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Corporate IT systems usually implement a combination of Role-Based Access Control (RBAC) and&amp;nbsp;&lt;a href=&#34;https://www.cerbos.dev/features-benefits-and-use-cases/abac&#34;&gt;Attribute-Based Access Control (ABAC)&lt;/a&gt;. Your job title (e.g. manager, staff) determines your level of access within the system—that’s RBAC. ABAC then also makes the system more secure by taking into account other factors such as the time, your location, your device, etc to decide whether or not you should be given access to certain things. This dual approach allows organizations to maintain security and flexibility.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Social media privacy settings&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Have you ever tried to reply to a social media post on Facebook or Twitter and noticed that the author limited who can comment? That is authorization in the form of ReBAC + DAC. ReBAC works to give access based on connections (if you’re friends or not), and determines what you can see on the person’s profile. DAC comes into play when the user controls their privacy settings, e.g. setting visibility or comment access to “friends only”.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Government Agencies&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In such high-security environments where classified information is present, Mandatory Access Control (MAC) is often the model of choice. This system provides rigid centralized control where access is granted only when a user’s clearance meets or exceeds the classification level of the information.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Getting started with authorization&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;When it comes to setting up and managing authorization systems, there are some best practices to follow, but also some challenges to watch out for.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Best practices&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Principle of least privilege: This principle proposes the idea that you should give users access to only what they need to carry out their tasks. If their job requires only a certain level of authorization, it should never go past that. In that way, you can limit the level of damage in the case where a bad actor gains access to the system.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Regular audits and reviews: It is important to continually check the access levels of the users within the system as time goes on—especially in a growing organization where roles change—to ensure everyone has the right level of access.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Scalability considerations: You want your authorization system to be able to scale as your application grows, not just to accommodate increasing traffic, but also to manage a growing number of security rules, users, and roles. A scalable authorization solution can handle this complexity without compromising performance.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Common challenges&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Managing complex permission structures: As the system grows it can get complex fast, making it hard to keep track of who has access to what.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Maintaining flexibility while ensuring security: It can be difficult to balance security and flexibility. If a system is “too secure” it can become complete unusable. Therefore it’s important to balance the strictness of the system with usability to avoid it becoming cumbersome for users.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Performance considerations: In large-scale systems, you usually want to maintain a certain level of performance. This can be somewhat hindered by continuously checking permissions and thus slowing the system down.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Maintenance of custom authorization systems: Homegrown solutions typically require significant maintenance and scaling as the system grows which is a team effort that could be spent on other features or problems.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Wrapping up&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Authorization is an incredibly important aspect of every secure system. It is used in almost all digital systems you see today, from your personal computer to your social media platform of choice. It works behind the scenes constantly, checking if you have the required access rights to do what you need to do.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In the end, good authorization is all about finding the right balance; between being secure and being easy to use, between giving people the access they need and protecting sensitive information. When it’s done right, authorization is a powerful tool that helps keep our digital lives running smoothly and safely. When it’s done wrong, it can leave us vulnerable to security breaches or make systems frustrating to use.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you want to exchange authorization design tips and ideas with other developers, or just learn more about authorization in general, you should&amp;nbsp;&lt;a href=&#34;https://go.cerbos.io/slack&#34;&gt;join our Community Slack today&lt;/a&gt;!&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;成员帖子最初由 Omu Inetimi 在 &lt;a href=&#34;https://www.cerbos.dev/blog/what-is-authorization&#34;&gt;Cerbos 博客&lt;/a&gt;上发布&lt;br&gt;&lt;/em &gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img 解码=&#34;async&#34; src=&#34;https://www.cerbos.dev/_next/image?url=https%3A%2F%2Fstylish-appliance-1c1cc1c30d.media.strapiapp.com%2Fwhat_is_authorization_examples_and_definitions_91d9086507.png&amp;w=3840&amp;q=75&#34; alt=&#34;什么是授权示例和定义” referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;构建安全应用程序时，需要考虑很多因素。谁被允许进入应用程序、用户如何被允许进入、避免不良行为者的措施等。但在任何应用程序的围墙内有一个特别重要的因素：授权。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在本文中，我们将了解授权的全部内容，并探讨几种关键的授权设计模式、它们的工作原理以及可能的实施场景。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 class=&#34;wp-block-heading&#34;&gt;什么是授权？&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;根据定义，授权是对某人对资源的访问的控制。这是检查和决定某人或某事是否值得执行某项任务或查看某些信息的过程。它控制用户在系统内可以做什么或不能做什么。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;想想您现在在该网站上的位置。您可以访问此特定网页并阅读本文。一位编辑由于其访问权限而撰写并发布了这篇文章，但您只能查看它，不能发布。您只能自由阅读，因为您没有编辑的权利，这就是工作中的授权。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;考虑授权机制的这三个组成部分：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;规则：也称为策略，它们有效地指定谁可以在什么条件下做什么。例如，只有“编辑”才能在此博客上创建新文章的规则。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;上下文详细信息：这包括有关用户、他们尝试访问的资源以及请求的具体情况的信息。详细信息可能包括用户的部门、一天中的时间、他们正在使用的设备类型或他们想要交互的特定资源。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;检查器：正确地称为“策略决策点”，它使用规则和详细信息来决定是否允许某些操作。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;授权在每个安全系统的幕后持续工作，不断确保您只能执行您有权执行的操作 — 不多也不少。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 class=&#34;wp-block-heading&#34;&gt;授权范例的类型&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;有多种授权范例，每种范例都有自己的优点和局限性。我们将在下面讨论一些最常见的问题。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;基于角色的访问控制 (RBAC)&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在&lt;a href=&#34;https://www.cerbos.dev/features-benefits-and-use-cases/rbac&#34;&gt;RBAC&lt;/a&gt;，根据用户在组织中的角色分配权限。每个“角色”（例如经理、员工等）都被赋予特定的访问权限。用户然后继承该角色的权限，这在大型组织中特别有用，因为它对广泛的业务组进行了逻辑建模。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;优点&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;易于管理：当用户的工作发生变化时，您只需更改他们的角色，他们的权限就会自动更新。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;简单易懂：很清楚为什么某人可以或不能做某事，因为这取决于他们的角色。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;限制&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;复杂性：如果您拥有大量角色和权限，事情可能会变得复杂。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;灵活性：有时用户需要执行正常角色之外的操作，而 RBAC 可能不够灵活，无法轻松处理这些事情。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;基于属性的访问控制 (ABAC)&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;ABAC 更加灵活。它被认为是一种更细粒度的授权方法，这意味着它可以通过考虑更多因素来处理更复杂的情况。因素可能包括用户属性（例如部门、角色和许可级别）、资源属性（例如文档分类、所有者和创建日期）和环境属性（例如一天中的时间、位置、网络、设备、IP） 。它可以结合所有这些来决定访问权限。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;优点&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;非常灵活：它可以处理各种复杂的情况。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;明智的决策：由于它考虑了很多因素，因此可以对谁获得访问权限做出更细致的选择。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;限制&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;实施难度更大：需要考虑的因素太多，需要做更多的工作才能正确设置所有内容。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;速度：检查所有这些详细信息可能需要时间，从而引入延迟，尤其是在大型系统中。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;自主访问控制 (DAC)&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在此系统中，资源所有者控制对其自己资源的访问。他们可以向任何他们愿意的人授予或撤销访问权限。这通常用于文件系统，例如个人计算机上的文件系统。 DAC 允许您设置文件或文件夹的权限，最终允许您决定谁可以查看或编辑它们。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;优点&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;用户控制：所有者可以控制谁可以访问其资源。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;实施更简单：更容易设置和了解谁负责什么。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;限制&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;风险：如果个人不仔细管理权限，可能会导致安全风险双用户。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;跟踪困难：在大型组织中，管理和跟踪每个用户的权限可能会变得困难。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;强制访问控制 (MAC)&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在 MAC 中，访问基于由中央机构管理的分类和标签系统。系统定义了用户只有具有正确许可级别才能获得的访问级别（例如绝密、秘密和机密）。这是一个非常严格的系统，主要用于数据安全至关重要的环境。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;优点&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;非常安全：由于系统的严格性，很难获得未经授权的访问。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;集中控制：这简化了绝对控制，并可以轻松确保从单一点遵守规则。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;限制&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;灵活性较差：由于其严格的安全性，无法适应用户角色的变化。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;难以管理：需要付出大量工作才能使所有规则正确并保持更新。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;基于关系的访问控制 (ReBAC)&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这是一种较新的方法，通常用于访问决策取决于系统内用户和资源之间的交互的情况。它对于社交网络和团队项目特别有用（例如 Facebook 和 Google Docs）。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在 ReBAC 中，您的权限可能会根据您与其他用户或数据本身的关系而变化。例如，在 Facebook 上，您可能可以看到朋友或朋友的朋友的帖子，但看不到与您没有联系的人的帖子。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;优点&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;适合社交网络：它符合我们对现实世界中联系的看法。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;可以处理复杂的关系：擅长处理人员和数据的复杂连接方式。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;限制&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;可能会变得复杂：随着越来越多的人加入并建立更多的联系，它可能会变得难以管理。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;需要频繁更新：随着关系的变化，系统需要跟上，这可能需要大量工作。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;授权的真实示例&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;为了更好地说明这些概念，以下是一些将实现这些范例的现实场景示例。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;企业网络&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;企业 IT 系统通常会结合使用基于角色的访问控制 (RBAC) 和&lt;a href=&#34;https://www.cerbos.dev/features-benefits-and-use-cases/abac&#34;&gt;属性 -基于访问控制（ABAC）&lt;/a&gt;。您的职位（例如经理、员工）决定了您在系统内的访问级别——即RBAC。然后，ABAC 还会考虑其他因素（例如时间、您的位置、您的设备等）来决定您是否应该有权访问某些内容，从而使系统更加安全。这种双重方法使组织能够保持安全性和灵活性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;社交媒体隐私设置&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;您是否曾尝试回复 Facebook 或 Twitter 上的社交媒体帖子，并注意到作者限制了可以发表评论的人？也就是ReBAC+DAC形式的授权。 ReBAC 根据关系（无论您是否是朋友）授予访问权限，并确定您可以在该人的个人资料中看到哪些内容。当用户控制其隐私设置时，例如，DAC 就会发挥作用。将可见性或评论权限设置为“仅限好友”。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;政府机构&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在存在机密信息的高安全性环境中，强制访问控制 (MAC) 通常是首选模型。该系统提供严格的集中控制，只有当用户的许可达到或超过信息的分类级别时才授予访问权限。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;授权开始&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在设置和管理授权系统时，需要遵循一些最佳实践，但也需要注意一些挑战。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;最佳实践&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;最小权限原则：该原则提出了这样的想法：您应该只允许用户访问他们执行任务所需的内容。如果他们的工作只需要一定程度的授权，那么就永远不应该超越这个范围。通过这种方式，您可以限制不良行为者访问系统时造成的损害程度。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;定期审核和审查：随着时间的推移，不断检查系统内用户的访问级别非常重要（尤其是在角色发生变化的成长型组织中），以确保每个人都拥有正确的访问级别。&lt;/li &gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;可扩展性注意事项：您希望授权系统能够随着应用程序的增长而扩展，不仅可以适应不断增加的流量，还可以管理越来越多的安全规则、用户和角色。可扩展的授权解决方案可以在不影响性能的情况下处理这种复杂性。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;常见挑战&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;管理复杂的权限结构：随着系统的发展，它会很快变得复杂，从而很难跟踪谁有权访问什么。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;在确保安全性的同时保持灵活性：平衡安全性和灵活性可能很困难。如果一个系统“太安全”，它可能会变得完全无法使用。因此，平衡系统的严格性和可用性非常重要，以避免给用户带来麻烦。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;性能注意事项：在大型系统中，您通常希望保持一定水平的性能。不断检查权限可能会在一定程度上阻碍这一点，从而减慢系统速度。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;自定义授权系统的维护：随着系统的发展，本土解决方案通常需要大量的维护和扩展，这需要团队的努力，而这些工作可能会花在其他功能或问题上。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;总结&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;授权是每个安全系统的一个极其重要的方面。它几乎用于您今天看到的所有数字系统，从您的个人计算机到您选择的社交媒体平台。它不断在幕后工作，检查您是否拥有执行所需操作所需的访问权限。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;最后，良好的授权就是找到适当的平衡点；在安全和易于使用之间，在为人们提供所需的访问权限和保护敏感信息之间。如果做得正确，授权是一个强大的工具，可以帮助我们的数字生活顺利、安全地运行。如果做得错误，可能会让我们容易受到安全漏洞的影响，或者使系统难以使用。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您想与其他开发者交流授权设计技巧和想法，或者只是了解有关授权的更多信息，您应该&lt;a href=&#34;https://go.cerbos.io/slack&#34;&gt;加入我们的 Slack 社区今天&lt;/a&gt;！&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Sun, 08 Dec 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Managing large-scale Redis clusters on Kubernetes with an operator – Kuaishou’s approach】与算子一起管理Kubernetes上的大规模Redis集群——快手的方法</title>
      <link>https://www.cncf.io/blog/2024/12/17/managing-large-scale-redis-clusters-on-kubernetes-with-an-operator-kuaishous-approach/</link>
      <description>【&lt;p&gt;&lt;em&gt;Member post originally published on &lt;a href=&#34;https://kubeblocks.io/blog/manage-large-scale-redis-on-k8s-with-kubeblocks&#34;&gt;KubeBlocks&lt;/a&gt; by Yuxing Liu&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As a popular short-form video application, Kuaishou relies heavily on Redis to deliver low-latency responses to its users. Operating on private cloud infrastructure, automating the management of large-scale Redis clusters with minimal human intervention presents a significant challenge. A promising solution emerged: running Redis on Kubernetes using an Operator.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;While containerizing stateless services like applications and Nginx is now standard, running stateful services like databases and Redis on Kubernetes remains debated. Based on Kuaishou’s experience transforming Redis from physical machines to a cloud-native solution, this blog explores solutions and key considerations for managing stateful services on Kubernetes with the KubeBlocks Operator.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;background&#34;&gt;Background&lt;a href=&#34;https://kubeblocks.io/blog/manage-large-scale-redis-on-k8s-with-kubeblocks#background&#34;&gt;&lt;/a&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As technology evolves, Kuaishou’s infrastructure is transitioning toward cloud-native technology stack. The infrastructure team delivers containers and Kubernetes to Application and PaaS systems. While stateless services at Kuaishou have almost fully adopted Kubernetes, the path toward cloud-native stateful services presents several challenges.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Taking Redis as an example, it is one of the most widely used stateful services at Kuaishou, characterized by its massive scale. Even small cost savings at this scale can deliver substantial financial benefits to the company. In its long-term planning, Kuaishou recognizes the significant potential of running Redis on Kubernetes, particularly in terms of cost optimization through improved resource utilization. This article shares insights from Kuaishou’s experience migrating Redis to Kubernetes, covering solutions, challenges encountered, and the corresponding strategies to address them.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;how-did-kuaishou-run-redis-on-kubernetes&#34;&gt;How Did Kuaishou Run Redis on Kubernetes?&lt;a href=&#34;https://kubeblocks.io/blog/manage-large-scale-redis-on-k8s-with-kubeblocks#how-did-kuaishou-run-redis-on-kubernetes&#34;&gt;&lt;/a&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;redis-deployment-architecture&#34;&gt;Redis Deployment Architecture&lt;a href=&#34;https://kubeblocks.io/blog/manage-large-scale-redis-on-k8s-with-kubeblocks#redis-deployment-architecture&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To meet the need for flexible shard management and support for hotspot migration and isolation, Kuaishou adopts a horizontally sharded, master-slave high-availability Redis architecture consisting of three components: Server, Sentinel, and Proxy.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://kubeblocks.io/assets/images/blog-redis-kuaishou-2-ccd82017ae8ebce4e4a8bb7289fc750f.png&#34; alt=&#34;Figure 2&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;analysis-what-does-kuaishou-require-from-a-redis-operator&#34;&gt;Analysis: What Does Kuaishou Require from a Redis Operator?&lt;a href=&#34;https://kubeblocks.io/blog/manage-large-scale-redis-on-k8s-with-kubeblocks#analysis-what-does-kuaishou-require-from-a-redis-operator&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;First, Redis Pod Management Requires a Layered Approach&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Redis Pod management needs to be handled in two layers: the first layer manages multiple shards, while the second layer manages multiple replicas within a single shard. It must support the dynamic scaling of the number of shards and the number of replicas per shard to adapt to varying workloads and usage scenarios.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This means that, in Operator’s implementation, a workload (such as a StatefulSet) is used to manage multiple replicas within each shard. On top of this, an additional layer (some CRD object) should be constructed to enable management of multiple shards within the entire Redis cluster.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Second, Ensuring Data Consistency and Reliability During Failures and Day-2 Operations&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;During shard or replica lifecycle changes, data consistency and reliability must be ensured. For example, shard scaling requires data rebalancing, while instance scaling within a shard may require data backup and restoration.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Thus, the Operator must support lifecycle hooks at both the shard and replica levels, enabling custom data management operations at different lifecycle stages.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Third, Topology Awareness for Service Discovery and Canary Releases&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The topology among multiple Redis Pods within a shard may dynamically change due to events like high-availability failovers, upgrades, or scaling operations. Service discovery and features like canary releases rely on the real-time topology.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To achieve this, the Operator must support dynamic topology awareness by introducing role detection and role labeling capabilities. This enables service discovery and canary releases based on the dynamic topology.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;These requirements go beyond the capabilities of any existing open-source Redis Operator and would typically require developing a highly complex Kubernetes Operator to fulfill them. However, building a stable Operator with well-designed APIs from scratch is daunting for most platform teams, as it demands expertise in both Kubernetes and databases, along with extensive real-world testing.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;the-kubeblocks-solution-came-into-our-view&#34;&gt;The KubeBlocks Solution Came into Our View&lt;a href=&#34;https://kubeblocks.io/blog/manage-large-scale-redis-on-k8s-with-kubeblocks#the-kubeblocks-solution-came-into-our-view&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;After evaluating several solutions,&amp;nbsp;&lt;strong&gt;KubeBlocks&lt;/strong&gt;&amp;nbsp;caught our attention as an open-source Kubernetes database Operator. What makes KubeBlocks unique is its extensibility, offering an&amp;nbsp;&lt;strong&gt;Addon mechanism&lt;/strong&gt;&amp;nbsp;that allows you to use its API to describe the Day-1 and Day-2 characteristics and behaviors of a database, enabling its full lifecycle management on Kubernetes. As stated on its website, KubeBlocks’ vision is to “Run any database on Kubernetes.” This flexibility enables us to customize the KubeBlocks Redis Addon to fit our in-house Redis cluster deployment architecture.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;KubeBlocks’ API design also aligns well with our requirements for managing Redis clusters:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;1. InstanceSet: A More Powerful Workload Than StatefulSet&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;InstanceSet&lt;/strong&gt;&amp;nbsp;is a workload used within KubeBlocks to replace StatefulSet, designed specifically for managing database Pods. Like StatefulSet, InstanceSet supports managing multiple Pods (referred to as Instances). The key difference is that InstanceSet can track the&amp;nbsp;&lt;strong&gt;Role&lt;/strong&gt;&amp;nbsp;of each database Pod (e.g., primary, secondary). For different databases (as KubeBlocks supports multiple types), KubeBlocks allows customization of Pod roles, role detection methods, and the upgrade order based on roles during canary upgrades. The InstanceSet controller dynamically detects role changes during runtime and updates the role information as labels in the Pod metadata, enabling role-based Service selector.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;StatefulSet assigns each instance a globally ordered, incrementing identifier. This mechanism provides stable network and storage identities, with the topology within the cluster relying on these identifiers. However, as the topology dynamically changes during runtime, the fixed identifiers provided by StatefulSet may fall short of meeting requirements. For example, StatefulSet identifiers cannot have gaps, and deleting an intermediate identifier is not allowed.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kuaishou’s platform team has contributed several PRs to the KubeBlocks community, including enhancements such as allowing Pods within the same InstanceSet to have different configurations, decommissioning Pods with specific ordinals (without first decommissioning Pods with higher ordinals), and controlling upgrade concurrency. These improvements make InstanceSet more adaptable to Kuaishou’s requirements for managing large-scale Redis clusters in production environments.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;2. Layered CRD &amp;amp; Controller Design: Component, Cluster Objects&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;KubeBlocks leverages a multi-layered CRD structure—&lt;strong&gt;Component&lt;/strong&gt;,&amp;nbsp;&lt;strong&gt;Cluster&lt;/strong&gt;—to manage the complex topology of database clusters. This design aligns seamlessly with Kuaishou’s Redis cluster deployment architecture:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Component&lt;/strong&gt;: Represents a group of Pods within the Redis cluster. For example, Proxy Pods form one Component, Sentinel Pods form another, and Redis-Server Pods are organized into one or more Components, each corresponding to a Shard. The number of Components dynamically changes based on the number of Shards.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p class=&#34;has-gray-300-background-color has-background&#34;&gt;⛱️&amp;nbsp;&lt;strong&gt;Shard&lt;/strong&gt;: A specialized Component that defines the sharding behavior of horizontally scalable databases. Each Shard shares the same configuration. In Kuaishou’s Redis Cluster, for example, each Shard (Component) consists of a primary Pod and a replica Pod. Scaling out adds a new Shard (Component), while scaling in removes one, enabling shard-level scaling and lifecycle management.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Cluster&lt;/strong&gt;: Represents the entire Redis cluster, integrating Proxy, Server, and Sentinel Components, while managing their startup topology and relationships.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This hierarchical design simplifies scaling, enhances lifecycle management, and provides the flexibility needed to support complex Redis deployment architecture in production.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Through close collaboration with the KubeBlocks community, we implemented the orchestration of a Redis cluster in the following ways:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://kubeblocks.io/assets/images/blog-redis-kuaishou-3-5b9c478f14e5551f8a75360203b57b06.png&#34; alt=&#34;Figure 3&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;There are three Components in a Redis Cluster:&amp;nbsp;&lt;code&gt;redis-server&lt;/code&gt;,&amp;nbsp;&lt;code&gt;redis-sentinel&lt;/code&gt;, and&amp;nbsp;&lt;code&gt;redis-proxy&lt;/code&gt;. Within each Component, Pods are managed using&amp;nbsp;&lt;strong&gt;InstanceSet&lt;/strong&gt;&amp;nbsp;instead of&amp;nbsp;&lt;strong&gt;StatefulSet&lt;/strong&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;using-kubernetes-federation-to-manage-ultra-large-scale-redis-clusters&#34;&gt;Using Kubernetes Federation to Manage Ultra-Large-Scale Redis Clusters&lt;a href=&#34;https://kubeblocks.io/blog/manage-large-scale-redis-on-k8s-with-kubeblocks#using-kubernetes-federation-to-manage-ultra-large-scale-redis-clusters&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;At Kuaishou, multiple applications operate in a multi-tenant manner within a single ultra-large-scale Redis cluster. For example, a single cluster may contain over 10,000 Pods, exceeding the capacity of a single Kubernetes cluster. As a result, we had to deploy a Redis cluster across multiple Kubernetes clusters. An important aspect is that we need to hide the complexity of managing multiple clusters from Redis application users.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34; id=&#34;federated-k8s-cluster-architecture&#34;&gt;Federated K8s Cluster Architecture&lt;a href=&#34;https://kubeblocks.io/blog/manage-large-scale-redis-on-k8s-with-kubeblocks#federated-k8s-cluster-architecture&#34;&gt;&lt;/a&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Fortunately, Kuaishou’s Kubernetes infrastructure team provides a mature Kubernetes federation service, offering unified scheduling and a unified view:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Unified Scheduling&lt;/strong&gt;: Federation serves as a centralized resource dispatch entry, enabling resource scheduling across multiple member clusters.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Unified View&lt;/strong&gt;: Federation acts as a unified resource access point, allowing seamless retrieval of resources across both the federation and member clusters.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;So, the question becomes how can the Redis cluster management solution based on KubeBlocks be integrated into Kuaishou’s internal federation cluster architecture? Below is the overall architecture:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://kubeblocks.io/assets/images/blog-redis-kuaishou-4-38a5f290fdae275b468c48bd65c19691.png&#34; alt=&#34;Figure 4&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The Federation Kubernetes Cluster serves as the central control plane for managing multiple member clusters. It is responsible for cross-cluster orchestration, resource distribution, and lifecycle management of the Redis cluster. Its responsibilities include:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Cross-Cluster Instance Distribution and Management: Ensures that Redis components (Proxy, Sentinel, Server) are distributed across member clusters based on resource requirements.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Concurrency Control&lt;/strong&gt;: Coordinates operations across clusters to ensure consistency and avoid conflicts.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Status Aggregation&lt;/strong&gt;: Collects and aggregates the status of all components from member clusters to provide a unified view.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Member K8s Clusters are the individual Kubernetes clusters where Redis Pods (instances) are deployed and managed. Each member cluster is responsible for running a subset of the overall Redis cluster. Its responsibilities include:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Instance Management&lt;/strong&gt;: Localized management of Redis Pods (Proxy, Sentinel, Server) via InstanceSet.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;So, we divided the KubeBlocks Operator into two parts and deployed them in different Kubernetes clusters:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;The&amp;nbsp;&lt;strong&gt;InstanceSet Controller&lt;/strong&gt;&amp;nbsp;is deployed in member clusters to manage Pods locally.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;The&amp;nbsp;&lt;strong&gt;Cluster Controller&lt;/strong&gt;&amp;nbsp;and&amp;nbsp;&lt;strong&gt;Component Controller&lt;/strong&gt;&amp;nbsp;are deployed in the federation cluster to handle global resource orchestration and coordination.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Once again, the layered CRD and Controller design of KubeBlocks is the key to enabling this deployment. If KubeBlocks had a monolithic CRD and Controller managing everything, splitting and deploying it separately in the Federation Kubernetes Cluster and Member Kubernetes Clusters would not have been possible.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34; id=&#34;fed-instanceset-controller&#34;&gt;Fed-InstanceSet Controller&lt;a href=&#34;https://kubeblocks.io/blog/manage-large-scale-redis-on-k8s-with-kubeblocks#fed-instanceset-controller&#34;&gt;&lt;/a&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;There may be multiple Member Kubernetes Clusters, requiring the InstanceSet in the Federation Kubernetes Cluster to be partitioned into multiple InstanceSets, with one InstanceSet assigned to each Member Cluster. Additionally, the Instances (Pods) managed by the original InstanceSet need to be distributed across the new InstanceSets in the Member Clusters.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To handle this,&amp;nbsp;&lt;strong&gt;Kuaishou developed the Fed-InstanceSet Controller&lt;/strong&gt;&amp;nbsp;to manage interactions between the Federation Cluster and its Member Clusters. Its key responsibilities include:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Scheduling Decisions&lt;/strong&gt;: Determining how many Instances each Member Cluster should deploy, based on predefined scheduling policies.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;InstanceSet Partitioning and Distribution&lt;/strong&gt;: Splitting the InstanceSet from the Federation Cluster and distributing the resulting InstanceSets to the appropriate Member Clusters.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To manage instance partitioning and ensure global uniqueness and proper ordering of Redis Instances in member Clusters, Kuaishou contributed a PR to the KubeBlocks community, adding an&amp;nbsp;&lt;strong&gt;Ordinals&lt;/strong&gt;&amp;nbsp;field to InstanceSet. This allows precise index assignment to instances.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The&amp;nbsp;&lt;strong&gt;Fed-InstanceSet Controller&lt;/strong&gt;&amp;nbsp;uses this field to assign unique index ranges to each Member Cluster, ensuring instance uniqueness and correct ordering across clusters.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://kubeblocks.io/assets/images/blog-redis-kuaishou-5-b038baa8377ca7861f18966529329fc5.png&#34; alt=&#34;Figure 5&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;discussion-are-stateful-services-fit-for-kubernetes&#34;&gt;Discussion: Are Stateful Services Fit for Kubernetes?&lt;a href=&#34;https://kubeblocks.io/blog/manage-large-scale-redis-on-k8s-with-kubeblocks#discussion-are-stateful-services-fit-for-kubernetes&#34;&gt;&lt;/a&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;benefits-and-risks-of-running-stateful-services-on-kubernetes&#34;&gt;Benefits and Risks of Running Stateful Services on Kubernetes&lt;a href=&#34;https://kubeblocks.io/blog/manage-large-scale-redis-on-k8s-with-kubeblocks#benefits-and-risks-of-running-stateful-services-on-kubernetes&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In our view, running stateful services on Kubernetes comes with notable benefits:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Improved resource utilization&lt;/strong&gt;: By merging multiple small resource pools for unified scheduling and enabling colocation of applications with Redis or Redis with other stateful services, resource usage is optimized, significantly reducing costs.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Enhanced operation efficiency&lt;/strong&gt;: With Kubernetes’s declarative APIs and the Operator pattern, it manages Redis services in an Infrastructure-as-Code (IaC) manner, reducing the need for manual intervention.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Lower maintenance costs&lt;/strong&gt;: Previously, Redis ran on physical machines, requiring dedicated personnel to manage the hardware infrastructure. By unifying the infrastructure onto containers and Kubernetes, infrastructure-related maintenance costs are reduced, and overall management efficiency is improved.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Although running stateful services on Kubernetes offers significant benefits, the potential risks must be carefully evaluated, especially for stateful services like databases and Redis, which demand high levels of importance and stability. The challenges include:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Performance degradation risk&lt;/strong&gt;: Running processes in containers, as opposed to directly on physical machines, introduces an additional layer, particularly due to the latency introduced by the overlay network. This raises concerns about potential service performance degradation.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Stability concerns&lt;/strong&gt;: Building the database platform (DBaaS) on the Kubernetes infrastructure raises concerns about whether the stability (availability and reliability) of databases or Redis might be affected.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Increased Operational Complexity&lt;/strong&gt;: In the event of an issue, would it require experts with both database and K8s technology expertise to effectively identify and resolve the problem?&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://kubeblocks.io/assets/images/blog-redis-kuaishou-1-cc1d3428301b50c242ff122b274af82e.png&#34; alt=&#34;Figure 1&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The following sections explore these risks in more detail.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;mitigate-risks-of-running-redis-on-kubernetes&#34;&gt;Mitigate Risks of Running Redis on Kubernetes&lt;a href=&#34;https://kubeblocks.io/blog/manage-large-scale-redis-on-k8s-with-kubeblocks#mitigate-risks-of-running-redis-on-kubernetes&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34; id=&#34;performance&#34;&gt;Performance&lt;a href=&#34;https://kubeblocks.io/blog/manage-large-scale-redis-on-k8s-with-kubeblocks#performance&#34;&gt;&lt;/a&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Containerizing Redis within a cloud-native architecture introduces an additional abstraction layer compared to traditional host-based deployments. However, industry benchmarks and Kuaishou’s internal testing show that performance differences are generally within 10%, which is often negligible in most use cases. While this variance is typically acceptable, organizations are advised to conduct their own performance testing to ensure the solution meets the specific needs of their workloads.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34; id=&#34;stability&#34;&gt;Stability&lt;a href=&#34;https://kubeblocks.io/blog/manage-large-scale-redis-on-k8s-with-kubeblocks#stability&#34;&gt;&lt;/a&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Migrating stateful services to Kubernetes has greatly improved operational efficiency through automation. However, this also made the execution processes more opaque, with even small configuration changes potentially impacting many instances. To mitigate the stability risks from unexpected scenarios — such as pod evictions, human error, or Operator bugs— Kuaishou utilizes the&amp;nbsp;&lt;strong&gt;Admission Webhook&lt;/strong&gt;&amp;nbsp;mechanism within the Kubernetes API server to intercept and validate change requests. This approach allows Kuaishou to directly reject any unauthorized operations. Given the multi-cluster Kubernetes setup across multiple availability zones (AZs), it’s critical to ensure change control across clusters. To achieve this, Kuaishou developed an internal risk mitigation system called&amp;nbsp;&lt;strong&gt;kube-shield&lt;/strong&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Additionally, it’s worth mentioning that Kuaishou has further enhanced availability and stability by improving support for fine-grained scheduling distribution and introducing load balancing features based on resource utilization.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34; id=&#34;operation-complexity&#34;&gt;Operation Complexity&lt;a href=&#34;https://kubeblocks.io/blog/manage-large-scale-redis-on-k8s-with-kubeblocks#operation-complexity&#34;&gt;&lt;/a&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Migrating from a host-based system to a Kubernetes-based environment, while ensuring ongoing maintenance, requires deep expertise in both Redis and K8s technologies. Relying solely on the Redis team or the K8s team for independent support would be challenging. Proper division of responsibilities not only enhances productivity but also allows each team to fully leverage their expertise in their respective domains.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For example, in Kuaishou’s cloud-native Redis solution:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Redis Team&lt;/strong&gt;: Focused on defining Redis cluster objects and encapsulating their operational expertise into declarative configurations.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Container Cloud Team&lt;/strong&gt;: Managed the Kubernetes side, including developing and maintaining the Operator, handling scheduling, and ensuring the cluster’s lifecycle.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://kubeblocks.io/assets/images/blog-redis-kuaishou-6-105d482f140f60a02013fd130ef4ef76.png&#34; alt=&#34;Figure 6&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;conclusion&#34;&gt;Conclusion&lt;a href=&#34;https://kubeblocks.io/blog/manage-large-scale-redis-on-k8s-with-kubeblocks#conclusion&#34;&gt;&lt;/a&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Cloud-native transformation for stateful services is a complex journey requiring careful evaluation of its pros and cons, and one filled with challenges. However, for Kuaishou, its value is self-evident. Starting with Redis, Kuaishou has worked closely with the KubeBlocks community to implement a cost-effective, cloud-native solution.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Looking forward, Kuaishou aims to build upon this experience to drive the cloud-native transformation of more stateful services, such as databases and middleware, thus reaping dual benefits in technology and cost efficiency.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;At KubeCon Hong Kong in August, Kuaishou and the KubeBlocks team delivered a joint presentation. If you’re interested, you can revisit&amp;nbsp;&lt;a href=&#34;https://kubeblocks.io/blog/migrate-redis-at-kuaishou-from-bare-metal-to-k8s&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;the talk&lt;/a&gt;&amp;nbsp;for further insights.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;&lt;strong&gt;About Author&lt;/strong&gt;: Yuxing Liu is the senior software engineer from Kuaishou. Yuxing has worked in the cloud-native teams of Alibaba Cloud and Kuaishou, focusing on the cloud-native field and gaining experience in open source, commercialization, and scaling of cloud-native technologies. Yuxing is also one of the maintainers of the CNCF/Dragonfly project and also one of the maintainers of the CNCF/Sealer project. Currently, he focuses on driving the cloud-native transformation of stateful business in Kuaishou.&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;&lt;strong&gt;About Kuaishou&lt;/strong&gt;: Kuaishou is a leading content community and social platform in China and globally, committed to becoming the most customer-obsessed company in the world. Kuaishou uses its technological backbone, powered by cutting-edge AI technology, to continuously drive innovation and product enhancements that enrich its service offerings and application scenarios, creating exceptional customer value. Through short videos and live streams on Kuaishou’s platform, users can share their lives, discover goods and services they need and showcase their talent. By partnering closely with content creators and businesses, Kuaishou provides technologies, products, and services that cater to diverse user needs across a broad spectrum of entertainment, online marketing services, e-commerce, local services, gaming, and much more.&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;会员帖子最初由 Yushing 在 &lt;a href=&#34;https://kubeblocks.io/blog/manage-large-scale-redis-on-k8s-with-kubeblocks&#34;&gt;KubeBlocks&lt;/a&gt; 上发布刘&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;作为流行的短视频应用，快手严重依赖 Redis 为用户提供低延迟响应。在私有云基础设施上运行，以最少的人工干预实现大规模 Redis 集群的自动化管理提出了重大挑战。一个有前途的解决方案出现了：使用 Operator 在 Kubernetes 上运行 Redis。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;虽然应用程序和 Nginx 等无状态服务的容器化现已成为标准，但在 Kubernetes 上运行数据库和 Redis 等有状态服务仍然存在争议。基于快手将Redis从物理机转变为云原生解决方案的经验，本博客探讨了使用KubeBlocks Operator管理Kubernetes上有状态服务的解决方案和关键注意事项。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;background&#34;&gt;​​背景&lt;a href=&#34;https://kubeblocks.io/blog/manage-large-scale-redis-on-k8s-with-kubeblocks#background &#34;&gt;&lt;/a&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;随着技术的发展，快手的基础设施正在向云原生技术栈过渡。基础设施团队将容器和 Kubernetes 交付给应用程序和 PaaS 系统。虽然快手的无状态服务几乎全面采用了 Kubernetes，但通往云原生有状态服务的道路面临着一些挑战。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;以Redis为例，它是快手使用最广泛的状态服务之一，其特点是规模庞大。即使是这种规模的小额成本节省也可以为公司带来巨大的经济效益。在其长期规划中，快手认识到在 Kubernetes 上运行 Redis 的巨大潜力，特别是在通过提高资源利用率来优化成本方面。本文分享了快手Redis迁移到Kubernetes的经验，包括解决方案、遇到的挑战以及相应的应对策略。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;how-did-kuaishou-run-redis-on-kubernetes&#34;&gt;快手是如何在 Kubernetes 上运行 Redis 的？&lt;a href=&#34;https://kubeblocks.io/blog/manage-large-scale-redis-on-k8s-with-kubeblocks#how-did-kuaishou-run-redis-on-kubernetes&#34;&gt;&lt;/a&gt;&lt;/ H2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;redis-deployment-architecture&#34;&gt;Redis 部署架构&lt;a href=&#34;https://kubeblocks.io/blog/manage-large-scale-redis-on-k8s -with-kubeblocks#redis-deployment-architecture&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;为了满足灵活的分片管理以及支持热点迁移和隔离的需求，快手采用了水平分片、主从高可用的Redis架构，由Server、Sentinel、Proxy三个组件组成。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://kubeblocks.io/assets/images/blog-redis-kuaishou-2-ccd82017ae8ebce4e4a8bb7289fc750f.png&#34; alt=&#34;图2&#34;referrerpolicy=&#34;否-引用者&#34;&gt;&lt;/图&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;analysis-what-does-kuaishou-require-from-a-redis-operator&#34;&gt;分析：快手对 Redis Operator 有何要求？&lt;a href=&#34;https://kubeblocks.io/blog/manage-large-scale-redis-on-k8s-with-kubeblocks#analysis-what-does-kuaishou-require-from-a-redis-operator&#34;&gt;&lt;/一个&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;首先，Redis Pod 管理需要分层方法&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Redis Pod 管理需要分两层处理：第一层管理多个分片，第二层管理单个分片内的多个副本。它必须支持分片数量和每个分片副本数量的动态扩展，以适应不同的工作负载和使用场景。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这意味着，在 Operator 的实现中，工作负载（例如 StatefulSet）用于管理每个分片内的多个副本。在此之上，应构建一个附加层（某些 CRD 对象）来管理整个 Redis 集群内的多个分片。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;第二，确保故障和第二天运营期间的数据一致性和可靠性&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在分片或副本生命周期发生变化时，必须保证数据的一致性和可靠性。例如，分片扩展需要数据重新平衡，而分片内的实例扩展可能需要数据备份和恢复。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;因此，Operator 必须支持分片和副本级别的生命周期挂钩，从而在不同的生命周期阶段启用自定义数据管理操作。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;三、服务发现和金丝雀发布的拓扑感知&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;由于高可用性故障转移、升级或扩展操作等事件，分片内多个 Redis Pod 之间的拓扑可能会动态变化。服务发现和金丝雀发布等功能依赖于实时拓扑。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;为了实现这一目标，Operator 必须通过引入角色检测和角色标记功能来支持动态拓扑感知。这使得基于动态拓扑的服务发现和金丝雀发布成为可能。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这些要求超出了任何现有开源 Redis Operator 的能力，通常需要开发高度复杂的 Kubernetes Operator 来满足这些要求。然而，对于大多数平台团队来说，从头开始构建一个具有精心设计的 API 的稳定 Operator 是一项艰巨的任务，因为它需要 Kubernetes 和数据库方面的专业知识，以及广泛的实际测试。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;the-kubeblocks-solution-came-into-our-view&#34;&gt;KubeBlocks 解决方案进入我们的视野&lt;a href=&#34;https://kubeblocks.io/blog /manage-large-scale-redis-on-k8s-with-kubeblocks#the-kubeblocks-solution-came-into-our-view&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在评估了多种解决方案后，&lt;strong&gt;KubeBlocks&lt;/strong&gt; 作为开源 Kubernetes 数据库运营商引起了我们的注意。 KubeBlocks 的独特之处在于它的可扩展性，提供&amp;nbsp;&lt;strong&gt;插件机制&lt;/strong&gt;，允许您使用其 API 来描述数据库的 Day-1 和 Day-2 特征和行为，从而在 Kubernetes 上实现其完整的生命周期管理。正如其网站所述，KubeBlocks 的愿景是“在 Kubernetes 上运行任何数据库”。这种灵活性使我们能够自定义 KubeBlocks Redis Addon 以适应我们内部的 Redis 集群部署架构。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;KubeBlocks 的 API 设计也非常符合我们管理 Redis 集群的要求：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;强&gt;1。 InstanceSet：比StatefulSet更强大的工作负载&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;InstanceSet&lt;/strong&gt;是 KubeBlocks 中使用的一种工作负载，用于替代 StatefulSet，专为管理数据库 Pod 而设计。与 StatefulSet 一样，InstanceSet 支持管理多个 Pod（简称 Instance）。主要区别在于 InstanceSet 可以跟踪每个数据库 Pod 的&lt;strong&gt;角色&lt;/strong&gt;（例如，主要、辅助）。针对不同的数据库（KubeBlocks支持多种类型），KubeBlocks允许自定义Pod角色、角色检测方式以及金丝雀升级时根据角色的升级顺序。 InstanceSet 控制器在运行时动态检测角色变化，并将角色信息更新为 Pod 元数据中的标签，从而实现基于角色的服务选择器。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;StatefulSet 为每个实例分配一个全局排序的递增标识符。该机制提供稳定的网络和存储身份，集群内的拓扑依赖于这些标识符。然而，由于拓扑在运行时动态变化，StatefulSet提供的固定标识符可能无法满足要求。例如，StatefulSet标识符不能有间隙，不允许删除中间标识符。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;快手平台团队向 KubeBlocks 社区贡献了多个 PR，包括允许同一 InstanceSet 内的 Pod 有不同配置、退役特定序号的 Pod（无需先退役更高序号的 Pod）、控制升级并发等增强功能。这些改进使得InstanceSet更能适应快手在生产环境中管理大规模Redis集群的需求。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;强&gt;2。分层 CRD 和控制器设计：组件、集群对象&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;KubeBlocks 利用多层 CRD 结构（&lt;strong&gt;组件&lt;/strong&gt;、&lt;strong&gt;集群&lt;/strong&gt;）来管理数据库集群的复杂拓扑。这一设计与快手的Redis集群部署架构无缝对接：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;组件&lt;/strong&gt;：代表 Redis 集群中的一组 Pod。例如，Proxy Pod 构成一个 Component，Sentinel Pod 构成另一个 Component，Redis-Server Pod 则组织成一个或多个 Component，每个 Component 对应一个 Shard。组件数量 dy根据分片数量进行自然变化。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p class=&#34;has-gray-300-background-color has-background&#34;&gt;​​⛱️ &lt;strong&gt;Shard&lt;/strong&gt;：定义水平可扩展数据库的分片行为的专用组件。每个分片共享相同的配置。以快手的Redis集群为例，每个Shard（组件）由一个主Pod和一个副本Pod组成。向外扩展会添加一个新的分片（组件），而向内扩展会删除一个新的分片（组件），从而实现分片级别的扩展和生命周期管理。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;集群&lt;/strong&gt;：代表整个 Redis 集群，集成了 Proxy、Server 和 Sentinel 组件，同时管理它们的启动拓扑和关系。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这种分层设计简化了扩展，增强了生命周期管理，并提供了支持生产中复杂的 Redis 部署架构所需的灵活性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;通过与 KubeBlocks 社区的密切合作，我们通过以下方式实现了 Redis 集群的编排：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://kubeblocks.io/assets/images/blog-redis-kuaishou-3-5b9c478f14e5551f8a75360203b57b06.png&#34; alt=&#34;图3&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Redis 集群中有三个组件：&lt;code&gt;redis-server&lt;/code&gt;、&lt;code&gt;redis-sentinel&lt;/code&gt; 和 &lt;code&gt;redis-proxy&lt;/code&gt;。在每个组件中，Pod 是使用 &lt;strong&gt;InstanceSet&lt;/strong&gt; 而不是 &lt;strong&gt;StatefulSet&lt;/strong&gt; 进行管理的。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;using-kubernetes-federation-to-manage-ultra-large-scale-redis-clusters&#34;&gt;使用 Kubernetes Federation 管理超大规模 Redis 集群&lt;a href=&#34;https://kubeblocks.io/blog/manage-large-scale-redis-on-k8s-with-kubeblocks#using-kubernetes-federation-to-manage-ultra-large-scale-redis-clusters&#34;&gt; &lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在快手，多个应用程序在单个超大规模Redis集群中以多租户方式运行。例如，单个集群可能包含超过 10,000 个 Pod，超出了单个 Kubernetes 集群的容量。因此，我们必须跨多个 Kubernetes 集群部署 Redis 集群。一个重要的方面是我们需要向 Redis 应用程序用户隐藏管理多个集群的复杂性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34; id=&#34;federated-k8s-cluster-architecture&#34;&gt;联合 K8s 集群架构&lt;a href=&#34;https://kubeblocks.io/blog/manage-large-scale-redis- on-k8s-with-kubeblocks#federated-k8s-cluster-architecture&#34;&gt;&lt;/a&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;幸运的是，快手的 Kubernetes 基础设施团队提供了成熟的 Kubernetes 联邦服务，提供统一调度和统一视图：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;统一调度&lt;/strong&gt;：联邦作为集中的资源调度入口，实现跨多个成员集群的资源调度。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;统一视图&lt;/strong&gt;：联邦充当统一的资源访问点，允许跨联邦和成员集群无缝检索资源。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;那么问题来了，基于KubeBlocks的Redis集群管理方案如何融入到快手内部联邦集群架构中呢？整体架构如下：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://kubeblocks.io/assets/images/blog-redis-kuaishou-4-38a5f290fdae275b468c48bd65c19691.png&#34; alt=&#34;图4&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;联邦 Kubernetes 集群作为管理多个成员集群的中央控制平面。它负责Redis集群的跨集群编排、资源分配和生命周期管理。其职责包括：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;跨集群实例分发和管理：确保 Redis 组件（Proxy、Sentinel、Server）根据资源需求跨成员集群进行分发。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;并发控制&lt;/strong&gt;：协调跨集群的操作，以确保一致性并避免冲突。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;状态聚合&lt;/strong&gt;：收集并聚合成员集群中所有组件的状态，以提供统一的视图。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;成员 K8s 集群是部署和管理 Redis Pod（实例）的单个 Kubernetes 集群。每个成员集群负责运行整个 Redis 集群的一个子集。其职责包括：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;实例管理&lt;/strong&gt;：通过 InstanceSet 对 Redis Pod（代理、哨兵、服务器）进行本地化管理。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;因此，我们将 KubeBlocks Operator 分为两部分，并将它们部署在不同的 Kubernetes 集群中：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;InstanceSet 控制器&lt;/strong&gt;部署在成员集群中，用于在本地管理 Pod。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;集群控制器&lt;/strong&gt;和&lt;strong&gt;组件控制器&lt;/strong&gt;部署在联合集群中，用于处理全局资源编排和协调。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;KubeBlocks 的分层 CRD 和控制器设计再次成为实现此部署的关键。如果 KubeBlocks 有一个单一的 CRD 和控制器来管理一切，那么在联邦 Kubernetes 集群和成员 Kubernetes 集群中分开和部署它是不可能的。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34; id=&#34;fed-instanceset-controller&#34;&gt;Fed-InstanceSet 控制器&lt;a href=&#34;https://kubeblocks.io/blog/manage-large-scale-redis-on- k8s-with-kubeblocks#fed-instanceset-controller&#34;&gt;&lt;/a&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;可能存在多个Member Kubernetes Cluster，需要将Federation Kubernetes Cluster中的InstanceSet划分为多个InstanceSet，每个Member Cluster分配一个InstanceSet。附加ly，原始 InstanceSet 管理的实例（Pod）需要分布在成员集群中的新 InstanceSet 中。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;为了解决这个问题，&lt;strong&gt;快手开发了 Fed-InstanceSet 控制器&lt;/strong&gt;来管理联邦集群与其成员集群之间的交互。其主要职责包括：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;调度决策&lt;/strong&gt;：根据预定义的调度策略确定每个成员集群应部署多少个实例。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;InstanceSet 分区和分发&lt;/strong&gt;：从联邦集群中拆分 InstanceSet，并将生成的 InstanceSet 分发到适当的成员集群。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;为了管理实例分区并确保成员集群中 Redis 实例的全局唯一性和正确排序，快手向 KubeBlocks 社区贡献了一个 PR，向 InstanceSet 添加了一个 &lt;strong&gt;Ordinals&lt;/strong&gt; 字段。这允许为实例精确分配索引。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Fed-InstanceSet 控制器&lt;/strong&gt;使用此字段为每个成员集群分配唯一的索引范围，确保实例的唯一性和跨集群的正确排序。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://kubeblocks.io/assets/images/blog-redis-kuaishou-5-b038baa8377ca7861f18966529329fc5.png&#34; alt=&#34;图5&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;discussion-are-stateful-services-fit-for-kubernetes&#34;&gt;讨论：有状态服务适合 Kubernetes 吗？&lt;a href=&#34;https://kubeblocks.io /blog/manage-large-scale-redis-on-k8s-with-kubeblocks#discussion-are-stateful-services-fit-for-kubernetes&#34;&gt;&lt;/a&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;benefits-and-risks-of-running-stateful-services-on-kubernetes&#34;&gt;在 Kubernetes 上运行有状态服务的好处和风险&lt;a href=&#34;https://kubeblocks.io/blog/manage-large-scale-redis-on-k8s-with-kubeblocks#benefits-and-risks-of-running-stateful-services-on-kubernetes&#34;&gt;&lt;/一个&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们认为，在 Kubernetes 上运行有状态服务具有显着的好处：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;提高资源利用率&lt;/strong&gt;：通过合并多个小型资源池进行统一调度，并实现应用与 Redis 或 Redis 与其他有状态服务的共置，优化资源利用率，显着降低成本。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;提高运行效率&lt;/strong&gt;：借助 Kubernetes 的声明式 API 和 Operator 模式，以基础设施即代码 (IaC) 的方式管理 Redis 服务，减少人工干预的需要。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;更低的维护成本&lt;/strong&gt;：此前，Redis运行在物理机上，需要专门的人员来管理硬件基础设施。通过将基础设施统一到容器和 Kubernetes 上，降低了基础设施相关的维护成本，并提高了整体管理能力提高了处理效率。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;虽然在 Kubernetes 上运行有状态服务可以带来显着的好处，但必须仔细评估潜在的风险，特别是对于数据库和 Redis 等有状态服务，它们需要高度的重要性和稳定性。挑战包括：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;&lt;strong&gt;性能下降风险&lt;/strong&gt;：在容器中运行进程（而不是直接在物理机上运行）会引入额外的层，特别是由于覆盖网络引入的延迟。这引起了人们对潜在服务性能下降的担忧。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;稳定性问题&lt;/strong&gt;：在 Kubernetes 基础设施上构建数据库平台 (DBaaS) 会引发人们对数据库或 Redis 的稳定性（可用性和可靠性）是否会受到影响的担忧。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;运营复杂性增加&lt;/strong&gt;：如果出现问题，是否需要同时具备数据库和 K8s 技术专业知识的专家来有效识别和解决问题？&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://kubeblocks.io/assets/images/blog-redis-kuaishou-1-cc1d3428301b50c242ff122b274af82e.png&#34; alt=&#34;图1&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;以下部分将更详细地探讨这些风险。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;mitigate-risks-of-running-redis-on-kubernetes&#34;&gt;降低在 Kubernetes 上运行 Redis 的风险&lt;a href=&#34;https://kubeblocks.io/blog /manage-large-scale-redis-on-k8s-with-kubeblocks#mitigate-risks-of-running-redis-on-kubernetes&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34; id=&#34;performance&#34;&gt;性能&lt;a href=&#34;https://kubeblocks.io/blog/manage-large-scale-redis-on-k8s-with-kubeblocks#performance &#34;&gt;&lt;/a&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;与传统的基于主机的部署相比，在云原生架构中容器化 Redis 引入了额外的抽象层。然而，行业基准和快手的内部测试表明，性能差异通常在 10% 以内，这在大多数用例中通常可以忽略不计。虽然这种差异通常是可以接受的，但建议组织进行自己的性能测试，以确保解决方案满足其工作负载的特定需求。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34; id=&#34;stability&#34;&gt;稳定性&lt;a href=&#34;https://kubeblocks.io/blog/manage-large-scale-redis-on-k8s-with-kubeblocks#stability &#34;&gt;&lt;/a&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;将有状态服务迁移到 Kubernetes，通过自动化极大地提高了运营效率。然而，这也使得执行过程更加不透明，即使很小的配置更改也可能会影响许多实例。为了降低意外情况（例如 pod 驱逐、人为错误或 Operator bug）带来的稳定性风险，快手利用 Kubernetes API 服务器内的&lt;strong&gt;Admission Webhook&lt;/strong&gt; 机制来拦截和验证变更请求sts。这种做法可以让快手直接拒绝任何未经授权的操作。鉴于跨多个可用区 (AZ) 的多集群 Kubernetes 设置，确保跨集群的变更控制至关重要。为了实现这一目标，快手开发了一个名为&lt;strong&gt;kube-shield&lt;/strong&gt;的内部风险缓解系统。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;此外，值得一提的是，快手通过完善对细粒度调度分发的支持以及引入基于资源利用率的负载均衡功能，进一步增强了可用性和稳定性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34; id=&#34;operation-complexity&#34;&gt;操作复杂度&lt;a href=&#34;https://kubeblocks.io/blog/manage-large-scale-redis-on-k8s-with- kubeblocks#operation-complexity&#34;&gt;&lt;/a&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;从基于主机的系统迁移到基于 Kubernetes 的环境，同时确保持续维护，需要在 Redis 和 K8s 技术方面拥有深厚的专业知识。仅仅依靠Redis团队或K8s团队的独立支持是有挑战性的。适当的职责分工不仅可以提高生产力，还可以让每个团队充分发挥各自领域的专业知识。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;以快手云原生Redis方案为例：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Redis 团队&lt;/strong&gt;：专注于定义 Redis 集群对象并将其操作专业知识封装到声明性配置中。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;容器云团队&lt;/strong&gt;：管理 Kubernetes 方面，包括开发和维护 Operator、处理调度以及确保集群的生命周期。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://kubeblocks.io/assets/images/blog-redis-kuaishou-6-105d482f140f60a02013fd130ef4ef76.png&#34; alt=&#34;图6&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;conclusion&#34;&gt;结论&lt;a href=&#34;https://kubeblocks.io/blog/manage-large-scale-redis-on-k8s-with-kubeblocks#conclusion &#34;&gt;&lt;/a&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;有状态服务的云原生转型是一个复杂的过程，需要仔细评估其优缺点，并且充满挑战。然而，对于快手来说，其价值是不言而喻的。从Redis开始，快手与KubeBlocks社区密切合作，实现了经济高效的云原生解决方案。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;展望未来，快手希望以此经验为基础，推动数据库、中间件等更有状态服务的云原生转型，从而获得技术和成本效率的双重效益。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;8月份的香港KubeCon上，快手与KubeBlocks团队联合发表了演讲。如果您有兴趣，可以重新访问&lt;a href=&#34;https://kubeblocks.io/blog/migrate-redis-at-kuaishou-from-bare-metal-to-k8s&#34; target=&#34;_blank&#34; rel=&#34; noreferrer noopener&#34;&gt;演讲&lt;/a&gt;以获取更多见解。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;&lt;strong&gt;作者简介&lt;/strong&gt;：刘宇星是老大或者来自快手的软件工程师。宇星曾就职于阿里云、快手云原生团队，专注于云原生领域，在云原生技术的开源、商业化、规模化等方面积累了丰富的经验。宇兴也是 CNCF/Dragonfly 项目的维护者之一，也是 CNCF/Sealer 项目的维护者之一。目前主要负责推动快手有状态业务的云原生转型。&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;&lt;strong&gt;关于快手&lt;/strong&gt;：快手是中国乃至全球领先的内容社区和社交平台，致力于成为全球最以客户为中心的公司。快手以前沿人工智能技术为支撑，不断推动创新和产品升级，丰富服务内容和应用场景，创造卓越的客户价值。通过快手平台上的短视频和直播，用户可以分享自己的生活，发现自己需要的商品和服务，展示自己的才华。通过与内容创作者和企业密切合作，快手提供技术、产品和服务，满足娱乐、在线营销服务、电子商务、本地服务、游戏等广泛领域的多样化用户需求。&lt;/em &gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Mon, 16 Dec 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【k9s – manage your Kubernetes cluster and it’s objects like a pro!】k9s – 像专业人士一样管理您的 Kubernetes 集群及其对象！</title>
      <link>https://www.cncf.io/blog/2024/12/06/k9s-manage-your-kubernetes-cluster-and-its-objects-like-a-pro/</link>
      <description>【&lt;p&gt;&lt;em&gt;Community post originally published on &lt;a href=&#34;https://dev.to/aws-builders/k9s-manage-your-kubernetes-cluster-like-a-pro-lko&#34;&gt;Dev.to &lt;/a&gt;by Sunny Bhambhani&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Introduction&lt;/strong&gt;&lt;br&gt;k9s is a terminal based GUI to manage any Kubernetes(k8s) cluster. Using this single utility, we can manage, traverse, watch all our Kubernetes objects.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;More information around k9s can be found here:&amp;nbsp;&lt;a href=&#34;https://k9scli.io/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;https://k9scli.io/&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We will dive a bit into k9s and see how it can help us in our day-to-day life, how we can get started, etc.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Features&lt;/strong&gt;&lt;br&gt;Before we go into the example on how it can help, what it can do for us, let’s see some of its features, it has a ton of features, but we will focus on the ones which can help us in our day-to-day activities:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Shows a helicopter view of all the Kubernetes objects.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Easily we can move from one namespace to another.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Watch/observe the state of Kubernetes objects using&amp;nbsp;&lt;code&gt;pulses&lt;/code&gt;.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Get the&amp;nbsp;&lt;code&gt;tree&lt;/code&gt;&amp;nbsp;kind of structure using&amp;nbsp;&lt;code&gt;xrays&lt;/code&gt;&amp;nbsp;to identify objects co-relation.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Manage the objects directly from the CLI, operations like deleting, editing, restarting is just one button away.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Interestingly using a single button, you can get shell access to the pods.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Check the logs from any of the pod without actually remembering the name of the pod, just select the pod and the logs are just one button away.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Sanitize/clean up all the pods which are in completed/error state.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;…. and a lot more.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Installation&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Its installation is straight forward and is available for almost all the platforms.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Refer&amp;nbsp;&lt;a href=&#34;https://k9scli.io/topics/install/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;https://k9scli.io/topics/install/&lt;/a&gt;&amp;nbsp;for more details.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;We will be doing this on Ubuntu.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Download the latest version of k9s binary, you can use the same URL/version if required or get the latest version released and update below URL accordingly.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For latest version, refer:&amp;nbsp;&lt;a href=&#34;https://github.com/derailed/k9s/releases&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;https://github.com/derailed/k9s/releases&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;$ wget https://github.com/derailed/k9s/releases/download/v0.32.7/k9s_linux_amd64.deb&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Install it using apt package manager.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;$ sudo apt install ./k9s_linux_amd64.deb&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Once done it will get the k9s binary installed here:&amp;nbsp;&lt;code&gt;/usr/bin/k9s&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;HOWTO&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Launch k9s&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;$ k9s&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Once k9s is launched you will be presented with a beautiful layout with lots of options.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;a href=&#34;https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2F87t67zev3sc44poetl0g.png&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;800&#34; height=&#34;250&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2F87t67zev3sc44poetl0g.png&#34; alt=&#34;k9s dashboard&#34; class=&#34;wp-image-121869&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2F87t67zev3sc44poetl0g.png 800w, https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2F87t67zev3sc44poetl0g-300x94.png 300w, https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2F87t67zev3sc44poetl0g-768x240.png 768w, https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2F87t67zev3sc44poetl0g-600x188.png 600w&#34; sizes=&#34;auto, (max-width: 800px) 100vw, 800px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Press 0 to view all the pods from all the namespaces.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Navigate between Kubernetes objects&lt;/strong&gt;&lt;br&gt;Navigating is pretty easy; it is more or less like&amp;nbsp;&lt;code&gt;vi&lt;/code&gt;&amp;nbsp;or&amp;nbsp;&lt;code&gt;vim&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;For example, if you want to view deployments then press&amp;nbsp;&lt;code&gt;:&lt;/code&gt;&amp;nbsp;it will bring the cursor to a text area where you can write the object that you are interested in, for instance in current example deployments.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;The short forms too are accepted i.e. deploy in case of deployment, svc in case of service, etc.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;This also supports crds 🙂&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;a href=&#34;https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fsbafx2ouy13s02h1a1zk.png&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;637&#34; height=&#34;226&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fsbafx2ouy13s02h1a1zk.png&#34; alt=&#34;k9s textarea&#34; class=&#34;wp-image-121862&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fsbafx2ouy13s02h1a1zk.png 637w, https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fsbafx2ouy13s02h1a1zk-300x106.png 300w, https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fsbafx2ouy13s02h1a1zk-564x200.png 564w&#34; sizes=&#34;auto, (max-width: 637px) 100vw, 637px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Pods management&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Press&amp;nbsp;&lt;code&gt;:&lt;/code&gt;&amp;nbsp;and type in pods, it will show you all the pods in selected namespace, if you want to see the&amp;nbsp;&lt;strong&gt;pods from all namespaces press&amp;nbsp;&lt;code&gt;0&lt;/code&gt;&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;a href=&#34;https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fs4qdyvbrg2v0k51jdi4i.png&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;800&#34; height=&#34;222&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fs4qdyvbrg2v0k51jdi4i.png&#34; alt=&#34;k9s pods management&#34; class=&#34;wp-image-121864&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fs4qdyvbrg2v0k51jdi4i.png 800w, https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fs4qdyvbrg2v0k51jdi4i-300x83.png 300w, https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fs4qdyvbrg2v0k51jdi4i-768x213.png 768w, https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fs4qdyvbrg2v0k51jdi4i-600x167.png 600w&#34; sizes=&#34;auto, (max-width: 800px) 100vw, 800px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;There are times where we have to&amp;nbsp;&lt;strong&gt;delete the pods on the fly&lt;/strong&gt;. Just select the pod and press&amp;nbsp;&lt;code&gt;ctrl+d&lt;/code&gt;&amp;nbsp;and you are done.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;a href=&#34;https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fgz8qqw4ls8bsslxrcz63.png&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;800&#34; height=&#34;46&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fgz8qqw4ls8bsslxrcz63.png&#34; alt=&#34;k9s delete pods&#34; class=&#34;wp-image-121858&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fgz8qqw4ls8bsslxrcz63.png 800w, https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fgz8qqw4ls8bsslxrcz63-300x17.png 300w, https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fgz8qqw4ls8bsslxrcz63-768x44.png 768w, https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fgz8qqw4ls8bsslxrcz63-776x46.png 776w, https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fgz8qqw4ls8bsslxrcz63-600x35.png 600w&#34; sizes=&#34;auto, (max-width: 800px) 100vw, 800px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;There are times when you have to&amp;nbsp;&lt;strong&gt;login to a pod&lt;/strong&gt;. Just select the pod and press&amp;nbsp;&lt;code&gt;s&lt;/code&gt;&amp;nbsp;and you are done. If you want to exit, press&amp;nbsp;&lt;code&gt;ctrl+d&lt;/code&gt;&amp;nbsp;or type in&amp;nbsp;&lt;code&gt;exit&lt;/code&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;a href=&#34;https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fjougf9ja81y1tc8s63er.png&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;766&#34; height=&#34;64&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fjougf9ja81y1tc8s63er.png&#34; alt=&#34;k9s shell&#34; class=&#34;wp-image-121861&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fjougf9ja81y1tc8s63er.png 766w, https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fjougf9ja81y1tc8s63er-300x25.png 300w, https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fjougf9ja81y1tc8s63er-600x50.png 600w, https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fjougf9ja81y1tc8s63er-760x64.png 760w&#34; sizes=&#34;auto, (max-width: 766px) 100vw, 766px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Want to&amp;nbsp;&lt;strong&gt;describe the pod details&lt;/strong&gt;, press&amp;nbsp;&lt;code&gt;d&lt;/code&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;a href=&#34;https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fq550ybix1w77jlgfkfdg.png&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;592&#34; height=&#34;379&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fq550ybix1w77jlgfkfdg.png&#34; alt=&#34;k9s describe pod&#34; class=&#34;wp-image-121863&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fq550ybix1w77jlgfkfdg.png 592w, https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fq550ybix1w77jlgfkfdg-300x192.png 300w, https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fq550ybix1w77jlgfkfdg-312x200.png 312w&#34; sizes=&#34;auto, (max-width: 592px) 100vw, 592px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Want to get the yaml output of the Kubernetes objects, just select the object and press&amp;nbsp;&lt;code&gt;y&lt;/code&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;a href=&#34;https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fntqmcug89ovtm58559wi.png&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;534&#34; height=&#34;535&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fntqmcug89ovtm58559wi.png&#34; alt=&#34;k9s get yaml manifest&#34; class=&#34;wp-image-121865&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fntqmcug89ovtm58559wi.png 534w, https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fntqmcug89ovtm58559wi-300x300.png 300w, https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fntqmcug89ovtm58559wi-150x150.png 150w, https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fntqmcug89ovtm58559wi-200x200.png 200w, https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fntqmcug89ovtm58559wi-399x400.png 399w&#34; sizes=&#34;auto, (max-width: 534px) 100vw, 534px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Want to see the logs of a specific pod, select the pod and press&amp;nbsp;&lt;code&gt;l&lt;/code&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;a href=&#34;https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fkdlnbgnqx5sb8wr6k4ox.png&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;800&#34; height=&#34;317&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fkdlnbgnqx5sb8wr6k4ox.png&#34; alt=&#34;k9s logs&#34; class=&#34;wp-image-121872&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fkdlnbgnqx5sb8wr6k4ox.png 800w, https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fkdlnbgnqx5sb8wr6k4ox-300x119.png 300w, https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fkdlnbgnqx5sb8wr6k4ox-768x304.png 768w, https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fkdlnbgnqx5sb8wr6k4ox-505x200.png 505w&#34; sizes=&#34;auto, (max-width: 800px) 100vw, 800px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;You can even do port-forward from the same UI, isn’t it cool :), Just press&amp;nbsp;&lt;code&gt;shift+f&lt;/code&gt;&amp;nbsp;and if you want to see any existing port-forward are present or not, press&amp;nbsp;&lt;code&gt;f&lt;/code&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;a href=&#34;https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Frvbhsdcrysrq0qizkwqt.png&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;660&#34; height=&#34;222&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Frvbhsdcrysrq0qizkwqt.png&#34; alt=&#34;k9s portforward1&#34; class=&#34;wp-image-121860&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Frvbhsdcrysrq0qizkwqt.png 660w, https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Frvbhsdcrysrq0qizkwqt-300x101.png 300w, https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Frvbhsdcrysrq0qizkwqt-595x200.png 595w&#34; sizes=&#34;auto, (max-width: 660px) 100vw, 660px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;a href=&#34;https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fy0m6jq8ee7ql4d4l0i61.png&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;800&#34; height=&#34;29&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fy0m6jq8ee7ql4d4l0i61.png&#34; alt=&#34;k9s portforward2&#34; class=&#34;wp-image-121867&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fy0m6jq8ee7ql4d4l0i61.png 800w, https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fy0m6jq8ee7ql4d4l0i61-300x11.png 300w, https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fy0m6jq8ee7ql4d4l0i61-768x28.png 768w, https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fy0m6jq8ee7ql4d4l0i61-776x29.png 776w, https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fy0m6jq8ee7ql4d4l0i61-600x22.png 600w, https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fy0m6jq8ee7ql4d4l0i61-760x29.png 760w&#34; sizes=&#34;auto, (max-width: 800px) 100vw, 800px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Sanitize/Clean up pods: For instance in below screen dump we can see there are 2 pods which are in&amp;nbsp;&lt;code&gt;Completed&lt;/code&gt;&amp;nbsp;and we want to clean them up.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;a href=&#34;https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Ftu6dfjbfo1hcuclqqwrn.png&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;800&#34; height=&#34;185&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Ftu6dfjbfo1hcuclqqwrn.png&#34; alt=&#34;k9s sanitize1&#34; class=&#34;wp-image-121871&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Ftu6dfjbfo1hcuclqqwrn.png 800w, https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Ftu6dfjbfo1hcuclqqwrn-300x69.png 300w, https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Ftu6dfjbfo1hcuclqqwrn-768x178.png 768w, https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Ftu6dfjbfo1hcuclqqwrn-600x139.png 600w&#34; sizes=&#34;auto, (max-width: 800px) 100vw, 800px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Just press&amp;nbsp;&lt;code&gt;z&lt;/code&gt;, you will be asked “if you are sure”, type in “Yes Please!” and the job is done.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;a href=&#34;https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fnox4xwih44tw3zq3yxrx.png&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;666&#34; height=&#34;208&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fnox4xwih44tw3zq3yxrx.png&#34; alt=&#34;k9s sanitize2&#34; class=&#34;wp-image-121868&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fnox4xwih44tw3zq3yxrx.png 666w, https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fnox4xwih44tw3zq3yxrx-300x94.png 300w, https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fnox4xwih44tw3zq3yxrx-600x187.png 600w&#34; sizes=&#34;auto, (max-width: 666px) 100vw, 666px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;XRAY&lt;/strong&gt;&lt;br&gt;Xray gives you a great detail in terms of co-relation between k8s objects, it basically provides a&amp;nbsp;&lt;code&gt;tree&lt;/code&gt;&amp;nbsp;like structure.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;a href=&#34;https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fl4djaywt649akums1i4z.png&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;800&#34; height=&#34;210&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fl4djaywt649akums1i4z.png&#34; alt=&#34;k8s xray&#34; class=&#34;wp-image-121870&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fl4djaywt649akums1i4z.png 800w, https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fl4djaywt649akums1i4z-300x79.png 300w, https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fl4djaywt649akums1i4z-768x202.png 768w, https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fl4djaywt649akums1i4z-600x158.png 600w&#34; sizes=&#34;auto, (max-width: 800px) 100vw, 800px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Pulses&lt;/strong&gt;&lt;br&gt;Pulses give a great dashboard to see what exactly is happening in your cluster, what all objects are there, health of your objects, etc?&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;NOTE: Make sure metrics-server is installed and running in the cluster otherwise you won’t see proper results. In my case it was not installed, therefore it was just stating blank results.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;a href=&#34;https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fs8wcch0wl97dbwqa6c91.png&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;800&#34; height=&#34;110&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fs8wcch0wl97dbwqa6c91.png&#34; alt=&#34;k9s pulses1&#34; class=&#34;wp-image-121866&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fs8wcch0wl97dbwqa6c91.png 800w, https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fs8wcch0wl97dbwqa6c91-300x41.png 300w, https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fs8wcch0wl97dbwqa6c91-768x106.png 768w, https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fs8wcch0wl97dbwqa6c91-600x83.png 600w&#34; sizes=&#34;auto, (max-width: 800px) 100vw, 800px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;After installing metrics-server and launching&amp;nbsp;&lt;code&gt;pulses&lt;/code&gt;&amp;nbsp;it shows an awesome dashboard.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;a href=&#34;https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2F1cx0wkk46i3s38kgs1o8.png&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;800&#34; height=&#34;301&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2F1cx0wkk46i3s38kgs1o8.png&#34; alt=&#34;k9s pulses2&#34; class=&#34;wp-image-121859&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2F1cx0wkk46i3s38kgs1o8.png 800w, https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2F1cx0wkk46i3s38kgs1o8-300x113.png 300w, https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2F1cx0wkk46i3s38kgs1o8-768x289.png 768w, https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2F1cx0wkk46i3s38kgs1o8-532x200.png 532w&#34; sizes=&#34;auto, (max-width: 800px) 100vw, 800px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;The great part about it is, it shows the current status of your cluster.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;It even shows what all objects are healthy and what all objects are unhealthy.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Legend: GREEN/HEALTHY &amp;amp; YELLOW/UNHEALTHY&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;References:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://k9scli.io/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;https://k9scli.io/&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/derailed/k9s&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;https://github.com/derailed/k9s&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Feel free add your thoughts, Happy learning 🙂&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;社区帖子最初发布于 &lt;a href=&#34;https://dev.to/aws-builders/k9s-manage-your-kubernetes-cluster-like-a-pro-lko&#34;&gt;Dev.to &lt;/a&gt;作者：Sunny Bhambhani&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;简介&lt;/strong&gt;&lt;br&gt;k9s 是一个基于终端的 GUI，用于管理任何 Kubernetes(k8s) 集群。使用这个单一的实用程序，我们可以管理、遍历、观察所有 Kubernetes 对象。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;有关 k9s 的更多信息可以在此处找到：&lt;a href=&#34;https://k9scli.io/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;https://k9scli.io/&lt;/a&gt; &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们将深入研究 k9s，看看它如何在我们的日常生活中帮助我们、我们如何开始等等。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;功能&lt;/strong&gt;&lt;br&gt;在我们深入了解它如何提供帮助、它能为我们做什么之前，让我们先看看它的一些功能，它有很多功能，但我们会关注那些可以帮助我们进行日常活动的事情：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;显示所有 Kubernetes 对象的直升机视图。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;我们可以轻松地从一个命名空间移动到另一个命名空间。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;使用&lt;code&gt;脉冲&lt;/code&gt;监视/观察 Kubernetes 对象的状态。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;使用&lt;code&gt;xrays&lt;/code&gt;获取&lt;code&gt;树&lt;/code&gt;类型的结构来识别对象相互关系。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;直接从 CLI 管理对象，删除、编辑、重启等操作只需一键完成。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;有趣的是，只需使用一个按钮，您就可以通过 shell 访问 Pod。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;检查任何 Pod 的日志，无需实际记住 Pod 的名称，只需选择该 Pod，只需按一下按钮即可查看日志。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;清理/清理所有处于已完成/错误状态的 Pod。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;...。还有更多。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;安装&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;其安装非常简单，并且适用于几乎所有平台。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;请参阅&lt;a href=&#34;https://k9scli.io/topics/install/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;https://k9scli.io/topics/install/&lt;/a&gt;了解更多详情。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;我们将在 Ubuntu 上执行此操作。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;下载最新版本的 k9s 二进制文件，如果需要，您可以使用相同的 URL/版本，或者获取发布的最新版本并相应更新以下 URL。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;有关最新版本，请参阅：&lt;a href=&#34;https://github.com/derailed/k9s/releases&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;https://github.com/derailed/ k9s/发布&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;$ wget https://github.com/derailed/k9s/releases/download/v0.32.7/k9s_linux_amd64.deb&lt;/code&gt;&lt;/上一篇&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;使用 apt 包管理器安装它。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;$ sudo apt install ./k9s_linux_amd64.deb&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;完成后，k9s 二进制文件将安装在此处：&lt;code&gt;/usr/bin/k9s&lt;/code&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;如何操作&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;启动 k9s&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;$ k9s&#xA;&lt;/c颂&gt;&lt;/前&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;k9s 启动后，您将看到一个漂亮的布局和很多选项。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;a href=&#34;https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads。 s3.amazonaws.com%2Fuploads%2Farticles%2F87t67zev3sc44poetl0g.png&#34;&gt;&lt;img loading=&#34;lazy&#34;解码=“异步”宽度=“800”高度=“250”src=“https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2F87t67zev3sc44poetl0g。 png&#34; alt=&#34;k9s 仪表板&#34;类=“wp-image-121869”srcset=“https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2F87t67zev3sc44poetl0g.png 800w， https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2F87t67zev3sc44poetl0g-300x94.png 300w， https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2F87t67zev3sc44poetl0g-768x240.png 768w， https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2F87t67zev3sc44poetl0g-600x188.png 600w“尺寸=”自动，（最大宽度：800px）100vw , 800px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;按 0 可查看所有命名空间中的所有 Pod。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;在 Kubernetes 对象之间导航&lt;/strong&gt;&lt;br&gt;导航非常简单；它或多或少类似于 &lt;code&gt;vi&lt;/code&gt; 或 &lt;code&gt;vim&lt;/code&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;例如，如果您想查看部署，请按&lt;code&gt;:&lt;/code&gt;，它将光标移至文本区域，您可以在其中写入您感兴趣的对象，例如在当前示例部署中。 &lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;也接受简短的形式，即部署时为部署，服务时为 svc 等。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;这也支持 crds 🙂&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;a href=&#34;https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads。 s3.amazonaws.com%2Fuploads%2Farticles%2Fsbafx2ouy13s02h1a1zk.png&#34;&gt;&lt;img loading=&#34;lazy&#34;解码=“异步”宽度=“637”高度=“226”src=“https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fsbafx2ouy13s02h1a1zk。 png&#34; alt=&#34;k9s 文本区域&#34;类=“wp-image-121862”srcset=“https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fsbafx2ouy13s02h1a1zk.png 637w， https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fsbafx2ouy13s02h1a1zk-300x106.png 300w， https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fsbafx2ouy13s02h1a1zk-564x200.png 564w“尺寸=”自动，（最大宽度：637px）100vw , 637px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Pod 管理&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;按&lt;code&gt;:&lt;/code&gt;并输入 pod，它将显示所选命名空间中的所有 pod，如果您想查看&lt;strong&gt;所有命名空间中的 pod，请按&lt;code&gt;0&lt;/code&gt; &lt;/strong&gt;。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;a href=&#34;https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads。 s3.amazonaws.com%2Fuploads%2Farticles%2Fs4qdyvbrg2v0k51jdi4i.png&#34;&gt;&lt;img loading=&#34;lazy&#34;解码=“异步”宽度=“800”高度=“222”src=“https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fs4qdyvbrg2v0k51jdi4i。 png&#34; alt=&#34;k9s pod 管理&#34;类=“wp-image-121864”srcset=“https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fs4qdyvbrg2v0k51jdi4i.png 800w， https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fs4qdyvbrg2v0k51jdi4i-300x83.png 300w， https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fs4qdyvbrg2v0k51jdi4i-768x213.png 768w， https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fs4qdyvbrg2v0k51jdi4i-600x167.png 600w“尺寸=”自动，（最大宽度：800px）100vw , 800px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;有时我们必须&lt;strong&gt;即时删除 Pod&lt;/strong&gt;。只需选择该 Pod 并按 &lt;code&gt;ctrl+d&lt;/code&gt; 即可完成。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;a href=&#34;https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads。 s3.amazonaws.com%2Fuploads%2Farticles%2Fgz8qqw4ls8bsslxrcz63.png&#34;&gt;&lt;img loading=&#34;lazy&#34;解码=“异步”宽度=“800”高度=“46”src=“https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fgz8qqw4ls8bsslxrcz63。 png&#34; alt=&#34;k9s 删除 pod&#34;类=“wp-image-121858”srcset=“https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fgz8qqw4ls8bsslxrcz63.png 800w， https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fgz8qqw4ls8bsslxrcz63-300x17.png 300w， https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fgz8qqw4ls8bsslxrcz63-768x44.png 768w， https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fgz8qqw4ls8bsslxrcz63-776x46.png 776w， https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fgz8qqw4ls8bsslxrcz63-600x35.png 600w“尺寸=”自动，（最大宽度：800px）100vw , 800px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-块k-列表&#34;&gt;&#xA;&lt;li&gt;有时您必须&lt;strong&gt;登录 Pod&lt;/strong&gt;。只需选择该 Pod 并按 &lt;code&gt;s&lt;/code&gt; 即可完成。如果您想退出，请按&lt;code&gt;ctrl+d&lt;/code&gt;或输入&lt;code&gt;exit&lt;/code&gt;。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;a href=&#34;https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads。 s3.amazonaws.com%2Fuploads%2Farticles%2Fjougf9ja81y1tc8s63er.png&#34;&gt;&lt;img loading=&#34;lazy&#34;解码=“异步”宽度=“766”高度=“64”src=“https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fjougf9ja81y1tc8s63er。 png&#34; alt=&#34;k9s shell&#34;类=“wp-image-121861”srcset=“https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fjougf9ja81y1tc8s63er.png 766w， https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fjougf9ja81y1tc8s63er-300x25.png 300w， https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fjougf9ja81y1tc8s63er-600x50.png 600w， https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fjougf9ja81y1tc8s63er-760x64.png 760w”尺寸=“自动，（最大宽度：766px）100vw , 766px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;想要&lt;strong&gt;描述 Pod 详细信息&lt;/strong&gt;，请按&lt;code&gt;d&lt;/code&gt;。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;a href=&#34;https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads。 s3.amazonaws.com%2Fuploads%2Farticles%2Fq550ybix1w77jlgfkfdg.png&#34;&gt;&lt;img loading=&#34;lazy&#34;解码=“异步”宽度=“592”高度=“379”src=“https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fq550ybix1w77jlgfkfdg。 png&#34; alt=&#34;k9s 描述 pod&#34;类=“wp-image-121863”srcset=“https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fq550ybix1w77jlgfkfdg.png 592w， https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fq550ybix1w77jlgfkfdg-300x192.png 300w， https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fq550ybix1w77jlgfkfdg-312x200.png 312w“尺寸=”自动，（最大宽度：592px）100vw , 592px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;想要获取 Kubernetes 对象的 yaml 输出，只需选择该对象并按&lt;code&gt;y&lt;/code&gt;即可。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;a href=&#34;https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads。 s3.amazonaws.com%2Fuploads%2Farticles%2Fntqmcug89ovtm58559wi.png&#34;&gt;&lt;img loading=&#34;lazy&#34; 解码=“异步”宽度=“534”高度=“535”src=“https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fntqmcug89ovtm58559wi.png &#34; alt=&#34;k9s 获取 yaml 清单&#34;类=“wp-image-121865”srcset=“https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fntqmcug89ovtm58559wi.png 534w， https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fntqmcug89ovtm58559wi-300x300.png 300w， https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fntqmcug89ovtm58559wi-150x150.png 150w， https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fntqmcug89ovtm58559wi-200x200.png 200w， https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fntqmcug89ovtm58559wi-399x400.png 399w“尺寸=”自动，（最大宽度：534px）100vw , 534px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;想要查看特定 Pod 的日志，请选择该 Pod 并按 &lt;code&gt;l&lt;/code&gt;。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;a href=&#34;https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads。 s3.amazonaws.com%2Fuploads%2Farticles%2Fkdlnbgnqx5sb8wr6k4ox.png&#34;&gt;&lt;img loading=&#34;lazy&#34;解码=“异步”宽度=“800”高度=“317”src=“https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fkdlnbgnqx5sb8wr6k4ox。 png&#34; alt=&#34;k9s 日志&#34;类=“wp-image-121872”srcset=“https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fkdlnbgnqx5sb8wr6k4ox.png 800w， https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fkdlnbgnqx5sb8wr6k4ox-300x119.png 300w， https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fkdlnbgnqx5sb8wr6k4ox-768x304.png 768w， https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fkdlnbgnqx5sb8wr6k4ox-505x200.png 505w“尺寸=”自动，（最大宽度：800px）100vw , 800px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;您甚至可以从同一个 UI 进行端口转发，这不是很酷吗:)，如果您想查看是否存在任何现有的端口转发，只需按 &lt;code&gt;shift+f&lt;/code&gt; ，按&lt;code&gt;f&lt;/code&gt;。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;a href=&#34;https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads。 s3.amazonaws.com%2Fuploads%2Farticles%2Frvbhsdcrysrq0qizkwqt.png&#34;&gt;&lt;img loading=&#34;lazy&#34;解码=“异步”宽度=“660”高度=“222”src=“https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Frvbhsdcrysrq0qizkwqt.png&#34; alt=&#34;k9s portforward1&#34; class=&#34;wp-image-121860&#34; srcset =“https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Frvbhsdcrysrq0qizkwqt.png 660w， https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Frvbhsdcrysrq0qizkwqt-300x101.png 300w， https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Frvbhsdcrysrq0qizkwqt-595x200.png 595w“尺寸=”自动，（最大宽度：660px）100vw , 660px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;a href=&#34;https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads。 s3.amazonaws.com%2Fuploads%2Farticles%2Fy0m6jq8ee7ql4d4l0i61.png&#34;&gt;&lt;img loading=&#34;lazy&#34;解码=“异步”宽度=“800”高度=“29”src=“https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fy0m6jq8ee7ql4d4l0i61。 png&#34; alt=&#34;k9s portforward2&#34;类=“wp-image-121867”srcset=“https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fy0m6jq8ee7ql4d4l0i61.png 800w， https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fy0m6jq8ee7ql4d4l0i61-300x11.png 300w， https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fy0m6jq8ee7ql4d4l0i61-768x28.png 768w， https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fy0m6jq8ee7ql4d4l0i61-776x29.png 776w， https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fy0m6jq8ee7ql4d4l0i61-600x22.png 600w， https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fy0m6jq8ee7ql4d4l0i61-760x29.png 760w“尺寸=”自动，（最大宽度：800px）100vw , 800px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;清理/清理 pod：例如，在下面的屏幕转储中，我们可以看到有 2 个 pod 处于&lt;code&gt;已完成&lt;/code&gt;状态，我们想要清理它们。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;a href=&#34;https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads。 s3.amazonaws.com%2Fuploads%2Farticles%2Ftu6dfjbfo1hcuclqqwrn.png&#34;&gt;&lt;img 加载 =“惰性”解码 =“异步”宽度=“800”高度=“185”src=“https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Ftu6dfjbfo1hcuclqqwrn.png”alt=“ k9s 消毒1&#34; class =“wp-image-121871”srcset =“https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Ftu6dfjbfo1hcuclqqwrn.png 800w， https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Ftu6dfjbfo1hcuclqqwrn-300x69.png 300w， https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Ftu6dfjbfo1hcuclqqwrn-768x178.png 768w， https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Ftu6dfjbfo1hcuclqqwrn-600x139.png 600w“尺寸=”自动，（最大宽度：800px）100vw , 800px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;只需按&lt;code&gt;z&lt;/code&gt;，系统会询问您“是否确定”，输入“Yes Please!”工作就完成了。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;a href=&#34;https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads。 s3.amazonaws.com%2Fuploads%2Farticles%2Fnox4xwih44tw3zq3yxrx.png&#34;&gt;&lt;img loading=&#34;lazy&#34;解码=“异步”宽度=“666”高度=“208”src=“https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fnox4xwih44tw3zq3yxrx。 png&#34; alt=&#34;k9s 消毒2&#34;类=“wp-image-121868”srcset=“https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fnox4xwih44tw3zq3yxrx.png 666w， https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fnox4xwih44tw3zq3yxrx-300x94.png 300w， https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fnox4xwih44tw3zq3yxrx-600x187.png 600w“尺寸=”自动，（最大宽度：666px）100vw , 666px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;XRAY&lt;/strong&gt;&lt;br&gt;Xray 为您提供了有关 k8s 对象之间相互关系的详细信息，它基本上提供了一个类似&lt;code&gt;树&lt;/code&gt;的结构。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;a href=&#34;https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads。 s3.amazonaws.com%2Fuploads%2Farticles%2Fl4djaywt649akums1i4z.png&#34;&gt;&lt;img loading=&#34;lazy&#34;解码=“异步”宽度=“800”高度=“210”src=“https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fl4djaywt649akums1i4z。 png&#34; alt=&#34;k8s x 射线&#34;类=“wp-image-121870”srcset=“https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fl4djaywt649akums1i4z.png 800w， https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fl4djaywt649akums1i4z-300x79.png 300w， https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fl4djaywt649akums1i4z-768x202.png 768w， https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fl4djaywt649akums1i4z-600x158.png 600w”尺寸=“自动，（最大宽度：800px）100vw , 800px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;脉冲&lt;/strong&gt;&lt;br&gt;脉冲提供了一个很棒的仪表板，可以查看集群中到底发生了什么、所有对象都有哪些、对象的运行状况等等？&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;注意：确保度量服务器已安装并在集群中运行，否则您将看不到正确的结果。就我而言，它没有安装，因此它只是显示空白结果。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;a href=&#34;https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads。 s3.amazonaws.com%2Fuploads%2Farticles%2Fs8wcch0wl97dbwqa6c91.png&#34;&gt;&lt;img loading=&#34;lazy&#34;解码=“异步”宽度=“800”高度=“110”src=“https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fs8wcch0wl97dbwqa6c91。 png&#34; alt=&#34;k9s 脉冲1&#34;类=“wp-image-121866”srcset=“https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fs8wcch0wl97dbwqa6c91.png 800w， https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fs8wcch0wl97dbwqa6c91-300x41.png 300w， https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fs8wcch0wl97dbwqa6c91-768x106.png 768w， https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2Fs8wcch0wl97dbwqa6c91-600x83.png 600w”尺寸=“自动，（最大宽度：800px）100vw , 800px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;安装指标服务器并启动&lt;code&gt;pulses&lt;/code&gt;后，它会显示一个很棒的仪表板。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;a href=&#34;https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads。 s3.amazonaws.com%2Fuploads%2Farticles%2F1cx0wkk46i3s38kgs1o8.png&#34;&gt;&lt;img loading=&#34;lazy&#34;解码=“异步”宽度=“800”高度=“301”src=“https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2F1cx0wkk46i3s38kgs1o8。 png&#34; alt=&#34;k9s 脉冲2&#34;类=“wp-image-121859”srcset=“https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2F1cx0wkk46i3s38kgs1o8.png 800w， https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2F1cx0wkk46i3s38kgs1o8-300x113.png 300w， https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2F1cx0wkk46i3s38kgs1o8-768x289.png 768w， https://www.cncf.io/wp-content/uploads/2024/12/https3A2F2Fdev-to-uploads.s3.amazonaws.com2Fuploads2Farticles2F1cx0wkk46i3s38kgs1o8-532x200.png 532w“尺寸=”自动，（最大宽度：800px）100vw , 800px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;它最重要的部分是，它显示集群的当前状态。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;它甚至可以显示哪些对象是健康的，哪些对象是不健康的嘿。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;图例：绿色/健康和黄色/不健康&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;参考文献：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://k9scli.io/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;https://k9scli.io/&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/derailed/k9s&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;https://github.com/derailed/k9s&lt;/a&gt;&lt;/li &gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;随意添加你的想法，快乐学习🙂&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Thu, 05 Dec 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【What is Inference Parallelism and how it works】什么是推理并行性及其工作原理</title>
      <link>https://www.cncf.io/blog/2024/12/18/what-is-inference-parallelism-and-how-it-works/</link>
      <description>【&lt;p&gt;&lt;em&gt;Member post originally published on the &lt;a href=&#34;https://www.infracloud.io/blogs/inference-parallelism/&#34;&gt;InfraCloud blog&lt;/a&gt; by Aman Juneja, Principal Solutions Engineer at InfraCloud Technologies&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In recent years, we’ve witnessed two recurring trends: the release of increasingly powerful GPUs and the introduction of Large Language Models (LLMs) with billions or trillions of parameters and expansive context windows. Many businesses are leveraging these LLMs by fine-tuning them or building out apps with&amp;nbsp;&lt;a href=&#34;https://www.infracloud.io/blogs/retrieval-augmented-generation-using-data-with-llms/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;domain-specific knowledge using RAG&lt;/a&gt;&amp;nbsp;and deploying them on dedicated GPU servers. Now, when it comes to deploying these models on GPU, one thing to notice is the model size, i.e., the space required (for storing the parameters and context tokens) to load the model into the GPU memory is too high compared to the memory available on the GPU.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;model-size-vs-gpu-memory&#34;&gt;Model Size vs GPU Memory&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;There are methods to reduce model sizes by using optimization techniques like&amp;nbsp;&lt;a href=&#34;https://www.infracloud.io/blogs/exploring-ai-model-inference/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;quantization, pruning, distillation &amp;amp; compression, etc.&lt;/a&gt;&amp;nbsp;But if you notice in the below comparison table between the latest GPU memory and space requirement for 70B models (FP16 quantized), it’s almost impossible to handle multiple requests at a time, or in some GPUs, the model will not even fit on the memory.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-fixed-layout&#34;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;GPU&lt;/th&gt;&lt;th&gt;FP16 (TFLOPS)&lt;br&gt;with sparsity&lt;/th&gt;&lt;th&gt;GPU Memory&lt;br&gt;(GB)&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;B200&lt;/td&gt;&lt;td&gt;4500&lt;/td&gt;&lt;td&gt;192&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;B100&lt;/td&gt;&lt;td&gt;3500&lt;/td&gt;&lt;td&gt;192&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;H200&lt;/td&gt;&lt;td&gt;1979&lt;/td&gt;&lt;td&gt;141&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;H100&lt;/td&gt;&lt;td&gt;1979&lt;/td&gt;&lt;td&gt;80&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;L4&lt;/td&gt;&lt;td&gt;242&lt;/td&gt;&lt;td&gt;24&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;L40S&lt;/td&gt;&lt;td&gt;733&lt;/td&gt;&lt;td&gt;48&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;L40&lt;/td&gt;&lt;td&gt;362&lt;/td&gt;&lt;td&gt;48&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;A100&lt;/td&gt;&lt;td&gt;624&lt;/td&gt;&lt;td&gt;80&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This is all with already applied FP16 quantization that incurs some loss of precision (which is usually acceptable in many of the generic use cases).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-fixed-layout&#34;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Models&lt;/th&gt;&lt;th&gt;KV Cache in GB for Parameters (FP16)&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;llama3-8B&lt;/td&gt;&lt;td&gt;16&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;llama3-70B&lt;/td&gt;&lt;td&gt;140&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;llama-2-13B&lt;/td&gt;&lt;td&gt;26&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;llama2-70B&lt;/td&gt;&lt;td&gt;140&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;mistral-7B&lt;/td&gt;&lt;td&gt;14&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This brings us to the context of this blog post, i.e. how enterprises run large billion or trillion parameters LLM models on these modern datacenter GPUs. Are there any ways to split these models into smaller pieces and run only what is required at the moment, or can we distribute the parts of the model into different GPUs? I will try to answer these questions in this blog post with the current set of methods available to perform inference parallelization and also will try to highlight some of the tools/libraries that support these methods of parallelization.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;inference-parallelism&#34;&gt;Inference parallelism&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Inference parallelism aims to distribute the computational workload of AI models, particularly deep learning models, across multiple processing units such as GPUs. This distribution allows for faster processing, reduced latency, and the ability to handle models that exceed the memory capacity of a single device.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Four primary methods have been developed to achieve inference parallelism, each with its strengths and applications:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Data Parallelism&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Tensor Parallelism&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Pipeline Parallelism&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Expert Parallelism&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;data-parallelism&#34;&gt;Data parallelism&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In data parallelism, we deploy multiple copies of models on different GPUs or GPU clusters. Each copy of the model independently processes the user request. In a simple analogy, this is like having multiple replicas of 1 microservice.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Now, a common question one might have is how it solves the problem of model size fitting into GPU memory, which we discussed at the start, and the short answer is that it doesn’t. This method is only recommended for smaller models that can fit into the GPU memory. In those cases, we can use multiple copies of the model deployed on different GPU instances and distribute the requests to different instances hence providing enough GPU resources for each request and also increasing the availability of the service. This will also increase the overall request throughput for the system as you have more instances to handle the traffic now.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://www.infracloud.io/assets/img/Blog/inference-parallelism/data-parallelism.webp&#34; alt=&#34;Data parallelism&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;&lt;a href=&#34;https://xzt102.github.io/publications/2021_WWW.pdf&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;(ImageSource)&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;tensor-parallelism&#34;&gt;Tensor parallelism&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In tensor parallelism, we split each layer of the model across different GPUs. A single user request will be shared across multiple GPUs and the result of each request’s GPU computations will be recombined over a&amp;nbsp;&lt;a href=&#34;https://www.infracloud.io/blogs/introduction-to-nvidia-network-operator/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;GPU-to-GPU network&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To understand it better, as the name suggests, we split the tensors into chunks along a particular dimension such that each device only holds 1/N chunk of the tensor. Computation is performed using this partial chunk to get partial output. These partial outputs are collected from all devices and then combined.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://www.infracloud.io/assets/img/Blog/inference-parallelism/tensore-parallelism.webp&#34; alt=&#34;Tensor parallelism&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;&lt;a href=&#34;https://awsdocs-neuron.readthedocs-hosted.com/en/latest/libraries/neuronx-distributed/tensor_parallelism_overview.html&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;(Image Source)&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As you might have noticed already, the bottleneck to the performance of tensor parallelism is the speed of the network between GPU-to-GPU. As each request will be computed across different GPUs and then combined, we need a high-performance network to ensure low latency numbers.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://www.infracloud.io/assets/img/Blog/inference-parallelism/model-parallelism.webp&#34; alt=&#34;Model parallelism&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;&lt;a href=&#34;https://xzt102.github.io/publications/2021_WWW.pdf&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;(Image Source)&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;pipeline-parallelism&#34;&gt;Pipeline parallelism&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In pipeline parallelism, we distribute a group of model layers across different GPUs. Layer-based partitioning is the fundamental approach in pipeline parallelism. The model’s layers are grouped into continuous blocks, forming stages. This partitioning is typically done vertically through the network’s architecture. Computational balance is a key consideration. Ideally, each stage should have an approximately equal computational load to prevent bottlenecks. This often involves grouping layers of varying complexities to achieve balance. Memory usage optimization is another critical factor. Stages are designed to fit within the memory constraints of individual devices while maximizing utilization. Communication overhead minimization is also important. The partitioning aims to reduce the amount of data transferred between stages, as inter-device communication can be a significant performance bottleneck.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;So for example, if you are deploying LLaMA3-8B model that has 32 layers on a 4 GPU instance, you can split and distribute 8 layers of model on each GPU. The processing of requests happens in a sequential manner where the computation starts at one GPU and continues to the next GPU with point-to-point communication.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Again, as multiple GPU instances are involved, the networking can become a huge bottleneck if we do not have high-speed network communication between the GPUs.This parallelism can increase the GPU throughput as every request will need fewer resources from each GPU and should be easily available, but it will end up increasing the overall latency as the request will be processed sequentially, and delay in any GPU computation or network component will cause an overall surge in latency.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://www.infracloud.io/assets/img/Blog/inference-parallelism/model-parallelism-layer-wise.webp&#34; alt=&#34;Model parallelism layer wise&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;&lt;a href=&#34;https://xzt102.github.io/publications/2021_WWW.pdf&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;(Image Source)&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;expert-parallelism&#34;&gt;Expert parallelism&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Expert parallelism, often implemented as a Mixture of Experts (MoE), is a technique that allows for the efficient use of large models during the inference process. It doesn’t solve the problem of fitting the models into the GPU memory but provides an option to have a broad capability model serving the requests based on the request context. In this technique, the model is divided into multiple expert sub-networks. Each expert is typically a neural network trained to handle specific types of inputs or subtasks within the broader problem domain. A gating network determines which expert to use for each input. Only a subset of experts is activated for any given input. Different experts can be distributed across different GPUs. Router/Gating network and active experts can operate in parallel. Inactive experts don’t consume computational resources. This greatly reduces the number of parameters that each request must interact with, as some experts are skipped. But like Tensor &amp;amp; Pipeline parallelism the overall request latency relies heavily on the GPU-to-GPU communication network. A request must be reconstituted back to their original GPUs after expert processing generating high networking communication over the GPU-to-GPU interconnect fabric.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This approach can lead to better utilization of hardware compared to Tensor parallelism as you don’t have to split the operations into smaller chunks.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://www.infracloud.io/assets/img/Blog/inference-parallelism/moe-llm.webp&#34; alt=&#34;MoE LLM&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;&lt;a href=&#34;https://www.datasciencecentral.com/why-the-newest-llms-use-a-moe-mixture-of-experts-architecture/?ref=dailydev&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;(Image Source)&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Following is a summary and comparison of the methods we discussed. You can use it as a reference when planning to choose one for your use case.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-fixed-layout&#34;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Aspect&lt;/th&gt;&lt;th&gt;Data Parallelism&lt;/th&gt;&lt;th&gt;Tensor Parallelism&lt;/th&gt;&lt;th&gt;Pipeline Parallelism&lt;/th&gt;&lt;th&gt;Expert Parallelism&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;Basic Concept&lt;/td&gt;&lt;td&gt;Splits input data across multiple devices&lt;/td&gt;&lt;td&gt;Splits individual tensors/layers across devices&lt;/td&gt;&lt;td&gt;Splits model into sequential stages across devices&lt;/td&gt;&lt;td&gt;Splits model into multiple expert sub-networks&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;How it Works&lt;/td&gt;&lt;td&gt;The same model is replicated on each device, processing different data chunks&lt;/td&gt;&lt;td&gt;Single layer/operation distributed across multiple devices&lt;/td&gt;&lt;td&gt;Different parts of the model pipeline on different devices&lt;/td&gt;&lt;td&gt;The router selects specific experts for each input&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Parallelization Unit&lt;/td&gt;&lt;td&gt;Batch of inputs&lt;/td&gt;&lt;td&gt;Individual tensors/layers&lt;/td&gt;&lt;td&gt;Model stages&lt;/td&gt;&lt;td&gt;Experts (sub-networks)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Scalability&lt;/td&gt;&lt;td&gt;Scales well with batch size&lt;/td&gt;&lt;td&gt;Scales well for very large models&lt;/td&gt;&lt;td&gt;Scales well for deep models&lt;/td&gt;&lt;td&gt;Scales well for wide models&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Memory Efficiency&lt;/td&gt;&lt;td&gt;Low (full model on each device)&lt;/td&gt;&lt;td&gt;High (only part of each layer on each device)&lt;/td&gt;&lt;td&gt;High (only part of the model on each device)&lt;/td&gt;&lt;td&gt;Medium to High (experts distributed across devices)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Communication Overhead&lt;/td&gt;&lt;td&gt;Low&lt;/td&gt;&lt;td&gt;Medium to High&lt;/td&gt;&lt;td&gt;Low (only between adjacent stages)&lt;/td&gt;&lt;td&gt;Medium (router communication and expert selection)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Load Balancing&lt;/td&gt;&lt;td&gt;Generally balanced if data is evenly distributed&lt;/td&gt;&lt;td&gt;Balanced within operations&lt;/td&gt;&lt;td&gt;Can be challenging, and requires careful stage design&lt;/td&gt;&lt;td&gt;Can be challenging, and requires effective routing&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Latency&lt;/td&gt;&lt;td&gt;Low for large batches&lt;/td&gt;&lt;td&gt;Can increase for small batches&lt;/td&gt;&lt;td&gt;Higher due to pipeline depth&lt;/td&gt;&lt;td&gt;Can be low if routing is efficient&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Throughput&lt;/td&gt;&lt;td&gt;High for large batches&lt;/td&gt;&lt;td&gt;Can be high for large models&lt;/td&gt;&lt;td&gt;High, especially for deep models&lt;/td&gt;&lt;td&gt;Can be very high for diverse inputs&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Typical Use Cases&lt;/td&gt;&lt;td&gt;Large batch inference, embarrassingly parallel tasks&lt;/td&gt;&lt;td&gt;Very large models that don’t fit on a single device&lt;/td&gt;&lt;td&gt;Deep models with sequential dependencies&lt;/td&gt;&lt;td&gt;Models with diverse sub-tasks or specializations&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Challenges&lt;/td&gt;&lt;td&gt;Limited by batch size, high memory usage&lt;/td&gt;&lt;td&gt;Complex implementation, potential communication bottlenecks&lt;/td&gt;&lt;td&gt;Pipeline bubble, difficulty in optimal stage partitioning&lt;/td&gt;&lt;td&gt;Load balancing, routing overhead, training instability&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Adaptability to Input Size&lt;/td&gt;&lt;td&gt;Highly adaptable&lt;/td&gt;&lt;td&gt;Less adaptable, fixed tensor partitioning&lt;/td&gt;&lt;td&gt;Less adaptable, fixed pipeline&lt;/td&gt;&lt;td&gt;Highly adaptable, different experts for different inputs&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Suitable Model Types&lt;/td&gt;&lt;td&gt;Most model types&lt;/td&gt;&lt;td&gt;Transformer-based models, very large neural networks&lt;/td&gt;&lt;td&gt;Deep sequential models&lt;/td&gt;&lt;td&gt;Multi-task models, language models with diverse knowledge&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Supported Inference Backends&lt;/td&gt;&lt;td&gt;TensonRT-LLM, vLLM, TGI&lt;/td&gt;&lt;td&gt;TensonRT-LLM, vLLM, TGI&lt;/td&gt;&lt;td&gt;TensonRT-LLM, vLLM, TGI&lt;/td&gt;&lt;td&gt;TensonRT-LLM, vLLM, TGI&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;parallelism-techniques-combined&#34;&gt;Parallelism techniques combined&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;By now, you might already be thinking that if using the above parallelism methods means we are reducing the overall consumption or utilization of GPU, then can we not combine or replicate these to increase the overall GPU throughput? Combining Inference parallelism methods can lead to more efficient and scalable systems, especially for large and complex models.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In the table below, you can see 4 possible options but in actual scenarios based on the number of GPUs you have, this combination can grow to a very large number.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-fixed-layout&#34;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Data Parallelism (DP)&lt;br&gt;+&lt;br&gt;Pipeline Parallelism (PP)&lt;/th&gt;&lt;th&gt;Tensor Parallelism (TP)&lt;br&gt;+&lt;br&gt;Pipeline Parallelism (PP)&lt;/th&gt;&lt;th&gt;Expert Parallelism (EP)&lt;br&gt;+&lt;br&gt;Data Parallelism (DP)&lt;/th&gt;&lt;th&gt;Tensor Parallelism (TP)&lt;br&gt;+&lt;br&gt;Expert Parallelism (EP)&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;Split the model into stages (pipeline parallelism)&lt;/td&gt;&lt;td&gt;Divide the model into stages (pipeline parallelism)&lt;/td&gt;&lt;td&gt;Distribute experts across devices (expert parallelism)&lt;/td&gt;&lt;td&gt;Split large expert models across devices (tensor parallelism)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Replicate each stage across multiple devices (data parallelism)&lt;/td&gt;&lt;td&gt;Split large tensors within each stage across devices (tensor parallelism)&lt;/td&gt;&lt;td&gt;Process multiple inputs in parallel (data parallelism)&lt;/td&gt;&lt;td&gt;Split large expert models across devices (tensor parallelism)&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;So for example let’s say you have 64 GPU available and you are planning to deploy llama3-8b or Mistral 8*7B model on them. The following are some of the possible combinations of the parallelism methods. These are just examples to understand the parallelism combination strategies, for the actual use case you need to consider and benchmark other options as well.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;LLaMA 3-8B (64 GPUs)&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-fixed-layout&#34;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Strategy&lt;/th&gt;&lt;th&gt;GPU Allocation&lt;/th&gt;&lt;th&gt;Pros&lt;/th&gt;&lt;th&gt;Cons&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;PP8TP8&lt;/td&gt;&lt;td&gt;64 = 8 (pipeline) × 8 (tensor)&lt;/td&gt;&lt;td&gt;– Balanced distribution&lt;br&gt;– Reduced Communication&lt;/td&gt;&lt;td&gt;– Pipeline bubbles&lt;br&gt;– Increased latency&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;PP4TP4DP4&lt;/td&gt;&lt;td&gt;64 = 4 (pipeline) × 4 (tensor) × 4 (data)&lt;/td&gt;&lt;td&gt;– Higher throughput&lt;br&gt;– Flexible for batch sizes&lt;/td&gt;&lt;td&gt;– Complex integration&lt;br&gt;– Requires large batches&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;DP8TP8&lt;/td&gt;&lt;td&gt;64 = 8 (data) × 8 (tensor)&lt;/td&gt;&lt;td&gt;– Higher throughput&lt;br&gt;– No pipeline bubbles&lt;/td&gt;&lt;td&gt;– Large batch size needed&lt;br&gt;– High memory per GPU&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Mistral 8*7B (64 GPUs)&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-fixed-layout&#34;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Strategy&lt;/th&gt;&lt;th&gt;GPU Allocation&lt;/th&gt;&lt;th&gt;Pros&lt;/th&gt;&lt;th&gt;Cons&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;EP8TP8&lt;/td&gt;&lt;td&gt;64 = 8 (experts) × 8 (tensor per expert)&lt;/td&gt;&lt;td&gt;– Balanced memory distribution&lt;br&gt;– Efficient memory use&lt;/td&gt;&lt;td&gt;– Complex load balancing&lt;br&gt;– Potential compute underutilization&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;EP8TP4DP2&lt;/td&gt;&lt;td&gt;64 = 8 (experts) × 4 (tensor) × 2 (data)&lt;/td&gt;&lt;td&gt;– Higher throughput&lt;br&gt;– Balanced utilization&lt;/td&gt;&lt;td&gt;– Needs careful load balancing&lt;br&gt;– Large batch sizes required&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;EP8PP2TP4&lt;/td&gt;&lt;td&gt;64 = 8 (experts) × 2 (pipeline) × 4 (tensor)&lt;/td&gt;&lt;td&gt;– Supports deeper experts&lt;br&gt;– Flexible scaling&lt;/td&gt;&lt;td&gt;– Increased latency&lt;br&gt;– Complex synchronization&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;how-to-choose-one&#34;&gt;How to choose one?&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Now we have covered 4 methods of Inference parallelism, and then we have multiple combinations of these methods, so a common question you might be having is how do you choose or identify which method to use. So, the choice of inference parallelism methods broadly depends on the following factors:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Model architecture&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Use case requirements (Latency vs Throughput)&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Hardware configuration&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;model-architecture&#34;&gt;Model architecture&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Model architecture plays a crucial role in determining the most effective inference parallelism strategy. You need to identify your model architecture and then choose the parallelism method or combination of them that fits well. Different model structures fit to different parallelization techniques:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Large, deep models (e.g., GPT-4, PaLM 2):&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Benefit from pipeline parallelism&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Can be split into stages across multiple GPUs&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Good for models with many sequential layers&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Wide models with large layer sizes (LLaMA 2, BLOOM):&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Ideal for tensor parallelism&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Allow splitting individual layers across GPUs&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Effective for models with very large matrix operations&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Ensemble models or Mixture of Experts (Mixtral 8x7B, Switch Transformers):&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Well-suited for expert parallelism&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Different experts can be distributed across GPUs&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Useful for models that use different sub-networks for various tasks&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Models with small computational graphs (GPT-3.5-turbo, Falcon-7B):&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Often works well with simple data parallelism&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Can replicate the entire model across GPUs&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Effective when the model fits entirely in GPU memory&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Attention-based models (e.g., Transformers):&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Can benefit from attention slicing or multi-head parallelism&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Allow distributing attention computations across GPUs&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;use-case-requirements-latency-vs-throughput-tradeoff&#34;&gt;Use case requirements (Latency vs Throughput tradeoff)&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;You need to be familiar with your business requirements or use case, i.e., what matters to business more, the latency of the user requests, or utilization of the GPU. Or can you identify the mode of your application i.e., is it a real-time application where response time to the user request is the main driver for the user experience, or is it an offline system where response time to the user request is not the primary concern&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The reason we need to be aware of this is the tradeoff between latency and GPU throughput. If you want to reduce the latency to the user request you need to allocate more GPU resources to each request and your choice of parallelism method will rely on that. You can do optimal batching so that requests are not struggling to acquire the GPU resource which increases the overall latency.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;However, if latency is not the consideration, then your goal should be to achieve maximum throughput on the GPU by choosing the right parallelism method and appropriate batch sizes that utilize GPU resources to its maximum throughput.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-fixed-layout&#34;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Use Case&lt;/th&gt;&lt;th&gt;Preferred Parallelism&lt;/th&gt;&lt;th&gt;Latency vs Throughput Consideration&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;Real-time chatbots&lt;/td&gt;&lt;td&gt;Data parallelism or Tensor parallelism&lt;/td&gt;&lt;td&gt;Low latency priority; moderate throughput&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Batch text processing&lt;/td&gt;&lt;td&gt;Pipeline parallelism&lt;/td&gt;&lt;td&gt;High throughput priority; latency less critical&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Content recommendation&lt;/td&gt;&lt;td&gt;Expert parallelism&lt;/td&gt;&lt;td&gt;High throughput for diverse inputs; moderate latency&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Sentiment analysis&lt;/td&gt;&lt;td&gt;Data parallelism&lt;/td&gt;&lt;td&gt;High throughput; latency less critical for bulk processing&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Voice assistants&lt;/td&gt;&lt;td&gt;Tensor parallelism or Pipeline parallelism&lt;/td&gt;&lt;td&gt;Very low latency priority; moderate throughput&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;hardware-configuration&#34;&gt;Hardware configuration&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Hardware configuration often dictates the feasible parallelism strategies, and the choice should be optimized for the specific inference workload and model architecture. Following are some hardware component choices that impact the overall parallelism choices.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-fixed-layout&#34;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Hardware Component&lt;/th&gt;&lt;th&gt;Impact on Parallelism Choice&lt;/th&gt;&lt;th&gt;Examples&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;GPU Memory Capacity&lt;/td&gt;&lt;td&gt;Determines feasibility of data parallelism and influences the degree of model sharding&lt;/td&gt;&lt;td&gt;NVIDIA A100 (80GB) allows larger model chunks than A100 (40GB)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Number of GPUs&lt;/td&gt;&lt;td&gt;Affects the degree of parallelism possible across all strategies&lt;/td&gt;&lt;td&gt;8 GPUs enable more parallelism than 4 GPUs&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;GPU Interconnect Bandwidth&lt;/td&gt;&lt;td&gt;Influences efficiency of tensor and pipeline parallelism&lt;/td&gt;&lt;td&gt;NVLink offers higher bandwidth than PCIe, benefiting tensor parallelism&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;CPU Capabilities&lt;/td&gt;&lt;td&gt;Impacts data preprocessing and postprocessing in parallelism strategies&lt;/td&gt;&lt;td&gt;High-core count CPUs can better handle data parallelism overhead&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;System Memory&lt;/td&gt;&lt;td&gt;Affects the ability to hold large datasets for data parallelism&lt;/td&gt;&lt;td&gt;1TB system RAM allows larger batch sizes than 256GB&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Storage Speed&lt;/td&gt;&lt;td&gt;Influences data loading speeds in data parallelism&lt;/td&gt;&lt;td&gt;NVMe SSDs provide faster data loading than SATA SSDs&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Network Bandwidth&lt;/td&gt;&lt;td&gt;Critical for distributed inference across multiple nodes&lt;/td&gt;&lt;td&gt;Networks based on Infiniband, RoCE are faster than conventional networks for GPU fabrics&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Specialized Hardware&lt;/td&gt;&lt;td&gt;Enables specific optimizations&lt;/td&gt;&lt;td&gt;Google TPUs are optimized for tensor operations&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;AI inference parallelism is a game-changer for running big AI models efficiently. We’ve looked at different ways to split up the work, like data parallelism, tensor parallelism, pipeline parallelism, and expert parallelism. Each method has its own pros and cons, and choosing the right one depends on your specific needs and setup. It’s exciting to see tools like&amp;nbsp;&lt;a href=&#34;https://nvidia.github.io/TensorRT-LLM/advanced/expert-parallelism.html#how-to-enable&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;TensorRT-LLM&lt;/a&gt;,&amp;nbsp;&lt;a href=&#34;https://docs.vllm.ai/en/latest/serving/distributed_serving.html&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;vLLM&lt;/a&gt;, and Hugging Face’s&amp;nbsp;&lt;a href=&#34;https://huggingface.co/docs/transformers/main/en/perf_train_gpu_many#tensor-parallelism&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;Text Generation Inference&lt;/a&gt;&amp;nbsp;making these advanced techniques easier for more people to use. As AI models keep getting bigger and more complex, knowing how to use these parallelism techniques will be super important. They’re not just about handling bigger models – they’re about running AI smarter and more efficiently. By using these methods well, we can do amazing things with AI, making it faster, cheaper, and more powerful for all kinds of uses.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The future of AI isn’t just about bigger models; it’s about finding clever ways to use them in the real world. With these parallelism techniques, we’re opening doors to AI applications that were once thought impossible. If you’re looking for experts who can help you scale or build your AI infrastructure, reach out to our&amp;nbsp;&lt;a href=&#34;https://www.infracloud.io/build-ai-cloud/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;AI &amp;amp; GPU Cloud experts&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you found this post valuable and informative, subscribe to our weekly newsletter for more posts like this. I’d love to hear your thoughts on this post, so do start a conversation on&amp;nbsp;&lt;a href=&#34;https://www.linkedin.com/in/aman-juneja-291588b9/&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;LinkedIn&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;references&#34;&gt;References&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://developer.nvidia.com/blog/demystifying-ai-inference-deployments-for-trillion-parameter-large-language-models/#:~:text=NVIDIA%20Blackwell%3A%20A%20new%20platform,as%20GPT%201.8T%20MoE.&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Demystifying AI Inference Deployments for Trillion Parameter Large Language Models&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://awsdocs-neuron.readthedocs-hosted.com/en/latest/libraries/neuronx-distributed/tensor_parallelism_overview.html&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Tensor Parallelism Overview&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://xzt102.github.io/publications/2021_WWW.pdf&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Parallelizing DNN Training on GPUs: Challenges and Opportunities&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.datasciencecentral.com/why-the-newest-llms-use-a-moe-mixture-of-experts-architecture/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Why the newest LLMs use a MoE (Mixture of Experts) architecture&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;成员帖子最初由 InfraCloud 首席解决方案工程师 Aman Juneja 发布在 &lt;a href=&#34;https://www.infracloud.io/blogs/inference-parallelism/&#34;&gt;InfraCloud 博客&lt;/a&gt;上技术&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;近年来，我们见证了两个反复出现的趋势：日益强大的 GPU 的发布以及具有数十亿或数万亿参数和扩展上下文窗口的大型语言模型 (LLM) 的引入。许多企业正在通过微调这些 LLM 或使用 &lt;a href=&#34;https://www.infracloud.io/blogs/retrieval-augmented- Generation-using-data-with-llms/&#34; target= 构建应用程序来利用这些 LLM。 &#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;使用 RAG 并将其部署在专用 GPU 服务器上的特定领域知识。现在，当谈到在 GPU 上部署这些模型时，需要注意的一件事是模型大小，即将模型加载到 GPU 内存中所需的空间（用于存储参数和上下文标记）与内存相比太高可在 GPU 上使用。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;model-size-vs-gpu-memory&#34;&gt;模型大小与 GPU 内存&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;有一些方法可以通过使用优化技术来减小模型大小，例如 &lt;a href=&#34;https://www.infracloud.io/blogs/exploring-ai-model-inference/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;量化、剪枝、蒸馏和压缩等。&lt;/a&gt; 但是，如果您在下面的比较表中注意到 70B 模型（FP16 量化）的最新 GPU 内存和空间需求之间的关系，那么它几乎是不可能一次处理多个请求，或者在某些 GPU 中，模型甚至无法容纳在内存中。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-fixed-layout&#34;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;GPU&lt;/th&gt;&lt;th&gt;FP16 (TFLOPS)&lt;br&gt;稀疏&lt;/th&gt;&lt;th&gt;GPU内存&lt;br&gt;(GB)&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;B200&lt;/td&gt;&lt;td&gt;4500&lt;/td&gt;&lt;td&gt;192&lt;/td&gt;&lt; /tr&gt;&lt;tr&gt;&lt;td&gt;B100&lt;/td&gt;&lt;td&gt; 3500&lt;/td&gt;&lt;td&gt;192&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;H200&lt;/td&gt;&lt;td&gt;1979&lt;/td&gt;&lt;td&gt;141&lt;/td&gt;&lt;/tr&gt;&lt;tr &gt;&lt;td&gt;H100&lt;/td&gt;&lt;td&gt;1979&lt;/td&gt;&lt;td&gt; 80&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;L4&lt;/td&gt;&lt;td&gt;242&lt;/td&gt;&lt;td&gt;24&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;L40S&lt;/td &gt;&lt;td&gt;733&lt;/td&gt;&lt;td&gt;48&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td &gt;L40&lt;/td&gt;&lt;td&gt;362&lt;/td&gt;&lt;td&gt;48&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;A100&lt;/td&gt;&lt;td&gt;624&lt;/td&gt;&lt;td&gt;80&lt; /td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这都是已经应用的 FP16 量化导致的一些精度损失（这在许多通用用例中通常是可以接受的）。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-fixed-layout&#34;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;模型&lt;/th&gt;&lt;th&gt;参数的 KV 缓存（以 GB 为单位） (FP16)&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;llama3-8B&lt;/td&gt;&lt;td&gt;16&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;llama3 -70B&lt;/td&gt;&lt;td&gt;140&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;llama-2-1 3B&lt;/td&gt;&lt;td&gt;26&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;llama2-70B&lt;/td&gt;&lt;td&gt;140&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;米斯特拉尔- 7B&lt;/td&gt;&lt;td&gt;14&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这让我们了解了这篇博文的背景，即企业如何在这些现代数据中心 GPU 上运行数十亿或万亿参数的 LLM 模型。有没有什么方法可以将这些模型分成更小的部分并仅运行目前需要，或者我们可以将模型的各个部分分配到不同的 GPU 中吗？我将尝试在这篇博文中使用当前可用于执行推理并行化的方法集来回答这些问题，并将尝试重点介绍一些支持这些并行化方法的工具/库。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;inference-parallelism&#34;&gt;推理并行性&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;推理并行旨在跨多个处理单元（例如 GPU）分配 AI 模型（尤其是深度学习模型）的计算工作负载。这种分布可以实现更快的处理、减少延迟，并能够处理超出单个设备内存容量的模型。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;已经开发了四种主要方法来实现推理并行性，每种方法都有其优点和应用：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;数据并行&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;张量并行&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;管道并行性&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;专家并行&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;data-parallelism&#34;&gt;数据并行&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在数据并行方面，我们在不同的 GPU 或 GPU 集群上部署模型的多个副本。模型的每个副本独立处理用户请求。打个简单的比方，这就像拥有 1 个微服务的多个副本。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;现在，人们可能会遇到的一个常见问题是它如何解决模型大小适合 GPU 内存的问题，我们在一开始就讨论过这个问题，简短的回答是它没有。此方法仅建议用于可容纳 GPU 内存的较小模型。在这些情况下，我们可以使用部署在不同 GPU 实例上的模型的多个副本，并将请求分发到不同的实例，从而为每个请求提供足够的 GPU 资源，并提高服务的可用性。这也将增加系统的整体请求吞吐量，因为您现在有更多实例来处理流量。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://www.infracloud.io/assets/img/Blog/inference-parallelism/data-parallelism.webp&#34; alt= “数据并行性”referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;&lt;a href=&#34;https://xzt102.github.io/publications/2021_WWW.pdf&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;(ImageSource)&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;tensor-parallelism&#34;&gt;张量并行&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在张量并行中，我们将模型的每一层拆分到不同的 GPU 上。单个用户请求将在多个 GPU 之间共享，每个请求的 GPU 计算结果将通过 &lt;a href=&#34;https://www.infracloud.io/blogs/introduction-to-nvidia-network-operator/ 重新组合&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;GPU 到 GPU 网络&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;为了更好地理解它，顾名思义，我们将张量沿特定维度分成块，这样每个设备仅保存 1/N 块张量。使用该部分块执行计算以获得部分输出。这些部分输出是从所有设备收集然后组合的。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://www.infracloud.io/assets/img/Blog/inference-parallelism/tensore-parallelism.webp&#34; alt= “张量并行度”referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;&lt;a href=&#34;https://awsdocs-neuron.readthedocs-hosted.com/en/latest/libraries/neuronx-distributed/tensor_parallelism_overview.html&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;（图片来源）&lt;/a &gt;&lt;/图标题&gt;&lt;/图&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;您可能已经注意到，张量并行性能的瓶颈是 GPU 到 GPU 之间的网络速度。由于每个请求都将在不同的 GPU 上计算然后组合，因此我们需要高性能网络来确保低延迟。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://www.infracloud.io/assets/img/Blog/inference-parallelism/model-parallelism.webp&#34; alt= “模型并行性”referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;&lt;a href=&#34;https://xzt102.github.io/publications/2021_WWW.pdf&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;（图片来源）&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;pipeline-parallelism&#34;&gt;管道并行&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在管道并行性中，我们将一组模型层分布在不同的 GPU 上。基于层的分区是管道并行的基本方法。该模型的层被分组为连续的块，形成阶段。这种划分通常是通过网络架构垂直完成的。计算平衡是一个关键考虑因素。理想情况下，每个阶段应具有大致相等的计算负载，以防止出现瓶颈。这通常涉及对不同复杂程度的层进行分组以实现平衡。内存使用优化是另一个关键因素。阶段的设计旨在适应各个设备的内存限制，同时最大限度地提高利用率。通信开销最小化也很重要。分区的目的是减少阶段之间传输的数据量，因为设备间通信可能是一个重要的性能瓶颈。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;例如，如果您要在 4 GPU 实例上部署具有 32 层的 LLaMA3-8B 模型，则可以在每个 GPU 上拆分和分布 8 层模型。请求的处理以顺序方式进行，计算从一个 GPU 开始，并通过点对点通信继续到下一个 GPU。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;同样，由于涉及多个 GPU 实例，如果 GPU 之间没有高速网络通信，网络可能会成为一个巨大的瓶颈。这种并行性可以提高 GPU 吞吐量，因为每个请求将需要每个 GPU 更少的资源并且应该很容易获得，但是随着请求的进行，它最终会增加整体延迟将按顺序处理，任何 GPU 计算或网络组件的延迟都会导致整体延迟激增。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://www.infracloud.io/assets/img/Blog/inference-parallelism/model-parallelism-layer-wise。 webp&#34; alt=&#34;模型并行层明智&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;&lt;a href=&#34;https://xzt102.github.io/publications/2021_WWW.pdf&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;（图片来源）&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;expert-parallelism&#34;&gt;专家并行&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;专家并行通常作为专家混合 (MoE) 实现，是一种允许在推理过程中高效使用大型模型的技术。它并没有解决将模型拟合到 GPU 内存中的问题，而是提供了一种选项，可以让广泛的功能模型根据请求上下文来服务请求。在该技术中，模型被划分为多个专家子网络。每个专家通常都是一个经过训练的神经网络，可以处理更广泛问题领域内的特定类型的输入或子任务。门控网络决定每个输入使用哪个专家。对于任何给定的输入，仅激活一部分专家。不同的专家可以分布在不同的 GPU 上。路由器/门控网络和主动专家可以并行操作。不活跃的专家不消耗计算资源。这大大减少了每个请求必须交互的参数数量，因为跳过了一些专家。但与张量和管道并行性一样，整体请求延迟在很大程度上依赖于 GPU 到 GPU 的通信网络。经过专家处理后，请求必须重新构造回其原始 GPU，从而通过 GPU 到 GPU 互连结构生成高网络通信。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;与张量并行相比，这种方法可以更好地利用硬件，因为您不必将操作分割成更小的块。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://www.infracloud.io/assets/img/Blog/inference-parallelism/moe-llm.webp&#34; alt= “教育部法学硕士”referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;&lt;a href=&#34;https://www.datasciencecentral.com/why-the-newest-llms-use-a-moe-mixture-of-experts-architecture/?ref=dailydev&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener &#34;&gt;（图片来源）&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;以下是我们讨论的方法的总结和比较。您可以在计划为您的用例选择一个时将其用作参考。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-fixed-layout&#34;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;方面&lt;/th&gt;&lt;th&gt;数据并行&lt;/th&gt;&lt;th&gt;张量并行&lt;/th&gt;&lt;th&gt;管道并行&lt;/th&gt;&lt;th&gt;专家并行&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;基本概念&lt;/td&gt;&lt;td&gt;跨多个设备分割输入数据&lt;/td&gt;&lt;td&gt;跨设备分割单个张量/层&lt;/td&gt;&lt;td&gt;分割模型跨设备划分为连续阶段&lt;/td&gt;&lt;td&gt;将模型拆分为多个专家子网络&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;工作原理&lt;/td&gt;&lt;td&gt;相同的模型被复制每个设备，处理不同的数据块&lt;/td&gt;&lt;td&gt;分布在多个设备上的单层/操作&lt;/td&gt;&lt;td&gt;不同设备上模型管道的不同部分&lt;/td&gt;&lt;td&gt;路由器选择特定的专家为了每个输入&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;并行化单元&lt;/td&gt;&lt;td&gt;批量输入&lt;/td&gt;&lt;td&gt;单个张量/层&lt;/td&gt;&lt;td&gt;模型阶段&lt;/td&gt;&lt;td&gt; td&gt;&lt;td&gt;专家（子网络）&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;可扩展性&lt;/td&gt;&lt;td&gt;随批量大小良好扩展&lt;/td&gt;&lt;td&gt;扩展对于非常大的模型来说很好&lt;/td&gt;&lt;td&gt;对于深度模型来说可以很好地扩展&lt;/td&gt;&lt;td&gt;对于宽模型来说可以很好地扩展&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;内存效率&lt;/td&gt;&lt; td&gt;低（每个设备上的完整模型）&lt;/td&gt;&lt;td&gt;高（每个设备上仅每个层的部分）&lt;/td&gt;&lt;td&gt;高（每个设备上仅每个层的部分模型）设备）&lt;/td&gt;&lt;td&gt;中到高（跨设备分布的专家）&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;通信开销&lt;/td&gt;&lt;td&gt;低&lt;/td&gt;&lt;td&gt;中至高&lt;/td&gt;&lt;td&gt;低（仅在相邻阶段之间）&lt;/td&gt;&lt;td&gt;中（路由器通信和专家选择）&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;负载平衡&lt;/td&gt;&lt;td&gt;如果数据均匀分布，则通常是平衡的&lt;/td&gt;&lt;td&gt;操作内平衡&lt;/td&gt;&lt;td&gt;可能具有挑战性，需要仔细的阶段设计&lt;/td&gt;&lt;td&gt;可以具有挑战性，并且需要有效的路由&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;延迟&lt;/td&gt;&lt;td&gt;大批量时较低&lt;/td&gt;&lt;td&gt;小批量时可以增加批次&lt;/td&gt;&lt;td&gt;由于管道深度而较高&lt;/td&gt;&lt;td&gt;如果路由高效，则可能较低&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;吞吐量&lt;/td&gt;&lt;td&gt;高对于大批量&lt;/td&gt;&lt;td&gt;对于大型模型可以很高&lt;/td&gt;&lt;td&gt;高，特别是对于深度模型&lt;/td&gt;&lt;td&gt;对于多样化可以非常高输入&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;典型用例&lt;/td&gt;&lt;td&gt;大批量推理，令人尴尬的并行任务&lt;/td&gt;&lt;td&gt;非常大的模型，不适合单个设备&lt;/td&gt;&lt;td&gt;具有顺序依赖关系的深度模型&lt;/td&gt;&lt;td&gt;具有不同子任务或专业&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;挑战&lt;/td&gt;&lt;td&gt;受批量大小限制，内存使用率高&lt;/td&gt;&lt;td&gt;实现复杂，潜在的通信瓶颈&lt;/td&gt;&lt;td &gt;管道气泡、最优阶段划分困难&lt;/td&gt;&lt;td&gt;负载均衡、路由开销、训练不稳定&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;对输入的适应性大小&lt;/td&gt;&lt;td&gt;适应性强&lt;/td&gt;&lt;td&gt;适应性较差，固定张量划分&lt;/td&gt;&lt;td&gt;适应性较差，固定管道&lt;/td&gt;&lt;td&gt;适应性强，不同的专家针对不同的输入&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;合适的模型类型&lt;/td&gt;&lt;td&gt;大多数模型类型&lt;/td&gt;&lt;td&gt;基于 Transformer 的模型，非常大的神经网络网络&lt;/td&gt;&lt;td&gt;深度序列模型&lt;/td&gt;&lt;td&gt;多任务模型、具有多种知识的语言模型&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;支持的推理后端&lt;/td&gt;&lt; td&gt;TensonRT-LLM，vLLM，TGI&lt;/td&gt;&lt;td&gt;TensonRT-LLM，vLLM，TGI&lt;/td&gt;&lt;td&gt;TensonRT-LLM， vLLM，TGI&lt;/td&gt;&lt;td&gt;TensonRT-LLM，vLLM，TGI&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;parallelism-techniques-combined&#34;&gt;并行技术组合&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;现在，您可能已经在想，如果使用上述并行方法意味着我们正在减少 GPU 的总体消耗或利用率，那么我们是否可以不组合或复制这些方法来提高 GPU 的总体吞吐量？结合推理并行方法可以带来更高效和可扩展的系统，特别是对于大型和复杂的模型。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在下表中，您可以看到 4 个可能的选项，但在实际场景中，根据您拥有的 GPU 数量，此组合可能会增长到非常大的数量。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-fixed-layout&#34;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;数据并行性 (DP)&lt;br&gt;+&lt;br&gt;管道并行性 (PP) &lt;/th&gt;&lt;th&gt;张量并行性 (TP)&lt;br&gt;+&lt;br&gt;管道并行性 (PP)&lt;/th&gt;&lt;th&gt;专家并行性 (EP)&lt;br&gt;+&lt;br&gt;数据并行性 (DP)&lt;/th&gt;&lt;th&gt;张量并行性 (TP)&lt;br&gt;+&lt;br&gt;专家并行性 (EP)&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;分割将模型划分为阶段（管道并行）&lt;/td&gt;&lt;td&gt;将模型划分为阶段（管道并行）&lt;/td&gt;&lt;td&gt;跨设备分配专家（专家并行）&lt;/td&gt;&lt;td&gt;跨设备拆分大型专家模型（张量并行）&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;跨多个设备复制每个阶段（数据并行）&lt;/td&gt;&lt;td&gt;跨设备拆分每个阶段中的大张量（张量并行性）&lt;/td&gt;&lt;td&gt;并行处理多个输入（数据并行性）&lt;/td&gt;&lt;td&gt;跨设备拆分大型专家模型（张量并行性）&lt;/td&gt;&lt;td&gt;跨设备拆分大型专家模型（张量并行性）并行性）&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;例如，假设您有 64 个可用 GPU，并且您计划在其上部署 llama3-8b 或 Mistral 8*7B 模型。以下是并行方法的一些可能的组合。这些只是理解并行组合策略的示例，对于实际用例，您还需要考虑和基准测试其他选项。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;LLaMA 3-8B（64 个 GPU）&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-fixed-layout&#34;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;策略&lt;/th&gt;&lt;th&gt;GPU分配&lt;/th&gt;&lt;th&gt;优点&lt;/th&gt;&lt;th&gt;缺点&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;PP8TP8&lt;/td&gt;&lt;td&gt;64 = 8（管道）× 8 （张量）&lt;/td&gt;&lt;td&gt;– 平衡分布&lt;br&gt;– 减少通信&lt;/td&gt;&lt;td&gt;– 管道气泡&lt;br&gt;– 延迟增加&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;PP4TP4DP4 &lt;/td&gt;&lt;td&gt;64 = 4（管道）× 4（张量）× 4（数据）&lt;/td&gt;&lt;td&gt; – 更高的吞吐量&lt;br&gt; – 批量灵活大小&lt;/td&gt;&lt;td&gt; – 复杂集成&lt;br&gt; – 需要大批量&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;DP8TP8&lt;/td&gt;&lt;td&gt;64 = 8（数据）× 8（张量)&lt;/td&gt;&lt;td&gt;– 更高的吞吐量&lt;br&gt;– 无管道气泡&lt;/td&gt;&lt;td&gt;– 需要大批量&lt;br&gt;– 每块内存较高GPU&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Mistral 8*7B（64 个 GPU）&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-fixed-layout&#34;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;策略&lt;/th&gt;&lt;th&gt;GPU分配&lt;/th&gt;&lt;th&gt;优点&lt;/th&gt;&lt;th&gt;缺点&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;EP8TP8&lt;/td&gt;&lt;td&gt;64 = 8（专家）× 8（每张量专家）&lt;/td&gt;&lt;td&gt;– 平衡ed 内存分配&lt;br&gt;– 高效的内存使用&lt;/td&gt;&lt;td&gt;– 复杂的负载平衡&lt;br&gt;– 潜在的计算利用率不足&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;EP8TP4DP2&lt;/td&gt;&lt;td&gt; 64 = 8（专家）× 4（张量）× 2（数据）&lt;/td&gt;&lt;td&gt;– 更高的吞吐量&lt;br&gt;– 平衡利用率&lt;/td&gt;&lt;td&gt;– 需要小心负载均衡&lt;br&gt;-需要大批量&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;EP8PP2TP4&lt;/td&gt;&lt;td&gt;64 = 8（专家）×2（管道）×4（张量）&lt;/ td&gt;&lt;td&gt;– 支持更深层次的专家&lt;br&gt;– 灵活扩展&lt;/td&gt;&lt;td&gt;– 增加延迟&lt;br&gt;– 复杂同步&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure &gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;how-to-choose-one&#34;&gt;如何选择一个？&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;现在我们已经介绍了 4 种推理并行方法，然后我们有这些方法的多种组合，因此您可能遇到的一个常见问题是如何选择或确定要使用哪种方法。因此，推理并行方法的选择大致取决于以下因素：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;模型架构&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;用例要求（延迟与吞吐量）&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;硬件配置&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;model-architecture&#34;&gt;模型架构&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;模型架构在确定最有效的推理并行策略方面起着至关重要的作用。您需要确定您的模型架构，然后选择适合的并行方法或它们的组合。不同的模型结构适合不同的并行化技术：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;大型、深度模型（例如 GPT-4、PaLM 2）：&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;从管道并行性中获益&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;可以跨多个 GPU 分为多个阶段&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;适合具有多个连续层的模型&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;具有大层尺寸的宽模型（LLaMA 2、BLOOM）：&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;张量并行的理想选择&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;允许跨 GPU 拆分各个层&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;对于具有非常大矩阵运算的模型有效&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;集成模型或专家组合（Mixtral 8x7B、开关变压器）：&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;非常适合专家并行&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;不同的专家可以分布在 GPU 上&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;对于使用不同子网络执行各种任务的模型非常有用&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;具有小型计算图的模型（GPT-3.5-turbo、Falcon-7B）：&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;通常适用于简单的数据并行性&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;可以跨 GPU 复制整个模型&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;当模型完全适合 GPU 内存时有效&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;基于注意力的模型（例如 Transformer）：&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;可以从注意力切片或多头并行性中受益&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;允许跨 GPU 分配注意力计算&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;use-case-requirements-latency-vs-throughput-tradeoff&#34;&gt;用例要求（延迟与阈值）吞吐量权衡）&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;您需要熟悉您的业务需求或用例，即什么对业务更重要、用户请求的延迟或 GPU 的利用率。或者您能否确定应用程序的模式，即，它是实时应用程序，其中对用户请求的响应时间是用户体验的主要驱动因素，还是离线系统，其中对用户请求的响应时间不是用户体验的主要驱动因素？主要关心的问题&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们需要意识到这一点的原因是延迟和 GPU 吞吐量之间的权衡。如果您想减少用户请求的延迟，您需要为每个请求分配更多的 GPU 资源，并且您选择的并行方法将取决于此。您可以进行最佳批处理，这样请求就不会努力获取 GPU 资源，从而增加整体延迟。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;但是，如果不考虑延迟，那么您的目标应该是通过选择正确的并行方法和适当的批处理大小来实现 GPU 上的最大吞吐量，从而利用 GPU 资源达到最大吞吐量。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-fixed-layout&#34;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;用例&lt;/th&gt;&lt;th&gt;首选并行度&lt;/th&gt;&lt;th &gt;延迟与吞吐量考虑&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;实时聊天机器人&lt;/td&gt;&lt;td&gt;数据并行性或张量并行性&lt;/td&gt;&lt;td&gt;低延迟优先；中等吞吐量&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;批量文本处理&lt;/td&gt;&lt;td&gt;管道并行&lt;/td&gt;&lt;td&gt;高吞吐量优先；延迟不太重要&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;内容推荐&lt;/td&gt;&lt;td&gt;专家并行性&lt;/td&gt;&lt;td&gt;不同输入的高吞吐量；中等延迟&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;情感分析&lt;/td&gt;&lt;td&gt;数据并行性&lt;/td&gt;&lt;td&gt;高吞吐量；延迟对于批量处理不太重要&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;语音助手&lt;/td&gt;&lt;td&gt;张量并行或管道并行&lt;/td&gt;&lt;td&gt;非常低的延迟优先级；中等吞吐量&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;hardware-configuration&#34;&gt;硬件配置&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;硬件配置通常决定了可行的并行策略，并且应针对特定的推理工作负载和模型架构来优化选择。以下是一些影响整体并行性选择的硬件组件选择。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-fixed-layout&#34;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;硬件组件&lt;/th&gt;&lt;th&gt;对并行性选择的影响&lt;/th&gt; &lt;th&gt;示例&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;GPU显存容量&lt;/td&gt;&lt;td&gt;决定数据并行的可行性并影响模型的程度分片&lt;/td&gt;&lt;td&gt;NVIDIA A100 (80GB) 允许比 A100 (40GB) 更大的模型块&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;GPU 数量&lt;/td&gt;&lt;td&gt;影响分片程度所有策略均可实现并行性&lt;/td&gt;&lt;td&gt;8 个 GPU 比 4 个 GPU 实现更多并行性&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;GPU 互连带宽&lt;/td&gt;&lt;td&gt;影响张量和管道并行性的效率&lt;/td&gt;&lt;td&gt;NVLink提供更高的禁令宽度高于 PCIe，有利于张量并行&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;CPU 能力&lt;/td&gt;&lt;td&gt;影响并行策略中的数据预处理和后处理&lt;/td&gt;&lt;td&gt;高核数 CPU可以更好地处理数据并行开销&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;系统内存&lt;/td&gt;&lt;td&gt;影响保存大型数据集的能力并行性&lt;/td&gt;&lt;td&gt;1TB系统RAM允许大于256GB的批量大小&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;存储速度&lt;/td&gt;&lt;td&gt;影响数据并行性中的数据加载速度&lt;/td &gt;&lt;td&gt;NVMe SSD 提供比 SATA SSD 更快的数据加载&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;网络带宽&lt;/td&gt;&lt;td&gt;对于跨多个设备的分布式推理至关重要节点&lt;/td&gt;&lt;td&gt;基于 Infiniband、RoCE 的网络比 GPU 结构的传统网络更快&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;专用硬件&lt;/td&gt;&lt;td&gt;实现特定优化&lt;/td&gt;&lt;td&gt; td&gt;&lt;td&gt;Google TPU 针对张量运算进行了优化&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;conclusion&#34;&gt;结论&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;人工智能推理并行性是高效运行大型人工智能模型的游戏规则改变者。我们研究了划分工作的不同方法，例如数据并行、张量并行、管道并行和专家并行。每种方法都有其优点和缺点，选择正确的方法取决于您的具体需求和设置。看到像 &lt;a href=&#34;https://nvidia.github.io/TensorRT-LLM/advanced/expert-parallelism.html#how-to-enable&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34; 这样的工具真是令人兴奋&gt;TensorRT-LLM&lt;/a&gt;，&lt;a href=&#34;https://docs.vllm.ai/en/latest/serving/distributed_serving.html&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;vLLM&lt;/a&gt; 和 Hugging Face 的 &lt;a href=&#34;https://huggingface.co/docs/transformers/main/en/perf_train_gpu_many#tensor-parallelism&#34; rel= &#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;文本生成推理&lt;/a&gt;让这些先进技术更容易被更多人使用。随着人工智能模型变得越来越大、越来越复杂，了解如何使用这些并行技术将变得非常重要。它们不仅仅是处理更大的模型，而是更智能、更高效地运行人工智能。通过充分利用这些方法，我们可以利用人工智能做出惊人的事情，使其更快、更便宜、更强大，适合各种用途。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;人工智能的未来不仅仅在于更大的模型；还在于更大的模型。这是关于找到在现实世界中使用它们的聪明方法。借助这些并行技术，我们为曾经被认为不可能的人工智能应用打开了大门。如果您正在寻找可以帮助您扩展或构建 AI 基础设施的专家，请联系我们的 &lt;a href=&#34;https://www.infracloud.io/build-ai-cloud/&#34; target=&#34;_blank&#34; rel =&#34;noreferrer noopener&#34;&gt;AI 和 GPU 云专家&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您发现这篇文章有价值且信息丰富，请订阅我们的每周时事通讯以获取更多此类帖子。我很想听听您对这篇文章的看法，所以请在 &lt;a href=&#34;https://www.linkedin.com/in/aman-juneja-29158 上开始对话8b9/&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;LinkedIn&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;references&#34;&gt;参考&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://developer.nvidia.com/blog/demystifying-ai-inference-deployments-for-trillion-parameter-large-language-models/#:~:text=NVIDIA%20Blackwell% 3A%20A%20new%20平台，如%20GPT%201.8T%20MoE。” target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;揭秘万亿参数大型语言模型的人工智能推理部署&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://awsdocs-neuron.readthedocs-hosted.com/en/latest/libraries/neuronx-distributed/tensor_parallelism_overview.html&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;张量并行概述&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://xzt102.github.io/publications/2021_WWW.pdf&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;GPU 上的并行 DNN 训练：挑战和机遇&lt;/a&gt;&lt; /里&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.datasciencecentral.com/why-the-newest-llms-use-a-moe-mixture-of-experts-architecture/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;为什么最新的法学硕士使用 MoE（专家混合）架构&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Tue, 17 Dec 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Platform Engineering needs Observability: here’s why】平台工程需要可观察性：原因如下</title>
      <link>https://www.cncf.io/blog/2024/12/16/platform-engineering-needs-observability-heres-why/</link>
      <description>【&lt;p&gt;&lt;em&gt;Blog post originally published on the &lt;a href=&#34;https://middleware.io/blog/platform-engineering/&#34;&gt;Middleware blog&lt;/a&gt; by Sri Krishna&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In the high-stakes environment of&amp;nbsp;&lt;a href=&#34;https://middleware.io/blog/best-practices-to-avoid-website-outages-on-black-friday/&#34;&gt;Black Friday&lt;/a&gt;, e-commerce platforms encounter intense traffic surges that can heavily strain system performance. For example, during Black Friday 2023, online sales soared to&amp;nbsp;&lt;a href=&#34;https://www.yugabyte.com/blog/black-friday-sales-results/&#34;&gt;$9.8 billion&lt;/a&gt;, a 7.5% increase from the previous year, highlighting the substantial pressure placed on digital infrastructures.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Despite these gains, some retailers experienced website&amp;nbsp;&lt;a href=&#34;https://analyticsindiamag.com/ai-origins-evolution/could-observability-help-prevent-another-crowdstrike-outage/&#34;&gt;outages&lt;/a&gt;, underscoring the critical need for reliable platform engineering practices that prioritize valuable feedback from internal customers.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;A key strategy to mitigate such risks is integrating&amp;nbsp;&lt;a href=&#34;https://middleware.io/blog/observability/&#34;&gt;observability&lt;/a&gt;&amp;nbsp;into platform engineering. Observability offers real-time insights into system behavior, allowing teams to proactively identify and address issues before they affect users. By adopting observability, platform engineering teams can improve system resilience, sustain uninterrupted user experiences during&amp;nbsp;&lt;a href=&#34;https://middleware.io/customers/hotplate/&#34;&gt;peak events&lt;/a&gt;, and uphold operational stability.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This article examines how observability elevates platform engineering by tackling complex challenges, refining workflows, and fortifying system reliability.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;understanding-platform-engineering&#34;&gt;Understanding Platform Engineering&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Platform engineering is about creating a stable, scalable foundation that meets the needs of&amp;nbsp;&lt;a href=&#34;https://middleware.io/blog/what-is-devops/&#34;&gt;development and operations teams&lt;/a&gt;. Rather than just managing&amp;nbsp;&lt;a href=&#34;https://middleware.io/blog/what-is-infrastructure-monitoring/&#34;&gt;infrastructure&lt;/a&gt;, it involves building shared tools, environments, and workflows to improve collaboration and minimize operational friction for development teams. By providing a standardized platform, platform engineering enables faster, consistent application deployment and allows engineers to focus on development without being weighed down by infrastructure complexities.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Roles within platform engineering, such as release engineers, tooling engineers, and infrastructure architects, work together to ensure smooth deployments, maintain tool efficiency, and design scalable infrastructure, all critical for a cohesive platform engineering strategy.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-complexities&#34;&gt;Complexities&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Modern infrastructure is increasingly complex and continuously evolving, posing significant cognitive load and challenges for engineers. This complexity stems from the need for various tools and frameworks, such as&amp;nbsp;&lt;a href=&#34;https://middleware.io/blog/kubernetes-monitoring/&#34;&gt;Kubernetes&lt;/a&gt;&amp;nbsp;for&amp;nbsp;&lt;a href=&#34;https://middleware.io/blog/what-is-container-orchestration/&#34;&gt;container orchestration&lt;/a&gt;,&amp;nbsp;&lt;a href=&#34;https://middleware.io/blog/helm-chart-tutorial/&#34;&gt;Helm&lt;/a&gt;&amp;nbsp;for application deployment, Terraform for infrastructure as code, and specialized monitoring systems. These tools, while powerful, must work in harmony, which requires careful planning and configuration.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://middleware.io/wp-content/uploads/2024/11/Platform-engg-1024x842.png&#34; alt=&#34;Understanding Platform Engineering and Internal Developer Platform&#34; class=&#34;wp-image-8354&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Platform engineering addresses these complexities by establishing a cohesive, scalable foundation, yet it must navigate several critical factors:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Distributed systems&lt;/strong&gt;: As&amp;nbsp;&lt;a href=&#34;https://middleware.io/blog/why-is-monitoring-your-application-important/&#34;&gt;applications&lt;/a&gt;&amp;nbsp;scale, they frequently extend across multiple servers, cloud providers, or regions, forming a complex interconnected network. Reliable communication among these services is important, as even minor disruptions can ripple across the entire system.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Microservices&lt;/strong&gt;: Breaking applications into smaller, independent services offers flexibility but introduces challenges like dependency management, version control, and service discovery to ensure each&amp;nbsp;&lt;a href=&#34;https://middleware.io/blog/microservices-architecture-docker/&#34;&gt;microservice&lt;/a&gt;&amp;nbsp;connects smoothly with others.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Real-time data flow&lt;/strong&gt;: Many applications rely on real-time data processing for analytics,&amp;nbsp;&lt;a href=&#34;https://middleware.io/blog/how-can-you-enhance-user-satisfaction-with-rum/&#34;&gt;user interactions&lt;/a&gt;, or insights. Handling these data streams efficiently requires infrastructure that can maintain high throughput with minimal latency.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For example, scaling a service during peak demand, such as an e-commerce sale, requires not only a reliable infrastructure but also automation and monitoring to dynamically adjust resources and prevent bottlenecks in real time.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-infrastructure-management&#34;&gt;Infrastructure management&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In platform engineering, effective infrastructure management is key to sustaining a reliable and scalable environment that supports both development and operations. Through efficient deployment,&amp;nbsp;&lt;a href=&#34;https://middleware.io/blog/observability-vs-monitoring/&#34;&gt;monitoring&lt;/a&gt;, and management of infrastructure, platform engineers establish a solid foundation that adapts to changing demands and improves&amp;nbsp;&lt;a href=&#34;https://middleware.io/blog/why-is-monitoring-your-application-important/&#34;&gt;application performance&lt;/a&gt;. Additionally, these practices enable developer self-service by providing integrated tools and workflows that empower developers to manage their applications autonomously.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This involves:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Automating deployments&lt;/strong&gt;&amp;nbsp;to ensure consistent and rapid releases, minimizing errors.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Monitoring performance&lt;/strong&gt;&amp;nbsp;across key metrics to detect and resolve issues before they affect users.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Scaling resources&lt;/strong&gt;&amp;nbsp;dynamically based on demand, managing costs while ensuring system readiness during peak times.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Together, these infrastructure management practices support platform engineering’s core goal: building a resilient environment that enables teams to deliver applications efficiently and reliably.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;platform-engineering-vs.-devops-vs.-site-reliability-engineering-(sre)&#34;&gt;Platform Engineering vs. DevOps vs. Site Reliability Engineering (SRE)&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;While platform engineering, DevOps, and Site Reliability Engineering (SRE) all contribute to improving software delivery, each focuses on distinct aspects of the process:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Platform engineering&lt;/strong&gt;: Focused on building and maintaining the core infrastructure and tools, platform engineering creates a scalable foundation for development and operations. A platform engineer provides self-service tools and environments, reducing friction and enabling teams to build, test, and deploy efficiently.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;DevOps&lt;/strong&gt;: DevOps is a cultural approach that promotes collaboration between development and operations. It aims to optimize workflows, automate processes, and improve delivery speed through practices like CI/CD, fostering alignment across teams for faster, more reliable releases.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Site reliability engineering (SRE)&lt;/strong&gt;: Developed at Google, SRE applies engineering principles to operations, focusing on balancing reliability and release velocity. SREs set and maintain service-level objectives (SLOs), manage incident response, and use error budgeting to keep services reliable while supporting a stable release pace.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;why-observability-is-needed-in-platform-engineering&#34;&gt;Why Observability is needed in Platform Engineering&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-beyond-traditional-monitoring&#34;&gt;Beyond traditional monitoring&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Traditional monitoring focuses on tracking known metrics, setting alert thresholds, and responding to specific issues as they arise. This makes it largely reactive and useful for catching immediate problems like high CPU usage or memory consumption. However, monitoring’s limitations become evident when dealing with the intricate, interdependent systems found in modern infrastructure, where isolated metrics rarely reveal the full picture.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Observability, by contrast, is dynamic and proactive, giving platform engineering teams and software developers a holistic view of system interactions. Instead of flagging individual metrics, observability enables engineers to query and explore data across services, providing insights into relationships and dependencies that monitoring alone might miss. This expanded visibility allows teams to troubleshoot complex issues more effectively, ensuring that all system components work together smoothly and stably.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-real-world-use-cases&#34;&gt;Real-world use cases&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In a microservices architecture, where applications are built from many interdependent services, a slowdown or failure in one component can cascade across the system.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For example, monitoring might highlight general latency in user-facing features, but observability tools can trace the source of the slowdown to a specific service. By examining traces, metrics, and logs, platform engineers can pinpoint precisely where the latency originates, whether it’s a slow database query or an overloaded API.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Consider these use cases:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Latency detection in distributed systems&lt;/strong&gt;: Observability traces can help track the path of a user request, identifying exactly where delays occur within the sequence of services. If a payment service is causing delays in the checkout process, observability will help pinpoint that bottleneck, while traditional monitoring might only indicate increased latency without context.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Root cause analysis across services&lt;/strong&gt;: In complex architectures, a failure in one microservice might impact several downstream services. Observability connects the dots, showing how errors propagate through the system and allowing platform engineers to trace the issue to a specific API call, third-party integration, or configuration change rather than treating symptoms across multiple services.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Proactive anomaly detection&lt;/strong&gt;: Observability also enables early detection of performance issues by identifying subtle changes, such as a gradual increase in response times or error rates. By recognizing these early indicators, platform engineers can take corrective action before an incident escalates, preserving system stability and user experience.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Through observability, platform engineering teams can maintain not only a responsive but also a resilient platform. They gain the depth needed to identify, address, and prevent issues, increasing overall system reliability while supporting the smooth operation of critical applications.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-the-three-pillars-of-observability&#34;&gt;The three pillars of Observability&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Observability relies on three foundational components, often called the “pillars” of observability, which together offer a comprehensive view of system health and performance:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Metrics&lt;/strong&gt;:&amp;nbsp;&lt;a href=&#34;https://middleware.io/product/metrics/&#34;&gt;Metrics&lt;/a&gt;&amp;nbsp;are quantitative data points that track the performance of key resources, such as CPU usage, memory consumption, or request rates. Metrics provide real-time indicators of system health, helping engineers identify trends and respond quickly to any abnormalities.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Logs&lt;/strong&gt;:&amp;nbsp;&lt;a href=&#34;https://middleware.io/product/log-monitoring/&#34;&gt;Logs&lt;/a&gt;&amp;nbsp;are detailed records of events across the system. They capture a chronological account of actions, errors, and system warnings, providing context for when, where, and how specific events occurred. Logs are invaluable for tracing issues back to their source, as they offer precise, timestamped information about the system’s state.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Traces&lt;/strong&gt;:&amp;nbsp;&lt;a href=&#34;https://middleware.io/product/distributed-tracing/&#34;&gt;Traces&lt;/a&gt;&amp;nbsp;follow the lifecycle of a request as it travels through different components of a system, from start to finish. They offer a visual map of each service or function the request interacts with, pinpointing where delays or errors might occur. Tracing is particularly useful for diagnosing issues in distributed systems, as it reveals how different services interact and where bottlenecks might lie.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The platform engineering team plays a crucial role in implementing these three pillars, allowing teams to gain an in-depth view of system operations enabling them to understand both individual components and their interactions within the broader infrastructure.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-proactive-issue-resolution&#34;&gt;Proactive issue resolution&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;One of the most significant advantages of observability is the ability to detect potential issues before they impact users proactively. Unlike traditional monitoring, which often alerts teams after an issue has occurred, observability enables engineers to identify patterns and anomalies early.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;By tracking unusual behaviors or shifts in metrics, logs, or traces, teams can respond to signs of potential failures in real time, addressing issues before they escalate.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This&amp;nbsp;&lt;a href=&#34;https://middleware.io/blog/proactive-monitoring/&#34;&gt;proactive approach&lt;/a&gt;&amp;nbsp;improves system resilience, optimizes workflows, and ultimately helps maintain a smooth user experience by reducing downtime and preventing disruptions. Initiating the platform engineering journey by engaging with engineering teams to identify bottlenecks and developer frustrations is crucial for continuous improvement.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;challenges-observability-solves-for-platform-engineers&#34;&gt;Challenges Observability solves for Platform Engineers&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-managing-complexity&#34;&gt;Managing complexity&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;With systems becoming increasingly distributed, internal platform teams play a crucial role in maintaining a clear overview. Observability provides the necessary visibility to understand how different components interact and where issues may arise.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Reducing MTTD and MTTR&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Reducing Mean Time to Detect (MTTD) and Mean Time to Resolution (MTTR) is critical for minimizing downtime and improving user experience. A platform team plays a crucial role in these efforts by making operations easy and improving collaboration among different tech teams. Observability lowers MTTD by continuously monitoring for anomalies, enabling engineers to catch issues as they emerge. Once a problem is detected, observability tools provide detailed, actionable insights that accelerate MTTR. With relevant data readily available, teams can efficiently assess issue severity, identify impacted areas, and implement solutions.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For more on the benefits of reduced MTTD and MTTR, see&amp;nbsp;&lt;a href=&#34;https://middleware.io/blog/mttr-vs-mttd/&#34;&gt;MTTR vs MTTD&lt;/a&gt;&amp;nbsp;and&amp;nbsp;&lt;a href=&#34;https://middleware.io/blog/how-to-reduce-mttr/&#34;&gt;How to Reduce MTTR&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-faster-triage-and-root-cause-analysis&#34;&gt;Faster triage and root cause analysis&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;When issues arise, the ability to quickly diagnose and resolve them is crucial. Observability facilitates faster triage by correlating data from metrics, logs, and traces, giving engineers a comprehensive view of what happened, when, and why.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;With these insights, engineers can delve into specific events to identify the root cause, whether it’s a failing&amp;nbsp;&lt;a href=&#34;https://middleware.io/blog/api-monitoring/&#34;&gt;API&lt;/a&gt;, resource bottleneck, or misconfigured service. This efficient diagnostic approach leads to quicker resolutions and contributes to a more stable and resilient system.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The platform engineering team binds various tools, services, and APIs into a cohesive internal developer platform, creating well-organized processes that strengthen developer autonomy and efficiency.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;building-an-observability-framework-for-platform-engineers&#34;&gt;Building an Observability Framework for Platform Engineers&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-building-blocks&#34;&gt;Building blocks&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Effective observability in platform engineering revolves around three main components:&amp;nbsp;&lt;strong&gt;logging, metrics, and tracing&lt;/strong&gt;. Internal developer platforms (IDPs) play a crucial role in facilitating these components by organizing workflows and providing tools that make software development complexities easy. Together, these elements provide a holistic view of system performance and health, enabling engineers to monitor, diagnose, and improve infrastructure more effectively.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-top-tools&#34;&gt;Top Tools&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Various tools in the industry make implementing observability practical and efficient, often managed by internal platform teams. Some of the most popular tools include:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Middleware&lt;/strong&gt;: A full-stack cloud observability platform that empowers teams to optimize cloud operations, reduce downtime, and boost productivity with 100% ingestion control.&amp;nbsp;&lt;a href=&#34;https://middleware.io/&#34;&gt;Middleware&lt;/a&gt;&amp;nbsp;offers a comprehensive suite of observability tools, including infrastructure monitoring, log monitoring, APM,&amp;nbsp;&lt;a href=&#34;https://middleware.io/blog/llm-observability/&#34;&gt;LLM observability&lt;/a&gt;, database monitoring,&amp;nbsp;&lt;a href=&#34;https://middleware.io/blog/how-can-synthetic-monitoring-enhance-website-reliability/&#34;&gt;synthetic monitoring&lt;/a&gt;, serverless monitoring, container monitoring, and&amp;nbsp;&lt;a href=&#34;https://middleware.io/blog/what-is-real-user-monitoring/&#34;&gt;real user monitoring&lt;/a&gt;. With Middleware, teams can improve MTTR, expedite root cause analysis, and boost developer productivity while reducing observability costs by up to 10X.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://middleware.io/wp-content/uploads/2024/11/1.1-1024x581.jpg&#34; alt=&#34;Middleware&#34; class=&#34;wp-image-8355&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;DataDog&lt;/strong&gt;: A monitoring and analytics platform that provides real-time insights into application performance, infrastructure health, and user experience. With&amp;nbsp;&lt;a href=&#34;https://middleware.io/blog/datadog-pricing/&#34;&gt;DataDog&lt;/a&gt;, teams can track key metrics, monitor logs, and receive alerts and notifications.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;New Relic&lt;/strong&gt;: An observability platform that provides real-time insights into application performance, user experience, and infrastructure health. With&amp;nbsp;&lt;a href=&#34;https://middleware.io/blog/new-relic-pricing/&#34;&gt;New Relic&lt;/a&gt;, teams can monitor and troubleshoot their systems, and gain insights into customer behavior.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Prometheus&lt;/strong&gt;: An open-source monitoring system that specializes in collecting and querying metrics. With&amp;nbsp;&lt;a href=&#34;https://middleware.io/blog/what-is-prometheus/&#34;&gt;Prometheus&lt;/a&gt;, teams can set up time-series data collection and define custom metrics to track critical aspects of their applications.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Grafana&lt;/strong&gt;: Known for its interactive dashboards, Grafana enables visualization of metrics collected from various sources, including Prometheus. With&amp;nbsp;&lt;a href=&#34;https://middleware.io/blog/grafana-alternatives/&#34;&gt;Grafana&lt;/a&gt;, teams can set up real-time monitoring and build customized dashboards to visualize performance trends.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Jaeger&lt;/strong&gt;: A distributed tracing tool that helps track the path of a request as it flows through different services. Jaeger enables engineers to pinpoint latency sources and identify where service interactions could be optimized to reduce bottlenecks.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;By combining these tools, teams can monitor their systems more effectively, gaining the visibility needed to maintain performance and reliability.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-best-practices&#34;&gt;Best practices&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Implementing observability effectively involves more than just choosing the right tools. Here are some key practices to ensure a successful observability strategy:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Start with high-impact services&lt;/strong&gt;: Begin by implementing observability in key services where visibility is most impactful, then gradually expand coverage across other parts of the infrastructure.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Promote team-wide adoption&lt;/strong&gt;: Ensure everyone understands the importance of observability and how to use the tools. Conduct training sessions and foster a culture that values data-driven insights, as this will encourage consistent use and better understanding across teams.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Prioritize consistency and data quality&lt;/strong&gt;: Establish standardized formats for logs, metrics, and traces to ensure consistency. Consistent data makes it easier to correlate insights and helps maintain a clean, actionable dataset.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Iterate and improve&lt;/strong&gt;: Observability is not a one-time setup; it evolves with the system. Regularly review and refine your observability practices to keep up with changing infrastructure needs and optimize performance.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;With these practices, the platform engineering team can build an observability framework that not only monitors systems constructively but also permits platform engineering to create a stable and reliable foundation for applications.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;using-observability-to-drive-developer-productivity&#34;&gt;Using Observability to drive developer productivity&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-strengthen-self-service&#34;&gt;Strengthen self-service&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Observability provides developers with real-time visibility into system performance, enabling them to diagnose and resolve issues independently. This autonomy lessens reliance on central support and boosts productivity, aligning with platform engineering’s goal of minimizing operational bottlenecks. By tracing issues quickly, developers can make direct improvements, refine workflows, and reduce dependency on operations teams.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Serving internal customers, primarily app developers, is crucial in improving self-service capabilities. With access to metrics, logs, and traces, developers can:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Diagnose issues faster&lt;/strong&gt;: Observability data enables developers to pinpoint issues independently, whether it’s an API bottleneck, database slowdown, or configuration error.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Optimize workflows&lt;/strong&gt;: Real-time insights allow developers to monitor the impact of their code changes, facilitating immediate improvements and supporting platform stability.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Minimize disruptions&lt;/strong&gt;: Self-service observability speeds up issue identification and resolution, leading to fewer disruptions in productivity and increasing platform resilience.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Case Study: Trademarkia&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For many organizations, observability is a powerful enabler of developer self-sufficiency. Consider the experience of&amp;nbsp;&lt;a href=&#34;https://www.trademarkia.com/&#34;&gt;Trademarkia&lt;/a&gt;, a visual search engine for trademarks, which encountered significant hurdles with an outdated tech stack. Transitioning from .NET Core to a microservices-based architecture, the company needed a reliable observability solution to keep pace with its newly distributed infrastructure.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;By implementing Middleware’s observability platform, Trademarkia gained the real-time log monitoring and insight needed to optimize issue detection and resolution. With this observability framework in place, developers could diagnose and resolve issues independently, often within minutes rather than hours. This self-service capability not only accelerated debugging times but also reduced dependency on central support, enabling the team to focus on scaling and improving the platform.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Trademarkia’s move to observability also had a measurable impact: a 20% reduction in time to resolution, improved productivity, and proactive issue detection. This observability-driven approach to platform management allowed Trademarkia to offer users a smoother, more responsive experience, ultimately reinforcing the stability of the platform and freeing engineers to focus on strategic development. The company’s success highlights the importance of initiating the platform engineering journey by engaging with engineering teams to identify bottlenecks and developer frustrations.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Read more about Trademarkia’s observability journey&amp;nbsp;&lt;a href=&#34;https://middleware.io/customers/trademarkia/&#34;&gt;here&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;choosing-the-right-observability-strategy&#34;&gt;Choosing the right Observability strategy&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Choosing the right observability strategy is a decisive factor for strengthening platform performance and ensuring alignment with organizational needs. Here are five key strategies with a platform engineers focus:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Align with business objectives&lt;br&gt;&lt;/strong&gt;Ensure observability supports broader goals, like rapid incident response or improved user experience, making it a valuable asset that aligns with platform engineering’s purpose of building a responsive and resilient infrastructure.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Prioritize scalability&lt;br&gt;&lt;/strong&gt;Choose solutions that can scale with infrastructure, managing increased data volumes without performance degradation. This directly supports platform engineering’s aim of creating an adaptable and future-ready foundation.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Focus on usability&lt;br&gt;&lt;/strong&gt;Opt for intuitive tools that are accessible to all team members, encouraging adoption across development, operations, and platform engineering teams. Usability drives collaboration and fosters quicker issue resolutions, reinforcing a cohesive engineering strategy.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Ensure smooth integration&lt;br&gt;&lt;/strong&gt;Select tools that integrate well with your existing tech stack, enabling a continuous data flow and improving efficiency. Smooth integration aligns with platform engineering’s goal of reducing operational friction and enabling efficient workflows.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Balance cost and value&lt;br&gt;&lt;/strong&gt;Evaluate the investment against long-term benefits in reliability and productivity, ensuring observability remains cost-effective. This supports platform engineering by ensuring resources are used effectively to build a resilient and sustainable platform.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;things-to-avoid-in-observability&#34;&gt;Things to avoid in Observability&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;While observability is crucial, certain practices can hinder its effectiveness. By steering clear of these common pitfalls, platform engineering teams and the platform team can maintain clarity, reduce operational load, and reinforce platform resilience.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Avoid information overload&lt;/strong&gt;: Observability can produce large volumes of data that may overwhelm teams and obscure critical insights. By concentrating on key metrics, logs, and traces, platform engineering teams can ensure that only relevant data informs performance and issue resolution, helping maintain a responsive and resilient platform.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Maintain data hygiene&lt;/strong&gt;: Regularly reviewing and removing outdated or redundant data keeps observability dashboards clear and actionable. Consistently managing data quality allows platform engineers to troubleshoot effectively without the distraction of irrelevant information, reducing operational overhead.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Ensure consistency&lt;/strong&gt;: Standardizing data formats, naming conventions, and protocols across observability tools enable teams to interpret data accurately and fosters a unified approach across the organization. Consistent data practices also allow platform engineering teams to improve infrastructure efficiently, minimizing confusion or errors and reinforcing platform stability.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Starting with observability may seem challenging, but by focusing on key services and gradually expanding, teams can see substantial improvements.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As platform engineering evolves, software engineering organizations will find observability pivotal in maintaining resilient and reliable systems. Emerging trends like&amp;nbsp;&lt;a href=&#34;https://middleware.io/blog/how-generative-ai-can-transform-observability/&#34;&gt;AI-driven observability&lt;/a&gt;&amp;nbsp;offer promise for even greater insights and operational gains.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;博客文章最初由 Sri Krishna 在&lt;a href=&#34;https://middleware.io/blog/platform-engineering/&#34;&gt;中间件博客&lt;/a&gt;上发布&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在&lt;a href=&#34;https://middleware.io/blog/best-practices-to-avoid-website-outages-on-black-friday/&#34;&gt;黑色星期五的高风险环境&lt;/a &gt;，电子商务平台遇到剧烈的流量激增，可能会严重影响系统性能。例如，2023 年黑色星期五期间，在线销售额飙升至&lt;a href=&#34;https://www.yugabyte.com/blog/black-friday-sales-results/&#34;&gt;98 亿美元&lt;/a&gt;，增长 7.5%与上一年相比，突显了数字基础设施面临的巨大压力。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;尽管取得了这些成绩，但一些零售商仍经历了网站&lt;a href=&#34;https://analyticsindiamag.com/ai-origins-evolution/could-observability-help-prevent-another-crowdstrike-outage/&#34;&gt;停机&lt;/a &gt;，强调迫切需要可靠的平台工程实践，优先考虑内部客户的宝贵反馈。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;减轻此类风险的关键策略是将&lt;a href=&#34;https://middleware.io/blog/observability/&#34;&gt;可观察性&lt;/a&gt;集成到平台工程中。可观察性提供对系统行为的实时洞察，使团队能够在问题影响用户之前主动识别和解决问题。通过采用可观察性，平台工程团队可以提高系统弹性，在&lt;a href=&#34;https://middleware.io/customers/hotplate/&#34;&gt;高峰事件&lt;/a&gt;期间维持不间断的用户体验，并保持操作稳定性。&lt;/ p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;本文探讨了可观察性如何通过应对复杂的挑战、改进工作流程和增强系统可靠性来提升平台工程。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;understanding-platform-engineering&#34;&gt;了解平台工程&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;平台工程旨在创建一个稳定、可扩展的基础，以满足&lt;a href=&#34;https://middleware.io/blog/what-is-devops/&#34;&gt;开发和运营团队&lt;/a&gt;的需求。它不仅仅是管理&lt;a href=&#34;https://middleware.io/blog/what-is-infrastruct-monitoring/&#34;&gt;基础设施&lt;/a&gt;，还涉及构建共享工具、环境和工作流程，以改善协作并最大限度地减少开发团队的运营摩擦。通过提供标准化平台，平台工程可以实现更快、一致的应用程序部署，并使工程师能够专注于开发，而不会受到基础设施复杂性的困扰。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;平台工程中的角色（例如发布工程师、工具工程师和基础设施架构师）共同努力确保顺利部署、保持工具效率并设计可扩展的基础设施，这对于一致的平台工程策略至关重要。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-complexities&#34;&gt;复杂性&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;现代基础设施日益复杂且不断发展，带来了巨大的认知负荷和工程师面临的挑战。这种复杂性源于对各种工具和框架的需求，例如 &lt;a href=&#34;https://middleware.io/blog/kubernetes-monitoring/&#34;&gt;Kubernetes&lt;/a&gt; 用于&lt;a href=&#34;https:// middleware.io/blog/what-is-container-orchestration/&#34;&gt;容器编排&lt;/a&gt;、&lt;a href=&#34;https://middleware.io/blog/helm-chart-tutorial/&#34;&gt;Helm&lt;/a &gt; 对于应用程序部署、基础设施即代码的 Terraform 以及专门的监控系统。这些工具虽然功能强大，但必须协调工作，这需要仔细规划和配置。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://middleware.io/wp-content/uploads/2024/11/Platform-engg-1024x842.png&#34; alt= “了解平台工程和内部开发者平台” class=&#34;wp-image-8354&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;平台工程通过建立一个有凝聚力、可扩展的基础来解决这些复杂性，但它必须解决几个关键因素：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;分布式系统&lt;/strong&gt;：随着&lt;a href=&#34;https://middleware.io/blog/why-is-monitoring-your-application-important/&#34;&gt;应用&lt;/a&gt;规模的扩大，它们经常跨越多个服务器、云提供商或区域，形成复杂的互连网络。这些服务之间的可靠通信非常重要，因为即使是很小的中断也会波及整个系统。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;微服务&lt;/strong&gt;：将应用程序分解为更小的独立服务提供了灵活性，但也带来了依赖性管理、版本控制和服务发现等挑战，以确保每个&lt;a href=&#34;https://middleware.io/ blog/microservices-architecture-docker/&#34;&gt;微服务&lt;/a&gt; 与其他服务顺利连接。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;实时数据流&lt;/strong&gt;：许多应用依赖实时数据处理进行分析，&lt;a href=&#34;https://middleware.io/blog/how-can-you-enhance -user-satisfaction-with-rum/&#34;&gt;用户交互&lt;/a&gt;，或见解。高效处理这些数据流需要能够以最小延迟保持高吞吐量的基础设施。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;例如，在需求高峰期间扩展服务（例如电子商务销售）不仅需要可靠的基础设施，还需要自动化和监控来动态调整资源并实时防止出现瓶颈。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-infrastruct-management&#34;&gt;基础设施管理&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在平台工程中，有效的基础设施管理是维持支持开发和运营的可靠且可扩展的环境的关键。通过高效部署、&lt;a href=&#34;https://middleware.io/blog/observability-vs-monitoring/&#34;&gt;监控&lt;/a&gt;和基础设施管理，平台工程师建立了坚实的基础，可以适应不断变化的需求和改进了&lt;a href=&#34;https://middleware.io/blog/why-is-monitoring-your-application-important/&#34;&gt;应用程序性能&lt;/a&gt;。此外，这些实践通过提供集成工具和工作流程来支持开发人员自助服务，使开发人员能够自主管理其应用程序。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这涉及：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;自动化部署&lt;/strong&gt;以确保一致、快速的发布，最大限度地减少错误。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;监控关键指标的性能&lt;/strong&gt;，以便在问题影响用户之前检测并解决问题。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;根据需求动态扩展资源&lt;/strong&gt;，管理成本，同时确保系统在高峰时段做好准备。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这些基础设施管理实践共同支持平台工程的核心目标：构建一个弹性环境，使团队能够高效、可靠地交付应用程序。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;platform-engineering-vs.-devops-vs.-site-reliability-engineering-(sre)&#34;&gt;平台工程与 DevOps 与站点可靠性工程 (SRE) &lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;虽然平台工程、DevOps 和站点可靠性工程 (SRE) 都有助于改进软件交付，但各自侧重于流程的不同方面：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;平台工程&lt;/strong&gt;：平台工程专注于构建和维护核心基础设施和工具，为开发和运营奠定了可扩展的基础。平台工程师提供自助服务工具和环境，减少摩擦并使团队能够高效构建、测试和部署。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;DevOps&lt;/strong&gt;：DevOps 是一种促进开发和运营之间协作的文化方法。它旨在通过 CI/CD 等实践来优化工作流程、自动化流程并提高交付速度，促进团队之间的协调，以实现更快、更可靠的发布。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;网站可靠性工程 (SRE)&lt;/strong&gt;：SRE 由 Google 开发，将工程原理应用于运营，重点关注平衡可靠性和发布速度。 SRE 设定并维护服务级别目标 (SLO)、管理事件响应并使用错误预算来保持服务可靠性，同时支持稳定的发布速度。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;why-observability-is-needed-in-platform-engineering&#34;&gt;为什么平台工程需要可观察性&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-beyond-traditional-monitoring&#34;&gt;超越传统监控&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;传统监控侧重于跟踪已知指标、设置警报阈值以及在出现特定问题时对其做出响应。这使得它在很大程度上具有反应性，并且对于捕获高 CPU 使用率或内存消耗等即时问题非常有用。然而，在处理现代基础设施中复杂、相互依赖的系统时，监控的局限性就变得显而易见，孤立的指标很少能揭示全貌。&lt;/p&gt;&lt;p&gt;相比之下，可观察性是动态且主动的，使平台工程团队和软件开发人员能够全面了解系统交互。可观察性使工程师能够查询和探索跨服务的数据，而不是标记单个指标，从而深入了解单独监控可能会错过的关系和依赖关系。这种扩展的可见性使团队能够更有效地解决复杂问题，确保所有系统组件顺利稳定地协同工作。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-real-world-use-cases&#34;&gt;真实世界用例&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在微服务架构中，应用程序是由许多相互依赖的服务构建的，一个组件的速度减慢或故障可能会影响整个系统。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;例如，监控可能会突出显示面向用户的功能中的一般延迟，但可观察性工具可以跟踪特定服务的速度下降的根源。通过检查跟踪、指标和日志，平台工程师可以准确查明延迟的根源，无论是缓慢的数据库查询还是过载的 API。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;考虑这些用例：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;分布式系统中的延迟检测&lt;/strong&gt;：可观测性跟踪可以帮助跟踪用户请求的路径，准确识别服务序列中发生延迟的位置。如果支付服务导致结账流程延迟，可观察性将有助于查明瓶颈，而传统监控可能仅表明延迟增加，而没有上下文。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;跨服务的根本原因分析&lt;/strong&gt;：在复杂的架构中，一个微服务的故障可能会影响多个下游服务。可观察性将各个点连接起来，显示错误如何在系统中传播，并允许平台工程师将问题跟踪到特定的 API 调用、第三方集成或配置更改，而不是跨多个服务处理症状。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;主动异常检测&lt;/strong&gt;：可观察性还可以通过识别细微的变化（例如响应时间或错误率的逐渐增加）来及早检测性能问题。通过识别这些早期指标，平台工程师可以在事件升级之前采取纠正措施，从而保持系统稳定性和用户体验。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;通过可观察性，平台工程团队不仅可以维护一个响应迅速的平台，而且还可以维护一个有弹性的平台。它们获得识别、解决和预防问题所需的深度，提高整体系统可靠性，同时支持关键应用程序的平稳运行。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-the- Three-pillars-of-observability&#34;&gt;可观察性的三大支柱&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;可观察性依赖于三个基本组件，通常称为可观察性的“支柱”，它们共同提供系统健康状况的全面视图并执行恩斯：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;指标&lt;/strong&gt;：&lt;a href=&#34;https://middleware.io/product/metrics/&#34;&gt;指标&lt;/a&gt;是跟踪关键资源性能的定量数据点，例如CPU 使用率、内存消耗或请求率。指标提供系统运行状况的实时指标，帮助工程师识别趋势并快速响应任何异常情况。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;日志&lt;/strong&gt;：&lt;a href=&#34;https://middleware.io/product/log-monitoring/&#34;&gt;日志&lt;/a&gt;是整个系统事件的详细记录。它们捕获操作、错误和系统警告的时间顺序记录，提供特定事件发生的时间、地点和方式的上下文。日志对于追踪问题的根源非常重要，因为它们提供了有关系统状态的精确的带时间戳的信息。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;跟踪&lt;/strong&gt;：&lt;a href=&#34;https://middleware.io/product/distributed-tracing/&#34;&gt;跟踪&lt;/a&gt;遵循请求在不同组件中传输时的生命周期一个系统，从开始到结束。它们提供与请求交互的每个服务或功能的可视化地图，精确指出可能发生延迟或错误的位置。跟踪对于诊断分布式系统中的问题特别有用，因为它揭示了不同服务如何交互以及瓶颈可能位于何处。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;平台工程团队在实现这三个支柱方面发挥着至关重要的作用，使团队能够深入了解系统操作，从而了解各个组件及其在更广泛的基础设施中的交互。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-proactive-issue-resolution&#34;&gt;主动解决问题&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;可观察性最重要的优势之一是能够在潜在问题主动影响用户之前检测到它们。与传统监控（通常在问题发生后向团队发出警报）不同，可观察性使工程师能够及早识别模式和异常情况。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;通过跟踪异常行为或指标、日志或跟踪的变化，团队可以实时响应潜在故障的迹象，在问题升级之前解决问题。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这种&lt;a href=&#34;https://middleware.io/blog/proactive-monitoring/&#34;&gt;主动方法&lt;/a&gt;可提高系统弹性、优化工作流程，并通过减少停机时间和最终帮助保持流畅的用户体验。防止干扰。通过与工程团队合作来识别瓶颈和开发人员的挫败感来启动平台工程之旅对于持续改进至关重要。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;challenges-observability-solves-for-platform-engineers&#34;&gt;平台工程师面临的可观测性挑战&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-managing-complexity&#34;&gt;管理复杂性&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;随着系统变得越来越分散，内部平台团队在维护中发挥着至关重要的作用一个清晰的概述。可观察性提供了必要的可见性，以了解不同组件如何交互以及可能出现问题的位置。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;减少 MTTD 和 MTTR&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;减少平均检测时间 (MTTD) 和平均解决时间 (MTTR) 对于最大限度地减少停机时间和改善用户体验至关重要。平台团队通过简化操作并改善不同技术团队之间的协作，在这些工作中发挥着至关重要的作用。可观察性通过持续监控异常情况来降低 MTTD，使工程师能够在问题出现时发现问题。一旦检测到问题，可观测性工具就会提供详细的、可操作的见解，从而加速 MTTR。有了相关数据，团队就可以有效评估问题的严重性、确定受影响的区域并实施解决方案。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;有关缩短 MTTD 和 MTTR 的好处的更多信息，请参阅&lt;a href=&#34;https://middleware.io/blog/mttr-vs-mttd/&#34;&gt;MTTR 与 MTTD&lt;/a&gt; 和&lt;a href= “https://middleware.io/blog/how-to-reduce-mttr/&#34;&gt;如何减少 MTTR&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-faster-triage-and-root-cause-analysis&#34;&gt;更快的分类和根本原因分析&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;出现问题时，快速诊断和解决问题的能力至关重要。可观察性通过关联来自指标、日志和跟踪的数据来促进更快的分类，使工程师能够全面了解发生的情况、时间和原因。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;借助这些见解，工程师可以深入研究特定事件以确定根本原因，无论是失败的 &lt;a href=&#34;https://middleware.io/blog/api-monitoring/&#34;&gt;API&lt;/a&gt;，资源瓶颈或服务配置错误。这种高效的诊断方法可以更快地解决问题，并有助于打造更稳定、更有弹性的系统。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;平台工程团队将各种工具、服务和 API 绑定到一个有凝聚力的内部开发人员平台中，创建组织良好的流程，增强开发人员的自主权和效率。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;building-an-observability-framework-for-platform-engineers&#34;&gt;为平台工程师构建可观察性框架&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-building-blocks&#34;&gt;构建块&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;平台工程中的有效可观察性围绕三个主要组件：&lt;strong&gt;日志记录、指标和跟踪&lt;/strong&gt;。内部开发人员平台 (IDP) 通过组织工作流程和提供简化软件开发复杂性的工具，在促进这些组件的发展方面发挥着至关重要的作用。这些元素共同提供了系统性能和运行状况的整体视图，使工程师能够更有效地监控、诊断和改进基础设施。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-top-tools&#34;&gt;热门工具&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;行业中的各种工具使可观察性的实施变得实用且高效，通常由内部平台团队管理。我的一些最流行的工具包括：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;中间件&lt;/strong&gt;：全栈云可观测性平台，使团队能够通过 100% 的摄取控制来优化云运营、减少停机时间并提高生产力。 &lt;a href=&#34;https://middleware.io/&#34;&gt;中间件&lt;/a&gt;提供了一整套可观察性工具，包括基础设施监控、日志监控、APM、&lt;a href=&#34;https://middleware.io/ blog/llm-observability/&#34;&gt;LLM 可观察性&lt;/a&gt;，数据库监控，&lt;a href=&#34;https://middleware.io/blog/how-can-synthetic-monitoring-enhance-website-reliability/&#34;&gt;综合监控&lt;/a&gt;、无服务器监控、容器监控和&lt;a href=&#34;https: //middleware.io/blog/what-is-real-user-monitoring/&#34;&gt;真实用户监控&lt;/a&gt;。借助中间件，团队可以改进 MTTR、加快根本原因分析并提高开发人员的工作效率，同时将可观测性成本降低多达 10 倍。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://middleware.io/wp-content/uploads/2024/11/1.1-1024x581.jpg&#34; alt=&#34;中间件“class =“wp-image-8355”referrerpolicy =“no-referrer”&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;DataDog&lt;/strong&gt;：一个监控和分析平台，可提供有关应用程序性能、基础设施运行状况和用户体验的实时见解。借助 &lt;a href=&#34;https://middleware.io/blog/datadog-pricing/&#34;&gt;DataDog&lt;/a&gt;，团队可以跟踪关键指标、监控日志以及接收警报和通知。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;New Relic&lt;/strong&gt;：一个可观察平台，可提供有关应用性能、用户体验和基础设施运行状况的实时洞察。借助 &lt;a href=&#34;https://middleware.io/blog/new-relic-pricing/&#34;&gt;New Relic&lt;/a&gt;，团队可以监控系统并排除故障，并深入了解客户行为。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Prometheus&lt;/strong&gt;：一个专门收集和查询指标的开源监控系统。借助 &lt;a href=&#34;https://middleware.io/blog/what-is-prometheus/&#34;&gt;Prometheus&lt;/a&gt;，团队可以设置时间序列数据收集并定义自定义指标来跟踪其应用程序的关键方面.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Grafana&lt;/strong&gt;：Grafana 以其交互式仪表板而闻名，它可以对从各种来源（包括 Prometheus）收集的指标进行可视化。借助 &lt;a href=&#34;https://middleware.io/blog/grafana-alternatives/&#34;&gt;Grafana&lt;/a&gt;，团队可以设置实时监控并构建自定义仪表板以可视化性能趋势。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Jaeger&lt;/strong&gt;：一种分布式跟踪工具，可帮助跟踪请求流经不同服务时的路径。 Jaeger 使工程师能够查明延迟源并确定可以优化服务交互的位置以减少瓶颈。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;通过组合这些工具，团队可以更有效地监控其系统，获得维持性能和可靠性所需的可见性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3class=&#34;wp-block-heading&#34; id=&#34;h-best-practices&#34;&gt;最佳实践&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;有效地实现可观察性不仅仅涉及选择正确的工具。以下是确保可观察性策略成功的一些关键实践：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;从高影响力的服务开始&lt;/strong&gt;：首先在可见性最具影响力的关键服务中实现可观察性，然后逐步扩大基础设施其他部分的覆盖范围。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;促进团队范围内的采用&lt;/strong&gt;：确保每个人都了解可观察性的重要性以及如何使用这些工具。举办培训课程并培养重视数据驱动见解的文化，因为这将鼓励团队之间的一致使用和更好的理解。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;优先考虑一致性和数据质量&lt;/strong&gt;：建立日志、指标和跟踪的标准化格式以确保一致性。一致的数据可以更轻松地关联见解，并有助于维护干净、可操作的数据集。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;迭代和改进&lt;/strong&gt;：可观察性不是一次性设置；它随着系统的发展而发展。定期审查和完善您的可观察性实践，以跟上不断变化的基础设施需求并优化性能。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;通过这些实践，平台工程团队可以构建一个可观察性框架，该框架不仅能够建设性地监控系统，而且还允许平台工程为应用程序创建稳定可靠的基础。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;using-observability-to-drive-developer-productivity&#34;&gt;使用可观察性提高开发人员生产力&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-strengthen-self-service&#34;&gt;加强自助服务&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;可观察性为开发人员提供了系统性能的实时可见性，使他们能够独立诊断和解决问题。这种自主权减少了对中央支持的依赖并提高了生产力，符合平台工程最小化运营瓶颈的目标。通过快速跟踪问题，开发人员可以直接改进、完善工作流程并减少对运营团队的依赖。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;为内部客户（主要是应用开发人员）提供服务对于提高自助服务能力至关重要。通过访问指标、日志和跟踪，开发人员可以：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;更快地诊断问题&lt;/strong&gt;：可观测性数据使开发人员能够独立查明问题，无论是 API 瓶颈、数据库速度减慢还是配置错误。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;优化工作流程&lt;/strong&gt;：实时洞察让开发者能够监控代码更改的影响，促进即时改进并支持平台稳定性。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;最大限度地减少干扰&lt;/strong&gt;：自助服务可观察性可加快问题识别和解决速度，从而减少对生产力的干扰并提高工作效率提高平台弹性。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;案例研究：Trademarkia&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;对于许多组织来说，可观察性是开发人员自给自足的强大推动者。考虑一下 &lt;a href=&#34;https://www.trademarkia.com/&#34;&gt;Trademarkia&lt;/a&gt; 的经历，这是一个商标视觉搜索引擎，它遇到了过时的技术堆栈的重大障碍。从 .NET Core 过渡到基于微服务的架构时，该公司需要一个可靠的可观测性解决方案来跟上其新的分布式基础架构的步伐。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;通过实施 Middleware 的可观察性平台，Trademarkia 获得了优化问题检测和解决所需的实时日志监控和洞察力。有了这个可观察性框架，开发人员就可以独立诊断和解决问题，通常只需几分钟而不是几小时。这种自助服务功能不仅加快了调试时间，还减少了对中央支持的依赖，使团队能够专注于扩展和改进平台。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Trademarkia 转向可观察性还产生了可衡量的影响：解决问题的时间缩短了 20%，提高了生产力，并主动检测问题。这种可观察性驱动的平台管理方法使 Trademarkia 能够为用户提供更流畅、响应更灵敏的体验，最终增强平台的稳定性，并使工程师能够专注于战略开发。该公司的成功凸显了通过与工程团队合作来识别瓶颈和开发人员挫败感来启动平台工程之旅的重要性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;在&lt;a href=&#34;https://middleware.io/customers/trademarkia/&#34;&gt;此处&lt;/a&gt;详细了解 Trademarkia 的可观察性之旅。&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;choosing-the-right-observability-strategy&#34;&gt;选择正确的可观察性策略&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;选择正确的可观察性策略是增强平台性能并确保符合组织需求的决定性因素。以下是平台工程师关注的五个关键策略：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;&lt;strong&gt;与业务目标保持一致&lt;br&gt;&lt;/strong&gt;确保可观测性支持更广泛的目标，例如快速事件响应或改进的用户体验，使其成为宝贵的资产，符合平台工程构建响应迅速且有弹性的基础设施的目的.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;优先考虑可扩展性&lt;br&gt;&lt;/strong&gt;选择可随基础架构扩展的解决方案，管理增加的数据量而不降低性能。这直接支持了平台工程创建适应性强、面向未来的基础的目标。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;注重可用性&lt;br&gt;&lt;/strong&gt;选择所有团队成员都可以使用的直观工具，鼓励开发、运营和平台工程团队采用。可用性推动协作并促进更快地解决问题，加强有凝聚力的工程策略。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;确保顺利集成&lt;br&gt;&lt;/strong&gt;选择与您现有技术堆栈良好集成的工具，从而实现连续的数据流并提高效率。平稳集成符合平台工程减少操作摩擦和实现高效工作流程的目标。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;平衡成本和价值&lt;br&gt;&lt;/strong&gt;根据可靠性和生产力方面的长期效益评估投资，确保可观测性保持成本效益。这通过确保有效利用资源来构建有弹性和可持续的平台来支持平台工程。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;things-to-avoid-in-observability&#34;&gt;可观察性中要避免的事情&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;虽然可观察性至关重要，但某些做法可能会阻碍其有效性。通过避开这些常见陷阱，平台工程团队和平台团队可以保持清晰度、减少运营负载并增强平台弹性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;避免信息过载&lt;/strong&gt;：可观察性会产生大量数据，这些数据可能会让团队不堪重负并掩盖关键见解。通过专注于关键指标、日志和跟踪，平台工程团队可以确保只有相关数据才能提供性能和问题解决方案，从而帮助维护一个响应迅速且具有弹性的平台。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;保持数据卫生&lt;/strong&gt;：定期检查并删除过时或冗余的数据，使可观察性仪表板保持清晰且可操作。持续管理数据质量使平台工程师能够有效地排除故障，而不会受到无关信息的干扰，从而降低运营开销。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;确保一致性&lt;/strong&gt;：跨可观测性工具标准化数据格式、命名约定和协议使团队能够准确解读数据，并在整个组织内形成统一的方法。一致的数据实践还使平台工程团队能够有效改进基础设施，最大限度地减少混乱或错误并增强平台稳定性。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;conclusion&#34;&gt;结论&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;从可观察性开始可能看起来具有挑战性，但通过专注于关键服务并逐步扩展，团队可以看到实质性的改进。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;随着平台工程的发展，软件工程组织将发现可观察性对于维护弹性和可靠的系统至关重要。 &lt;a href=&#34;https://middleware.io/blog/how-generative-ai-can-transform-observability/&#34;&gt;人工智能驱动的可观察性&lt;/a&gt;等新兴趋势有望带来更深入的见解和运营收益。 &lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/分区&gt;</description>
      <pubDate>Sun, 15 Dec 2024 16:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>