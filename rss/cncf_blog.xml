<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>CNCF - Blog</title>
    <link>http://rsshub.rssforever.com/cncf</link>
    <description>CNCF - Blog - Powered by RSSHub</description>
    <managingEditor>contact@rsshub.app (RSSHub)</managingEditor>
    <item>
      <title>【Kubestronaut in Orbit: Eyal Zekaria】在轨道上的 Kubetronaut：Eyal Zekaria</title>
      <link>https://www.cncf.io/blog/2024/12/03/kubestronaut-in-orbit-eyal-zekaria/</link>
      <description>【&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1650&#34; height=&#34;866&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/12/Kubestronaut-in-Orbit-11.jpg&#34; alt=&#34;kubestronaut&#34; class=&#34;wp-image-121766&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/12/Kubestronaut-in-Orbit-11.jpg 1650w, https://www.cncf.io/wp-content/uploads/2024/12/Kubestronaut-in-Orbit-11-300x157.jpg 300w, https://www.cncf.io/wp-content/uploads/2024/12/Kubestronaut-in-Orbit-11-1024x537.jpg 1024w, https://www.cncf.io/wp-content/uploads/2024/12/Kubestronaut-in-Orbit-11-768x403.jpg 768w, https://www.cncf.io/wp-content/uploads/2024/12/Kubestronaut-in-Orbit-11-194x102.jpg 194w, https://www.cncf.io/wp-content/uploads/2024/12/Kubestronaut-in-Orbit-11-388x204.jpg 388w, https://www.cncf.io/wp-content/uploads/2024/12/Kubestronaut-in-Orbit-11-776x408.jpg 776w, https://www.cncf.io/wp-content/uploads/2024/12/Kubestronaut-in-Orbit-11-1552x816.jpg 1552w, https://www.cncf.io/wp-content/uploads/2024/12/Kubestronaut-in-Orbit-11-900x472.jpg 900w, https://www.cncf.io/wp-content/uploads/2024/12/Kubestronaut-in-Orbit-11-381x200.jpg 381w, https://www.cncf.io/wp-content/uploads/2024/12/Kubestronaut-in-Orbit-11-762x400.jpg 762w, https://www.cncf.io/wp-content/uploads/2024/12/Kubestronaut-in-Orbit-11-590x310.jpg 590w, https://www.cncf.io/wp-content/uploads/2024/12/Kubestronaut-in-Orbit-11-1180x620.jpg 1180w&#34; sizes=&#34;auto, (max-width: 1650px) 100vw, 1650px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Get to know Eyal&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This week’s Kubestronaut in Orbit, Eyal Zekaria is a Senior Cloud Architect in Berlin, Germany. Eyal has a DevOps and SRE background and has experience operating Kubernetes clusters at scale at different cloud providers. In his current role he helps other companies in their cloud journey. Outside of Kubernetes, Eyal is also interested in automation and open source software.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you’d like to be a Kubestronaut like Eyal, get more details on the CNCF Kubestronaut page.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;When did you get started with Kubernetes and/or cloud-native? What was your first project?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The company I worked for in 2017 was using Mesos/Marathon to run their microservices — after evaluating Kubernetes, we started moving services over one by one.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;What are the primary CNCF projects you work on or use today?&amp;nbsp; What projects have you enjoyed the most in your career?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Besides the components that are built into Kubernetes, I think that &lt;a href=&#34;https://www.cncf.io/projects/cert-manager/&#34;&gt;cert-manager&lt;/a&gt;, &lt;a href=&#34;https://www.cncf.io/projects/open-policy-agent-opa/&#34;&gt;Open Policy Agent (OPA)&lt;/a&gt;, and &lt;a href=&#34;https://www.cncf.io/projects/prometheus/&#34;&gt;Prometheus&lt;/a&gt; are the ones I like the most.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;How have the certs or CNCF helped you in your career?&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Getting the certifications helped me bridge gaps in my knowledge. My experience has been predominantly using managed Kubernetes services where many aspects are taken out of your control for the sake of convenience – which is great, but it can also be detrimental when trying to understand how things work internally.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;What are some other books/sites/courses you recommend for people who want to work with k8s?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“&lt;a href=&#34;https://github.com/kelseyhightower/kubernetes-the-hard-way&#34;&gt;Kubernetes the Hard Way&lt;/a&gt;” by Kelsey Hightower is awesome, as well as anything by Kelsey, but I find the preparation for all Kubernetes-related CNCF certifications very useful as well.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;What do you do in your free time?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Play tennis, or any other racket sports.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;What would you tell someone who is just starting their K8s certification journey? Any tips or tricks?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Create a sandbox cluster and start getting comfortable interacting with it. Break it, fix it, enable and disable different features.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Then start experimenting with running workloads in it, including all the involved aspects.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“1650”高度=“866”src=“https://www.cncf.io/ wp-content/uploads/2024/12/Kubestronaut-in-Orbit-11.jpg&#34; alt=&#34;kubestronaut&#34; class=&#34;wp-image-121766&#34; srcset =“https://www.cncf.io/wp-content/uploads/2024/12/Kubestronaut-in-Orbit-11.jpg 1650w，https://www.cncf.io/wp-content/uploads/ 2024/12/Kubestronaut-in-Orbit-11-300x157.jpg 300w, https://www.cncf.io/wp-content/uploads/2024/12/Kubestronaut-in-Orbit-11-1024x537.jpg 1024w，https://www.cncf.io/wp-content/uploads/2024 /12/Kubestronaut-in-Orbit-11-768x403.jpg 768w, https://www.cncf.io/wp-content/uploads/2024/12/Kubestronaut-in-Orbit-11-194x102.jpg 194w，https://www.cncf.io/wp-content/uploads/2024 /12/Kubestronaut-in-Orbit-11-388x204.jpg 388w, https://www.cncf.io/wp-content/uploads/2024/12/Kubestronaut-in-Orbit-11-776x408.jpg 776w，https://www.cncf.io/wp-content/uploads/2024 /12/Kubestronaut-in-Orbit-11-1552x816.jpg 1552w, https://www.cncf.io/wp-content/uploads/2024/12/Kubestronaut-in-Orbit-11-900x472.jpg 900w，https://www.cncf.io/wp-content/uploads/2024 /12/Kubestronaut-in-Orbit-11-381x200.jpg 381w, https://www.cncf.io/wp-content/uploads/2024/12/Kubestronaut-in-Orbit-11-762x400.jpg 762w，https://www.cncf.io/wp-content/uploads/2024 /12/Kubestronaut-in-Orbit-11-590x310.jpg 590w, https://www.cncf.io/wp-content/uploads/2024/12/Kubestronaut-in-Orbit-11-1180x620.jpg 1180w“尺寸=”自动，（最大宽度：1650px）100vw，1650px“引用策略=&#34;无引荐&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;了解埃亚尔&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;本周的 Kubetronaut in Orbit，Eyal Zekaria 是德国柏林的高级云架构师。 Eyal 拥有 DevOps 和 SRE 背景，并且拥有在不同云提供商大规模运营 Kubernetes 集群的经验。在目前的职位上，他帮助其他公司开展云之旅。除了 Kubernetes 之外，Eyal 还对自动化和开源软件感兴趣。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您想成为像 Eyal 一样的 Kubetronaut，请在 CNCF Kubetronaut 页面上获取更多详细信息。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;您什么时候开始使用 Kubernetes 和/或云原生？您的第一个项目是什么？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我在 2017 年工作的公司正在使用 Mesos/Marathon 来运行他们的微服务 - 在评估 Kubernetes 后，我们开始一项一项地迁移服务。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;您现在从事或使用的主要 CNCF 项目是什么？  在您的职业生涯中，您最喜欢哪些项目？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;除了 Kubernetes 内置的组件之外，我认为 &lt;a href=&#34;https://www.cncf.io/projects/cert-manager/&#34;&gt;cert-manager&lt;/a&gt;、&lt;a href= “https://www.cncf.io/projects/open-policy-agent-opa/&#34;&gt;开放策略代理 (OPA)&lt;/a&gt; 和 &lt;a href=&#34;https://www.cncf.io/项目/普罗米修斯/&#34;&gt;普罗米修斯&lt;/a&gt;是我最喜欢的。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;证书或 CNCF 对您的职业生涯有何帮助？ &lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;获得认证帮助我弥补了知识上的差距。我的经验是predom为了方便起见，使用托管 Kubernetes 服务，许多方面都脱离了您的控制——这很好，但在尝试了解事物内部如何工作时也可能是有害的。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;您为想要使用 k8s 的人推荐了哪些其他书籍/网站/课程？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kelsey Hightower 的“&lt;a href=&#34;https://github.com/kelseyhightower/kubernetes-the-hard-way&#34;&gt;Kubernetes the Hard Way&lt;/a&gt;”非常棒，还有 Kelsey 的任何内容，但我发现所有与 Kubernetes 相关的 CNCF 认证的准备工作也非常有用。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;你空闲时间做什么？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;打网球或任何其他球拍运动。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;您会对刚刚开始 K8s 认证之旅的人说些什么？有什么提示或技巧吗？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;创建一个沙箱集群并开始舒适地与之交互。打破它、修复它、启用和禁用不同的功能。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;然后开始尝试在其中运行工作负载，包括所有涉及的方面。&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Mon, 02 Dec 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Kubernetes for databases: weighing the pros and cons】用于数据库的 Kubernetes：权衡利弊</title>
      <link>https://www.cncf.io/blog/2024/11/27/kubernetes-for-databases-weighing-the-pros-and-cons/</link>
      <description>【&lt;p&gt;&lt;em&gt;Member post originally published on &lt;a href=&#34;https://thenewstack.io/kubernetes-for-databases-weighing-the-pros-and-cons/&#34;&gt;The New Stack&lt;/a&gt; by Kate Obiidykhata&lt;/em&gt;, &lt;em&gt;Percona&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Over the past few decades,&amp;nbsp;&lt;a href=&#34;https://thenewstack.io/databases/&#34;&gt;database&lt;/a&gt;&amp;nbsp;management has shifted from traditional relational databases on monolithic hardware to cloud native, distributed environments. With the rise of microservices and containerization, modern databases need to fit seamlessly into more complex, dynamic systems, requiring advanced solutions to balance scale, performance and flexibility.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For large organizations navigating these complex environments, managing databases at scale presents myriad challenges. Companies with extensive&amp;nbsp;&lt;a href=&#34;https://thenewstack.io/data/&#34;&gt;data&lt;/a&gt;&amp;nbsp;operations often face issues like ensuring high availability, disaster recovery and scaling resources efficiently. To tackle these, many adopt a hybrid approach, combining on-premises infrastructure with cloud resources to meet their diverse needs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;A natural result of this hybrid model is the push toward standardization. By consolidating various components, including databases, onto a unified infrastructure platform, organizations aim to reduce operational overhead and improve consistency across different environments, streamlining their overall operations.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Why Kubernetes Is Gaining Traction for Databases&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As&amp;nbsp;&lt;a href=&#34;https://thenewstack.io/kubernetes/&#34;&gt;Kubernetes&lt;/a&gt;&amp;nbsp;has become the default infrastructure layer for many enterprises, running databases on Kubernetes is becoming more prevalent. Initially, there was skepticism about Kubernetes’ suitability for database workloads. However, this has changed as&amp;nbsp;&lt;a href=&#34;https://roadmap.sh/kubernetes&#34;&gt;Kubernetes has matured&lt;/a&gt;&amp;nbsp;and the community has developed tools and best practices for managing&amp;nbsp;&lt;a href=&#34;https://thenewstack.io/how-to-better-manage-stateful-applications-in-kubernetes/&#34;&gt;stateful applications&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For platform engineers, Kubernetes offers a robust framework to build internal database management platforms. This approach allows for custom solutions tailored to specific organizational needs, such as automated provisioning and integration with existing CI/CD pipelines.&lt;a href=&#34;https://www.percona.com/?utm_content=sponsor+module&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Benefits of Running Databases on Kubernetes&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Standardization&lt;/strong&gt;: Kubernetes provides a unified platform for managing databases and applications across on-premises and cloud environments.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Self-service&lt;/strong&gt;: Developers and teams can provision and manage databases through self-service, streamlining operations.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Scalability&lt;/strong&gt;: Kubernetes supports elastic scaling, allowing databases to handle varying workloads seamlessly.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Resilience&lt;/strong&gt;: Built-in features like failover and recovery increase the reliability of databases running on Kubernetes.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Overcoming the Challenges of Kubernetes for Databases&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Despite the benefits, managing databases on Kubernetes introduces complexities. These include maintaining stateful applications, ensuring data consistency and integrating with existing infrastructure.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Fortunately, the Kubernetes ecosystem has responded with tools like operators, which simplify the management of stateful applications by automating common tasks such as backups, scaling and updates.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Key approaches to database management on Kubernetes include:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Hyperscalers or public database as a service (DBaaS) providers&lt;/strong&gt;: These services are easy to use but often come with&amp;nbsp;&lt;a href=&#34;https://thenewstack.io/the-hidden-cost-of-dbaass-convenience/&#34;&gt;higher costs&lt;/a&gt;, hidden fees, limited customization and potential vendor lock-in.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Proprietary or private DBaaS solutions&lt;/strong&gt;: While less expensive than hyperscalers and requiring fewer internal resources, these solutions can still result in lock-in and may grow more costly as data scales.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Building an internal platform&lt;/strong&gt;: This option offers maximum control and eliminates vendor lock-in but requires significant internal expertise and maintenance, as well as careful management of included components like:&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Operators&lt;/strong&gt;: Kubernetes operators play a crucial role in managing database instances by automating common tasks such as backups, scaling and updates.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Monitoring and troubleshooting&lt;/strong&gt;: Effective monitoring and troubleshooting tools are essential for managing the health and performance of databases running on Kubernetes.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;The Future of Database Management&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The shift towards Kubernetes and the evolution of open source tools have redefined how enterprises manage databases. Open source&amp;nbsp;&lt;a href=&#34;https://www.percona.com/software/percona-everest&#34;&gt;Percona Everest&lt;/a&gt;&amp;nbsp;addresses many of these challenges by automating database provisioning and management across any Kubernetes infrastructure, whether deployed in the cloud or on premises.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For enterprises seeking a flexible, scalable and cost-effective database solution, Percona Everest presents a compelling alternative to traditional database management strategies.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;成员帖子最初发布于&lt;a href=&#34;https://thenewstack.io/kubernetes-for-databases-weighing-the-pros-and-cons/&#34;&gt;新堆栈&lt;/a&gt;，作者： Kate Obiidykhata&lt;/em&gt;、&lt;em&gt;Percona&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在过去的几十年里，&lt;a href=&#34;https://thenewstack.io/databases/&#34;&gt;数据库&lt;/a&gt;管理已从单一硬件上的传统关系数据库转向云原生分布式环境。随着微服务和容器化的兴起，现代数据库需要无缝地融入更复杂、动态的系统，需要先进的解决方案来平衡规模、性能和灵活性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;对于在这些复杂环境中航行的大型组织来说，大规模管理数据库面临着无数的挑战。拥有大量&lt;a href=&#34;https://thenewstack.io/data/&#34;&gt;数据&lt;/a&gt;运营的公司经常面临确保高可用性、灾难恢复和有效扩展资源等问题。为了解决这些问题，许多公司采用混合方法，将本地基础设施与云资源相结合，以满足他们的多样化需求。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这种混合模式的自然结果是推动标准化。通过将包括数据库在内的各种组件整合到统一的基础设施平台上，组织的目标是减少运营开销并提高不同环境之间的一致性，从而简化其整体运营。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;为什么 Kubernetes 正在获得数据库的青睐&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;随着 &lt;a href=&#34;https://thenewstack.io/kubernetes/&#34;&gt;Kubernetes&lt;/a&gt; 已成为许多企业的默认基础架构层，在 Kubernetes 上运行数据库变得越来越普遍。最初，人们对 Kubernetes 是否适合数据库工作负载持怀疑态度。然而，随着 &lt;a href=&#34;https://roadmap.sh/kubernetes&#34;&gt;Kubernetes 的成熟&lt;/a&gt;，并且社区开发了用于管理的工具和最佳实践&lt;a href=&#34;https://thenewstack .io/how-to-better-manage-stateful-applications-in-kubernetes/&#34;&gt;有状态应用程序&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;对于平台工程师来说，Kubernetes 提供了一个强大的框架来构建内部数据库管理平台。这种方法允许根据特定组织需求定制定制解决方案，例如自动配置以及与现有 CI/CD 管道集成。&lt;a href=&#34;https://www.percona.com/?utm_content=sponsor+module&#34; target=&#34; _blank&#34; rel=&#34;noreferrer noopener&#34;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;在 Kubernetes 上运行数据库的好处&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;标准化&lt;/strong&gt;：Kubernetes 提供了一个统一的平台，用于跨本地和云环境管理数据库和应用程序。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;自助服务&lt;/strong&gt;：开发人员和团队可以通过自助服务配置和管理数据库，从而简化操作。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;可扩展性&lt;/strong&gt;：Kubernetes支持弹性伸缩，允许数据库无缝处理不同的工作负载。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;弹性&lt;/strong&gt;：故障转移和恢复等内置功能提高了 Kubernetes 上运行的数据库的可靠性。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;克服 Kubernetes 对数据库的挑战&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;尽管有这些好处，但在 Kubernetes 上管理数据库却带来了复杂性。其中包括维护有状态的应用程序、确保数据一致性以及与现有基础设施集成。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;幸运的是，Kubernetes 生态系统已经推出了 Operator 等工具，这些工具通过自动执行备份、扩展和更新等常见任务来简化有状态应用程序的管理。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes 上数据库管理的主要方法包括：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;超大规模企业或公共数据库即服务 (DBaaS) 提供商&lt;/strong&gt;：这些服务易于使用，但通常附带&lt;a href=&#34;https://thenewstack.io/the-hidden-cost -of-dbaass-convenience/&#34;&gt;更高的成本&lt;/a&gt;、隐性费用、有限的定制和潜在的供应商锁定。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;专有或私有 DBaaS 解决方案&lt;/strong&gt;：虽然比超大规模提供商便宜且需要的内部资源较少，但这些解决方案仍然可能导致锁定，并且随着数据规模的扩大，成本可能会更高。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;构建内部平台&lt;/strong&gt;：此选项可提供最大程度的控制并消除供应商锁定，但需要大量的内部专业知识和维护，以及对所包含组件的仔细管理，例如：&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;操作员&lt;/strong&gt;：Kubernetes 操作员通过自动执行备份、扩展和更新等常见任务，在管理数据库实例方面发挥着至关重要的作用。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;监控和故障排除&lt;/strong&gt;：有效的监控和故障排除工具对于管理 Kubernetes 上运行的数据库的运行状况和性能至关重要。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;数据库管理的未来&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;向 Kubernetes 的转变和开源工具的发展重新定义了企业管理数据库的方式。开源 &lt;a href=&#34;https://www.percona.com/software/percona-everest&#34;&gt;Percona Everest&lt;/a&gt; 通过跨任何 Kubernetes 基础设施（无论是部署在云端或本地。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;对于寻求灵活、可扩展且经济高效的数据库解决方案的企业来说，Percona Everest 提供了传统数据库管理策略的引人注目的替代方案。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Tue, 26 Nov 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Top 6 cloud computing trends for 2025】2025 年 6 大云计算趋势</title>
      <link>https://www.cncf.io/blog/2024/12/03/top-6-cloud-computing-trends-for-2025/</link>
      <description>【&lt;p&gt;&lt;em&gt;Member post by&lt;/em&gt;&lt;strong&gt; &lt;/strong&gt;&lt;em&gt;Sameer Danave, Senior Director of Marketing, MSys Technologies&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;I’m excited about our new project but overwhelmed by all the technological changes,” &lt;/em&gt;one of our solution architects shared in an MSys Slack channel before dropping a dozen links to the latest AI advancements. He’s a seasoned tech veteran who might need a hug. And who could blame him? Even in an industry used to rapid evolution, where new technologies emerge almost every quarter, AI is accelerating change at unprecedented rates. AI-powered cloud scalability, next-gen tools and platforms, and edge computing advancements stretch everyone’s capacity to keep up.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To clarify this whirlwind, I spoke with technology professionals at MSys Technologies and worldwide to uncover the latest cloud computing trends—AI-focused and beyond. This blog is here to keep you up to date on the essentials. So dive in and explore what’s next in cloud computing!&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;1. AI-Powered Cloud: AI as the Core of Cloud Transformation&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;AI has transformed multiple industries, and cloud computing is no exception. In 2025, AI won’t just be another service running in the cloud—it will be the intelligent force optimizing every aspect of cloud operations. From real-time resource allocation and automated scaling to intelligent systems countering threats, AI will play a pivotal role in reshaping the cloud landscape. Businesses that embrace this paradigm shift stand to reap extraordinary rewards: unparalleled efficiency, dramatic cost reductions, and performance levels once thought unattainable.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;2. Edge-to-Cloud AI Integration: Bridging the Gap for Seamless Computing&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The future of AI lies in the seamless integration of edge and cloud computing. In 2025, AI workloads will dynamically shift between the edge and the cloud, leveraging each search’s unique strengths. The cloud will handle training for complex AI models, while the edge will manage real-time inferencing, ensuring rapid responses. Next-generation edge platforms will support end-to-end automation, delivering comprehensive solutions across multi-cloud and edge environments.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;3. Hybrid and Multi-Cloud Strategies: The Enterprise Favorites for Flexibility&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Enterprises worldwide are already adopting hybrid and multi-cloud strategies—for good reason. By blending public cloud services from various providers, companies in 2025 will continue to boost flexibility while avoiding vendor lock-in. Hybrid cloud solutions elevate data storage management, enabling organizations to maximize existing infrastructure while seamlessly integrating public and private clouds. This approach results in scalable, secure, and redundant systems that enhance storage, improve disaster recovery, bolster data security, and keep businesses agile in a rapidly evolving landscape.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;4. Serverless Computing: Streamlining Infrastructure for Scalable Solutions&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Serverless computing is transforming how software services are built and deployed, reducing the need for infrastructure management. It enables developers to easily deploy code without concerns about underlying infrastructure. This has several benefits, including faster time-to-market, scalability, and lower costs for new service deployments. Given these advantages, serverless computing will see widespread adoption among enterprises globally in the coming years.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;5. Quantum Computing as a Service: Mainstreaming Quantum through the Cloud&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Quantum computing is beginning to find real-world applications. In 2025, it will step out of the lab and into mainstream business—not through costly hardware investments but via cloud services. Industry giants like IBM, Google, Microsoft, and Amazon are democratizing access to this technology, making quantum capabilities accessible to organizations of all sizes. The potential impacts are profound: from breakthrough drug discoveries to unbreakable encryption, quantum cloud services will unlock innovations previously deemed impossible.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;6. DevEdgeOps: Adopting DevOps for the Edge Computing Era&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Edge computing is transforming how data is being processed and utilized. Unlike traditional cloud methods, edge computing brings computational power directly to the data source. However, traditional DevOps practices, highly effective in cloud-centric environments, need adaptation for the edge. The “one-size-fits-all” approach can’t tackle the unique challenges of edge computing—such as scale, connectivity, security, and diverse devices. Enter DevEdgeOps: a specialized approach that combines the agility and automation of DevOps with the specific requirements of edge environments. This approach bridges the gap, enabling organizations to manage the complexities of edge computing with the same efficiency and speed that DevOps brings to the cloud.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Embracing the Future of Cloud Computing&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The cloud computing landscape 2025 is defined by innovation—AI-powered optimization, seamless edge-to-cloud integration, hybrid strategies, serverless scalability, and quantum breakthroughs. These trends aren’t just reshaping the cloud but transforming how businesses operate and innovate. At &lt;a href=&#34;https://www.msystechnologies.com/&#34;&gt;MSys Technologies&lt;/a&gt;, we specialize in delivering cutting-edge cloud services and solutions tailored to your needs. From strategy to execution, we help businesses stay ahead in this dynamic landscape. The opportunities are immense, and the future of cloud computing is here. Let MSys Technologies &lt;a href=&#34;https://www.msystechnologies.com/contact-us/&#34;&gt;guide you&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;会员帖子&lt;/em&gt;&lt;strong&gt; &lt;/strong&gt;&lt;em&gt;MSys Technologies 高级营销总监 Sameer Danave&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;我对我们的新项目感到兴奋，但对所有技术变革感到不知所措。&lt;/em&gt;我们的一位解决方案架构师在 MSys Slack 频道中分享道，然后发布了十几个最新人工智能进展的链接。他是一位经验丰富的技术老手，可能需要拥抱。谁能责怪他呢？即使在一个习惯于快速发展、几乎每个季度都会出现新技术的行业中，人工智能也正在以前所未有的速度加速变革。人工智能驱动的云可扩展性、下一代工具和平台以及边缘计算的进步增强了每个人跟上步伐的能力。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;为了澄清这一旋风，我与 MSys Technologies 和世界各地的技术专业人士进行了交谈，以揭示最新的云计算趋势——以人工智能为中心以及其他领域。此博客旨在让您了解最新的要点。因此，深入探索云计算的未来！ &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;1.人工智能驱动的云：人工智能作为云转型的核心&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;人工智能已经改变了多个行业，云计算也不例外。到 2025 年，人工智能将不仅仅是在云中运行的另一种服务，它将成为优化云操作各个方面的智能力量。从实时资源分配和自动扩展到应对威胁的智能系统，人工智能将在重塑云格局中发挥关键作用。接受这种范式转变的企业将获得非凡的回报：无与伦比的效率、显着的成本降低以及曾经被认为无法达到的性能水平。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;2.边缘到云人工智能集成：弥合无缝计算的差距&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;人工智能的未来在于边缘计算和云计算的无缝集成。到 2025 年，人工智能工作负载将在边缘和云端之间动态转移，利用每种搜索的独特优势。云端将处理复杂人工智能模型的训练，而边缘将管理实时推理，确保快速响应。下一代边缘平台将支持端到端自动化，提供跨多云和边缘环境的全面解决方案。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;3.混合和多云策略：企业最喜欢的灵活性&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;世界各地的企业已经在采用混合和多云战略——这是有充分理由的。通过融合来自不同提供商的公共云服务，企业将在 2025 年继续提高灵活性，同时避免供应商锁定。混合云解决方案提升了数据存储管理，使组织能够最大限度地利用现有基础设施，同时无缝集成公共云和私有云。这种方法可实现可扩展、安全和冗余的系统，从而增强存储、改善灾难恢复、增强数据安全性、并在快速发展的环境中保持业务敏捷。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;4.无服务器计算：简化可扩展解决方案的基础设施&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;无服务器计算正在改变软件服务的构建和部署方式，减少基础设施管理的需求。它使开发人员能够轻松部署代码，而无需担心底层基础设施。这有几个好处，包括更快的上市时间、可扩展性以及更低的新服务部署成本。鉴于这些优势，无服务器计算将在未来几年在全球企业中得到广泛采用。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;5。量子计算即服务：通过云使量子主流化&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;量子计算开始在现实世界中找到应用。到 2025 年，它将走出实验室，进入主流业务——不是通过昂贵的硬件投资，而是通过云服务。 IBM、谷歌、微软和亚马逊等行业巨头正在使这项技术的使用民主化，使各种规模的组织都可以使用量子能力。潜在的影响是深远的：从突破性的药物发现到牢不可破的加密，量子云服务将解锁以前认为不可能的创新。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;6。 DevEdgeOps：边缘计算时代采用 DevOps&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;边缘计算正在改变数据的处理和利用方式。与传统的云方法不同，边缘计算将计算能力直接带到数据源。然而，传统的 DevOps 实践在以云为中心的环境中非常有效，但需要适应边缘。 “一刀切”的方法无法解决边缘计算的独特挑战，例如规模、连接性、安全性和多样化设备。 DevEdgeOps 是一种专门的方法，它将 DevOps 的敏捷性和自动化与边缘环境的特定要求相结合。这种方法弥合了差距，使组织能够以 DevOps 为云带来的相同效率和速度管理边缘计算的复杂性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;拥抱云计算的未来&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;2025 年的云计算格局由创新定义：人工智能驱动的优化、边缘到云的无缝集成、混合策略、无服务器可扩展性和量子突破。这些趋势不仅重塑了云，还改变了企业的运营和创新方式。在 &lt;a href=&#34;https://www.msystechnologies.com/&#34;&gt;MSys Technologies&lt;/a&gt;，我们专注于提供根据您的需求量身定制的尖端云服务和解决方案。从战略到执行，我们帮助企业在这个充满活力的环境中保持领先地位。机遇是巨大的，云计算的未来就在这里。让 MSys Technologies &lt;a href=&#34;https://www.msystechnologies.com/contact-us/&#34;&gt;指导您&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Mon, 02 Dec 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Why we, as knowledge workers, should take care of work-life balance】为什么我们作为知识工作者应该注意工作与生活的平衡</title>
      <link>https://www.cncf.io/blog/2024/12/05/why-we-as-knowledge-workers-should-take-care-of-work-life-balance/</link>
      <description>【&lt;p&gt;&lt;em&gt;Community post by &lt;a href=&#34;https://www.linkedin.com/in/annalisagennaro&#34;&gt;Annalisa Gennaro&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;At the beginning of this year, I fell apart. I found myself in pieces, struggling to say a single word without bursting into tears. I had severe sleep issues, suffered from intense anxiety and experienced a form of depression. I had to stop, to take a break, and recover. During this time, I reflected on what truly matters in life, and how we should protect ourselves and our loved ones from these risks. I wished to write a farewell post as a former CNCF Ambassador to thank everyone. The book I refer to is “Slow Productivity” by Cal Newport. Not everything I will hint at refers to my very personal experience.&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;———————————–&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The modern era is characterized by competitive business environments; however, knowledge workers find it difficult to balance work and life. Many of the new facets of remote work arrangements and the persistent implementation of redundant productivity (and busyness) tools have also developed a culture where eradicating people is achieved instead of processes. As a result, tracking systems such as these impose excessive constraints on the knowledge worker and expose them to burning out and health problems especially mental health problems. In his book “&lt;em&gt;Slow Productivity&lt;/em&gt;”, Cal Newport, a writer and academic, points out that the rush of many works destroys the welfare of the worker and the end result of the work resulting in wastage in the long term.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Inaccurate Evaluation of Productivity in Knowledge Workers, Its Causes and Consequences&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;One of the critical challenges that knowledge workers encounter is the absence of appropriate productivity metrics. It differs from conventional types of labor, with output quantifiable, thus knowledge work is more involved in complexity and cannot be restricted by basic measures, such as the number of hours spent working or the tasks settled. According to Newport, assimilation of the standards of knowledge work into the industrial prism is irrational: “&lt;em&gt;Concrete productivity metrics of the type that shaped the industrial sector will never properly fit in the more amorphous knowledge work setting. (Nor should we want it to fit, as this quantitative approach to labour ushers in its own stark inhumanities). In the absence of this clarity, however, pseudo-productivity can seem like the only viable default option.&lt;/em&gt;” (in “Slow Productivity”).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As a result, productivity was measured with the help of close supervision tools such as the amount of time spent on different screens, emails sent and designated tasks performed within the set time. However, such methods frequently lead to quantity over quality, making the worker engage in an endless observable cycle of tasks revealing activity that may not necessarily depict the worth of the work done. Newport states: “&lt;em&gt;The more activity you see, the more you can assume that I’m contributing to the organization’s bottom line. […] we also gravitate away from deeper efforts toward shallower, more concrete tasks that can be more easily checked off a to-do list. Long work sessions that don’t immediately produce obvious contrails of effort become a source of anxiety […]&lt;/em&gt;” (in “Slow Productivity”). This inconsistency provokes work related stress and anxiety allowance where the employees have to earn their relevancy by proving it’s worth on such shallow metrics.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Setting and Respecting Boundaries: Why This is Crucial&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Newport stresses the necessity of boundaries, not just towards coworkers but critically towards the C-people higher in the hierarchy. He claims that always being on call is bad for the self and for any real work that could take place, high-end innovation needs periods of disconnection and reflection.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;And this production-saving measure has to be brought about with distinct conscious effort on the part of the employees:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Assertive Communication:&lt;/strong&gt; Such expectation can be created where assertive and effective communication can be possible regarding working hours and availability. Newman sagaciously argues that knowledge workers should not wait to be directed but rather take charge of the boundaries establishment and maintenance, you have to be proactive in protecting your deep work spaces, because no one else will do it for you.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Defending Your Schedule:&lt;/strong&gt; Similarly, Newport highlights those inherent time fatigue where one should focus on none of the other tasks or requests that do not lead to focusing on the goals in the long pull. It is not necessary to respond to all issues at hand immediately, and in such a case it becomes important to resist the temptation to do just anything in order to retain focus and mental energy for more worthwhile endeavors.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Time Blocking&lt;/strong&gt;: Newport supports the practice of time blocking where people assign certain hours for serious work, other hours for rest or personal engagement and clients. This is not only a strategy for increasing productivity, but also a means of enhancing focus and improving health. Time-blocking is much more than a means to improve performance, it’s a way of protecting performance and achieving balance: &lt;em&gt;“[…] I recommended better organizing your horse using time-blocking so that tasks could be better separated from deeper efforts.”&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;The Challenges and Opportunities of Remote Work&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As is the case in remote work, flexibility is built into the equation, but there are always hurdles to the achievement of the intended target of improving the sphere of life balance. Many such organisations have now adopted monitoring practices like tracking time spent online or online task performance to determine how productive employees are. Newport observes these practices as enhancing the culture of overwork, more so in the remote working setups: “&lt;em&gt;Slow productivity supports legacy-building accomplishments but allows them to unfold at a more human speed”.&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Boundaryless work has negative consequences on remote workers, as they are likely to work more hours, check emails after hours or even the constant sense of obligation to be at work. Newport warns of this inclination and stresses the need for work cutoff times as well as breaks: “&lt;em&gt;The way we’re working no longer works. What’s needed is more intentional thinking about what we mean by “productivity” in the knowledge sector – seeking ideas that start&amp;nbsp; from the premise that these efforts must be sustainable and engaging for the actual humans doing the work&lt;/em&gt;“.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Strategies for Protecting Work-Life&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Burnout is inevitable unless knowledge workers actively maintain a balance, and adopt resilience-building approaches that can vary widely.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Fixed Routines and Time Discipline&lt;/strong&gt;: Even in remote work, establishing fixed routines that separate work from personal time is recommended. This helps to create mental and physical space for relaxation. A solid routine is the key to creating a healthy distance between work and free time, and to protecting moments of true rest.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Minimizing Notifications&lt;/strong&gt;: Another way to watch the clock when it is not the time to work is to restrict the number of notifications that require action remotely. This can also protect leisure time as these work related notifications are not warranted especially after office hours. Lessen the interruptions for focus’ sake and hopefully avert burn out.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Scheduled Breaks&lt;/strong&gt;: Breaks are one of the most important parts of the work for the entire day and by no means a waste of time. Breaks are not the dispensable perks, instead, they are the basic necessity for high-level cognitive performance.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Mindfulness and Stress Management&lt;/strong&gt;: Knowledge workers, especially, can benefit from managing stress and focusing through the adoption of mindfulness or meditative practices. Taking care of one’s mental health in the same manner as physical health is important.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Letting Go of Non-Essential and Monotonous Tasks&lt;/strong&gt;: If there is a need, sometimes, identifying strategies to assist oneself from performing nonessential tasks or automating mundane work may help save working hours and concentration towards value-added tasks. Newport says that an attention to what is most important is one of the key abilities any knowledge worker can learn.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Conclusion&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Do not confuse productivity with busyness: you shouldn’t be busy to demonstrate being busy during your workday. We should be measured on the basis of results that may go beyond the hourly tracking of our tasks.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“&lt;em&gt;It seems like the benefits of technology have created the ability to stack more into our days and onto our schedules than we have the capacity to handle while maintaining a level of quality which makes the things worth doing… I think that’s where the burnout really hurts – when you want to care about something but you’re removed from the capacity to do the thing or do it properly and give it your passion and full attention and creativity because you’re expected to do so many other things&lt;/em&gt;.” (Steve, a strategic planner interviewed by Cal Newport).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Knowledge workers are able to safeguard their time and concentrate on important, worthwhile activities by establishing reasonable limits, being clear in their communication, and using techniques such as time-blocking and practicing mindfulness. This way it is possible to not only enhance one’s work but also achieve a more healthy, practicing work-life balance. This is what I wish for all of us. It doesn’t matter the industry field we have been working in, which company hired us or which personal and professional goals we set for ourselves.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Take care.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;社区帖子，作者：&lt;a href=&#34;https://www.linkedin.com/in/annalisageennaro&#34;&gt;Annalisa Gennaro&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;今年年初，我崩溃了。我发现自己支离破碎，努力说不出一个字，却又不流泪。我有严重的睡眠问题，患有严重的焦虑症，并经历过某种形式的抑郁症。我必须停下来，休息一下，然后恢复。在这段时间里，我反思了生活中真正重要的是什么，以及我们应该如何保护自己和我们所爱的人免受这些风险的影响。我想以前 CNCF 大使的身份写一篇告别文章来感谢大家。我参考的书是卡尔·纽波特的《缓慢的生产力》。我所暗示的一切并非都指我个人的经历。&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;———————————–&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;当今时代的特点是商业环境竞争激烈；然而，知识工作者发现很难平衡工作和生活。远程工作安排的许多新方面以及冗余生产力（和忙碌）工具的持续实施也形成了一种文化，在这种文化中，消除人员而不是流程。因此，诸如此类的跟踪系统对知识工作者施加了过多的限制，并使他们面临倦怠和健康问题，尤其是心理健康问题。作家兼学者卡尔·纽波特（Cal Newport）在其著作《&lt;em&gt;缓慢的生产力&lt;/em&gt;”中指出，许多工作的匆忙破坏了工人的福利，工作的最终结果导致了长期的浪费。术语。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;知识型员工生产力评估不准确及其原因和后果&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;知识工作者遇到的关键挑战之一是缺乏适当的生产力指标。它与传统劳动类型不同，产出可量化，因此知识工作更加复杂，不能被工作时长、完成的任务等基本指标所限制。纽波特认为，将知识工作标准同化到工业棱镜中是不合理的：“塑造工业部门的具体生产力指标永远无法正确适应更加无定形的知识工作环境。 （我们也不应该希望它适合，因为这种劳动力的定量方法本身就带来了明显的不人道行为）。然而，在缺乏这种清晰度的情况下，伪生产力似乎是唯一可行的默认选项。&lt;/em&gt;”（在“生产力低下”中）。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;因此，我们借助密切监督工具来衡量生产力，例如在不同屏幕上花费的时间、发送的电子邮件以及在设定时间内执行的指定任务。然而，这种方法经常导致数量超过质量，使工人陷入无休止的可观察的任务循环中，这些任务揭示的活动不一定能够描述所完成工作的价值。纽波特统计es：“&lt;em&gt;您看到的活动越多，您就越能认为我为组织的盈利做出了贡献。 [……]我们也从更深层次的努力转向更浅层、更具体的任务，这些任务可以更容易地从待办事项列表中划掉。长时间的工作不会立即产生明显的努力轨迹，这会成为焦虑的根源[...]&lt;/em&gt;”（在“生产力低下”中）。这种不一致会引发与工作相关的压力和焦虑津贴，员工必须通过在如此肤浅的指标上证明其价值来获得相关性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;设置和尊重界限：为什么这很重要&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Newport 强调界限的必要性，不仅针对同事，而且批判性地针对更高层级的 C 级人员。他声称，总是随叫随到对自己不利，对于任何可能发生的实际工作来说，高端创新都需要一段时间的脱节和反思。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这种节产措施必须通过员工的自觉努力来实现：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;自信的沟通：&lt;/strong&gt;如果可以就工作时间和可用性进行自信和有效的沟通，就可以产生这种期望。纽曼睿智地认为，知识工作者不应该等待指导，而应该负责边界的建立和维护，你必须主动保护你的深层工作空间，因为没有人会为你做这件事。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;捍卫你的日程安排：&lt;/strong&gt;同样，纽波特强调了那些固有的时间疲劳，即人们不应该关注任何其他任务或要求，因为这些任务或要求不会导致专注于长期目标。没有必要立即回应手头的所有问题，在这种情况下，抵制随心所欲地做任何事情的诱惑就变得很重要，以便保留注意力和精神能量以进行更有价值的努力。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;时间划分&lt;/strong&gt;：Newport 支持时间划分的做法，即人们将某些时间分配给认真的工作，其他时间用于休息或个人参与和客户。这不仅是提高生产力的策略，也是增强注意力和改善健康的一种手段。时间限制不仅仅是提高表现的一种手段，它还是一种保护表现和实现平衡的方式：&lt;em&gt;“[…]我建议使用时间限制更好地组织你的马，以便更好地将任务与更深层次的努力分开.”&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;远程工作的挑战和机遇&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;与远程工作的情况一样，灵活性已成为考虑因素，但在实现改善生活平衡的预期目标方面始终存在障碍。许多此类组织现在已经采用了监控实践，例如跟踪在线时间或在线任务绩效来检测我了解员工的工作效率。纽波特认为这些做法加剧了过度劳累的文化，在远程工作环境中更是如此：“生产力低下支持遗产建设的成就，但允许它们以更人性化的速度展开”。&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;无边界工作会给远程工作人员带来负面影响，因为他们可能会工作更长的时间，下班后检查电子邮件，甚至持续有工作的义务感。纽波特对这种倾向发出警告，并强调工作截止时间和休息的必要性：“我们的工作方式不再有效。我们需要更刻意地思考知识领域中“生产力”的含义 - 寻求想法，前提是这些努力必须是可持续的，并且对实际从事工作的人有吸引力&lt;/em&gt;“。&lt;/p &gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;保护工作与生活的策略&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;除非知识工作者积极保持平衡，并采取差异很大的弹性建设方法，否则倦怠是不可避免的。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;固定例程和时间纪律&lt;/strong&gt;：即使在远程工作中，也建议建立固定例程，将工作与个人时间分开。这有助于创造放松身心的空间。稳定的作息习惯是在工作和空闲时间之间保持健康距离以及保护真正休息时刻的关键。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;最小化通知&lt;/strong&gt;：在非工作时间查看时钟的另一种方法是限制需要远程操作的通知数量。这也可以保护休闲时间，因为这些与工作相关的通知是不必要的，尤其是在办公时间之后。为了集中注意力，减少干扰，并希望避免倦怠。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;预定休息&lt;/strong&gt;：休息是一整天工作中最重要的部分之一，绝不是浪费时间。休息并不是可有可无的福利，相反，它们是高水平认知表现的基本必需品。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;正念和压力管理&lt;/strong&gt;：尤其是知识工作者，可以通过采用正念或冥想练习来管理压力和集中注意力，从而受益。像照顾身体健康一样照顾心理健康很重要。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;放弃非必要和单调的任务&lt;/strong&gt;：有时，如果有需要，确定帮助自己执行非必要任务或自动化日常工作的策略可能有助于节省工作时间并集中精力实现价值- 添加任务。纽波特说，关注最重要的事情是任何知识工作者都可以学习的关键能力之一。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;结论&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;不要将生产力与忙碌混淆：您不应该在工作日中表现出忙碌。我们应该根据结果来衡量这可能超出了我们每小时跟踪我们的任务的范围。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“&lt;em&gt;技术的好处似乎让我们能够在日常生活和日程安排中添加更多超出我们处理能力的内容，同时保持一定的质量水平，这使得事情值得做……我认为这就是倦怠真正让人痛苦的地方——当你想要关心某件事，但你却没有能力去做这件事，或者无法正确地做这件事，也无法投入你的热情、充分的注意力和创造力，因为你被期望做很多其他的事情。事情&lt;/em&gt;”。 （史蒂夫，接受加州纽波特采访的战略规划师）。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;通过设定合理的限制、清晰的沟通以及使用时间限制和练习正念等技巧，知识工作者能够保护自己的时间并专注于重要、有价值的活动。这样，不仅可以提高工作效率，还可以实现更健康、实践工作与生活的平衡。这就是我对我们所有人的希望。无论我们从事哪个行业领域、哪家公司雇用我们或者我们为自己设定哪些个人和职业目标。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;保重。&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Wed, 04 Dec 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Announcing Linkerd 2.17: Egress, rate limiting, and federated services】宣布 Linkerd 2.17：出口、速率限制和联合服务</title>
      <link>https://www.cncf.io/blog/2024/12/05/announcing-linkerd-2-17-egress-rate-limiting-and-federated-services/</link>
      <description>【&lt;p&gt;&lt;em&gt;Project post originally published on the &lt;a href=&#34;https://linkerd.io/2024/12/05/announcing-linkerd-2.17/&#34;&gt;Linkerd blog&lt;/a&gt; by William Morgan&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Today we’re happy to announce the release of Linkerd 2.17, a new version of Linkerd that introduces several major new features to the project: egress traffic visibility and control; rate limiting; and&amp;nbsp;&lt;em&gt;federated services,&lt;/em&gt;&amp;nbsp;a powerful new multicluster primitive that combines services running in multiple clusters into a single logical service. This release also updates Linkerd to support OpenTelemetry for distributed tracing.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Linkerd 2.17 is our first major release since our&amp;nbsp;&lt;a href=&#34;https://linkerd.io/2024/10/23/making-linkerd-sustainable/&#34;&gt;announcement of Linkerd’s sustainability in October&lt;/a&gt;. Not unrelatedly, it is one of the first Linkerd releases in years to introduce multiple significant features at once. Despite this, we worked hard to stay true to Linkerd’s core design principle of&amp;nbsp;&lt;em&gt;simplicity&lt;/em&gt;. For example, these new features are designed to avoid configuration when possible; and when not possible, to make it minimal, consistent, and principled. After all, Linkerd’s simplicity—our rejection of the status quo that says, “the service mesh is complex and must be complex”—is key to its popularity, and it’s our duty to live up to that reputation in this and every release.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Read on for more!&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;egress-visibility-and-control&#34;&gt;Egress visibility and control&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Linkerd 2.17 introduces visibility and control for egress traffic leaving the Kubernetes cluster from meshed pods. Kubernetes itself provides no mechanisms for understanding egress traffic, and only rudimentary ones for restricting it, limited to IP ranges and ports. With the 2.17 release, Linkerd now gives you full L7 (i.e. application-layer) visibility and control of all egress traffic: you can view the source, destination, and traffic levels of all traffic leaving your cluster, including the hostnames, and, with configuration, the full HTTP paths or gRPC methods. You also can deploy&amp;nbsp;&lt;em&gt;egress security policies&lt;/em&gt;&amp;nbsp;that allow or disallow that traffic with that same level of granularity, allowing you to allowlist or blocklist egress by DNS domain rather than IP range and port.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Linkerd’s egress functionality does not require changes from the application and only minimal configuration to get started. For more advanced usage, egress configuration is built on Gateway API resources, allowing you to configure egress visibility and policies with the same extensible and Kubernetes-native configuration primitives used for almost every other aspect of Linkerd, including dynamic traffic routing, zero trust authorization policies, and more.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For example, enabling basic egress metrics across the entire cluster is as simple as adding this configuration:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;&lt;a href=&#34;https://linkerd.io/2024/12/05/announcing-linkerd-2.17/#&#34;&gt;&lt;/a&gt;&lt;code&gt;apiVersion: policy.linkerd.io/v1alpha1&#xA;kind: EgressNetwork&#xA;metadata:&#xA;  namespace: linkerd-egress&#xA;  name: all-egress-traffic&#xA;spec:&#xA;  trafficPolicy: Allow&#xA;&lt;/code&gt;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;See&amp;nbsp;&lt;a href=&#34;https://linkerd.io/2.17/features/egress/&#34;&gt;egress docs&lt;/a&gt;&amp;nbsp;for more.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;rate-limiting&#34;&gt;Rate limiting&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Rate limiting is a reliability mechanism that protects services from being overloaded. In contrast to&amp;nbsp;&lt;a href=&#34;https://linkerd.io/2/reference/circuit-breaking/&#34;&gt;Linkerd’s circuit breaking feature&lt;/a&gt;, which is client-side behavior designed to protect clients from failing services, rate limiting is server-side behavior: it is enforced by the service receiving the traffic and designed to protect it from misbehaving clients.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Just as with egress, Linkerd’s rate limiting feature is designed to require minimal configuration, while still being flexible and configurable to a wide variety of scenarios. For example, a basic rate limit of 100 requests per second for a Server named “web-http” can be enabled with this configuration:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;&lt;a href=&#34;https://linkerd.io/2024/12/05/announcing-linkerd-2.17/#&#34;&gt;&lt;/a&gt;&lt;code&gt;apiVersion: policy.linkerd.io/v1alpha1&#xA;kind: HTTPLocalRateLimitPolicy&#xA;metadata:&#xA;  namespace: emojivoto&#xA;  name: web-rlpolicy&#xA;spec:&#xA;  targetRef:&#xA;    group: policy.linkerd.io&#xA;    kind: Server&#xA;    name: web-http&#xA;  total:&#xA;    requestsPerSecond: 100&#xA;&lt;/code&gt;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Linkerd’s rate limiting feature also provides&amp;nbsp;&lt;em&gt;per-client&lt;/em&gt;&amp;nbsp;rate limit policies that allow you to ensure rate limits are distributed “fairly” across multiple clients. Combined with retries, timeouts, circuit breaking, latency-aware load balancing, and dynamic traffic routing, rate limiting extends Linkerd’s already wide arsenal of in-cluster distributed system reliability features.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;See&amp;nbsp;&lt;a href=&#34;https://linkerd.io/2.17/features/rate-limiting/&#34;&gt;rate limiting docs&lt;/a&gt;&amp;nbsp;for more.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;federated-services&#34;&gt;Federated services&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In Linkerd 2.17 we’ve shipped an exciting new multicluster feature:&amp;nbsp;&lt;em&gt;federated services&lt;/em&gt;. A federated service is a logical union of the replicas of the same service across multiple clusters. Meshed clients talking to a federated service will automatically load balance across all endpoints in all clusters, taking full advantage of Linkerd’s best-in-class latency-aware load balancing.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;With federated services, not only is application code decoupled from cluster deployment decisions—service&amp;nbsp;&lt;em&gt;Foo&lt;/em&gt;&amp;nbsp;talking to service&amp;nbsp;&lt;em&gt;Bar&lt;/em&gt;&amp;nbsp;needs only to call “Bar”, not to specify which cluster(s) it is on—but failure handling is transparent and automatic as well. Linkerd will transparently handle a wide variety of situations, including:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;An entire cluster is down&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;A cluster is up but the service on that cluster is down, or failing in some way (including L7 failures, e.g. returning 5xx response codes)&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;A cluster is slow, or the service is slow&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In all these cases, Linkerd will automatically load balance across all service endpoints on all clusters, using its default latency-aware (latency EWMA) balancing to send individual requests to the best endpoint.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Federated services were designed to capture a recent trend we see in multicluster Kubernetes adoption:&amp;nbsp;&lt;em&gt;planned large-scale multicluster&lt;/em&gt;&amp;nbsp;Kubernetes. Linkerd’s original multicluster functionality, released in the good ol’ days of Linkerd 2.8, was designed for the ad-hoc, pair-to-pair connectivity that was common at the time. However, modern Kubernetes platforms are often much more intentional in their multicluster usage, sometimes ranging into the hundreds or thousands of clusters. Federated services join features such as&amp;nbsp;&lt;a href=&#34;https://linkerd.io/2/tasks/pod-to-pod-multicluster/&#34;&gt;flat network / pod-to-pod multicluster&lt;/a&gt;&amp;nbsp;(introduced in Linkerd 2.14) in the toolbox for this new class of Kubernetes adoption.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;See&amp;nbsp;&lt;a href=&#34;https://linkerd.io/2.17/features/multicluster/#federated-services&#34;&gt;federated services docs&lt;/a&gt;&amp;nbsp;for more.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;linkerd-day-at-kubecon-london&#34;&gt;Linkerd Day at KubeCon London&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We’re delighted to report that&amp;nbsp;&lt;a href=&#34;https://events.linuxfoundation.org/kubecon-cloudnativecon-europe/co-located-events/linkerd-day/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;the CNCF is hosting Linkerd Day&lt;/a&gt;&amp;nbsp;at KubeCon London next April! Many of the Linkerd maintainers will be in attendance, and we’re expecting a great lineup of Linkerd talks as well as plenty of Linkerd users. Come see us in London!&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;how-to-get-linkerd-217&#34;&gt;How to get Linkerd 2.17&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The&amp;nbsp;&lt;a href=&#34;https://github.com/linkerd/linkerd2/releases/tag/edge-24.11.8&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;edge-24.11.8&lt;/a&gt;&amp;nbsp;release is the corresponding edge release for Linkerd 2.17. See the&amp;nbsp;&lt;a href=&#34;https://linkerd.io/releases/&#34;&gt;Linkerd releases page&lt;/a&gt;&amp;nbsp;for more.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://buoyant.io/?__hstc=249056664.5dad504b3803eb06e8ad542f84a8c351.1733415865270.1733415865270.1733415865270.1&amp;amp;__hssc=249056664.1.1733415865270&amp;amp;__hsfp=2110343318&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Buoyant&lt;/a&gt;, the creators of Linkerd, has additionally released&amp;nbsp;&lt;a href=&#34;https://buoyant.io/blog/announcing-linkerd-2-17/?__hstc=249056664.5dad504b3803eb06e8ad542f84a8c351.1733415865270.1733415865270.1733415865270.1&amp;amp;__hssc=249056664.1.1733415865270&amp;amp;__hsfp=2110343318&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Buoyant Enterprise for Linkerd 2.17.0&lt;/a&gt;&amp;nbsp;and published a&amp;nbsp;&lt;a href=&#34;https://docs.buoyant.io/release-notes/buoyant-enterprise-linkerd/enterprise-2.17.0/?__hstc=249056664.5dad504b3803eb06e8ad542f84a8c351.1733415865270.1733415865270.1733415865270.1&amp;amp;__hssc=249056664.1.1733415865270&amp;amp;__hsfp=2110343318&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Linkerd 2.17 changelog&lt;/a&gt;&amp;nbsp;with additional guidance and content.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;linkerd-is-for-everyone&#34;&gt;Linkerd is for everyone&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Linkerd is a graduated project of the&amp;nbsp;&lt;a href=&#34;https://cncf.io/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Cloud Native Computing Foundation&lt;/a&gt;. Linkerd is&amp;nbsp;&lt;a href=&#34;https://linkerd.io/2019/10/03/linkerds-commitment-to-open-governance/&#34;&gt;committed to open governance.&lt;/a&gt;&amp;nbsp;If you have feature requests, questions, or comments, we’d love to have you join our rapidly-growing community! Linkerd is hosted on&amp;nbsp;&lt;a href=&#34;https://github.com/linkerd/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;GitHub&lt;/a&gt;, and we have a thriving community on&amp;nbsp;&lt;a href=&#34;https://slack.linkerd.io/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Slack&lt;/a&gt;,&amp;nbsp;&lt;a href=&#34;https://twitter.com/linkerd&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Twitter&lt;/a&gt;, and the&amp;nbsp;&lt;a href=&#34;https://linkerd.io/community/get-involved/&#34;&gt;mailing lists&lt;/a&gt;. Come and join the fun!&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;项目帖子最初由 William Morgan 在 &lt;a href=&#34;https://linkerd.io/2024/12/05/announcing-linkerd-2.17/&#34;&gt;Linkerd 博客&lt;/a&gt;上发布&lt;/a&gt;嗯&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;今天我们很高兴地宣布发布 Linkerd 2.17，这是 Linkerd 的新版本，为该项目引入了几个主要的新功能：出口流量可见性和控制；速率限制；联合服务是一种强大的新多集群原语，它将多个集群中运行的服务组合成单个逻辑服务。此版本还更新了 Linkerd 以支持 OpenTelemetry 进行分布式跟踪。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Linkerd 2.17 是我们&lt;a href=&#34;https://linkerd.io/2024/10/23/making-linkerd-sustainable/&#34;&gt;10 月份宣布 Linkerd 可持续发展&lt;/a&gt;以来的第一个主要版本。并非不相关的是，它是多年来第一个同时引入多个重要功能的 Linkerd 版本之一。尽管如此，我们还是努力忠于 Linkerd 的核心设计原则：&lt;em&gt;简单&lt;/em&gt;。例如，这些新功能旨在尽可能避免配置；当不可能时，使其最小化、一致且有原则。毕竟，Linkerd 的简单性——我们对“服务网格很复杂而且必须很复杂”的现状的拒绝——是其受欢迎的关键，我们有责任在这个版本和每个版本中不辜负这一声誉。&lt; /p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;继续阅读以了解更多信息！&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;egress-visibility-and-control&#34;&gt;出口可见性和控制&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Linkerd 2.17 引入了对从网状 Pod 离开 Kubernetes 集群的出口流量的可见性和控制。 Kubernetes 本身没有提供了解出口流量的机制，仅提供基本的限制机制，仅限于 IP 范围和端口。在 2.17 版本中，Linkerd 现在为您提供对所有出口流量的完整 L7（即应用程序层）可见性和控制：您可以查看离开集群的所有流量的源、目的地和流量级别（包括主机名），并且，配置、完整的 HTTP 路径或 gRPC 方法。您还可以部署&lt;em&gt;出口安全策略&lt;/em&gt;，以相同的粒度允许或禁止该流量，从而允许您按 DNS 域而不是 IP 范围和端口将出口列入允许或阻止列表。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Linkerd 的出口功能不需要对应用程序进行更改，只需最少的配置即可启动。对于更高级的使用，出口配置基于网关 API 资源，允许您使用用于 Linkerd 几乎所有其他方面的相同可扩展和 Kubernetes 原生配置原语来配置出口可见性和策略，包括动态流量路由、零信任授权策略等等。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;例如，在整个集群中启用基本出口指标就像添加以下配置一样简单：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;代码类s=&#34;&#34;&gt;&lt;a href=&#34;https://linkerd.io/2024/12/05/announcing-linkerd-2.17/#&#34;&gt;&lt;/a&gt;&lt;code&gt;api版本：policy.linkerd.io/v1alpha1&#xA;种类：出口网络&#xA;元数据：&#xA;  命名空间：linkerd-egress&#xA;  名称：所有出口流量&#xA;规格：&#xA;  流量策略：允许&#xA;&lt;/code&gt;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;请参阅&lt;a href=&#34;https://linkerd.io/2.17/features/egress/&#34;&gt;egress 文档&lt;/a&gt;了解更多信息。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;rate-limiting&#34;&gt;速率限制&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;速率限制是一种防止服务过载的可靠性机制。与 &lt;a href=&#34;https://linkerd.io/2/reference/circum-writing/&#34;&gt;Linkerd 的熔断功能&lt;/a&gt;（旨在保护客户端免受失败服务影响的客户端行为）相比，限制是服务器端行为：它由接收流量的服务强制执行，旨在保护其免受行为不当的客户端的影响。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;与出口一样，Linkerd 的速率限制功能旨在需要最少的配置，同时仍然灵活且可配置到各种场景。例如，可以使用以下配置启用名为“web-http”的服务器每秒 100 个请求的基本速率限制：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;&lt;a href=&#34;https://linkerd.io/2024/12/05/announcing-linkerd-2.17/#&#34;&gt;&lt;/a &gt;&lt;code&gt;api版本：policy.linkerd.io/v1alpha1&#xA;种类：HTTPLocalRateLimitPolicy&#xA;元数据：&#xA;  命名空间：表情符号&#xA;  名称：web-rlpolicy&#xA;规格：&#xA;  目标参考：&#xA;    组：policy.linkerd.io&#xA;    种类：服务器&#xA;    名称：web-http&#xA;  全部的：&#xA;    每秒请求数：100&#xA;&lt;/code&gt;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Linkerd 的速率限制功能还提供&lt;em&gt;每个客户端&lt;/em&gt;的速率限制策略，使您能够确保速率限制在多个客户端之间“公平”分配。与重试、超时、断路、延迟感知负载平衡和动态流量路由相结合，速率限制扩展了 Linkerd 已经广泛的集群内分布式系统可靠性功能。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;请参阅&lt;a href=&#34;https://linkerd.io/2.17/features/rate-limiting/&#34;&gt;速率限制文档&lt;/a&gt;了解更多信息。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;federated-services&#34;&gt;联合服务&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在 Linkerd 2.17 中，我们推出了一项令人兴奋的新多集群功能：&lt;em&gt;联合服务&lt;/em&gt;。联合服务是跨多个集群的同一服务的副本的逻辑联合。与联合服务通信的网状客户端将自动在所有集群中的所有端点之间进行负载平衡，充分利用 Linkerd 一流的延迟感知负载平衡。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;借助联合服务，应用程序代码不仅可以与集群部署决策分离，服务 &lt;em&gt;Foo&lt;/em&gt; 与服务 &lt;em&gt;Bar&lt;/em&gt; 通信只需调用“Bar”，而不需要指定哪个服务它所在的集群 - 但故障处理也是透明且自动的。 Linkerd 将透明地处理各种情况，包括：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul cl屁股=“wp-block-list”&gt;&#xA;&lt;li&gt;整个集群已关闭&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;集群已启动，但该集群上的服务已关闭，或以某种方式出现故障（包括 L7 故障，例如返回 5xx 响应代码）&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;集群速度慢，或者服务速度慢&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在所有这些情况下，Linkerd 将自动在所有集群上的所有服务端点之间进行负载平衡，使用其默认的延迟感知（延迟 EWMA）平衡将各个请求发送到最佳端点。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;联合服务旨在捕捉我们在多集群 Kubernetes 采用方面看到的最新趋势：&lt;em&gt;计划的大规模多集群&lt;/em&gt; Kubernetes。 Linkerd 最初的多集群功能在 Linkerd 2.8 的美好时光中发布，专为当时常见的临时、对对连接而设计。然而，现代 Kubernetes 平台在多集群使用方面通常更加有意，有时会涉及数百或数千个集群。联合服务加入了&lt;a href=&#34;https://linkerd.io/2/tasks/pod-to-pod-multicluster/&#34;&gt;扁平网络/pod-to-pod 多集群&lt;/a&gt;（在 Linkerd 中引入）等功能2.14）在用于此类新 Kubernetes 采用的工具箱中。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;有关详细信息，请参阅&lt;a href=&#34;https://linkerd.io/2.17/features/multicluster/#federated-services&#34;&gt;联合服务文档&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;linkerd-day-at-kubecon-london&#34;&gt;KubeCon 伦敦 Linkerd 日&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们很高兴地报告&lt;a href=&#34;https://events.linuxfoundation.org/kubecon-cloudnativecon-europe/co- located-events/linkerd-day/&#34; target=&#34;_blank&#34; rel=&#34; noreferrer noopener&#34;&gt;CNCF 将于明年 4 月在伦敦 KubeCon 举办 Linkerd Day&lt;/a&gt;！许多 Linkerd 维护者都将出席，我们期待 Linkerd 演讲的精彩阵容以及大量 Linkerd 用户。来伦敦见我们吧！&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;how-to-get-linkerd-217&#34;&gt;如何获取 Linkerd 2.17&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/linkerd/linkerd2/releases/tag/edge-24.11.8&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;edge-24.11.8&lt;/ a&gt; 版本是 Linkerd 2.17 的相应边缘版本。请参阅&lt;a href=&#34;https://linkerd.io/releases/&#34;&gt;Linkerd 版本页面&lt;/a&gt;了解更多信息。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;一href=&#34;https://buoyant.io/?__hstc=249056664.5dad504b3803eb06e8ad542f84a8c351.173341586 5270.1733415865270.1733415865270.1&amp;__hssc=249056664.1.1733415865270&amp;__hsfp=2110343318&#34; Linkerd 的创建者 target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Buoyant&lt;/a&gt; 还发布了&lt;a href=&#34;https://buoyant.io/blog/announcing-linkerd-2-17/?__hstc=249056664.5dad504b3803eb06e8ad542f84a8 c351.1733415865270.1733415865270.1733415865270.1&amp;__hssc=249056664.1.1733415865270&amp;__hsfp=2110343318&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Buoyant Enterprise for Linkerd 2.17.0&lt;/a&gt; 并发布了 &lt;a href=&#34;https://docs.buoyant.io/release-notes/buoyant-企业-linkerd/enterprise-2.17.0/?__hstc=249056664.5dad504b3803eb06e8ad542f84a8c351.173 3415865270.1733415865270.1733415865270.1&amp;__hssc=249056664.1.1733415865270&amp;__hsfp=2110343318&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Linkerd 2.17 变更日志&lt;/a&gt; 包含其他指导和内容。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;linkerd-is-for-everyone&#34;&gt;Linkerd 适合所有人&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Linkerd 是&lt;a href=&#34;https://cncf.io/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;云原生计算基金会&lt;/a&gt;的毕业项目。 Linkerd &lt;a href=&#34;https://linkerd.io/2019/10/03/linkerds-commitment-to-open-governance/&#34;&gt;致力于开放治理。&lt;/a&gt;如果您有功能请求、疑问，或评论，我们很高兴您加入我们快速发展的社区！ Linkerd 托管在 &lt;a href=&#34;https://github.com/linkerd/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;GitHub&lt;/a&gt; 上，我们在 &lt;a href=&#34; 上拥有一个蓬勃发展的社区https://slack.linkerd.io/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Slack&lt;/a&gt;，&lt;a href=&#34;https://twitter.com/linkerd&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Twitter&lt;/a&gt; 和&lt;a href=&#34;https://linkerd.io/community/get-involved/&#34;&gt;邮件列表&lt;/a&gt;。快来加入乐趣吧！&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Wed, 04 Dec 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Why does OpenTelemetry work differently on mobile versus backend apps?】为什么 OpenTelemetry 在移动应用程序和后端应用程序上的工作方式不同？</title>
      <link>https://www.cncf.io/blog/2024/11/29/why-does-opentelemetry-work-differently-on-mobile-versus-backend-apps/</link>
      <description>【&lt;p&gt;&lt;em&gt;&amp;nbsp;Member post by Jamie Lynch, Senior Software Engineer at Embrace&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;OpenTelemetry has historically been adopted mainly on backend systems, where it’s a great solution for gaining insight into what’s happening in production by gathering telemetry via an open standard. This avoids the dreaded costs of vendor lock-in because as long as a provider supports the OTel data format, you can easily switch and take control over your own data.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Up until now, OTel’s adoption on mobile has not been quite as widespread. However, there are early signs that this is rapidly changing and that engineers are adopting the standard for similar reasons as for backend observability. Mobile provides some unique challenges for gathering telemetry compared to backend development, and in this post we will highlight what those challenges are as well as a few solutions for fixing them.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;A primer on mobile challenges&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Before we cover some of the ways OTel is different on mobile, it’s worth comparing mobile development to backend development, as mobile devices have unique constraints that affect how telemetry is collected.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Hardware is lower spec on mobile devices&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Backend servers have lots of CPU and memory, whereas most mobile devices have lower spec hardware that is less performant.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Furthermore, if your backend app runs into performance issues, you can usually just provision more servers with beefier hardware. When (not if) your mobile app runs into performance issues, shipping your users better devices is usually not an option! So on mobile, you’re stuck supporting a cohort of potentially thousands of underpowered Android/iOS device models.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Battery life is sacrosanct on mobile&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;You’ve probably experienced the frustration of running out of charge on a mobile device. Power consumption is much more important on mobile than the backend where everything is plugged into the mains –&amp;nbsp; that’s one reason why CPUs tend to be lower frequency on mobile as they require less power.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The OS itself is also much more aggressive about prolonging battery life on mobile. Approaches that might be viable on the backend, such as polling for data every second, are almost always not an option on mobile. Mobile operating systems will eagerly kill processes that use excessive resources, and it’s usually impossible to have a process running continuously in the background. In contrast, this is fairly simple to do on the backend.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Network connectivity&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Backend servers have consistent network connections with great bandwidth and low latency. Mobile devices do not enjoy these luxuries! Their network connection is usually high latency, may have prolonged periods with no connection (e.g., long-haul flights with airplane mode enabled), and bandwidth can be low.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Process lifecycle differences&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;An application server that responds to HTTP requests will run continuously. That’s not the case on mobile. A user may switch between dozens of apps in a short period, and to save limited battery and compute resources, the OS may terminate these processes at any time without warning. While this may happen on the backend in extreme scenarios such as memory pressure, on mobile this is a daily fact of life.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Transactions versus user experience&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Backend applications typically have short transactions – a HTTP request comes in, some operation occurs, and a response is returned to the client. On mobile, a user might open an app for a few minutes, but they might also use it for hours, performing hundreds or even thousands of interactions with the application during a single session. The data, context, and duration of traces captured can therefore be vastly different between backend and mobile applications.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Mobile runs in a single process&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The majority of mobile apps run in a single process which means OTel collectors and exporters run in the same process. This is quite different to the backend where these components typically run in separate processes. If the process terminates on mobile due to a crash or an OS kill, without additional work to persist telemetry, data will be lost.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;How do these constraints affect OTel on mobile?&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Sending telemetry over poor network connection&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://thenewstack.io/why-your-mobile-app-needs-client-side-network-monitoring/&#34;&gt;Network connectivity is situational on mobile devices&lt;/a&gt;, making it necessary to plan for the worst case where telemetry cannot be delivered to your backend of choice. Even if you’re lucky enough to have a connection 95% of the time, that still means you could be missing 1 in 20 requests if you take the “fire and forget” approach. For mobile, where your app may be running on thousands of different devices, this can leave a substantial hole in your observability. It’s therefore essential to persist data before sending it.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Persisting data may sound straightforward – it’s just writing a bunch of data to disk, right? Unfortunately, on mobile, this simple act introduces a whole bunch of complexity. First, the average mobile device does not have much free disk space, so the amount of telemetry that can be persisted needs to be limited in some way. This requires picking a strategy to delete telemetry data. Common strategies involve prioritizing the newest and most important types rather than stale data.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Second, it’s necessary to deal with I/O errors, potential schema changes depending on how the data is persisted, and data being sent from a different process (and maybe even a different day) from when it was captured. If engineers forget to deal with this complexity, then subtle bugs can creep into your data pipeline that impact your observability.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Handling process termination (crashes or OS kills)&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If a process terminates on mobile, it’s necessary to immediately save any captured telemetry. This is partly due to poor network connections as discussed previously, but also because blocking the UI thread with HTTP requests on process termination can lead to &lt;a href=&#34;https://embrace.io/blog/intelligent-anr-reporting/&#34;&gt;blockages and ANRs&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For a crash or OS kill, it’s generally not possible to predict when a process is going to terminate, and once it has happened, the amount that can be done is fairly limited. For example, once a C signal is raised on mobile, it’s possible to install a signal handler that reacts to the crash, but the implementation must be &lt;a href=&#34;https://www.gnu.org/software/libc/manual/html_node/POSIX-Safety-Concepts.html&#34;&gt;async-safe&lt;/a&gt;. These implementation constraints make it impossible to send HTTP requests, and very hard to do anything other than storing telemetry for later processing.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In order to capture most telemetry, an option is to periodically persist telemetry so that an up-to-date “snapshot” of the captured data can be read the next time an application launches. We’ll elaborate on this a bit later.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Conserving limited device resources&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;There’s no silver bullet for conserving resources such as battery and memory on mobile. The first step as an engineer working on an app is to be judicious in what telemetry is captured. For example, polling the OS every minute for memory data might be acceptable on the backend, but on mobile devices it would be preferable to rely on OS callbacks instead for significant events.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Profiling the impact of telemetry code in hot paths, such as application startup, also becomes more crucial on mobile. This is something that at Embrace we do as SDK vendors on our own code, but it’s also something that should be considered for your own application, as every mobile app may behave differently out in the wild.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Supporting long-running spans&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://thenewstack.io/opentelemetry-challenges-handling-long-running-spans/&#34;&gt;Long-running spans&lt;/a&gt; are a challenge in OpenTelemetry for mobile because user sessions can run for much longer times than a typical backend HTTP request. This means they can accumulate many events, making the span payloads quite large. Spans also can’t be sent until they are completed, so there’s the potential for data loss if the process terminates halfway through a span.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Embrace solves this problem on mobile with “&lt;a href=&#34;https://www.cncf.io/blog/2024/06/14/why-embrace-created-span-snapshots-for-mobile-observability-with-opentelemetry/&#34;&gt;span snapshots&lt;/a&gt;.” In this approach a JSON representation of all non-completed spans is stored on disk periodically, and if the process does terminate unexpectedly,&amp;nbsp; then on next launch the application is able to send these to an OTel-compliant backend.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Are there additional differences between mobile and backend OTel?&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Semantic conventions are less developed&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;OTel’s &lt;a href=&#34;https://opentelemetry.io/docs/concepts/semantic-conventions/&#34;&gt;semantic conventions&lt;/a&gt; are agreed-upon conventions on how telemetry should be captured by an application. These are great because using conventions means that OTel implementations can assume knowledge about what telemetry data contains.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For example, rather than showing an OTel span for a network request, a backend solution could process a span containing &lt;a href=&#34;https://opentelemetry.io/docs/specs/semconv/http/http-spans/&#34;&gt;HTTP call information&lt;/a&gt; and add opinionated logic on top of standard OTel that reveals superior insights into network performance. As OTel has historically had traction on the backend, more semantic conventions are agreed-upon for backend concepts such as HTTP requests and cloud events, than for mobile events such as user sessions.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Backend is always on, while mobile has user sessions&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The other key difference between backend and mobile is that the backend is usually running 24/7, 365 days a year. In contrast, a mobile messaging app might have very short user sessions of a few seconds, or a movie-streaming app might have user sessions that potentially run for hours. Problems can develop over time and across endless combinations of user, device, and app conditions. The uncontrolled nature of the mobile environment is certainly more complicated than the standard OTel paradigm.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;How is OTel likely to evolve on mobile in the future?&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In Embrace’s view there are three key points where the OTel community can improve support for mobile.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Network connectivity handling&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Currently, the OTel implementation for mobile doesn’t fully account for the differences between the backend and mobile, and it’s too easy for data to get lost due to unexpected process termination or long-running spans. We expect this to change as more observability vendors adopt OTel and agree on common solutions.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;More semantic conventions will be established&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://opentelemetry.io/docs/concepts/semantic-conventions/&#34;&gt;Semantic conventions&lt;/a&gt; are agreed-upon conventions for how telemetry should be captured using basic OTel data types such as spans and events. For example, an Android phone entering battery saver mode and then exiting it when a user plugs in a charger could be &lt;a href=&#34;https://opentelemetry.io/docs/concepts/signals/traces/&#34;&gt;modeled as a span&lt;/a&gt; as it has a start and end time.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If an OTel-compliant backend implementation supports a semantic convention for battery saver mode, then it could perform extra processing on the telemetry data that might surface hidden trends that correlate with the presence of this span. This data is important from a mobile engineer perspective as low power indicates the OS will be more willing to constrain background jobs and reduce the amount of system resources available – therefore affecting the performance of an app.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;The OTel ecosystem will expand to mobile&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;There is already a rich ecosystem of OTel instrumentation for backend libraries and technologies. The same doesn’t exist (yet) on mobile, but we believe that as more and more mobile engineers implement OTel and further SDK vendors become OTel-compliant, that will change.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Hopefully, we can move towards a future where telemetry and instrumentation really only need to be written once for commonly shared libraries in the mobile ecosystem. If you’d like to explore OpenTelemetry for mobile today, check out &lt;a href=&#34;https://github.com/embrace-io?q=&amp;amp;type=public&#34;&gt;Embrace’s open source, OTel-compliant SDKs&lt;/a&gt; and &lt;a href=&#34;https://embraceio-community.slack.com/&#34;&gt;join our Slack community&lt;/a&gt; to learn more about how to modernize your mobile observability.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt; 成员帖子，作者：Embrace 高级软件工程师 Jamie Lynch&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;OpenTelemetry 历来主要在后端系统上采用，它是一个很好的解决方案，可以通过开放标准收集遥测数据来深入了解生产中发生的情况。这避免了供应商锁定带来的可怕成本，因为只要提供商支持 OTel 数据格式，您就可以轻松切换并控制自己的数据。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;到目前为止，OTel 在移动设备上的采用还没有那么广泛。然而，有早期迹象表明这种情况正在迅速改变，并且工程师出于与后端可观察性类似的原因而采用该标准。与后端开发相比，移动设备为收集遥测数据带来了一些独特的挑战，在这篇文章中，我们将重点介绍这些挑战以及解决这些挑战的一些解决方案。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;移动挑战入门&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在我们介绍 OTel 在移动设备上的一些不同之处之前，有必要将移动开发与后端开发进行比较，因为移动设备具有影响遥测数据收集方式的独特限制。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;移动设备上的硬件规格较低&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;后端服务器拥有大量 CPU 和内存，而大多数移动设备的硬件规格较低，性能较差。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;此外，如果您的后端应用程序遇到性能问题，您通常可以配置更多具有更强大硬件的服务器。当（而不是如果）您的移动应用程序遇到性能问题时，为用户提供更好的设备通常不是一个选择！因此，在移动设备上，您必须支持可能有数千种功能不足的 Android/iOS 设备型号。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;移动设备上的电池寿命是神圣不可侵犯的&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;您可能经历过移动设备电量耗尽的挫败感。在移动设备上，功耗比所有设备都插入电源的后端重要得多 - 这就是移动设备上的 CPU 往往较低频率的原因之一，因为它们需要的电量较少。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;操作系统本身在延长移动设备电池寿命方面也更加积极。在后端可能可行的方法（例如每秒轮询数据）在移动设备上几乎总是行不通。移动操作系统会急切地杀死使用过多资源的进程，并且通常不可能让进程在后台持续运行。相比之下，这在后端相当简单。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;网络连接&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;后端服务器具有一致的网络连接，具有高带宽和低延迟。移动设备无法享受这些奢侈！他们的网络连接通常延迟较高，可能会长时间无连接（例如，启用飞行模式的长途航班），并且带宽可能会受到影响。低。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;流程生命周期差异&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;响应 HTTP 请求的应用程序服务器将持续运行。移动设备上的情况并非如此。用户可能会在短时间内在数十个应用程序之间切换，为了节省有限的电池和计算资源，操作系统可能会在没有警告的情况下随时终止这些进程。虽然在内存压力等极端情况下，这可能会发生在后端，但在移动设备上，这是日常生活中的事实。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;交易与用户体验&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;后端应用程序通常具有较短的事务 - 传入 HTTP 请求，发生一些操作，然后将响应返回给客户端。在移动设备上，用户可能会打开应用程序几分钟，但也可能会使用它几个小时，在单个会话期间与应用程序执行数百甚至数千次交互。因此，后端应用程序和移动应用程序之间捕获的跟踪数据、上下文和持续时间可能存在很大差异。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;移动设备在单个进程中运行&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;大多数移动应用程序在单个进程中运行，这意味着 OTel 收集器和导出器在同一进程中运行。这与后端完全不同，这些组件通常在单独的进程中运行。如果进程在移动设备上由于崩溃或操作系统终止而终止，并且没有额外的工作来持久保存遥测数据，数据将会丢失。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;这些限制对移动设备上的 OTel 有何影响？&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;通过较差的网络连接发送遥测数据&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://thenewstack.io/why-your-mobile-app-needs-client-side-network-monitoring/&#34;&gt;网络连接在移动设备上是视情况而定的&lt;/a&gt;，因此有必要针对无法将遥测数据传送到您选择的后端的最坏情况进行计划。即使您足够幸运，95% 的时间都有连接，但这仍然意味着如果您采取“即发即忘”的方法，您可能会错过二十分之一的请求。对于移动设备，您的应用程序可能在数千种不同的设备上运行，这可能会给您的可观察性留下很大的漏洞。因此，在发送数据之前保留数据至关重要。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;持久化数据可能听起来很简单——它只是将一堆数据写入磁盘，对吧？不幸的是，在移动设备上，这个简单的行为带来了一大堆复杂性。首先，普通移动设备没有太多可用磁盘空间，因此需要以某种方式限制可以持久保存的遥测数据量。这需要选择一种删除遥测数据的策略。常见策略包括优先考虑最新和最重要的类型，而不是过时的数据。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;其次，有必要处理 I/O 错误、潜在的架构更改（具体取决于数据的保存方式）以及从不同进程（甚至可能是不同日期）发送的数据。被捕获。如果工程师忘记处理这种复杂性，那么细微的错误可能会渗透到您的数据管道中，从而影响您的可观察性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;处理进程终止（崩溃或操作系统终止）&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果进程在移动设备上终止，则有必要立即保存任何捕获的遥测数据。这部分是由于前面讨论的网络连接不良造成的，但也因为在进程终止时使用 HTTP 请求阻塞 UI 线程可能会导致 &lt;a href=&#34;https://embrace.io/blog/intelligent-anr-reporting/&#34; &gt;阻塞和 ANR&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;对于崩溃或操作系统终止，通常无法预测进程何时终止，而且一旦发生，可以完成的工作量相当有限。例如，一旦在移动设备上发出 C 信号，就可以安装对崩溃做出反应的信号处理程序，但实现必须是 &lt;a href=&#34;https://www.gnu.org/software/libc/manual /html_node/POSIX-Safety-Concepts.html&#34;&gt;异步安全&lt;/a&gt;。这些实现限制使得无法发送 HTTP 请求，并且除了存储遥测数据以供以后处理之外，很难执行任何其他操作。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;为了捕获大多数遥测数据，可以选择定期保留遥测数据，以便在下次应用程序启动时可以读取所捕获数据的最新“快照”。我们稍后会详细说明这一点。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;节省有限的设备资源&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;没有什么灵丹妙药可以节省移动设备的电池和内存等资源。作为开发应用程序的工程师，第一步是明智地选择捕获的遥测数据。例如，每分钟轮询操作系统一次以获取内存数据在后端可能是可以接受的，但在移动设备上，最好依赖操作系统回调来处理重要事件。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;分析遥测代码对热路径（例如应用程序启动）的影响在移动设备上也变得更加重要。这是 Embrace 作为 SDK 供应商在我们自己的代码上所做的事情，但这也是您自己的应用程序应该考虑的事情，因为每个移动应用程序在野外的行为可能有所不同。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;支持长时间运行的跨度&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://thenewstack.io/opentelemetry-challenges-handling-long-running-spans/&#34;&gt;长时间运行的跨度&lt;/a&gt;是 OpenTelemetry 移动版中的一个挑战，因为用户会话可以运行比典型的后端 HTTP 请求更长的时间。这意味着它们可以累积许多事件，从而使跨度有效负载变得相当大。 Span 在完成之前也无法发送，因此如果进程在 Span 中途终止，则可能会丢失数据。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Embrace 通过“&lt;a href=&#34;https://www.cncf.io/blog/2024/06/14/why-embrace-created-span-snapshots-for-mobile-observability-”在移动设备上解决了这个问题with-opentelemetry/&#34;&gt;跨度快照&lt;/a&gt;。”在这种方法中，JS所有未完成跨度的 ON 表示会定期存储在磁盘上，如果进程确实意外终止，那么在下次启动时，应用程序能够将它们发送到符合 OTel 标准的后端。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;移动和后端 OTel 之间是否还有其他差异？&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;语义约定不太发达&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;OTel 的&lt;a href=&#34;https://opentelemetry.io/docs/concepts/semantic-conventions/&#34;&gt;语义约定&lt;/a&gt;是关于应用程序应如何捕获遥测数据的商定约定。这些都很棒，因为使用约定意味着 OTel 实现可以假设了解遥测数据包含的内容。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;例如，后端解决方案可以处理包含 &lt;a href=&#34;https://opentelemetry.io/docs/specs/semconv/http/http-spans/ 的跨度，而不是显示网络请求的 OTel 跨度&#34;&gt;HTTP 呼叫信息&lt;/a&gt;，并在标准 OTel 之上添加固执己见的逻辑，以揭示对网络性能的卓越洞察。由于 OTel 历来对后端具有吸引力，因此与用户会话等移动事件相比，HTTP 请求和云事件等后端概念达成了更多的语义约定。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;后端始终开启，而移动设备有用户会话&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;后端和移动设备之间的另一个主要区别是后端通常一年 365 天、每天 24/7 运行。相比之下，移动消息应用程序的用户会话可能非常短，只有几秒钟，或者电影流应用程序的用户会话可能会运行数小时。随着时间的推移以及用户、设备和应用程序条件的无限组合，问题可能会出现。移动环境不受控制的本质肯定比标准 OTel 范式更加复杂。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;OTel 未来可能如何在移动领域发展？&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在 Embrace 看来，OTel 社区可以通过三个关键点来改善对移动的支持。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;网络连接处理&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;目前，OTel 的移动实现并未完全考虑后端和移动之间的差异，并且很容易因进程意外终止或长时间运行而导致数据丢失。我们预计，随着越来越多的可观测性供应商采用 OTel 并就通用解决方案达成一致，这种情况将会改变。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;将建立更多语义约定&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://opentelemetry.io/docs/concepts/semantic-conventions/&#34;&gt;语义约定&lt;/a&gt;是关于如何使用基本 OTel 数据类型（例如跨度和事件。例如，进入省电模式然后在用户插入充电器时退出的 Android 手机可以&lt;a href=&#34;https://opentelemetry.io/docs/concepts/signals/traces/&#34;&gt;建模为跨度&lt;/a&gt; 因为它有一个 st艺术和结束时间。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果符合 OTel 标准的后端实现支持电池节省模式的语义约定，那么它可以对遥测数据执行额外的处理，这些数据可能会显示与此跨度的存在相关的隐藏趋势。从移动工程师的角度来看，这些数据非常重要，因为低功耗表明操作系统将更愿意限制后台作业并减少可用的系统资源量，从而影响应用程序的性能。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;OTel 生态系统将扩展到移动领域&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;已经有一个丰富的用于后端库和技术的 OTel 仪器生态系统。同样的情况在移动设备上尚不存在，但我们相信，随着越来越多的移动工程师实施 OTel，并且更多的 SDK 供应商变得符合 OTel 标准，这种情况将会改变。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;希望我们能够迈向这样一个未来：遥测和仪器实际上只需要为移动生态系统中的公共共享库编写一次。如果您想立即探索适用于移动设备的 OpenTelemetry，请查看&lt;a href=&#34;https://github.com/embrace-io?q=&amp;type=public&#34;&gt;Embrace 的符合 OTel 标准的开源 SDK&lt;/a&gt;并&lt;a href=&#34;https://embraceio-community.slack.com/&#34;&gt;加入我们的 Slack 社区&lt;/a&gt;，详细了解如何实现移动可观察性现代化。&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Thu, 28 Nov 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Fluent Bit v3.2: Building on best-in-class performance and efficiency】Fluent Bit v3.2：以一流的性能和效率为基础</title>
      <link>https://www.cncf.io/blog/2024/12/04/fluent-bit-v3-2-building-on-best-in-class-performance-and-efficiency/</link>
      <description>【&lt;p&gt;&lt;em&gt;Member post originally published on &lt;a href=&#34;https://chronosphere.io/learn/fluent-bit-v3-2/&#34;&gt;Chronosphere’s blog&lt;/a&gt; by Carolyn King, Head of Community &amp;amp; Developer at Chronosphere&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;New release: Fluent Bit v3.2&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This week Fluent Bit maintainers are excited to announce the launch of Fluent Bit v3.2. This release delivers major performance improvements, increased efficiency, new signal support, and new capabilities for OpenTelemetry, YAML and eBPF. With v3.2, the Fluent Bit project continues to innovate and deliver the new capabilities and ecosystem integrations required to meet the complex needs of observability and security teams.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Built on the best practices and learnings from Fluentd, Fluent Bit was created to be a light-weight version able to collect and forward logs from Internet of Things (IoT) devices and containers, where deploying Fluentd would be impractical due to limited system resources.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Since its inception, Fluent Bit has expanded its capabilities to include collecting logs, metrics, and traces, providing in-stream processing and multi-routing capabilities, and much more.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;After achieving CNCF graduated project status in 2019, Fluent Bit hit 1 billion downloads in 2022 and adoption has since skyrocketed from 1 to over 15 billion downloads today. This growth has been largely fueled by the adoption of Kubernetes and Fluent Bit’s compatibility with cloud native environments.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Key drivers of Fluent Bit’s global adoption include:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Designed for Cloud-Native:&lt;/strong&gt;&amp;nbsp;Microservices are now the de facto architecture for delivering cloud-native applications. With its small memory and CPU utilization,&amp;nbsp;&lt;a href=&#34;https://docs.chronosphere.io/pipeline-data/route/plugins/source-plugins/fluent-bit&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Fluent Bit&lt;/a&gt;&amp;nbsp;is optimized for those environments.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Built for Kubernetes and Containers:&lt;/strong&gt;&amp;nbsp;Fluent Bit is able to process large amounts of data efficiently. Because of its scalability, Fluent Bit is embedded in major Kubernetes distributions, including those from AWS, GCP, and Azure.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Observability and security data is more important than ever:&lt;/strong&gt;&amp;nbsp;Enterprises are increasingly storing and analyzing event data as part of their observability and security efforts to reduce application downtime and incident response time.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Let’s take a look at the Fluent Bit v3.2 TLDR:&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Performance improvements with SIMD and Multi-threading&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;New signal type support for Blob&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Fluent Bit + eBPF&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Interoperable ecosystem with new OTel and YAML Capabilities&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;1. Performance improvements with SIMD and Multi-threading&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;While Fluent Bit throughput and resource usage is already best in class, v3.2 introduces internal enhancements to optimize processing of log files as well as new defaults that ensure the best performance out of the box.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;a href=&#34;https://chronosphere.io/wp-content/uploads/2024/11/1FluentBitv3.2-1024x538.png&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;538&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/12/1FluentBitv3.2-1024x538-1.png&#34; alt=&#34;Image Alt Text&#34; class=&#34;wp-image-121846&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/12/1FluentBitv3.2-1024x538-1.png 1024w, https://www.cncf.io/wp-content/uploads/2024/12/1FluentBitv3.2-1024x538-1-300x158.png 300w, https://www.cncf.io/wp-content/uploads/2024/12/1FluentBitv3.2-1024x538-1-768x404.png 768w, https://www.cncf.io/wp-content/uploads/2024/12/1FluentBitv3.2-1024x538-1-194x102.png 194w, https://www.cncf.io/wp-content/uploads/2024/12/1FluentBitv3.2-1024x538-1-388x204.png 388w, https://www.cncf.io/wp-content/uploads/2024/12/1FluentBitv3.2-1024x538-1-776x408.png 776w, https://www.cncf.io/wp-content/uploads/2024/12/1FluentBitv3.2-1024x538-1-900x473.png 900w, https://www.cncf.io/wp-content/uploads/2024/12/1FluentBitv3.2-1024x538-1-381x200.png 381w, https://www.cncf.io/wp-content/uploads/2024/12/1FluentBitv3.2-1024x538-1-761x400.png 761w, https://www.cncf.io/wp-content/uploads/2024/12/1FluentBitv3.2-1024x538-1-590x310.png 590w&#34; sizes=&#34;auto, (max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;With v3.2, Fluent Bit now comes standard with Single Instruction Multi Data (SIMD) support for log processing and parsing without any additional work from users, providing immediate performance benefits with this release.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In addition, 3.2 builds on Fluent Bit’s core with continued default multi-threading for inputs, outputs, and processing of observability signal types, including logs, metrics, and traces.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;2. New signal type support for Blob&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Fluent Bit 3.2 includes two new signal types with blob and eBPF. While Fluent Bit has traditionally been used to move petabytes of machine and observability data, new requirements from users include binary data like photos, videos, and files. A common use case – AI companies require the ability to move large volumes of pictures and videos in order to train their AI models.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;a href=&#34;https://chronosphere.io/wp-content/uploads/2024/11/2FluentBitv3.2-1024x571.png&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;571&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/12/2FluentBitv3.2-1024x571-1.png&#34; alt=&#34;Image Alt Text&#34; class=&#34;wp-image-121847&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/12/2FluentBitv3.2-1024x571-1.png 1024w, https://www.cncf.io/wp-content/uploads/2024/12/2FluentBitv3.2-1024x571-1-300x167.png 300w, https://www.cncf.io/wp-content/uploads/2024/12/2FluentBitv3.2-1024x571-1-768x428.png 768w, https://www.cncf.io/wp-content/uploads/2024/12/2FluentBitv3.2-1024x571-1-900x502.png 900w, https://www.cncf.io/wp-content/uploads/2024/12/2FluentBitv3.2-1024x571-1-359x200.png 359w, https://www.cncf.io/wp-content/uploads/2024/12/2FluentBitv3.2-1024x571-1-717x400.png 717w&#34; sizes=&#34;auto, (max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;With blob signal support Fluent Bit can be used for moving massive files to storage destinations such as Azure Blob. This is particularly relevant for applications that need to collect and process photos and video files. In addition to AI, this includes autonomous vehicles, transportation, healthcare, retail, industrial automation, and more. Fluent Bit offers a turnkey way for companies to collect this data and the ability to send it to multiple backends.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;3. Fluent Bit + eBPF&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Extended Berkeley Packet Filter (eBPF) is bringing new capabilities in security and advanced observability to Fluent Bit. In v3.2, Fluent Bit adds the ability to run eBPF programs to ingest data into the pipeline.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;How fluent-bit can benefit from eBPF&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Use the existing tracepoints and tracing hooks in the kernel to extend the number of input events generators&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;code&gt;in_docker_events&lt;/code&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;code&gt;in_kubernetes_events&lt;/code&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;[…]&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Trace events from all system calls&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Trace events from other userland programs through uprobes and ftrace tracing points&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Trace and gain visibility into xdp/sockets information&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Trace and gain visibility into performance counters&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Allow users to load custom eBPF programs for custom needs&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Be independent of external tracing tools&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This includes out-of-the-box eBPF capabilities for users to plug in their own eBPF programs. New eBPF capabilities also provide integrations that enable developers to plug in to other CNCF eBPF projects, such as Falco and Tracee, for security use cases.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;4. An interoperable ecosystem with new OTel and YAML capabilities&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Since its inception, Fluent Bit was designed for extensibility and to be interoperable with the best technologies in the space.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Eduardo Silva, original creator of Fluent Bit, shared “From the beginning, Fluent Bit was built to integrate with best in class technologies and open source standards, enabling users to build the tech stack that is best for them.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;With the rise of the OpenTelemetry protocol as a standard for observability,&amp;nbsp; Fluent Bit continues its integration and standardization with OTel. This includes increased compatibility across logs, metrics, and traces.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The interoperability of Fluent Bit and OTel means that teams can choose the best technology for their needs. For example, let’s say a developer needs a lighter and more performant agent than the OTel collector but they need to be able to convert the data to an OTel format.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The user can now use the Fluent Bit agent to collect the data, and then leverage the OTel Envelope processor to convert the logs to the correct format for an OTel backend.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;a href=&#34;https://chronosphere.io/wp-content/uploads/2024/11/4FluentBitv3.2-1024x391.png&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;391&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/12/4FluentBitv3.2-1024x391-1.png&#34; alt=&#34;Image Alt Text&#34; class=&#34;wp-image-121849&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/12/4FluentBitv3.2-1024x391-1.png 1024w, https://www.cncf.io/wp-content/uploads/2024/12/4FluentBitv3.2-1024x391-1-300x115.png 300w, https://www.cncf.io/wp-content/uploads/2024/12/4FluentBitv3.2-1024x391-1-768x293.png 768w, https://www.cncf.io/wp-content/uploads/2024/12/4FluentBitv3.2-1024x391-1-900x344.png 900w, https://www.cncf.io/wp-content/uploads/2024/12/4FluentBitv3.2-1024x391-1-524x200.png 524w&#34; sizes=&#34;auto, (max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The interoperability of Fluent Bit and OTel is particularly important for users who are (1) migrating to Open Source standards and (2) implementing the OpenTelemetry protocol. Fluent Bit v3.2 introduces the following OTel capabilities:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;The OpenTelemetry Envelope processor&lt;/strong&gt;&lt;strong&gt;.&amp;nbsp;&lt;/strong&gt;The envelope processor enhances the handling of non-native OpenTelemetry data. The new OpenTelemetry envelope processor allows any of the Fluent bit log sources to automatically convert into an OTel schema without any additional work from the user side. This enables users to send non-OpenTelemetry logs to an OpenTelemetry backend.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Content Modifier for OpenTelemetry Logs&lt;/strong&gt;&lt;strong&gt;.&amp;nbsp;&lt;/strong&gt;With additions to the Content Modifier users can now recognize additional OTel data, including resources and scopes. Users now have the ability to manage OpenTelemetry logs, resources and scopes and to enrich or transform logs that are under an OTel log schema.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;New additions to YAML also make it easier for developers to adopt and leverage Fluent Bit. As many developers know, YAML has been the standard for Kubernetes configuration and many other applications for years.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;a href=&#34;https://chronosphere.io/wp-content/uploads/2024/11/5FluentBitv3.2-1024x801.png&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;801&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/12/5FluentBitv3.2-1024x801-1.png&#34; alt=&#34;Image Alt Text&#34; class=&#34;wp-image-121848&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/12/5FluentBitv3.2-1024x801-1.png 1024w, https://www.cncf.io/wp-content/uploads/2024/12/5FluentBitv3.2-1024x801-1-300x235.png 300w, https://www.cncf.io/wp-content/uploads/2024/12/5FluentBitv3.2-1024x801-1-768x601.png 768w, https://www.cncf.io/wp-content/uploads/2024/12/5FluentBitv3.2-1024x801-1-900x704.png 900w, https://www.cncf.io/wp-content/uploads/2024/12/5FluentBitv3.2-1024x801-1-256x200.png 256w, https://www.cncf.io/wp-content/uploads/2024/12/5FluentBitv3.2-1024x801-1-511x400.png 511w&#34; sizes=&#34;auto, (max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Previous Fluent Bit versions included some YAML compatibility, but Fluent Bit v3.2 now includes full support for YAML in every part of the Fluent Bit pipeline, including parsers, configuration, processors, and settings.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This allows a single unified configuration language across both Fluent Bit and Kubernetes resources which means that developers don’t need to recreate efforts inside of Fluent Bit.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Conclusion&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Fluent Bit v3.2 pushes the boundaries of performance, versatility, and interoperability in cloud-native observability. With significant enhancements like SIMD support, eBPF integrations, and full OpenTelemetry compatibility, this release ensures Fluent Bit continues to meet the evolving needs of today’s observability and security teams. Whether you’re moving large datasets or optimizing Kubernetes workflows, Fluent Bit v3.2 is equipped to help you achieve more with less.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Ready to get started?&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://docs.fluentbit.io/manual/installation/getting-started-with-fluent-bit&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Upgrade to Fluent Bit v3.2&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://chronosphere.io/fluent-bit-academy&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Learn more with the Fluent Bit Academy&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/fluent/fluent-bit&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Contribute to the project&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Chronosphere is a leading observability company, empowering customers to reduce data complexity and volume, optimize costs, and remediate issues faster. Visit: chronosphere.io.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;成员帖子最初由社区和主管 Carolyn King 发布在 &lt;a href=&#34;https://chronosphere.io/learn/fluid-bit-v3-2/&#34;&gt;Chronosphere 的博客&lt;/a&gt;上Chronosphere 开发人员&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;新版本：Fluent Bit v3.2&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;本周 Fluent Bit 维护者很高兴地宣布推出 Fluent Bit v3.2。此版本带来了重大性能改进、效率提高、新信号支持以及 OpenTelemetry、YAML 和 eBPF 的新功能。在 v3.2 中，Fluent Bit 项目继续创新并提供满足可观察性和安全团队复杂需求所需的新功能和生态系统集成。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;基于 Fluentd 的最佳实践和学习，Fluent Bit 被创建为一个轻量级版本，能够从物联网 (IoT) 设备和容器收集和转发日志，而在这些设备和容器中部署 Fluentd 由于有限的原因是不切实际的系统资源。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;自成立以来，Fluent Bit 已扩展其功能，包括收集日志、指标和跟踪、提供流内处理和多路由功能等等。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在 2019 年获得 CNCF 毕业项目地位后，Fluent Bit 在 2022 年下载量达到 10 亿次，此后采用率从 1 次飙升至如今的超过 150 亿次下载量。这一增长很大程度上得益于 Kubernetes 的采用以及 Fluent Bit 与云原生环境的兼容性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Fluent Bit 全球采用的主要驱动因素包括：&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;专为云原生而设计&lt;/strong&gt;：微服务现已成为交付云原生应用程序的实际架构。由于内存和 CPU 占用率较低，&lt;a href=&#34;https://docs.chronosphere.io/pipeline-data/route/plugins/source-plugins/fluence-bit&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34; &gt;Fluent Bit&lt;/a&gt; 针对这些环境进行了优化。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;专为 Kubernetes 和容器构建：&lt;/strong&gt; Fluent Bit 能够高效处理大量数据。由于其可扩展性，Fluent Bit 嵌入到主要 Kubernetes 发行版中，包括来自 AWS、GCP 和 Azure 的发行版。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;可观测性和安全性数据比以往任何时候都更加重要&lt;/strong&gt;：作为可观测性和安全性工作的一部分，企业越来越多地存储和分析事件数据，以减少应用程序停机时间和事件响应时间。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;让我们看一下 Fluent Bit v3.2 TLDR：&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;SIMD 和多线程的性能改进&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;对 Blob 的新信号类型支持&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Fluent Bit + eBPF&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;具有新 OTel 和 YAML 功能的互操作生态系统&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;1. SIMD 和多线程的性能改进&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;虽然流畅放置和资源使用已经是同类中最好的，v3.2 引入了内部增强功能来优化日志文件的处理以及确保开箱即用的最佳性能的新默认值。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image”&gt;&lt;a href =“https://chronosphere.io/wp-content/uploads/2024/11/1FluentBitv3.2-1024x538.png”&gt;&lt;img loading =“lazy” “解码=“异步”宽度=“1024”高度=“538” src=&#34;https://www.cncf.io/wp-content/uploads/2024/12/1FluentBitv3.2-1024x538-1.png&#34; alt=&#34;图像替代文本&#34; class=&#34;wp-image-121846&#34; srcset =“https://www.cncf.io/wp-content/uploads/2024/12/1FluentBitv3.2-1024x538-1.png 1024w，https://www.cncf.io/wp-content/uploads/ 2024/12/1FluentBitv3.2-1024x538-1-300x158.png 300w，https://www.cncf.io/wp-content/uploads/2024/12/1FluentBitv3.2-1024x538-1-768x404.png 768w， https://www.cncf.io/wp-content/uploads/2024/12/1FluentBitv3.2-1024x538-1-194x102.png 194w，https://www.cncf.io/wp-content/uploads/2024 /12/1FluentBitv3.2-1024x538-1-388x204.png 388w，https://www.cncf.io/wp-content/uploads/2024/12/1FluentBitv3.2-1024x538-1-776x408.png 776w， https://www.cncf.io/wp-content/uploads/2024/12/1FluentBitv3.2-1024x538-1-900x473.png 900w，https://www.cncf.io/wp-content/uploads/2024 /12/1FluentBitv3.2-1024x538-1-381x200.png 381w，https://www.cncf.io/wp-content/uploads/2024/12/1FluentBitv3.2-1024x538-1-761x400.png 761w， https://www.cncf.io/wp-content/uploads/2024/12/1FluentBitv3.2-1024x538-1-590x310.png 590w“尺寸=”自动，（最大宽度：1024px）100vw，1024px“引用政策=&#34;无引荐&#34;&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在 v3.2 中，Fluent Bit 现在标配单指令多数据 (SIMD) 支持，用于日志处理和解析，无需用户进行任何额外工作，此版本可立即提供性能优势。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;此外，3.2 建立在 Fluent Bit 的核心之上，为输入、输出和可观测信号类型（包括日志、指标和跟踪）的处理提供持续的默认多线程。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;2.对 Blob 的新信号类型支持&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Fluent Bit 3.2 包括两种新的信号类型：blob 和 eBPF。虽然 Fluent Bit 传统上用于移动 PB 级的机器和可观测数据，但用户的新要求包括照片、视频和文件等二进制数据。一个常见的用例 - 人工智能公司需要能够移动大量图片和视频来训练他们的人工智能模型。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image”&gt;&lt;a href =“https://chronosphere.io/wp-content/uploads/2024/11/2FluentBitv3.2-1024x571.png”&gt;&lt;img loading =“lazy” “解码=“异步”宽度=“1024”高度=“571” src=&#34;https://www.cncf.io/wp-content/uploads/2024/12/2FluentBitv3.2-1024x571-1.png&#34; alt=&#34;图像替代文本&#34; class=&#34;wp-image-121847&#34; srcset =“https://www.cncf.io/wp-content/uploads/2024/12/2FluentBitv3.2-1024x571-1.png 1024w，https://www.cncf.io/wp-content/uploads/ 2024/12/2FluentBitv3.2-1024x571-1-300x167.png 300w，https://www.cncf.io/wp-content/uploads/2024/12/2FluentBitv3.2-1024x571-1-768x428.png 768w，https://www.cncf.io/wp-content/uploads/2024/12/2FluentBitv3.2-1024x571-1-900x502.png 900w， https://www.cncf.io/wp-content/uploads/2024/12/2FluentBitv3.2-1024x571-1-359x200.png 359w，https://www.cncf.io/wp-content/uploads/2024 /12/2FluentBitv3.2-1024x571-1-717x400.png 717w“尺寸=”自动，（最大宽度：1024px）100vw，1024px“referrerpolicy=“no-referrer”&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;借助 blob 信号支持，Fluent Bit 可用于将大量文件移动到 Azure Blob 等存储目的地。这对于需要收集和处理照片和视频文件的应用程序尤其重要。除了人工智能之外，这还包括自动驾驶汽车、交通、医疗保健、零售、工业自动化等。 Fluent Bit 为公司提供了一种统包方式来收集这些数据并能够将其发送到多个后端。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;3. Fluent Bit + eBPF&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;扩展伯克利数据包过滤器 (eBPF) 为 Fluent Bit 带来了安全性和高级可观察性方面的新功能。在 v3.2 中，Fluent Bit 添加了运行 eBPF 程序以将数据提取到管道中的功能。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Fluent-bit 如何从 eBPF 中受益&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;使用内核中现有的跟踪点和跟踪挂钩来扩展输入事件生成器的数量&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;code&gt;in_docker_events&lt;/code&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;code&gt;in_kubernetes_events&lt;/code&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;[…]&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;跟踪所有系统调用的事件&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;通过 uprobes 和 ftrace 跟踪点跟踪来自其他用户空间程序的事件&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;跟踪并了解 xdp/socket 信息&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;跟踪并了解性能计数器&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;允许用户加载自定义 eBPF 程序以满足自定义需求&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;独立于外部跟踪工具&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这包括开箱即用的 eBPF 功能，供用户插入自己的 eBPF 程序。新的 eBPF 功能还提供集成，使开发人员能够插入其他 CNCF eBPF 项目（例如 Falco 和 Tracee）以实现安全用例。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;4.具有新 OTel 和 YAML 功能的可互操作生态系统&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;自诞生以来，Fluent Bit 就致力于可扩展性以及与该领域最佳技术的互操作性。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Fluent Bit 的原创者 Eduardo Silva 分享道：“从一开始，Fluent Bit 的构建就是为了与一流的技术和开源标准集成，使用户能够构建最适合他们的技术堆栈。”&lt;/ p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;随着 OpenTelemetry 协议作为可观测性标准的兴起，Fluent Bit 继续与 OTel 进行集成和标准化。这包括提高日志、指标和跟踪之间的兼容性。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Fluent Bit 和 OTel 的互操作性意味着团队可以选择最适合其需求的技术。例如，乐也就是说，开发人员需要比 OTel 收集器更轻、性能更高的代理，但他们需要能够将数据转换为 OTel 格式。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;用户现在可以使用 Fluent Bit 代理来收集数据，然后利用 OTel Envelope 处理器将日志转换为 OTel 后端的正确格式。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;a href=&#34;https://chronosphere.io/wp-content/uploads/2024/11/4FluentBitv3.2-1024x391.png&#34;&gt;&lt;img loading=&#34;lazy “解码=“异步”宽度=“1024”高度=“391” src=&#34;https://www.cncf.io/wp-content/uploads/2024/12/4FluentBitv3.2-1024x391-1.png&#34; alt=&#34;图像替代文本&#34; class=&#34;wp-image-121849&#34; srcset =“https://www.cncf.io/wp-content/uploads/2024/12/4FluentBitv3.2-1024x391-1.png 1024w，https://www.cncf.io/wp-content/uploads/ 2024/12/4FluentBitv3.2-1024x391-1-300x115.png 300w，https://www.cncf.io/wp-content/uploads/2024/12/4FluentBitv3.2-1024x391-1-768x293.png 768w， https://www.cncf.io/wp-content/uploads/2024/12/4FluentBitv3.2-1024x391-1-900x344.png 900w，https://www.cncf.io/wp-content/uploads/2024 /12/4FluentBitv3.2-1024x391-1-524x200.png 524w“尺寸=”自动，（最大宽度：1024px）100vw，1024px“referrerpolicy=“no-referrer”&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Fluent Bit 和 OTel 的互操作性对于 (1) 迁移到开源标准和 (2) 实施 OpenTelemetry 协议的用户尤为重要。 Fluent Bit v3.2 引入了以下 OTel 功能：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;&lt;strong&gt;OpenTelemetry Envelope 处理器&lt;/strong&gt;&lt;strong&gt;。 &lt;/strong&gt;包络处理器增强了对非本机 OpenTelemetry 数据的处理。新的 OpenTelemetry 包络处理器允许任何 Fluent 位日志源自动转换为 OTel 模式，而无需用户方进行任何额外工作。这使用户能够将非 OpenTelemetry 日志发送到 OpenTelemetry 后端。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;OpenTelemetry 日志的内容修饰符&lt;/strong&gt;&lt;strong&gt;。 &lt;/strong&gt;通过添加内容修饰符，用户现在可以识别其他 OTel 数据，包括资源和范围。用户现在能够管理 OpenTelemetry 日志、资源和范围，并丰富或转换 OTel 日志架构下的日志。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;YAML 的新增功能还使开发人员更容易采用和利用 Fluent Bit。正如许多开发人员所知，YAML 多年来一直是 Kubernetes 配置和许多其他应用程序的标准。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image”&gt;&lt;a href =“https://chronosphere.io/wp-content/uploads/2024/11/5FluentBitv3.2-1024x801.png”&gt;&lt;img loading =“lazy” “解码=“异步”宽度=“1024”高度=“801” src=&#34;https://www.cncf.io/wp-content/uploads/2024/12/5FluentBitv3.2-1024x801-1.png&#34; alt=&#34;图像替代文本&#34; class=&#34;wp-image-121848&#34; srcset =“https://www.cncf.io/wp-content/uploads/2024/12/5FluentBitv3.2-1024x801-1.png 1024w，https://www.cncf.io/wp-content/uploads/ 2024/12/5FluentBitv3.2-1024x801-1-300x235.png 300w，https://www.cncf.io/wp-content/uploads/2024/12/5FluentBitv3.2-1024x801-1-768x601.png 768w，https://www.cncf.io/wp-content/uploads/2024/12/5FluentBitv3.2- 1024x801-1-900x704.png 900w，https://www.cncf.io/wp-content/uploads/2024/12/5FluentBitv3.2-1024x801-1-256x200.png 256w， https://www.cncf.io/wp-content/uploads/2024/12/5FluentBitv3.2-1024x801-1-511x400.png 511w“尺寸=”自动，（最大宽度：1024px）100vw，1024px“引用策略=&#34;无引荐&#34;&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;以前的 Fluent Bit 版本包含一些 YAML 兼容性，但 Fluent Bit v3.2 现在在 Fluent Bit 管道的每个部分都包含对 YAML 的完全支持，包括解析器、配置、处理器和设置。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这允许跨 Fluent Bit 和 Kubernetes 资源使用单一的统一配置语言，这意味着开发人员无需在 Fluent Bit 内部重新创建工作。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;结论&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Fluent Bit v3.2 突破了云原生可观察性的性能、多功能性和互操作性的界限。凭借 SIMD 支持、eBPF 集成和完整的 OpenTelemetry 兼容性等重大增强功能，该版本可确保 Fluent Bit 继续满足当今可观察性和安全团队不断变化的需求。无论您是要移动大型数据集还是优化 Kubernetes 工作流程，Fluent Bit v3.2 都能帮助您事半功倍。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;准备好开始了吗？&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://docs.fluentbit.io/manual/installation/getting-started-with-fluent-bit&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;升级到 Fluent Bit v3。 2&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://chronosphere.io/fluent-bit-academy&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;通过 Fluent Bit Academy 了解更多信息&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/ Fluent/fluence-bit&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;为项目做出贡献&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Chronosphere 是一家领先的可观测性公司，帮助客户降低数据复杂性和数据量、优化成本并更快地修复问题。访问：chronosphere.io。&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Tue, 03 Dec 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Kubernetes at the edge using LINBIT SDS for persistent storage】边缘的 Kubernetes 使用 LNBIT SDS 进行持久存储</title>
      <link>https://www.cncf.io/blog/2024/11/28/kubernetes-at-the-edge-using-linbit-sds-for-persistent-storage/</link>
      <description>【&lt;p&gt;&lt;em&gt;Member post originally published on &lt;a href=&#34;https://linbit.com/blog/kubernetes-at-the-edge-using-linbit-sds-for-persistent-storage/&#34;&gt;Linbit’s blog&lt;/a&gt; by Matt Kereczman&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Edge computing is a distributed computing paradigm that brings data processing and computation closer to the data source or “edge” of the network. This reduces latency and removes Internet connectivity as a point of failure for users of edge services.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Since more hardware is involved in an edge computing environment than there is in a traditional central data center topology, there is a need to keep that hardware relatively inexpensive and replaceable. Generally, that will mean the hardware running at the edge will have less system resources than what you might find in a central data center.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;LINBIT SDS, which consists of LINSTOR® and DRBD® from LINBIT®, has a very small footprint on system resources. This leaves more resources available for other edge services and applications and makes LINBIT SDS an ideal candidate for solving persistent storage needs at the edge.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The core function of LINBIT SDS is to provide resilient and feature-rich block storage to the many platforms it integrates with. The resilience comes from DRBD, the block storage replication driver managed by LINSTOR in LINBIT SDS, allows services to tolerate host-level failures. This is an important feature at the edge, since host-level failures may be more frequent when using less expensive hardware that might not be as fault tolerant as hardware that you would run in a proper data center.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To prove and highlight some of the claims I’ve made about LINBIT SDS above, I used my trusty&amp;nbsp;&lt;a href=&#34;https://libre.computer/products/aml-s905x-cc/&#34;&gt;Libre Computer AML-S905X-CC (Le Potato) ARM-based single board computer (SBC)&lt;/a&gt;&amp;nbsp;cluster to run LINBIT SDS and&amp;nbsp;&lt;a href=&#34;https://k3s.io/&#34;&gt;K3s&lt;/a&gt;. If you’re not familiar with “Le Potato” SBCs, they are simply 2GB Raspberry Pi 4 model B clones. I would characterize my “Potato cluster” as severely underpowered compared to the enterprise grade hardware used by some of LINBIT’s users, and would even go as far as saying this is the floor in terms of hardware capability that I would try something like this on. To read about LINBIT SDS on a much more capable ARM-based system read my blog,&amp;nbsp;&lt;a href=&#34;https://linbit.com/blog/benchmarking-on-ampere-altra-max-platform-with-linbit-sds/&#34;&gt;Benchmarking on Ampere Altra Max Platform with LINBIT SDS&lt;/a&gt;. That said, if LINBIT SDS can run on my budget Raspberry Pi clone cluster, it can run anywhere.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Here is a real photograph* of my Le Potato cluster and cooling system in my home lab:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;623&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/11/linstor-kubernetes-edge-rpi_0-1024x623-1.jpg&#34; alt=&#34;Not a real photograph&#34; class=&#34;wp-image-121748&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/11/linstor-kubernetes-edge-rpi_0-1024x623-1.jpg 1024w, https://www.cncf.io/wp-content/uploads/2024/11/linstor-kubernetes-edge-rpi_0-1024x623-1-300x183.jpg 300w, https://www.cncf.io/wp-content/uploads/2024/11/linstor-kubernetes-edge-rpi_0-1024x623-1-768x467.jpg 768w, https://www.cncf.io/wp-content/uploads/2024/11/linstor-kubernetes-edge-rpi_0-1024x623-1-900x548.jpg 900w, https://www.cncf.io/wp-content/uploads/2024/11/linstor-kubernetes-edge-rpi_0-1024x623-1-329x200.jpg 329w, https://www.cncf.io/wp-content/uploads/2024/11/linstor-kubernetes-edge-rpi_0-1024x623-1-657x400.jpg 657w&#34; sizes=&#34;auto, (max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;📝&amp;nbsp;&lt;strong&gt;NOTE:&lt;/strong&gt;&amp;nbsp;This is not a real photograph.&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;small-footprint-on-system-resources&#34;&gt;Small Footprint on System Resources&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The cluster I’m using does not have a ton of resources available. Using the&amp;nbsp;&lt;code&gt;kubectl top node&lt;/code&gt;&amp;nbsp;command we can see what each of these nodes has available with LINBIT SDS already deployed.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code lang=&#34;sql&#34; class=&#34;language-sql&#34;&gt;root@potato-0:~# kubectl top node&#xA;NAME       CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%&#xA;potato-0   1111m        27%    1495Mi          77%&#xA;potato-1   1277m        31%    1666Mi          86%&#xA;potato-2   1096m        27%    1634Mi          84%&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;A single CPU core in these quad-core Libre Computer SBCs is equal to 1000m, or 1000 millicpus. This output shows us that with LINBIT SDS and Kubernetes running on them, that they still have 69-73% of their CPU resources available. Memory pressure on these 2Gi SBCs is extremely limiting, but we still have a little room to play around.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;A typical LINBIT SDS deployment in Kubernetes consists of the following containers:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;LINSTOR operator&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;LINSTOR controller&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;LINSTOR satellites&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;LINSTOR CSI controller&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;LINSTOR CSI daemonset&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;LINSTOR High Availability (HA) controller daemonset&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p&gt;📝&amp;nbsp;&lt;strong&gt;NOTE:&lt;/strong&gt;&amp;nbsp;You can verify which containers the latest LINBIT SDS deployment in Kubernetes uses by viewing the image lists that LINBIT maintains at&amp;nbsp;&lt;a href=&#34;https://charts.linstor.io/&#34;&gt;charts.linstor.io&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Using&amp;nbsp;&lt;code&gt;kubectl top pods -n linbit-sds --sum&lt;/code&gt;&amp;nbsp;we can see how much memory and CPU the LINBIT SDS containers are using.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code lang=&#34;markdown&#34; class=&#34;language-markdown&#34;&gt;root@potato-0:~# kubectl top -n linbit-sds pods --sum&#xA;NAME                                                   CPU(cores)   MEMORY(bytes)&#xA;ha-controller-bk2rh                                    4m           20Mi&#xA;ha-controller-bxhs7                                    5m           19Mi&#xA;ha-controller-knvg8                                    3m           21Mi&#xA;linstor-controller-5b84bfc497-wrbdn                    25m          168Mi&#xA;linstor-csi-controller-8c9fdd6c-q7rj5                  45m          124Mi&#xA;linstor-csi-node-c46bb                                 3m           31Mi&#xA;linstor-csi-node-knmv2                                 4m           29Mi&#xA;linstor-csi-node-x9bhr                                 3m           33Mi&#xA;linstor-operator-controller-manager-6dd5bfbfc8-cfp7t   10m          57Mi&#xA;potato-0                                               9m           87Mi&#xA;potato-1                                               10m          68Mi&#xA;potato-2                                               10m          57Mi&#xA;                                                       ________     ________&#xA;                                                       127m         719Mi&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;That’s less than a quarter of a single CPU core and under 1Gi of the 6Gi available in my tiny cluster.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If I create a LINBIT SDS provisioned persistent volume claim (PVC) replicated twice for a demo MinIO pod, we can check the utilization again while we’re actually running services. Using the following PVC and pod manifest LINBIT SDS will provision a LINSTOR volume, replicate it between two nodes (as defined in my storageClass) using DRBD, and schedule MinIO pod with data persisted on the LINBIT SDS managed storage.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code lang=&#34;markdown&#34; class=&#34;language-markdown&#34;&gt;root@potato-0:~# kubectl apply -f - &amp;lt;&amp;lt;EOF&#xA;apiVersion: v1&#xA;kind: Namespace&#xA;metadata:&#xA;  name: minio&#xA;  labels:&#xA;    name: minio&#xA;EOF&#xA;namespace/minio created&#xA;&#xA;root@potato-0:~# kubectl apply -f - &amp;lt;&amp;lt;EOF&#xA;kind: PersistentVolumeClaim&#xA;apiVersion: v1&#xA;metadata:&#xA;  name: demo-pvc-0&#xA;  namespace: minio&#xA;spec:&#xA;  storageClassName: linstor-csi-lvm-thin-r2&#xA;  accessModes:&#xA;    - ReadWriteOnce&#xA;  resources:&#xA;    requests:&#xA;      storage: 4G&#xA;EOF&#xA;persistentvolumeclaim/demo-pvc-0 created&#xA;&#xA;root@potato-0:~# kubectl apply -f - &amp;lt;&amp;lt;EOF&#xA;apiVersion: v1&#xA;kind: Pod&#xA;metadata:&#xA;  labels:&#xA;    app: minio&#xA;  name: minio&#xA;  namespace: minio&#xA;spec:&#xA;  containers:&#xA;  - name: minio&#xA;    image: quay.io/minio/minio:latest&#xA;    command:&#xA;    - /bin/bash&#xA;    - -c&#xA;    args:&#xA;    - minio server /data --console-address :9090&#xA;    volumeMounts:&#xA;    - mountPath: /data&#xA;      name: demo-pvc-0&#xA;  volumes:&#xA;  - name: demo-pvc-0&#xA;    persistentVolumeClaim:&#xA;      claimName: demo-pvc-0&#xA;EOF&#xA;pod/minio created&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Using the&amp;nbsp;&lt;code&gt;kubectl port-forward pod/minio 9000 9090 -n minio --address 0.0.0.0&lt;/code&gt;&amp;nbsp;command, I forwarded traffic on port 9000 from my&amp;nbsp;&lt;code&gt;potato-0&lt;/code&gt;&amp;nbsp;node to the MinIO pod. I then started an upload of a Debian image (583Mi) to a new MinIO bucket (&lt;code&gt;bucket-0&lt;/code&gt;) using the MinIO console accessible at&amp;nbsp;&lt;a href=&#34;https://potato-0:9000/&#34;&gt;https://potato-0:9000&lt;/a&gt;. During the upload I captured the output of&amp;nbsp;&lt;code&gt;kubectl top&lt;/code&gt;&amp;nbsp;again to compare against my previous results.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code lang=&#34;markdown&#34; class=&#34;language-markdown&#34;&gt;root@potato-2:~# kubectl top pods -n linbit-sds --sum&#xA;NAME                                                   CPU(cores)   MEMORY(bytes)&#xA;ha-controller-bk2rh                                    3m           22Mi&#xA;ha-controller-bxhs7                                    5m           26Mi&#xA;ha-controller-knvg8                                    6m           16Mi&#xA;linstor-controller-5b84bfc497-wrbdn                    72m          174Mi&#xA;linstor-csi-controller-8c9fdd6c-q7rj5                  30m          127Mi&#xA;linstor-csi-node-c46bb                                 8m           33Mi&#xA;linstor-csi-node-knmv2                                 3m           25Mi&#xA;linstor-csi-node-x9bhr                                 2m           31Mi&#xA;linstor-operator-controller-manager-6dd5bfbfc8-cfp7t   174m         58Mi&#xA;potato-0                                               4m           118Mi&#xA;potato-1                                               8m           131Mi&#xA;potato-2                                               7m           81Mi&#xA;                                                       ________     ________&#xA;                                                       317m         846Mi&#xA;root@potato-2:~# kubectl top node&#xA;NAME       CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%&#xA;potato-0   2581m        64%    1623Mi          84%&#xA;potato-1   1556m        38%    1713Mi          88%&#xA;potato-2   1147m        28%    1636Mi          84%&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;That’s a pretty minimal difference. The LINSTOR satellite pods (potato-0, potato-1, and potato-2) are using a little more memory than in the first sample. The extra memory is likely to hold DRBD’s bitmap because there are physical replicas on potato-0 and potato-1, and a diskless “tiebreaker” assignment on potato-2, which does not store a bitmap.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code lang=&#34;markdown&#34; class=&#34;language-markdown&#34;&gt;root@potato-2:~# kubectl exec -n linbit-sds deployments/linstor-controller -- linstor resource list&#xA;+----------------------------------------------------------------------------------------------------------------+&#xA;| ResourceName                             | Node     | Port | Usage  | Conns |      State | CreatedOn           |&#xA;|================================================================================================================|&#xA;| pvc-e5c40aa3-e9b2-40dc-b096-e96a61a27d47 | potato-0 | 7000 | InUse  | Ok    |   UpToDate | 2023-09-08 17:37:32 |&#xA;| pvc-e5c40aa3-e9b2-40dc-b096-e96a61a27d47 | potato-1 | 7000 | Unused | Ok    |   UpToDate | 2023-09-08 17:37:18 |&#xA;| pvc-e5c40aa3-e9b2-40dc-b096-e96a61a27d47 | potato-2 | 7000 | Unused | Ok    | TieBreaker | 2023-09-08 17:37:40 |&#xA;+----------------------------------------------------------------------------------------------------------------+&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;resilience-during-host-failures&#34;&gt;Resilience During Host Failures&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Now that the storage has data, I can simulate a failure in the cluster and see whether the data persists. I can tell that the MinIO pod is running on potato-0 from the&amp;nbsp;&lt;code&gt;linstor resource list&lt;/code&gt;&amp;nbsp;command which shows the PVC as&amp;nbsp;&lt;code&gt;InUse&lt;/code&gt;&amp;nbsp;on potato-0. To do this, I used the command&amp;nbsp;&lt;code&gt;echo c &amp;gt; /proc/sysrq-trigger&lt;/code&gt;&amp;nbsp;on potato-0. This immediately crashes the kernel, and unless you’ve configured your system otherwise, it will not reboot on its own.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;While waiting for Kubernetes to catch and react to the failure, I checked DRBD’s state on the remaining nodes and could see that potato-1, the remaining “diskful” peer, reported&amp;nbsp;&lt;code&gt;UpToDate&lt;/code&gt;&amp;nbsp;data, so it would be able to take over services:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code lang=&#34;markdown&#34; class=&#34;language-markdown&#34;&gt;root@potato-2:~# kubectl exec -it -n linbit-sds potato-1 -- drbdadm status&#xA;pvc-e5c40aa3-e9b2-40dc-b096-e96a61a27d47 role:Secondary&#xA;  disk:UpToDate&#xA;  potato-0 connection:Connecting&#xA;  potato-2 role:Secondary&#xA;    peer-disk:Diskless&#xA;&#xA;root@potato-2:~# kubectl exec -it -n linbit-sds potato-2 -- drbdadm status&#xA;pvc-e5c40aa3-e9b2-40dc-b096-e96a61a27d47 role:Secondary&#xA;  disk:Diskless&#xA;  potato-0 connection:Connecting&#xA;  potato-1 role:Secondary&#xA;    peer-disk:UpToDate&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;After roughly five minutes, Kubernetes picked up on the failure and began terminating potato-0’s pods. I didn’t use a deployment, or any other workload resources for managing this pod, so it will not be rescheduled on its own. To delete a pod from a dead node I needed to use the force, that is:&amp;nbsp;&lt;code&gt;kubectl delete pod -n minio minio --force&lt;/code&gt;. With the pod deleted, I could recreate it by using the same command used earlier:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code lang=&#34;markdown&#34; class=&#34;language-markdown&#34;&gt;root@potato-2:~# kubectl apply -f - &amp;lt;&amp;lt;EOF&#xA;apiVersion: v1&#xA;kind: Pod&#xA;metadata:&#xA;  labels:&#xA;    app: minio&#xA;  name: minio&#xA;  namespace: minio&#xA;spec:&#xA;  containers:&#xA;  - name: minio&#xA;    image: quay.io/minio/minio:latest&#xA;    command:&#xA;    - /bin/bash&#xA;    - -c&#xA;    args:&#xA;    - minio server /data --console-address :9090&#xA;    volumeMounts:&#xA;    - mountPath: /data&#xA;      name: demo-pvc-0&#xA;  volumes:&#xA;  - name: demo-pvc-0&#xA;    persistentVolumeClaim:&#xA;      claimName: demo-pvc-0&#xA;EOF&#xA;pod/minio created&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;After the pod was rescheduled on potato-1, and the port-forward to the MinIO pod restarted from potato-1, I could once again access the console and see the contents of my bucket were intact. This is because the DRBD resource LINBIT SDS created for the MinIO pod’s persistent storage replicates writes synchronously between the cluster peers. This means that by using DRBD, you have a block-for-block copy of your block devices on more than one node in the cluster at all times.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In this scenario, K3s happened to reschedule the MinIO pod on another node with a physical replica of the DRBD device, but this isn’t necessarily always the case. If K3s would have rescheduled the MinIO pod on a node without a physical replica of the DRBD device, the LINSTOR CSI driver would have created what we call a “diskless” resources on that node. A “diskless” resource uses DRBD’s replication network to attach the “diskless” peer to a node in the cluster that does contain a physical replica of the volume, allowing reads and writes to occur over the network. You can think of this like NVMe-oF or iSCSI targets and initiators, except that it uses DRBD’s internal protocols. Since this may be undesirable for workloads that are sensitive to latency, such as databases, you can&amp;nbsp;&lt;a href=&#34;https://linbit.com/drbd-user-guide/linstor-guide-1_0-en/#s-kubernetes-volume-accessibility-and-locality&#34;&gt;configure LINBIT SDS to enforce volume locality in Kubernetes&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;total-cost-of-ownership&#34;&gt;Total Cost of Ownership&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;LINBIT SDS is open source, with LINBIT offering&amp;nbsp;&lt;a href=&#34;https://linbit.com/software-defined-storage/&#34;&gt;support and services&lt;/a&gt;&amp;nbsp;on a subscription basis. This means that the total cost of ownership (TCO) in terms of acquisition can be as low as the price of your hardware. My Potato cluster can be had for&amp;nbsp;&lt;a href=&#34;https://www.amazon.com/Libre-Computer-AML-S905X-CC-Potato-64-bit/dp/B074P6BNGZ/&#34;&gt;less than $100 USD from Amazon&lt;/a&gt;&amp;nbsp;at the time I’m writing this blog. Realistically, you’re not going to run anything meaningful on a couple of Raspberry Pi clones, but I think I’ve made my point that you don’t need to spend tens of thousands of dollars for hardware to run a LINBIT SDS cluster.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The other side of TCO is the operating cost. This is where TCO involving open source software gets a bit more abstract. The price of hiring a Linux system administrator familiar with distributed storage can vary widely depending on the region you operate in, and you’ll want to have enough other work to keep an admin busy to make their salary a good investment. If that makes open source sound expensive, you’re not wrong, but LINBIT stands by its software and its users offering subscriptions at a fraction of the cost of hiring your own&amp;nbsp;&lt;a href=&#34;https://www.youtube.com/watch?v=r_3GcGCXtUo&#34;&gt;distributed storage expert&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Ultimately the actual TCO will come down to the expertise your organization has on staff and how many spare cycles they can put towards maintaining an open source solution like LINBIT SDS. I feel like this is where I can insert one of my favorite quotes regarding open source software, “think free as in free speech, not free beer.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;concluding-thoughts&#34;&gt;Concluding Thoughts&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;I’ve proven, at least to myself but hopefully to you the reader, that you&amp;nbsp;&lt;em&gt;could&lt;/em&gt;&amp;nbsp;run LINBIT SDS and Kubernetes on a cluster that fits in a shoe box, with a price tag that’s probably lower than the shoes that came in said shoe box. The efficiency of LINSTOR when coupled with the resilient block storage from DRBD makes running edge services possible using replaceable hardware. The self healing nature of Kubernetes and LINBIT SDS makes replacing a node as easy as running a single command to add it to the Kubernetes cluster, making the combination an excellent platform for running persistent containers at the edge.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;After using this “Potato cluster” for a few days to write this blog, I am happy with it, but I’m also eager to tinker with other ARM-based systems that are a bit more powerful. In the past I’ve used DRBD and Pacemaker for HA clustering on small form factor Micro ATX boards with Intel processors to great success, but the low power and size requirements of newer ARM-based systems is attractive for edge environments. If you have experience with a specific hardware platform that could fit this bill, consider&amp;nbsp;&lt;a href=&#34;https://forums.linbit.com/&#34;&gt;joining the LINBIT Slack community&lt;/a&gt;&amp;nbsp;and dropping me a message.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;成员帖子最初发布于 &lt;a href=&#34;https://linbit.com/blog/kubernetes-at-the-edge-using-linbit-sds-for-persistent-storage/&#34;&gt;Linbit 的博客&lt;/a&gt; 作者：Matt Kereczman&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;边缘计算是一种分布式计算范式，它使数据处理和计算更接近数据源或网络的“边缘”。这可以减少延迟并消除互联网连接作为边缘服务用户的故障点。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;由于边缘计算环境中涉及的硬件比传统中央数据中心拓扑中涉及的硬件更多，因此需要保持该硬件相对便宜且可更换。一般来说，这意味着在边缘运行的硬件所拥有的系统资源将少于中央数据中心的系统资源。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;LINBIT SDS 由 LINBIT® 的 LINSTOR® 和 DRBD® 组成，对系统资源的占用非常小。这为其他边缘服务和应用程序留下了更多可用资源，并使 LINBIT SDS 成为解决边缘持久存储需求的理想选择。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;LINBIT SDS 的核心功能是为其集成的许多平台提供弹性且功能丰富的块存储。弹性来自 DRBD，这是由 LINBIT SDS 中的 LINSTOR 管理的块存储复制驱动程序，允许服务容忍主机级故障。这是边缘的一个重要功能，因为当使用较便宜的硬件时，主机级故障可能会更频繁，而这些硬件的容错能力可能不如在适当的数据中心运行的硬件。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;为了证明并强调我在上面对 LINBIT SDS 所做的一些声明，我使用了我值得信赖的&lt;a href=&#34;https://libre.computer/products/aml-s905x-cc/&#34;&gt;Libre Computer AML -S905X-CC (Le Potato) 基于 ARM 的单板计算机 (SBC)&lt;/a&gt; 集群，用于运行 LINBIT SDS 和&lt;a href=&#34;https://k3s.io/&#34;&gt;K3s&lt;/a&gt;。如果您不熟悉“Le Potato”SBC，它们只是 2GB Raspberry Pi 4 B 型克隆。与 LINBIT 的一些用户使用的企业级硬件相比，我认为我的“Potato 集群”的性能严重不足，甚至会说这是我会尝试类似操作的硬件功能的底线。要了解功能更强大的基于 ARM 的系统上的 LINBIT SDS，请阅读我的博客，&lt;a href=&#34;https://linbit.com/blog/benchmarking-on-ampere-altra-max-platform-with-linbit-sds /&#34;&gt;使用 LINBIT SDS 在 Ampere Altra Max 平台上进行基准测试&lt;/a&gt;。也就是说，如果 LINBIT SDS 可以在我的预算 Raspberry Pi 克隆集群上运行，那么它就可以在任何地方运行。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这是我的家庭实验室 Le Potato 集群和冷却系统的真实照片*：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“1024”高度=“623”src=“https://www.cncf.io/ wp-content/uploads/2024/11/linstor-kubernetes-edge-rpi_0-1024x623-1.jpg&#34; alt=&#34;不是真实照片&#34;类=“wp-image-121748”srcset =“https://www.cncf.io/wp-content/uploads/2024/11/linstor-kubernetes-edge-rpi_0-1024x623-1.jpg 1024w， https://www.cncf.io/wp-content/uploads/2024/11/linstor-kubernetes-edge-rpi_0-1024x623-1-300x183.jpg 300w， https://www.cncf.io/wp-content/uploads/2024/11/linstor-kubernetes-edge-rpi_0-1024x623-1-768x467.jpg 768w， https://www.cncf.io/wp-content/uploads/2024/11/linstor-kubernetes-edge-rpi_0-1024x623-1-900x548.jpg 900w， https://www.cncf.io/wp-content/uploads/2024/11/linstor-kubernetes-edge-rpi_0-1024x623-1-329x200.jpg 329w， https://www.cncf.io/wp-content/uploads/2024/11/linstor-kubernetes-edge-rpi_0-1024x623-1-657x400.jpg 657w“尺寸=”自动，（最大宽度：1024px）100vw , 1024px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;📝 &lt;strong&gt;注意：&lt;/strong&gt; 这不是真实的照片。&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;small-footprint-on-system-resources&#34;&gt;系统资源占用小&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我正在使用的集群没有大量可用资源。使用 &lt;code&gt;kubectl top node&lt;/code&gt; 命令，我们可以查看每个节点在已部署的 LINBIT SDS 中可用的内容。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code lang=&#34;sql&#34; class=&#34;language-sql&#34;&gt;root@potato-0:~# kubectl 顶级节点&#xA;名称 CPU（核心数） CPU% 内存（字节） 内存%&#xA;马铃薯-0 1111m 27% 1495Mi 77%&#xA;马铃薯-1 1277m 31% 1666Mi 86%&#xA;马铃薯-2 1096m 27% 1634Mi 84%&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这些四核 Libre Computer SBC 中的单个 CPU 核心等于 1000m，或 1000 millicpus。此输出向我们表明，当 LINBIT SDS 和 Kubernetes 在其上运行时，它们仍然有 69-73% 的 CPU 资源可用。这些 2Gi SBC 上的内存压力非常有限，但我们仍然有一点发挥空间。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes 中典型的 LINBIT SDS 部署包含以下容器：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;LINSTOR 运算符&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;LINSTOR 控制器&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;LINSTOR 卫星&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;LINSTOR CSI 控制器&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;LINSTOR CSI 守护进程集&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;LINSTOR 高可用性 (HA) 控制器守护程序集&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p&gt;📝 &lt;strong&gt;注意：&lt;/strong&gt; 您可以通过查看 LINBIT 在 &lt;a href=&#34;https://charts.linstor.io/ 维护的映像列表来验证 Kubernetes 中最新的 LINBIT SDS 部署使用哪些容器&#34;&gt;charts.linstor.io&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;/块引用&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;使用&lt;code&gt;kubectl top pods -n linbit-sds --sum&lt;/code&gt;我们可以看到 LINBIT SDS 容器使用了多少内存和 CPU。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code lang=&#34;markdown&#34; class=&#34;language-markdown&#34;&gt;root@potato-0:~# kubectl top -n linbit-sds pods --sum&#xA;名称 CPU（核心数） 内存（字节）&#xA;ha-控制器-bk2rh 4m 20Mi&#xA;ha-c控制器-bxhs7 5m 19Mi&#xA;ha-控制器-knvg8 3m 21Mi&#xA;林斯托控制器-5b84bfc497-wrbdn 25m 168Mi&#xA;林斯托-CSI-控制器-8c9fdd6c-q7rj5 45m 124Mi&#xA;林斯托-csi-节点-c46bb 3m 31Mi&#xA;linstor-CSI-节点-knmv2 4m 29Mi&#xA;林斯托-CSI-节点-x9bhr 3m 33Mi&#xA;林斯托操作员控制器管理器-6dd5bfbfc8-cfp7t 10m 57Mi&#xA;马铃薯-0 9m 87Mi&#xA;马铃薯-1 10m 68Mi&#xA;马铃薯-2 10m 57Mi&#xA;                                                       ________ ________&#xA;                                                       127m 719米&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这还不到单个 CPU 核心的四分之一，并且低于我的小型集群中可用的 6Gi 的 1Gi。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果我为演示 MinIO Pod 创建一个 LINBIT SDS 配置的持久卷声明 (PVC) 复制两次，我们可以在实际运行服务时再次检查利用率。使用以下 PVC 和 pod 清单，LINBIT SDS 将配置一个 LINSTOR 卷，使用 DRBD 在两个节点（如我的 storageClass 中定义）之间复制它，并使用保留在 LINBIT SDS 托管存储上的数据来调度 MinIO pod。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code lang=&#34;markdown&#34; class=&#34;language-markdown&#34;&gt;root@potato-0:~# kubectl apply -f - &lt;&lt;EOF&#xA;api版本：v1&#xA;种类：命名空间&#xA;元数据：&#xA;  姓名：米尼奥&#xA;  标签：&#xA;    姓名：米尼奥&#xA;EOF&#xA;创建命名空间/minio&#xA;&#xA;root@potato-0:~# kubectl apply -f - &lt;&lt;EOF&#xA;种类：持久卷声明&#xA;api版本：v1&#xA;元数据：&#xA;  名称：演示-PVC-0&#xA;  命名空间：minio&#xA;规格：&#xA;  存储类名称：linstor-csi-lvm-thin-r2&#xA;  访问模式：&#xA;    - 读写一次&#xA;  资源：&#xA;    要求：&#xA;      存储：4G&#xA;EOF&#xA;已创建持久卷声明/demo-pvc-0&#xA;&#xA;root@potato-0:~# kubectl apply -f - &lt;&lt;EOF&#xA;api版本：v1&#xA;种类: 豆荚&#xA;元数据：&#xA;  标签：&#xA;    应用程序：迷你&#xA;  姓名：米尼奥&#xA;  命名空间：minio&#xA;规格：&#xA;  容器：&#xA;  - 姓名：米尼奥&#xA;    图片：quay.io/minio/minio：最新&#xA;    命令：&#xA;    - /bin/bash&#xA;    - -c&#xA;    参数：&#xA;    - minio服务器/数据--控制台地址：9090&#xA;    体积安装：&#xA;    - 挂载路径：/data&#xA;      名称：演示-PVC-0&#xA;  卷：&#xA;  - 名称：demo-pvc-0&#xA;    持久卷声明：&#xA;      声明名称：demo-pvc-0&#xA;EOF&#xA;已创建 pod/minio&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;使用 &lt;code&gt;kubectl port-forward pod/minio 9000 9090 -n minio --address 0.0.0.0&lt;/code&gt; 命令，我从 &lt;code&gt;potato-0&lt;/code&gt; 转发端口 9000 上的流量节点到 MinIO pod。然后，我开始使用 MinIO 控制台将 Debian 映像 (583Mi) 上传到新的 MinIO 存储桶 (&lt;code&gt;bucket-0&lt;/code&gt;)，该控制台可访问 &lt;a href=&#34;https://potato-0:9000/ &#34;&gt;https://potato-0:9000&lt;/a&gt;。在上传过程中我捕获再次查看 &lt;code&gt;kubectl top&lt;/code&gt; 的输出，以与我之前的结果进行比较。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code lang=&#34;markdown&#34; class=&#34;language-markdown&#34;&gt;root@potato-2:~# kubectl top pods -n linbit-sds --sum&#xA;名称 CPU（核心数） 内存（字节）&#xA;ha-控制器-bk2rh 3m 22Mi&#xA;ha-控制器-bxhs7 5m 26Mi&#xA;ha-控制器-knvg8 6m 16Mi&#xA;林斯托控制器-5b84bfc497-wrbdn 72m 174Mi&#xA;林斯托-CSI-控制器-8c9fdd6c-q7rj5 30m 127Mi&#xA;林斯托-csi-节点-c46bb 8m 33Mi&#xA;linstor-CSI-节点-knmv2 3m 25Mi&#xA;林斯托-CSI-节点-x9bhr 2m 31Mi&#xA;林斯托运营商控制器管理器-6dd5bfbfc8-cfp7t 174m 58Mi&#xA;马铃薯-0 4m 118Mi&#xA;马铃薯-1 8m 131Mi&#xA;马铃薯-2 7m 81Mi&#xA;                                                       ________ ________&#xA;                                                       317m 846米&#xA;root@potato-2:~# kubectl 顶级节点&#xA;名称 CPU（核心数） CPU% 内存（字节） 内存%&#xA;马铃薯-0 2581m 64% 1623Mi 84%&#xA;马铃薯-1 1556m 38% 1713Mi 88%&#xA;马铃薯-2 1147m 28% 1636Mi 84%&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这是一个非常小的差异。 LINSTOR 卫星吊舱（potato-0、potato-1 和potato-2）使用的内存比第一个样本多一点。额外的内存可能会保存 DRBD 的位图，因为在potato-0 和potato-1 上有物理副本，并且在potato-2 上有无盘“决胜局”分配，而potato-2 不存储位图。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code lang=&#34;markdown&#34; class=&#34;language-markdown&#34;&gt;root@potato-2:~# kubectl exec -n linbit-sds 部署/linstor-controller -- linstor资源清单&#xA;+------------------------------------------------ -------------------------------------------------- -------------+&#xA;|资源名称 |节点|港口|用途 |康恩斯 |      状态|创建于 |&#xA;|==================================================== =================================================== =============|&#xA;| PVC-E5C40AA3-E9B2-40DC-B096-E96A61A27D47 |马铃薯-0 | 7000 |使用中 |好的 |   最新 | 2023-09-08 17:37:32 |&#xA;| PVC-E5C40AA3-E9B2-40DC-B096-E96A61A27D47 |马铃薯-1 | 7000 |未使用 |好的 |   最新 | 2023-09-08 17:37:18 |&#xA;| PVC-E5C40AA3-E9B2-40DC-B096-E96A61A27D47 |马铃薯2 | 7000 |未使用 |好的 |决胜局 | 2023-09-08 17:37:40 |&#xA;+------------------------------------------------ -------------------------------------------------- -------------+&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;resilience-during-host-failures&#34;&gt;主机故障期间的恢复能力&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;现在存储中有数据了，我可以模拟集群中的故障，看看数据是否仍然存在。我可以通过 &lt;code&gt;linstor resources list&lt;/code&gt; 命令得知 MinIO pod 正在马铃薯 0 上运行，该命令将 PVC 在马铃薯 0 上显示为 &lt;code&gt;InUse&lt;/code&gt;。为此，我在potato-0 上使用了命令&lt;code&gt;echo c &gt; /proc/sysrq-trigger&lt;/code&gt;。这会立即使内核崩溃，除非您已经配置了系统，否则它不会自行重新启动。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在等待 Kubernetes 捕获故障并对故障做出反应时，我检查了其余节点上的 DRBD 状态，并可以看到剩下的“磁盘”对等点potato-1 报告了 &lt;code&gt;UpToDate&lt;/code&gt; 数据，因此它将能够接管服务：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code lang=&#34;markdown&#34; class=&#34;language-markdown&#34;&gt;root@potato-2:~# kubectl exec -it -n linbit-sdspotato-1 -- drbdadm地位&#xA;pvc-e5c40aa3-e9b2-40dc-b096-e96a61a27d47 作用：次要&#xA;  磁盘：最新&#xA;  potato-0 连接：正在连接&#xA;  马铃薯2角色：次要&#xA;    对等磁盘：无盘&#xA;&#xA;root@potato-2:~# kubectl exec -it -n linbit-sdspotato-2 -- drbdadm 状态&#xA;pvc-e5c40aa3-e9b2-40dc-b096-e96a61a27d47 作用：次要&#xA;  磁盘：无盘&#xA;  potato-0 连接：正在连接&#xA;  马铃薯-1角色：次要&#xA;    对等磁盘：UpToDate&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;大约五分钟后，Kubernetes 发现了故障并开始终止potato-0 的 Pod。我没有使用部署或任何其他工作负载资源来管理此 Pod，因此它不会自行重新安排。要从死节点删除 pod，我需要使用强制力，即：&lt;code&gt;kubectl delete pod -n minio minio --force&lt;/code&gt;。删除 Pod 后，我可以使用之前使用的相同命令重新创建它：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code lang=&#34;markdown&#34; class=&#34;language-markdown&#34;&gt;root@potato-2:~# kubectl apply -f - &lt;&lt;EOF&#xA;api版本：v1&#xA;种类: 豆荚&#xA;元数据：&#xA;  标签：&#xA;    应用程序：迷你&#xA;  姓名：米尼奥&#xA;  命名空间：minio&#xA;规格：&#xA;  容器：&#xA;  - 姓名：米尼奥&#xA;    图片：quay.io/minio/minio：最新&#xA;    命令：&#xA;    - /bin/bash&#xA;    - -c&#xA;    参数：&#xA;    - minio服务器/数据--控制台地址：9090&#xA;    体积安装：&#xA;    - 挂载路径：/data&#xA;      名称：演示-PVC-0&#xA;  卷：&#xA;  - 名称：demo-pvc-0&#xA;    持久卷声明：&#xA;      声明名称：demo-pvc-0&#xA;EOF&#xA;已创建 pod/minio&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在 Pod 被重新安排到 Poto-1 上，并且从 Poto-1 重新启动到 MinIO Pod 的端口转发后，我可以再次访问控制台并看到存储桶中的内容完好无损。这是因为为 MinIO pod 的持久存储创建的 DRBD 资源 LINBIT SDS 在集群对等点之间同步复制写入。这意味着通过使用 DRBD，您可以始终在集群中的多个节点上拥有块设备的逐块副本。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在这种情况下，K3s 碰巧重新调度了 MinIO pod在具有 DRBD 设备物理副本的另一个节点上，但情况并不一定总是如此。如果 K3s 在没有 DRBD 设备物理副本的节点上重新调度 MinIO pod，则 LINSTOR CSI 驱动程序将在该节点上创建我们所说的“无盘”资源。 “无盘”资源使用 DRBD 的复制网络将“无盘”对等点附加到集群中包含卷物理副本的节点，从而允许通过网络进行读取和写入。您可以将其视为 NVMe-oF 或 iSCSI 目标和启动器，只不过它使用 DRBD 的内部协议。由于这对于对延迟敏感的工作负载（例如数据库）可能并不理想，因此您可以&lt;a href=&#34;https://linbit.com/drbd-user-guide/linstor-guide-1_0-en/#s-kubernetes -volume-accessibility-and-locality&#34;&gt;配置 LINBIT SDS 以在 Kubernetes 中强制实施卷局部性&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;total-cost-of-ownership&#34;&gt;总拥有成本&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;LINBIT SDS 是开源的，LINBIT 在订阅的基础上提供&lt;a href=&#34;https://linbit.com/software-defined-storage/&#34;&gt;支持和服务&lt;/a&gt;。这意味着采购方面的总拥有成本 (TCO) 可以与硬件的价格一样低。我的 Potato 集群可以&lt;a href=&#34;https://www.amazon.com/Libre-Computer-AML-S905X-CC-Potato-64-bit/dp/B074P6BNGZ/&#34;&gt;不到 100 美元从 Amazon 购买&lt;/a&gt; 在我写这篇博客的时候。实际上，您不会在几个 Raspberry Pi 克隆上运行任何有意义的内容，但我想我已经表明了我的观点，即您不需要花费数万美元购买硬件来运行 LINBIT SDS 集群。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;TCO 的另一面是运营成本。这就是涉及开源软件的 TCO 变得更加抽象的地方。雇用熟悉分布式存储的 Linux 系统管理员的价格可能会根据您所在的区域而有很大差异，并且您需要有足够的其他工作来让管理员保持忙碌，以使他们的薪水成为一项不错的投资。如果这让开源听起来很昂贵，那么您没有错，但 LINBIT 坚持其软件及其用户的立场，以仅雇用自己的成本的一小部分提供订阅&lt;a href=&#34;https://www.youtube.com/ watch?v=r_3GcGCXtUo&#34;&gt;分布式存储专家&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;最终，实际的 TCO 将取决于您的组织拥有的员工专业知识以及他们可以投入多少空闲周期来维护 LINBIT SDS 等开源解决方案。我觉得在这里我可以插入我最喜欢的关于开源软件的名言之一，“像自由言论一样思考自由，而不是免费啤酒。”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;conclusion-thoughts&#34;&gt;结论性想法&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我已经证明，至少向我自己，但希望向读者您证明，您可以在适合鞋子的集群上运行 LINBIT SDS 和 Kubernetes。牛，其价格标签可能低于上述鞋盒中的鞋子。 LINSTOR 的效率与 DRBD 的弹性块存储相结合，使得使用可更换硬件运行边缘服务成为可能。 Kubernetes 和 LINBIT SDS 的自我修复特性使得更换节点就像运行单个命令将其添加到 Kubernetes 集群一样简单，使该组合成为在边缘运行持久容器的绝佳平台。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在使用这个“Potato cluster”几天来写这篇博客后，我很高兴，但我也渴望修补其他更强大的基于 ARM 的系统。过去，我在配备 Intel 处理器的小型 Micro ATX 主板上使用 DRBD 和 Pacemaker 进行 HA 集群，取得了巨大成功，但较新的基于 ARM 的系统的低功耗和尺寸要求对于边缘环境很有吸引力。如果您有使用符合此要求的特定硬件平台的经验，请考虑&lt;a href=&#34;https://forums.linbit.com/&#34;&gt;加入 LINBIT Slack 社区&lt;/a&gt;并向我留言。&lt;/ p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Wed, 27 Nov 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【The ultimate KubeCon + CloudNativeCon North America 2024 recap: the CNCF ambassadors’ edition】KubeCon + CloudNativeCon 北美 2024 年终极回顾：CNCF 大使版</title>
      <link>https://www.cncf.io/blog/2024/11/26/the-ultimate-kubecon-cloudnativecon-north-america-2024-recap-the-cncf-ambassadors-edition/</link>
      <description>【&lt;p&gt;&lt;a href=&#34;https://horovits.medium.com/?source=post_page---byline--1362959030c1--------------------------------&#34;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Ambassador post originally published on &lt;a href=&#34;https://horovits.medium.com/the-ultimate-kubecon-2024-recap-the-cncf-ambassadors-edition-1362959030c1&#34;&gt;Medium&lt;/a&gt; by Dotan Horovits&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading has-gray-300-background-color has-background&#34;&gt;&lt;em&gt;This is a summary of the&amp;nbsp;&lt;a href=&#34;https://community.cncf.io/events/details/cncf-cncf-online-programs-presents-live-with-the-experts-cloud-native-ambassadors-share-the-best-of-kubecon-2024/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;CNCF’s KubeCon+CloudNativeCon NA 2024 recap live stream&lt;/a&gt;&amp;nbsp;event hosted on November 19th.&lt;/em&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1600&#34; height=&#34;900&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/11/Ambassadors-Unplugged-Twitter-Post-1.jpg&#34; alt=&#34;Ambassadors Unplugged: Insights from KubeCon + CloudNativeCon North America 2024 banner&#34; class=&#34;wp-image-121352&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/11/Ambassadors-Unplugged-Twitter-Post-1.jpg 1600w, https://www.cncf.io/wp-content/uploads/2024/11/Ambassadors-Unplugged-Twitter-Post-1-300x169.jpg 300w, https://www.cncf.io/wp-content/uploads/2024/11/Ambassadors-Unplugged-Twitter-Post-1-1024x576.jpg 1024w, https://www.cncf.io/wp-content/uploads/2024/11/Ambassadors-Unplugged-Twitter-Post-1-768x432.jpg 768w, https://www.cncf.io/wp-content/uploads/2024/11/Ambassadors-Unplugged-Twitter-Post-1-900x506.jpg 900w, https://www.cncf.io/wp-content/uploads/2024/11/Ambassadors-Unplugged-Twitter-Post-1-356x200.jpg 356w, https://www.cncf.io/wp-content/uploads/2024/11/Ambassadors-Unplugged-Twitter-Post-1-711x400.jpg 711w&#34; sizes=&#34;auto, (max-width: 1600px) 100vw, 1600px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;f9ea&#34;&gt;Want to catch up on KubeCon’s highlights and takeaways? Take it from the experts who know the cloud-native space inside out — the&amp;nbsp;&lt;a href=&#34;https://www.cncf.io/people/ambassadors/&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;CNCF Ambassadors&lt;/a&gt;!&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;2d43&#34;&gt;I’d like to thank the&amp;nbsp;&lt;em&gt;Cloud Native Computing Foundation (CNCF)&lt;/em&gt;, the organization behind KubeCon, for inviting me to host its&amp;nbsp;&lt;a href=&#34;https://community.cncf.io/events/details/cncf-cncf-online-programs-presents-live-with-the-experts-cloud-native-ambassadors-share-the-best-of-kubecon-2024/&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;official KubeCon+CloudNativeCon North America 2024 recap session&lt;/a&gt;. The CNCF hosts Kubernetes, Argo, Backstage, OpenTelemetry and over 200 other cloud-native projects we know and love. You can find the full recording of the session on the&amp;nbsp;&lt;em&gt;KubeCon + CloudNativeCon Salt Lake City 2024&lt;/em&gt;&amp;nbsp;playlist on the&amp;nbsp;&lt;a href=&#34;https://www.youtube.com/watch?v=WHT1CisdKEE&amp;amp;list=PLj6h78yzYM2Pw4mRw4S-1p_xLARMqPkA7&amp;amp;index=310&amp;amp;t=4s&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;CNCF’s official YouTube channel&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;37ed&#34;&gt;In this recap session I sat down with fellow CNCF Ambassadors and cloud-native experts&amp;nbsp;&lt;a href=&#34;https://www.linkedin.com/in/viktorfarcic&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;Viktor Farcic&lt;/a&gt;&amp;nbsp;and&amp;nbsp;&lt;a href=&#34;https://twitter.com/mkoerbi&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;Max Körbächer&lt;/a&gt;&amp;nbsp;to unpack the major project announcements and key themes from Salt Lake City: the standout talks, co-located events, and those memorable hallway conversations.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;8fb4&#34;&gt;In this post, I’ll share a recap of that highlight-packed hour-long discussion. Let’s go!&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio&#34;&gt;&lt;div class=&#34;wp-block-embed__wrapper&#34;&gt;&#xA;&lt;iframe loading=&#34;lazy&#34; title=&#34;Live with the Experts! CNCF Ambassadors &amp;amp; the Best of KubeCon&#34; width=&#34;500&#34; height=&#34;281&#34; src=&#34;https://www.youtube.com/embed/WHT1CisdKEE?start=7&amp;amp;feature=oembed&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; referrerpolicy=&#34;no-referrer&#34; allowfullscreen=&#34;&#34;&gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;2e92&#34;&gt;Expert panel: Viktor Farcic and Max Körbächer&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;37d5&#34;&gt;Viktor Farcic is a lead rapscallion at&amp;nbsp;&lt;a href=&#34;https://www.upbound.io/&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;Upbound&lt;/a&gt;&amp;nbsp;and a published author. He is a host of the YouTube channel&amp;nbsp;&lt;a href=&#34;https://www.youtube.com/c/devopstoolkit&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;DevOps Toolkit&lt;/a&gt;&amp;nbsp;and a co-host of&amp;nbsp;&lt;a href=&#34;https://www.youtube.com/c/DevOpsParadox&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;DevOps Paradox&lt;/a&gt;. Or as he presented himself: “the Crossplane guy”.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;0b0e&#34;&gt;Max Körbächer is Co-Founder at&amp;nbsp;&lt;a href=&#34;https://www.reply.com/liquid-reply/en/&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;Liquid Reply&lt;/a&gt;. He is Co-Chair of the CNCF Environmental Sustainability Technical Advisory Group and served 3 years at the Kubernetes release team. He runs the Munich Kubernetes Meetup as well as the Munich and Ukraine Kubernetes Community Days.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 class=&#34;wp-block-heading&#34; id=&#34;1356&#34;&gt;The state of KubeCon and the Cloud Native ecosystem&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;5d96&#34;&gt;What an amazing KubeCon we had at Salt Lake City! It was the largest KubeCon in North America after the Covid pandemic, hosting over 9,000 attendees.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;3ccf&#34;&gt;It was also amazing to see the hands raised when Chris Aniszczyk, the CTO of the CNCF, asked at the opening keynote who’s a first-timer, and half of the crowd raised their hands. Chris confirmed we have about 50% new folks. Stay tuned for the CNCF’s transparency report, as we always publish after these events.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;928&#34; height=&#34;786&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/11/image-18.jpg&#34; alt=&#34;Screenshot showing Linkedin message from Dotan&#34; class=&#34;wp-image-121742&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/11/image-18.jpg 928w, https://www.cncf.io/wp-content/uploads/2024/11/image-18-300x254.jpg 300w, https://www.cncf.io/wp-content/uploads/2024/11/image-18-768x650.jpg 768w, https://www.cncf.io/wp-content/uploads/2024/11/image-18-900x762.jpg 900w, https://www.cncf.io/wp-content/uploads/2024/11/image-18-236x200.jpg 236w, https://www.cncf.io/wp-content/uploads/2024/11/image-18-472x400.jpg 472w&#34; sizes=&#34;auto, (max-width: 928px) 100vw, 928px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;ebac&#34;&gt;This year’s KubeCon was also an opportunity to celebrate&amp;nbsp;&lt;a href=&#34;https://horovits.medium.com/kubernetes-turns-10-a-fireside-chat-with-kelsey-hightower-on-its-impact-and-future-475bbc7137a4&#34;&gt;a decade to Kubernetes&lt;/a&gt;, the project that started the CNCF and the cloud-native ecosystem. It’s astonishing to see how it has grown: at the time of this KubeCon we have&amp;nbsp;&lt;strong&gt;208 projects&lt;/strong&gt;&amp;nbsp;under the CNCF, run by&amp;nbsp;&lt;strong&gt;255k contributors&lt;/strong&gt;&amp;nbsp;from across&amp;nbsp;&lt;strong&gt;193 countries&lt;/strong&gt;. The&amp;nbsp;&lt;a href=&#34;https://landscape.cncf.io/&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;CNCF landscape&lt;/a&gt;&amp;nbsp;is getting crowded (so much so, that I started guiding people on&amp;nbsp;&lt;a href=&#34;https://www.youtube.com/watch?v=Fqm0yZif-ns&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;how to navigate the CNCF landscape&lt;/a&gt;&amp;nbsp;:-))&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;37f3&#34;&gt;Let’s look at some KubeCon news and highlights from these projects.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;d745&#34;&gt;Flatcar joins the CNCF: a cloud-native Linux OS&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;aa1c&#34;&gt;A new joiner to the CNCF is Flatcar. It’s actually the first time the CNCF has adopted an operating system distribution. As Chris Aniszczyk rightly put it: “A secure community-owned cloud native operating system was one of the missing layers of the CNCF technology stack”.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;992&#34; height=&#34;806&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/11/image-18-1.jpg&#34; alt=&#34;Screenshot showing Dotan linkedin post&#34; class=&#34;wp-image-121743&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/11/image-18-1.jpg 992w, https://www.cncf.io/wp-content/uploads/2024/11/image-18-1-300x244.jpg 300w, https://www.cncf.io/wp-content/uploads/2024/11/image-18-1-768x624.jpg 768w, https://www.cncf.io/wp-content/uploads/2024/11/image-18-1-900x731.jpg 900w, https://www.cncf.io/wp-content/uploads/2024/11/image-18-1-246x200.jpg 246w, https://www.cncf.io/wp-content/uploads/2024/11/image-18-1-492x400.jpg 492w&#34; sizes=&#34;auto, (max-width: 992px) 100vw, 992px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;107b&#34;&gt;Flatcar provides a lightweight Linux OS, derived from CoreOS, that is specifically tailored for hosting container workloads. Max says it has always been handing around, who’s going to take care of the project. He points out its value for platform engineers who look for the recommended golden image for their organization.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;25ef&#34;&gt;Viktor noted that while an important addition, it’s a low-level component to which end-users don’t get exposed and don’t really care, especially if running on managed Kubernetes like EKS and GKE.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;3e19&#34;&gt;A big kudos to the Kinvolk team that originally developed it, and to Microsoft for evolving it these past years since the acquisition and now contributing it to the CNCF Sandbox. For more details, check out the&amp;nbsp;&lt;a href=&#34;https://www.cncf.io/blog/2024/10/29/flatcar-brings-container-linux-to-the-cncf-incubator/&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;announcement&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;f7cf&#34;&gt;wasmCloud matures into incubation: WebAssembly at the CNCF&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;e514&#34;&gt;Alongside new projects joining the CNCF Sandbox, we see projects maturing from Sandbox to Incubation, one of which&amp;nbsp;&lt;a href=&#34;https://horovits.medium.com/wasmcloud-the-kubernetes-for-webassembly-02a5025c6115&#34;&gt;wasmCloud, the popular WebAssembly platfrom&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;a href=&#34;https://horovits.medium.com/wasmcloud-the-kubernetes-for-webassembly-02a5025c6115&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1378&#34; height=&#34;368&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/11/image-4-2.jpg&#34; alt=&#34;image&#34; class=&#34;wp-image-121349&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/11/image-4-2.jpg 1378w, https://www.cncf.io/wp-content/uploads/2024/11/image-4-2-300x80.jpg 300w, https://www.cncf.io/wp-content/uploads/2024/11/image-4-2-1024x273.jpg 1024w, https://www.cncf.io/wp-content/uploads/2024/11/image-4-2-768x205.jpg 768w, https://www.cncf.io/wp-content/uploads/2024/11/image-4-2-900x240.jpg 900w, https://www.cncf.io/wp-content/uploads/2024/11/image-4-2-600x160.jpg 600w, https://www.cncf.io/wp-content/uploads/2024/11/image-4-2-1200x320.jpg 1200w&#34; sizes=&#34;auto, (max-width: 1378px) 100vw, 1378px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;e35c&#34;&gt;I’ve noted in the past that&amp;nbsp;&lt;a href=&#34;https://horovits.medium.com/webassembly-the-next-frontier-in-cloud-native-evolution-eef0ff965716&#34;&gt;WebAssembly is the next frontier in cloud-native evolution&lt;/a&gt;, and wasmCloud is a cornerstone of this movement within the CNCF stack. The project has over a 100 regular contributors representing 73 unique companies.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;a6c3&#34;&gt;wasmCloud is deployed by major organizations such as Adobe, Orange, MachineMetrics, TM Forum member CSPs, and Akamai Technologies. It’s interesting to see the wide variety of use cases for wasmCloud out there, from industrial IoT and automotive to digital services and banking. Max notes in particular the talk by Siemens at wasmCon co-located event, in which their shared their use case for embedded development.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;4c47&#34;&gt;Viktor thinks that WASM isn’t here to replace containers, but rather provides its value alongside containers, with use cases such as edge computing. Max notes that if you run WASM in Kubernetes, it can practically leverage all the ecosystem of Kubernetes. For more on the wasmCloud maturation, check out the&amp;nbsp;&lt;a href=&#34;https://www.cncf.io/blog/2024/11/12/cncf-welcomes-wasmcloud-to-the-cncf-incubator/&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;announcement blog&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;8498&#34;&gt;Dapr and cert-manager reach CNCF graduation&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;0b69&#34;&gt;The highest maturity level in the CNCF is Graduation. This KubeCon we saw two important projects reaching graduation: Dapr and cert-manager.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;a48c&#34;&gt;Dapr, the Distributed Application Runtime project, has today 3,700 individual contributors from more than 400 organizations, which is a good testament to the project’s maturity and sustainability. It is used by tens of thousands of organizations, including Grafana Labs, FICO, HDFC Bank, SharperImage.com and ZEISS.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;0896&#34;&gt;There was a big graduation party with Dapr folks at Sale Lake City to celebrate this occasion. Congrats to Microsoft Azure team who founded it and are lead maintainers, to Diagrid who also leads it and all other maintainers and everyone involved. See the&amp;nbsp;&lt;a href=&#34;https://www.cncf.io/announcements/2024/11/12/cloud-native-computing-foundation-announces-dapr-graduation/&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;announcement post&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1400&#34; height=&#34;1412&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/11/image-18-2.jpg&#34; alt=&#34;Screenshot showing LinkedIn post from Dotan&#34; class=&#34;wp-image-121744&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/11/image-18-2.jpg 1400w, https://www.cncf.io/wp-content/uploads/2024/11/image-18-2-297x300.jpg 297w, https://www.cncf.io/wp-content/uploads/2024/11/image-18-2-1015x1024.jpg 1015w, https://www.cncf.io/wp-content/uploads/2024/11/image-18-2-150x150.jpg 150w, https://www.cncf.io/wp-content/uploads/2024/11/image-18-2-768x775.jpg 768w, https://www.cncf.io/wp-content/uploads/2024/11/image-18-2-900x908.jpg 900w, https://www.cncf.io/wp-content/uploads/2024/11/image-18-2-198x200.jpg 198w, https://www.cncf.io/wp-content/uploads/2024/11/image-18-2-397x400.jpg 397w&#34; sizes=&#34;auto, (max-width: 1400px) 100vw, 1400px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;0c5d&#34;&gt;Another critical component in our Kubernetes stack reaching graduation is cert-manager project. It is no wonder this project is graduated, as it’s pretty much the de-facto standard for issuance and renewal of TLS and mTLS certificates these days, and we tend to take it for granted. In fact, 86 percent of new production clusters are created with cert-manager deployed as standard practice!&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;28f8&#34;&gt;As we looked back at the times, a decade ago, when we could spend half a day setting certificates or failing clusters due to expired certificates, Viktor Max and I agreed it’s a bliss to have it baked in. See the&amp;nbsp;&lt;a href=&#34;https://www.cncf.io/announcements/2024/11/12/cloud-native-computing-foundation-announces-cert-manager-graduation/&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;announcement post&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;a href=&#34;https://horovits.medium.com/jaeger-v2-unveiled-distributed-tracing-powered-by-opentelemetry-be612dbee774&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1398&#34; height=&#34;362&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/11/image-4-3.jpg&#34; alt=&#34;link to Jaeger V2 article&#34; class=&#34;wp-image-121350&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/11/image-4-3.jpg 1398w, https://www.cncf.io/wp-content/uploads/2024/11/image-4-3-300x78.jpg 300w, https://www.cncf.io/wp-content/uploads/2024/11/image-4-3-1024x265.jpg 1024w, https://www.cncf.io/wp-content/uploads/2024/11/image-4-3-768x199.jpg 768w, https://www.cncf.io/wp-content/uploads/2024/11/image-4-3-900x233.jpg 900w, https://www.cncf.io/wp-content/uploads/2024/11/image-4-3-600x155.jpg 600w, https://www.cncf.io/wp-content/uploads/2024/11/image-4-3-1200x311.jpg 1200w&#34; sizes=&#34;auto, (max-width: 1398px) 100vw, 1398px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 class=&#34;wp-block-heading&#34; id=&#34;194c&#34;&gt;Jaeger and Prometheues play nicely with OpenTelemetry&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;9566&#34;&gt;The biggest news on the observability front were the major releases of two graduated projects:&amp;nbsp;&lt;a href=&#34;https://horovits.medium.com/jaeger-v2-unveiled-distributed-tracing-powered-by-opentelemetry-be612dbee774&#34;&gt;Jaeger v2&lt;/a&gt;&amp;nbsp;and&amp;nbsp;&lt;a href=&#34;https://horovits.medium.com/prometheus-3-0-unveiled-highlights-from-promcon-europe-2024-1c5edca32c87&#34;&gt;Prometheus v3&lt;/a&gt;. Interestingly, a clear silver lining goes through both these releases, and that’s OpenTelemetry.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;f61c&#34;&gt;Jaeger has been rearchitected to take advantage of the OpenTelemetry Collector framework, while Prometheus aims at becoming the de-facto backend for OpenTelemetry metrics. It’s wonderful to see the collaboration across these CNCF projects, driving for unified observability&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;9f5e&#34;&gt;On the OpenTelemetry side, we’ve shared during KubeCon the great work of the CI/CD Observability Special Interest Group (OTel CI/CD), which&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;923c&#34;&gt;For more information see the&amp;nbsp;&lt;a href=&#34;https://www.cncf.io/blog/2024/11/04/opentelemetry-is-expanding-into-ci-cd-observability/&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;CNCF blog&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;932&#34; height=&#34;788&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/11/image-18-3.jpg&#34; alt=&#34;Screenshot showing LinkedIn post from Dotan&#34; class=&#34;wp-image-121745&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/11/image-18-3.jpg 932w, https://www.cncf.io/wp-content/uploads/2024/11/image-18-3-300x254.jpg 300w, https://www.cncf.io/wp-content/uploads/2024/11/image-18-3-768x649.jpg 768w, https://www.cncf.io/wp-content/uploads/2024/11/image-18-3-900x761.jpg 900w, https://www.cncf.io/wp-content/uploads/2024/11/image-18-3-237x200.jpg 237w, https://www.cncf.io/wp-content/uploads/2024/11/image-18-3-473x400.jpg 473w&#34; sizes=&#34;auto, (max-width: 932px) 100vw, 932px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;af18&#34;&gt;In addition, OpenMetrics has been archived and merged into Prometheus, and is now embarking on OpenMetrics 2.0. A new working group has been founded under Prometheus, and its first focus will be requirements gathering and scoping of the 2.0. This is your opportunity to influence. You can read more in&amp;nbsp;&lt;a href=&#34;https://horovits.medium.com/openmetrics-is-archived-merged-into-prometheus-d555598d2d04&#34;&gt;this post&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;df2a&#34;&gt;Cloud Native reference architectures shared by CNCF end users&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;ed4d&#34;&gt;Alongside new projects, at the CNCF we look at how to help users design and architect their systems for the various use cases based on the cloud-native stack. The End User TAB (technical advisory board) is a forum to collect valuable end-user feedback and learnings.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;9cbf&#34;&gt;Under the TAB, the Reference Architecture working group was formed to collect references and provide practical guidance and examples for building cloud native applications, and has launched its first Reference Architectures — Scaling through Platform Engineering at&amp;nbsp;&lt;em&gt;Allianz Direct&lt;/em&gt;&amp;nbsp;and Scaling&amp;nbsp;&lt;em&gt;Adobe&lt;/em&gt;’s Service Delivery Foundation with a Cell-based Architecture.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;986&#34; height=&#34;836&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/11/image-18-4.jpg&#34; alt=&#34;Screenshot showing LinkedIn post from Dotan&#34; class=&#34;wp-image-121746&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/11/image-18-4.jpg 986w, https://www.cncf.io/wp-content/uploads/2024/11/image-18-4-300x254.jpg 300w, https://www.cncf.io/wp-content/uploads/2024/11/image-18-4-768x651.jpg 768w, https://www.cncf.io/wp-content/uploads/2024/11/image-18-4-900x763.jpg 900w, https://www.cncf.io/wp-content/uploads/2024/11/image-18-4-236x200.jpg 236w, https://www.cncf.io/wp-content/uploads/2024/11/image-18-4-472x400.jpg 472w&#34; sizes=&#34;auto, (max-width: 986px) 100vw, 986px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;aa23&#34;&gt;As a former systems architect, these real-life architecture patterns have often been a topic of my discussions at KubeCon and other community gatherings. I’m excited at this new initiative, as it facilitates this sort of discussion and enables the community to share design blueprints from large-scale production deployments in an organized fashion.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;99f1&#34;&gt;We now have a new dedicated CNCF sub-domain for that:&amp;nbsp;&lt;a href=&#34;https://architecture.cncf.io/&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;architecture.cncf.io&lt;/a&gt;. Bookmark it, as I expect to see more reference architectures added there over time. In fact, you can also submit your own reference architecture in that page, to share it with the world.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;451a&#34;&gt;That’s not all&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;358e&#34;&gt;What? no AI? don’t worry. On our hour-long fireside chat we covered artificial intelligence and machine learning, which have been a major theme this KubeCon, as well as platform engineering, environmental sustainability initiatives and many more topics.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;17b5&#34;&gt;Check out the full episode on&amp;nbsp;&lt;a href=&#34;https://www.youtube.com/watch?v=1TrPev5IzB8&amp;amp;list=PLd57eY2edRXz4djMETYTm-2p8WGTdoX3D&amp;amp;index=1&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;YouTube&lt;/a&gt;&amp;nbsp;or on&amp;nbsp;&lt;a href=&#34;https://creators.spotify.com/pod/show/openobservability/episodes/CNCF-Ambassadors-Share-the-Best-of-KubeCon-2024---OpenObservability-Talks-S5E06-e2rffal&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;OpenObservbability Talks&lt;/a&gt;&amp;nbsp;on all major podcast apps.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;a href=&#34;https://horovits.medium.com/?source=post_page---byline--1362959030c1---------------------- -----------&#34;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;大使帖子最初发布于 &lt;a href=&#34;https://horovits.medium.com/the-ultimate-kubecon-2024-recap-the-cncf-ambassadors-edition-1362959030c1&#34;&gt;Medium&lt;/ a&gt; 作者：Dotan Horovits&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading has-gray-300-background-color has-background&#34;&gt;​​&lt;em&gt;这是&lt;a href=&#34;https://community.cncf.io/events/详细信息/cncf-cncf-online-programs-presents-live-with-the-experts-cloud-native-ambassadors-share-the-best-of-kubecon-2024/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;CNCF 于 11 月 19 日举办的 KubeCon+CloudNativeCon NA 2024 直播回顾&lt;/a&gt;活动。&lt;/em&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“1600”高度=“900”src=“https://www.cncf.io/ wp-content/uploads/2024/11/Ambassadors-Unplugged-Twitter-Post-1.jpg&#34; alt=&#34;Ambassadors Unplugged：来自 KubeCon + CloudNativeCon 北美的见解2024 横幅&#34; class=&#34;wp-image-121352&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/11/Ambassadors-Unplugged-Twitter-Post-1.jpg 1600w, https://www.cncf.io/wp-content/uploads/2024/11/Ambassadors-Unplugged-Twitter-Post-1-300x169.jpg 300w，https://www.cncf.io/wp-content/uploads /2024/11/Ambassadors-Unplugged-Twitter-Post-1-1024x576.jpg 1024w, https://www.cncf.io/wp-content/uploads/2024/11/Ambassadors-Unplugged-Twitter-Post-1-768x432.jpg 768w，https://www.cncf.io/wp-content/uploads /2024/11/Ambassadors-Unplugged-Twitter-Post-1-900x506.jpg 900w, https://www.cncf.io/wp-content/uploads/2024/11/Ambassadors-Unplugged-Twitter-Post-1-356x200.jpg 356w，https://www.cncf.io/wp-content/uploads /2024/11/Ambassadors-Unplugged-Twitter-Post-1-711x400.jpg 711w&#34; 尺寸 = &#34;自动, （最大宽度：1600px）100vw，1600px“referrerpolicy =“no-referrer”&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;f9ea&#34;&gt;想要了解 KubeCon 的亮点和要点吗？借鉴对云原生领域了如指掌的专家——&lt;a href=&#34;https://www.cncf.io/people/ambassadors/&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;CNCF 大使的说法&lt;/a&gt;！&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;2d43&#34;&gt;我要感谢 KubeCon 背后的组织&lt;em&gt;云原生计算基金会 (CNCF)&lt;/em&gt; 邀请我主持其&lt;a href=&#34;https://community.cncf.io/events/details/cncf-cncf-online-programs-presents-live-with-the-experts-cloud-native-ambassadors-share-the-best-of-kubecon -2024/&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;KubeCon+CloudNativeCon 北美 2024 年官方回顾会议&lt;/a&gt;。 CNCF 托管 Kubernetes、Argo、Backstage、OpenTelemetry 以及我们了解和喜爱的 200 多个其他云原生项目。您可以在 &lt;a href=&#34;https://www.youtube.com/watch?v=WHT1CisdKEE&amp;list=PLj6h78yzYM2Pw4mRw4S 上的 &lt;em&gt;KubeCon + CloudNativeCon 盐湖城 2024&lt;/em&gt; 播放列表中找到会议的完整录制内容-1p_xLARMqPkA7&amp;index=310&amp;t=4s&#34; rel =“noreferrer noopener”目标=“_blan”k&#34;&gt;CNCF 官方 YouTube 频道&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;37ed&#34;&gt;在这次回顾会议中，我与 CNCF 大使和云原生专家一起坐下来&lt;a href=&#34;https://www.linkedin.com/in/viktorfarcic&#34; rel=&#34;noreferrer noopener&#34; target =&#34;_blank&#34;&gt;维克托·法西奇&lt;/a&gt;和&lt;a href=&#34;https://twitter.com/mkoerbi&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;Max Körbächer&lt;/a&gt; 解读盐湖城的主要项目公告和关键主题：杰出的演讲、同地举办的活动以及那些令人难忘的走廊对话。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;8fb4&#34;&gt;在这篇文章中，我将回顾一下长达一小时的精彩讨论。我们走吧！&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio&#34;&gt;&lt;div class=&#34; wp-block-embed__wrapper&#34;&gt;&#xA;&lt;iframe loading=&#34;lazy&#34; title=&#34;与专家一起生活！CNCF 大使和 KubeCon 的精华&#34; width=&#34;500&#34; height=&#34;281&#34; src=&#34;https://www.youtube.com/embed/WHT1CisdKEE? start = 7＆feature = oembed“frameborder =”0“允许”剪贴板写入;网络共享; referrerpolicy=&#34;no-referrer&#34;allowfullscreen=&#34;&#34;&gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&lt;/图&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;2e92&#34;&gt;专家小组：Viktor Farcic 和 Max Körbächer&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;37d5&#34;&gt;Viktor Farcic 是 &lt;a href=&#34;https://www.upbound.io/&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;Upbound&lt;/a&gt; 的主要 rapscallion，并且是发表的作者。他是 YouTube 频道 &lt;a href=&#34;https://www.youtube.com/c/devopstoolkit&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;DevOps Toolkit&lt;/a&gt; 的主持人和联合主持人&lt;a href=&#34;https://www.youtube.com/c/DevOpsParadox&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;DevOps 悖论&lt;/a&gt;。或者正如他自我介绍的那样：“跨平面家伙”。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;0b0e&#34;&gt;Max Körbächer 是 &lt;a href=&#34;https://www.reply.com/liquid-reply/en/&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;Liquid 联合创始人回复&lt;/a&gt;。他是 CNCF 环境可持续发展技术咨询小组的联合主席，并在 Kubernetes 发布团队工作了 3 年。他负责举办慕尼黑 Kubernetes 聚会以及慕尼黑和乌克兰 Kubernetes 社区日。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 class=&#34;wp-block-heading&#34; id=&#34;1356&#34;&gt;KubeCon 和云原生生态系统的状态&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;5d96&#34;&gt;我们在盐湖城举办的 KubeCon 真是太棒了！这是 Covid 大流行后北美最大的 KubeCon，接待了 9,000 多名与会者。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;3ccf&#34;&gt;当 CNCF 首席技术官 Chris Aniszczyk 在开幕主题演讲中询问谁是第一次参加时，一半的观​​众举起了手，这也令人惊讶。 Chris 确认我们大约有 50% 的新员工。请继续关注 CNCF 的透明度报告，因为我们总是在这些活动之后发布。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“928”高度=“786”src=“https://www.cncf.io/ wp-内容/上传/2024/11/image-18.jpg&#34; alt=&#34;显示来自 Dotan 的 Linkedin 消息的屏幕截图&#34; class=&#34;wp-image-121742&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/ 11/image-18.jpg 928w, https://www.cncf.io/wp-content/uploads/2024/11/image-18-300x254.jpg 300w，https://www.cncf.io/wp-content/uploads/2024/11/image -18-768x650.jpg 768w, https://www.cncf.io/wp-content/uploads/2024/11/image-18-900x762.jpg 900w，https://www.cncf.io/wp-content/uploads/2024/11/image -18-236x200.jpg 236w, https://www.cncf.io/wp-content/uploads/2024/11/image-18-472x400.jpg 472w“尺寸=”自动，（最大宽度：928px）100vw，928px“referrerpolicy=”无-推荐人&#34;&gt;&lt;/图&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;ebac&#34;&gt;今年的 KubeCon 也是一个庆祝&lt;a href=&#34;https://horovits.medium.com/kubernetes-turns-10-a-fireside-chat-with-kelsey-hightower- on-its-impact-and-future-475bbc7137a4&#34;&gt;Kubernetes 十年&lt;/a&gt;，该项目启动了 CNCF 和云原生生态系统。它的发展速度令人惊讶：在本次 KubeCon 上，CNCF 下有&lt;strong&gt;208 个项目&lt;/strong&gt;，由来自&lt;strong&gt;193 个国家/地区的&lt;strong&gt;25.5 万贡献者&lt;/strong&gt;运营强&gt;。 &lt;a href=&#34;https://landscape.cncf.io/&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;CNCF 景观&lt;/a&gt;变得越来越拥挤（以至于我开始引导人们&lt; a href=&#34;https://www.youtube.com/watch?v=Fqm0yZif-ns&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;如何浏览 CNCF风景&lt;/a&gt; :-))&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;37f3&#34;&gt;让我们看看这些项目的一些 KubeCon 新闻和亮点。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;d745&#34;&gt;Flatcar 加入 CNCF：云原生 Linux 操作系统&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;aa1c&#34;&gt;CNCF 的新成员是 Flatcar。这实际上是 CNCF 第一次采用操作系统发行版。正如 Chris Aniszczyk 正确指出的那样：“社区拥有的安全云原生操作系统是 CNCF 技术堆栈中缺失的层之一”。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“992”高度=“806”src=“https://www.cncf.io/ wp-content/uploads/2024/11/image-18-1.jpg&#34; alt=&#34;显示 Dotan linkedin 帖子的屏幕截图&#34; class=&#34;wp-image-121743&#34; srcset =“https://www.cncf.io/wp-content/uploads/2024/11/image-18-1.jpg 992w，https://www.cncf.io/wp-content/uploads/2024/ 11/image-18-1-300x244.jpg 300w, https://www.cncf.io/wp-content/uploads/2024/11/image-18-1-768x624.jpg 768w，https://www.cncf.io/wp-content/uploads/2024/11 /image-18-1-900x731.jpg 900w, https://www.cncf.io/wp-content/uploads/2024/11/image-18-1-246x200.jpg 246w，https://www.cncf.io/wp-content/uploads/2024/11 /image-18-1-492x400.jpg 492w“尺寸=”自动，（最大宽度：992px）100vw， 992px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;107b&#34;&gt;Flatcar 提供了一个源自 CoreOS 的轻量级 Linux 操作系统，专为托管容器工作负载而定制。马克斯说，它一直在交接，谁来照顾这个项目。他指出了它对于为其组织寻找推荐的黄金映像的平台工程师的价值。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;25ef&#34;&gt;Viktor 指出，虽然这是一个重要的补充，但它是一个低级组件，最终用户不会接触到也不会真正关心，特别是在 EKS 和 GKE 等托管 Kubernetes 上运行时。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;3e19&#34;&gt;非常感谢最初开发它的 Kinvolk 团队，也感谢 Microsoft 自收购以来在过去几年中不断发展它，现在将其贡献给 CNCF 沙盒。有关更多详细信息，请查看 &lt;a href=&#34;https://www.cncf.io/blog/2024/10/29/flatcar-brings-container-linux-to-the-cncf-incubator/&#34; rel=&#34; noreferrer noopener&#34; target=&#34;_blank&#34;&gt;公告&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;f7cf&#34;&gt;wasmCloud 成熟并进入孵化阶段：CNCF 的 WebAssembly&lt;/h2​​&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;e514&#34;&gt;除了加入 CNCF 沙盒的新项目之外，我们还看到项目从沙盒走向孵化，其中之一&lt;a href=&#34;https://horovits.medium.com/wasmcloud-the-kubernetes-for -web assembly-02a5025c6115&#34;&gt;wasmCloud，流行的 WebAssembly 平台&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;a href=&#34;https://horovits.medium.com/wasmcloud-the-kubernetes-for-web assembly-02a5025c6115&#34;&gt;&lt;img loading=&#34;lazy&#34;解码=“异步”宽度=“1378”高度=“368” src =“https://www.cncf.io/wp-content/uploads/2024/11/image-4-2.jpg”alt =“图像”class =“wp-image-121349”srcset =“https： //www.cncf.io/wp-content/uploads/2024/11/image-4-2.jpg 1378w， https://www.cncf.io/wp-content/uploads/2024/11/image-4-2-300x80.jpg 300w，https://www.cncf.io/wp-content/uploads/2024/11 /image-4-2-1024x273.jpg 1024w, https://www.cncf.io/wp-content/uploads/2024/11/image-4-2-768x205.jpg 768w，https://www.cncf.io/wp-content/uploads/2024/11 /image-4-2-900x240.jpg 900w, https://www.cncf.io/wp-content/uploads/2024/11/image-4-2-600x160.jpg 600w，https://www.cncf.io/wp-content/uploads/2024/11 /image-4-2-1200x320.jpg 1200w“尺寸=”自动，（最大宽度：1378px） 100vw，1378px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;e35c&#34;&gt;我过去曾注意到&lt;a href=&#34;https://horovits.medium.com/web assembly-the-next-frontier-in-cloud-native-evolution-eef0ff965716&#34;&gt; WebAssembly 是云原生演进的下一个前沿&lt;/a&gt;，而 wasmCloud 是 CNCF 堆栈中这一运动的基石。该项目有超过 100 名定期贡献者，代表 73 家独特的公司。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;a6c3&#34;&gt;wasmCloud 由 Adob​​e、Orange、MachineMetrics、TM 论坛成员 CSP 和 Akamai Technologies 等主要组织部署。有趣的是，看到 wasmCloud 的广泛用例，从工业物联网和汽车到数字服务和银行业。 Max 特别注意到西门子在 wasmCon 同期活动中的演讲，其中他们分享了嵌入式开发的用例。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;4c47&#34;&gt;Viktor 认为 WASM 并不是为了取代容器，而是通过用例与容器一起提供其价值例如边缘计算。 Max 指出，如果您在 Kubernetes 中运行 WASM，它实际上可以利用 Kubernetes 的所有生态系统。有关 wasmCloud 成熟度的更多信息，请查看 &lt;a href=&#34;https://www.cncf.io/blog/2024/11/12/cncf-welcomes-wasmcloud-to-the-cncf-incubator/&#34; rel= “noreferrer noopener” target=&#34;_blank&#34;&gt;公告博客&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;8498&#34;&gt;Dapr 和 cert-manager 获得 CNCF 毕业&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;0b69&#34;&gt;CNCF 的最高成熟度级别是毕业。这次 KubeCon 我们看到两个重要的项目即将毕业：Dapr 和 cert-manager。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;a48c&#34;&gt;Dapr 是分布式应用程序运行时项目，目前拥有来自 400 多个组织的 3,700 名个人贡献者，这很好地证明了该项目的成熟度和可持续性。它被数以万计的组织使用，包括 Grafana Labs、FICO、HDFC Bank、SharperImage.com 和 ZEISS。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;0896&#34;&gt;Dapr 人员在塞尔湖城举办了一场盛大的毕业派对来庆祝这一时刻。祝贺创建它并担任首席维护人员的 Microsoft Azure 团队、领导它的 Diagrid 以及所有其他维护人员和所有参与者。请参阅&lt;a href=&#34;https://www.cncf.io/announcements/2024/11/12/cloud-native-computing-foundation-announces-dapr-graduation/&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank &#34;&gt;公告帖子&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“1400”高度=“1412”src=“https://www.cncf.io/ wp-content/uploads/2024/11/image-18-2.jpg&#34; alt=&#34;显示 Dotan 的 LinkedIn 帖子的屏幕截图&#34; class=&#34;wp-image-121744&#34; srcset =“https://www.cncf.io/wp-content/uploads/2024/11/image-18-2.jpg 1400w，https://www.cncf.io/wp-content/uploads/2024/ 11/image-18-2-297x300.jpg 297w, https://www.cncf.io/wp-content/uploads/2024/11/image-18-2-1015x1024.jpg 1015w，https://www.cncf.io/wp-content/uploads/2024/11 /image-18-2-150x150.jpg 150w, https://www.cncf.io/wp-content/uploads/2024/11/image-18-2-768x775.jpg 768w，https://www.cncf.io/wp-content/uploads/2024/11 /image-18-2-900x908.jpg 900w, https://www.cncf.io/wp-content/uploads/2024/11/image-18-2-198x200.jpg 198w，https://www.cncf.io/wp-content/uploads/2024/11 /image-18-2-397x400.jpg 397w“尺寸=”自动，（最大宽度：1400px） 100vw，1400px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;0c5d&#34;&gt;我们 Kubernetes 堆栈中即将毕业的另一个关键组件是 cert-manager 项目。难怪这个项目已经毕业，因为它几乎是当今 TLS 和 mTLS 证书颁发和续订的事实上的标准，我们倾向于认为这是理所当然的。事实上，86% 的新生产集群都是通过标准实践部署的 cert-manager 创建的！&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;28f8&#34;&gt;当我们回顾十年前的时代时，我们可能会花半天时间来设置证书或因证书过期而导致集群失败，Viktor Max 和我一致认为，将其融入其中是一种幸福参见;&lt;a href=&#34;https://www.cncf.io/announcements/2024/11/12/cloud-native-computing-foundation-announces-cert-manager-graduation/&#34; rel=&#34;noreferrer noopener&#34; target=&#34; _blank&#34;&gt;公告帖子&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;a href=&#34;https://horovits.medium.com/jaeger-v2-unveiled-distributed-tracing-powered-by-opentelemetry-be612dbee774&#34;&gt;&lt; img 加载=“惰性”解码=“异步”宽度=“1398”高度=“362” src=&#34;https://www.cncf.io/wp-content/uploads/2024/11/image-4-3.jpg&#34; alt=&#34;Jaeger V2 文章链接&#34; class=&#34;wp-image-121350&#34; srcset =“https://www.cncf.io/wp-content/uploads/2024/11/image-4-3.jpg 1398w， https://www.cncf.io/wp-content/uploads/2024/11/image-4-3-300x78.jpg 300w，https://www.cncf.io/wp-content/uploads/2024/11 /image-4-3-1024x265.jpg 1024w, https://www.cncf.io/wp-content/uploads/2024/11/image-4-3-768x199.jpg 768w，https://www.cncf.io/wp-content/uploads/2024/11 /image-4-3-900x233.jpg 900w, https://www.cncf.io/wp-content/uploads/2024/11/image-4-3-600x155.jpg 600w，https://www.cncf.io/wp-content/uploads/2024/11 /image-4-3-1200x311.jpg 1200w“尺寸=”自动，（最大宽度：1398px） 100vw，1398px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 class=&#34;wp-block-heading&#34; id=&#34;194c&#34;&gt;Jaeger 和 Prometheues 与 OpenTelemetry 配合得很好&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;9566&#34;&gt;可观测性方面的最大新闻是两个毕业项目的主要版本：&lt;a href=&#34;https://horovits.medium.com/jaeger-v2-unveiled-distributed-tracing-powered -by-opentelemetry-be612dbee774&#34;&gt;Jaeger v2&lt;/a&gt; 和 &lt;a href=&#34;https://horovits.medium.com/prometheus-3-0-unveiled-highlights-from-promcon-europe-2024-1c5edca32c87&#34;&gt;普罗米修斯 v3&lt;/a&gt;。有趣的是，这两个版本都有一个明显的一线希望，那就是 OpenTelemetry。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;f61c&#34;&gt;Jaeger 已重新架构，以利用 OpenTelemetry Collector 框架，而 Prometheus 旨在成为 OpenTelemetry 指标事实上的后端。很高兴看到这些 CNCF 项目之间的协作，推动统一的可观察性&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;9f5e&#34;&gt;在 OpenTelemetry 方面，我们在 KubeCon 期间分享了 CI/CD 可观测性特别兴趣小组 (OTel CI/CD) 的出色工作，&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;923c&#34;&gt;如需了解更多信息，请参阅&lt;a href=&#34;https://www.cncf.io/blog/2024/11/04/opentelemetry-is-expanding-into-ci-cd-observability/ “ rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;CNCF 博客&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“932”高度=“788”src=“https://www.cncf.io/ wp-content/uploads/2024/11/image-18-3.jpg&#34; alt=&#34;显示 Dotan 的 LinkedIn 帖子的屏幕截图&#34; class=&#34;wp-image-121745&#34; srcset =“https://www.cncf.io/wp-content/uploads/2024/11/image-18-3.jpg 932w，https://www.cncf.io/wp-content/uploads/2024/ 11/image-18-3-300x254.jpg 300w, https://www.cncf.io/wp-content/uploads/2024/11/image-18-3-768x649.jpg 768w，https://www.cncf.io/wp-content/uploads/2024/11 /image-18-3-900x761.jpg 900w，https://www.cncf.io/wp-content/uploads/2024/11/image-18-3-237x200.jpg 237w，https://www.cncf.io/wp-content/uploads/2024/11/image-18-3-473x400.jpg 473w&#34;尺寸=“自动，（最大宽度：932px）100vw，932px” referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;af18&#34;&gt;此外，OpenMetrics已经归档并合并到Prometheus中，现在正在着手OpenMetrics 2.0。 Prometheus 下成立了一个新的工作组，其首要重点是收集需求并确定 2.0 的范围。这是你发挥影响力的机会。您可以在&lt;a href=&#34;https://horovits.medium.com/openmetrics-is-archived-merged-into-prometheus-d555598d2d04&#34;&gt;这篇文章&lt;/a&gt;中了解更多信息。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;df2a&#34;&gt;CNCF 最终用户共享的云原生参考架构&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;ed4d&#34;&gt;除了新项目之外，在 CNCF，我们还研究如何帮助用户基于云原生堆栈针对各种用例设计和构建他们的系统。最终用户 TAB（技术咨询委员会）是一个收集有价值的最终用户反馈和学习的论坛。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;9cbf&#34;&gt;在 TAB 下，成立了参考架构工作组，以收集参考资料并为构建云原生应用程序提供实用指导和示例，并在 &lt;em&gt; 推出了第一个参考架构 - 通过平台工程进行扩展Allianz Direct&lt;/em&gt; 和通过基于单元的架构扩展 &lt;em&gt;Adobe&lt;/em&gt; 的服务交付基础。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“986”高度=“836”src=“https://www.cncf.io/ wp-content/uploads/2024/11/image-18-4.jpg&#34; alt=&#34;显示 Dotan 的 LinkedIn 帖子的屏幕截图&#34; class=&#34;wp-image-121746&#34; srcset =“https://www.cncf.io/wp-content/uploads/2024/11/image-18-4.jpg 986w，https://www.cncf.io/wp-content/uploads/2024/ 11/image-18-4-300x254.jpg 300w, https://www.cncf.io/wp-content/uploads/2024/11/image-18-4-768x651.jpg 768w，https://www.cncf.io/wp-content/uploads/2024/11 /image-18-4-900x763.jpg 900w, https://www.cncf.io/wp-content/uploads/2024/11/image-18-4-236x200.jpg 236w，https://www.cncf.io/wp-content/uploads/2024/11 /image-18-4-472x400.jpg 472w“尺寸=”自动，（最大宽度：986px）100vw， 986px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;aa23&#34;&gt;作为一名前系统架构师，这些现实生活中的架构模式经常成为我在 KubeCon 和其他社区聚会上讨论的主题。我对这项新举措感到兴奋，因为它促进了此类讨论，并使社区能够以有组织的方式共享大规模生产部署的设计蓝图。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;99f1&#34;&gt;我们现在有一个新的专用 CNCF 子域：&lt;a href=&#34;https://architecture.cncf.io/&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;architecture .cncf.io&lt;/a&gt;。将其添加为书签，因为我希望随着时间的推移会看到更多的参考架构被添加到其中。事实上，您还可以在该页面提交您自己的参考架构，与全世界分享。&lt;/p&gt;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;451a&#34;&gt;这还不是全部&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;358e&#34;&gt;什么？没有人工智能？不用担心。在长达一小时的炉边聊天中，我们讨论了人工智能和机器学习（这一直是 KubeCon 的主要主题），以及平台工程、环境可持续发展计划和更多主题。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;17b5&#34;&gt;在 &lt;a href=&#34;https://www.youtube.com/watch?v=1TrPev5IzB8&amp;list=PLd57eY2edRXz4djMETYTm-2p8WGTdoX3D&amp;index=1&#34; rel=&#34;noreferrer noopener&#34; target=&#34; 上观看完整剧集_blank&#34;&gt;YouTube&lt;/a&gt; 或 &lt;a href=&#34;https://creators.spotify.com/pod/show/openobservability/episodes/CNCF-Ambassadors-Share-the-Best-of-KubeCon-2024---OpenObservability-Talks-S5E06-e2rffal&#34; rel=&#34; noreferrer noopener&#34; target=&#34;_blank&#34;&gt;OpenObservbability Talks&lt;/a&gt; 针对所有主要播客应用。&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Mon, 25 Nov 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【AWS CloudWatch metrics explained: how to monitor and optimize your cloud resources?】AWS CloudWatch 指标解释：如何监控和优化您的云资源？</title>
      <link>https://www.cncf.io/blog/2024/12/02/aws-cloudwatch-metrics-explained-how-to-monitor-and-optimize-your-cloud-resources/</link>
      <description>【&lt;p&gt;&lt;em&gt;Member post originally published on the &lt;a href=&#34;https://middleware.io/blog/aws-cloudwatch-metrics-explained-how-to-monitor-and-optimize-your-cloud-resources/&#34;&gt;Middleware blog&lt;/a&gt; by &lt;a href=&#34;https://middleware.io/blog/authors/sanjay/&#34;&gt;Sanjay Suthar&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As your&amp;nbsp;&lt;a href=&#34;https://middleware.io/solutions/aws/&#34;&gt;AWS&lt;/a&gt;&amp;nbsp;environment expands—whether in terms of resources, the number of services, or even the scale of your team—managing these elements becomes increasingly challenging. With multiple instances, databases, and services running concurrently, maintaining an organized overview can quickly become overwhelming.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This growth often makes it difficult to know if every component is functioning optimally and delivering the expected performance. In an ideal scenario, you’d have a system that not only monitors each part of your&amp;nbsp;&lt;a href=&#34;https://middleware.io/blog/what-is-infrastructure-monitoring/&#34;&gt;infrastructure&lt;/a&gt;&amp;nbsp;but also provides real-time insights, ensuring everything runs as smoothly as intended.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This is where&amp;nbsp;&lt;a href=&#34;https://middleware.io/blog/analyze-aws-cloudwatch-resources/&#34;&gt;AWS CloudWatch&lt;/a&gt;&amp;nbsp;comes into play. AWS CloudWatch serves as your essential tool for monitoring, analyzing, and acting on key metrics, not only within your AWS environment but also for external applications and services running on-premises or in other cloud platforms. It offers valuable insights into how each AWS service is performing, helping you manage and fine-tune your resources effectively.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The purpose of this guide is to provide clear, actionable guidance on using CloudWatch metrics to maintain a&amp;nbsp;&lt;a href=&#34;https://middleware.io/blog/aws-monitoring/&#34;&gt;well-monitored AWS environment&lt;/a&gt;. From configuring alarms to utilizing advanced features like CloudWatch’s custom dashboards, we’ll explore everything CloudWatch offers to keep your infrastructure running at its best.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;understanding-aws-cloudwatch&#34;&gt;Understanding AWS CloudWatch&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;AWS CloudWatch goes beyond basic monitoring—it’s a comprehensive service that helps you gain deep insights into your AWS infrastructure.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;One of CloudWatch’s core strengths is its ability to gather data from a wide range of sources, including AWS services and external applications. Whether you’re monitoring the performance of your EC2 instances, tracking&amp;nbsp;&lt;a href=&#34;https://middleware.io/blog/top-ways-to-prevent-database-failures/&#34;&gt;database&lt;/a&gt;&amp;nbsp;connections in RDS, following Lambda invocations, or collecting metrics from on-premises servers and third-party services via&amp;nbsp;&lt;a href=&#34;https://middleware.io/blog/what-is-opentelemetry/&#34;&gt;OpenTelemetry&lt;/a&gt;, CloudWatch consolidates all these metrics, giving you a centralized view of your entire infrastructure.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Beyond simply collecting&amp;nbsp;&lt;a href=&#34;https://middleware.io/blog/devops-metrics-you-should-be-monitoring/&#34;&gt;metrics&lt;/a&gt;, CloudWatch offers an&amp;nbsp;&lt;a href=&#34;https://middleware.io/platform/alerts/&#34;&gt;alerting&lt;/a&gt;&amp;nbsp;feature. You can set up alarms that notify you when certain thresholds are reached, allowing you to respond to potential issues before they escalate.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;These features give you more control and understanding of your AWS environment, offering the insights needed to troubleshoot problems as they occur and maintain a well-functioning infrastructure.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;the-importance-of-cloudwatch-metrics-in-aws-resource-management&#34;&gt;The importance of CloudWatch metrics in AWS resource management&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;CloudWatch metrics are essential because they provide live data on how both your AWS and non-AWS resources are performing. They help you monitor various aspects of your infrastructure, giving you insights into resource usage and potential problem areas.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For example, metrics like&amp;nbsp;&lt;strong&gt;CPU Utilization&lt;/strong&gt;&amp;nbsp;in EC2 instances, provided by CloudWatch, indicate when a server is experiencing high demand. This can signal the need to either scale up your resources or redistribute traffic to avoid any slowdowns. Similarly,&amp;nbsp;&lt;strong&gt;Freeable Memory&lt;/strong&gt;&amp;nbsp;for RDS, which is tracked by CloudWatch, helps you determine if your database instance requires resizing to handle your workloads more effectively.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;CloudWatch is also valuable for&amp;nbsp;&lt;a href=&#34;https://middleware.io/blog/reduce-observability-costs/&#34;&gt;managing costs&lt;/a&gt;. By examining usage patterns, you might notice that certain instances are consistently running at a fraction of their capacity. For example, if you see that an EC2 instance’s CPU usage never exceeds 10%, it might be an indicator that you’re over-provisioned, and you could switch to a smaller instance type to save on costs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In comparison to other cloud platforms, AWS CloudWatch stands out with its seamless integration with the entire AWS ecosystem. For instance, Google Cloud uses&amp;nbsp;&lt;a href=&#34;https://middleware.io/blog/cloud-monitoring-tools/&#34;&gt;&lt;strong&gt;Cloud Monitoring&lt;/strong&gt;&lt;/a&gt;, and Azure has&amp;nbsp;&lt;strong&gt;Azure Monitor&lt;/strong&gt;—both effective tools but lacks the level of integration CloudWatch offers with AWS-specific services. This tight integration means CloudWatch not only monitors but can also trigger actions (like Auto Scaling) based on the metrics it tracks, making it a more cohesive option for managing AWS resources.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;how-aws-cloudwatch-works&#34;&gt;How AWS CloudWatch works&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;AWS CloudWatch functions by collecting metrics,&amp;nbsp;&lt;a href=&#34;https://middleware.io/blog/what-is-log-monitoring/&#34;&gt;logs&lt;/a&gt;, and events from various sources, including AWS services like EC2, RDS, and Lambda, as well as from on-premises servers, external cloud services, and applications instrumented with OpenTelemetry. These metrics are gathered and made accessible, allowing you to monitor performance and set alarms based on specific thresholds across your entire infrastructure.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Think of CloudWatch as a monitoring hub for your AWS infrastructure. It captures data from different services and translates it into actionable insights, which you can then visualize through dashboards or use to trigger automated actions.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For instance, you can customize CloudWatch Dashboards to display metrics that are crucial for your organization’s operations, such as CPU utilization for EC2 instances or request counts for a load balancer. Alarms can be set to notify you when these metrics reach predefined thresholds. These alarms can also initiate automated responses, like scaling an Auto Scaling group or executing a Lambda function, ensuring that your infrastructure responds promptly to changing conditions without requiring manual intervention.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;core-metrics-to-monitor-in-aws-cloudwatch&#34;&gt;Core metrics to monitor in AWS CloudWatch&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;When&amp;nbsp;&lt;a href=&#34;https://middleware.io/blog/proactive-monitoring/&#34;&gt;monitoring your environment&lt;/a&gt;, whether it’s on AWS or beyond, several key metrics provide valuable insights into the performance and health of your services. While the metrics mentioned here are essential, always remember that the importance of metrics can vary based on your specific AWS setup and workloads.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;EC2 Metrics&lt;/strong&gt;: Monitor&amp;nbsp;&lt;strong&gt;CPU Utilization&lt;/strong&gt;&amp;nbsp;and&amp;nbsp;&lt;strong&gt;Disk Read Ops&lt;/strong&gt;&amp;nbsp;to evaluate how well your instances are handling workloads. Consistent high CPU utilization might indicate the need for scaling, while spikes in Disk Read Ops can highlight potential bottlenecks in data access.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;RDS Metrics&lt;/strong&gt;: Pay close attention to&amp;nbsp;&lt;strong&gt;Database Connections&lt;/strong&gt;&amp;nbsp;and&amp;nbsp;&lt;strong&gt;Freeable Memory&lt;/strong&gt;. These metrics help you understand how your databases are performing and whether they need resizing or optimization to prevent issues like connection throttling.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Lambda Metrics&lt;/strong&gt;: Track&amp;nbsp;&lt;strong&gt;Invocations&lt;/strong&gt;&amp;nbsp;and&amp;nbsp;&lt;strong&gt;Errors&lt;/strong&gt;&amp;nbsp;to measure how effectively your serverless functions are executing. Sudden increases in errors can indicate problems with your code or triggers.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;EKS Metrics&lt;/strong&gt;: Since EKS often contributes significantly to AWS bills, monitoring&amp;nbsp;&lt;strong&gt;CPU and Memory Utilization per Pod&lt;/strong&gt;,&amp;nbsp;&lt;strong&gt;Cluster Node Capacity&lt;/strong&gt;, and&amp;nbsp;&lt;strong&gt;Request Latencies&lt;/strong&gt;&amp;nbsp;is crucial. These metrics help ensure your Kubernetes clusters are running efficiently and that workloads are evenly distributed across your pods.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;CloudWatch allows you to create custom dashboards that visualize these metrics, offering a clear view of your services’ performance and enabling you to quickly identify and address any issues. This comprehensive monitoring ensures that your infrastructure is functioning as expected, reducing the chances of unexpected downtimes or performance degradations.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;hands-on:-creating-and-using-cloudwatch-alarms&#34;&gt;Hands-on: Creating and using CloudWatch alarms&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Monitoring an EC2 instance using CloudWatch helps you keep track of how well your server is handling workloads and enables you to quickly identify and resolve potential issues such as high CPU usage or network traffic. Here’s a comprehensive, step-by-step guide on how to set this up:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://middleware.io/wp-content/uploads/2024/10/AWS-3-1024x534.png&#34; alt=&#34;AWS CloudWatch Metrics: Creating and using CloudWatch alarms&#34; class=&#34;wp-image-8230&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-launch-your-ec2-instance&#34;&gt;Launch your EC2 Instance&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Start by logging in to the&amp;nbsp;&lt;strong&gt;AWS Management Console&lt;/strong&gt;&amp;nbsp;and navigating to the&amp;nbsp;&lt;strong&gt;EC2&lt;/strong&gt;&amp;nbsp;service.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Click on&amp;nbsp;&lt;strong&gt;Launch Instance&lt;/strong&gt;&amp;nbsp;and follow the setup process:&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Choose an Amazon Machine Image (AMI)&lt;/strong&gt;: Select the appropriate AMI, such as Amazon Linux 2 or Ubuntu.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Instance Type&lt;/strong&gt;: Choose the instance type that fits your workload, e.g., t2.micro (eligible for the free tier).&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Configure Instance Details&lt;/strong&gt;:&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Scroll down to the&amp;nbsp;&lt;strong&gt;Monitoring&lt;/strong&gt;&amp;nbsp;section and enable the&amp;nbsp;&lt;strong&gt;Detailed Monitoring&lt;/strong&gt;&amp;nbsp;checkbox. This option ensures that CloudWatch collects data at 1-minute intervals instead of the default 5-minute intervals, which is essential for catching any sudden spikes in resource usage.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://middleware.io/wp-content/uploads/2024/10/AWS-4.png&#34; alt=&#34;AWS CloudWatch Metrics: Launch your EC2 Instance&#34; class=&#34;wp-image-8231&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Once your EC2 instance is running, you can proceed to monitor it using CloudWatch.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-access-cloudwatch-from-the-aws-console&#34;&gt;Access CloudWatch from the AWS Console&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;After launching your instance, go to the&amp;nbsp;&lt;strong&gt;AWS Management Console&lt;/strong&gt;&amp;nbsp;and open&amp;nbsp;&lt;strong&gt;CloudWatch&lt;/strong&gt;&amp;nbsp;from the list of services. This is your main hub for tracking all the metrics related to your EC2 instance’s performance.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-viewing-metrics-for-your-ec2-instance&#34;&gt;Viewing metrics for your EC2 Instance&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;In CloudWatch, go to the&amp;nbsp;&lt;strong&gt;Metrics&lt;/strong&gt;&amp;nbsp;section and select&amp;nbsp;&lt;strong&gt;EC2&lt;/strong&gt;.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Click on&amp;nbsp;&lt;strong&gt;Per-Instance Metrics&lt;/strong&gt;&amp;nbsp;to view a list of metrics for your instance.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Select your instance to see live data for metrics like CPU utilization, network traffic, and disk activity.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://middleware.io/wp-content/uploads/2024/10/AWS-5-1024x536.png&#34; alt=&#34;AWS CloudWatch Metrics: Viewing metrics for your EC2 Instance&#34; class=&#34;wp-image-8232&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-understanding-key-metrics-to-monitor&#34;&gt;Understanding key metrics to monitor&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;CloudWatch offers a variety of metrics for EC2 instances, but let’s focus on the most important ones:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;CPU Utilization&lt;/strong&gt;: This metric indicates the percentage of CPU capacity currently in use. For example, if you notice consistent high CPU usage (e.g., above 80%), it may indicate that your instance is struggling with the workload, and you might need to consider upgrading your instance type or optimizing your applications to handle the load more efficiently.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;NetworkIn / NetworkOut&lt;/strong&gt;: These metrics track the volume of data being received and transmitted by your instance. High values here could indicate&amp;nbsp;&lt;a href=&#34;https://middleware.io/customers/hotplate/&#34;&gt;increased traffic&lt;/a&gt;, which may be normal during peak periods, or unexpected activity if there’s a sudden spike. Monitoring these metrics helps you understand if your&amp;nbsp;&lt;a href=&#34;https://content.techgig.com/expert-opinion/why-is-monitoring-your-application-important/articleshow/105003258.cms&#34;&gt;application&lt;/a&gt;&amp;nbsp;is experiencing heavy traffic or if there’s a potential issue, such as unauthorized data access.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Disk Read Ops / Disk Write Ops&lt;/strong&gt;: These metrics show how often your instance reads from or writes to the disk. For instance, Disk Read Ops represents read operations, and Disk Write Ops represents write operations. High values might mean that your application is heavily interacting with data stored on the disk, which can cause slower response times if not managed properly. If your instance is running a database, for example, a spike in these metrics might indicate an increase in read/write queries.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-setting-up-alarms-to-monitor-your-metrics&#34;&gt;Setting up alarms to monitor your metrics&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Once you have a good understanding of these metrics, it’s important to set up alarms to notify you when they go beyond acceptable limits:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Create an alarm&lt;/strong&gt;: In the CloudWatch console, navigate to&amp;nbsp;&lt;strong&gt;Alarms&lt;/strong&gt;&amp;nbsp;and click&amp;nbsp;&lt;strong&gt;Create Alarm&lt;/strong&gt;.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Choose a metric&lt;/strong&gt;: Select the metric you want to monitor (e.g.,&amp;nbsp;&lt;strong&gt;CPU Utilization&lt;/strong&gt;).&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Set a threshold&lt;/strong&gt;: Define when the alarm should trigger. For example, set the alarm to activate when CPU usage exceeds 80%. This threshold can be adjusted based on your specific needs.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Configure notifications&lt;/strong&gt;:&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Use&amp;nbsp;&lt;strong&gt;Amazon Simple Notification Service (SNS)&lt;/strong&gt;&amp;nbsp;to send alerts. SNS is a messaging service that sends notifications to multiple endpoints like email, SMS, or Lambda functions.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Create an SNS topic (e.g., “EC2-High-CPU-Alert”) and subscribe to it with your email address to receive notifications.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-testing-and-validating-your-cloudwatch-alarms&#34;&gt;Testing and validating your CloudWatch alarms&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To ensure your alarms are functioning correctly, you can simulate load on your EC2 instance:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Install the&amp;nbsp;&lt;em&gt;stres&lt;/em&gt;s Tool&lt;/strong&gt;:&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;If you’re using an Amazon Linux 2 instance, install it using&lt;br&gt;&lt;strong&gt;&lt;em&gt;sudo yum install stress -y&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;For Ubuntu, use&lt;br&gt;&lt;strong&gt;&lt;em&gt;sudo apt-get update &amp;amp;&amp;amp; sudo apt-get install stress -y&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Run a Test Load&lt;/strong&gt;:&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Execute the following command to generate CPU load for 5 minutes:&lt;br&gt;&lt;strong&gt;&lt;em&gt;stress –cpu 4 –timeout 300&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;This command will push your CPU utilization up, allowing you to check if your alarm triggers correctly in CloudWatch.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://middleware.io/wp-content/uploads/2024/10/AWS-6-1024x652.png&#34; alt=&#34;AWS CloudWatch Metrics: Testing and validating your CloudWatch alarms&#34; class=&#34;wp-image-8233&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;why-this-monitoring-matters&#34;&gt;Why this monitoring matters&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Monitoring your EC2 instance isn’t just about observing metrics; it’s about understanding how your infrastructure behaves. This process provides valuable insights into the performance and stability of your instance. For example, if your instance shows consistently high CPU usage, it could indicate that it’s struggling to handle the workload. Similarly, a sudden increase in disk activity might signal that your application is generating more data than expected, which could lead to running out of storage space.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;By consistently monitoring these metrics, you’ll be well-equipped to take timely action, whether that involves scaling up resources to meet demand, fine-tuning your application to improve efficiency, or investigating any unusual spikes in traffic or resource usage. This proactive approach ensures that your AWS environment remains reliable and responsive to changing conditions.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;top-5-third-party-tools-to-monitor-aws-cloudwatch&#34;&gt;Top 5 third-party tools to monitor AWS CloudWatch&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;While AWS CloudWatch offers solid built-in monitoring features, several third-party tools can enhance your experience by providing advanced analytics, more intuitive dashboards, or additional integrations. Here are the top 5 tools to consider for extending your AWS CloudWatch capabilities, with a focus on their unique features:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-middleware&#34;&gt;Middleware&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://middleware.io/&#34;&gt;Middleware&lt;/a&gt;&amp;nbsp;is a full-stack cloud&amp;nbsp;&lt;a href=&#34;https://middleware.io/blog/observability/&#34;&gt;observability&lt;/a&gt;&amp;nbsp;platform that integrates with AWS CloudWatch, offering pre-built dashboards. It simplifies cloud management by making metrics more accessible and actionable for your team. Middleware is known for its straightforward setup and smooth integration with CloudWatch, allowing you to gain deeper insights into your AWS infrastructure’s performance.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Key features:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Ready-to-use dashboards designed for AWS environments, helping you visualize your data without extensive setup.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Quick and easy integration with CloudWatch for a complete overview of your AWS environment.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://middleware.io/images/infa_cta.png&#34; alt=&#34;Infra content CTA&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-datadog&#34;&gt;Datadog&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://middleware.io/blog/datadog-pricing/&#34;&gt;Datadog&lt;/a&gt;&amp;nbsp;is a versatile monitoring tool that offers enhanced visibility into your AWS infrastructure by extending CloudWatch’s monitoring capabilities. It lets you combine CloudWatch metrics with logs, traces, and events from other services, providing a comprehensive view of your AWS ecosystem.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Key features:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Seamless integration with CloudWatch, plus customizable alerting to suit your specific needs.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Anomaly detection powered by AI to identify unusual patterns in your data and detect potential issues early on.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Datadog excels at correlating data across different services, making it more than just a UI enhancement over CloudWatch’s native features.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-new-relic&#34;&gt;New Relic&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://middleware.io/comparison/newrelic-alternative/&#34;&gt;New Relic&lt;/a&gt;&amp;nbsp;offers an observability platform that brings together AWS CloudWatch metrics with application performance data, providing a clearer picture of how your services interact. It’s particularly useful for monitoring complex, distributed environments.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Key features:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Full-stack monitoring, combining CloudWatch metrics with detailed application insights.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Distributed tracing to identify slow-performing areas within your applications and services.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;New Relic provides a comprehensive view, helping you understand how AWS resources and your applications work together, making it easier to troubleshoot and optimize.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-prometheus-with-grafana&#34;&gt;Prometheus with Grafana&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://middleware.io/blog/what-is-prometheus/&#34;&gt;Prometheus&lt;/a&gt;, paired with&amp;nbsp;&lt;a href=&#34;https://middleware.io/blog/grafana-alternatives/&#34;&gt;Grafana&lt;/a&gt;, offers a powerful open-source solution for monitoring AWS CloudWatch metrics. It’s particularly effective in cloud environments that change frequently, such as Kubernetes clusters, and allows complete customization of how you visualize and alert on your data.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Key features:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Fully customizable dashboards with Grafana, allowing you to tailor visualizations to your specific AWS metrics.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Adaptable to dynamic cloud environments like EKS, where workloads and resource needs frequently change.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This combination is ideal for those who prefer open-source tools and want full control over their monitoring setup.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-zabbix&#34;&gt;Zabbix&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Zabbix is another open-source monitoring tool that integrates well with AWS CloudWatch, providing advanced alerting and custom dashboards. It automatically discovers AWS services and resources, making it easier to monitor your environment without manual configuration.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Key features:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Customizable dashboards and detailed reports for analyzing CloudWatch metrics.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Automatic discovery of AWS instances and services, saving you time on setup.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Zabbix offers more advanced alerting capabilities compared to CloudWatch’s built-in alerts, making it suitable for organizations looking for a more tailored monitoring solution.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;These&amp;nbsp;&lt;a href=&#34;https://middleware.io/blog/observability/tools/&#34;&gt;third-party tools&lt;/a&gt;&amp;nbsp;add significant value to your AWS CloudWatch setup, providing more detailed insights, predictive analytics, and enhanced visualizations. Whether you’re looking for a user-friendly option or prefer an open-source solution with Prometheus and Grafana, these tools can help you gain a deeper understanding of your AWS environment.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;best-practices-for-using-aws-cloudwatch-metrics&#34;&gt;Best practices for using AWS CloudWatch metrics&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To truly leverage AWS CloudWatch and ensure effective monitoring, consider the following advanced practices:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-set-alarms-with-appropriate-thresholds-and-anomaly-detection&#34;&gt;Set alarms with appropriate thresholds and anomaly detection&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Use dynamic alarms&lt;/strong&gt;: Instead of setting static thresholds (e.g., CPU &amp;gt; 80%), use&amp;nbsp;&lt;strong&gt;anomaly detection&lt;/strong&gt;&amp;nbsp;to create alarms that adapt to normal patterns of your workload. This helps reduce false positives and catch unusual behavior more accurately.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Create multi-condition alarms&lt;/strong&gt;: Set up composite alarms that trigger only when multiple conditions are met, such as high CPU utilization&amp;nbsp;&lt;strong&gt;and&lt;/strong&gt;&amp;nbsp;low available memory. This prevents unnecessary alerts and ensures that you only get notified about significant issues.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-monitor-custom-metrics-for-business-critical-data&#34;&gt;Monitor custom metrics for business-critical data&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Collect custom metrics&lt;/strong&gt;: Use CloudWatch’s ability to collect custom metrics relevant to your specific application or business logic, such as transaction latency, user login counts, or payment failures. This ensures that you monitor aspects beyond the basic system metrics.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Set up custom dashboards&lt;/strong&gt;: Create dashboards that include a mix of AWS service metrics and your custom metrics, offering a complete picture of your application’s health.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-enable-detailed-monitoring-of-critical-resources&#34;&gt;Enable detailed monitoring of critical resources&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Go beyond basic monitoring:&lt;/strong&gt;&amp;nbsp;Enable detailed monitoring (1-minute intervals) for critical resources such as production EC2 instances and RDS databases. This provides more granular visibility and helps quickly identify short-lived performance issues.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Use high-resolution metrics:&lt;/strong&gt;&amp;nbsp;For highly dynamic or high-traffic resources, leverage high-resolution metrics (with 1-second granularity) to capture even the smallest fluctuations in performance.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-implement-log-monitoring-and-analysis&#34;&gt;Implement log monitoring and analysis&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Utilize CloudWatch Logs Insights&lt;/strong&gt;: Regularly use CloudWatch Logs Insights to run SQL-like queries against your log data. This helps identify patterns, troubleshoot issues, and gain insights without having to transfer logs to a different service.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Centralized log management&lt;/strong&gt;: Collect logs from multiple sources (EC2 instances, Lambda functions, on-premises servers) into a single CloudWatch Logs group. This provides a unified view, making it easier to monitor and debug across the entire application stack.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-combine-cloudwatch-with-automation-tools&#34;&gt;Combine CloudWatch with automation tools&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Use AWS Systems Manager automation documents&lt;/strong&gt;: Create automation documents in Systems Manager that CloudWatch can trigger in response to alarms, such as restarting services, clearing caches, or scaling up resources automatically.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Automate responses with AWS Lambda&lt;/strong&gt;: Set up Lambda functions to respond to CloudWatch Alarms for routine tasks like archiving logs when storage is low, clearing disk space, or performing automated recovery actions.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Integrate with OpenTelemetry for Non-AWS monitoring&lt;/strong&gt;: Use OpenTelemetry to collect metrics, logs, and traces from non-AWS applications and infrastructure, allowing you to send this data to CloudWatch. This integration helps you gain a unified view of your entire environment, making CloudWatch even more effective as a centralized monitoring solution.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-use-resource-level-permissions-for-cloudwatch-access&#34;&gt;Use resource-level permissions for CloudWatch access&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Implement fine-grained access control&lt;/strong&gt;: Configure IAM policies to grant CloudWatch access only to the specific resources and metrics each team or service needs. This helps maintain security and prevents unauthorized access to sensitive metrics.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Segment dashboards by role&lt;/strong&gt;: Create role-specific dashboards for different teams (e.g., DevOps, Security, Developers), so they only see the metrics relevant to their responsibilities.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-enable-cloudwatch-contributor-insights&#34;&gt;Enable CloudWatch Contributor Insights&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Identify usage patterns&lt;/strong&gt;: Enable CloudWatch Contributor Insights to analyze the top contributors to performance bottlenecks, high traffic, or errors in your environment. This tool helps you pinpoint which resources or clients are driving the most activity and focus your troubleshooting efforts accordingly.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-regularly-review-and-clean-up-cloudwatch-alarms-and-dashboards&#34;&gt;Regularly review and clean up CloudWatch alarms and dashboards&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Avoid alarm tatigue:&lt;/strong&gt;&amp;nbsp;Periodically review and adjust your alarms to ensure they remain relevant and reduce unnecessary alerts. Remove alarms for resources that are no longer in use.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Archive and rotate logs:&lt;/strong&gt;&amp;nbsp;Implement log retention policies that automatically archive or delete old logs to manage costs and ensure that CloudWatch Logs remain manageable.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;By incorporating these best practices, you’ll gain deeper insights into your AWS environment, automate routine responses to issues, and maintain tighter control over your infrastructure’s health. This approach ensures that your monitoring strategy is both effective and tailored to the needs of your applications and business.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;AWS CloudWatch metrics are an essential tool for managing and optimizing both your AWS and non-AWS resources. They provide real-time visibility into the performance of your infrastructure and allow you to take action before problems arise.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Looking ahead, integrating CloudWatch with machine learning services like SageMaker can help predict anomalies and optimize resource usage automatically. Additionally, leveraging AWS Lambda for automated responses to CloudWatch alarms can help you streamline operations even further.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;成员帖子最初发布于 &lt;a href=&#34;https://middleware.io/blog/aws-cloudwatch-metrics-explained-how-to-monitor-and-optimize-your-cloud-resources /&#34;&gt;中间件博客&lt;/a&gt;，作者：&lt;a href=&#34;https://middleware.io/blog/authors/sanjay/&#34;&gt;Sanjay Suthar&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;随着您的 &lt;a href=&#34;https://middleware.io/solutions/aws/&#34;&gt;AWS&lt;/a&gt; 环境的扩展 - 无论是在资源、服务数量还是团队规模方面——管理这些元素变得越来越具有挑战性。由于多个实例、数据库和服务同时运行，维护有组织的概览很快就会变得难以承受。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这种增长通常使我们很难知道每个组件是否都以最佳方式运行并提供预期的性能。在理想的情况下，您拥有的系统不仅可以监控&lt;a href=&#34;https://middleware.io/blog/what-is-infrastruct-monitoring/&#34;&gt;基础设施&lt;/a&gt;的各个部分，还提供实时洞察，确保一切按预期顺利运行。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这就是 &lt;a href=&#34;https://middleware.io/blog/analyze-aws-cloudwatch-resources/&#34;&gt;AWS CloudWatch&lt;/a&gt; 发挥作用的地方。 AWS CloudWatch 是您监控、分析关键指标并采取行动的重要工具，不仅适用于您的 AWS 环境，还适用于在本地或其他云平台中运行的外部应用程序和服务。它提供了有关每项 AWS 服务的执行情况的宝贵见解，帮助您有效地管理和调整您的资源。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;本指南的目的是提供关于使用 CloudWatch 指标来维护&lt;a href=&#34;https://middleware.io/blog/aws-monitoring/&#34;&gt;受良好监控的 AWS 环境&lt;/一个&gt;。从配置警报到利用 CloudWatch 自定义仪表板等高级功能，我们将探索 CloudWatch 提供的一切功能，以确保您的基础设施保持最佳运行状态。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;understanding-aws-cloudwatch&#34;&gt;了解 AWS CloudWatch&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;AWS CloudWatch 超越了基本监控 — 它是一项全面的服务，可帮助您深入了解您的 AWS 基础设施。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;CloudWatch 的核心优势之一是能够从各种来源（包括 AWS 服务和外部应用程序）收集数据。无论您是监控 EC2 实例的性能，还是跟踪 RDS 中的&lt;a href=&#34;https://middleware.io/blog/top-ways-to-prevent-database-failures/&#34;&gt;数据库&lt;/a&gt;连接、执行 Lambda 调用，或通过 &lt;a href=&#34;https://middleware.io/blog/what-is-opentelemetry/&#34;&gt;OpenTelemetry&lt;/a&gt;、CloudWatch 从本地服务器和第三方服务收集指标整合所有这些指标，为您提供整个基础架构的集中视图。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;不仅仅是收集&lt;a href=&#34;https://middleware.io/blog/devops-metrics-you-should-be-monitoring/&#34;&gt;指标&lt;/a&gt;CloudWatch 提供&lt;a href=&#34;https://middleware.io/platform/alerts/&#34;&gt;警报&lt;/a&gt;功能。您可以设置警报，在达到特定阈值时通知您，以便您在潜在问题升级之前对其做出响应。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这些功能使您可以更好地控制和了解您的 AWS 环境，提供解决问题所需的见解并维护运行良好的基础设施。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;the-importance-of-cloudwatch-metrics-in-aws-resource-management&#34;&gt;CloudWatch 指标在 AWS 资源管理中的重要性&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;CloudWatch 指标至关重要，因为它们提供有关 AWS 和非 AWS 资源执行情况的实时数据。它们帮助您监控基础设施的各个方面，让您深入了解资源使用情况和潜在问题领域。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;例如，CloudWatch 提供的 EC2 实例中的&lt;strong&gt;CPU 利用率&lt;/strong&gt;等指标可指示服务器何时遇到高需求。这可能表明需要扩大资源或重新分配流量以避免任何减速。同样，CloudWatch 跟踪的 RDS 的&lt;strong&gt;可用内存&lt;/strong&gt;可帮助您确定数据库实例是否需要调整大小以更有效地处理工作负载。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;CloudWatch 对于&lt;a href=&#34;https://middleware.io/blog/reduce-observability-costs/&#34;&gt;管理成本&lt;/a&gt;也很有价值。通过检查使用模式，您可能会注意到某些实例始终以其容量的一小部分运行。例如，如果您发现 EC2 实例的 CPU 使用率从未超过 10%，则可能表明您配置过多，您可以切换到较小的实例类型以节省成本。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;与其他云平台相比，AWS CloudWatch 因其与整个 AWS 生态系统的无缝集成而脱颖而出。例如，Google Cloud 使用&lt;a href=&#34;https://middleware.io/blog/cloud-monitoring-tools/&#34;&gt;&lt;strong&gt;云监控&lt;/strong&gt;&lt;/a&gt;，而 Azure 则使用&lt;strong&gt;Azure监控 - 都是有效的工具，但缺乏 CloudWatch 与 AWS 特定服务提供的集成水平。这种紧密集成意味着 CloudWatch 不仅可以监控，还可以根据其跟踪的指标触发操作（例如 Auto Scaling），从而使其成为管理 AWS 资源的更具凝聚力的选项。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;how-aws-cloudwatch-works&#34;&gt;AWS CloudWatch 的工作原理&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;AWS CloudWatch 通过从各种来源（包括 AWS 服务）收集指标、&lt;a href=&#34;https://middleware.io/blog/what-is-log-monitoring/&#34;&gt;日志&lt;/a&gt;和事件来发挥作用例如 EC2、RDS 和 Lambda，以及来自本地服务器、外部云服务和使用 OpenTelemetry 检测的应用程序。这些指标被收集并可供访问，允许您监控性能并根据特定阈值设置警报lds 遍布您的整个基础设施。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;将 CloudWatch 视为 AWS 基础设施的监控中心。它捕获来自不同服务的数据并将其转化为可操作的见解，然后您可以通过仪表板将其可视化或用于触发自动化操作。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;例如，您可以自定义 CloudWatch 控制面板来显示对组织运营至关重要的指标，例如 EC2 实例的 CPU 利用率或负载均衡器的请求计数。可以设置警报，以便在这些指标达到预定义阈值时通知您。这些警报还可以启动自动响应，例如扩展 Auto Scaling 组或执行 Lambda 函数，确保您的基础设施能够迅速响应不断变化的条件，而无需手动干预。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;core-metrics-to-monitor-in-aws-cloudwatch&#34;&gt;在 AWS CloudWatch 中监控的核心指标&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;当&lt;a href=&#34;https://middleware.io/blog/proactive-monitoring/&#34;&gt;监控您的环境&lt;/a&gt;时，无论是在 AWS 上还是其他地方，几个关键指标都可以提供有关性能和性能的宝贵见解。您的服务的健康状况。虽然此处提到的指标很重要，但请始终记住，指标的重要性可能会根据您的特定 AWS 设置和工作负载而有所不同。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;EC2 指标&lt;/strong&gt;：监控&lt;strong&gt;CPU 利用率&lt;/strong&gt;和&lt;strong&gt;磁盘读取操作&lt;/strong&gt;，以评估您的实例处理工作负载的情况。持续的高 CPU 利用率可能表明需要进行扩展，而磁盘读取操作的峰值可能会凸显数据访问中的潜在瓶颈。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;RDS 指标&lt;/strong&gt;：密切关注&lt;strong&gt;数据库连接&lt;/strong&gt;和&lt;strong&gt;可用内存&lt;/strong&gt;。这些指标可帮助您了解数据库的性能以及是否需要调整大小或优化以防止连接限制等问题。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Lambda 指标&lt;/strong&gt;：跟踪&lt;strong&gt;调用&lt;/strong&gt;和&lt;strong&gt;错误&lt;/strong&gt;以衡量无服务器函数的执行效率。错误突然增加可能表明您的代码或触发器存在问题。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;EKS 指标&lt;/strong&gt;：由于 EKS 通常对 AWS 账单影响很大，因此需要监控&lt;strong&gt;每个 Pod 的 CPU 和内存利用率&lt;/strong&gt;、&lt;strong&gt;集群节点容量&lt;/strong&gt;和&lt; strong&gt;请求延迟&lt;/strong&gt;至关重要。这些指标有助于确保您的 Kubernetes 集群高效运行，并且工作负载在您的 Pod 之间均匀分布。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;CloudWatch 允许您创建自定义仪表板来可视化这些指标，提供服务性能的清晰视图，并使您能够快速识别和解决任何问题。这种全面的监控可确保您的基础设施正常运行g 如预期的那样，减少意外停机或性能下降的可能性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;hands-on:-creating-and-using-cloudwatch-alarms&#34;&gt;动手操作：创建和使用 CloudWatch 警报&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;使用 CloudWatch 监控 EC2 实例可帮助您跟踪服务器处理工作负载的情况，并使您能够快速识别和解决潜在问题，例如高 CPU 使用率或网络流量。以下是有关如何设置的全面分步指南：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://middleware.io/wp-content/uploads/2024/10/AWS-3-1024x534.png&#34; alt= “AWS CloudWatch 指标：创建和使用 CloudWatch 警报” class=&#34;wp-image-8230&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-launch-your-ec2-instance&#34;&gt;启动您的 EC2 实例&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;首先登录&lt;strong&gt;AWS 管理控制台&lt;/strong&gt;并导航至&lt;strong&gt;EC2&lt;/strong&gt;服务。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;点击&lt;strong&gt;启动实例&lt;/strong&gt;并按照设置流程进行操作：&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;选择 Amazon 系统映像 (AMI)&lt;/strong&gt;：选择适当的 AMI，例如 Amazon Linux 2 或 Ubuntu。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;实例类型&lt;/strong&gt;：选择适合您工作负载的实例类型，例如 t2.micro（符合免费套餐资格）。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;配置实例详细信息&lt;/strong&gt;：&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;向下滚动到&lt;strong&gt;监控&lt;/strong&gt;部分并启用&lt;strong&gt;详细监控&lt;/strong&gt;复选框。此选项可确保 CloudWatch 以 1 分钟间隔（而不是默认的 5 分钟间隔）收集数据，这对于捕获资源使用量的突然峰值至关重要。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://middleware.io/wp-content/uploads/2024/10/AWS-4.png&#34; alt=&#34;AWS CloudWatch 指标：启动您的 EC2 实例&#34; class=&#34;wp-image-8231&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;EC2 实例运行后，您可以继续使用 CloudWatch 对其进行监控。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-access-cloudwatch-from-the-aws-console&#34;&gt;从 AWS 控制台访问 CloudWatch&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;启动实例后，转到&lt;strong&gt;AWS 管理控制台&lt;/strong&gt;并从服务列表中打开&lt;strong&gt;CloudWatch&lt;/strong&gt;。这是您跟踪与 EC2 实例性能相关的所有指标的主要中心。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-viewing-metrics-for-your-ec2-instance&#34;&gt;查看您的 EC2 实例的指标&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;在 CloudWatch 中，转到&lt;strong&gt;指标&lt;/strong&gt;部分并选择&lt;strong&gt;EC2&lt;/strong&gt;。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;点击&lt;strong&gt;每个实例指标&lt;/strong&gt;即可查看您的实例的指标列表实例。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;选择您的实例以查看 CPU 利用率、网络流量和磁盘活动等指标的实时数据。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://middleware.io/wp-content/uploads/2024/10/AWS-5-1024x536.png&#34; alt= “AWS CloudWatch 指标：查看 EC2 实例的指标” class=&#34;wp-image-8232&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-understanding-key-metrics-to-monitor&#34;&gt;了解要监控的关键指标&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;CloudWatch 为 EC2 实例提供了各种指标，但让我们重点关注最重要的指标：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;CPU 利用率&lt;/strong&gt;：此指标表示当前使用的 CPU 容量的百分比。例如，如果您发现 CPU 使用率持续较高（例如，高于 80%），则可能表明您的实例正在努力应对工作负载，您可能需要考虑升级实例类型或优化应用程序以更有效地处理负载.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;NetworkIn / NetworkOut&lt;/strong&gt;：这些指标跟踪您的实例接收和传输的数据量。此处的较高值可能表示&lt;a href=&#34;https://middleware.io/customers/hotplate/&#34;&gt;流量增加&lt;/a&gt;，这在高峰期可能是正常现象，或者如果突然出现峰值，则表示出现意外活动。监控这些指标可以帮助您了解&lt;a href=&#34;https://content.techgig.com/expert-opinion/why-is-monitoring-your-application-important/articleshow/105003258.cms&#34;&gt;应用程序&lt;/a &gt; 遇到流量过大或存在潜在问题（例如未经授权的数据访问）。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;磁盘读取操作/磁盘写入操作&lt;/strong&gt;：这些指标显示您的实例读取或写入磁盘的频率。例如，Disk Read Ops 代表读操作，Disk Write Ops 代表写操作。高值可能意味着您的应用程序与磁盘上存储的数据进行大量交互，如果管理不当，可能会导致响应时间变慢。例如，如果您的实例正在运行数据库，这些指标的峰值可能表明读/写查询的增加。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-setting-up-alarms-to-monitor-your-metrics&#34;&gt;设置警报来监控您的指标&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;一旦您充分了解这些指标，设置警报以在超出可接受的限制时通知您非常重要：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;&lt;strong&gt;创建警报&lt;/strong&gt;：在 CloudWatch 控制台中，导航到&lt;strong&gt;警报&lt;/strong&gt;并点击&lt;strong&gt;创建警报&lt;/strong&gt;。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;选择指标&lt;/strong&gt;：选择您要监控的指标（例如&lt;strong&gt;CPU 利用率&lt;/strong&gt;）。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;设置阈值&lt;/strong&gt;：定义何时触发警报。例如，设置当CPU使用率超过80%时激活警报。该阈值可以是根据您的具体需求进行调整。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;配置通知&lt;/strong&gt;：&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;使用&lt;strong&gt;Amazon Simple Notification Service (SNS)&lt;/strong&gt;发送提醒。 SNS 是一种消息传递服务，可将通知发送到电子邮件、SMS 或 Lambda 函数等多个端点。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;创建一个 SNS 主题（例如“EC2-High-CPU-Alert”）并使用您的电子邮件地址订阅该主题以接收通知。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-testing-and-validating-your-cloudwatch-alarms&#34;&gt;测试和验证您的 CloudWatch 警报&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;为了确保您的警报正常运行，您可以模拟 EC2 实例上的负载：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;&lt;strong&gt;安装&lt;em&gt;压力&lt;/em&gt;工具&lt;/strong&gt;：&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;如果您使用的是 Amazon Linux 2 实例，请使用&lt;br&gt;&lt;strong&gt;&lt;em&gt;sudo yum installstress -y&lt;/em&gt;&lt;/strong&gt;进行安装&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;对于 Ubuntu，请使用&lt;br&gt;&lt;strong&gt;&lt;em&gt;sudo apt-get update &amp;&amp; sudo apt-get installstress -y&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;运行测试负载&lt;/strong&gt;：&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;执行以下命令生成 5 分钟的 CPU 负载：&lt;br&gt;&lt;strong&gt;&lt;em&gt;stress –cpu 4 –timeout 300&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;此命令将提高您的 CPU 利用率，以便您检查您的警报是否在 CloudWatch 中正确触发。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://middleware.io/wp-content/uploads/2024/10/AWS-6-1024x652.png&#34; alt= “AWS CloudWatch 指标：测试和验证您的 CloudWatch 警报” class=&#34;wp-image-8233&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;why-this-monitoring-matters&#34;&gt;为什么此监控很重要&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;监控您的 EC2 实例不仅仅是观察指标；还包括观察指标。这是关于了解您的基础设施的行为方式。此过程提供了有关实例的性能和稳定性的宝贵见解。例如，如果您的实例显示持续较高的 CPU 使用率，则可能表明它正在努力处理工作负载。同样，磁盘活动的突然增加可能表明您的应用程序正在生成比预期更多的数据，这可能会导致存储空间不足。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;通过持续监控这些指标，您将能够及时采取行动，无论是扩大资源以满足需求、微调应用程序以提高效率，还是调查任何异常的流量或资源使用高峰。这种主动方法可确保您的 AWS 环境保持可靠并能够响应不断变化的条件。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;top-5-third-party-tools-to-monitor-aws-cloudwatch&#34;&gt;用于监控 AWS CloudWatch 的前 5 名第三方工具&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;虽然 AWS CloudWatch 提供可靠的内置监控功能，但多个第三方工具可以增强您的体验通过提供高级分析、更直观的仪表板或其他集成。以下是扩展 AWS CloudWatch 功能时需要考虑的 5 个主要工具，重点关注其独特功能：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-middleware&#34;&gt;中间件&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://middleware.io/&#34;&gt;中间件&lt;/a&gt;是一个全栈云&lt;a href=&#34;https://middleware.io/blog/observability/&#34;&gt;可观察性&lt; /a&gt; 与 AWS CloudWatch 集成的平台，提供预构建的仪表板。它使您的团队更容易访问和操作指标，从而简化了云管理。中间件以其简单的设置以及与 CloudWatch 的顺利集成而闻名，使您能够更深入地了解 AWS 基础设施的性能。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;主要特点：&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;专为 AWS 环境设计的即用型仪表板，可帮助您可视化数据，无需进行大量设置。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;与 CloudWatch 快速轻松集成，全面了解您的 AWS 环境。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;img解码=“async”src=“https://middleware.io/images/infa_cta.png”alt=“基础设施内容CTA”referrerpolicy=“no-referrer”&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-datadog&#34;&gt;数据狗&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://middleware.io/blog/datadog-pricing/&#34;&gt;Datadog&lt;/a&gt; 是一款多功能监控工具，可通过扩展 CloudWatch 的监控功能来增强对 AWS 基础设施的可见性。它允许您将 CloudWatch 指标与来自其他服务的日志、跟踪和事件相结合，从而提供 AWS 生态系统的全面视图。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;主要特点：&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;与 CloudWatch 无缝集成，并可自定义警报以满足您的特定需求。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;由 AI 提供支持的异常检测可识别数据中的异常模式并及早发现潜在问题。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Datadog 擅长关联不同服务之间的数据，使其不仅仅是对 CloudWatch 原生功能的 UI 增强。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-new-relic&#34;&gt;新遗物&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://middleware.io/comparison/newrelic-alternative/&#34;&gt;New Relic&lt;/a&gt; 提供了一个可观察性平台，将 AWS CloudWatch 指标与应用程序性能数据结合在一起，从而提供更清晰的视图您的服务如何交互。它对于监控复杂的分布式环境特别有用。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;主要特点：&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;全栈监控，将 CloudWatch 指标与详细的应用洞察相结合。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;分布式跟踪，用于识别应用和服务中性能缓慢的区域。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;New Relic 提供全面的视图，帮助您了解 AWS 资源和应用程序如何协同工作，从而更轻松地进行故障排除和优化。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-prometheus-with-grafana&#34;&gt;普罗米修斯与 Grafana&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://middleware.io/blog/what-is-prometheus/&#34;&gt;Prometheus&lt;/a&gt;，与 &lt;a href=&#34;https://middleware.io/blog/grafana 配对-alternatives/&#34;&gt;Grafana&lt;/a&gt;，提供强大的开源解决方案来监控 AWS CloudWatch 指标。它在频繁变化的云环境（例如 Kubernetes 集群）中特别有效，并且允许完全自定义数据的可视化和警报方式。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;主要特点：&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;使用 Grafana 完全可定制的仪表板，让您可以根据特定的 AWS 指标定制可视化效果。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;适应 EKS 等工作负载和资源需求经常变化的动态云环境。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;对于那些喜欢开源工具并希望完全控制其监控设置的人来说，这种组合是理想的选择。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-zabbix&#34;&gt;Zabbix&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Zabbix 是另一个开源监控工具，与 AWS CloudWatch 集成良好，提供高级警报和自定义仪表板。它会自动发现 AWS 服务和资源，让您可以更轻松地监控您的环境，而无需手动配置。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;主要特点：&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;可自定义的仪表板和详细报告，用于分析 CloudWatch 指标。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;自动发现 AWS 实例和服务，节省您的设置时间。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;与 CloudWatch 的内置警报相比，Zabbix 提供了更高级的警报功能，使其适合寻求更量身定制的监控解决方案的组织。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这些&lt;a href=&#34;https://middleware.io/blog/observability/tools/&#34;&gt;第三方工具&lt;/a&gt;为您的 AWS CloudWatch 设置增添了重要价值，提供更详细的见解、预测分析、和增强的可视化。无论您是在寻找用户友好的选项还是更喜欢 Prometheus 和 Grafana 的开源解决方案，这些工具都可以帮助您更深入地了解您的 AWS 环境。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;best-practices-for-using-aws-cloudwatch-metrics&#34;&gt;使用 AWS CloudWatch 指标的最佳实践&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;要真正利用 AWS CloudWatch 并确保有效监控，请考虑以下高级实践：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-set-alarms-with-property-thresholds-and-anomaly-detection&#34;&gt;设置具有适当阈值和异常检测的警报&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;使用动态警报&lt;/strong&gt;：不要设置静态阈值（例如，CPU &gt; 80%），而是使用&lt;strong&gt;异常检测&lt;/strong&gt;来创建适应正常工作负载模式的警报。这有助于减少误报并更准确地捕捉异常行为。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;创建多条件警报&lt;/strong&gt;：设置触发多个条件的复合警报仅当满足多个条件时，例如 CPU 利用率高&lt;strong&gt;和&lt;/strong&gt;可用内存低。这可以防止不必要的警报，并确保您只收到有关重大问题的通知。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-monitor-custom-metrics-for-business-ritic-data&#34;&gt;监控关键业务数据的自定义指标&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;收集自定义指标&lt;/strong&gt;：利用 CloudWatch 的功能来收集与您的特定应用程序或业务逻辑相关的自定义指标，例如交易延迟、用户登录计数或付款失败。这可确保您监控基本系统指标之外的各个方面。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;设置自定义控制面板&lt;/strong&gt;：创建包含 AWS 服务指标和自定义指标组合的控制面板，提供应用程序运行状况的完整情况。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-enable-detailed-monitoring-of-ritic-resources&#34;&gt;启用对关键资源的详细监控&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;超越基本监控&lt;/strong&gt;：对生产 EC2 实例和 RDS 数据库等关键资源启用详细监控（间隔 1 分钟）。这提供了更精细的可见性，并有助于快速识别短暂的性能问题。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;使用高分辨率指标&lt;/strong&gt;：对于高度动态或高流量的资源，可以利用高分辨率指标（粒度为 1 秒）来捕获性能中最小的波动。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-implement-log-monitoring-and-analysis&#34;&gt;实现日志监控与分析&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;利用 CloudWatch Logs Insights&lt;/strong&gt;：定期使用 CloudWatch Logs Insights 对日志数据运行类似 SQL 的查询。这有助于识别模式、解决问题并获得见解，而无需将日志传输到其他服务。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;集中日志管理&lt;/strong&gt;：将来自多个来源（EC2 实例、Lambda 函数、本地服务器）的日志收集到单个 CloudWatch Logs 组中。这提供了统一的视图，使整个应用程序堆栈的监控和调试变得更加容易。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-combine-cloudwatch-with-automation-tools&#34;&gt;将 CloudWatch 与自动化工具相结合&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;使用 AWS Systems Manager 自动化文档&lt;/strong&gt;：在 Systems Manager 中创建 CloudWatch 可以触发的自动化文档以响应警报，例如重新启动服务、清除缓存或自动扩展资源。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;使用 AWS Lambda 自动响应&lt;/strong&gt;：设置 Lambda 函数以响应 CloudWatch 警报来执行日常任务，例如在存储空间不足时归档日志、清理磁盘空间或执行自动恢复操作。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;与 OpenT 集成用于非 AWS 监控的 elemetry：使用 OpenTelemetry 从非 AWS 应用程序和基础设施收集指标、日志和跟踪，从而允许您将此数据发送到 CloudWatch。这种集成可帮助您获得整个环境的统一视图，使 CloudWatch 作为集中监控解决方案更加有效。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-use-resource-level-permissions-for-cloudwatch-access&#34;&gt;使用资源级权限进行 CloudWatch 访问&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;实施细粒度访问控制&lt;/strong&gt;：配置 IAM 策略，仅向 CloudWatch 授予对每个团队或服务所需的特定资源和指标的访问权限。这有助于维护安全并防止未经授权访问敏感指标。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;按角色细分仪表板&lt;/strong&gt;：为不同团队（例如 DevOps、安全性、开发人员）创建特定于角色的仪表板，以便他们只能看到与其职责相关的指标。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-enable-cloudwatch-contributor-insights&#34;&gt;启用 CloudWatch Contributor Insights&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;识别使用模式&lt;/strong&gt;：启用 CloudWatch Contributor Insights 来分析环境中性能瓶颈、高流量或错误的主要原因。该工具可帮助您查明哪些资源或客户端驱动的活动最多，并相应地集中您的故障排除工作。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-regularly-review-and-clean-up-cloudwatch-alarms-and-dashboards&#34;&gt;定期检查和清理 CloudWatch 警报和控制面板&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;避免闹钟疲劳&lt;/strong&gt;：定期检查和调整您的闹钟，以确保它们保持相关性并减少不必要的提醒。删除不再使用的资源的警报。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;归档和轮换日志&lt;/strong&gt;：实施自动归档或删除旧日志的日志保留策略，以管理成本并确保 CloudWatch Logs 保持可管理性。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;通过整合这些最佳实践，您将更深入地了解您的 AWS 环境、自动执行对问题的例行响应，并保持对基础设施运行状况的更严格控制。这种方法可确保您的监控策略既有效又适合您的应用程序和业务的需求。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;conclusion&#34;&gt;结论&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;AWS CloudWatch 指标是管理和优化 AWS 和非 AWS 资源的重要工具。它们提供对基础设施性能的实时可见性，并允许您在问题出现之前采取行动。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;展望未来，将 CloudWatch 与 SageMaker 等机器学习服务集成可以帮助预测异常并自动优化资源使用。此外，利用 AWS Lambda 进行自动化重新部署对 CloudWatch 警报的响应可以帮助您进一步简化操作。&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Sun, 01 Dec 2024 16:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>