<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>CNCF - Blog</title>
    <link>http://cloudys-rsshub-ab061133bcab.herokuapp.com/cncf</link>
    <description>CNCF - Blog - Powered by RSSHub</description>
    <managingEditor>contact@rsshub.app (RSSHub)</managingEditor>
    <item>
      <title>【The autonomous enterprise and the four pillars of platform control: 2026 forecast】自主企业和平台控制的四大支柱：2026 年预测</title>
      <link>https://www.cncf.io/blog/2026/01/23/the-autonomous-enterprise-and-the-four-pillars-of-platform-control-2026-forecast/</link>
      <description>【&lt;p&gt;The promise of DevOps and Platform Engineering is to balance developer velocity with enterprise governance. In 2026, AI Agents move from being simple assistance tools to the core mechanisms that automate this balance. Recent publications, such as the CNCF &lt;a href=&#34;https://www.cncf.io/wp-content/uploads/2025/11/cncf_report_stateofcloud_111025a.pdf?utm_source=chatgpt.com&#34;&gt;2025 Technology Radar&lt;/a&gt; report, highlight growing experimentation with agentic AI standards (for example, MCP). As we begin 2026, it’s time to forecast how the enterprise shift to autonomy will be defined by four distinct, AI-driven control mechanisms: golden paths, guardrails, safety nets, and manual review workflows.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Governing the autonomous enterprise&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Based on conversations with platform engineering teams at large enterprises and broader industry signals, some fundamental priorities for 2026 are emerging: speed, security, and cost optimization should be achieved autonomously.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This reflects a powerful consensus across the industry, centered on the following key shifts:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;A potential 2026 paradigm shift:&lt;/strong&gt; AI’s role may evolve from a copilot to an agent with delegated authority over mission-critical tasks (provisioning, security, incident response).&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;The necessity of control:&lt;/strong&gt; This new level of automation demands a sophisticated governance framework. A generic “guardrail” approach is insufficient; success depends on a clear taxonomy of controls.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;The four pillars of control:&lt;/strong&gt; These pillars—&lt;strong&gt;golden paths, guardrails, safety nets, and manual review workflows&lt;/strong&gt;— could form the adaptive, secure foundation for high-velocity infrastructure management in large enterprises.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Golden paths: The self-tuning, autonomous road&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Golden paths&lt;/strong&gt; are the curated, pre-approved blueprints that make the secure, compliant choice the &lt;em&gt;easiest&lt;/em&gt; choice for developers (e.g., standardized IaC modules, self-service portals). &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;2026 Prediction: Increasing autonomy for generation and optimization&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Intent-to-infrastructure:&lt;/strong&gt; AI Agents will move beyond simple code generation. Developers input high-level requirements (e.g. “I need a secure, scalable service for my application in AWS US-East”), and the AI Agent fully composes, validates, and provisions the compliant infrastructure according to the pre-defined golden path.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;The “janitor” agent:&lt;/strong&gt; Provisioning is only half the battle. In 2026, golden paths will include embedded “time-to-live” policies. An autonomous agent will proactively identify and decommission “zombie infrastructure” (orphaned resources, idle dev environments), solving the massive problem of cloud waste and reducing the security attack surface.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Continuous path improvement:&lt;/strong&gt; Agents will continuously monitor the performance, cost, and adoption of these golden paths. They will recommend and, in many cases, autonomously implement improvements—such as swapping out a resource type or optimizing a default configuration—to meet defined SLOs (Service Level Objectives) and FinOps targets.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;The platform engineer’s role:&lt;/strong&gt; Shifting to the curation and quality control of the AI-powered golden path, ensuring the &lt;em&gt;best&lt;/em&gt; practice is always the &lt;em&gt;default&lt;/em&gt; practice.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Guardrails: Autonomous governance and zero-drift assurance&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Guardrails&lt;/strong&gt; are the hard, non-negotiable stops—the “crash barriers”—that prevent actions or configurations that would compromise the security or stability of the platform (e.g., blocking public storage buckets, enforcing binary authorization).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;2026 Prediction: From reactive scanners to proactive AI enforcers&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;AI-Driven Policy-as-Code:&lt;/strong&gt; Agents will translate high-level compliance requirements (e.g., “PCI-DSS compliance”) into executable, deterministic Guardrails and deploy them across the infrastructure lifecycle (CI/CD, runtime).&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Autonomous vulnerability response:&lt;/strong&gt; Upon the announcement of a new critical vulnerability (CVE) or security patch, AI-driven systems may increasingly automate the creation and deployment of runtime guardrails, under predefined policies and human-approved constraints (e.g., network policies, temporary access restrictions, or container image blocks) across affected environments. This provides an immediate, defensive shield, dramatically reducing the enterprise’s time-to-protection from days to minutes.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;The “auditor” agent:&lt;/strong&gt; Compliance evidence collection will be fully automated. Since the AI Agent enforces the guardrails, it will also generate real-time, immutable audit reports for standards like PCI-DSS or SOC2, substantially reducing the manual effort typically associated with audit preparation.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Autonomous drift remediation:&lt;/strong&gt; This becomes a standard feature. AI Agents will continuously scan the live environment against the desired state defined by the golden path and its embedded guardrails. Upon detecting unauthorized changes (drift), the agent will autonomously revert or fix the misconfiguration instantly, moving closer to near-zero configuration drift for compliance-sensitive environments.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Focus on prevention:&lt;/strong&gt; The goal is for AI to ensure that developers rarely, if ever, encounter a guardrail by guiding them through the golden path.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Safety nets: Predictive reliability and auto-recovery&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Safety nets&lt;/strong&gt; are reactive controls that detect failures or threats and facilitate swift recovery (e.g., monitoring, automated rollbacks, backup procedures).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;2026 Prediction: Full autonomy in detection and remediation&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Predictive SRE:&lt;/strong&gt; AI Agents, trained on vast quantities of observability data, will predict outages and performance degradation &lt;em&gt;before&lt;/em&gt; they impact users. They will use sophisticated pattern recognition to trigger proactive scaling or maintenance to avert an incident entirely.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Autonomous incident response:&lt;/strong&gt; For incidents that do occur, the agent will move beyond suggestion (AIOps 1.0) to full auto-remediation (AIOps 2.0).&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;The agent identifies the root cause, correlates it with the appropriate runbook action, and executes the fix (e.g., traffic shifting, restarting a service, or executing a rollback) autonomously, with the potential to significantly reduce Mean Time to Resolution (MTTR) in many scenarios.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;The SRE’s evolved role:&lt;/strong&gt; Defining the rules, tolerances, and error budgets for the Safety Net agents, and focusing on complex, novel failure modes that require human creativity.&amp;nbsp;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;With cost optimization cited as the top priority for 2025 and chaos engineering still at &amp;lt;10% adoption, the market is primed for the autonomous ‘Safety Nets’ and ‘FinOps Agents’ we predict.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Manual review workflows: The strategic human-in-the-loop&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Manual review workflows&lt;/strong&gt; are processes requiring human judgment, oversight, and intervention for high-risk, complex, or financial decisions (e.g., architectural reviews, large budget approvals, security post-mortems).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;2026 Prediction: AI-optimized human judgment&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Risk scored reviews:&lt;/strong&gt; AI Agents will automate the &lt;em&gt;prep work&lt;/em&gt; for manual reviews. Before a human architect reviews a deployment, the agent will generate a comprehensive risk report, checking compliance, cost forecast, and architectural fitness against the enterprise framework, presenting the reviewer with a simple risk score and a go/no-go Recommendation.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Strategic friction:&lt;/strong&gt; This mechanism acts as the necessary point of strategic friction. While golden paths, guardrails, and safety nets achieve near-full autonomy, the manual review remains a crucial step for accountability and holistic risk assessment that only human judgment can provide.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;The future of approval:&lt;/strong&gt; Manual review shifts from a bureaucratic bottleneck to a brief, highly informed, high-impact decision-making process.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Conclusion: Architecting for the agentic future&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Many of these capabilities are being explored incrementally across the cloud native ecosystem through open source projects, standards discussions, and platform engineering communities, rather than as a single unified solution.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;The new mandate:&lt;/strong&gt; Enterprise IT leaders should stop viewing AI as a feature and start architecting for an &lt;strong&gt;agentic infrastructure platform&lt;/strong&gt; that effectively manages these four distinct control mechanisms.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;The outcome:&lt;/strong&gt; By granting full autonomy to the steering (golden paths), prevention (guardrails), and recovery (safety nets), and strategically implementing AI-optimized manual review, organizations could achieve unprecedented speed, resilience, and compliance in 2026.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Recent data from the &lt;/em&gt;&lt;em&gt;&lt;a href=&#34;https://www.cncf.io/wp-content/uploads/2025/11/cncf_report_stateofcloud_111025a.pdf?utm_source=chatgpt.com&#34;&gt;CNCF’s State of Cloud Native Development report&lt;/a&gt; &lt;/em&gt;&lt;em&gt;(Nov 2025) aligns with broader industry signals pointing toward increased interest in autonomous and AI-assisted platforms&lt;/em&gt;&lt;em&gt;: with 15.6 million cloud-native developers and ‘Agentic AI’ platforms like MCP already entering the adoption phase, the industry is moving exactly where we predicted—toward a fully autonomous, platform-managed future.&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;DevOps 和平台工程的承诺是平衡开发人员速度与企业治理。到 2026 年，人工智能代理将从简单的辅助工具转变为自动化实现这种平衡的核心机制。最近的出版物，例如 CNCF &lt;a href=&#34;https://www.cncf.io/wp-content/uploads/2025/11/cncf_report_stateofcloud_111025a.pdf?utm_source=chatgpt.com&#34;&gt;2025 技术雷达&lt;/a&gt;报告，强调了对代理 AI 标准（例如 MCP）不断进行的实验。 2026 年伊始，是时候预测企业将如何通过四种不同的人工智能驱动的控制机制来定义向自治的转变：黄金路径、护栏、安全网和手动审核工作流程。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;治理自主企业&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;根据与大型企业平台工程团队的对话以及更广泛的行业信号，2026 年的一些基本优先事项正在浮现：速度、安全性和成本优化应自主实现。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这反映了整个行业的强大共识，主要集中在以下关键转变：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;2026 年潜在的范式转变：&lt;/strong&gt;人工智能的角色可能会从副驾驶演变为代理，在关键任务（配置、安全、事件响应）上拥有授权。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;控制的必要性：&lt;/strong&gt;这种新的自动化水平需要复杂的治理框架。通用的“护栏”方法是不够的；成功取决于清晰的控制分类。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;四大控制支柱&lt;/strong&gt;：这些支柱（&lt;strong&gt;黄金路径、护栏、安全网和手动审核工作流程&lt;/strong&gt;）可以为大型企业的高速基础设施管理奠定适应性、安全的基础。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;黄金路径：自我调整、自主之路&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;黄金路径&lt;/strong&gt;是精心策划、预先批准的蓝图，使安全、合规的选择成为开发人员&lt;em&gt;最简单&lt;/em&gt;的选择（例如，标准化 IaC 模块、自助服务门户）。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;2026 年预测：增加生成和优化的自主权&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;基础设施意图：&lt;/strong&gt;人工智能代理将超越简单的代码生成。开发人员输入高级要求（例如“我需要为 AWS 美国东部的应用程序提供安全、可扩展的服务”），AI 代理将根据预定义的黄金路径完全构建、验证和配置合规基础设施。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;“看门人”代理：&lt;/strong&gt;配置只是成功的一半。到 2026 年，黄金路径将包括嵌入的“生存时间”策略。自主代理将主动识别并停用“僵尸基础设施”（孤立资源、闲置开发环境），解决云浪费和减少安全攻击面。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;持续路径改进&lt;/strong&gt;：代理将持续监控这些黄金路径的性能、成本和采用情况。他们会建议并在许多情况下自主实施改进，例如更换资源类型或优化默认配置，以满足定义的 SLO（服务级别目标）和 FinOps 目标。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;平台工程师的角色&lt;/strong&gt;：转向人工智能驱动的黄金路径的策划和质量控制，确保&lt;em&gt;最佳&lt;/em&gt;实践始终是&lt;em&gt;默认&lt;/em&gt;实践。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;护栏：自治治理和零漂移保证&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;护栏&lt;/strong&gt;是硬性的、不可协商的停止——“崩溃屏障”——防止危及平台安全性或稳定性的操作或配置（例如，阻止公共存储桶、强制执行二进制授权）。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;2026 年预测：从反应式扫描仪到主动式 AI 执行器&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;人工智能驱动的策略即代码：&lt;/strong&gt;代理会将高级合规性要求（例如“PCI-DSS 合规性”）转化为可执行的确定性 Guardrail，并将其部署到整个基础设施生命周期（CI/CD、运行时）。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;自主漏洞响应&lt;/strong&gt;：在发布新的关键漏洞 (CVE) 或安全补丁后，人工智能驱动的系统可能会在受影响环境中的预定义策略和人工批准的约束（例如网络策略、临时访问限制或容器映像块）下，越来越多地自动化创建和部署运行时护栏。这提供了即时的防御盾牌，将企业的保护时间从几天缩短到几分钟。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;“审核员”代理：&lt;/strong&gt;合规证据收集将完全自动化。由于人工智能代理强制执行护栏，它还将针对 PCI-DSS 或 SOC2 等标准生成实时、不可变的审计报告，从而大大减少通常与审计准备相关的手动工作量。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;自主漂移修复&lt;/strong&gt;：这已成为一项标准功能。人工智能代理将根据黄金路径及其嵌入式护栏定义的所需状态持续扫描实时环境。在检测到未经授权的更改（漂移）后，代理将立即自动恢复或修复错误配置，从而在合规性敏感的环境中接近零配置漂移。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;注重预防&lt;/strong&gt;：人工智能的目标是通过引导开发者走上黄金之路，确保他们很少（如果有的话）遇到护栏。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;安全网：预测可靠性和自动恢复&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;安全网&lt;/strong&gt;是检测故障或威胁并促进快速恢复的反应控制（例如监控、自动回滚、备份程序）。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;2026 年预测：检测和修复完全自主&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;预测性 SRE：&lt;/strong&gt;经过大量可观测性数据训练的 AI 代理将在影响用户之前预测中断和性能下降。他们将使用复杂的模式识别来触发主动扩展或维护，以完全避免事件发生。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;自主事件响应&lt;/strong&gt;：对于确实发生的事件，代理将超越建议 (AIOps 1.0) 转向完全自动修复 (AIOps 2.0)。&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;代理会识别根本原因，将其与适当的运行手册操作相关联，并自主执行修复（例如流量转移、重新启动服务或执行回滚），在许多情况下可能会显着缩短平均解决时间 (MTTR)。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;SRE 的角色演变：&lt;/strong&gt;为安全网代理定义规则、容差和错误预算，并专注于需要人类创造力的复杂、新颖的故障模式。 &lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;由于成本优化被视为 2025 年的首要任务，而混沌工程的采用率仍低于 10%，我们预测市场已为自主“安全网”和“FinOps 代理”做好了准备。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;手动审核工作流程：战略性人机交互&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;手动审核工作流程&lt;/strong&gt;是需要人工判断、监督和干预高风险、复杂或财务决策（例如架构审核、大额预算批准、安全事后分析）的流程。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;2026 年预测：人工智能优化的人类判断&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;风险评分审核：&lt;/strong&gt;AI 代理将自动执行手动审核的&lt;em&gt;准备工作&lt;/em&gt;。在人类架构师审查部署之前，代理将生成全面的风险报告，检查合规性、成本预测和架构是否适合企业框架，向审查者提供简单的风险评分和继续/不继续的建议。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;战略摩擦：&lt;/strong&gt;这一机制是战略摩擦的必要点。虽然黄金通道、护栏和安全网实现了近乎完全的自主，但人工审查仍然是问责制和整体风险评估的关键一步，只有人类的判断才能提供。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;审批的未来&lt;/strong&gt;：人工审核将从官僚主义瓶颈转变为简短、信息丰富、影响力大的决策过程。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;结论：面向代理未来的架构&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;其中许多功能正在云端逐步探索通过开源项目、标准讨论和平台工程社区来构建原生生态系统，而不是作为单一的统一解决方案。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;新任务&lt;/strong&gt;：企业 IT 领导者不应再将 AI 视为一项功能，而是开始构建能够有效管理这四种不同控制机制的&lt;strong&gt;代理基础设施平台&lt;/strong&gt;。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;成果&lt;/strong&gt;：通过赋予指导（黄金路径）、预防（护栏）和恢复（安全网）完全自主权，并战略性地实施人工智能优化的手动审核，组织可以在 2026 年实现前所未有的速度、弹性和合规性。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;来自&lt;/em&gt;&lt;em&gt;&lt;a href=&#34;https://www.cncf.io/wp-content/uploads/2025/11/cncf_report_stateofcloud_111025a.pdf?utm_source=chatgpt.com&#34;&gt;CNCF 云原生开发状况报告&lt;/a&gt;的最新数据&lt;/em&gt;&lt;em&gt;（2025 年 11 月）与更广泛的行业信号一致，表明对自主和人工智能辅助平台的兴趣日益浓厚&lt;/em&gt;&lt;em&gt;：随着 1560 万云原生开发者和 MCP 等“代理人工智能”平台已经进入采用阶段，该行业正朝着我们预测的方向发展——迈向完全自主、平台管理的未来。&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Thu, 22 Jan 2026 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【LitmusChaos Q4 2025 update: community, contributions, and project progress】LitmusChaos 2025 年第 4 季度更新：社区、贡献和项目进展</title>
      <link>https://www.cncf.io/blog/2026/01/22/litmuschaos-q4-2025-update-community-contributions-and-project-progress/</link>
      <description>【&lt;p&gt;As we enter the new year, we’re excited to share the Q4 updates from the LitmusChaos community. Over the past few months, the chaos engineering ecosystem and the LitmusChaos community have continued to grow steadily, driven by strong participation, thoughtful contributions, and meaningful collaboration across the globe.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This blog captures the highlights from &lt;strong&gt;October, November, and December&lt;/strong&gt;, bringing together key project updates, community initiatives, contributor activities, and ecosystem developments around LitmusChaos. Our goal is to keep the community informed, celebrate the work happening across the project, and reflect on the collective progress made during the quarter.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;About LitmusChaos&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://litmuschaos.io/&#34;&gt;LitmusChaos&lt;/a&gt; is an open source chaos engineering platform that helps teams identify weaknesses and potential outages in their infrastructure by running controlled chaos experiments. Built on cloud-native principles, LitmusChaos enables teams to validate system resilience and proactively strengthen their DevOps pipelines against real-world software and infrastructure failures.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Started in late 2017 with a focus on simple chaos jobs for Kubernetes, LitmusChaos became a CNCF Sandbox project in 2020 and was promoted to a CNCF Incubating project in January 2022. Today, the project is maintained by contributors from multiple organizations across cloud-native vendors, solution providers, and end users.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;LitmusChaos is used in production by organizations worldwide, including companies such as Adidas, FIS, iFood, Cyren, Intuit, Lenskart, Orange, as well as technology leaders like Red Hat and VMware.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Project Updates &amp;amp; Releases&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Release 3.24.0 (December 2025)&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The latest release introduces significant enhancements to user experience and system stability. For more details, check out the &lt;a href=&#34;https://github.com/litmuschaos/litmus/releases/tag/3.24.0&#34;&gt;release&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;Key Highlights:&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Enhanced experiment management with editable step names in fault settings, giving users better control over their chaos experiments&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Improved ChaosHub customization capabilities, allowing teams to better tailor their chaos engineering workflows&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Fixed critical UI issues, including blank page rendering in experiment run history and caching problems in the overview page&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Added Kubernetes branding updates and refined the visual interface by removing deprecated elements&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Enhanced image registry flexibility with support for empty registry names&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;New Contributors:&lt;/strong&gt; @LipsaDas0710, @Kamalesh-Seervi, @Poswark, @1spyral, @SharanRP&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Release 3.23.0 (November 2025)&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;A security-focused release that also brought significant documentation improvements and UI enhancements.&amp;nbsp;For more details, check out the &lt;a href=&#34;https://github.com/litmuschaos/litmus/releases/tag/3.23.0&#34;&gt;release&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;Key Highlights:&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Critical security patches addressing multiple CVEs, including authorization bypass vulnerabilities (CVE-2024-45337, CVE-2025-22868, CVE-2025-22869)&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Strengthened JWT secret generation with increased salt length for improved authentication security&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Enhanced chaos probe functionality, allowing probes with the same name across different projects&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Major documentation updates, including new AWS SSM and GCP experiment coverage&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Visual refresh across the platform with updated cloud provider logos (AWS, Azure, GCP, Spring Boot) and improved UI consistency&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Fixed image registry issues and improved error handling for command probes&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;New Contributors:&lt;/strong&gt; @thisis-gp, @Coder-pro1, @Devankguptaa, @VIDHITTS, @72umesh, @khushi1310, @Ayushi-Maurya2904, @harshneyy, @kunalsinghdadhwal, @Avirup-001, @yashgoyal0110, @adi-ray&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Release 3.22.0 (October 2025)&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Focused on security hardening and operational improvements.&amp;nbsp;For more details, check out the &lt;a href=&#34;https://github.com/litmuschaos/litmus/releases/tag/3.22.0&#34;&gt;release&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;Key Highlights:&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Critical security fixes addressing namespace compromise via hostPID and potential denial of service vulnerabilities&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Improved resource management with restrictions on CPU/memory usage&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Enhanced log visibility with fixes to fault execution container logs&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Resolved the missing experiment pod logs issue, improving debugging capabilities&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Removed hardcoded namespaces from Kubernetes manifests for better flexibility&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Fixed server address scheme handling for manifest re-downloads&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;br&gt;&lt;strong&gt;New Contributors:&lt;/strong&gt; @prateekch33, @zyue110026, @PriteshKiri, @Gmerold, @UJESH2K, @harshit12339&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Across these three releases, Litmus Chaos welcomed 28 new contributors, demonstrating strong community momentum. The quarter emphasized security hardening, user experience improvements, and enhanced customization capabilities while maintaining the platform’s commitment to comprehensive chaos engineering tooling.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Innovation Spotlight: LitmusChaos MCP Server&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;October marked a watershed moment for LitmusChaos with the release of our &lt;a href=&#34;https://docs.litmuschaos.io/docs/mcp-server/overview&#34;&gt;&lt;strong&gt;Model Context Protocol (MCP) Server&lt;/strong&gt;&lt;/a&gt; – a revolutionary integration that brings natural language interfaces to chaos engineering.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;What is the LitmusChaos MCP Server?&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The LitmusChaos MCP Server leverages Anthropic’s Model Context Protocol to enable AI assistants like Claude to interact directly with LitmusChaos through natural language. This integration transforms how teams approach chaos engineering by removing technical barriers and making resilience testing accessible to everyone.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Hacktoberfest 2025 (The Month of Open Source)&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Hacktoberfest has always been special for LitmusChaos, and this year, we made it even bigger. The community came together to contribute to LitmusChaos and Litmus Docs, improving the project’s security, user experience, and accessibility with Litmus 4.0.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Here’s what we achieved together in October:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/litmuschaos/litmus&#34;&gt;GitHub&lt;/a&gt; Stars: 112+ new stars&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;23 new contributors to the Litmus repository&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;18 new contributors to the Litmus Docs repository&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;These numbers reflect the incredible passion our contributors showed throughout Hacktoberfest. A big shoutout to everyone who helped strengthen LitmusChaos through code, docs, and discussions!&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;In-Person Meetup Events&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This quarter, we hosted 3 in-person meetups in Bangalore and Hyderabad.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;LitmusChaos x Hacktoberfest Meetup – Bangalore (October 4)&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We kicked off October with an incredible gathering, welcoming more than &lt;strong&gt;130 attendees&lt;/strong&gt; who came to celebrate open source and learn about chaos engineering. Check out a snapshot of the event &lt;a href=&#34;https://www.youtube.com/watch?v=RPXbq4pypns&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1279&#34; height=&#34;720&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image-10.jpg&#34; alt=&#34;Group photo of the LitmusChaos Hacktoberfest Meetup in Bangalore&#34; class=&#34;wp-image-154923&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image-10.jpg 1279w, https://www.cncf.io/wp-content/uploads/2026/01/image-10-300x169.jpg 300w, https://www.cncf.io/wp-content/uploads/2026/01/image-10-1024x576.jpg 1024w, https://www.cncf.io/wp-content/uploads/2026/01/image-10-768x432.jpg 768w, https://www.cncf.io/wp-content/uploads/2026/01/image-10-900x507.jpg 900w, https://www.cncf.io/wp-content/uploads/2026/01/image-10-355x200.jpg 355w, https://www.cncf.io/wp-content/uploads/2026/01/image-10-711x400.jpg 711w&#34; sizes=&#34;auto, (max-width: 1279px) 100vw, 1279px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Hacktoberfest Hyderabad Meetup (October 11)&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We hosted an additional Hacktoberfest meetup in&amp;nbsp;Hyderabad that continued to bring together passionate open-source enthusiasts. You can see a short video of the event &lt;a href=&#34;https://www.youtube.com/watch?v=NO_Vfaqnk7E&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1280&#34; height=&#34;720&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2026/01/1760268625432.jpeg&#34; alt=&#34;Group photo of the second LitmusChaos Hacktoberfest Meetup in Hyderabad&#34; class=&#34;wp-image-154924&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2026/01/1760268625432.jpeg 1280w, https://www.cncf.io/wp-content/uploads/2026/01/1760268625432-300x169.jpeg 300w, https://www.cncf.io/wp-content/uploads/2026/01/1760268625432-1024x576.jpeg 1024w, https://www.cncf.io/wp-content/uploads/2026/01/1760268625432-768x432.jpeg 768w, https://www.cncf.io/wp-content/uploads/2026/01/1760268625432-900x506.jpeg 900w, https://www.cncf.io/wp-content/uploads/2026/01/1760268625432-356x200.jpeg 356w, https://www.cncf.io/wp-content/uploads/2026/01/1760268625432-711x400.jpeg 711w&#34; sizes=&#34;auto, (max-width: 1280px) 100vw, 1280px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Resilience and Chaos Testing Meetup (December 6)&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The energy in the room was incredible for the first meetup that I’ve hosted around Chaos and Resilience testing, and the feedback from the community was amazing. You can read more about the event &lt;a href=&#34;https://www.linkedin.com/pulse/my-first-resilience-testing-meetup-new-harness-office-pritesh-kiri-mwcqc/?trackingId=YB6wAcKAQPejftX4aoH7WA%3D%3D&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1600&#34; height=&#34;1115&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image.jpeg&#34; alt=&#34;Group photo of the Resilience and Chaos Testing Meetup&#34; class=&#34;wp-image-154922&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image.jpeg 1600w, https://www.cncf.io/wp-content/uploads/2026/01/image-300x209.jpeg 300w, https://www.cncf.io/wp-content/uploads/2026/01/image-1024x714.jpeg 1024w, https://www.cncf.io/wp-content/uploads/2026/01/image-768x535.jpeg 768w, https://www.cncf.io/wp-content/uploads/2026/01/image-900x627.jpeg 900w, https://www.cncf.io/wp-content/uploads/2026/01/image-287x200.jpeg 287w, https://www.cncf.io/wp-content/uploads/2026/01/image-574x400.jpeg 574w&#34; sizes=&#34;auto, (max-width: 1600px) 100vw, 1600px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Latest from the LitmusChaos Community&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;User Stories:&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1999&#34; height=&#34;992&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image2.png&#34; alt=&#34;intertech logo&#34; class=&#34;wp-image-155550&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image2.png 1999w, https://www.cncf.io/wp-content/uploads/2026/01/image2-300x149.png 300w, https://www.cncf.io/wp-content/uploads/2026/01/image2-1024x508.png 1024w, https://www.cncf.io/wp-content/uploads/2026/01/image2-768x381.png 768w, https://www.cncf.io/wp-content/uploads/2026/01/image2-900x447.png 900w, https://www.cncf.io/wp-content/uploads/2026/01/image2-1800x893.png 1800w, https://www.cncf.io/wp-content/uploads/2026/01/image2-403x200.png 403w, https://www.cncf.io/wp-content/uploads/2026/01/image2-806x400.png 806w&#34; sizes=&#34;auto, (max-width: 1999px) 100vw, 1999px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Here is a sneak peek into the adopter story presented by &lt;a href=&#34;https://www.intertech.com.tr/&#34;&gt;&lt;strong&gt;Intertech&lt;/strong&gt;&lt;/a&gt; on how they are using LitmusChaos:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Intertech, Turkey’s largest financial technology software company, uses Litmus to proactively ensure the resilience of its critical banking infrastructure. Integrated into their SRE practices on a Kubernetes-based platform, Litmus enables Intertech to run chaos experiments such as pod failures, network latency, and resource stress to validate system behavior under real-world failure scenarios. By leveraging Litmus’ Kubernetes-native and customizable chaos engineering framework, Intertech has strengthened incident response readiness and improved the overall reliability of its banking applications, helping safeguard services for millions of customers.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Community Content&amp;nbsp;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As the community continues to grow, so does the content. Over the quarter, the community members have created some amazing and exciting content to uplift the presence of LitmusChaos on the Cloud Native map. Check out all the latest content curated by the community for the community:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Monthly Community Meetings&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Held every third Wednesday of the month at 10 PM IST / 6:30 PM CET / 5:30 PM BST / 11:30 AM CT / 9:30 AM PST, community meetings remained vibrant hubs of discussion throughout Q4. You can find the &lt;a href=&#34;https://www.youtube.com/playlist?list=PLmM1fgu30seVxbGPRTG8sRwILwDTHhuUn&#34;&gt;recordings of all meetings&lt;/a&gt; on our YouTube channel, along with the meeting notes &lt;a href=&#34;https://hackmd.io/a4Zu_sH4TZGeih-xCimi3Q?view&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Monthly Contributors Meetings&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Held every second and last Thursday at 7:00 PM IST / 1:30 PM GMT / 3:30 PM CEST / 9:30 AM ET, our contributor meetings maintained strong participation. Topics included technical implementation discussions, code reviews, documentation improvements, new feature proposals, and bug triage and prioritization. Find the &lt;a href=&#34;https://www.youtube.com/playlist?list=PLmM1fgu30seUavpD-pBRsmWiUCZ2EaM_G&#34;&gt;videos on YouTube&lt;/a&gt; and the meeting notes &lt;a href=&#34;https://docs.google.com/document/d/1AoXIPofrl1qEsPENVuYCJJxdB0kTjvRC3j5JRXmz8d4/edit?tab=t.0&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Videos and Blogs:&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;You can see other previously held in-person and virtual meetups on our &lt;a href=&#34;https://www.youtube.com/@litmuschaos&#34;&gt;YouTube channel&lt;/a&gt;, in addition to getting started content and technical deep dives.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For blog content, visit the &lt;a href=&#34;https://litmuschaos.io/blog&#34;&gt;LitmusChaos blog&lt;/a&gt; and &lt;a href=&#34;http://dev.to/&#34;&gt;DEV.to&lt;/a&gt; for the latest community updates.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Closing Thoughts&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Q4 2025 exemplified what makes open-source communities powerful: collaboration, innovation, and shared purpose. From the groundbreaking MCP Server to record-breaking Hacktoberfest participation, from enterprise adoption milestones to vibrant in-person meetups – every achievement reflects the passion and dedication of this community.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As we enter 2026, we’re energized by the possibilities ahead. Chaos engineering is evolving from a specialized practice to an essential discipline, and LitmusChaos is at the forefront of this transformation.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Here’s to building more resilient systems together. Here’s to chaos engineering for everyone. Here’s to an incredible 2026.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Keep Learning. Keep Testing. Keep Building Resilience&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Connect with LitmusChaos&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The LitmusChaos community continues to grow with amazing contributions (issue identification, suggestions, and PRs), and is looking forward to another year of contributions and growth.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Visit the &lt;a href=&#34;https://litmuschaos.io/&#34;&gt;LitmusChaos Website&lt;/a&gt; for more detailed information about LitmusChaos and getting involved with the community.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Resources&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Join the #litmus channel on Kubernetes Slack to engage the community and learn, ask, and contribute.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Stay updated with the blog, and contribute your own blog content by using the tag #litmuschaos on DEV.to.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Fill out &lt;a href=&#34;https://forms.gle/TYGmnCfGjuQDYHMc7&#34;&gt;&lt;strong&gt;this&lt;/strong&gt;&lt;/a&gt; form to get an invite to our contributors and community calls.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Check out the &lt;a href=&#34;https://github.com/litmuschaos/litmus/blob/master/CONTRIBUTING.md&#34;&gt;Contributing Guide&lt;/a&gt; to get started with contributions.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Subscribe to the &lt;a href=&#34;https://www.youtube.com/channel/UCa57PMqmz_j0wnteRa9nCaw&#34;&gt;LitmusChaos YouTube Channel&lt;/a&gt; for the latest videos.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Follow &lt;a href=&#34;https://twitter.com/LitmusChaos&#34;&gt;@LitmusChaos&lt;/a&gt; on X/Twitter for the latest social updates.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;在进入新的一年之际，我们很高兴分享 LitmusChaos 社区的第四季度更新。在过去的几个月里，在全球范围内的大力参与、深思熟虑的贡献和有意义的合作的推动下，混沌工程生态系统和 LitmusChaos 社区持续稳定增长。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;此博客记录了&lt;strong&gt;10 月、11 月和 12 月&lt;/strong&gt;的亮点，汇集了围绕 LitmusChaos 的关键项目更新、社区计划、贡献者活动和生态系统开发。我们的目标是让社区随时了解情况，庆祝整个项目所开展的工作，并反思本季度取得的集体进展。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;关于 LitmusChaos&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://litmuschaos.io/&#34;&gt;LitmusChaos&lt;/a&gt; 是一个开源混沌工程平台，可帮助团队通过运行受控混沌实验来识别其基础设施中的弱点和潜在中断。 LitmusChaos 基于云原生原则构建，使团队能够验证系统弹性并针对现实世界的软件和基础设施故障主动加强其 DevOps 管道。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;LitmusChaos 于 2017 年底启动，专注于 Kubernetes 的简单混沌作业，于 2020 年成为 CNCF 沙箱项目，并于 2022 年 1 月晋升为 CNCF 孵化项目。如今，该项目由来自云原生供应商、解决方案提供商和最终用户的多个组织的贡献者维护。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;LitmusChaos 被世界各地的组织用于生产，包括 Adidas、FIS、iFood、Cyren、Intuit、Lenskart、Orange 等公司，以及 Red Hat 和 VMware 等技术领导者。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;项目更新和发布&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;版本 3.24.0（2025 年 12 月）&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;最新版本显着增强了用户体验和系统稳定性。有关更多详细信息，请查看&lt;a href=&#34;https://github.com/litmuschaos/litmus/releases/tag/3.24.0&#34;&gt;版本&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;主要亮点：&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;通过故障设置中的可编辑步骤名称增强实验管理，让用户更好地控制混沌实验&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;改进了 ChaosHub 自定义功能，使团队能够更好地定制混沌工程工作流程&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;修复了关键的 UI 问题，包括实验运行历史记录中的空白页面呈现以及概览页面中的缓存问题&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;添加了 Kubernetes 品牌更新，并通过删除已弃用的元素来完善可视界面&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;通过支持空注册表名称增强映像注册表灵活性&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;新贡献者：&lt;/strong&gt;@LipsaDas0710、@Kamalesh-Seervi、@Poswark、@1spyral、@SharanRP&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;版本 3.23.0（2025 年 11 月）&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;一个以安全为重点的版本还带来了重大的文档改进和 UI 增强。 有关更多详细信息，请查看&lt;a href=&#34;https://github.com/litmuschaos/litmus/releases/tag/3.23.0&#34;&gt;版本&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;主要亮点：&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;针对多个 CVE 的关键安全补丁，包括授权绕过漏洞（CVE-2024-45337、CVE-2025-22868、CVE-2025-22869）&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;通过增加盐长度来增强 JWT 密钥生成，以提高身份验证安全性&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;增强了混沌探针功能，允许在不同项目中使用相同名称的探针&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;主要文档更新，包括新的 AWS SSM 和 GCP 实验覆盖范围&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;通过更新云提供商徽标（AWS、Azure、GCP、Spring Boot）和改进的 UI 一致性，实现整个平台的视觉刷新&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;修复了图像注册表问题并改进了命令探测的错误处理&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;新贡献者：&lt;/strong&gt;@thisis-gp、@Coder-pro1、@Devankguptaa、@VIDHITTS、@72umesh、@khushi1310、@Ayushi-Maurya2904、@harshneyy、@kunalsinghdadhwal、@Avirup-001、@yashgoyal0110、@adi-ray&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;版本 3.22.0（2025 年 10 月）&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;专注于安全强化和运营改进。 有关更多详细信息，请查看&lt;a href=&#34;https://github.com/litmuschaos/litmus/releases/tag/3.22.0&#34;&gt;版本&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;主要亮点：&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;重要的安全修复，解决了通过 hostPID 造成的命名空间泄露和潜在的拒绝服务漏洞&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;改进了资源管理，限制了 CPU/内存使用&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;通过修复故障执行容器日志来增强日志可见性&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;解决了实验 Pod 日志缺失的问题，提高了调试能力&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;从 Kubernetes 清单中删除了硬编码命名空间，以提高灵活性&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;修复了清单重新下载的服务器地址方案处理&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;br&gt;&lt;strong&gt;新贡献者：&lt;/strong&gt;@prateekch33、@zyue110026、@PriteshKiri、@Gmerold、@UJESH2K、@harshit12339&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在这三个版本中，Litmus Chaos 迎来了 28 位新贡献者，展现了强大的社区势头。本季度强调安全强化、用户体验改进和增强的定制功能，同时保持平台对全面混沌工程工具的承诺。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;创新聚焦：LitmusChaos MCP 服务器&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;10 月标志着 LitmusChaos 的一个分水岭，我们发布了&lt;a href=&#34;https://docs.litmuschaos.io/docs/mcp-server/overview&#34;&gt;&lt;strong&gt;模型上下文协议 (MCP) 服务器&lt;/strong&gt;&lt;/a&gt;，这是一种革命性的集成，为混沌工程带来了自然语言界面。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;什么是 LitmusChaos MCP 服务器？&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;石蕊混沌MCP 服务器利用 Anthropic 的模型上下文协议，使 Claude 等 AI 助手能够通过自然语言直接与 LitmusChaos 交互。这种集成消除了技术障碍并使每个人都可以进行弹性测试，从而改变了团队处理混沌工程的方式。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Hacktoberfest 2025（开源月）&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Hacktoberfest 一直对 LitmusChaos 来说很特别，今年我们把它做得更大。社区齐心协力为 LitmusChaos 和 Litmus Docs 做出贡献，利用 Litmus 4.0 提高项目的安全性、用户体验和可访问性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;以下是我们在 10 月份共同取得的成就：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/litmuschaos/litmus&#34;&gt;GitHub&lt;/a&gt; 星星：112+ 新星星&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Litmus 存储库的 23 位新贡献者&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Litmus Docs 存储库新增 18 位贡献者&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这些数字反映了我们的贡献者在 Hacktoberfest 期间表现出的令人难以置信的热情。向所有通过代码、文档和讨论帮助加强 LitmusChaos 的人表示大力的感谢！&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;面对面聚会活动&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;本季度，我们在班加罗尔和海得拉巴举办了 3 场面对面聚会。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;LitmusChaos x Hacktoberfest 聚会 - 班加罗尔（10 月 4 日）&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们以一次令人难以置信的聚会拉开了 10 月的序幕，欢迎超过 &lt;strong&gt;130 名与会者&lt;/strong&gt;前来庆祝开源并了解混沌工程。 &lt;a href=&#34;https://www.youtube.com/watch?v=RPXbq4pypns&#34;&gt;此处&lt;/a&gt;查看活动快照。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; Decoding=&#34;async&#34; width=&#34;1279&#34; height=&#34;720&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image-10.jpg&#34; alt=&#34;班加罗尔 LitmusChaos Hacktoberfest 聚会合影&#34; class=&#34;wp-image-154923&#34; srcset =“https://www.cncf.io/wp-content/uploads/2026/01/image-10.jpg 1279w，https://www.cncf.io/wp-content/uploads/2026/01/image-10-300x169.jpg 300w， https://www.cncf.io/wp-content/uploads/2026/01/image-10-1024x576.jpg 1024w，https://www.cncf.io/wp-content/uploads/2026/01/image-10-768x432.jpg 768w， https://www.cncf.io/wp-content/uploads/2026/01/image-10-900x507.jpg 900w，https://www.cncf.io/wp-content/uploads/2026/01/image-10-355x200.jpg 355w， https://www.cncf.io/wp-content/uploads/2026/01/image-10-711x400.jpg 711w“尺寸=”自动，（最大宽度：1279px）100vw，1279px“referrerpolicy=“no-referrer”&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Hacktoberfest 海得拉巴聚会（10 月 11 日）&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们在海得拉巴举办了另一场 Hacktoberfest 聚会，继续将热情的开源爱好者聚集在一起。您可以在&lt;a href=&#34;https://www.youtube.com/watch?v=NO_Vfaqnk7E&#34;&gt;此处&lt;/a&gt;观看该活动的短视频。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“1280”高度=“720”src=&#34;https://www.cncf.io/wp-content/uploads/2026/01/1760268625432.jpeg&#34; alt=&#34;海得拉巴第二届 LitmusChaos Hacktoberfest 聚会合影&#34; class=&#34;wp-image-154924&#34; srcset =“https://www.cncf.io/wp-content/uploads/2026/01/1760268625432.jpeg 1280w，https://www.cncf.io/wp-content/uploads/2026/01/1760268625432-300x169.jpeg 300w， https://www.cncf.io/wp-content/uploads/2026/01/1760268625432-1024x576.jpeg 1024w，https://www.cncf.io/wp-content/uploads/2026/01/1760268625432-768x432.jpeg 768w， https://www.cncf.io/wp-content/uploads/2026/01/1760268625432-900x506.jpeg 900w，https://www.cncf.io/wp-content/uploads/2026/01/1760268625432-356x200.jpeg 356w， https://www.cncf.io/wp-content/uploads/2026/01/1760268625432-711x400.jpeg 711w“尺寸=”自动，（最大宽度：1280像素）100vw，1280像素“referrerpolicy=”no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;弹性和混沌测试聚会（12 月 6 日）&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;对于我举办的第一次围绕混沌和弹性测试的聚会，房间里的能量令人难以置信，来自社区的反馈也令人惊叹。您可以在&lt;a href=&#34;https://www.linkedin.com/pulse/my-first-resilience-testing-meetup-new-harness-office-pritesh-kiri-mwcqc/?trackingId=YB6wAcKAQPejftX4aoH7WA%3D%3D&#34;&gt;此处&lt;/a&gt;了解有关该活动的更多信息。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; Decoding=&#34;async&#34; width=&#34;1600&#34; height=&#34;1115&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image.jpeg&#34; alt=&#34;弹性和混沌测试聚会合影&#34; class=&#34;wp-image-154922&#34; srcset =“https://www.cncf.io/wp-content/uploads/2026/01/image.jpeg 1600w，https://www.cncf.io/wp-content/uploads/2026/01/image-300x209.jpeg 300w， https://www.cncf.io/wp-content/uploads/2026/01/image-1024x714.jpeg 1024w，https://www.cncf.io/wp-content/uploads/2026/01/image-768x535.jpeg 768w， https://www.cncf.io/wp-content/uploads/2026/01/image-900x627.jpeg 900w，https://www.cncf.io/wp-content/uploads/2026/01/image-287x200.jpeg 287w， https://www.cncf.io/wp-content/uploads/2026/01/image-574x400.jpeg 574w&#34;sizes=&#34;auto,(最大宽度:1600px)100vw,1600px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;LitmusChaos 社区的最新动态&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;用户故事：&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt; &lt;img load =“lazy”decoding =“async”width =“1999”height =“992”src =“https://www.cncf.io/wp-content/uploads/2026/01/image2.png”alt =“intertech徽标”class =“wp-image-155550” srcset =“https://www.cncf.io/wp-content/uploads/2026/01/image2.png 1999w，https://www.cncf.io/wp-content/uploads/2026/01/image2-300x149.png 300w， https://www.cncf.io/wp-content/uploads/2026/01/image2-1024x508.png 1024w，https://www.cncf.io/wp-content/uploads/2026/01/image2-768x381.png 768w， https://www.cncf.io/wp-content/uploads/2026/01/image2-900x447.png 900w，https://www.cncf.io/wp-content/uploads/2026/01/image2-1800x893.png 1800w， https://www.cncf.io/wp-content/uploads/2026/01/image2-403x200.png 403w，https://www.cncf.io/wp-content/uploads/2026/01/image2-806x400.png 806w“尺寸=”自动，（最大宽度：1999px）100vw，1999px“referrerpolicy=“no-referrer”&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;以下是 &lt;a href=&#34;https://www.intertech.com.tr/&#34;&gt;&lt;strong&gt;Intertech&lt;/strong&gt;&lt;/a&gt; 介绍的采用者故事，了解他们如何使用 LitmusChaos：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;土耳其最大的金融技术软件公司 Intertech 使用 Litmus 主动确保其关键银行基础设施的弹性。 Litmus 集成到基于 Kubernetes 的平台上的 SRE 实践中，使 Intertech 能够运行 Pod 故障、网络延迟和资源压力等混沌实验，以验证真实故障场景下的系统行为。通过利用 Litmus 的 Kubernetes 原生和可定制的混沌工程框架，Intertech 加强了事件响应准备并提高了其银行应用程序的整体可靠性，帮助保护数百万客户的服务。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;社区内容&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;随着社区不断发展，内容也在不断发展。在本季度，社区成员创建了一些令人惊叹且令人兴奋的内容，以提升 LitmusChaos 在云原生地图上的存在感。查看社区为社区策划的所有最新内容：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;每月社区会议&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;每月第三个星期三晚上 10 点（美国标准时间）/下午 6:30（欧洲中部时间）/下午 5:30（英国夏令时）/上午 11:30（中部时间）/上午 9:30（太平洋标准时间）举行，社区会议在整个第四季度仍然是活跃的讨论中心。您可以在我们的 YouTube 频道上找到&lt;a href=&#34;https://www.youtube.com/playlist?list=PLmM1fgu30seVxbGPRTG8sRwILwDTHhuUn&#34;&gt;所有会议的录音&lt;/a&gt;，以及&lt;a href=&#34;https://hackmd.io/a4Zu_sH4TZGeih-xCimi3Q?view&#34;&gt;此处&lt;/a&gt;的会议记录。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;每月贡献者会议&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们的贡献者会议每隔一秒举行一次，时间为上周四晚上 7:00（美国标准时间）/下午 1:30（格林尼治标准时间）/下午 3:30（欧洲中部夏令时间）/上午 9:30（美国东部时间），我们的贡献者会议保持了强劲的参与度。主题包括技术实施讨论、代码审查、文档改进、新功能提案以及错误分类和优先级。查找 &lt;a href=&#34;https://www.youtube.com/playlist?list=PLmM1fgu30seUavpD-pBRsmWiUCZ2EaM_G&#34;&gt;YouTube 上的视频&lt;/a&gt;和会议记录&lt;a href=&#34;https://docs.google.com/document/d/1AoXIPofrl1qEsPENVuYCJJxdB0kTjvRC3j5JRXmz8d4/edit?tab=t.0&#34;&gt;此处&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;视频和博客：&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;除了入门内容和技术深入探讨之外，您还可以在我们的 &lt;a href=&#34;https://www.youtube.com/@litmuschaos&#34;&gt;YouTube 频道&lt;/a&gt;上观看之前举办的其他现场和虚拟聚会。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;有关博客内容，请访问 &lt;a href=&#34;https://litmuschaos.io/blog&#34;&gt;LitmusChaos 博客&lt;/a&gt; 和 &lt;a href=&#34;http://dev.to/&#34;&gt;DEV.to&lt;/a&gt; 了解最新的社区更新。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;结束语&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;2025 年第四季度的示例它使开源社区变得强大：协作、创新和共同目标。从突破性的 MCP 服务器到破纪录的 Hacktoberfest 参与，从企业采用里程碑到充满活力的面对面聚会 - 每一项成就都体现了这个社区的热情和奉献精神。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;进入 2026 年，我们对未来的可能性充满活力。混沌工程正在从一种专业实践发展成为一门重要学科，而 LitmusChaos 处于这一转变的最前沿。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这是为了共同构建更具弹性的系统。这是为大家带来的混沌工程。为令人难以置信的 2026 年干杯。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;不断学习。继续测试。不断增强韧性&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;与 LitmusChaos 联系&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;LitmusChaos 社区凭借惊人的贡献（问题识别、建议和 PR）继续发展，并期待新的一年的贡献和增长。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;访问 &lt;a href=&#34;https://litmuschaos.io/&#34;&gt;LitmusChaos 网站&lt;/a&gt;，了解有关 LitmusChaos 和参与社区的更多详细信息。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;资源&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;加入 Kubernetes Slack 上的 #litmus 频道，与社区互动并学习、提问和贡献。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;随时了解博客的最新动态，并使用 DEV.to 上的 #litmuschaos 标签贡献您自己的博客内容。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;填写&lt;a href=&#34;https://forms.gle/TYGmnCfGjuQDYHMc7&#34;&gt;&lt;strong&gt;此&lt;/strong&gt;&lt;/a&gt;表单即可获得我们的贡献者和社区电话会议的邀请。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;查看&lt;a href=&#34;https://github.com/litmuschaos/litmus/blob/master/CONTRIBUTING.md&#34;&gt;贡献指南&lt;/a&gt;以开始贡献。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;订阅&lt;a href=&#34;https://www.youtube.com/channel/UCa57PMqmz_j0wnteRa9nCaw&#34;&gt;LitmusChaos YouTube 频道&lt;/a&gt;以获取最新视频。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在 X/Twitter 上关注&lt;a href=&#34;https://twitter.com/LitmusChaos&#34;&gt;@LitmusChaos&lt;/a&gt;，了解最新的社交动态。&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Wed, 21 Jan 2026 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Platform engineering maintenance pitfalls and smart strategies to stay ahead】平台工程维护陷阱和保持领先的明智策略</title>
      <link>https://www.cncf.io/blog/2026/01/21/platform-engineering-maintenance-pitfalls-and-smart-strategies-to-stay-ahead/</link>
      <description>【&lt;p&gt;Platform engineering is a discipline that aims to increase the productivity of software engineering teams by designing, building, and maintaining internal platforms that abstract underlying infrastructure complexity and provide self-service capabilities. Kubernetes-based platforms are often complex multi-Open Source Software (OSS) integrations; thus, platform engineering is not a “declare once and forget it” process. It requires continuous dependency maintenance and strategies for inevitable breaking changes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In this blog post, we’ll go over the integration of fourteen OSS projects to maintain the platform that is built on top of a Kubernetes cluster. We explore the following challenges:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Catching up with software upstream changes&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Controlling the supply chain&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Keeping up with Kubernetes upgrades&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Maintaining Helm chart upgrades&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Maintaining Applications with persistent data&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;The necessity of runtime validation&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Catching Up With Software Upstream Changes&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For this article, we have analyzed the last three years of releases for the following OSS projects: &lt;a href=&#34;https://github.com/argoproj/argo-cd&#34;&gt;argo-cd&lt;/a&gt;, &lt;a href=&#34;https://github.com/knative/serving&#34;&gt;knative-serving&lt;/a&gt;, &lt;a href=&#34;https://github.com/istio/istio&#34;&gt;istio&lt;/a&gt;, &lt;a href=&#34;https://github.com/goharbor/harbor&#34;&gt;harbor&lt;/a&gt;, &lt;a href=&#34;http://github.com/keycloak/keycloak&#34;&gt;keycloak&lt;/a&gt;, &lt;a href=&#34;https://github.com/cloudnative-pg/cloudnative-pg&#34;&gt;cloudnative-pg&lt;/a&gt;, &lt;a href=&#34;https://github.com/go-gitea/gitea&#34;&gt;gitea&lt;/a&gt;, &lt;a href=&#34;https://github.com/kubernetes/ingress-nginx&#34;&gt;ingress-nginx&lt;/a&gt;, &lt;a href=&#34;https://github.com/grafana/grafana&#34;&gt;grafana&lt;/a&gt;, &lt;a href=&#34;https://github.com/bitnami-labs/sealed-secrets&#34;&gt;sealed-secrets&lt;/a&gt;, &lt;a href=&#34;https://github.com/kyverno/kyverno&#34;&gt;kyverno&lt;/a&gt;, &lt;a href=&#34;https://github.com/prometheus/prometheus&#34;&gt;prometheus&lt;/a&gt;, &lt;a href=&#34;https://github.com/kubernetes-sigs/external-dns&#34;&gt;external-dns&lt;/a&gt;, and &lt;a href=&#34;https://github.com/cert-manager/cert-manager&#34;&gt;cert-manager&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Based on our experience and analysis, you can expect between &lt;strong&gt;2-5 major upgrades, 43-52 minor upgrades, and 276-327 software patches every year&lt;/strong&gt;. That’s nearly an update a day!&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1200&#34; height=&#34;742&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image1.png&#34; alt=&#34;Platform engineering build from OSS CNCF projects graph showing the aggregated number of changes per release type of major, minor, and patch.&#34; class=&#34;wp-image-155482&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image1.png 1200w, https://www.cncf.io/wp-content/uploads/2026/01/image1-300x186.png 300w, https://www.cncf.io/wp-content/uploads/2026/01/image1-1024x633.png 1024w, https://www.cncf.io/wp-content/uploads/2026/01/image1-768x475.png 768w, https://www.cncf.io/wp-content/uploads/2026/01/image1-900x557.png 900w, https://www.cncf.io/wp-content/uploads/2026/01/image1-323x200.png 323w, https://www.cncf.io/wp-content/uploads/2026/01/image1-647x400.png 647w&#34; sizes=&#34;auto, (max-width: 1200px) 100vw, 1200px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;A significant challenge arises from the responsibility of maintaining a robust security posture. Every day, a number of security vulnerabilities are discovered. They are addressed in upstream projects that your platform needs to apply as security patches. This significantly contributes to the number of patches from the diagram above. Such changes must be monitored and quickly adopted into your platform.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In line with this, a project or its chart maintainers may opt to stop maintaining previous versions and only provide an upgrade path towards the latest major release, which effectively marks an older major version as end-of-life. Even if you only intend to adopt a security upgrade, you are practically forced to follow the maintained version.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;A significant amount of maintenance effort can be automated, particularly when it comes to identifying new application versions. Helm chart releases are organized in repositories and registries, whereas binary software releases are found on GitHub using their API. This makes essential download and upgrading tasks a good candidate for being delegated to scripts that open a pull request accordingly. Automation addresses the short-term end-of-life problem.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Controlling the Supply Chain&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Recent years taught us that critical parts of the supply chain, such as container registries or Helm chart repositories, can be subject to rate limiting or disruptive changes like deprecation on short notice by either OSS communities or software vendors. Adopting those changes and ensuring platform instances are using the new platform version is often impossible in such a short time frame.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Maintaining a platform-dedicated container registry cache and a mono repository with Helm charts makes code-breaking changes transparent to users and buys platform engineers time to adapt. Similarly, this provides platform administrators the time to plan for an upgrade.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Keeping Up With Kubernetes Upgrades&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;While each Kubernetes minor version is maintained for 12 months, cloud platform providers often push for faster adoption, and expectations are set that users will keep up with the latest version. A new Kubernetes version may come with deprecated APIs that your Helm chart relies on, making upgrading your Helm chart an inevitability.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;A Kubernetes conformance smoke test enables you to discover potential breaking changes. Render all manifests that the platform would deploy and statically test the entire output against the Kubernetes OpenAPI schema, including all added custom resource definitions (CRDs).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Maintaining Helm Chart Upgrades&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;With a &lt;em&gt;platform as a product&lt;/em&gt; mindset, you own the full impact of what you deploy. Community Helm charts may reduce the number of manifests you need to define, but they do not remove the responsibility of understanding exactly what is being introduced into your Kubernetes cluster.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In practice, simply reviewing the Go template code is rarely sufficient to assess the effects of a new chart version on your platform, so other strategies need to be applied. Some of the Helm charts upgrades are delivered with modifications to immutable Kubernetes properties, such as Deployment’s label selector, complicating maintenance and upgrades further.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;By implementing a custom platform operator capable of managing changes to immutable Kubernetes properties, you can ensure a smooth upgrade. Detect potentially disruptive changes before they affect production environments by analyzing rendered Helm chart manifests: current version vs new version. The diff can also be performed against a running cluster, performing a dry run before applying changes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Maintaining Applications With Persistent Data&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Many Helm charts are delivered with dependencies that simplify deployment by bundling essential components such as SQL databases and key-value stores. These maintain the state on their dependent apps, and frequently require persistent volumes to do so.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For example, Helm dependencies declare manifests to deploy a PostgreSQL database service, but do not come with any operator that is aware of database lifecycle management (upgrades, migrations, replication). This “batteries-included” approach simplifies the initial deployment, but is a technical debt for platform operations.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To address these challenges, you must review the included dependency charts to check if they maintain application-critical data. Avoid using SQL databases provided as Helm chart dependencies. Instead, deploy database services via database operators, such as CloudnativePG, that are aware of both Kubernetes storage limitations (e.g., volume attachments) and database lifecycle requirements, such as migration workflows on major upgrades.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;The Necessity of Runtime Validation&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;A Helm chart upgrade that deploys without errors does not necessarily ensure the application still behaves as expected. This goes regardless of whether it relies on core manifests alone or additional custom resources. Code-breaking changes (whether in the chart or the application itself) often will not surface through simple manifest validation. Resources may appear healthy while silently diverging from their previous configuration, and even logs may fail to expose integration issues.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This makes robust quality assurance essential, particularly through automated integration tests where possible. Automated tests should operate on a running cluster to ensure that all services can contact their dependencies and that endpoints are exposed as expected.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Long-term cluster monitoring is essential as well. Issues like applications OOMKilled, CPU throttling, or running out of disk space often occur only after days or even weeks, depending on workload patterns. Detecting these problems early relies heavily on well-designed Prometheus rules. The Kube-Prometheus-Stack offers a solid foundation, but adding application-specific rules and alerting conditions can provide more insights.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Final Thoughts&amp;nbsp;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Once you commit to delivering a platform, you become responsible for the lifecycle of components. The open source community that develops essential applications usually responds quickly to compatibility and security issues; however, these changes still need to be integrated into your platform. You need to prepare for the operational cost, upgrading parts, and replacing components that are no longer maintained. The upside of coordinating this effort in your platform is that it provides relief to development teams from having to perform all the same work simultaneously. A high degree of automation and development of dedicated platform management components and tools ensures long-term maintainability.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Additionally, feedback and upstream contributions are an integral part of using open source software that ensures other users in similar scenarios can benefit from the experience and that upstream projects remain healthy.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;平台工程是一门学科，旨在通过设计、构建和维护内部平台来提高软件工程团队的生产力，这些平台抽象了底层基础设施的复杂性并提供自助服务功能。基于 Kubernetes 的平台通常是复杂的多开源软件 (OSS) 集成；因此，平台工程并不是一个“声明一次就可以忘记”的过程。它需要持续的依赖维护和针对不可避免的重大更改的策略。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在这篇博文中，我们将介绍 14 个 OSS 项目的集成，以维护构建在 Kubernetes 集群之上的平台。我们探讨以下挑战：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;跟上软件上游的变化&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;控制供应链&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;跟上 Kubernetes 升级&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;维护 Helm 图表升级&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;使用持久数据维护应用程序&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;运行时验证的必要性&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;赶上软件上游变化&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在本文中，我们分析了以下 OSS 项目过去三年的版本：&lt;a href=&#34;https://github.com/argoproj/argo-cd&#34;&gt;argo-cd&lt;/a&gt;、&lt;a href=&#34;https://github.com/knative/serving&#34;&gt;knative-serving&lt;/a&gt;、&lt;a href=&#34;https://github.com/istio/istio&#34;&gt;istio&lt;/a&gt;、&lt;a href=&#34;https://github.com/goharbor/harbor&#34;&gt;港口&lt;/a&gt;、&lt;a href=&#34;http://github.com/keycloak/keycloak&#34;&gt;keycloak&lt;/a&gt;、&lt;a href=&#34;https://github.com/cloudnative-pg/cloudnative-pg&#34;&gt;cloudnative-pg&lt;/a&gt;、&lt;a href=&#34;https://github.com/go-gitea/gitea&#34;&gt;gitea&lt;/a&gt;、&lt;a href=&#34;https://github.com/kubernetes/ingress-nginx&#34;&gt;ingress-nginx&lt;/a&gt;、&lt;a href=&#34;https://github.com/grafana/grafana&#34;&gt;grafana&lt;/a&gt;、&lt;a href=&#34;https://github.com/bitnami-labs/sealed-secrets&#34;&gt;密封秘密&lt;/a&gt;、&lt;a href=&#34;https://github.com/kyverno/kyverno&#34;&gt;kyverno&lt;/a&gt;、&lt;a href=&#34;https://github.com/prometheus/prometheus&#34;&gt;prometheus&lt;/a&gt;、&lt;a href=&#34;https://github.com/kubernetes-sigs/external-dns&#34;&gt;external-dns&lt;/a&gt; 和 &lt;a href=&#34;https://github.com/cert-manager/cert-manager&#34;&gt;cert-manager&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;根据我们的经验和分析，您每年预计会出现&lt;strong&gt;2-5 个主要升级、43-52 个次要升级和 276-327 个软件补丁&lt;/strong&gt;。这几乎是一天更新一次！&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt; &lt;img loading =“lazy”decoding =“async”width =“1200”height =“742”src =“https://www.cncf.io/wp-content/uploads/2026/01/image1.png”alt =“OSS CNCF项目图表中的平台工程构建，显示主要，次要和补丁的每个版本类型的更改汇总数量。” class =“wp-image-155482”srcset =“https://www.cncf.io/wp-content/uploads/2026/01/image1.png 1200w，https://www.cncf.io/wp-content/uploads/2026/01/image1-300x186.png 300w， https://www.cncf.io/wp-content/uploads/2026/01/image1-1024x633.png 1024w，https://www.cncf.io/wp-content/uploads/2026/01/image1-768x475.png 768w，https://www.cncf.io/wp-content/uploads/2026/01/image1-900x557.png 900w，https://www.cncf.io/wp-content/uploads/2026/01/image1-323x200.png 323w， https://www.cncf.io/wp-content/uploads/2026/01/image1-647x400.png 647w&#34;sizes=&#34;auto,(最大宽度:1200px)100vw,1200px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;维护稳健的安全态势的责任带来了重大挑战。每天都会发现许多安全漏洞。它们在您的平台需要作为安全补丁应用的上游项目中得到解决。这极大地增加了上图中的补丁数量。必须监控此类更改并快速将其应用到您的平台中。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;与此相一致，项目或其图表维护者可能会选择停止维护以前的版本，而只提供通往最新主要版本的升级路径，这实际上将旧主要版本标记为生命周期结束。即使您只想采用安全升级，您实际上也被迫遵循维护版本。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;大量的维护工作可以实现自动化，特别是在识别新的应用程序版本时。 Helm 图表版本在存储库和注册表中组织，而二进制软件版本则使用其 API 在 GitHub 上找到。这使得基本的下载和升级任务成为委托给相应打开拉取请求的脚本的良好候选者。自动化解决了短期报废问题。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;控制供应链&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;近年来，我们了解到供应链的关键部分（例如容器注册表或 Helm 图表存储库）可能会受到速率限制或破坏性更改的影响，例如 OSS 社区或软件供应商在短时间内通知弃用。在如此短的时间内采用这些更改并确保平台实例使用新的平台版本通常是不可能的。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;维护平台专用的容器注册表缓存和带有 Helm 图表的单一存储库，可以使代码破坏更改对用户透明，并为平台工程师赢得适应时间。同样，这为平台管理员提供了规划升级的时间。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;跟上 Kubernetes 升级&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;虽然每个 Kubernetes 小版本都会维护 12 个月，但云平台提供商通常会推动更快的采用，并且期望用户能够跟上最新版本。新的 Kubernetes 版本可能附带您的 Helm Chart 所依赖的已弃用的 API，这使得升级您的 Helm Chart 成为必然。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes 一致性冒烟测试使您能够发现潜在的重大更改。渲染平台将部署的所有清单，并根据 Kubernetes OpenAPI 架构静态测试整个输出，包括所有添加的自定义资源定义 (CRD)。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 类=“wp-bl”ock-heading&#34;&gt;维护 Helm Chart 升级&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;凭借&lt;em&gt;平台即产品&lt;/em&gt;的心态，您拥有所部署内容的全部影响。社区 Helm 图表可能会减少您需要定义的清单数量，但它们并不能免除准确理解 Kubernetes 集群中引入的内容的责任。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在实践中，仅仅检查 Go 模板代码很少足以评估新图表版本对您平台的影响，因此需要应用其他策略。一些 Helm 图表升级是通过对不可变的 Kubernetes 属性（例如 Deployment 的标签选择器）进行修改而提供的，这使维护和升级进一步复杂化。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;通过实现能够管理不可变 Kubernetes 属性更改的自定义平台操作员，您可以确保顺利升级。通过分析渲染的 Helm 图表清单：当前版本与新版本，在潜在的破坏性更改影响生产环境之前检测到它们。还可以针对正在运行的集群执行差异，在应用更改之前执行试运行。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;使用持久数据维护应用程序&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;许多 Helm 图表都附带依赖项，这些依赖项通过捆绑 SQL 数据库和键值存储等基本组件来简化部署。它们维护其依赖应用程序的状态，并且经常需要持久卷来执行此操作。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;例如，Helm 依赖项声明清单以部署 PostgreSQL 数据库服务，但不附带任何了解数据库生命周期管理（升级、迁移、复制）的操作员。这种“包含电池”的方法简化了初始部署，但对平台运营来说是一种技术债务。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;为了应对这些挑战，您必须查看随附的依赖关系图表，以检查它们是否维护应用程序关键数据。避免使用作为 Helm 图表依赖项提供的 SQL 数据库。相反，通过数据库操作员（例如 CloudnativePG）部署数据库服务，这些操作员了解 Kubernetes 存储限制（例如卷附件）和数据库生命周期要求（例如重大升级时的迁移工作流程）。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;运行时验证的必要性&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;部署无错误的 Helm 图表升级不一定能确保应用程序仍按预期运行。无论它是单独依赖核心清单还是依赖额外的自定义资源，这都是如此。代码破坏性更改（无论是在图表中还是应用程序本身）通常不会通过简单的清单验证而显现出来。资源可能看起来很健康，但悄悄地偏离了以前的配置，甚至日志也可能无法暴露集成问题。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这使得强大的质量保证变得至关重要，特别是在可能的情况下通过自动化集成测试。自动化测试应该在运行时运行集群以确保所有服务都可以联系其依赖项，并且端点按预期公开。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;长期集群监控也很重要。应用程序 OOMKilled、CPU 限制或磁盘空间不足等问题通常仅在几天甚至几周后发生，具体取决于工作负载模式。及早发现这些问题在很大程度上依赖于精心设计的 Prometheus 规则。 Kube-Prometheus-Stack 提供了坚实的基础，但添加特定于应用程序的规则和警报条件可以提供更多见解。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;最终想法&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;一旦您承诺交付一个平台，您就需要对组件的生命周期负责。开发重要应用程序的开源社区通常会对兼容性和安全问题做出快速响应；但是，这些更改仍然需要集成到您的平台中。您需要为运营成本、升级零件以及更换不再维护的组件做好准备。在平台中协调这项工作的好处是，它可以让开发团队不必同时执行所有相同的工作。高度自动化以及专用平台管理组件和工具的开发确保了长期的可维护性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;此外，反馈和上游贡献是使用开源软件不可或缺的一部分，可确保类似场景中的其他用户可以从体验中受益，并确保上游项目保持健康。&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Tue, 20 Jan 2026 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Kubernetes Fuels AI Growth; Organizational Culture Remains the Decisive Factor】Kubernetes 推动人工智能发展；组织文化仍然是决定性因素</title>
      <link>https://www.cncf.io/blog/2026/01/20/kubernetes-fuels-ai-growth-organizational-culture-remains-the-decisive-factor/</link>
      <description>【&lt;p&gt;The &lt;a href=&#34;https://www.cncf.io/reports/the-cncf-annual-cloud-native-survey/&#34;&gt;CNCF Annual Cloud Native Survey&lt;/a&gt; confirms a long-developing trend: Kubernetes has moved from container orchestration to becoming the backbone of modern infrastructure—including AI.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Production usage of Kubernetes now stands at 82% among container users, and 66% of AI adopters are using it to scale inference workloads. Kubernetes is no longer a niche tool; it’s a core infrastructure layer supporting scale, reliability, and increasingly AI systems.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This shift reflects both the technical evolution and growing operational maturity of the cloud native ecosystem. 98% of organizations surveyed have now adopted cloud native technologies, making it the near-universal standard for modern enterprise infrastructure.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image aligncenter size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;434&#34; height=&#34;230&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image-12-2.jpg&#34; alt=&#34;Cloud native adoption reaches 98% across surveyed organizations.&#34; class=&#34;wp-image-155422&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image-12-2.jpg 434w, https://www.cncf.io/wp-content/uploads/2026/01/image-12-2-300x159.jpg 300w, https://www.cncf.io/wp-content/uploads/2026/01/image-12-2-194x102.jpg 194w, https://www.cncf.io/wp-content/uploads/2026/01/image-12-2-377x200.jpg 377w&#34; sizes=&#34;auto, (max-width: 434px) 100vw, 434px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Kubernetes: From Infrastructure Choice to Infrastructure Standard&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Survey data shows that Kubernetes has matured into the enterprise default. Organizations have moved beyond experimentation and are now focused on standardizing their infrastructure strategies. With this maturity comes more consistent deployment models and a broader application of cloud native best practices across teams.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image aligncenter size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;886&#34; height=&#34;230&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image-12-3.jpg&#34; alt=&#34;66% of organizations use Kubernetes to host generative AI workloads and 82% of container users deploy Kubernetes in production, up from 66% in 2023.&#34; class=&#34;wp-image-155423&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image-12-3.jpg 886w, https://www.cncf.io/wp-content/uploads/2026/01/image-12-3-300x78.jpg 300w, https://www.cncf.io/wp-content/uploads/2026/01/image-12-3-768x199.jpg 768w, https://www.cncf.io/wp-content/uploads/2026/01/image-12-3-600x156.jpg 600w&#34; sizes=&#34;auto, (max-width: 886px) 100vw, 886px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes is now the default choice for building scalable, observable systems. It’s the platform teams rely on as they move from pilots to production-grade AI workloads.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;AI Adoption Is Infrastructure-First&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;There’s often a gap between AI ambition and what infrastructure can support. The 2025 data found that only 7% of organizations deploy AI models daily, and over half don’t train models at all. Instead, many prioritize the reliable and cost-effective operation of pre-trained models.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image aligncenter size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;430&#34; height=&#34;228&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image-12-4.jpg&#34; alt=&#34;47% of organizations deploy AI models occasionally, with only 7% deploying daily.&#34; class=&#34;wp-image-155429&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image-12-4.jpg 430w, https://www.cncf.io/wp-content/uploads/2026/01/image-12-4-300x159.jpg 300w, https://www.cncf.io/wp-content/uploads/2026/01/image-12-4-194x102.jpg 194w, https://www.cncf.io/wp-content/uploads/2026/01/image-12-4-377x200.jpg 377w&#34; sizes=&#34;auto, (max-width: 430px) 100vw, 430px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes is helping bridge that gap, enabling teams to unify how they scale, deploy and manage AI workloads. As the report notes, &lt;em&gt;“Success requires treating AI/ML as a first-class infrastructure challenge, not just an algorithmic one.”&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;What Mature Teams Are Doing: GitOps, Platforms, Observability&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The survey reinforces the growing trend toward platform engineering. Teams that have adopted GitOps workflows, internal developer portals, and automated pipelines are better positioned to scale AI and cloud native workloads.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;A clear signal of maturity: 0% of “explorers” report using GitOps, compared to 58% of “innovators.” These practices represent well-established methods that support consistency, scalability, and operational efficiency.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image aligncenter size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;430&#34; height=&#34;228&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image-12-5.jpg&#34; alt=&#34;GitOps adoption jumps from 0% among cloud native explorers to 58% among cloud native innovators&#34; class=&#34;wp-image-155430&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image-12-5.jpg 430w, https://www.cncf.io/wp-content/uploads/2026/01/image-12-5-300x159.jpg 300w, https://www.cncf.io/wp-content/uploads/2026/01/image-12-5-194x102.jpg 194w, https://www.cncf.io/wp-content/uploads/2026/01/image-12-5-377x200.jpg 377w&#34; sizes=&#34;auto, (max-width: 430px) 100vw, 430px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Observability also continues to be critical as workloads become more dynamic. OpenTelemetry’s position as the second-highest-velocity CNCF project reflects strong momentum for vendor-neutral, standardized instrumentation. Teams now depend on real-time visibility to keep systems reliable and performant in production.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Culture Is Now the Primary Barrier&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For the first time, culture—not complexity or security—is the top barrier to cloud native adoption. 47% of organizations cite cultural change with development teams as their biggest challenge.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image aligncenter size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;430&#34; height=&#34;228&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image-12.jpg&#34; alt=&#34;Cultural changes with the development team ranks as the #1 challenge for deploying containers (47%), surpassing technical concerns.&#34; class=&#34;wp-image-155417&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image-12.jpg 430w, https://www.cncf.io/wp-content/uploads/2026/01/image-12-300x159.jpg 300w, https://www.cncf.io/wp-content/uploads/2026/01/image-12-194x102.jpg 194w, https://www.cncf.io/wp-content/uploads/2026/01/image-12-377x200.jpg 377w&#34; sizes=&#34;auto, (max-width: 430px) 100vw, 430px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This highlights a recurring insight from the survey: the technical foundation is in place, but many organizations still need to adapt their internal structures and workflows to fully benefit from cloud native capabilities.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Looking Ahead: Infrastructure and Sustainability&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As Kubernetes cements its position as the infrastructure for AI and modern workloads, the community faces the new challenge of sustainability. AI workloads are increasing pressure on open source infrastructure through machine-driven usage.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The report warns that many systems operate on a “dangerously fragile premise.” Ensuring continued innovation will depend on organizations stepping up to contribute, support maintainers, and participate actively in sustaining the ecosystem.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Sustaining the future of cloud native will require intentional investment in infrastructure, governance, and community. CNCF will continue advancing this work through open collaboration, evolving standards, and support for maintainers and contributors across the ecosystem.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For those building at scale, now is the time to align your infrastructure strategy with what the data—and the community—clearly show.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Join our upcoming webinar, &lt;a href=&#34;https://community.cncf.io/events/details/cncf-cncf-online-programs-presents-cloud-native-live-the-cncf-annual-cloud-native-survey-infrastructure-of-ais-future/&#34;&gt;&lt;em&gt;Cloud Native Live: The CNCF Annual Cloud Native Survey — Infrastructure of AI’s Future&lt;/em&gt;&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;on February 3, 2026, to hear SVP of research Hilary Carter and a special guest analyst discuss the results of the survey and what that means for the future of the cloud native ecosystem.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;a href=&#34;https://www.cncf.io/reports/the-cncf-annual-cloud-native-survey/&#34;&gt;CNCF 年度云原生调查&lt;/a&gt;证实了一个长期发展趋势：Kubernetes 已从容器编排转变为包括人工智能在内的现代基础设施的支柱。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;目前容器用户中 Kubernetes 的生产使用率为 82%，66% 的 AI 采用者正在使用它来扩展推理工作负载。 Kubernetes 不再是一个小众工具；它是支持规模、可靠性和日益增长的人工智能系统的核心基础设施层。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这种转变反映了云原生生态系统的技术演变和运营成熟度的提高。 98% 的受访组织现已采用云原生技术，使其成为现代企业基础设施的近乎通用标准。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-imagealigncenter size-full&#34;&gt;&lt;imgloading=&#34;lazy&#34;decoding=&#34;async&#34;width=&#34;434&#34;height=&#34;230&#34;src=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image-12-2.jpg&#34; alt=&#34;在接受调查的组织中，云原生采用率达到 98%。&#34; class =“wp-image-155422”srcset =“https://www.cncf.io/wp-content/uploads/2026/01/image-12-2.jpg 434w，https://www.cncf.io/wp-content/uploads/2026/01/image-12-2-300x159.jpg 300w， https://www.cncf.io/wp-content/uploads/2026/01/image-12-2-194x102.jpg 194w，https://www.cncf.io/wp-content/uploads/2026/01/image-12-2-377x200.jpg 377w“尺寸=”自动，（最大宽度：434px）100vw， 434px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Kubernetes：从基础设施选择到基础设施标准&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;调查数据显示，Kubernetes 已成熟为企业默认。组织已经超越了实验，现在专注于标准化其基础设施战略。随着这种成熟度的到来，部署模型更加一致，云原生最佳实践在团队中得到更广泛的应用。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-imagealigncenter size-full&#34;&gt;&lt;imgloading=&#34;lazy&#34;decoding=&#34;async&#34;width=&#34;886&#34;height=&#34;230&#34;src=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image-12-3.jpg&#34;alt=&#34;66%的组织使用Kubernetes来托管生成式AI工作负载，82%的容器用户在生产中部署Kubernetes，这一比例从2023 年将达到 66%。” class =“wp-image-155423”srcset =“https://www.cncf.io/wp-content/uploads/2026/01/image-12-3.jpg 886w，https://www.cncf.io/wp-content/uploads/2026/01/image-12-3-300x78.jpg 300w， https://www.cncf.io/wp-content/uploads/2026/01/image-12-3-768x199.jpg 768w，https://www.cncf.io/wp-content/uploads/2026/01/image-12-3-600x156.jpg 600w“尺寸=”自动，（最大宽度：886px）100vw， 886px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes 现在是构建可扩展、可观察系统的默认选择。这是团队从试点转向生产级人工智能工作负载时所依赖的平台。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;人工智能采用是基础设施优先&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;经常有一个g人工智能的雄心与基础设施可以支持的内容之间存在一定的差距。 2025 年的数据发现，只有 7% 的组织每天部署人工智能模型，超过一半的组织根本不训练模型。相反，许多人优先考虑预训练模型的可靠且经济高效的运行。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-imagealigncenter size-full&#34;&gt;&lt;imgloading=&#34;lazy&#34;decoding=&#34;async&#34;width=&#34;430&#34;height=&#34;228&#34;src=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image-12-4.jpg&#34; alt=&#34;47% 的组织偶尔部署 AI 模型，只有 7% 每天部署。&#34; class =“wp-image-155429”srcset =“https://www.cncf.io/wp-content/uploads/2026/01/image-12-4.jpg 430w，https://www.cncf.io/wp-content/uploads/2026/01/image-12-4-300x159.jpg 300w， https://www.cncf.io/wp-content/uploads/2026/01/image-12-4-194x102.jpg 194w，https://www.cncf.io/wp-content/uploads/2026/01/image-12-4-377x200.jpg 377w“尺寸=”自动，（最大宽度：430px）100vw， 430px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes 正在帮助弥合这一差距，使团队能够统一扩展、部署和管理 AI 工作负载的方式。正如报告指出的那样，“成功需要将 AI/ML 视为一流的基础设施挑战，而不仅仅是算法挑战。”&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;成熟团队正在做什么：GitOps、平台、可观察性&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;该调查强化了平台工程日益增长的趋势。采用 GitOps 工作流程、内部开发人员门户和自动化管道的团队能够更好地扩展人工智能和云原生工作负载。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;成熟度的明确信号：0% 的“探索者”报告使用 GitOps，而“创新者”的比例为 58%。这些实践代表了支持一致性、可扩展性和运营效率的成熟方法。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-imagealigncenter size-full&#34;&gt;&lt;imgloading=&#34;lazy&#34;decoding=&#34;async&#34;width=&#34;430&#34;height=&#34;228&#34;src=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image-12-5.jpg&#34;alt=&#34;云原生探索者中的 GitOps 采用率从 0% 跃升至云原生创新者中的 58%&#34; class =“wp-image-155430”srcset =“https://www.cncf.io/wp-content/uploads/2026/01/image-12-5.jpg 430w，https://www.cncf.io/wp-content/uploads/2026/01/image-12-5-300x159.jpg 300w， https://www.cncf.io/wp-content/uploads/2026/01/image-12-5-194x102.jpg 194w，https://www.cncf.io/wp-content/uploads/2026/01/image-12-5-377x200.jpg 377w“尺寸=”自动，（最大宽度：430px）100vw， 430px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;随着工作负载变得更加动态，可观察性也仍然至关重要。 OpenTelemetry 作为第二高速度​​ CNCF 项目的地位反映了供应商中立的标准化仪器的强劲势头。团队现在依靠实时可见性来保持系统在生产中的可靠性和性能。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;文化现在是主要障碍&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;第一次，文化——而不是复杂性或安全性——成为了p 云原生采用的障碍。 47% 的组织将开发团队的文化变革视为最大的挑战。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-imagealigncenter size-full&#34;&gt;&lt;imgloading=&#34;lazy&#34;decoding=&#34;async&#34;width=&#34;430&#34;height=&#34;228&#34;src=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image-12.jpg&#34;alt=&#34;开发团队的文化变化被列为部署容器的第一大挑战 (47%)，超过了技术问题。&#34; class =“wp-image-155417”srcset =“https://www.cncf.io/wp-content/uploads/2026/01/image-12.jpg 430w，https://www.cncf.io/wp-content/uploads/2026/01/image-12-300x159.jpg 300w， https://www.cncf.io/wp-content/uploads/2026/01/image-12-194x102.jpg 194w，https://www.cncf.io/wp-content/uploads/2026/01/image-12-377x200.jpg 377w“尺寸=”自动，（最大宽度：430px）100vw， 430px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这凸显了调查中反复出现的一个见解：技术基础已经到位，但许多组织仍然需要调整其内部结构和工作流程，以充分受益于云原生功能。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;展望未来：基础设施和可持续发展&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;随着 Kubernetes 巩固其作为人工智能和现代工作负载基础设施的地位，社区面临着可持续性的新挑战。人工智能工作负载通过机器驱动的使用给开源基础设施带来越来越大的压力。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;该报告警告说，许多系统都在“危险脆弱的前提下”运行。确保持续创新将取决于组织加紧贡献、支持维护者并积极参与维持生态系统。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;维持云原生的未来需要对基础设施、治理和社区进行有意投资。 CNCF 将通过开放协作、不断发展的标准以及对整个生态系统的维护者和贡献者的支持来继续推进这项工作。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;对于那些大规模建设的人来说，现在是根据数据和社区明确显示的内容调整基础设施策略的时候了。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;参加我们即将举行的网络研讨会，&lt;a href=&#34;https://community.cncf.io/events/details/cncf-cncf-online-programs-presents-cloud-native-live-the-cncf-annual-cloud-native-survey-infrastruct-of-ais-future/&#34;&gt;&lt;em&gt;云原生直播：CNCF 年度云原生调查 — 人工智能未来的基础设施&lt;/em&gt;&lt;/a&gt;&lt;em&gt;， &lt;/em&gt;2026 年 2 月 3 日，聆听研究高级副总裁 Hilary Carter 和一位特邀客座分析师讨论调查结果以及这对云原生生态系统的未来意味着什么。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Mon, 19 Jan 2026 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Reclaiming underutilized GPUs in Kubernetes using scheduler plugins】使用调度程序插件回收 Kubernetes 中未充分利用的 GPU</title>
      <link>https://www.cncf.io/blog/2026/01/20/reclaiming-underutilized-gpus-in-kubernetes-using-scheduler-plugins/</link>
      <description>【&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;The problem nobody talks about&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;GPUs are expensive; and yours are probably sitting idle right now. High-end GPUs (for example, NVIDIA A100-class devices) can cost $10,000+, and in a Kubernetes cluster running AI workloads, you might have dozens of them. Here’s the uncomfortable truth: most of the time, they’re sitting idle. If you’re struggling with GPU scheduling in Kubernetes or looking for ways to reclaim idle GPUs, you’re not alone.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;A data scientist spins up a training job, requests 4 GPUs, runs for two hours, then leaves for lunch. The GPUs sit allocated but unused. Meanwhile, another team’s job is queued, waiting for resources that technically exist but aren’t available.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Standard Kubernetes scheduling doesn’t help here. It sees allocated resources as unavailable — period. The scheduler does not currently take real-time GPU utilization into account.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Kubernetes scheduling trade-offs for GPUs&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes was built for CPUs. Its scheduling model assumes resources are either allocated or free, with nothing in between. For CPUs, this mostly works — a pod using 10% of its requested CPU isn’t blocking others in the same way.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;GPUs are different. They’re discrete, expensive, and often requested in large quantities. A pod requesting 4 GPUs gets exactly 4 GPUs, even if it’s only actively using them 20% of the time. This is the core challenge of GPU resource management in Kubernetes — the scheduler has no concept of actual utilization.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The default Kubernetes preemption mechanism (DefaultPreemption) can evict lower-priority pods to make room for higher-priority ones. But it only considers priority — not actual utilization. Pods are treated equivalently from a preemption perspective when they share the same priority, regardless of their current utilization.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We evaluated several existing approaches. For example, device plugins focus on allocation, while autoscaling addresses capacity rather than reclaiming idle resources. Cluster autoscaler can add nodes but won’t reclaim idle resources on existing ones. Various GPU sharing approaches exist, but they don’t address the fundamental scheduling problem.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;The core idea: Utilization-aware preemption&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We needed utilization-aware preemption that considers what GPUs are actually doing, not just what they’ve been allocated. The solution: a custom Kubernetes scheduler plugin for idle GPU reclaim that replaces the default preemption logic with an alternative approach that incorporates utilization signals.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The plugin, which we called ReclaimIdleResource, operates in the PostFilter phase of the scheduling cycle. This is where Kubernetes looks for preemption candidates when a pod can’t be scheduled normally.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Here’s the key insight: instead of just comparing priorities, we query Prometheus for GPU utilization metrics (in our case, sourced from DCGM).&amp;nbsp; A pod is only eligible for preemption if:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;1. Its priority is below the preemptor’s threshold&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;2. It’s been running long enough to establish a usage pattern&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;3. Its actual GPU utilization is below a configured threshold&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This means an idle pod with priority 1000 can be preempted by a pod with priority 500, if the idle pod isn’t actually using its GPUs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Where ReclaimIdleResource fits in the scheduling cycle&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The plugin replaces DefaultPreemption in the PostFilter phase, activating only when normal scheduling fails.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1600&#34; height=&#34;789&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image-13.png&#34; alt=&#34;This image shows a flow chart view of the scheduling cycle. It shows the flow from PreFilter to Filter to Score. At score, if nodes are found, the chart moves straight on to bind. If nodes aren&#39;t found, the flow chart moves to PostFilter ReclaimIdleResource replaces DefaultPreemption. &#34; class=&#34;wp-image-155694&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image-13.png 1600w, https://www.cncf.io/wp-content/uploads/2026/01/image-13-300x148.png 300w, https://www.cncf.io/wp-content/uploads/2026/01/image-13-1024x505.png 1024w, https://www.cncf.io/wp-content/uploads/2026/01/image-13-768x379.png 768w, https://www.cncf.io/wp-content/uploads/2026/01/image-13-900x444.png 900w, https://www.cncf.io/wp-content/uploads/2026/01/image-13-406x200.png 406w, https://www.cncf.io/wp-content/uploads/2026/01/image-13-811x400.png 811w&#34; sizes=&#34;auto, (max-width: 1600px) 100vw, 1600px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;How it works&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The plugin hooks into the scheduler as a PostFilter extension:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;profiles:&#xA;- schedulerName: default-scheduler&#xA;  plugins:&#xA;    postFilter:&#xA;      enabled:&#xA;      - name: ReclaimIdleResource&#xA;      disabled:&#xA;      - name: DefaultPreemption&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;When a GPU-requesting pod can’t be scheduled, the plugin:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;1. Checks cooldown&lt;/strong&gt; — Has this pod recently triggered preemption? If so, wait. This prevents thrashing.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;2. Scans potential victims&lt;/strong&gt; — Finds all lower-priority pods on candidate nodes that have GPUs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;3. Evaluates each victim&lt;/strong&gt; — Parses its PriorityClass for reclaim policy annotations, checks if it’s still in its “toleration period” (grace period after scheduling), queries Prometheus for average GPU utilization over the monitoring window, and compares utilization against the idle threshold.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;4. Selects minimal victims&lt;/strong&gt; — Sorts eligible victims by GPU count (descending) and priority (ascending), then selects the minimum set needed to free enough GPUs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;5. Validates the decision&lt;/strong&gt; — Runs filter plugins to confirm the preemptor will actually fit after preemption.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The policy is defined per-PriorityClass through annotations:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;kind: PriorityClass&#xA;metadata:&#xA;  name: batch-workload&#xA;  annotations:&#xA;    reclaim-idle-resource.scheduling.x-k8s.io/minimum-preemptable-priority: &#34;10000&#34;&#xA;    reclaim-idle-resource.scheduling.x-k8s.io/toleration-seconds: &#34;3600&#34;&#xA;    reclaim-idle-resource.scheduling.x-k8s.io/resource-idle-seconds: &#34;3600&#34;&#xA;    reclaim-idle-resource.scheduling.x-k8s.io/resource-idle-usage-threshold: &#34;10.0&#34;&#xA;value: 8000&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This says: pods in this priority class can tolerate preemption for one hour after scheduling, and can be preempted if their GPU usage stays below 10% for an hour — but only by pods with priority 10000 or higher.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Key design decisions&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Why PriorityClass annotations?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We considered a custom CRD, but PriorityClass already exists in the scheduling mental model. Teams already think about priority when designing workloads. Adding reclaim policy as annotations keeps the configuration close to where people expect it.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Why a monitoring window instead of instant utilization?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;GPU workloads are bursty. A training job might spike to 100% utilization during forward/backward passes, then drop to near-zero during data loading. Instant measurements would give false positives. We use a configurable window (typically 30–60 minutes) to capture the true usage pattern.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Why query Prometheus instead of using in-memory metrics?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The scheduler runs as a single replica. We needed utilization data that survives scheduler restarts and can be queried historically. DCGM exports to Prometheus naturally, and most GPU clusters already have this pipeline.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Why a cooldown period?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Without it, a preemptor pod could trigger preemption, fail to schedule for unrelated reasons, and immediately trigger another preemption attempt. The 30-second cooldown prevents rapid-fire preemption storms.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;What we learned&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Tuning matters more than we expected. &lt;/strong&gt;The idle threshold and monitoring window need to match your workload patterns. Too aggressive and you’ll preempt jobs mid-training. Too conservative and you won’t reclaim much.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Observability is essential. &lt;/strong&gt;We added extensive logging and Kubernetes events so operators can understand why preemption decisions were made. When someone’s job gets preempted, they want to know why.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Multi-Instance GPU (MIG) adds additional scheduling considerations.. &lt;/strong&gt;NVIDIA’s Multi-Instance GPU feature means a single physical GPU can be partitioned. We had to add partition-size compatibility checks to avoid preempting pods on nodes where the preemptor couldn’t run.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Related Links&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;• Kubernetes Scheduler Plugins: https://github.com/kubernetes-sigs/scheduler-plugins&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;• NVIDIA DCGM Exporter: https://github.com/NVIDIA/dcgm-exporter&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Originally published on Medium. Permission granted for republishing on CNCF blog.&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;无人谈论的问题&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;GPU 价格昂贵；而你的可能现在闲置着。高端 GPU（例如 NVIDIA A100 级设备）的价格可能超过 10,000 美元，在运行 AI 工作负载的 Kubernetes 集群中，您可能拥有数十个 GPU。这是一个令人不安的事实：大多数时候，他们都闲着。如果您在 Kubernetes 中的 GPU 调度方面遇到困难，或者正在寻找回收空闲 GPU 的方法，那么您并不孤单。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;一位数据科学家启动一项训练作业，请求 4 个 GPU，运行两个小时，然后出去吃午饭。 GPU 已分配但未使用。与此同时，另一个团队的作业正在排队，等待技术上存在但不可用的资源。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;标准 Kubernetes 调度在这里没有帮助。它将分配的资源视为不可用——就这样。调度程序当前不考虑实时 GPU 利用率。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Kubernetes 调度与 GPU 的权衡&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes 是为 CPU 构建的。其调度模型假设资源要么已分配，要么已释放，没有中间状态。对于 CPU，这在很大程度上是有效的 - 使用其请求 CPU 的 10% 的 Pod 不会以同样的方式阻止其他 Pod。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;GPU 是不同的。它们是离散的、昂贵的，并且通常需要大量的。请求 4 个 GPU 的 Pod 正好获得 4 个 GPU，即使它只在 20% 的时间里主动使用它们。这是 Kubernetes 中 GPU 资源管理的核心挑战——调度器没有实际利用率的概念。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;默认的 Kubernetes 抢占机制（DefaultPreemption）可以驱逐低优先级的 pod，为高优先级的 pod 腾出空间。但它只考虑优先级，而不考虑实际利用率。当 Pod 共享相同的优先级时，从抢占的角度来看，它们被同等对待，无论它们当前的利用率如何。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们评估了几种现有的方法。例如，设备插件专注于分配，而自动缩放则解决容量问题，而不是回收闲置资源。集群自动缩放程序可以添加节点，但不会回收现有节点上的空闲资源。存在各种 GPU 共享方法，但它们并没有解决根本的调度问题。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;核心思想：利用率感知抢占&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们需要利用率感知的抢占，考虑 GPU 实际在做什么，而不仅仅是它们被分配的事情。解决方案：用于空闲 GPU 回收的自定义 Kubernetes 调度程序插件，用包含利用率信号的替代方法替换默认的抢占逻辑。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;该插件我们称为 ReclaimIdleResource，在调度周期的 PostFilter 阶段运行。当 Pod 无法正常调度时，Kubernetes 会在此处寻找抢占候选者。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这里是关键的见解：不仅仅是比较优先级，我们e 查询 Prometheus 以获取 GPU 利用率指标（在我们的示例中，来自 DCGM）。  pod 仅在以下情况下才有资格被抢占：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;1.它的优先级低于抢占者的阈值&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;2.它已经运行了足够长的时间来建立使用模式&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;3.其实际 GPU 利用率低于配置的阈值&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这意味着，如果空闲 Pod 实际上并未使用其 GPU，则优先级为 1000 的空闲 Pod 可以被优先级为 500 的 Pod 抢占。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;ReclaimIdleResource 在调度周期中的位置&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;该插件替换了PostFilter阶段的DefaultPreemption，仅在正常调度失败时激活。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;imgloading=&#34;lazy&#34;decoding=&#34;async&#34; width=&#34;1600&#34; height=&#34;789&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image-13.png&#34; alt=&#34;此图为调度周期的流程图视图，展示了从PreFilter到Filter到Score的流程。在score时，如果找到节点，则图表直线移动如果未找到节点，流程图将移至 PostFilter ReclaimIdleResource 替换 DefaultPreemption。 https://www.cncf.io/wp-content/uploads/2026/01/image-13-300x148.png 300w，https://www.cncf.io/wp-content/uploads/2026/01/image-13-1024x505.png 1024w， https://www.cncf.io/wp-content/uploads/2026/01/image-13-768x379.png 768w，https://www.cncf.io/wp-content/uploads/2026/01/image-13-900x444.png 900w， https://www.cncf.io/wp-content/uploads/2026/01/image-13-406x200.png 406w，https://www.cncf.io/wp-content/uploads/2026/01/image-13-811x400.png 811w“尺寸=”自动，（最大宽度：1600px）100vw， 1600px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;它是如何工作的&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;该插件作为 PostFilter 扩展挂钩到调度程序：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;配置文件：&#xA;- 调度程序名称：默认调度程序&#xA;  插件：&#xA;    后置过滤器：&#xA;      启用：&#xA;      - 名称：回收空闲资源&#xA;      禁用：&#xA;      - 名称：默认抢占&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;当无法调度 GPU 请求的 pod 时，插件：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;强&gt;1。检查冷却时间&lt;/strong&gt; - 此 Pod 最近是否触发了抢占？如果是这样，请等待。这可以防止抖动。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;强&gt;2。扫描潜在受害者&lt;/strong&gt; - 查找具有 GPU 的候选节点上所有优先级较低的 Pod。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;强&gt;3。评估每个受害者 - 解析其 PriorityClass 以获取回收策略注释，检查其是否仍处于“容忍期”（调度后的宽限期），查询 Prometheus 监控窗口内的平均 GPU 利用率，并将利用率与空闲阈值进行比较。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;强&gt;4。选择最少的受害者&lt;/strong&gt; - 按 GPU 数量（降序）和优先级（升序）对符合条件的受害者进行排序，然后选择释放足够 GP 所需的最小集合我们。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;强&gt;5。验证决策&lt;/strong&gt; - 运行过滤器插件以确认抢占器在抢占后确实适合。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;该策略是通过注释按 PriorityClass 定义的：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;种类：优先级&#xA;元数据：&#xA;  名称：批量工作负载&#xA;  注释：&#xA;    回收空闲资源.scheduling.x-k8s.io/最小可抢占优先级：“10000”&#xA;    回收空闲资源.scheduling.x-k8s.io/toleration-秒：“3600”&#xA;    回收空闲资源.scheduling.x-k8s.io/资源空闲秒：“3600”&#xA;    回收-空闲-资源.scheduling.x-k8s.io/resource-idle-usage-threshold：“10.0”&#xA;价值：8000&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这表示：此优先级的 pod 可以在调度后容忍抢占一小时，并且如果 GPU 使用率在一小时内保持在 10% 以下，则可以被抢占 - 但只能被优先级为 10000 或更高的 pod 抢占。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;关键设计决策&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;为什么要使用 PriorityClass 注释？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们考虑了自定义 CRD，但 PriorityClass 已经存在于调度心智模型中。团队在设计工作负载时已经考虑了优先级。添加回收策略作为注释可以使配置接近人们期望的位置。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;为什么采用监控窗口而不是即时利用率？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;GPU 工作负载是突发性的。训练作业在前向/后向传递过程中利用率可能会飙升至 100%，然后在数据加载过程中降至接近于零。即时测量会给出误报。我们使用可配置的窗口（通常为 30-60 分钟）来捕获真实的使用模式。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;为什么查询 Prometheus 而不是使用内存指标？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;调度程序作为单个副本运行。我们需要在调度程序重新启动后仍然存在并且可以历史查询的利用率数据。 DCGM 自然地导出到 Prometheus，并且大多数 GPU 集群已经拥有此管道。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;为什么要有冷却时间？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果没有它，抢占器 Pod 可能会触发抢占，由于不相关的原因而无法调度，并立即触发另一次抢占尝试。 30 秒的冷却时间可以防止速射先发制人的风暴。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;我们学到了什么&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;调整比我们预期的更重要。 &lt;/strong&gt;空闲阈值和监控窗口需要与您的工作负载模式相匹配。过于激进，你会在训练中抢占工作机会。太保守，你不会收回太多。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;可观察性至关重要。 &lt;/strong&gt;我们添加了广泛的日志记录和 Kubernetes 事件，以便操作员能够了解为何做出抢占决策。当某人的工作被抢占时，他们想知道原因。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;多实例 GPU (MIG) 增加了额外的调度考虑因素。&lt;/strong&gt;NVIDIA 的多实例 GPU 功能意味着可以对单个物理 GPU 进行分区。我们必须添加分区-大小兼容性检查，以避免抢占抢占器无法运行的节点上的 pod。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;相关链接&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;• Kubernetes 调度程序插件：https://github.com/kubernetes-sigs/scheduler-plugins&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;• NVIDIA DCGM 导出器：https://github.com/NVIDIA/dcgm-exporter&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;最初发布于 Medium。已获得在 CNCF 博客上重新发布的许可。&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Mon, 19 Jan 2026 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Top 28 Kubernetes resources for 2026: Learn and stay up-to-date】2026 年 28 个 Kubernetes 最佳资源：学习并保持最新状态</title>
      <link>https://www.cncf.io/blog/2026/01/19/top-28-kubernetes-resources-for-2026-learn-and-stay-up-to-date/</link>
      <description>【&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The cloud native community is thriving and Kubernetes has a lot to do with it. In this open source ecosystem, practitioners are continually sharing knowledge, tools, and lessons learned from first-hand experience to help others succeed.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Whether your goal is to learn the fundamentals, stay current on the latest releases and patterns, build an Internal Developer Platform (IDP), or run artificial intelligence (AI) / machine learning (ML) workloads on Kubernetes, there are more resources than any one person could possibly keep up with. This guide is designed for engineers who are new to Kubernetes or those who are already deploying and maintaining workloads in production environments. It’s a curated set of durable, high‑signal places to listen, watch, and discuss different aspects of the K8s and cloud native ecosystem, grouped from fundamentals through advanced operations and community resources.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Start with Fundamentals&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you’re brand-new, work through Fundamentals and Labs before worrying about exams or listening to podcasts. These build basic mental models and vocabulary before you touch a cluster.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/tutorials/&#34;&gt;Kubernetes Basics (Official Tutorials)&lt;/a&gt;: Interactive, in‑browser tutorials from the project maintainers that walk you through core concepts and simple labs.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.udemy.com/course/kubernetes-getting-started/&#34;&gt;Kubernetes Course (Udemy)&lt;/a&gt;: A short, structured video course that reinforces the basics if you prefer an instructor‑led format.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Get into hands-on Labs and Sandboxes&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Once core ideas make sense, practice real commands in safe, disposable environments.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://training.play-with-kubernetes.com/kubernetes-workshop/&#34;&gt;Play with Kubernetes&lt;/a&gt;: A free, browser‑based playground that lets you spin up temporary clusters and experiment without installing anything locally.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://killercoda.com/playgrounds/scenario/kubernetes&#34;&gt;Killercoda Kubernetes Scenarios&lt;/a&gt;: An interactive lab platform with browser terminals and guided Kubernetes scenarios covering pods, deployments, services, networking, and troubleshooting.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://kodekloud.com/studio/labs/kubernetes?ref=kodekloud.com&#34;&gt;KodeKloud Kubernetes Labs&lt;/a&gt;: Hands‑on labs and playgrounds, including&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://training.linuxfoundation.org/certification/certified-kubernetes-administrator-cka/&#34;&gt;Certified Kubernetes Administrator (CKA)&lt;/a&gt;, &lt;a href=&#34;https://training.linuxfoundation.org/certification/certified-kubernetes-application-developer-ckad/&#34;&gt;Certified Kubernetes Application Developer (CKAD)&lt;/a&gt;, &lt;a href=&#34;https://training.linuxfoundation.org/certification/certified-kubernetes-security-specialist/&#34;&gt;Certified Kubernetes Security Specialist (CKS)&lt;/a&gt;‑aligned environments so you can try real commands in a realistic cluster.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Explore learning roadmaps, guides, and exams&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;These help you choose what to learn next instead of bouncing randomly between topics.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://roadmap.sh/kubernetes&#34;&gt;Kubernetes Roadmap&lt;/a&gt;: A community‑maintained visual roadmap that lays out topics from fundamentals through advanced areas like security, observability, and networking.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://devopscube.com/learn-kubernetes-complete-roadmap/&#34;&gt;How to Learn Kubernetes in 2025&lt;/a&gt;: A step‑by‑step guide suggesting an order for core concepts, labs, and complementary tools so you can build a coherent self‑study plan.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;CKA/CKAD/CKS: CNCF exam curricula and handbooks that define the domains and competencies for each certification and double as skill checklists.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Stay current with podcasts&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Use these to reinforce concepts and hear real‑world stories while commuting or context‑switching.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://kubernetespodcast.com/&#34;&gt;Kubernetes Podcast from Google&lt;/a&gt;: A long‑running show with guest insights from the Kubernetes community plus news and commentary from recent releases and events.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://podcasts.apple.com/us/podcast/kubernetes-bytes/id1580068566&#34;&gt;Kubernetes Bytes&lt;/a&gt;: Focuses on Kubernetes and cloud‑native topics, often diving into platform engineering, operations, and ecosystem projects.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://packetpushers.net/podcast/day-two-devops/&#34;&gt;Day Two DevOps&lt;/a&gt;: Conversations with technical leaders on modern DevOps, covering automation, security, networking, and day‑2 concerns.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.softwaredefinedtalk.com/episodes&#34;&gt;Software Defined Talk&lt;/a&gt;: A broader enterprise software and cloud show where Kubernetes, DevOps, serverless, and security are common topics.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://podcasts.apple.com/us/podcast/open-source-data/id1530428904&#34;&gt;Open||Source||Data&lt;/a&gt;: Explores open‑source data, software, and AI through conversations with developers, regulators, and academics, useful for data‑heavy K8s workloads.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://podcast.bretfisher.com/&#34;&gt;DevOps and Docker Talk&lt;/a&gt;: Covers DevOps, cloud management, sysadmin topics, and container tools like Docker, Kubernetes, and Swarm.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.buzzsprout.com/1010419&#34;&gt;The Deep Edge Podcast&lt;/a&gt;: Discusses cloud‑native and networking technologies that underpin more advanced Kubernetes use cases at the edge.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://feeder.co/discover/184933d887/cncf-io&#34;&gt;Cloud Native Engineering&lt;/a&gt;: Aggregates news, events, and deep dives from across the cloud native ecosystem, with frequent coverage of Kubernetes and related CNCF projects.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Explore curated lists, videos, and advanced topics&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Once you’re comfortable, these resources will help you branch into production practices and specialized workloads.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/ramitsurana/awesome-kubernetes&#34;&gt;Awesome Kubernetes&lt;/a&gt;: A long‑standing curated “awesome list” collecting Kubernetes learning material, documentation, tutorials, tools, and blog posts.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/@cncf&#34;&gt;CNCF YouTube Channel&lt;/a&gt;: Publishes KubeCon sessions and highlight reels, Cloud Native Live sessions, and short explainers on Kubernetes, GitOps, and policy as code.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://kube.fm/&#34;&gt;KubeFM&lt;/a&gt;: Features expert opinions, success stories, and failure stories about running and scaling Kubernetes in production.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://dok.community/&#34;&gt;Data on Kubernetes Community&lt;/a&gt;: Focuses on running data‑intensive, stateful, and AI/ML workloads on Kubernetes, with content often tied to live sessions and talks.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Engage: Communities, chat, and events&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As you start building and operating clusters, learning from others is one of the fastest ways to increase your knowledge. Here are some great places to do just that.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Forums and Q&amp;amp;A&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Reddit: &lt;a href=&#34;https://www.reddit.com/r/kubernetes/&#34;&gt;/r/kubernetes/&lt;/a&gt; and &lt;a href=&#34;https://www.reddit.com/r/devops/&#34;&gt;/r/devops/&lt;/a&gt; are best for architecture debates and quick Q&amp;amp;A.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;X (formerly Twitter): &lt;a href=&#34;https://x.com/kubernetesio&#34;&gt;@kubernetesio&lt;/a&gt; and &lt;a href=&#34;https://x.com/learnk8s&#34;&gt;@learnk8s&lt;/a&gt; are great Kubernetes resources.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Bluesky: &lt;a href=&#34;https://bsky.app/profile/kelseyhightower.com&#34;&gt;@kelseyhightower.com&lt;/a&gt; and &lt;a href=&#34;https://bsky.app/profile/cncf.io&#34;&gt;@cncf.io&lt;/a&gt; are active and informative accounts.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Real‑time chat&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Discord: &lt;a href=&#34;https://k8s-at-home.com/&#34;&gt;Kubernetes @ Home&lt;/a&gt; and &lt;a href=&#34;https://discord.com/invite/3F5nvYK&#34;&gt;k8s/openshift&lt;/a&gt; host active discussions around best practices, home‑lab experimentation, cluster configuration, and troubleshooting.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Slack: &lt;a href=&#34;https://slack.cncf.io/&#34;&gt;CNCF Slack&lt;/a&gt; for project/SIG chatter, &lt;a href=&#34;https://www.devopschat.co/community/register&#34;&gt;DevOpsChat&lt;/a&gt; for broader DevOps/SRE, and &lt;a href=&#34;https://fairwindscommunity.slack.com/join/shared_invite/zt-3ki8tr7tv-rLECXXzthoD4L7bDVxVzpg#/shared-invite/email&#34;&gt;Fairwinds OSS Community&lt;/a&gt; for Kubernetes governance and cost topics.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Meetups and events&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.meetup.com/topics/kubernetes/&#34;&gt;Kubernetes Meetups&lt;/a&gt;: Local Cloud Native, DevOps, and Kubernetes meetups around the world that host talks, lightning sessions, and social gatherings. Find one near you!&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cncf.io/kcds/&#34;&gt;Kubernetes Community Days (KCDs)&lt;/a&gt;: Regional, community‑run conferences supported by the CNCF that often include dedicated sessions on AI/ML platforms, data on Kubernetes, platform engineering, MLOps, and more.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://events.linuxfoundation.org/about/calendar/?_sft_lfevent-category=kubecon-cloudnativecon-cncf-events&#34;&gt;KubeCon + CloudNativeCon&lt;/a&gt;: The flagship CNCF events, with hundreds of Kubernetes and Cloud Native sessions, most of which are also later available on YouTube.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Deepen your Kubernetes expertise&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you’re interested in hard‑won expertise on security, cost optimization, and guardrails, you can also explore our library of resources. These focus on practical, production‑grade Kubernetes operations and governance.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.fairwinds.com/kubernetes-security-add-on-management&#34;&gt;eBook: How to Build Better Cluster Security Through Smart Add-On Management&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.fairwinds.com/blog/ai-cloud-native-managing-kubernetes-platform&#34;&gt;Blog: AI Runs Best On Cloud Native—But Who’s Managing the Kubernetes Platform?&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.fairwinds.com/ebook-lessons-learned-from-a-decade-of-managing-k8s&#34;&gt;eBook: Lessons Learned from a Decade of Managing K8s&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.fairwinds.com/blog/benefits-open-source-idp-design-aws&#34;&gt;Blog: The Benefits of Using an Open Source IDP Design On AWS&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you’d rather focus on your building and refining your applications than on cluster upgrades, add‑ons, and security patching, &lt;a href=&#34;https://calendly.com/melissa-fairwinds/30min?__hstc=91154437.4224623da34aa179dfa3b327a9c02dfb.1763141925180.1764879758103.1764881854680.8&amp;amp;__hssc=91154437.1.1764959517974&amp;amp;__hsfp=3440324983&amp;amp;hsCtaTracking=a849dc40-48e5-423e-9ef4-d3a89514017c%7Cacea6f44-9875-48e7-a0e8-09347c53b443&amp;amp;month=2025-12&#34;&gt;talk with us&lt;/a&gt; about Managed Kubernetes‑as‑a‑Service for your mission‑critical workloads.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;云原生社区正在蓬勃发展，Kubernetes 与之有很大关系。在这个开源生态系统中，从业者不断分享知识、工具和从第一手经验中吸取的教训，以帮助他人取得成功。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;无论您的目标是学习基础知识、了解最新版本和模式、构建内部开发人员平台 (IDP)，还是在 Kubernetes 上运行人工智能 (AI)/机器学习 (ML) 工作负载，这里提供的资源比任何人都可能跟上的要多。本指南专为刚刚接触 Kubernetes 或已经在生产环境中部署和维护工作负载的工程师而设计。这是一组精心策划的持久、高信号场所，可供聆听、观看和讨论 K8 和云原生生态系统的不同方面，从基础知识到高级操作和社区资源。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;从基础知识开始&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您是新手，请先完成基础知识和实验，然后再担心考试或收听播客。在您接触集群之前，这些会构建基本的心理模型和词汇。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/tutorials/&#34;&gt;Kubernetes 基础知识（官方教程）&lt;/a&gt;：项目维护人员提供的交互式浏览器内教程，可引导您完成核心概念和简单的实验。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.udemy.com/course/kubernetes-getting-started/&#34;&gt;Kubernetes 课程 (Udemy)&lt;/a&gt;：这是一门简短的结构化视频课程，如果您喜欢讲师指导的形式，可以强化基础知识。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;进入实践实验室和沙盒&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;一旦核心想法有意义，就可以在安全、一次性的环境中练习真正的命令。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://training.play-with-kubernetes.com/kubernetes-workshop/&#34;&gt;玩转 Kubernetes&lt;/a&gt;：一个基于浏览器的免费游乐场，可让您启动临时集群并进行实验，而无需在本地安装任何内容。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://killercoda.com/playgrounds/scenario/kubernetes&#34;&gt;Killercoda Kubernetes 场景&lt;/a&gt;：一个交互式实验室平台，具有浏览器终端和指导性 Kubernetes 场景，涵盖 Pod、部署、服务、网络和故障排除。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://kodekloud.com/studio/labs/kubernetes?ref=kodekloud.com&#34;&gt;KodeKloud Kubernetes 实验室&lt;/a&gt;：实践实验室和游乐场，包括&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://training.linuxfoundation.org/certification/certified-kubernetes-administrator-cka/&#34;&gt;认证 Kubernetes 管理员 (CKA)&lt;/a&gt;、&lt;a href=&#34;https://training.linuxfoundation.org/certification/certified-kubernetes-application-developer-ckad/&#34;&gt;认证 Kubernetes 应用开发人员 (CKAD)&lt;/a&gt;、&lt;a href=&#34;https://training.linuxfoundation.org/certification/certified-kubernetes-security-specialist/&#34;&gt;认证 Kubernetes 安全专家 (CKS)&lt;/a&gt;‑一致的环境，以便您可以在真实的集群中尝试真实的命令。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;探索学习路线图、指南和考试&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这些可以帮助您选择接下来要学习的内容，而不是在主题之间随机切换。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://roadmap.sh/kubernetes&#34;&gt;Kubernetes 路线图&lt;/a&gt;：社区维护的可视化路线图，列出了从基础知识到安全性、可观察性和网络等高级领域的主题。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://devopscube.com/learn-kubernetes-complete-roadmap/&#34;&gt;2025 年如何学习 Kubernetes&lt;/a&gt;：分步指南，建议核心概念、实验和补充工具的顺序，以便您可以制定连贯的自学计划。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;CKA/CKAD/CKS：CNCF 考试课程和手册，定义了每个认证的领域和能力，并兼作技能清单。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;及时了解播客&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;使用它们来强化概念并在通勤或环境切换时听到现实世界的故事。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://kubernetespodcast.com/&#34;&gt;Google 的 Kubernetes 播客&lt;/a&gt;：一个长期播出的节目，包含来自 Kubernetes 社区的嘉宾见解以及来自最新版本和活动的新闻和评论。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://podcasts.apple.com/us/podcast/kubernetes-bytes/id1580068566&#34;&gt;Kubernetes Bytes&lt;/a&gt;：专注于 Kubernetes 和云原生主题，经常深入探讨平台工程、运营和生态系统项目。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://packetpushers.net/podcast/day-two-devops/&#34;&gt;第二天 DevOps&lt;/a&gt;：与技术领导者就现代 DevOps 进行对话，涵盖自动化、安全、网络和第二天关注的问题。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.softwaredefinetalk.com/episodes&#34;&gt;软件定义讲座&lt;/a&gt;：更广泛的企业软件和云展示，其中 Kubernetes、DevOps、无服务器和安全性是常见主题。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://podcasts.apple.com/us/podcast/open-source-data/id1530428904&#34;&gt;开放||源||数据&lt;/a&gt;：通过与开发者、监管机构和学者的对话探索开源数据、软件和人工智能，这对于数据量大的 K8s 工作负载非常有用。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://podcast.bretfisher.com/&#34;&gt;DevOps 和 Docker Talk&lt;/a&gt;：涵盖 DevOps、云管理、系统管理主题以及 Docker、Kubernetes 和 Swarm 等容器工具。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.buzzsprout.com/1010419&#34;&gt;Deep Edge 播客&lt;/a&gt;：讨论支持更高级的边缘 Kubernetes 使用案例的云原生和网络技术。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://feeder.co/discover/184933d887/cncf-io&#34;&gt;云原生工程&lt;/a&gt;：聚合整个云原生生态系统的新闻、事件和深入研究，频繁报道 Kubernetes 和相关 CNCF 项目。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;探索精选列表、视频和高级主题&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;一旦您感到舒适，这些资源将帮助您扩展到生产实践和专门的工作负载。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/ramitsurana/awesome-kubernetes&#34;&gt;Awesome Kubernetes&lt;/a&gt;：长期策划的“很棒列表”，收集 Kubernetes 学习材料、文档、教程、工具和博客文章。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/@cncf&#34;&gt;CNCF YouTube 频道&lt;/a&gt;：发布 KubeCon 会议和精彩片段、云原生直播会议以及有关 Kubernetes、GitOps 和政策即代码的简短说明。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://kube.fm/&#34;&gt;KubeFM&lt;/a&gt;：提供有关在生产中运行和扩展 Kubernetes 的专家意见、成功案例和失败案例。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://dok.community/&#34;&gt;Kubernetes 社区数据&lt;/a&gt;：专注于在 Kubernetes 上运行数据密集型、有状态的 AI/ML 工作负载，内容通常与实时会话和演讲相关。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;参与：社区、聊天和活动&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;当您开始构建和运营集群时，向他人学习是增加知识的最快方法之一。这里有一些很棒的地方可以做到这一点。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;论坛和问答&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;Reddit：&lt;a href=&#34;https://www.reddit.com/r/kubernetes/&#34;&gt;/r/kubernetes/&lt;/a&gt; 和 &lt;a href=&#34;https://www.reddit.com/r/devops/&#34;&gt;/r/devops/&lt;/a&gt; 最适合架构辩论和快速问答。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;X（以前称为 Twitter）：&lt;a href=&#34;https://x.com/kubernetesio&#34;&gt;@kubernetesio&lt;/a&gt; 和 &lt;a href=&#34;https://x.com/learnk8s&#34;&gt;@learnk8s&lt;/a&gt; 是很棒的 Kubernetes 资源。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Bluesky：&lt;a href=&#34;https://bsky.app/profile/kelseyhightower.com&#34;&gt;@kelseyhightower.com&lt;/a&gt; 和 &lt;a href=&#34;https://bsky.app/profile/cncf.io&#34;&gt;@cncf.io&lt;/a&gt; 是活跃且信息丰富的帐户。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;实时聊天&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;Discord：&lt;a href=&#34;https://k8s-at-home.com/&#34;&gt;Kubernetes @ Home&lt;/a&gt; 和 &lt;a href=&#34;https://discord.com/invite/3F5nvYK&#34;&gt;k8s/openshift&lt;/a&gt; 围绕最佳实践、家庭实验室实验、集群配置和故障排除进行积极讨论。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Slack：&lt;a href=&#34;https://slack.cncf.io/&#34;&gt;CNCF Slack&lt;/a&gt; 用于项目/SIG 聊天，&lt;a href=&#34;https://www.devopschat.co/community/register&#34;&gt;DevOpsChat&lt;/a&gt; 用于更广泛的 DevOps/SRE，&lt;a href=&#34;https://fairwindscommunity.slack.com/join/shared_invite/zt-3ki8tr7tv-rLECXXzthoD4L7bDVxVzpg#/shared-invite/email&#34;&gt;Fairwinds OSS 社区&lt;/a&gt;，了解 Kubernetes 治理和成本主题。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;聚会和活动&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.meetup.com/topics/kubernetes/&#34;&gt;Kubernetes 聚会&lt;/a&gt;：世界各地的本地云原生、DevOps 和 Kubernetes 聚会，举办演讲、闪电会议和社交聚会。寻找您附近的一个！&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cncf.io/kcds/&#34;&gt;库布ernetes 社区日 (KCD)&lt;/a&gt;：由 CNCF 支持的区域性社区会议，通常包括有关 AI/ML 平台、Kubernetes 数据、平台工程、MLOps 等的专门会议。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://events.linuxfoundation.org/about/calendar/?_sft_lfevent-category=kubecon-cloudnativecon-cncf-events&#34;&gt;KubeCon + CloudNativeCon&lt;/a&gt;：旗舰 CNCF 活动，举办数百场 Kubernetes 和云原生会议，其中大部分会议稍后还可在 YouTube 上观看。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;加深您的 Kubernetes 专业知识&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您对安全、成本优化和护栏方面来之不易的专业知识感兴趣，您还可以探索我们的资源库。这些重点关注实用的生产级 Kubernetes 操作和治理。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.fairwinds.com/kubernetes-security-add-on-management&#34;&gt;电子书：如何通过智能附加组件管理构建更好的集群安全性&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.fairwinds.com/blog/ai-cloud-native-managing-kubernetes-platform&#34;&gt;博客：人工智能在云原生上运行最佳 - 但谁在管理 Kubernetes 平台？&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.fairwinds.com/ebook-lessons-learned-from-a-decade-of-managing-k8s&#34;&gt;电子书：管理 K8 十年的经验教训&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.fairwinds.com/blog/benefits-open-source-idp-design-aws&#34;&gt;博客：在 AWS 上使用开源 IDP 设计的优势&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您更愿意专注于构建和完善应用程序而不是集群升级、附加组件和安全修补，&lt;a href=&#34;https://calendly.com/melissa-fairwinds/30min?__hstc=91154437.4224623da34aa179dfa3b327a9c02dfb.1763141925180.1764879758103.1764881854680.8&amp;__hssc= 91154437.1.1764959517974&amp;__hsfp=3440324983&amp;hsCtaTracking=a849dc40-48e5-423e- 9ef4-d3a89514017c%7Cacea6f44-9875-48e7-a0e8-09347c53b443&amp;month=2025-12&#34;&gt;谈话与我们联系&lt;/a&gt;了解适用于您的任务关键型工作负载的托管 Kubernetes 即服务。&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Sun, 18 Jan 2026 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【CRI-O completes second OSTIF audit】CRI-O 完成第二次 OSTIF 审核</title>
      <link>https://www.cncf.io/blog/2026/01/16/cri-o-completes-second-ostif-audit/</link>
      <description>【&lt;p&gt;The &lt;strong&gt;Open Source Technology Improvement Fund&lt;/strong&gt; is proud to share the results of our security audit of &lt;a href=&#34;https://cri-o.io/&#34;&gt;&lt;strong&gt;CRI-O&lt;/strong&gt;&lt;/a&gt;. CRI-O is an implementation of the &lt;a href=&#34;https://kubernetes.io/&#34;&gt;Kubernetes&lt;/a&gt; Container Runtime Interface (CRI) that is OCI-compliant (-O) that provides the backend between OCI-format container images and the Kubernetes control plane. With the help of &lt;a href=&#34;https://x41-dsec.de/&#34;&gt;&lt;strong&gt;X41 D-Sec&lt;/strong&gt;&lt;/a&gt; and the &lt;a href=&#34;https://www.cncf.io/&#34;&gt;&lt;strong&gt;Cloud Native Computing Foundation&lt;/strong&gt;&lt;/a&gt; (CNCF), CRI-O completed their &lt;a href=&#34;https://ostif.org/our-audit-of-cri-o-is-complete-high-severity-issues-found-and-fixed/&#34;&gt;second security audit with OSTIF&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Audit Process&lt;/strong&gt;:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This security engagement took place in late fall of 2025, performed by an audit team from X41. By manually reviewing the source code from the CRI-O public repository, with additional support from static analysis tooling, the auditors were able to evaluate the security health of the project. In paying particular attention to package dependencies, the sandbox implementation, fuzzing integration, DoS vectors, and image verification processes, the auditors inspected the project for multiple security concerns relevant to the functionality of the project .&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Audit Results&lt;/strong&gt;:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;2 Findings&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;2 Informational&amp;nbsp;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Further Security Work Recommendations&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The auditor’s report describes the CRI-O code as “well-designed and effectively executed, striking a sound balance between minimalism and practical robustness.” There were two findings with security impact identified by this engagement, and while they are ranked to be Informational findings, the report urges robust and automated security best practices to help runtime and reliability.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Thank you&lt;/strong&gt; to the individuals and groups that made this engagement possible:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;CRI-O maintainers and community, especially: Peter Hunt and Sascha Grunert&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;X41 D-Sec, especially: Markus Vervier, Eric Sesterhenn, Alexander Schloegl, Christian Mayr, Hannes Moesl-Canaval, and Antonela Conti&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;The CNCF&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;You can read the Audit Report &lt;a href=&#34;https://ostif.org/wp-content/uploads/2026/01/X41-OSTIF-CRI-O-Audit-Public-Report-2025-12-03.pdf&#34;&gt;&lt;strong&gt;HERE&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;You can read X41’s Blog &lt;a href=&#34;https://x41-dsec.de/security/research/job/news/2026/01/13/cri-o/&#34;&gt;&lt;strong&gt;HERE&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;strong&gt;开源技术改进基金&lt;/strong&gt;很自豪地分享我们对 &lt;a href=&#34;https://cri-o.io/&#34;&gt;&lt;strong&gt;CRI-O&lt;/strong&gt;&lt;/a&gt; 的安全审计结果。 CRI-O 是 &lt;a href=&#34;https://kubernetes.io/&#34;&gt;Kubernetes&lt;/a&gt; 容器运行时接口 (CRI) 的实现，它符合 OCI 标准 (-O)，提供 OCI 格式容器映像和 Kubernetes 控制平面之间的后端。在 &lt;a href=&#34;https://x41-dsec.de/&#34;&gt;&lt;strong&gt;X41 D-Sec&lt;/strong&gt;&lt;/a&gt; 和&lt;a href=&#34;https://www.cncf.io/&#34;&gt;&lt;strong&gt;云原生计算基金会&lt;/strong&gt;&lt;/a&gt; (CNCF) 的帮助下，CRI-O 完成了他们的&lt;a href=&#34;https://ostif.org/our-audit-of-cri-o-is-complete-high-severity-issues-found-and-fixed/&#34;&gt;OSTIF 进行第二次安全审核&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;审核流程&lt;/strong&gt;：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;此次安全活动于 2025 年秋末进行，由 X41 的审计团队执行。通过手动审查 CRI-O 公共存储库中的源代码，并借助静态分析工具的额外支持，审计人员能够评估项目的安全健康状况。审计人员特别关注包依赖性、沙箱实现、模糊集成、DoS 向量和图像验证过程，检查了项目是否存在与项目功能相关的多个安全问题。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;审核结果&lt;/strong&gt;：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;2 项调查结果&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;2 信息性&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;进一步的安全工作建议&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;审计报告将 CRI-O 代码描述为“精心设计且有效执行，在极简主义和实用稳健性之间取得了良好的平衡。”这次活动确定了两项具有安全影响的调查结果，虽然它们被列为信息性调查结果，但该报告敦促强大的自动化安全最佳实践来帮助运行时间和可靠性。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;感谢&lt;/strong&gt;促成此次参与的个人和团体：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;CRI-O 维护者和社区，尤其是：Peter Hunt 和 Sascha Grunert&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;X41 D-Sec，尤其是：Markus Vervier、Eric Sesterhenn、Alexander Schloegl、Christian Mayr、Hannes Moesl-Canaval 和 Antonela Conti&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;CNCF&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;您可以&lt;a href=&#34;https://ostif.org/wp-content/uploads/2026/01/X41-OSTIF-CRI-O-Audit-Public-Report-2025-12-03.pdf&#34;&gt;&lt;strong&gt;此处&lt;/strong&gt;&lt;/a&gt;阅读审核报告&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;您可以阅读 X41 的博客&lt;a href=&#34;https://x41-dsec.de/security/research/job/news/2026/01/13/cri-o/&#34;&gt;&lt;strong&gt;此处&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Thu, 15 Jan 2026 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【KubeCon + CloudNativeCon NA: Top sessions from the CNCF End User TAB】KubeCon + CloudNativeCon NA：CNCF 最终用户 TAB 的热门会议</title>
      <link>https://www.cncf.io/blog/2026/01/15/kubecon-cloudnativecon-na-top-sessions-from-the-cncf-end-user-tab/</link>
      <description>【&lt;p&gt;2025 brought significant developments in the cloud native landscape, with a strong focus on AI but new projects and end user reports in many other areas. As always, KubeCon is one of the key places we see the progress coming from project reports, end users showcasing their stacks and use cases or vendors in the sponsor hall.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In this blog post, we start 2026 with a look back at the latest KubeCon+ CloudNativeCon North America in Atlanta, highlighting selected sessions from members of the &lt;a href=&#34;https://www.cncf.io/people/end-user-technical-advisory-board/&#34;&gt;CNCF End User Technical Advisory Board (TAB).&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Alolita Sharma&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;So many interesting sessions make it hard to short-list my favorite talks 😀 Talks that made it to my list included:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Session Title: &lt;/strong&gt;Benchmarking GenAI Foundation Model Inference Optimizations on Kubernetes&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;“&lt;/strong&gt;Minimizing inference costs for LLM deployments is a critical component of cost observability, cost management and infra capacity management for all organizations operating inference pipelines. Speakers Sachin Mathew Varghese of Capital One and Brendan Slabe of Google focused this talk on optimization techniques to measure and benchmarked inference performance in a standardized way and walked through a Kubernetes SIG project to benchmark GenAI foundation model inference.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Session Title:&lt;/strong&gt; Discover Cortex: High Scalability Metrics in 2025&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“Cortex is a key technology in the CNCF observability project ecosystem which provides a highly scalable, multi-tenant storage solution for OpenTelemetry and Prometheus metrics observability. This maintainer talk by Friedrich Gonzalez, Charlie Le and Alolita Sharma from Apple and Anand Rajagopal from AWS zoomed in on key features in Release 1.19, what’s next on the project roadmap and community.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Session Title: &lt;/strong&gt;Project Lightning Talk: Perses: Update&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“Perses is an exciting sandbox project for observability visualization to watch out for in the cloud-native observability landscape. Core maintainer Augustin Husson provided a progress update about new features and community growth in this session.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Session Title: &lt;/strong&gt;Retrofitting OTEL Collectors &amp;amp; Prometheus – How To Overcome Scale/Design Limitations&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“Scaling observability data collection is key to handling trace span cardinality from Kubernetes clusters across multiple regions. Using multiple OpenTelemetry connectors and processors for each Collector and yet maintaining an efficient memory footprint is more art than science.This session, by Vijay Samuel and Sandeep Raveesh of EBay, explored some solutions to achieve this optimization leveraging long-term retention examples.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Chad Beaudin&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Session Title&lt;/strong&gt;: Maintainers Summit&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&amp;nbsp;“Yes, I know this is a bit of a cheat since it wasn’t a session.&amp;nbsp; However, this was my first time attending the Maintainers Summit and it was an exciting experience.&amp;nbsp; Hearing the conversations from the maintainer community on things they liked, and more importantly, the struggles they were dealing with was great.&amp;nbsp; Additionally, the famous Hallway Track was a lot of fun just getting to meet the various project maintainers.&amp;nbsp;Lots of passion all around.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Kenta Tada&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;KubeCon + CloudNativeCon North America 2025 presented a compelling lineup of sessions tackling the evolving challenges of networking, runtime customization, and long-term sustainability in large-scale cloud-native environments. As Kubernetes operations mature, themes such as IPv6 adoption, runtime extensibility, and Long-Term Support (LTS) are becoming pivotal for scalability, reliability, and operational resilience. The following three sessions stood out as particularly valuable for end‑user practitioners and platform engineers:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Session Title: &lt;/strong&gt;TikTok’s IPv6 Journey To Cilium: Pitfalls and Lessons Learned&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“Migrating to IPv6‑only environments is a milestone for hyperscale operators, and TikTok’s move to Cilium provides a rare, first-hand look at this transformation. This session detailed the technical journey of deploying Cilium on IPv6‑only Kubernetes clusters, highlighting pitfalls and engineering workarounds that enabled production readiness. Attendees gained insights into debugging Cilium network policies, handling IPv6‑specific DNS and NDP traffic behaviors, and overcoming kernel‑level challenges such as NodePort timeouts — essential knowledge for teams modernizing their networking stack.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Session Title: &lt;/strong&gt;Container Runtime Customization at Netflix: A Case Study With NRI and OCI Hooks&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“Runtime extensibility remains one of the most powerful yet underexplored aspects of Kubernetes operations. In this case study, Netflix engineers revealed how they evolved *Titus*, their global-scale container platform, by integrating ContainerD’s Node Resource Interface (NRI) and OCI hooks to support complex, specialized workloads—while preserving Kubernetes compatibility. The session offered an&amp;nbsp; inside view of custom lifecycle management, network and storage adaptations, and sidecar orchestration at scale. This was essential for platform teams building or maintaining custom runtime layers and seeking the balance between flexibility and standardization.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Session Title: &lt;/strong&gt;Shaping LTS Together: What We’ve Learned the Hard Way&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“As Kubernetes penetrates regulated and mission‑critical environments, LTS is emerging as a key concern for platform teams and vendors. This cross‑vendor panel gathered members to share operational lessons from maintaining Kubernetes over extended timelines. Discussions covered defining LTS scope (security vs. stability), managing upgrade paths, aligning dependencies, and fostering ecosystem coordination. For attendees tasked with maintaining clusters beyond the upstream support window—or interested in the future of Kubernetes lifecycle management—this was a strategic session.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Ricardo Rocha&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Session Title&lt;/strong&gt;: Benchmarking GenAI Foundation Model Inference Optimizations on Kubernetes&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“Model inference is slowly becoming a possible bottleneck in many environments. Consistent benchmarking is a key part to optimize all the different components and layers involved, this is an effort worth following. This was one of many sessions in this KubeCon + CloudNativeCon around inference optimization which helpedl end users struggling in this area.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Session Title: &lt;/strong&gt;Slurm Bridge: Slurm Scheduling Superpowers in Kubernetes&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“In the age of the GPU, interfacing cloud native environments (on-premises and public cloud) with existing supercomputers and other HPC environments is becoming essential. This effort comes from SchedMD, the company behind SLURM, making it worth following.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Session Title:&lt;/strong&gt; DRA is GA! Kubernetes WG Device Management – GPUs, TPUs, NICs and More With DRA&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;“&lt;/strong&gt;DRA will be key to interface new generation accelerators and other specialized environments with the cloud native infrastructures we all have become used to. Extremely happy to see this in GA and great to see all the updates and developments.”&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Session Title: &lt;/strong&gt;Managing a Million Infra Resources at Spotify: Designing the Platform To Manage Change at Scale&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“Spotify is a previous winner of the Top End User award and has always been one of the key end users in our community, also bringing forwards new tools such as Backstage. Listening to how changes are managed at their scale helped everyone, no matter the size of the deployment.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Joseph Sandoval&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Session Title:&lt;/strong&gt; Evolving Kubernetes Scheduling &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://kccncna2025.sched.com/event/27FeY/evolving-kubernetes-scheduling-eric-tune-wojciech-tyczynski-google&#34;&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;”&lt;/strong&gt;The scheduler is where the rubber meets the road for AI/ML on Kubernetes. Right now, teams are cobbling together third-party extensions to make GPU workloads actually work: managing gang scheduling, topology awareness, pre-emption policies. Tune and Tyczyński are core contributors who show the community’s roadmap for moving this functionality upstream. The key insight from the talk: “The Kubernetes scheduler is designed to schedule one pod on one node at a time, and we now need it to schedule groups of pods on groups of nodes at a time.” That fundamental architectural shift is what separates batch/ML workloads from the microservices patterns K8s was built for, and signals where the community is investing to make Kubernetes the invisible substrate for AI workloads.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;br&gt;&lt;strong&gt;Session Title:&lt;/strong&gt; Keynote: Supply Chain Reaction: A Cautionary Tale in K8s Security &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://kccncna2025.sched.com/event/27HSy/keynote-supply-chain-reaction-a-cautionary-tale-in-k8s-security-stacey-potter-manager-of-community-openssf-adolfo-garcia-veytia-founder-and-engineer-carabiner-systems&#34;&gt;&lt;br&gt;&lt;/a&gt;“Supply chain attacks are the nightmare scenario because your cluster passes every security scan while the build pipeline itself is compromised. Stacey and Adolfo ditched the standard slide deck for a live skit that dramatized exactly how this happens: an engineer watches helplessly as cryptomining malware spreads through their secure cluster. Firewalls worked. mTLS was configured correctly. Vulnerability scanners came back clean. None of it mattered because the compiler itself was tainted. The theatrical format worked because it made the abstract threat tangible and kept you engaged through what could have been another dry security talk. Their demonstration of the OSPS Baseline with Sigstore, SLSA attestation, and gittuf shows the defensive playbook: verify provenance at every step, not just the final artifact. If you’re building platforms that developers trust, this is why supply chain security has moved from a nice-to-have to a table-stakes requirement.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Henrik Blixt&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Session Title:&lt;/strong&gt; The Evolution of Platform APIs in the Age of LLMs &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“As a platform product manager at Intuit this session stood out because it tackled how platform APIs are changing in the era of large language models (LLMs),&amp;nbsp; shifting from rigid definitions toward more dynamic, conversational, and “wizard-style” interactions where devs and automation agents can &lt;em&gt;consume&lt;/em&gt; the platform in new ways, which&amp;nbsp; is highly relevant to me: it highlighted how platform engineering is evolving to offer model-driven interfaces rather than only static APIs, making service consumption, management, and troubleshooting far more intuitive.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Session Title:&amp;nbsp;&lt;/strong&gt; Progressive Configuration Delivery for Zero-Downtime Cloud Workloads &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“Being an Argo maintainer, this session hit a soft spot, because it addressed progressive delivery of configurations (not just code or images), with a CRD-based approach that decouples image versioning from configuration delivery and enables batch/traffic-based rollout of config changes. This kind of capability is directly aligned with our need to manage configuration drift, rollout risk, and seamless service updates . I was thrilled when&amp;nbsp;they detailed&amp;nbsp;how this can reduce the blast radius of config changes across multiple services and clusters, which resonated with many other audience members as well!”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Session Title: &lt;/strong&gt;Creating and Maintaining Ephemeral Runtime Environments for 18,000 Developers &lt;strong&gt;&lt;br&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“This session resonated strongly since it featured a real-world case of scaling ephemeral environments to 18,000 developers, which directly touches on the kind of demand and features we see at Intuit and it aligns with our focus on developer experience and velocity: providing on-demand, isolated, production-like runtime environments supports feature velocity, reduces risk, and improves confidence in deployments.”&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;2025 年云原生领域取得了重大发展，重点关注人工智能，但许多其他领域也出现了新项目和最终用户报告。与往常一样，KubeCon 是我们从项目报告、最终用户展示其堆栈和用例或赞助商大厅中的供应商中看到进展的关键场所之一。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在这篇博文中，我们从 2026 年开始回顾在亚特兰大举行的最新 KubeCon+ CloudNativeCon 北美会议，重点介绍 &lt;a href=&#34;https://www.cncf.io/people/end-user-technical-advisory-board/&#34;&gt;CNCF 最终用户技术咨询委员会 (TAB) 成员的精选会议。&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;阿洛丽塔·夏尔马&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如此多有趣的会议让我很难列出我最喜欢的演讲😀 进入我的列表的演讲包括：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;会议标题：&lt;/strong&gt;在 Kubernetes 上对 GenAI 基础模型推理优化进行基准测试&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;“&lt;/strong&gt;最大限度地降低 LLM 部署的推理成本是所有运行推理管道的组织的成本可观测性、成本管理和基础设施容量管理的关键组成部分。Capital One 的 Sachin Mathew Varghese 和 Google 的 Brendan Slabe 的演讲重点讨论了以标准化方式衡量推理性能和进行基准测试的优化技术，并介绍了一个 Kubernetes SIG 项目来对 GenAI 基础模型推理进行基准测试。”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;会议标题：&lt;/strong&gt;探索 Cortex：2025 年的高可扩展性指标&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“Cortex 是 CNCF 可观测性项目生态系统中的一项关键技术，它为 OpenTelemetry 和 Prometheus 指标可观测性提供了高度可扩展的多租户存储解决方案。来自 Apple 的 Friedrich Gonzalez、Charlie Le 和 Alolita Sharma 以及来自 AWS 的 Anand Rajagopal 的维护者演讲重点介绍了 1.19 版中的关键功能，以及项目路线图和社区的下一步发展。”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;会议标题：&lt;/strong&gt;闪电项目演讲：Perses：更新&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“Perses 是一个令人兴奋的可观测性可视化沙盒项目，在云原生可观测性领域值得关注。核心维护者 Augustin Husson 在本次会议中提供了有关新功能和社区发展的最新进展。”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;会议标题：&lt;/strong&gt;改造 OTEL 收集器和 Prometheus – 如何克服规模/设计限制&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“扩展可观测性数据收集是处理跨多个区域的 Kubernetes 集群的跟踪范围基数的关键。为每个收集器使用多个 OpenTelemetry 连接器和处理器，同时保持高效的内存占用更多的是艺术而不是科学。本次会议由 EBay 的 Vijay Samuel 和 Sandeep Raveesh 主持，探讨了一些解决方案，以利用长期保留示例来实现这种优化。”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;查德·博丁&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;会议标题&lt;/strong&gt;：维护者峰会&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt; “是的，我知道这有点作弊，因为这不是一次会议。  然而，这是我第一次参加维护者峰会，这是一次令人兴奋的经历。  听到维护者社区关于他们喜欢的事情的对话，更重要的是，他们正在处理的斗争是伟大的。  此外，著名的走廊轨道与各个项目维护人员见面也很有趣。 到处充满激情。”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;多田健太&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;KubeCon + CloudNativeCon North America 2025 举办了一系列引人注目的会议，旨在应对大规模云原生环境中不断变化的网络、运行时定制和长期可持续性挑战。随着 Kubernetes 运营的成熟，IPv6 采用、运行时可扩展性和长期支持 (LTS) 等主题正成为可扩展性、可靠性和运营弹性的关键。以下三场会议对于最终用户从业者和平台工程师特别有价值：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;会议标题：&lt;/strong&gt;TikTok 的 IPv6 Cilium 之旅：陷阱和经验教训&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“迁移到纯 IPv6 环境对于超大规模运营商来说是一个里程碑，TikTok 迁移到 Cilium 为我们提供了罕见的第一手资料来了解这一转变。本次会议详细介绍了在纯 IPv6 Kubernetes 集群上部署 Cilium 的技术历程，重点介绍了实现生产准备的陷阱和工程解决方法。与会者深入了解了调试 Cilium 网络策略、处理 IPv6 特定的 DNS 和 NDP 流量行为，以及克服 NodePort 超时等内核级挑战，这些都是团队实现网络堆栈现代化的基本知识。”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;会议标题：&lt;/strong&gt;Netflix 的容器运行时定制：NRI 和 OCI Hook 的案例研究&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“运行时可扩展性仍然是 Kubernetes 操作中最强大但尚未充分开发的方面之一。在本案例研究中，Netflix 工程师揭示了他们如何通过集成 ContainerD 的节点资源接口 (NRI) 和 OCI 挂钩来发展全球规模的容器平台 *Titus*，以支持复杂、专业的工作负载，同时保持 Kubernetes 兼容性。该会议提供了自定义生命周期管理、网络和存储适应以及大规模 sidecar 编排的内部视图。这对于平台团队构建或维护自定义运行时层以及寻求灵活性和标准化之间的平衡至关重要。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;会议标题：&lt;/strong&gt;共同塑造 LTS：我们历经艰辛才学到的东西&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“随着 Kubernetes 渗透到受监管和任务关键型环境中，LTS 正在成为平台团队和供应商的一个主要关注点。这个跨供应商小组聚集了成员，分享长期维护 Kubernetes 的操作经验教训。涵盖的讨论定义 LTS 范围（安全性与稳定性）、管理升级路径、调整依赖关系并促进生态系统协调。对于负责在上游支持窗口之外维护集群的与会者或对 Kubernetes 生命周期管理的未来感兴趣的与会者来说，这是一次战略会议。”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;里卡多·罗查&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;会议标题&lt;/strong&gt;：Kubernetes 上的 GenAI 基础模型推理优化基准测试&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“模型推理正在慢慢成为许多环境中可能的瓶颈。一致的基准测试是优化涉及的所有不同组件和层的关键部分，这是一项值得遵循的努力。这是 KubeCon + CloudNativeCon 中围绕推理优化的众多会议之一，帮助了在该领域苦苦挣扎的最终用户。”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;会议标题：&lt;/strong&gt;Slurm Bridge：Kubernetes 中的 Slurm 调度超级能力&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“在 GPU 时代，云原生环境（本地和公共云）与现有超级计算机和其他 HPC 环境的接口变得至关重要。这项工作来自 SLURM 背后的公司 SchedMD，值得关注。”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;会议标题：&lt;/strong&gt;DRA 正式发布！ Kubernetes WG 设备管理 – GPU、TPU、NIC 等使用 DRA&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;“&lt;/strong&gt;DRA 将成为新一代加速器和其他专业环境与我们都已经习惯的云原生基础设施接口的关键。非常高兴在正式版中看到这一点，也很高兴看到所有的更新和发展。” &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;会议标题：&lt;/strong&gt;管理 Spotify 的一百万基础设施资源：设计大规模管理变革的平台&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“Spotify 是顶级最终用户奖的前任获得者，并且一直是我们社区的关键最终用户之一，还带来了 Backstage 等新工具。无论部署规模有多大，了解如何管理大规模的变更对每个人都有帮助。”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;约瑟夫·桑多瓦尔&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;会议标题：&lt;/strong&gt;不断发展的 Kubernetes 调度&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://kccncna2025.sched.com/event/27FeY/evolving-kubernetes-scheduling-eric-tune-wojciech-tyczynski-google&#34;&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;”&lt;/strong&gt;调度程序是 Kubernetes 上 AI/ML 的关键所在。目前，团队正在拼凑第三方扩展，以使 GPU 工作负载真正发挥作用：管理组调度、拓扑感知、抢占策略。 Tune 和 Tyczyński 是核心贡献者，他们展示了社区将该功能向上游推进的路线图。演讲的主要见解是：“Kubernetes 调度程序旨在一次在一个节点上调度一个 pod，而我们现在需要它一次在一组节点上调度一组 pod。”这种基本的架构转变是将批处理/机器学习工作负载与微型工作负载区分开来的。K8s 专为服务模式而构建，并表明社区正在投资哪些领域，以使 Kubernetes 成为人工智能工作负载的隐形基础。”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;br&gt;&lt;strong&gt;会议标题：&lt;/strong&gt;主题演讲：供应链反应：K8s 安全性的警示故事&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://kccncna2025.sched.com/event/27HSy/keynote-supply-chain-reaction-a-cautionary-tale-in-k8s-security-stacey-potter-manager-of-community-openssf-adolfo-garcia-veytia-Founder-and-engineer-carabiner-systems&#34;&gt;&lt;br&gt;&lt;/a&gt;“供应链攻击是一场噩梦，因为您的集群通过了每次安全扫描，而构建管道本身却受到了损害。史黛西和阿道夫放弃了标准的幻灯片，转而制作了一个现场短剧，戏剧化地描述了这种情况的发生：一名工程师无助地看着加密货币挖矿恶意软件在他们的安全集群中传播。防火墙起作用了。 mTLS 配置正确。漏洞扫描仪恢复正常。这些都不重要，因为编译器本身就被污染了。戏剧形式之所以有效，是因为它使抽象的威胁变得有形，并让你参与到可能是另一场枯燥的安全谈话中。他们使用 Sigstore、SLSA 证明和 gittuf 演示了 OSPS 基线，展示了防御策略：验证每一步的出处，而不仅仅是最终的工件。如果您正在构建开发人员信任的平台，这就是为什么供应链安全已从“可有可无”转变为“赌注”要求。”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;亨里克·布利克特&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;会议标题：&lt;/strong&gt;法学硕士时代平台 API 的演变&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“作为 Intuit 的平台产品经理，本次会议之所以脱颖而出，是因为它讨论了平台 API 在大型语言模型 (LLM) 时代的变化，从严格的定义转向更加动态、对话式和“向导式”的交互，开发人员和自动化代理可以以新的方式&lt;em&gt;使用&lt;/em&gt;平台，这与我高度相关：它强调了平台工程如何发展为提供模型驱动的接口而不仅仅是静态 API，从而使服务消费、管理和故障排除更加直观。”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;会议标题：&lt;/strong&gt;零停机云工作负载的渐进式配置交付&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“作为 Argo 维护者，本次会议触及了一个软肋，因为它解决了配置（不仅仅是代码或图像）的渐进式交付问题，采用基于 CRD 的方法将图像版本控制与配置交付分离，并支持基于批量/流量的配置更改推出。这种功能直接满足我们管理配置漂移、部署风险和无缝服务更新的需求。当他们详细介绍这如何减少跨多个服务和集群的配置更改的影响范围时，我感到很兴奋，这也引起了许多其他观众的共鸣！”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;会议标题：&lt;/strong&gt;为 18,000 名开发人员创建和维护临时运行时环境&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“本次会议引起了强烈反响，因为它介绍了将临时环境扩展到 18,000 名开发人员的真实案例，这直接触及了我们在 Intuit 看到的需求和功能，并且与我们对开发人员体验和速度的关注相一致：提供按需、隔离、类似生产的运行时环境支持功能速度、降低风险并提高部署信心。”&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Wed, 14 Jan 2026 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【The symbiotic revolution: AI and cloud native technologies transforming the digital landscape】共生革命：人工智能和云原生技术改变数字格局</title>
      <link>https://www.cncf.io/blog/2026/01/13/the-symbiotic-revolution-ai-and-cloud-native-technologies-transforming-the-digital-landscape/</link>
      <description>【&lt;p&gt;&lt;em&gt;This Ambassador Blog was originally published on the writer’s blog and is republished here with permission.&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1195&#34; height=&#34;675&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2026/01/AI-and-Kubernetes-1195x675-1.jpg&#34; alt=&#34;AI and Kubernetes handshake&#34; class=&#34;wp-image-154928&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2026/01/AI-and-Kubernetes-1195x675-1.jpg 1195w, https://www.cncf.io/wp-content/uploads/2026/01/AI-and-Kubernetes-1195x675-1-300x169.jpg 300w, https://www.cncf.io/wp-content/uploads/2026/01/AI-and-Kubernetes-1195x675-1-1024x578.jpg 1024w, https://www.cncf.io/wp-content/uploads/2026/01/AI-and-Kubernetes-1195x675-1-768x434.jpg 768w, https://www.cncf.io/wp-content/uploads/2026/01/AI-and-Kubernetes-1195x675-1-900x508.jpg 900w, https://www.cncf.io/wp-content/uploads/2026/01/AI-and-Kubernetes-1195x675-1-354x200.jpg 354w, https://www.cncf.io/wp-content/uploads/2026/01/AI-and-Kubernetes-1195x675-1-708x400.jpg 708w&#34; sizes=&#34;auto, (max-width: 1195px) 100vw, 1195px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In the ever-evolving world of technology, few pairings have sparked as much innovation as the intersection of artificial intelligence (AI) and cloud native architectures. Cloud native technologies, built around containers, microservices, and orchestration tools like Kubernetes, emphasize scalability, resilience, and agility. Meanwhile, AI—encompassing machine learning (ML), deep learning, and generative models—drives intelligent automation and data-driven insights. As we approach 2026, this synergy is reshaping how organizations deploy, manage, and optimize workloads. In this blog post, we’ll explore how AI is revolutionizing cloud native workloads, the benefits AI brings to cloud native environments, and how AI itself gains from powerhouse tools like Kubernetes. We’ll also dive into real-world use cases that illustrate this transformative relationship.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;How AI is Influencing and Changing Cloud Native Workloads&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Cloud native workloads traditionally involve containerized applications orchestrated across distributed systems, but AI is injecting intelligence into these processes, making them more adaptive and efficient. At its core, AI influences workloads by enabling predictive analytics, automated optimization, and dynamic resource allocation.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;One key change is the shift from static to AI-driven scaling. Traditional cloud native setups rely on rule-based autoscaling, but AI models can predict demand spikes using historical data, optimizing resource usage in real-time. For instance, AI workloads demand massive computational power, often involving GPUs, and cloud native designs ensure these resources scale seamlessly without overprovisioning. This evolution turns rigid infrastructures into flexible, self-healing systems.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;AI is also altering workload development cycles. Generative AI tools streamline DevOps by automating code generation, testing, and security checks in cloud native applications. In AI-native infrastructures, workloads become more resilient to failures, with AI detecting anomalies and rerouting tasks proactively. This not only reduces downtime but also lowers costs by minimizing idle resources.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Moreover, AI is pushing cloud native workloads toward edge computing and hybrid environments. By processing data closer to the source, AI-enhanced workloads handle real-time applications like IoT analytics more effectively, blurring the lines between cloud and on-premises setups. Overall, AI is transforming cloud native workloads from mere scalable containers into intelligent, proactive ecosystems that anticipate needs and adapt instantaneously.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;How Cloud Native Environments Benefit from AI&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The benefits flow both ways: cloud native environments, characterized by their modularity and portability, are supercharged by AI integration. This results in enhanced efficiency, security, and innovation across the board.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;AI optimizes resource management in cloud native setups. By analyzing usage patterns, AI algorithms enable predictive scaling, reducing waste and ensuring cost-efficiency. For example, in hybrid cloud environments, AI provides insights that improve application performance and resource allocation, leading to faster decision-making. This is particularly valuable for handling variable workloads, where AI can dynamically provision resources in response to changes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Security and resilience also see massive gains. AI-powered tools detect threats in real-time within containerized environments, automating responses to vulnerabilities. Collaboration across teams improves as AI fosters agility and cost savings, allowing developers to focus on innovation rather than maintenance. In AI-native applications, this translates to personalized user experiences and faster deployment cycles.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Additionally, cloud native environments benefit from AI’s ability to handle massive data volumes. Scalability becomes effortless, with AI enabling remote access and global collaboration in development. The cloud’s flexibility for AI training and deployment overcomes barriers like cost and scaling, making it an ideal platform for complex models. In essence, AI turns cloud native infrastructures into smarter, more resilient hubs that drive business value through automation and intelligence.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;How AI Benefits from Technologies Like Kubernetes&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes, the de facto standard for container orchestration, provides AI with the robust foundation needed to thrive at scale. AI workloads, often resource-intensive and distributed, see immense gains from Kubernetes’ capabilities in portability, scalability, and management.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes excels in handling AI’s demanding tasks, such as model training and inference, by efficiently managing GPUs and accelerators. It ensures reproducibility and portability, allowing AI models to run consistently across environments—from on-premises to multi-cloud. For large-scale AI operations, Kubernetes simplifies orchestration, isolating processes and automating CI/CD pipelines.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;AI benefits from Kubernetes’ automation features, like self-optimizing clusters and predictive resource management, which accelerate ML pipelines. GPU resource management is a standout advantage, enabling efficient allocation for training without manual intervention. Moreover, Kubernetes supports edge AI deployments and enhances security, making it ideal for production-grade AI.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Going forward, AI will continue to benefit from Kubernetes advancements, such as smarter MLOps and integration with frameworks like PyTorch. By providing a consistent API, Kubernetes allows seamless movement of AI research and production workloads, fostering innovation. Ultimately, Kubernetes empowers AI to scale globally while maintaining efficiency and reliability.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Real-World Use Cases: AI and Cloud Native in Action&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To ground these concepts, let’s examine some real-world examples where AI and cloud native technologies intersect. The following examples highlight how end users and platform teams are utilizing Kubernetes and cloud native technologies in AI environments in production:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/case-studies/openai/&#34;&gt;OpenAI leverages Kubernetes for massive-scale AI training&lt;/a&gt;, scaling to &lt;a href=&#34;https://www.fairwinds.com/blog/ai-cloud-native-managing-kubernetes-platform&#34;&gt;over 7,500 nodes&lt;/a&gt; for parallel processing in model development. This demonstrates Kubernetes’ capability in handling resource-intensive AI workloads while ensuring portability.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.zdnet.com/article/cloud-native-computing-is-poised-to-explode-thanks-to-ai-inference-work/&#34;&gt;Google Cloud uses Kubernetes for AI inference&lt;/a&gt;, processing quadrillions of tokens monthly. Their internal jobs highlight how cloud native orchestration supports explosive growth in AI demands, optimizing for bare-metal performance in neoclouds.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://blogs.oracle.com/developers/autoscaling-gpu-workloads-oci-kubernetes-engine-oke&#34;&gt;Oracle uses Kubernetes to orchestrate GPU-accelerated AI workloads&lt;/a&gt;, automatically scaling pods using GPU accelerators to minimize the number of idle GPUs, the costs associated with them, and ensuring fast response performance when GPU demand is high.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.uber.com/blog/ubers-journey-to-ray-on-kubernetes-ray-setup/&#34;&gt;Uber runs its Machine Learning platform on Kubernetes&lt;/a&gt;, observing 1.5- to 4-times improvement in ‌training speed and better GPU utilization for resources across zones and clusters.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://venturebeat.com/security/armo-shows-how-chatgpt-can-help-protect-kubernetes&#34;&gt;ARMO integrates ChatGPT with Kubernetes for security&lt;/a&gt;, allowing teams to generate custom controls in natural language to secure clusters and pipelines. This use case shows AI enhancing cloud native security without deep coding expertise.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://venturebeat.com/ai/scaleops-new-ai-infra-product-slashes-gpu-costs-for-self-hosted-enterprise?amp=&amp;amp;amp=&#34;&gt;ScaleOps’ AI Infra Product, running on Kubernetes, slashes GPU costs by 50-70% for enterprise LLMs&lt;/a&gt; by automating optimization across clouds and on-premises. Early adopters report seamless integration, proving the cost-saving potential of AI-driven cloud native management.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;These cases underscore the practical impact: from cost reductions and security enhancements to scalable innovation, AI, and cloud native technologies are driving tangible business outcomes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Conclusion: A Future of Mutual Empowerment&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The fusion of AI and cloud native technologies like Kubernetes is more than a trend—it’s a paradigm shift. AI infuses intelligence into workloads, making them adaptive and efficient, while cloud native environments gain from AI’s optimization and automation. In turn, AI thrives on Kubernetes’ orchestration, scaling to meet global demands. As seen in deployments by OpenAI, Google, Uber, and others, this symbiosis is already yielding breakthroughs. Looking ahead, expect even tighter integrations, with AI-native infrastructures becoming the norm. For organizations, embracing this revolution means unlocking unprecedented agility, cost savings, and innovation in an AI-driven world.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;此大使博客最初发布在作者的博客上，经许可在此处重新发布。&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt; &lt;img loading =“lazy”decoding =“async”width =“1195”height =“675”src =“https://www.cncf.io/wp-content/uploads/2026/01/AI-and-Kubernetes-1195x675-1.jpg”alt =“AI和Kubernetes握手”class =“wp-image-154928” srcset =“https://www.cncf.io/wp-content/uploads/2026/01/AI-and-Kubernetes-1195x675-1.jpg 1195w，https://www.cncf.io/wp-content/uploads/2026/01/AI-and-Kubernetes-1195x675-1-300x169.jpg 300w， https://www.cncf.io/wp-content/uploads/2026/01/AI-and-Kubernetes-1195x675-1-1024x578.jpg 1024w，https://www.cncf.io/wp-content/uploads/2026/01/AI-and-Kubernetes-1195x675-1-768x434.jpg 768w， https://www.cncf.io/wp-content/uploads/2026/01/AI-and-Kubernetes-1195x675-1-900x508.jpg 900w，https://www.cncf.io/wp-content/uploads/2026/01/AI-and-Kubernetes-1195x675-1-354x200.jpg 354w， https://www.cncf.io/wp-content/uploads/2026/01/AI-and-Kubernetes-1195x675-1-708x400.jpg 708w“尺寸=”自动，（最大宽度：1195px）100vw，1195px“referrerpolicy=”no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在不断发展的技术世界中，很少有配对能够像人工智能 (AI) 和云原生架构的交集那样激发如此多的创新。围绕容器、微服务和 Kubernetes 等编排工具构建的云原生技术强调可扩展性、弹性和敏捷性。与此同时，人工智能（包括机器学习 (ML)、深度学习和生成模型）推动智能自动化和数据驱动的见解。随着 2026 年的临近，这种协同作用正在重塑组织部署、管理和优化工作负载的方式。在这篇博文中，我们将探讨人工智能如何彻底改变云原生工作负载、人工智能给云原生环境带来的好处，以及人工智能本身如何从 Kubernetes 等强大工具中获益。我们还将深入研究说明这种变革关系的现实用例。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;人工智能如何影响和改变云原生工作负载&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;云原生工作负载传统上涉及跨分布式系统编排的容器化应用程序，但人工智能正在为这些流程注入智能，使它们更具适应性和效率。人工智能的核心是通过预测分析、自动优化和动态资源分配来影响工作负载。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;一个关键的变化是从静态扩展向人工智能驱动扩展的转变。传统的云原生设置依赖于基于规则的自动扩展，但人工智能模型可以使用历史数据预测需求峰值，从而实时优化资源使用。例如，人工智能工作负载需要大量的计算能力，通常涉及 GPU，而云原生设计可确保这些资源无缝扩展而不会过度配置。这种演变将刚性的基础设施转变为灵活的、自我修复的系统。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;人工智能也在改变工作负载开发周期。生成式 AI 工具通过在云原生应用程序中自动生成代码、测试和安全检查来简化 DevOps。在人工智能原生基础设施中，通过人工智能主动检测异常并重新路由任务，工作负载对故障的恢复能力变得更强。这不仅可以减少停机时间，还可以通过最大限度地减少闲置资源来降低成本。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;此外，人工智能正在将云原生工作负载推向边缘计算和混合环境。通过处理更接近源的数据，人工智能增强的工作负载可以更有效地处理物联网分析等实时应用程序，从而模糊了云和本地设置之间的界限。总体而言，人工智能正在将云原生工作负载从单纯的可扩展容器转变为能够预测需求并即时适应的智能、主动的生态系统。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;云原生环境如何从人工智能中受益&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;好处是双向的：以模块化和可移植性为特征的云原生环境通过人工智能集成得到了增强。这会全面提高效率、安全性和创新。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;人工智能优化了云原生设置中的资源管理。通过分析使用模式，人工智能算法可以实现预测性扩展，减少浪费并确保成本效益。例如，在混合云环境中，人工智能提供的见解可以提高应用程序性能和资源分配，从而加快决策速度。这对于处理可变工作负载特别有价值，其中人工智能可以动态配置资源以响应变化。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;安全性和弹性也取得了巨大的进步。人工智能驱动的工具可以实时检测容器化环境中的威胁，自动响应漏洞。随着人工智能促进敏捷性和成本节约，跨团队的协作得到改善，使开发人员能够专注于创新而不是维护。在人工智能原生应用程序中，这意味着个性化的用户体验和更快的部署周期。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;此外，云原生环境受益于人工智能处理海量数据的能力。通过人工智能实现远程访问和开发中的全球协作，可扩展性变得毫不费力。云在人工智能训练和部署方面的灵活性克服了成本和扩展等障碍，使其成为复杂模型的理想平台。从本质上讲，人工智能将云原生基础设施转变为更智能、更有弹性的中心，通过自动化和智能化推动业务价值。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;人工智能如何从 Kubernetes 等技术中受益&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes 是容器编排的事实上的标准，为 AI 提供了大规模发展所需的坚实基础。 AI 工作负载通常是资源密集型和分布式的，可以从 Kubernetes 在可移植性、可扩展性和管理方面的功能获得巨大收益。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes 擅长处理人工智能的高要求任务，例如模型训练通过有效管理 GPU 和加速器来进行推理。它确保了可重复性和可移植性，使人工智能模型能够跨环境（从本地到多云）一致运行。对于大规模人工智能操作，Kubernetes 简化了编排、隔离流程以及自动化 CI/CD 管道。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;人工智能受益于 Kubernetes 的自动化功能，例如自我优化集群和预测资源管理，可加速机器学习管道。 GPU 资源管理是一个突出的优势，无需人工干预即可高效分配训练。此外，Kubernetes 支持边缘 AI 部署并增强安全性，非常适合生产级 AI。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;展望未来，人工智能将继续受益于 Kubernetes 的进步，例如更智能的 MLOps 以及与 PyTorch 等框架的集成。通过提供一致的 API，Kubernetes 允许人工智能研究和生产工作负载的无缝移动，从而促进创新。最终，Kubernetes 使人工智能能够在全球范围内扩展，同时保持效率和可靠性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;实际用例：人工智能和云原生的实际应用&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;为了奠定这些概念的基础，让我们看一下人工智能和云原生技术交叉的一些现实示例。以下示例重点介绍了最终用户和平台团队如何在生产中的 AI 环境中利用 Kubernetes 和云原生技术：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/case-studies/openai/&#34;&gt;OpenAI 利用 Kubernetes 进行大规模 AI 训练&lt;/a&gt;，扩展到&lt;a href=&#34;https://www.fairwinds.com/blog/ai-cloud-native-managing-kubernetes-platform&#34;&gt;超过 7,500 个节点&lt;/a&gt;在模型开发中进行并行处理。这证明了 Kubernetes 在处理资源密集型人工智能工作负载的同时确保可移植性的能力。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.zdnet.com/article/cloud-native-computing-is-poished-to-explode-thanks-to-ai-inference-work/&#34;&gt;Google Cloud 使用 Kubernetes 进行 AI 推理&lt;/a&gt;，每月处理数千万个令牌。他们的内部工作强调了云原生编排如何支持人工智能需求的爆炸性增长，优化新云中的裸机性能。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://blogs.oracle.com/developers/autoscaling-gpu-workloads-oci-kubernetes-engine-oke&#34;&gt;Oracle 使用 Kubernetes 来编排 GPU 加速的 AI 工作负载&lt;/a&gt;，使用 GPU 加速器自动扩展 Pod，以最大程度地减少空闲 GPU 的数量及其相关成本，并确保在 GPU 需求较高时快速响应性能。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.uber.com/blog/ubers-journey-to-ray-on-kubernetes-ray-setup/&#34;&gt;Uber 在 Kubernetes 上运行其机器学习平台&lt;/a&gt;，观察到训练速度提高了 1.5 到 4 倍，跨区域和集群的资源 GPU 利用率提高了。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://venturebeat.com/security/armo-shows-how-chatgpt-can-help-protect-kubernetes&#34;&gt;ARMO 集成ChatGPT 与 Kubernetes 一起实现安全&lt;/a&gt;，允许团队以自然语言生成自定义控件，以保护集群和管道的安全。该用例展示了人工智能无需深厚的编码专业知识即可增强云原生安全性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://venturebeat.com/ai/scaleops-new-ai-infra-product-slashes-gpu-costs-for-self-hosted-enterprise?amp=&amp;amp=&#34;&gt;ScaleOps 的 AI 基础设施产品在 Kubernetes 上运行，通过跨云和本地的自动化优化，将企业 LLM 的 GPU 成本削减 50-70%&lt;/a&gt;。早期采用者表示无缝集成，证明了人工智能驱动的云原生管理的成本节约潜力。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这些案例强调了实际影响：从降低成本和增强安全性到可扩展的创新、人工智能和云原生技术正在推动切实的业务成果。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;结论：相互赋权的未来&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;人工智能与 Kubernetes 等云原生技术的融合不仅仅是一种趋势，更是一种范式转变。人工智能将智能注入工作负载中，使其具有适应性和高效性，而云原生环境则从人工智能的优化和自动化中获益。反过来，人工智能在 Kubernetes 的协调下蓬勃发展，并通过扩展来满足全球需求。从 OpenAI、谷歌、Uber 和其他公司的部署中可以看出，这种共生关系已经取得了突破。展望未来，预计集成会更加紧密，人工智能原生基础设施将成为常态。对于组织来说，拥抱这场革命意味着在人工智能驱动的世界中释放前所未有的敏捷性、成本节约和创新。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Mon, 12 Jan 2026 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【A decade of open source in CNCF with 300,000+ contributors and counting】CNCF 开源十年，拥有超过 300,000 名贡献者，而且还在不断增加</title>
      <link>https://www.cncf.io/blog/2026/01/12/a-decade-of-open-source-in-cncf-with-300000-contributors-and-counting/</link>
      <description>【&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We’re excited to announce that the Cloud Native Computing Foundation (CNCF) community has reached an important milestone: &lt;a href=&#34;https://www.cncf.io/project-metrics/&#34;&gt;&lt;strong&gt;more than 300,000 contributors&lt;/strong&gt;&lt;/a&gt; have participated in CNCF hosted projects across more than 11500 organizations from 190 countries.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This incredible metric reflects the collective efforts of those who contribute code, documentation, reviews, testing, issue triage, design, and community support across the CNCF project landscape. It also represents continued participation across projects at every stage,&amp;nbsp; from sandbox to graduated, and showcases the scale of collaboration that is the foundation of cloud native open source.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;A community-driven cloud native ecosystem&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.cncf.io/project-metrics/&#34;&gt;CNCF projects&lt;/a&gt; are built and maintained by a global community of contributors working in the open.&amp;nbsp; Reaching more than 300,000 contributors is the result of years of open collaboration across many communities who have given their time and effort to help build the cloud native ecosystem. Contributors participate in different ways and at different levels, but all contributions help projects evolve, improve reliability, and remain responsive to user needs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Contributions across the project lifecycle&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;CNCF hosts projects at different stages of maturity, each with its own contributor dynamics:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Sandbox &lt;/strong&gt;projects explore new ideas and early-stage innovation.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Incubating &lt;/strong&gt;projects&lt;strong&gt; &lt;/strong&gt;show growing adoption and contributor activity.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Graduated &lt;/strong&gt;projects demonstrate long-term sustainability and broad community involvement.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Across all stages, contributor participation is essential to project health, and the growth highlights ongoing engagement across this full lifecycle.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Thank you to the community&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This milestone belongs to the entire community; everyone who has opened a pull request, reviewed a change, filed an issue, improved documentation, or supported others along the way.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As CNCF projects continue to grow and evolve, community participation remains central to their success. Thank you to everyone who has contributed and continues to contribute on a daily basis.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To explore contributor activity and learn how to get involved, visit the &lt;a href=&#34;https://www.cncf.io/project-metrics/&#34;&gt;&lt;strong&gt;CNCF Project Metrics&lt;/strong&gt; page&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们很高兴地宣布，云原生计算基金会 (CNCF) 社区已达到一个重要里程碑：&lt;a href=&#34;https://www.cncf.io/project-metrics/&#34;&gt;&lt;strong&gt;超过 300,000 名贡献者&lt;/strong&gt;&lt;/a&gt;参与了来自 190 个国家/地区 11500 多个组织的 CNCF 托管项目。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这个令人难以置信的指标反映了整个 CNCF 项目环境中贡献代码、文档、审查、测试、问题分类、设计和社区支持的人们的集体努力。它还代表了从沙箱到分级的各个阶段的项目持续参与，并展示了作为云原生开源基础的协作规模。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;社区驱动的云原生生态系统&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.cncf.io/project-metrics/&#34;&gt;CNCF 项目&lt;/a&gt;由开放工作的全球贡献者社区构建和维护。  超过 300,000 名贡献者是许多社区多年来开放合作的结果，他们付出了时间和精力来帮助构建云原生生态系统。贡献者以不同的方式和不同的级别参与，但所有贡献都有助于项目发展、提高可靠性并保持对用户需求的响应。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;整个项目生命周期的贡献&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;CNCF 托管处于不同成熟阶段的项目，每个项目都有自己的贡献者动态：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;沙盒&lt;/strong&gt;项目探索新想法和早期创新。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;孵化&lt;/strong&gt;项目&lt;strong&gt; &lt;/strong&gt;显示采用率和贡献者活动不断增长。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;毕业&lt;/strong&gt;项目展示了长期可持续性和广泛的社区参与。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在所有阶段，贡献者的参与对于项目的健康发展至关重要，而这种增长凸显了整个生命周期中的持续参与。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;感谢社区&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这个里程碑属于整个社区；在此过程中提出拉取请求、审查更改、提出问题、改进文档或支持其他人的每个人。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;随着 CNCF 项目的不断发展和发展，社区参与仍然是其成功的核心。感谢所有每天做出贡献并继续做出贡献的人。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;要探索贡献者活动并了解如何参与，请访问&lt;a href=&#34;https://www.cncf.io/project-metrics/&#34;&gt;&lt;strong&gt;CNCF 项目指标&lt;/strong&gt;页面&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Sun, 11 Jan 2026 16:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>