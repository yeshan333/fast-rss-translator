<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>CNCF - Blog</title>
    <link>http://rsshub.rssforever.com/cncf</link>
    <description>CNCF - Blog - Powered by RSSHub</description>
    <managingEditor>contact@rsshub.app (RSSHub)</managingEditor>
    <item>
      <title>【The updated etcd Project Journey Report is live – the project now has more than 5,500 individual contributors!】更新后的 etcd 项目旅程报告已上线 – 该项目现在拥有超过 5,500 名个人贡献者！</title>
      <link>https://www.cncf.io/blog/2024/10/07/the-updated-etcd-project-journey-report-is-live-the-project-now-has-more-than-5500-individual-contributors/</link>
      <description>【&lt;p&gt;We’re excited to share the updated &lt;a href=&#34;https://www.cncf.io/reports/etcd-project-journey-report/&#34;&gt;etcd Project Journey Report&lt;/a&gt;! etcd is one of CNCF’s longest-standing graduated projects. We initially looked at the project’s growth back in &lt;a href=&#34;https://www.cncf.io/blog/2021/03/30/etcd-project-journey-report-individual-project-contributors-increase-by-67-after-joining-cncf/&#34;&gt;2021&lt;/a&gt;, and are happy to see continued growth in innovation from old and new contributors and end users.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;etcd is a key-value store for distributed systems that provides a way for applications of any complexity — from simple web applications to large software platforms — to store and access critical data. It is the primary datastore for CNCF’s highest open source velocity project, Kubernetes.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;etcd was accepted into the CNCF Incubator in 2018, where it remained for two years before graduating in November 2020. It has demonstrated steady and impressive growth since joining&amp;nbsp; CNCF in 2018.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Some of the highlights of the report include:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Contributor diversity: The total number of contributing companies has increased by 75% since etcd joined CNCF, rising from 499 to 873. This corresponds to a rise in individual contributors 143% from 2,328 to 5,667. All time contributions to etcd now total over 168,800, up 127% from 74,327 in 2018.&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Production adoption: etcd has been adopted by organizations across the globe, including leaders in financial services, technology, telecommunications, artificial intelligence, and others, such as Fidelity Investments, Ant Financial, and Huawei.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Community knowledge-sharing: etcd has been the subject of 38 keynotes, talks, sessions, meetings, and workshops at KubeCon + CloudNativeCon events across the globe, attended by tens of thousands each year.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Have a look at the full updated &lt;a href=&#34;https://www.cncf.io/reports/etcd-project-journey-report/&#34;&gt;etcd Project Journey Report&lt;/a&gt; to learn more about these accomplishments in more detail.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;我们很高兴分享更新后的 &lt;a href=&#34;https://www.cncf.io/reports/etcd-project-journey-report/&#34;&gt;etcd 项目历程报告&lt;/a&gt;！ etcd 是 CNCF 历史最悠久的毕业项目之一。我们最初在&lt;a href=&#34;https://www.cncf.io/blog/2021/03/30/etcd-project-journey-report-individual-project-contributors-increase-by-中查看了该项目的增长情况67-after-joining-cncf/&#34;&gt;2021&lt;/a&gt;，很高兴看到新老贡献者和最终用户的创新持续增长。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;etcd 是分布式系统的键值存储，它为任何复杂性的应用程序（从简单的 Web 应用程序到大型软件平台）提供了一种存储和访问关键数据的方法。它是 CNCF 最高开源速度项目 Kubernetes 的主要数据存储。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;etcd 于 2018 年被 CNCF 孵化器接纳，并在那里呆了两年，于 2020 年 11 月毕业。自 2018 年加入 CNCF 以来，它表现出了稳定而令人印象深刻的增长。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;报告的一些要点包括：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;贡献者多样性：自 etcd 加入 CNCF 以来，贡献公司总数增加了 75%，从 499 家增加到 873 家。这相当于个人贡献者从 2,328 家增加到 5,667 家，增加了 143%。目前对 etcd 的所有贡献总数已超过 168,800 个，比 2018 年的 74,327 个增长了 127%。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;生产采用：etcd 已被全球各地的组织采用，包括金融服务、技术、电信、人工智能等领域的领先企业，例如富达投资、蚂蚁金服和华为。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;社区知识共享：etcd 已成为全球 KubeCon + CloudNativeCon 活动中 38 场主题演讲、演讲、会议、会议和研讨会的主题，每年有数万人参加。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;查看完整更新的&lt;a href=&#34;https://www.cncf.io/reports/etcd-project-journey-report/&#34;&gt;etcd 项目历程报告&lt;/a&gt;，了解有关这些内容的更多信息更详细地取得成就。 &lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Sun, 06 Oct 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Kubestronaut in Orbit: Phong Nguyen Van】在轨 Kubetronaut：Phong Nguyen Van</title>
      <link>https://www.cncf.io/blog/2024/10/08/kubestronaut-in-orbit-phong-nguyen-van/</link>
      <description>【&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1800&#34; height=&#34;945&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/10/Kubestronaut-in-Orbit-1-1.jpg&#34; alt=&#34;Kubestronaut &#34; class=&#34;wp-image-118720&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/10/Kubestronaut-in-Orbit-1-1.jpg 1800w, https://www.cncf.io/wp-content/uploads/2024/10/Kubestronaut-in-Orbit-1-1-300x158.jpg 300w, https://www.cncf.io/wp-content/uploads/2024/10/Kubestronaut-in-Orbit-1-1-1024x538.jpg 1024w, https://www.cncf.io/wp-content/uploads/2024/10/Kubestronaut-in-Orbit-1-1-768x403.jpg 768w, https://www.cncf.io/wp-content/uploads/2024/10/Kubestronaut-in-Orbit-1-1-194x102.jpg 194w, https://www.cncf.io/wp-content/uploads/2024/10/Kubestronaut-in-Orbit-1-1-388x204.jpg 388w, https://www.cncf.io/wp-content/uploads/2024/10/Kubestronaut-in-Orbit-1-1-776x408.jpg 776w, https://www.cncf.io/wp-content/uploads/2024/10/Kubestronaut-in-Orbit-1-1-1552x816.jpg 1552w, https://www.cncf.io/wp-content/uploads/2024/10/Kubestronaut-in-Orbit-1-1-900x473.jpg 900w, https://www.cncf.io/wp-content/uploads/2024/10/Kubestronaut-in-Orbit-1-1-381x200.jpg 381w, https://www.cncf.io/wp-content/uploads/2024/10/Kubestronaut-in-Orbit-1-1-762x400.jpg 762w, https://www.cncf.io/wp-content/uploads/2024/10/Kubestronaut-in-Orbit-1-1-590x310.jpg 590w, https://www.cncf.io/wp-content/uploads/2024/10/Kubestronaut-in-Orbit-1-1-1180x620.jpg 1180w&#34; sizes=&#34;(max-width: 1800px) 100vw, 1800px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Get to know Phong&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This week’s Kubestronaut in Orbit, Phong Nguyen Van, is a full-stack software engineer in Ho Chi Minh, Vietnam with over 7 years of experience and a passion for cloud technologies and Kubernetes. Phong also holds 5 AWS certifications along with his 5 K8s certifications and is in the top 3% of Stack Overflow users.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you’d like to be a Kubestronaut like Phong, get more details on the &lt;a href=&#34;https://www.cncf.io/training/kubestronaut/&#34;&gt;CNCF Kubestronaut&lt;/a&gt; page.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;When did you get started with Kubernetes and/or cloud-native? What was your first project?&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;My first project was creating and supporting Kubernetes clusters in production environments for multi-tenancy LMS as Microservices.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;What are the primary CNCF projects you work on or use today?&amp;nbsp; What projects have you enjoyed the most in your career?&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;I primarily use &lt;a href=&#34;https://kubernetes.io/docs/home/&#34;&gt;Kubernetes&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;How have the certs or CNCF helped you in your career?&amp;nbsp;&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The certs helped me to get an in depth understanding of Kubernetes architecture and security.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;What are some other books/sites/courses you recommend for people who want to work with k8s?&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To prepare, I used &lt;a href=&#34;https://business.udemy.com/cncf-endorsed-content/&#34;&gt;Udemy &lt;/a&gt;(check out the CNCF endorsed content), and content on Cloud Guru and KodeKloud.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;What do you do in your free time?&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;I like to study new technologies and spend time with my family – my wife Nhu Dang and my daughter Khanh Vy .&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;What would you tell someone who is just starting their K8s certification journey? Any tips or tricks?&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Make sure you have a deep understanding of the fundamentals and once you have that, you can move on to the higher and more complicated levels. CNCF recommends exploring the CNCF &lt;a href=&#34;https://www.cncf.io/projects/kubernetes/&#34;&gt;Kubernetes project&lt;/a&gt; to get started.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Today the Cloud native ecosystem is way more than Kubernetes. Do you plan to get other cloud native certifications from the CNCF ?&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Absolutely, I am thinking about observability certs like:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cncf.io/training/certification/pca/&#34;&gt;Prometheus Certified Associate (PCA)&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cncf.io/training/certification/#ica&#34;&gt;Istio Certified Associate (ICA)&amp;nbsp;&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cncf.io/training/certification/#CGOA&#34;&gt;GitOps Certified Associate (CGOA)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“1800”高度=“945”src=“https://www.cncf.io/ wp-content/uploads/2024/10/Kubestronaut-in-Orbit-1-1.jpg&#34; alt=&#34;Kubestronaut&#34; class=&#34;wp-image-118720&#34; srcset=&#34;https://www.cncf.io/wp -content/uploads/2024/10/Kubestronaut-in-Orbit-1-1.jpg 1800w，https://www.cncf.io/wp-content/uploads/2024/10/Kubestronaut-in-Orbit-1- 1-300x158.jpg 300w，https://www.cncf.io/wp-content/uploads/2024/10/Kubestronaut-in-Orbit-1-1-1024x538.jpg 1024w，https://www.cncf。 io/wp-content/uploads/2024/10/Kubestronaut-in-Orbit-1-1-768x403.jpg 768w，https://www.cncf.io/wp-content/uploads/2024/10/Kubestronaut-in -Orbit-1-1-194x102.jpg 194w，https://www.cncf.io/wp-content/uploads/2024/10/Kubestronaut-in-Orbit-1-1-388x204.jpg 388w，https:// /www.cncf.io/wp-content/uploads/2024/10/Kubestronaut-in-Orbit-1-1-776x408.jpg 776w，https://www.cncf.io/wp-content/uploads/2024/ 10/Kubestronaut-in-Orbit-1-1-1552x816.jpg 1552w，https://www.cncf.io/wp-content/uploads/2024/10/Kubestronaut-in-Orbit-1-1-900x473.jpg 900w，https://www.cncf.io/wp-content/uploads/2024/10/Kubestronaut-in-Orbit-1-1-381x200.jpg 381w，https://www.cncf.io/wp-content /uploads/2024/10/Kubestronaut-in-Orbit-1-1-762x400.jpg 762w，https://www.cncf.io/wp-content/uploads/2024/10/Kubestronaut-in-Orbit-1- 1-590x310.jpg 590w，https://www.cncf.io/wp-content/uploads/2024/10/Kubestronaut-in-Orbit-1-1-1180x620.jpg 1180w“尺寸=”（最大宽度： 1800 像素) 100vw, 1800 像素&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;了解 Phong&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;本周 Orbit 的 Kubetronaut Phong Nguyen Van 是越南胡志明市的一名全栈软件工程师，拥有 7 年多的经验，对云技术和 Kubernetes 充满热情。 Phong 还拥有 5 项 AWS 认证以及 5 项 K8s 认证，并且在 Stack Overflow 用户中名列前 3%。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您想成为像 Phong 这样的 Kubetronaut，请在 &lt;a href=&#34;https://www.cncf.io/training/kubestronaut/&#34;&gt;CNCF Kubetronaut&lt;/a&gt; 页面获取更多详细信息。&lt; /p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;您什么时候开始使用 Kubernetes 和/或云原生？您的第一个项目是什么？&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我的第一个项目是在生产环境中创建和支持 Kubernetes 集群，以将多租户 LMS 作为微服务。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;您目前从事或使用的主要 CNCF 项目是什么？  在您的职业生涯中您最喜欢哪些项目？&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我主要使用&lt;a href=&#34;https://kubernetes.io/docs/home/&#34;&gt;Kubernetes&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;证书或 CNCF 对您的职业生涯有何帮助？ &lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这些证书帮助我深入了解 Kubernetes 架构和安全性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;您为想要使用 k8s 的人推荐了哪些其他书籍/网站/课程？&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;为了做好准备，我sed &lt;a href=&#34;https://business.udemy.com/cncf-endorsed-content/&#34;&gt;Udemy &lt;/a&gt;（查看 CNCF 认可的内容），以及 Cloud Guru 和 KodeKloud 上的内容。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;你空闲时间做什么？&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我喜欢学习新技术并与家人共度时光 - 我的妻子 Nhu Dang 和我的女儿 Khanh Vy。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;您会对刚刚开始 K8s 认证之旅的人说些什么？有什么提示或技巧吗？&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;确保您对基础知识有深入的了解，一旦掌握了这一点，您就可以进入更高、更复杂的级别。 CNCF 建议探索 CNCF &lt;a href=&#34;https://www.cncf.io/projects/kubernetes/&#34;&gt;Kubernetes 项目&lt;/a&gt;以开始使用。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;如今，云原生生态系统的意义远不止 Kubernetes。您是否计划获得 CNCF 的其他云原生认证？&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;当然，我正在考虑可观察性证书，例如：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cncf.io/training/certification/pca/&#34;&gt;普罗米修斯认证助理 (PCA)&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cncf.io/training/certification/#ica&#34;&gt;Istio 认证工程师 (ICA)&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cncf.io/training/certification/#CGOA&#34;&gt;GitOps 认证助理 (CGOA)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Mon, 07 Oct 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【TAG Environmental Sustainability Week is here: a global call for green tech】TAG环境可持续发展周来了：全球呼吁绿色科技</title>
      <link>https://www.cncf.io/blog/2024/10/08/tag-environmental-sustainability-week-is-here-a-global-call-for-green-tech/</link>
      <description>【&lt;p&gt;&lt;em&gt;By TAG Environmental Sustainability&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXc0iebRDJ7Ud3YhQz1xH9Mo552UsIQyGTftZlwyngclVn8LQaPqM5pD1CJIR2gd6ZMx3_IE4JChcCVjvQ0RjU6hf4DuwOi7_8pn6VdYeLAOvO0o2DH991g_tGzSgvXE2AAL9mfjIgm4vfqHZ799M7U8oNtH?key=ENelyAzGxm5sQXG-xFPG2Q&#34; alt=&#34;TAG environmental sustainability&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Get ready for the &lt;strong&gt;&lt;a href=&#34;https://tag-env-sustainability.cncf.io/events/cloud-native-sustainability-week/&#34;&gt;CNCF Cloud Native Sustainability Week 2024&lt;/a&gt;&lt;/strong&gt;, which will take place from &lt;strong&gt;October 7th to 13th, 2024&lt;/strong&gt;. This global event, organized by the &lt;strong&gt;CNCF Technical Advisory Group for Environmental Sustainability (TAG ENV)&lt;/strong&gt;, aims to bring together communities worldwide to discuss, learn, and contribute to a more sustainable cloud-native future.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;With &lt;strong&gt;in-person meetups&lt;/strong&gt; across &lt;strong&gt;20+ cities&lt;/strong&gt;, including &lt;strong&gt;Berlin&lt;/strong&gt;, &lt;strong&gt;Tokyo&lt;/strong&gt;, and &lt;strong&gt;Aarhus&lt;/strong&gt;, and a &lt;a href=&#34;https://community.cncf.io/events/details/cncf-cloud-native-sustainability-presents-virtual-mini-conference-cloud-native-sustainability-week-2024/&#34;&gt;&lt;strong&gt;Global Virtual Mini-Conference&lt;/strong&gt;&lt;/a&gt; on &lt;strong&gt;October 8th, 2024&lt;/strong&gt;, this week promises to deliver rich discussions on topics like &lt;strong&gt;green software&lt;/strong&gt; and &lt;strong&gt;optimizing IT infrastructures&lt;/strong&gt; to reduce environmental impact. The online conference will bring together experts from across the globe, with sessions streamed live on &lt;strong&gt;YouTube&lt;/strong&gt;, so no matter where you are, you can participate and engage with the latest innovations in sustainable tech.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;These meetups provide a platform for tech enthusiasts, developers, and sustainability advocates to connect, share insights, and collaborate on cloud-native solutions that reduce energy consumption and optimize IT infrastructure. Local challenges and global perspectives will be explored, all with the goal of making the tech industry more sustainable.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Throughout the week, you can also expect a series of &lt;strong&gt;YouTube livestreams&lt;/strong&gt; featuring discussions and insights from sustainability leaders in cloud-native technology. The recordings will be available afterward, ensuring anyone can catch up on the key takeaways.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Whether you’re a seasoned professional in the tech world, a sustainability enthusiast, or someone just starting your journey, there’s something for everyone at &lt;strong&gt;Cloud Native Sustainability Week 2024&lt;/strong&gt;. This event is an opportunity to learn, contribute, and be part of a global movement dedicated to making the technology sector more environmentally friendly. You can explore the full event details, including how to participate in both local meetups and the virtual mini-conference, on the official pages&lt;a href=&#34;https://tag-env-sustainability.cncf.io/events/cloud-native-sustainability-week/&#34;&gt; here&lt;/a&gt;.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Sustainability Week offers a unique opportunity to:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Learn about the latest trends in sustainable cloud native technologies&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Connect with experts and peers passionate about environmental sustainability&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Discover practical strategies for reducing the environmental impact of your cloud infrastructure&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Contribute to the ongoing dialogue on creating a more sustainable tech industry&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;By attending or hosting a session, you can help drive the conversation forward, sharing ideas and best practices that will shape the future of sustainable cloud-native infrastructure. Let’s work together to make a meaningful impact and create a greener, more responsible tech ecosystem!&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Join us in making tech more sustainable, one innovation at a time!&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Call for Actions&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Join Local Meetups:&lt;/strong&gt; Visit our &lt;a href=&#34;https://tag-env-sustainability.cncf.io/events/cloud-native-sustainability-week/&#34;&gt;Event Page&lt;/a&gt; to find local meetups and RSVP if you’ll be attending!&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Participate in Our Mini Virtual Conference:&lt;/strong&gt; Check out the conference through this &lt;a href=&#34;https://community.cncf.io/events/details/cncf-cloud-native-sustainability-presents-virtual-mini-conference-cloud-native-sustainability-week-2024/&#34;&gt;link&lt;/a&gt; and make sure to RSVP.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Stay tuned:&lt;/strong&gt; Follow us on social media to keep up with the latest news, events, and updates.&lt;br&gt;&lt;br&gt;&lt;em&gt;Slack:&lt;/em&gt; &lt;a href=&#34;https://slack.cncf.io/&#34;&gt;CNCF Slack&lt;/a&gt; with &lt;a href=&#34;https://cloud-native.slack.com/archives/C03F270PDU6&#34;&gt;#tag-environmental-sustainability&lt;/a&gt; and &lt;a href=&#34;https://cloud-native.slack.com/archives/C06TCK5RXCG&#34;&gt;# tag-env-cloud-native-sustainability-week&lt;br&gt;&lt;/a&gt;&lt;em&gt;LinkedIn: &lt;/em&gt;&lt;a href=&#34;https://www.linkedin.com/company/cncf-tag-environmental-sustainability/posts/?feedView=all&#34;&gt;&lt;em&gt;CNCF TAG Environmental Sustainability&lt;br&gt;&lt;/em&gt;&lt;/a&gt;&lt;em&gt;X: &lt;a href=&#34;https://x.com/CNCFEnvTAG&#34;&gt;@CNCFEnvTAG&lt;/a&gt;&lt;br&gt;&lt;/em&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Engage in Environmental Sustainability:&lt;/strong&gt; Let’s discuss, consider being a part of us, and take action for change!&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;作者：TAG环境可持续发展&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXc0iebRDJ7Ud3YhQz1xH9Mo552UsIQyGTftZlwyngclVn8LQaPqM5pD1CJIR2gd6ZMx3_IE4JChcCVjvQ0RjU6hf4Du wOi7_8pn6VdYeLAOvO0o2DH991g_tG​​zSgvXE2AAL9mfjIgm4vfqHZ799M7U8oNtH?key=ENelyAzGxm5sQXG-xFPG2Q&#34; alt=&#34;TAG 环境可持续性“referrerpolicy =“no-referrer”&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;为 &lt;strong&gt;&lt;a href=&#34;https://tag-env-sustainability.cncf.io/events/cloud-native-sustainability-week/&#34;&gt;2024 年 CNCF 云原生可持续发展周做好准备&lt;/a &gt;&lt;/strong&gt;，将于&lt;strong&gt;2024 年 10 月 7 日至 13 日&lt;/strong&gt;举行。这项全球活动由&lt;strong&gt;CNCF 环境可持续性技术咨询小组 (TAG ENV)&lt;/strong&gt; 组织，旨在将世界各地的社区聚集在一起，讨论、学习并为更加可持续的云原生未来做出贡献。&lt;/strong&gt; p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在 &lt;strong&gt;20 多个城市&lt;/strong&gt;举办&lt;strong&gt;面对面聚会&lt;/strong&gt;，包括&lt;strong&gt;柏林&lt;/strong&gt;、&lt;strong&gt;东京&lt;/strong&gt;和&lt;strong&gt;奥胡斯&lt;/strong&gt;，以及&lt;a href=&#34;https://community.cncf.io/events/details/cncf-cloud-native-sustainability-presents-virtual-mini-conference-cloud-native-sustainability-week -2024/&#34;&gt;&lt;strong&gt;全球虚拟小型会议&lt;/strong&gt;&lt;/a&gt;将于&lt;strong&gt;2024年10月8日&lt;/strong&gt;举行，本周有望就&lt;strong&gt;绿色软件&lt;等主题进行丰富的讨论/strong&gt;并&lt;strong&gt;优化 IT 基础设施&lt;/strong&gt;以减少对环境的影响。在线会议将汇集来自全球各地的专家，并在 &lt;strong&gt;YouTube&lt;/strong&gt; 上直播会议，因此无论您身在何处，都可以参与并接触可持续技术的最新创新。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这些聚会为技术爱好者、开发人员和可持续发展倡导者提供了一个交流、分享见解并就云原生解决方案进行协作的平台，以减少能源消耗并优化 IT 基础设施。我们将探讨当地挑战和全球视角，所有这些都是为了使科技行业更具可持续性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在这一周，您还可以观看一系列 &lt;strong&gt;YouTube 直播&lt;/strong&gt;，其中包含云原生技术领域可持续发展领导者的讨论和见解。随后将提供录音，以确保任何人都能掌握关键要点。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;无论您是科技界经验丰富的专业人士、可持续发展爱好者，还是刚刚开始您的旅程的人，&lt;strong&gt;2024 年云原生可持续发展周&lt;/strong&gt;都能满足每个人的需求。此次活动是一个学习、贡献和参与致力于使技术行业更加环保的全球运动的机会。您可以在官方页面上探索完整的活动详细信息，包括如何参加本地聚会和虚拟迷你会议&lt;a href=&#34;https://tag-env-sustainability.cncf.io/events/cloud-native-sustainability-week/&#34;&gt;此处&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;可持续发展周提供了一个独特的机会：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;了解可持续云原生技术的最新趋势&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;与热衷于环境可持续发展的专家和同行交流&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;探索减少云基础设施对环境影响的实用策略&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;为持续开展的关于创建更具可持续性的科技行业的对话做出贡献&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;通过参加或主持会议，您可以帮助推动对话向前发展，分享将塑造可持续云原生基础设施未来的想法和最佳实践。让我们共同努力，产生有意义的影响，创建一个更环保、更负责任的科技生态系统！&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;与我们一起，让技术更具可持续性，一次一项创新！&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;号召行动&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;参加本地聚会&lt;/strong&gt;：访问我们的&lt;a href=&#34;https://tag-env-sustainability.cncf.io/events/cloud-native-sustainability-week/&#34;&gt;活动页面&lt; /a&gt; 查找当地聚会并回复（如果您要参加的话）！ &lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;参加我们的小型虚拟会议：&lt;/strong&gt;通过此 &lt;a href=&#34;https://community.cncf.io/events/details/cncf-cloud-native-sustainability- 查看会议Presents-virtual-mini-conference-cloud-native-sustainability-week-2024/&#34;&gt;链接&lt;/a&gt;并确保回复。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;敬请关注：&lt;/strong&gt;在社交媒体上关注我们，了解最新新闻、活动和更新。&lt;br&gt;&lt;br&gt;&lt;em&gt;Slack：&lt;/em&gt; &lt;a href= “https://slack.cncf.io/&#34;&gt;CNCF Slack&lt;/a&gt; 与 &lt;a href=&#34;https://cloud-native.slack.com/archives/C03F270PDU6&#34;&gt;#tag-environmental-sustainability&lt;/a&gt; a&gt; 和 &lt;a href=&#34;https://cloud-native.slack.com/archives/C06TCK5RXCG&#34;&gt;# tag-env-cloud-native-sustainability-week&lt;br&gt;&lt;/a&gt;&lt;em&gt;LinkedIn: &lt; /em&gt;&lt;a href=&#34;https://www.linkedin.com/company/cncf-tag-environmental-sustainability/posts/?feedView=all&#34;&gt;&lt;em&gt;CNCF TAG 环境可持续发展&lt;br&gt;&lt;/em&gt; &lt;/a&gt;&lt;em&gt;X：&lt;a href=&#34;https://x.com/CNCFEnvTAG&#34;&gt;@CNCFEnvTAG&lt;/a&gt;&lt;br&gt;&lt;/em&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;参与环境可持续发展：&lt;/strong&gt;让我们讨论，考虑成为我们的一部分，并采取行动推动变革！&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Mon, 07 Oct 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Understanding initial states in cloud migration】了解云迁移的初始状态</title>
      <link>https://www.cncf.io/blog/2024/10/02/understanding-initial-states-in-cloud-migration/</link>
      <description>【&lt;p&gt;&lt;em&gt;Member post by &lt;a href=&#34;https://www.linkedin.com/in/anshul-sao/&#34;&gt;Anshul Sao&lt;/a&gt;, Co-founder &amp;amp; CTO, &lt;a href=&#34;https://www.facets.cloud/&#34;&gt;Facets.cloud &lt;/a&gt;&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In today’s tech landscape, organizations frequently face the need to migrate—whether from on-premise to the cloud, from one cloud provider to another, or managing multiple cloud environments. While cloud service providers (CSPs) offer equivalent services and often provide funding and resources to facilitate these migrations, a common challenge persists: many migrations result in a target state that is not significantly better, and sometimes even worse, than the initial state.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;When it comes to cloud migration, a one-size-fits-all approach doesn’t work. Your strategy should be tailored to your starting point—your initial state. Understanding your current infrastructure before diving into a migration can make the difference between a smooth transition and a series of costly headaches.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Further, it may be a missed opportunity to clear out legacy mistakes and sub-optimal tools and practices.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For CIOs, CTOs, and Heads of DevOps, this is especially crucial. Let’s explore why it’s essential to grasp your initial state and how it can shape your cloud migration journey, whether you’re moving from one cloud provider to another (like AWS to GCP) or transitioning from on-premises to the cloud.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;a&gt;&lt;/a&gt;&lt;strong&gt;Assessing Your Initial State&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Before you can plan your migration, you need to understand the state of your existing infrastructure. There are three initial states most organizations fall into:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol start=&#34;1&#34; class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Complete Automation with Modernized Infrastructure&lt;/strong&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Complete Automation with Legacy Infrastructure&lt;/strong&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Partial or No Automation with Legacy Infrastructure&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Each of these scenarios requires a different approach to migration. Let’s break them down.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;a&gt;&lt;/a&gt;&lt;strong&gt;1. Complete Automation with Modernized Infrastructure&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In this scenario, your organization has already embraced modern practices. You’re running Kubernetes with cloud-native databases, and have well-defined CI/CD pipelines in place. Infrastructure as Code (IaC) is used for everything from infra creation to observability and other concerns.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;But here’s the catch: when you migrate to a different cloud provider, much of the tooling you’ve relied on becomes obsolete. Cloud-specific Terraform scripts, CDK, networking configurations, and security policies— all need to be rewritten to fit the new environment. The same goes for your FinOps tools, account management systems, reporting, ETLs, and analytics. Cloud functions like AWS Lambda, Google Cloud Functions (GCF), and Azure Functions (AFs) need a fresh approach.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;What Stays the Same:&lt;/strong&gt; Thankfully, not everything changes. Your Kubernetes manifests, deployment strategies, config management, and CI/CD tooling can remain largely intact, providing continuity in an otherwise disruptive process.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Adopting Platform Engineering:&lt;/strong&gt; This is the perfect moment to rethink how you approach automation. Instead of building out individual projects with repetitive processes like in the current cloud, consider adopting platform engineering. By creating reusable building blocks that can be deployed across multiple projects, you’ll not only streamline your migration but also set your organization up for long-term scalability and success. Most of your existing tooling can be remodeled in this way, achieving mostly overlooked but important aspects like DevOps and Developer Productivity, Stable Infrastructure, and Cost optimization by design.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;a&gt;&lt;/a&gt;&lt;strong&gt;2. Complete Automation with Legacy Infrastructure&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If your infrastructure is fully automated but still running on legacy systems—think VMs and self-hosted databases—your migration will involve a steep learning curve. The automation you’ve developed for your current environment may not translate well to the target cloud provider.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Challenges:&lt;/strong&gt; Moving from VMs and self-hosted databases to a new cloud environment means you must re-engineer everything. Autoscaling, health checks, load balancers, security groups, route tables—all fundamental components work differently across cloud providers. It’s almost like starting from scratch.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Tooling Obsolescence:&lt;/strong&gt; In this case, almost all of your tooling will need to be replaced. For example, your existing CloudFormation templates or Terraform scripts may be useless in the target cloud. Even your CI systems might require adjustments.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;The Modernization Hook:&lt;/strong&gt; Now there are two choices, rebuild the posture as it was in the target cloud or invest the same effort in modernizing your stack. Since you’re already redesigning and re-automating everything, you might as well future-proof your operations. The delta in effort required for modernization at this stage is minimal, as the kinds of testing and qualification—such as performance testing, sanity checks, and other validation processes—will be similar for both migration and modernization activities. By aligning these efforts, you can streamline the process and ensure that your infrastructure is ready for the future.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;a&gt;&lt;/a&gt;&lt;strong&gt;3. Partial or No Automation with Legacy Infrastructure&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This is the toughest spot, but it’s a reality for many organizations. If your processes are still largely manual and you haven’t embraced automation, migrating to the cloud will be a significant challenge.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Challenges:&lt;/strong&gt; The main problem here is that your current operating method won’t cut it in the cloud. Manual processes are inefficient, error-prone, and impossible to scale in a modern cloud environment.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Why Now is the Time to Change:&lt;/strong&gt; Cloud migration is your chance to transform how your organization works. It’s the right moment to evaluate new tools and platforms to help you manage workloads more effectively in the cloud. All aspects, from provisioning to deployment to monitoring, can be automated, making your operations more efficient and reliable. Reskilling your team, adopting new practices, and investing in automation will make the migration smoother and set your organization up for future success. That said, it will require significant investment in upskilling your current workforce, seeking consultation, and finding partners to ease your journey of automation.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;a&gt;&lt;/a&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Cloud migration is more than just a technical shift; it’s an opportunity to question your old practices, embrace new trends like platform engineering, and reboot your operations for a more efficient, scalable future. Assessing your initial state is the first step in this journey. Whether you’re fully automated with modernized infrastructure or struggling with manual processes, understanding where you stand will help you confidently navigate the complexities of cloud migration.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you’re ready to take the next step, consider exploring how platform engineering can affect your migration strategy. It could be the key to unlocking the full potential of your cloud operations.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;成员帖子，作者：&lt;a href=&#34;https://www.linkedin.com/in/anshul-sao/&#34;&gt;Anshul Sao&lt;/a&gt;，联合创始人兼首席技术官，&lt;a href=&#34; https://www.facets.cloud/&#34;&gt;Facets.cloud&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在当今的技术环境中，组织经常面临迁移的需要，无论是从本地迁移到云、从一个云提供商迁移到另一个云提供商，还是管理多个云环境。虽然云服务提供商 (CSP) 提供同等服务，并且经常提供资金和资源来促进这些迁移，但一个常见的挑战仍然存在：许多迁移导致的目标状态并不比初始状态明显更好，有时甚至更糟。&lt; /p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在云迁移方面，一刀切的方法是行不通的。您的策略应该根据您的起点（您的初始状态）量身定制。在进行迁移之前了解您当前的基础架构可以让您顺利过渡并避免一系列代价高昂的麻烦。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;此外，这可能会错失清除遗留错误以及次优工具和实践的机会。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;对于 CIO、CTO 和 DevOps 负责人来说，这一点尤其重要。让我们探讨为什么掌握初始状态至关重要，以及它如何塑造您的云迁移之旅，无论您是从一个云提供商迁移到另一个云提供商（例如 AWS 到 GCP），还是从本地迁移到云。&lt;/p &gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;a&gt;&lt;/a&gt;&lt;strong&gt;评估您的初始状态&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在规划迁移之前，您需要了解现有基础架构的状态。大多数组织都会陷入三种初始状态：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol开始=“1”类=“wp-block-list”&gt;&#xA;&lt;li&gt;&lt;strong&gt;通过现代化基础设施实现完全自动化&lt;/strong&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;利用旧基础设施实现完全自动化&lt;/strong&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;旧基础设施实现部分自动化或无自动化&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;每种情况都需要不同的迁移方法。让我们把它们分解一下。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;a&gt;&lt;/a&gt;&lt;strong&gt;1.通过现代化基础设施实现完全自动化&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在这种情况下，您的组织已经采用了现代实践。您正在使用云原生数据库运行 Kubernetes，并拥有明确定义的 CI/CD 管道。基础设施即代码 (IaC) 用于处理从基础设施创建到可观察性和其他问题的所有事务。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;但有一个问题：当您迁移到不同的云提供商时，您依赖的许多工具都会过时。特定于云的 Terraform 脚本、CDK、网络配置和安全策略 - 都需要重写以适应新环境。 FinOps 工具、账户管理系统、报告、ETL 和分析也是如此。 AWS Lambda、Google Cloud Functions (GCF) 和 Azure Functions (AF) 等云函数需要一种全新的方法。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;什么站是一样的：&lt;/strong&gt;幸运的是，并不是一切都改变了。您的 Kubernetes 清单、部署策略、配置管理和 CI/CD 工具可以基本保持不变，从而在原本具有破坏性的流程中提供连续性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;采用平台工程&lt;/strong&gt;：这是重新思考如何实现自动化的最佳时机。考虑采用平台工程，而不是像当前云中那样通过重复流程构建单个项目。通过创建可跨多个项目部署的可重用构建块，您不仅可以简化迁移，还可以让您的组织获得长期可扩展性和成功。您的大多数现有工具都可以通过这种方式进行重构，从而实现大多数被忽视但重要的方面，例如开发运营和开发人员生产力、稳定的基础设施和设计成本优化。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;a&gt;&lt;/a&gt;&lt;strong&gt;2.使用遗留基础设施实现完全自动化&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您的基础设施是完全自动化的，但仍在旧系统上运行（例如虚拟机和自托管数据库），您的迁移将涉及陡峭的学习曲线。您为当前环境开发的自动化可能无法很好地应用于目标云提供商。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;挑战：&lt;/strong&gt;从虚拟机和自托管数据库迁移到新的云环境意味着您必须重新设计一切。自动扩展、运行状况检查、负载均衡器、安全组、路由表——所有基本组件在不同云提供商之间的工作方式都不同。这几乎就像从头开始。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;工具过时：&lt;/strong&gt;在这种情况下，几乎所有工具都需要更换。例如，您现有的 CloudFormation 模板或 Terraform 脚本在目标云中可能毫无用处。甚至您的 CI 系统也可能需要调整。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;现代化挂钩：&lt;/strong&gt;现在有两种选择：重建目标云中的状态，或者投入相同的精力来实现堆栈现代化。既然您已经在重新设计和重新自动化一切，那么您不妨让您的运营面向未来。此阶段现代化所需的工作增量很小，因为迁移和现代化活动的测试和资格类型（例如性能测试、健全性检查和其他验证过程）将相似。通过协调这些工作，您可以简化流程并确保您的基础架构为未来做好准备。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;a&gt;&lt;/a&gt;&lt;strong&gt;3.遗留基础设施部分自动化或无自动化&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这是最困难的地方，但对于许多组织来说这是现实。如果您的流程仍然主要是手动的，并且您还没有采用自动化，那么迁移到云将是一个重大挑战。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;挑战：&lt;/strong&gt;这里的主要问题是您当前的操作方法不会在云端削减它。手动流程效率低下、容易出错，并且无法在现代云环境中扩展。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;为什么现在是改变的时候了：&lt;/strong&gt;云迁移是您改变组织运作方式的机会。现在是评估新工具和平台以帮助您更有效地管理云中工作负载的最佳时机。从配置到部署再到监控的所有方面都可以实现自动化，使您的运营更加高效和可靠。重新培训您的团队、采用新实践以及投资自动化将使迁移更加顺利，并为您的组织未来的成功奠定基础。也就是说，需要大量投资来提高现有员工的技能、寻求咨询并寻找合作伙伴来简化您的自动化之旅。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;a&gt;&lt;/a&gt;&lt;strong&gt;结论&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;云迁移不仅仅是一种技术转变；更是一种技术转变。这是一个质疑旧做法、拥抱平台工程等新趋势以及重新启动运营以实现更高效、可扩展的未来的机会。评估您的初始状态是此旅程的第一步。无论您是通过现代化基础设施实现完全自动化，还是在手动流程中苦苦挣扎，了解自己的处境都将帮助您自信地应对云迁移的复杂性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您准备好采取下一步，请考虑探索平台工程如何影响您的迁移策略。它可能是释放云运营全部潜力的关键。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Tue, 01 Oct 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Optimizing Kubernetes Networking with Chelsio T6 Unified Wire Adapters】使用 Chelsio T6 统一有线适配器优化 Kubernetes 网络</title>
      <link>https://www.cncf.io/blog/2024/10/08/optimizing-kubernetes-networking-with-chelsio-t6-unified-wire-adapters/</link>
      <description>【&lt;p&gt;&lt;em&gt;Member post by Chelsio Communications&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Introduction&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As Kubernetes continues transforming the cloud-native infrastructure, high-performance networking has become essential for maintaining seamless operations in containerized applications. Chelsio T6 Unified Wire Adapters provide advanced networking capabilities that meet the demands of modern Kubernetes deployments, especially for handling data-intensive workloads. With features like &lt;strong&gt;SR-IOV&lt;/strong&gt;, hardware offloading, and acceleration for versatile protocols such as &lt;strong&gt;iWARP&lt;/strong&gt;, &lt;strong&gt;NVMe/TCP&lt;/strong&gt;, and &lt;strong&gt;NVMe-oF&lt;/strong&gt;, T6 adapters allow Kubernetes clusters to scale efficiently while ensuring optimal performance.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In this blog post, we explore the integration of Chelsio T6 adapters into Kubernetes environments using &lt;strong&gt;CNI plugins&lt;/strong&gt;, highlighting how their flexibility improves networking across a wide range of applications.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Key Benefits of T6 Adapters for Kubernetes&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;1. Performance Gains through SR-IOV&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Chelsio T6 adapters support &lt;strong&gt;Single Root I/O Virtualization (SR-IOV)&lt;/strong&gt;, allowing multiple &lt;strong&gt;Virtual Functions (VFs)&lt;/strong&gt; to be exposed to Kubernetes pods and enabling direct I/O access to the network hardware. This delivers low-latency, high-throughput networking, which is essential for Kubernetes clusters handling critical workloads. By offloading network tasks to hardware, T6 adapters reduce the load on the host CPU, allowing more resources to be available for containerized applications, which enhances their performance, particularly when managing large volumes of data.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;With SR-IOV, T6 adapters enable Kubernetes deployments to scale efficiently without compromising performance, making them the ideal choice for demanding high-performance workloads such as &lt;strong&gt;AI&lt;/strong&gt;, &lt;strong&gt;analytics&lt;/strong&gt;, and &lt;strong&gt;machine learning&lt;/strong&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;2. CNI Plugin Integration&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Chelsio T6 adapters are fully compatible with Kubernetes’ &lt;strong&gt;Container Networking Interface (CNI)&lt;/strong&gt; plugins, which manage pod networking across clusters. In the T6 testing environment, &lt;strong&gt;Flannel&lt;/strong&gt; and &lt;strong&gt;Multus&lt;/strong&gt; are used as CNI plugins. This demonstrates the seamless integration of T6 adapters into Kubernetes for managing Layer 3 IPv4 networking and multiple networks per pod.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The &lt;strong&gt;SR-IOV CNI plugin&lt;/strong&gt; and the &lt;strong&gt;SR-IOV Network Device Plugin&lt;/strong&gt; are used to attach Chelsio Virtual Functions (VFs) directly to pods. This integration allows Kubernetes administrators to effectively manage high-performance networking while maintaining flexibility in their network configurations. With these plugins, T6 adapters can deliver near-line-rate performance across multiple Kubernetes nodes, ensuring efficient communication between the pods.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;3. Protocol Flexibility&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Chelsio T6 adapters support hardware offloading for multiple networking protocols, such as &lt;strong&gt;iWARP&lt;/strong&gt;, &lt;strong&gt;NVMe/TCP&lt;/strong&gt;, and &lt;strong&gt;NVMe-oF&lt;/strong&gt; (NVMe over Fabrics). This flexibility makes the T6 adapters ideal for Kubernetes clusters with diverse networking requirements.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;NVMe/TCP&lt;/strong&gt; and &lt;strong&gt;NVMe-oF&lt;/strong&gt; provide high-performance data transfer capabilities for storage-intensive applications, making T6 adapters ideal for environments that demand quick and reliable access to storage resources. T6 adapters also support &lt;strong&gt;TLS/SSL&lt;/strong&gt; and &lt;strong&gt;IPsec&lt;/strong&gt; offloading, improving the security of data transfers while lowering CPU usage during encryption and decryption. These offloading features make T6 adapters beneficial in environments where secure and high-speed data transfers are essential.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;4. Use Case: High-Performance Workloads&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For workloads that require significant data throughput, such as &lt;strong&gt;AI&lt;/strong&gt; and &lt;strong&gt;machine learning&lt;/strong&gt; applications, Chelsio T6 adapters provide the necessary performance. During testing, T6 adapters achieved &lt;strong&gt;98 Gbps line-rate throughput&lt;/strong&gt; while utilizing only &lt;strong&gt;35% of CPU resources&lt;/strong&gt;. This leaves ample CPU headroom for additional container deployments, making T6 adapters ideal for real-time and data-driven Kubernetes environments.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In addition to improving network performance, the offloading capabilities of T6 adapters significantly reduce CPU utilization, enabling Kubernetes clusters to scale without requiring expensive CPU upgrades. This makes the T6 adapters an ideal solution for data centers handling high-throughput applications or seeking to consolidate networking, storage, and computing onto a unified platform.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Technical Walkthrough&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In the test environment described in the technical report, &lt;strong&gt;CRI-O&lt;/strong&gt; served as the container runtime, while &lt;strong&gt;Flannel&lt;/strong&gt; provided Layer 3 IPv4 networking between nodes. &lt;strong&gt;Multus&lt;/strong&gt; was used to configure multiple networks per pod, enabling more advanced network configurations. Chelsio T6 VFs were allocated to pods using the &lt;strong&gt;SR-IOV CNI plugin&lt;/strong&gt;, achieving near-line-rate performance across a 3-node Kubernetes cluster.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This setup illustrates how easily Kubernetes administrators can deploy T6 adapters in real-world environments, utilizing SR-IOV to enhance performance and efficiency.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Conclusion&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Chelsio T6 adapters provide cutting-edge networking solutions for Kubernetes, utilizing &lt;strong&gt;SR-IOV&lt;/strong&gt; and &lt;strong&gt;CNI plugins&lt;/strong&gt;, such as &lt;strong&gt;Flannel&lt;/strong&gt; and &lt;strong&gt;Multus&lt;/strong&gt;, to achieve high-throughput and low-latency connectivity. An integration of protocol offloading and acceleration, including &lt;strong&gt;NVMe/TCP&lt;/strong&gt;, &lt;strong&gt;NVMe-oF&lt;/strong&gt;, &lt;strong&gt;iWARP&lt;/strong&gt;, &lt;strong&gt;TLS/SSL&lt;/strong&gt;, and &lt;strong&gt;IPsec&lt;/strong&gt;, makes T6 adapters an excellent choice for Kubernetes environments running high-performance and data-intensive applications.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Chelsio T6 adapters, with their seamless scalability and support for multiple networking protocols, empower Kubernetes clusters to effortlessly manage modern workloads.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Call to Action&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To learn more, explore the full technical report on T6 Kubernetes performance &lt;a href=&#34;https://www.chelsio.com/wp-content/uploads/resources/t6-kubernetes-linux.pdf&#34;&gt;here&lt;/a&gt; or visit the &lt;a href=&#34;https://www.chelsio.com/&#34;&gt;Chelsio Communications website&lt;/a&gt; to discover how T6 adapters can enhance your Kubernetes deployments.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;Chelsio Communications 的会员帖子&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;简介&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;随着 Kubernetes 不断变革云原生基础设施，高性能网络对于维持容器化应用程序的无缝操作变得至关重要。 Chelsio T6 统一线路适配器提供先进的网络功能，可以满足现代 Kubernetes 部署的需求，特别是处理数据密集型工作负载。凭借&lt;strong&gt;SR-IOV&lt;/strong&gt;、硬件卸载以及&lt;strong&gt;iWARP&lt;/strong&gt;、&lt;strong&gt;NVMe/TCP&lt;/strong&gt;和&lt;strong&gt;NVMe等通用协议加速等功能， &lt;/strong&gt;，T6 适配器允许 Kubernetes 集群高效扩展，同时确保最佳性能。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在这篇博文中，我们探讨了使用 &lt;strong&gt;CNI 插件&lt;/strong&gt;将 Chelsio T6 适配器集成到 Kubernetes 环境中，重点介绍了它们的灵活性如何改进各种应用程序中的网络。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;适用于 Kubernetes 的 T6 适配器的主要优势&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;1.通过 SR-IOV 提高性能&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Chelsio T6 适配器支持&lt;strong&gt;单根 I/O 虚拟化 (SR-IOV)&lt;/strong&gt;，允许向 Kubernetes Pod 公开多个&lt;strong&gt;虚拟功能 (VF)&lt;/strong&gt;，并启用直接 I /O 访问网络硬件。这提供了低延迟、高吞吐量的网络，这对于处理关键工作负载的 Kubernetes 集群至关重要。通过将网络任务卸载到硬件，T6 适配器减少了主机 CPU 上的负载，从而使容器化应用程序可以使用更多资源，从而增强了它们的性能，特别是在管理大量数据时。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;借助 SR-IOV，T6 适配器使 Kubernetes 部署能够在不影响性能的情况下高效扩展，使其成为要求高性能工作负载（例如&lt;strong&gt;AI&lt;/strong&gt;、&lt;strong&gt;分析&lt;/strong&gt;）的理想选择和&lt;strong&gt;机器学习&lt;/strong&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;2. CNI 插件集成&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Chelsio T6 适配器与 Kubernetes 的&lt;strong&gt;容器网络接口 (CNI)&lt;/strong&gt; 插件完全兼容，该插件可跨集群管理 Pod 网络。在T6测试环境中，使用&lt;strong&gt;Flannel&lt;/strong&gt;和&lt;strong&gt;Multus&lt;/strong&gt;作为CNI插件。这演示了 T6 适配器与 Kubernetes 的无缝集成，用于管理第 3 层 IPv4 网络和每个 Pod 的多个网络。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;SR-IOV CNI 插件&lt;/strong&gt;和&lt;strong&gt;SR-IOV 网络设备插件&lt;/strong&gt;用于将 Chelsio 虚拟功能 (VF) 直接附加到 Pod。这种集成使 Kubernetes 管理员能够有效管理高性能网络，同时保持网络配置的灵活性s。借助这些插件，T6 适配器可以跨多个 Kubernetes 节点提供接近线速的性能，确保 Pod 之间的高效通信。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;3.协议灵活性&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Chelsio T6 适配器支持多种网络协议的硬件卸载，例如 &lt;strong&gt;iWARP&lt;/strong&gt;、&lt;strong&gt;NVMe/TCP&lt;/strong&gt; 和 &lt;strong&gt;NVMe-oF&lt;/strong&gt;（NVMe over面料）。这种灵活性使得 T6 适配器非常适合具有不同网络需求的 Kubernetes 集群。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;NVMe/TCP&lt;/strong&gt; 和 &lt;strong&gt;NVMe-oF&lt;/strong&gt; 为存储密集型应用提供高性能数据传输功能，使 T6 适配器成为需要快速可靠访问数据的环境的理想选择存储资源。 T6 适配器还支持 &lt;strong&gt;TLS/SSL&lt;/strong&gt; 和 &lt;strong&gt;IPsec&lt;/strong&gt; 卸载，提高数据传输的安全性，同时降低加密和解密过程中的 CPU 使用率。这些卸载功能使 T6 适配器在安全和高速数据传输至关重要的环境中受益。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;4.使用案例：高性能工作负载&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;对于需要大量数据吞吐量的工作负载（例如&lt;strong&gt;AI&lt;/strong&gt;和&lt;strong&gt;机器学习&lt;/strong&gt;应用程序），Chelsio T6 适配器可提供必要的性能。在测试期间，T6 适配器实现了&lt;strong&gt;98 Gbps 线速吞吐量&lt;/strong&gt;，同时仅利用了&lt;strong&gt;35% 的CPU 资源&lt;/strong&gt;。这为额外的容器部署留下了充足的 CPU 空间，使 T6 适配器成为实时和数据驱动的 Kubernetes 环境的理想选择。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;除了提高网络性能之外，T6 适配器的卸载功能还可以显着降低 CPU 利用率，使 Kubernetes 集群能够进行扩展，而无需进行昂贵的 CPU 升级。这使得 T6 适配器成为处理高吞吐量应用程序或寻求将网络、存储和计算整合到统一平台上的数据中心的理想解决方案。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;技术演练&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在技术报告中描述的测试环境中，&lt;strong&gt;CRI-O&lt;/strong&gt;充当容器运行时，而&lt;strong&gt;Flannel&lt;/strong&gt;提供节点之间的第3层IPv4网络。 &lt;strong&gt;Multus&lt;/strong&gt; 用于为每个 Pod 配置多个网络，从而实现更高级的网络配置。使用 &lt;strong&gt;SR-IOV CNI 插件&lt;/strong&gt;将 Chelsio T6 VF 分配给 Pod，在 3 节点 Kubernetes 集群中实现近线速性能。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;此设置展示了 Kubernetes 管理员如何轻松地在现实环境中部署 T6 适配器，利用 SR-IOV 来提高性能和效率。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr class=&#34;wp-块-分隔符有-alpha-通道-不透明度&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;结论&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Chelsio T6 适配器利用 &lt;strong&gt;SR-IOV&lt;/strong&gt; 和 &lt;strong&gt;CNI 插件&lt;/strong&gt;（例如 &lt;strong&gt;Flannel&lt;/strong&gt; 和 &lt;strong&gt; &gt;Multus&lt;/strong&gt;，实现高吞吐量和低延迟连接。协议卸载和加速的集成，包括&lt;strong&gt;NVMe/TCP&lt;/strong&gt;、&lt;strong&gt;NVMe-oF&lt;/strong&gt;、&lt;strong&gt;iWARP&lt;/strong&gt;、&lt;strong&gt;TLS/SSL&lt;/strong&gt;和 &lt;strong&gt;IPsec&lt;/strong&gt;，使 T6 适配器成为运行高性能和数据密集型应用程序的 Kubernetes 环境的绝佳选择。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Chelsio T6 适配器凭借其无缝可扩展性和对多种网络协议的支持，使 Kubernetes 集群能够轻松管理现代工作负载。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;号召性用语&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;要了解更多信息，请在&lt;a href=&#34;https://www.chelsio.com/wp-content/uploads/resources/t6-kubernetes-linux.pdf&#34;&gt;此处&lt;查看有关 T6 Kubernetes 性能的完整技术报告&lt; /a&gt; 或访问 &lt;a href=&#34;https://www.chelsio.com/&#34;&gt;Chelsio Communications 网站&lt;/a&gt;，了解 T6 适配器如何增强您的 Kubernetes 部署。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Mon, 07 Oct 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Engineering leaders continue focus on TestOps – operational strategies】工程领导者继续关注 TestOps——运营策略</title>
      <link>https://www.cncf.io/blog/2024/10/04/engineering-leaders-continue-focus-on-testops-operational-strategies/</link>
      <description>【&lt;p&gt;&lt;em&gt;Community post by &lt;a href=&#34;https://www.linkedin.com/in/s-jan/&#34;&gt;Saqib Jan&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As technologies become more advanced year on year, the complexity of software testing increases, too.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;When building a testing strategy, companies typically map their operations into three segments: the people, the process, and the technology involved. And the hardest challenges companies face are often around the technology itself, like dealing with complex test environments that have various frameworks and APIs at different levels.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;It’s exceedingly important to create a realistic test environment with the right APIs to test how everything works together from start to finish. But managing a large testing infrastructure is a major hurdle for all companies – startups and enterprises alike.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This is because every month dozens of mobile devices are launched by various vendors, and there’s also the launch of operating systems. And so, it means that your potential customers could land on your website or app from anywhere, and buying all the devices for testing with all the different operating systems is not economical which makes testing inordinately hard.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;But engineering leaders see in TestOps an opportunity to deliver high-quality software at an accelerated pace. “By taking a TestOps approach to software testing, organizations can determine the most cost-effective strategies in the long term—removing blockers, empowering development teams to deliver better features and apps, and enabling cross-functional conversations about high availability testing practices,” says Mayank Bhola CTO of a software testing platform&lt;a href=&#34;https://www.lambdatest.com/&#34;&gt; LambdaTest&lt;/a&gt;.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Tackling Complexity With TestOps&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;You want a testing environment that is not limited by the devices, operating system, or programming language, and can quickly allow you to create real-time machines with the exact testing environment you need. But building and maintaining this kind of infrastructure requires significant resources and bandwidth.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;You could build your own in-house device lab, but the reality is that if you buy ten devices today, a few months later, ten more will hit the market. You’ll then need to buy and maintain these new devices, along with your older ones. And even then your ambitious IT requirements will inevitably have to grapple with scaling problems, let alone changes to tooling and processes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Shay Elmualem, Principal Tech Lead at&lt;a href=&#34;https://www.legitsecurity.com/&#34;&gt; Legit Security&lt;/a&gt;, shares, “To prioritize test coverage, we first focus on the most commonly used browsers among our users—typically Chrome and Firefox. We use a matrix setup in GitHub Actions to run our tests across these different browsers simultaneously, which helps us cover multiple platforms in parallel without sacrificing speed.” This systematic approach helps ensure consistent cross-browser compatibility and is by practice crucial for user experience.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Because every company with a growing product portfolio might find it increasingly difficult to keep up with the latest devices and operating systems while ensuring consistent testing across different teams. It’s very exhaustive and when you try to automate at scale, things usually fail.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Bhola, in our email conversation, discussed how LambdaTest empowers software testing with highly available instant infrastructure by dynamically updating testing capabilities based on real-time metrics and usage patterns. “We consistently monitor device, platform, browser, and version usage in production through a monitoring tool over a rolling window of 30 days. And based on this data, we dynamically update our testing capabilities to align with customer needs. This involves prioritizing test cases that target the most widely used configurations and eliminating outdated device configurations that are no longer in demand.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This ensures that testers have access to the most relevant testing environments. Bhola further enthused, “We also analyze the usage patterns of commands to identify the most frequently executed commands by customers and ensure that our test suite includes relevant test cases to cover these scenarios comprehensively.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;You Don’t Need To Test Everything!&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To ensure testing produces high availability and high user satisfaction, targeted testing and leveraging customer telemetry are growing trends for achieving sustainable app performance. It’s not about testing everything, but instead focusing on the areas that often have the most significant impact according to Jeff Friedman, Director of Engineering at&lt;a href=&#34;https://rad.security/&#34;&gt; RAD Security&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;By focusing on the most critical areas of the application, teams can optimize their testing efforts and ensure that the highest-value features are delivered efficiently. “We can maintain high velocity in the dev environment with targeted tests, to ensure feature functionality, while relying on more stable, higher-level tests in the CI and pre-production environments to ensure that system-level functionality isn’t impacted by code changes. We use customer telemetry and the Pareto Principle (80-20 rule) to focus development and testing efforts on the highest-payoff configurations, using CI compatibility matrix testing to guide fast-follow compatibility fixes,” Friedman elaborated in an email interview.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“Our CI environment can test across multiple cloud and Kubernetes configurations for backend services, and different browser types and form factors for the frontend,” Friedman explained. “We standardize our testing process with uniform open source telemetry tooling and testing platforms to manage a standard set of CI checks as well.” This helps ensure a high quality level across the board, as well as a high level of consistency across applications.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Prioritizing environments (devices, platforms, browsers) to focus on has remained unchanged for decades. “This is an area where I see a missed opportunity,” says&lt;a href=&#34;https://www.linkedin.com/in/kohsukekawaguchi&#34;&gt; Kohsuke Kawaguchi&lt;/a&gt;, famous for creating Jenkins, the open-source automation server. “The abundance of data,” he exposits, “combined with machine learning, should enable us to make much more intelligent, fine-grained decisions about which tests on which environments are worthwhile.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“Infrastructure as code, device clouds, and containers are great—until they’re not.&amp;nbsp; These approaches often scale testing without improving efficiency. In other words, you’re just burning money,” Kawaguchi pointed out in an email interview. “To truly enhance efficiency, teams need to do more with the same budget. Focus on selecting tests that matter and use AI to screen test failures. You can spend 10 times the money to run 10 times more tests, but if the people processing the results can’t handle 10 times the input, it’s not effective.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;TestOps is the Way Forward to Enhance Quality with Speed&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Everyone wants a highly available testing environment. Speed is critical, not just for rapid development and efficient deployment, but also for testing. Realistically, speed can be both the solution and the problem when developing higher-quality software. So, you need to make sure you’re not chasing speed and exhausting resources to the point where you unintentionally compromise on quality.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Matthew Jones, a distinguished engineer and Chief Ansible Architect at&lt;a href=&#34;https://www.redhat.com/en&#34;&gt; Red Hat&lt;/a&gt;, shares his experience in managing software delivery. “Because of the nature of how we deliver software, we work really hard to control our requirements and dependencies so that we can limit our test matrix. We specifically normalize all of our deployment types so that they look and act the same no matter where we’re deploying them.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;By emphasizing the need to control requirements, dependencies, and deployment types, Jones underscores how a streamlined approach can significantly reduce the complexity of the testing process. “This simplification,” he affirms, “allows organizations to trust their layered testing with fewer artifacts, leading to faster development and deployment cycles.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;TestOps is the most economical and best way to effectively productionize testing. “It is emerging as a critical requirement in cross-functional teams because it offers businesses an efficient way to manage testing and operations throughout their software development life cycle,”&lt;a href=&#34;https://www.linkedin.com/in/mayankbhola&#34;&gt; Bhola&lt;/a&gt; remarks. “You can solve for managing infrastructure complexities while keeping up with evolving technologies to better meet performance expectations and offer more value to meet complex user needs.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Most interestingly, to this end, more businesses today are adopting modern TestOps methodologies and leveraging the benefits of cloud-based testing platforms that provide instant high-performance infrastructure to ensure consistency across multiple test environments—staging, QA, and production—and accelerate the delivery of high-quality, reliable applications with more efficient release cycles.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Author:&lt;/strong&gt; Saqib Jan&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Email: &lt;/strong&gt;sakimjan8@gmail.com&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;LinkedIn:&lt;/strong&gt; &lt;a href=&#34;https://linkedin.com/in/s-jan&#34;&gt;&lt;strong&gt;https://linkedin.com/in/s-jan&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;BIO: &lt;/strong&gt;Saqib Jan is a technology analyst with experience in application development, FinOps, and cloud technologies.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;&lt;a href=&#34;https://www.linkedin.com/in/s-jan/&#34;&gt;Saqib Jan&lt;/a&gt;&lt;/em&gt;的社区帖子&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;随着技术逐年变得更加先进，软件测试的复杂性也随之增加。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在制定测试策略时，公司通常将其运营分为三个部分：人员、流程和所涉及的技术。公司面临的最艰巨的挑战通常围绕技术本身，例如处理具有不同级别的各种框架和 API 的复杂测试环境。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;使用正确的 API 创建一个真实的测试环境来测试一切从头到尾如何协同工作非常重要。但管理大型测试基础设施是所有公司（初创公司和企业）的主要障碍。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这是因为各个供应商每个月都会推出数十种移动设备，同时还会推出操作系统。因此，这意味着您的潜在客户可以从任何地方登陆您的网站或应用程序，并且购买所有设备来测试所有不同的操作系统并不经济，这使得测试变得异常困难。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;但工程领导者在 TestOps 中看到了加速交付高质量软件的机会。 “通过采用 TestOps 方法进行软件测试，组织可以确定长期来看最具成本效益的策略——消除障碍，使开发团队能够提供更好的功能和应用程序，并实现有关高可用性测试实践的跨职能对话。”软件测试平台 &lt;a href=&#34;https://www.lambdatest.com/&#34;&gt;LambdaTest&lt;/a&gt; 的首席技术官 Mayank Bhola 说道。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;通过 TestOps 解决复杂性&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;您想要一个不受设备、操作系统或编程语言限制的测试环境，并且可以让您快速创建具有所需测试环境的实时机器。但构建和维护此类基础设施需要大量资源和带宽。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;您可以建立自己的内部设备实验室，但现实是，如果您今天购买十台设备，几个月后，还会有另外十台设备投放市场。然后，您需要购买并维护这些新设备以及旧设备。即使如此，您雄心勃勃的 IT 要求也将不可避免地必须解决扩展问题，更不用说工具和流程的更改了。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.legitsecurity.com/&#34;&gt;Legit Security&lt;/a&gt; 首席技术主管 Shay Elmualem 表示：“为了优先考虑测试覆盖率，我们首先关注最常用的我们用户使用的浏览器——通常是 Chrome 和 Firefox。我们使用 GitHub Actions 中的矩阵设置在这些不同的浏览器上同时运行测试，这有助于我们并行覆盖多个平台，而不会牺牲速度。”这种系统性的批准ach 有助于确保一致的跨浏览器兼容性，并且实际上对于用户体验至关重要。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;因为每家产品组合不断增长的公司可能会发现越来越难以跟上最新的设备和操作系统，同时确保不同团队之间的测试保持一致。它非常详尽，当您尝试大规模自动化时，事情通常会失败。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Bhola 在我们的电子邮件对话中讨论了 LambdaTest 如何通过基于实时指标和使用模式动态更新测试功能，利用高度可用的即时基础架构来支持软件测试。 “我们通过监控工具在 30 天的滚动窗口内持续监控生产中的设备、平台、浏览器和版本使用情况。根据这些数据，我们动态更新我们的测试能力，以满足客户需求。这涉及优先考虑针对最广泛使用的配置的测试用例，并消除不再需要的过时设备配置。”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这确保测试人员能够访问最相关的测试环境。 Bhola 进一步说道：“我们还分析命令的使用模式，以识别客户最常执行的命令，并确保我们的测试套件包含相关的测试用例，以全面覆盖这些场景。”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;您不需要测试所有内容！&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;为了确保测试产生高可用性和高用户满意度，有针对性的测试和利用客户遥测是实现可持续应用性能的增长趋势。 &lt;a href=&#34;https://rad.security/&#34;&gt;RAD Security&lt;/a&gt; 工程总监 Jeff Friedman 表示，这并不是要测试所有内容，而是要重点关注通常具有最重大影响的领域。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;通过专注于应用程序最关键的领域，团队可以优化他们的测试工作并确保高效地交付最高价值的功能。 “我们可以通过有针对性的测试在开发环境中保持高速，以确保功能功能，同时依靠 CI 和预生产环境中更稳定、更高级别的测试来确保系统级功能不受代码影响变化。我们使用客户遥测和 Pareto 原则（80-20 规则）将开发和测试工作集中在最高回报的配置上，使用 CI 兼容性矩阵测试来指导快速跟踪兼容性修复，”Friedman 在电子邮件采访中详细阐述。 p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“我们的 CI 环境可以测试后端服务的多个云和 Kubernetes 配置，以及前端的不同浏览器类型和外形规格，”Friedman 解释道。 “我们使用统一的开源遥测工具和测试平台来标准化我们的测试流程，以管理一组标准的 CI 检查。”这有助于确保高全面的质量水平，以及跨应用程序的高度一致性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;几十年来，优先关注的环境（设备、平台、浏览器）一直没有改变。 “我认为这是一个错失良机的领域，”&lt;a href=&#34;https://www.linkedin.com/in/kohsukekawaguchi&#34;&gt;Kohsuke Kawaguchi&lt;/a&gt; 说道，他因创建开源软件 Jenkins 而闻名自动化服务器。他解释说：“丰富的数据与机器学习相结合，应该使我们能够做出更智能、更精细的决策，决定在哪些环境上进行哪些测试值得。”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“基础设施即代码、设备云和容器都很棒——直到它们不是。  这些方法通常会扩展测试规模而不会提高效率。换句话说，你只是在烧钱。”川口在电子邮件采访中指出。 “要真正提高效率，团队需要用相同的预算做更多的事情。专注于选择重要的测试，并使用人工智能来筛选测试失败。你可以花 10 倍的钱来运行 10 倍的测试，但如果处理结果的人无法处理 10 倍的输入，那就没有效果。”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;TestOps 是快速提高质量的出路&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;每个人都想要一个高度可用的测试环境。速度至关重要，不仅对于快速开发和高效部署，而且对于测试也至关重要。实际上，在开发更高质量的软件时，速度既可以是解决方案，也可以是问题。因此，您需要确保您不会为了追求速度而耗尽资源，以至于无意中牺牲了质量。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Red Hat 的杰出工程师兼首席 Ansible 架构师 Matthew Jones 分享了他在管理软件交付方面的经验。 “由于我们交付软件方式的本质，我们非常努力地控制我们的需求和依赖关系，以便我们可以限制我们的测试矩阵。我们特别规范了所有部署类型，以便无论我们将它们部署在何处，它们的外观和行为都相同。”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;通过强调控制需求、依赖关系和部署类型的需要，Jones 强调了简化的方法如何显着降低测试过程的复杂性。 “这种简化，”他肯定道，“让组织可以用更少的工件来信任他们的分层测试，从而加快开发和部署周期。”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;TestOps 是有效生产测试的最经济、最好的方法。 “它正在成为跨职能团队的一项关键要求，因为它为企业提供了一种在整个软件开发生命周期中管理测试和运营的有效方法，”&lt;a href=&#34;https://www.linkedin.com/in/ mayankbhola&#34;&gt;Bhola&lt;/a&gt; 评论。 “您可以解决管理基础设施复杂性的问题，同时跟上不断发展的技术可以更好地满足性能期望并提供更多价值来满足复杂的用户需求。”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;最有趣的是，为此，如今越来越多的企业正在采用现代 TestOps 方法，并利用基于云的测试平台的优势，这些平台提供即时高性能基础架构，以确保跨多个测试环境（分阶段、QA 和生产）的一致性并通过更高效的发布周期加速高质量、可靠的应用程序的交付。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;作者：&lt;/strong&gt; Saqib Jan&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;电子邮件：&lt;/strong&gt;sakimjan8@gmail.com&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;LinkedIn：&lt;/strong&gt; &lt;a href=&#34;https://linkedin.com/in/s-jan&#34;&gt;&lt;strong&gt;https://linkedin.com/in/s-jan&lt;/强&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;BIO：&lt;/strong&gt;Saqib Jan 是一位技术分析师，在应用程序开发、FinOps 和云技术方面拥有丰富的经验。&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Thu, 03 Oct 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Benefits of Kubernetes and Cloud Native Security Associate (KCSA) Certification】Kubernetes 和云原生安全助理 (KCSA) 认证的优势</title>
      <link>https://www.cncf.io/blog/2024/10/03/benefits-of-kubernetes-and-cloud-native-security-associate-kcsa-certification/</link>
      <description>【&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;em&gt;From a discussion with &lt;a href=&#34;https://www.linkedin.com/in/andr3wmartin/&#34;&gt;Andrew Martin,&lt;/a&gt; CEO and Co-Founder, ControlPlane and &lt;a href=&#34;https://www.linkedin.com/in/ashley-ward-jp/&#34;&gt;Ashley Ward&lt;/a&gt;, CTO, ControlPlane&lt;/em&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Earning the &lt;a href=&#34;https://www.cncf.io/training/certification/kcsa/&#34;&gt;Kubernetes and Cloud Native Security Associate (KCSA)&lt;/a&gt; certification is valuable for both organizations and IT professionals. This certification signifies a strong understanding of basic security configurations for Kubernetes clusters, crucial for embedding security across all roles in an organization. KCSA Certification holders not only increase their value to current and future employers but also enhance their problem-solving skills in security incidents and will have increased confidence in cloud native security discussions. This certification ensures a thorough grasp of best practices, significantly improving an organization’s security posture and fostering a culture of continuous learning and development in a rapidly evolving tech landscape.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Security is in everyone’s interests across every organization and obtaining a security-focused certification like the soon-to-be-updated &lt;a href=&#34;https://training.linuxfoundation.org/cks-program-changes/&#34;&gt;Certified Kubernetes Security Specialist (CKS)&lt;/a&gt;, the&amp;nbsp; Kubernetes and Cloud Native Security Associate (KCSA) certification is increasingly valuable. This certification confirms a person’s deep understanding of basic security configuration of clusters, and ensures they have the knowledge to build security into their role, understanding what and why there are security configurations in place, regardless of their role.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Key benefits of having a Kubernetes security certification&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;For Organizations&lt;/strong&gt;: Security is not an optional component of any solution and having people with the relevant certifications clearly demonstrates that they have people delivering the best in class secure solutions. Some of the key benefits to an organization are:&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Security will be embedded from the start&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Certificate holders have the best practices and standards at the core of what they do and can help others&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Your investment in people helps with retainment and can then also help with recruitment&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;For Individuals:&lt;/strong&gt; Earning the certification demonstrates your commitment to continued learning and development.&amp;nbsp; You become more valuable to your current employer and future ones by being able to show how security is a core part of your work.&amp;nbsp; Some key benefits then are:&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Increase your value to employers&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Prepares you to advance to additional professional certifications&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Give you the confidence to participate further in cloud native security discussions and research&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Overall, security is an essential part of all businesses and as more and more organizations embrace cloud native computing it becomes necessary to increase security understanding to all roles. Kubernetes security certification demonstrates that you are continuously learning and developing – which in itself is a valuable trait for employers.&amp;nbsp; It shows that you understand the seriousness of security in cloud native and highlights your diligence to employers.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Running applications in a safe, scalable, and efficient manner is really difficult.&amp;nbsp; Managing hardware failures, deployments, networking, and all the other components of modern software can be tricky.&amp;nbsp; Kubernetes provides a means for more and more people to deploy applications in a simple way, knowing that Kubernetes can manage complexity.&amp;nbsp; However, the complexity doesn’t go away!&amp;nbsp; It is just handled by the platform or orchestrator.&amp;nbsp; It’s therefore essential to have an understanding of the security implications and best practices, and that demands specialized knowledge and awareness of containers, data, and the types of threats that you might encounter and that’s why it’s important to have specialized knowledge in Kubernetes security&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes security certification demonstrates that the holder has gone through comprehensive training on the best practices and tools available to help mitigate risks in a containerized environment and being certified in Kubernetes security differentiates you from other IT professionals because organizations and individuals in the industry recognise that Kubernetes environments need specialized knowledge.&amp;nbsp; Being certified in Kubernetes security differentiates you by calling out your in-depth knowledge of the specialized threats on that platform.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Today’s tech landscape is in a state of constant change.&amp;nbsp; From new ways of working and technologies to novel threats and risks.&amp;nbsp; Continuous learning is essential if you want to remain relevant in the cloud native security space.&amp;nbsp; Certification in Kubernetes security demonstrates your commitment to keeping your skills relevant in this fast paced environment.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;But Kubernetes security certification is not just a “checkbox” exercise, the training and exposure to the tools and techniques needed to secure a Kubernetes environment are varied. The KCSA certification ensures that holders have covered all the areas of risk rather than one or two specific areas.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;KCSA certification is valuable for the DevOps teams specifically as certification will enable the team&amp;nbsp; to communicate with each other using a common understanding built on their shared learnings through certification.&amp;nbsp; Where only some members of the team can be certified, they can then use this learning to enhance and expand their colleagues’ security knowledge.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Learning the first principles of security in a Kubernetes cluster means that real-world security challenges can be examined through a knowledgeable lens.&amp;nbsp; The certification makes you an effective member of a team being able to contribute understanding and best practices to any challenges.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;There is a large demand for individuals with security knowledge in the cloud native space.&amp;nbsp; Regardless of your area of specialization within IT your certification is a building block that could take you further into operations, secure development, DevSecOps, or even into security teams.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Understanding the components and risks in each area of Kubernetes is essential for effective problem-solving in security incidents. &amp;nbsp; The certification brings together your organizational knowledge, your application knowledge, your platform knowledge, and your security knowledge, allowing you to effectively understand the stack and to troubleshoot, with a suitably experienced team, a security incident.&amp;nbsp; As much as your certification will make you a vital team member, it is essential to remember that security incidents must be investigated in a specific way – especially when law enforcement may need to be involved.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Additionally, Kubernetes security certification is vital for working in multi-cloud environments. As Kubernetes becomes the standard for multi-cloud deployments, having this certification proves an individual’s capability in managing security across hybrid, private, or multi-cloud Kubernetes environments. Kubernetes security certification isn’t specific to cloud environments (Cloud Native doesn’t mean it has to run in the cloud!)&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Beyond technical skills, the certification fosters a deeper engagement with the cloud-native community. It encourages and gives you the ability to have deeper discussions on critical topics, leading to further collaboration and innovation within the industry. This involvement not only enhances personal growth but also contributes positively to the broader cloud-native ecosystem, driving progress and setting new standards in security practice and may inspire you to do more work with the CNCF.&amp;nbsp; That can only lead to growth in the community and that’s something that can only be good for the entire industry!&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes and Cloud Native Security Associate certification is a powerful asset for IT professionals. It enhances career prospects, bolsters problem-solving skills, and ensures comprehensive security knowledge in managing cloud-native applications. For organizations, it signifies a commitment to security excellence, aiding in recruitment, retention, and delivering secure solutions. This certification is essential for staying relevant in the dynamic tech landscape and contributing to a stronger, more secure future in cloud-native computing.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;em&gt;摘自与 &lt;a href=&#34;https://www.linkedin.com/in/andr3wmartin/&#34;&gt;Andrew Martin&lt;/a&gt; 首席执行官兼联合创始人的讨论-ControlPlane 创始人和 &lt;a href=&#34;https://www.linkedin.com/in/ashley-ward-jp/&#34;&gt;Ashley Ward&lt;/a&gt;、ControlPlane 首席技术官&lt;/em&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;获得 &lt;a href=&#34;https://www.cncf.io/training/certification/kcsa/&#34;&gt;Kubernetes 和云原生安全助理 (KCSA)&lt;/a&gt; 认证对于组织和 IT 专业人员都很有价值。该认证标志着对 Kubernetes 集群基本安全配置的深刻理解，这对于在组织中的所有角色中嵌入安全性至关重要。 KCSA 认证持有者不仅可以增加他们对当前和未来雇主的价值，还可以增强他们在安全事件中解决问题的能力，并对云原生安全讨论增强信心。该认证可确保全面掌握最佳实践，显着改善组织的安全状况，并在快速发展的技术环境中培养持续学习和发展的文化。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;安全符合每个组织中每个人的利益，并获得以安全为中心的认证，例如即将更新的&lt;a href=&#34;https://training.linuxfoundation.org/cks-program-changes/&#34;&gt;认证 Kubernetes 安全专家 (CKS)&lt;/a&gt;、Kubernetes 和云原生安全助理 (KCSA) 认证的价值越来越高。该认证证实了一个人对集群基本安全配置的深刻理解，并确保他们拥有将安全构建到其角色中的知识，了解安全配置的内容和原因，无论其角色如何。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;拥有 Kubernetes 安全认证的主要优势&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;对于组织&lt;/strong&gt;：安全性不是任何解决方案的可选组成部分，拥有相关认证的人员清楚地表明他们拥有提供一流安全解决方案的人员。对组织的一些主要好处是：&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;从一开始就嵌入安全性&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;证书持有者的工作以最佳实践和标准为核心，可以帮助他人&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;您对人员的投资有助于留住人才，进而有助于招聘&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;对于个人：&lt;/strong&gt;获得认证表明您致力于持续学习和发展。  通过展示安全性如何成为您工作的核心部分，您对当前和未来的雇主变得更有价值。  一些主要好处是：&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;提高您对雇主的价值&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;帮助您做好获得其他专业认证的准备&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;让您有信心进一步参与云原生安全讨论问题与研究&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;总体而言，安全性是所有企业的重要组成部分，随着越来越多的组织采用云原生计算，有必要提高对所有角色的安全性理解。 Kubernetes 安全认证表明您正在不断学习和发展——这本身就是雇主的一个宝贵特质。  这表明您了解云原生安全的严重性，并向雇主凸显了您的勤奋。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;以安全、可扩展且高效的方式运行应用程序确实很困难。  管理硬件故障、部署、网络和现代软件的所有其他组件可能很棘手。  Kubernetes 为越来越多的人提供了一种以简单的方式部署应用程序的方法，因为他们知道 Kubernetes 可以管理复杂性。  然而，复杂性并没有消失！  它仅由平台或编排器处理。  因此，了解安全影响和最佳实践至关重要，这需要对容器、数据以及可能遇到的威胁类型具有专业知识和认识，这就是为什么拥有 Kubernetes 安全方面的专业知识很重要&lt;/ p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes 安全认证表明持有者已经接受过有关最佳实践和工具的全面培训，可帮助降低容器化环境中的风险，并且获得 Kubernetes 安全认证将使您与其他 IT 专业人员区分开来，因为行业中的组织和个人认识到Kubernetes 环境需要专业知识。  获得 Kubernetes 安全认证将使您脱颖而出，因为您对该平台上的专门威胁有深入的了解。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;当今的科技格局正处于不断变化的状态。  从新的工作方式和技术到新的威胁和风险。  如果您想在云原生安全领域保持领先地位，持续学习至关重要。  Kubernetes 安全认证表明您致力于在这个快节奏的环境中保持技能的相关性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;但是 Kubernetes 安全认证不仅仅是一个“复选框”练习，保护 Kubernetes 环境所需的工具和技术的培训和接触是多种多样的。 KCSA 认证可确保持有者涵盖所有风险领域，而不是一两个特定领域。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;KCSA 认证对于 DevOps 团队非常有价值，特别是因为认证将使团队能够通过认证建立在共享学习基础上的共识，从而相互沟通。  如果只有部分团队成员可以获得认证，他们就可以利用这次学习来增强和扩展同事的安全知识。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;学习基本原则Kubernetes 集群中的安全性意味着可以通过知识渊博的视角来检查现实世界的安全挑战。  该认证使您成为团队的有效成员，能够为任何挑战贡献理解和最佳实践。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;云原生领域对具有安全知识的个人的需求很大。  无论您的 IT 专业领域是什么，您的认证都是一个构建模块，可以带您进一步进入运营、安全开发、DevSecOps，甚至进入安全团队。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;了解 Kubernetes 每个领域的组件和风险对于有效解决安全事件中的问题至关重要。   该认证汇集了您的组织知识、应用程序知识、平台知识和安全知识，使您能够有效地了解堆栈并与经验丰富的团队一起解决安全事件。  尽管您的认证将使您成为重要的团队成员，但必须记住，必须以特定方式调查安全事件 - 特别是当可能需要涉及执法部门时。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;此外，Kubernetes 安全认证对于在多云环境中工作至关重要。随着 Kubernetes 成为多云部署的标准，拥有此认证证明了个人跨混合、私有或多云 Kubernetes 环境管理安全性的能力。 Kubernetes 安全认证并非特定于云环境（云原生并不意味着它必须在云端运行！）&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;除了技术技能之外，该认证还促进了与云原生社区的更深入的参与。它鼓励并让您能够就关键主题进行更深入的讨论，从而促进行业内的进一步合作和创新。这种参与不仅可以促进个人成长，还可以为更广泛的云原生生态系统做出积极贡献，推动进步并在安全实践中制定新标准，并可能会激励您与 CNCF 开展更多工作。  这只会带来社区的增长，这只会对整个行业有利！&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes 和云原生安全助理认证对于 IT 专业人员来说是一笔强大的资产。它可以增强职业前景，增强解决问题的技能，并确保在管理云原生应用程序方面拥有全面的安全知识。对于组织而言，它意味着对卓越安全的承诺，有助于招聘、保留和提供安全解决方案。此认证对于在动态技术领域保持领先地位并为云原生计算领域的更强大、更安全的未来做出贡献至关重要。&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; 类=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Wed, 02 Oct 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Volcano v1.10.0 officially released, 10 features to improve the unified scheduling and fine-grained resource management capabilities】Volcano v1.10.0正式发布，10大特性提升统一调度和细粒度资源管理能力</title>
      <link>https://www.cncf.io/blog/2024/10/04/volcano-v1-10-0-officially-released-10-features-to-improve-the-unified-scheduling-and-fine-grained-resource-management-capabilities/</link>
      <description>【&lt;p&gt;&lt;em&gt;Project post by Volcano maintainers &lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;On September 19, 2024, UTC+8, Volcano Community officially released version 1.10.0, introducing the following new features:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Support Queue Priority Scheduling Strategy&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Enable Fine-Grained GPU Resource Sharing and Reclaim&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Introduce Pod Scheduling Readiness Support&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Add Sidecar Container Scheduling Capabilities&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Enhance Vcctl Command Line Tool&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Ensure Compatibility with Kubernetes v1.30&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Strengthen Volcano Security Measures&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Optimize Volcano for Large-Scale Performance&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Improve GPU Monitoring Function&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Optimize Helm Chart Installation And Upgrade Processes&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Support Queue Priority Scheduling Strategy&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In traditional big data processing scenarios, users can directly set queue priorities to control the scheduling order of jobs. To ease the migration from Hadoop/Yarn to cloud-native platforms, Volcano supports setting priorities at the queue level, reducing migration costs for big data users while enhancing user experience and resource utilization efficiency.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Queues are a fundamental resource in Volcano, each with its own priority. By default, a queue’s priority is determined by its &lt;code&gt;share&lt;/code&gt; value, which is calculated by dividing the resources allocated to the queue by its total capacity. This is done automatically, with no manual configuration needed. The smaller the &lt;code&gt;share&lt;/code&gt; value, the fewer resources the queue has, making it less saturated and more likely to receive resources first. Thus, queues with smaller &lt;code&gt;share&lt;/code&gt; values have higher priority, ensuring fairness in resource allocation.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In production environments—especially in big data scenarios—users often prefer to manually set queue priorities to have a clearer understanding of the order in which queues are scheduled. Since the &lt;code&gt;share&lt;/code&gt; value is dynamic and changes in real-time as resources are allocated, Volcano introduces a &lt;code&gt;priority&lt;/code&gt; field to allow users to set queue priorities more intuitively. The higher the &lt;code&gt;priority&lt;/code&gt;, the higher the queue’s standing. High-priority queues receive resources first, while low-priority queues have their jobs reclaimed earlier when resources need to be recycled.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Queue Priority Definition:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;type QueueSpec struct {&#xA;...&#xA;  // Priority define the priority of queue. Higher values are prioritized for scheduling and considered     later during reclamation.&#xA;  // +optional&#xA;  Priority int32 `json:&#34;priority,omitempty&#34; protobuf:&#34;bytes,10,opt,name=priority&#34;`&#xA;}&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To ensure compatibility with the share mechanism, Volcano also considers the share value when calculating queue priorities. By default, if a user has not set a specific queue priority or if priorities are equal, Volcano will fall back to comparing share values. In this case, the queue with the smaller share has higher priority. Users have the flexibility to choose between different priority strategies based on their specific needs—either by using the priority or the share method.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For queue priority design doc, please refer to: &lt;a href=&#34;https://github.com/volcano-sh/volcano/blob/master/docs/design/queue-priority.md&#34;&gt;Queue priority&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Enable Fine-Grained GPU Resource Sharing and Reclaim&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Volcano introduced the elastic queue capacity scheduling feature in version v1.9, allowing users to directly set the capacity for each resource dimension within a queue. This feature also supports elastic scheduling based on the deserved value, enabling more fine-grained resource sharing and recycling across queues.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For detailed design information on elastic queue capacity scheduling, refer to the &lt;a href=&#34;https://github.com/volcano-sh/volcano/blob/master/docs/design/capacity-scheduling.md&#34;&gt;Capacity Scheduling Design Document&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For a step-by-step guide on using the capacity plugin, see the &lt;a href=&#34;https://github.com/volcano-sh/volcano/blob/master/docs/user-guide/how_to_use_capacity_plugin.md&#34;&gt;Capacity Plugin User Guide&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Configure each dimension deserved resource samples for the queue:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;apiVersion: scheduling.volcano.sh/v1beta1&#xA;kind: Queue&#xA;metadata:&#xA;  name: demo-queue&#xA;spec:&#xA;  reclaimable: true&#xA;  deserved: # set the deserved field.&#xA;    cpu: 64&#xA;    memeory: 128Gi&#xA;    nvidia.com/a100: 40&#xA;    nvidia.com/v100: 80&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In version v1.10, Volcano extends its support to include reporting different types of GPU resources within elastic queue capacities. NVIDIA’s default &lt;code&gt;Device Plugin&lt;/code&gt; does not distinguish between GPU models, instead reporting all resources uniformly as &lt;code&gt;nvidia.com/gpu&lt;/code&gt;. This limits AI training and inference tasks from selecting specific GPU models, such as A100 or T4, based on their particular needs. To address this, Volcano now supports reporting distinct GPU models at the &lt;code&gt;Device Plugin&lt;/code&gt; level, working with the &lt;code&gt;capacity&lt;/code&gt; plugin to enable more precise GPU resource sharing and recycling.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For instructions on using the &lt;code&gt;Device Plugin&lt;/code&gt; to report various GPU models, please refer to the &lt;a href=&#34;https://github.com/volcano-sh/devices/tree/release-1.1/docs/resource-naming&#34;&gt;GPU Resource Naming Guide&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In version v1.10.0, the &lt;code&gt;capacity&lt;/code&gt; plugin is the default for queue management. Note that the &lt;code&gt;capacity&lt;/code&gt; and &lt;code&gt;proportion&lt;/code&gt; plugins are incompatible, so after upgrading to v1.10.0, you must set the &lt;code&gt;deserved&lt;/code&gt; field for queues to ensure proper functionality.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For detailed instructions, please refer to the &lt;a href=&#34;https://github.com/volcano-sh/volcano/blob/master/docs/user-guide/how_to_use_capacity_plugin.md&#34;&gt;Capacity Plugin User Guide&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The &lt;code&gt;capacity&lt;/code&gt; plugin allocates cluster resources based on the &lt;code&gt;deserved&lt;/code&gt; value set by the user, while the &lt;code&gt;proportion&lt;/code&gt; plugin dynamically allocates resources according to queue weight. Users can select either the &lt;code&gt;capacity&lt;/code&gt; or &lt;code&gt;proportion&lt;/code&gt; plugin for queue management based on their specific needs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For more details on the proportion plugin, please visit: &lt;a href=&#34;https://volcano.sh/en/docs/plugins/#proportion&#34;&gt;Proportion Plugin&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Introduce Pod Scheduling Readiness Support&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Once a Pod is created, it is considered ready for scheduling. In Kube-scheduler, it will try its best to find a suitable node to place all pending Pods. However, in reality, some Pods may be in a “lack of necessary resources” state for a long time. These Pods actually interfere with the decision-making and operation of the scheduler (and downstream components such as Cluster AutoScaler) in an unnecessary way, causing problems such as resource waste. Pod Scheduling Readiness is a new feature of Kube-sheduler. In Kubernetes v.1.30 GA, it has become a stable feature. It controls the scheduling timing of Pods by setting the schedulingGates field of the Pod.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In previous versions, Volcano has integrated all algorithms of the K8s default scheduler, fully covering the native scheduling functions of Kube-scheduler. Therefore, Volcano can completely replace Kube-scheduler as a unified scheduler under the cloud native platform, supporting unified scheduling of microservices and AI/big data workloads. In the latest version v1.10, Volcano has introduced Pod Scheduling Readiness scheduling capability to further meet users’ scheduling needs in diverse scenarios.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For the documentation of Pod Scheduling Readiness features, please refer to: &lt;a href=&#34;https://kubernetes.io/docs/concepts/scheduling-eviction/pod-scheduling-readiness/&#34;&gt;Pod Scheduling Readiness | Kubernetes&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For the Pod Scheduling Readiness design doc of volcano, please refer to: &lt;a href=&#34;https://github.com/volcano-sh/volcano/pull/3581&#34;&gt;Proposal for Support of Pod Scheduling Readiness by ykcai-daniel · Pull Request #3581 · volcano-sh/volcano (github.com)&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Add Sidecar Container Scheduling Capabilities&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;A Sidecar container is an auxiliary container designed to support the main business container by handling tasks such as logging, monitoring, and network initialization.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Prior to Kubernetes v1.28, the concept of Sidecar containers existed only informally, with no dedicated API to distinguish them from business containers. Both types of containers were treated equally, which meant that Sidecar containers could be started after the business container and might end before it. Ideally, Sidecar containers should start before and finish after the business container to ensure complete collection of logs and monitoring data.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes v1.28 introduces formal support for Sidecar containers at the API level, implementing unified lifecycle management for init containers, Sidecar containers, and business containers. This update also adjusts how resource requests and limits are calculated for Pods, and the feature will enter Beta status in v1.29.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The development of this feature involved extensive discussions, mainly focusing on maintaining compatibility with existing APIs and minimizing disruptive changes. Rather than introducing a new container type, Kubernetes reuses the init container type and designates Sidecar containers by setting the init container’s restartPolicy to Always. This approach addresses both API compatibility and lifecycle management issues effectively.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;With this update, the scheduling of Pods now considers the Sidecar container’s resource requests as part of the business container’s total requests. Consequently, the Volcano scheduler has been updated to support this new calculation method, allowing users to schedule Sidecar containers with Volcano.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For more information on Sidecar containers, visit &lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/pods/sidecar-containers/&#34;&gt;Sidecar Containers | Kubernetes&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Enhance Vcctl Command Line Tool&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;vcctl is a command line tool for operating Volcano’s built-in CRD resources. It can be conveniently used to view/delete/pause/resume vcjob resources, and supports viewing/deleting/opening/closing/updating queue resources. Volcano has enhanced vcctl in the new version, adding the following features:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Support creating/deleting/viewing/describing jobflow and jobtemplate resources&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Support querying vcjob in a specified queue&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Support querying Pods by queue and vcjob filtering&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For detailed guidance documents on vcctl, please refer to: &lt;a href=&#34;https://github.com/volcano-sh/volcano/blob/master/docs/design/command-line-enhancement.md#new-format-of-volcano-command-line&#34;&gt;vcctl Command Line Enhancement&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Ensure Compatibility with Kubernetes v1.30&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Volcano closely follows the pace of Kubernetes community versions and supports every major version of Kubernetes. The latest supported version is v1.30, and runs complete UT and E2E use cases to ensure functionality and reliability.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you want to participate in the development of Volcano adapting to the new version of Kubernetes, please refer to: &lt;a href=&#34;https://github.com/volcano-sh/volcano/blob/master/docs/design/adapt-k8s-todo.md&#34;&gt;adapt-k8s-todo&lt;/a&gt; for community contributions.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Strengthen Volcano Security Measures&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Volcano has always attached great importance to the security of the open source software supply chain. It follows the specifications defined by OpenSSF in terms of license compliance, security vulnerability disclosure and repair, warehouse branch protection, CI inspection, etc. Volcano recently added a new workflow to Github Action, which will run OpenSSF security checks when the code is merged, and update the software security score in real time to continuously improve software security.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;At the same time, Volcano has reduced the RBAC permissions of each component, retaining only the necessary permissions, avoiding potential risks of unauthorized access and improving the security of the system.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Related PRs:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/volcano-sh/volcano/pull/3655&#34;&gt;Added the scorecard github action and its badge by harshitasao · Pull Request #3655 · volcano-sh/volcano&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/volcano-sh/volcano/pull/3545&#34;&gt;Shrink permissions of vc scheduler &amp;amp; controller by Monokaix · Pull Request #3545 · volcano-sh/volcano (github.com)&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/volcano-sh/volcano/pull/3504&#34;&gt;Add pre-install&amp;amp;pre-upgrade hook for admission-init job by Monokaix · Pull Request #3504 · volcano-sh/volcano (github.com)&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Optimize Volcano for Large-Scale Performance&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In large-scale scenarios, Volcano has done a lot of performance optimization work, mainly including:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Optimize vcjob update strategy, reduce vcjob update and synchronization frequency, reduce API Server pressure, and improve QPS of submitted tasks&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Add controller gate switch to vc controller, users can choose to close unnecessary controllers, reduce memory usage and CPU load&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;All controllers use shared informer to reduce memory usage&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Improve GPU Monitoring Function&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The new version of Volcano optimizes and enhances GPU monitoring indicators, fixes the problem of inaccurate GPU monitoring, and adds node information to the GPU computing power and video memory monitoring indicators, allowing users to more intuitively view the computing power of each GPU on each node, the total amount and allocated amount of video memory.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Related PR: &lt;a href=&#34;https://github.com/volcano-sh/volcano/pull/3620/&#34;&gt;Update volcano-vgpu monitoring system by archlitchi · Pull Request #3620 · volcano-sh/volcano (github.com)&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Optimize Helm Chart Installation And Upgrade Processes&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Volcano has optimized the installation and upgrade process of helm chart, and supports installing helm chart packages to set more custom parameters, mainly including:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;By using the helm hook mechanism, after successfully installing Volcano, the volcano-admission-init job is automatically deleted to avoid the subsequent upgrade failure using helm upgrade, related PR: &lt;a href=&#34;https://github.com/volcano-sh/volcano/pull/3504&#34;&gt;Add pre-install&amp;amp;pre-upgrade hook for admission-init job by Monokaix · Pull Request #3504 · volcano-sh/volcano (github.com)&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Update the secret file required by Volcano admission after each successful installation to avoid the problem of repeated installation and uninstallation of Volcano without specifying the helm package name, which will cause the Volcano admission process to fail, related PR: &lt;a href=&#34;https://github.com/volcano-sh/volcano/pull/3653&#34;&gt;Update volcano-admission secret when it already exists by Monokaix · Pull Request #3653 · volcano-sh/volcano (github.com)&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Support setting common labels for resource objects in helm packages, related PR: &lt;a href=&#34;https://github.com/volcano-sh/volcano/pull/3511&#34;&gt;Add common labels for chart objects by Aakcht · Pull Request #3511 · volcano-sh/volcano (github.com)&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Support setting log level for Volcano components through helm, related PR: &lt;a href=&#34;https://github.com/volcano-sh/volcano/pull/3656&#34;&gt;Expose volcano components (controller, scheduler, etc.) log level control to the helm chat values by chenshiwei-io · Pull Request #3656 · volcano-sh/volcano (github.com)&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Support specifying the image registry of Volcano components through helm, related PR: &lt;a href=&#34;https://github.com/volcano-sh/volcano/pull/3436&#34;&gt;add image registry for helm by calvin0327 · Pull Request #3436 · volcano-sh/volcano (github.com)&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Support setting container-level securityContext through helm, related PR: &lt;a href=&#34;https://github.com/volcano-sh/volcano/pull/3704&#34;&gt;feat: Add securityContext support at container level in helm chart templates by lekaf974 · Pull Request #3704 · volcano-sh/volcano (github.com)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Contributors&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Volcano 1.10.0 version includes hundreds of contributions from 36 community contributors. Thanks for your contributions.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Contributors on GitHub:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-fixed-layout&#34;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;&lt;strong&gt;@googs1025&lt;/strong&gt;&lt;/th&gt;&lt;th&gt;&lt;strong&gt;@WulixuanS&lt;/strong&gt;&lt;/th&gt;&lt;th&gt;&lt;strong&gt;@SataQiu&lt;/strong&gt;&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;@guoqinwill&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;@lowang-bh&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;@shruti2522&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;@lukasboettcher&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;@wangyysde&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;@bibibox&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;@Wang-Kai&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;@y-ykcir&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;@lekaf974&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;@yeahdongcn&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;@Monokaix&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;@Aakcht&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;@yxxhero&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;@babugeet&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;@liuyuanchun11&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;@MichaelXcc&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;@william-wang&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;@lengrongfu&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;@xieyanker&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;@lx1036&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;@archlitchi&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;@hwdef&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;@wangyang0616&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;@microyahoo&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;@snappyyouth&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;@harshitasao&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;@chenshiwei-io&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;@TaiPark&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;@Aakcht&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;@ykcai-daniel&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;@lekaf974&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;@JesseStutler&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;@belo4ya&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Reference&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Release note: v1.10.0&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/volcano-sh/volcano/releases/tag/v1.10.0&#34;&gt;https://github.com/volcano-sh/volcano/releases/tag/v1.10.0&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Branch：release-1.10&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/volcano-sh/volcano/tree/release-1.10&#34;&gt;https://github.com/volcano-sh/volcano/tree/release-1.10&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;Volcano 维护者发布的项目&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;2024年9月19日UTC+8，火山社区正式发布1.10.0版本，引入以下新功能：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;支持队列优先级调度策略&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;启用细粒度 GPU 资源共享和回收&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;引入 Pod 调度准备支持&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;添加 Sidecar 容器调度功能&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;增强 Vcctl 命令行工具&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;确保与 Kubernetes v1.30 兼容&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;加强火山安全措施&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;优化 Volcano 以实现大规模性能&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;完善GPU监控功能&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;优化 Helm Chart 安装和升级流程&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;支持队列优先级调度策略&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在传统的大数据处理场景中，用户可以直接设置队列优先级来控制作业的调度顺序。为了方便从Hadoop/Yarn到云原生平台的迁移，Volcano支持在队列级别设置优先级，降低大数据用户的迁移成本，同时提升用户体验和资源利用效率。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;队列是 Volcano 中的基本资源，每个队列都有自己的优先级。默认情况下，队列的优先级由其 &lt;code&gt;share&lt;/code&gt; 值决定，该值是通过将分配给队列的资源除以其总容量来计算的。这是自动完成的，无需手动配置。 &lt;code&gt;share&lt;/code&gt; 值越小，队列拥有的资源就越少，从而使其饱和度降低，并且更有可能首先接收资源。因此，&lt;code&gt;share&lt;/code&gt;值较小的队列具有较高的优先级，保证资源分配的公平性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在生产环境中，尤其是在大数据场景中，用户通常更喜欢手动设置队列优先级，以便更清楚地了解队列的调度顺序。由于&lt;code&gt;share&lt;/code&gt;值是动态的并且随着资源分配而实时变化，Volcano引入了&lt;code&gt;priority&lt;/code&gt;字段来允许用户更直观地设置队列优先级。 &lt;code&gt;优先级&lt;/code&gt;越高，队列的地位就越高。高优先级队列先接收资源，低优先级队列在需要回收资源时先回收作业。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;队列优先级定义：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;类型 QueueSpec 结构 {&#xA;...&#xA;  // Priority 定义队列的优先级。较高的值会优先进行调度，并在稍后的回收过程中考虑。&#xA;  // +可选&#xA;  优先级 int32 `json:&#34;priority,omitempty&#34; protobuf:&#34;bytes,10,opt,name=priority&#34;`&#xA;}&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;为了确保与共享机制的兼容性，Volcano 在计算队列优先级时也会考虑共享值。默认情况下，如果用户没有设置特定的队列优先级或者优先级相等，火山将退回到比较股票价值。在这种情况下，份额较小的队列具有较高的优先级。用户可以根据自己的具体需求灵活地选择不同的优先级策略——无论是使用优先级还是共享方法。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;队列优先级设计文档请参考：&lt;a href=&#34;https://github.com/volcano-sh/volcano/blob/master/docs/design/queue-priority.md&#34;&gt;队列优先级&lt; /a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;启用细粒度 GPU 资源共享和回收&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Volcano在v1.9版本中引入了弹性队列容量调度功能，允许用户直接设置队列内每个资源维度的容量。该特性还支持基于应得值的弹性调度，实现更细粒度的跨队列资源共享和回收。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;有关弹性队列容量调度的详细设计信息，请参阅&lt;a href=&#34;https://github.com/volcano-sh/volcano/blob/master/docs/design/capacity-scheduling.md&#34;&gt;容量调度设计文档&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;有关使用容量插件的分步指南，请参阅&lt;a href=&#34;https://github.com/volcano-sh/volcano/blob/master/docs/user-guide/how_to_use_capacity_plugin。 md&#34;&gt;容量插件使用指南&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;为队列配置每个维度应有的资源样本：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;api版本：scheduling.volcano.sh/v1beta1&#xA;种类：队列&#xA;元数据：&#xA;  名称：演示队列&#xA;规格：&#xA;  可回收：true&#xA;  应得: # 设置应得字段。&#xA;    中央处理器：64&#xA;    内存：128Gi&#xA;    nvidia.com/a100：40&#xA;    nvidia.com/v100: 80&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在 v1.10 版本中，Volcano 扩展了其支持范围，包括报告弹性队列容量内不同类型的 GPU 资源。 NVIDIA 的默认&lt;code&gt;Device Plugin&lt;/code&gt; 不区分 GPU 型号，而是将所有资源统一报告为 &lt;code&gt;nvidia.com/gpu&lt;/code&gt;。这限制了人工智能训练和推理任务根据其特定需求选择特定的 GPU 模型，例如 A100 或 T4。为了解决这个问题，Volcano 现在支持在设备插件级别报告不同的 GPU 模型，并与容量插件配合使用，以实现更精确的 GPU 资源共享和回收。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;有关使用&lt;code&gt;设备插件&lt;/code&gt;报告各种 GPU 型号的说明，请参阅&lt;a href=&#34;https://github.com/volcano-sh/devices/tree/release- 1.1/docs/resource-naming&#34;&gt;GPU资源命名指南&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在 v1.10.0 版本中，&lt;code&gt;capacity&lt;/code&gt; 插件是队列管理的默认插件。请注意，&lt;code&gt;capacity&lt;/code&gt; 和 &lt;code&gt;proportion&lt;/code&gt; 插件不兼容，因此升级到 v1.10.0 后，必须为队列设置 &lt;code&gt;deserved&lt;/code&gt; 字段，以确保正确功能。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;详细说明请参考&lt;a href=&#34;https://github.com/volcano-sh/volcano/blob/master/docs/user-guide/how_to_use_capacity_plugin.md&#34;&gt;容量插件用户指南&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;code&gt;capacity&lt;/code&gt;插件根据用户设置的&lt;code&gt;deserved&lt;/code&gt;值分配集群资源，而&lt;code&gt;proportion&lt;/code&gt;插件则根据队列动态分配资源重量。用户可以根据自己的具体需求选择&lt;code&gt;capacity&lt;/code&gt;或&lt;code&gt;proportion&lt;/code&gt;插件进行队列管理。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;有关比例插件的更多详细信息，请访问：&lt;a href=&#34;https://volcano.sh/en/docs/plugins/#proportion&#34;&gt;比例插件&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;引入 Pod 调度准备支持&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Pod 一旦创建，就被认为已准备好进行调度。在 Kube-scheduler 中，它会尽力寻找合适的节点来放置所有待处理的 Pod。但现实中，有些 Pod 可能会长期处于“缺乏必要资源”的状态。这些Pod实际上以不必要的方式干扰了调度器（以及Cluster AutoScaler等下游组件）的决策和运行，造成资源浪费等问题。 Pod 调度就绪是 Kube-sheduler 的一个新功能。在 Kubernetes v.1.30 GA 中，它已成为一项稳定的功能。它通过设置Pod的schedulingGates字段来控制Pod的调度时机。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在之前的版本中，Volcano已经集成了K8s默认调度器的所有算法，完全覆盖了Kube-scheduler的原生调度功能。因此，Volcano可以完全替代Kube-scheduler作为云原生平台下的统一调度器，支持微服务和AI/大数据工作负载的统一调度。在最新版本v1.10中，Volcano引入了Pod Scheduling Readiness调度能力，进一步满足用户多样化场景的调度需求。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;有关 Pod 调度就绪功能的文档，请参阅：&lt;a href=&#34;https://kubernetes.io/docs/concepts/scheduling-eviction/pod-scheduling-readiness/&#34;&gt;Pod 调度就绪 |库伯内特&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;volcano的Pod Scheduling Readiness设计文档请参考：&lt;a href=&#34;https://github.com/volcano-sh/volcano/pull/3581&#34;&gt;ykcai支持Pod Scheduling Readiness的提案-daniel·Pull Request #3581·volcano-sh/volcano (github.com)&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;添加 Sidecar 容器调度功能&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Sidecar容器是一个辅助容器，旨在通过处理日志、监控、网络初始化等任务来支持主业务容器。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在 Kubernetes v1.28 之前，Sidecar 容器的概念只是非正式存在，没有专用的 API 来区分它们和业务容器。两种类型的容器受到同等对待，这意味着 Sidecar 容器可以在业务容器之后启动，也可以在其之前结束。理想情况下，Sidecar 容器应在之前启动并在之后完成业务容器，保证日志和监控数据的完整收集。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes v1.28在API层面正式支持Sidecar容器，实现init容器、Sidecar容器、业务容器的统一生命周期管理。本次更新还调整了 Pod 资源请求和限制的计算方式，该功能将在 v1.29 中进入 Beta 状态。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;此功能的开发涉及广泛的讨论，主要集中在保持与现有 API 的兼容性并最大限度地减少破坏性更改。 Kubernetes 没有引入新的容器类型，而是重用了 init 容器类型，并通过将 init 容器的 restartPolicy 设置为 Always 来指定 Sidecar 容器。这种方法有效地解决了 API 兼容性和生命周期管理问题。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;通过此更新，Pod 的调度现在将 Sidecar 容器的资源请求视为业务容器总请求的一部分。因此，Volcano 调度程序已更新以支持这种新的计算方法，允许用户使用 Volcano 调度 Sidecar 容器。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;有关 Sidecar 容器的更多信息，请访问 &lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/pods/sidecar-containers/&#34;&gt;Sidecar 容器 | Kubernetes&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;增强 Vcctl 命令行工具&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;vcctl是一个用于操作Volcano内置CRD资源的命令行工具。可以方便地用于查看/删除/暂停/恢复vcjob资源，支持查看/删除/打开/关闭/更新队列资源。 Volcano在新版本中对vcctl进行了增强，增加了以下功能：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;支持创建/删除/查看/描述作业流程和作业模板资源&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;支持查询指定队列中的vcjob&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;支持通过队列和vcjob过滤查询Pod&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;关于vcctl的详细指导文档请参考：&lt;a href=&#34;https://github.com/volcano-sh/volcano/blob/master/docs/design/command-line-enhancement.md#new -format-of-volcano-command-line&#34;&gt;vctl 命令行增强&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;确保与 Kubernetes v1.30 兼容&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Volcano 紧跟 Kubernetes 社区版本的步伐，支持 Kubernetes 的各个主要版本。最新支持的版本是v1.30，并运行完整的UT和E2E用例以确保功能和可靠性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您想参与Volcano适配新版本Kubernetes的开发，请参考：&lt;a href=&#34;https://github.com/volcano-sh/volcano/blob/master/docs/ design/adapt-k8s-todo.md&#34;&gt;adapt-k8s-todo&lt;/a&gt; 用于社区贡献。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;加强火山安全措施&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;火山一直非常重要关注开源软件供应链的安全。它在许可证合规性、安全漏洞披露和修复、仓库分支保护、CI检查等方面遵循OpenSSF定义的规范。Volcano最近在Github Action中添加了一个新的工作流程，它将在代码合并时运行OpenSSF安全检查，并实时更新软件安全评分，持续提升软件安全性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;同时，Volcano减少了各组件的RBAC权限，只保留必要的权限，避免了未授权访问的潜在风险，提高了系统的安全性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;相关 PR：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/volcano-sh/volcano/pull/3655&#34;&gt;添加了记分卡 github 操作及其徽章，由 Harritasao · Pull 请求#3655 · Volcano-sh/volcano&lt;/一个&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/volcano-sh/volcano/pull/3545&#34;&gt;通过 Monokaix 缩小 vc 调度程序和控制器的权限 · Pull 请求 #3545 · Volcano-sh/volcano (github.com) com）&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/volcano-sh/volcano/pull/3504&#34;&gt;为 Monokaix 的准入初始化作业添加预安装和预升级挂钩 · Pull 请求 #3504 ·volcano-sh /volcano (github.com)&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;优化 Volcano 以实现大规模性能&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在大规模场景下，Volcano 做了很多性能优化工作，主要包括：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;优化vcjob更新策略，降低vcjob更新和同步频率，减轻API Server压力，提高提交任务的QPS&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;为vc控制器添加controller gateway开关，用户可以选择关闭不需要的控制器，减少内存使用和CPU负载&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;所有控制器都使用共享通知程序来减少内存使用&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;完善GPU监控功能&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Volcano新版本优化增强了GPU监控指标，修复了GPU监控不准确的问题，并在GPU算力和显存监控指标中添加了节点信息，让用户更直观地查看每个GPU的算力情况每个节点上的视频内存总量和分配量。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;相关PR：&lt;a href=&#34;https://github.com/volcano-sh/volcano/pull/3620/&#34;&gt;archlitchi更新volcano-vgpu监控系统·Pull Request #3620·volcano-sh/volcano （github.com）&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;优化 Helm Chart 安装和升级流程&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Volcano优化了Helm Chart的安装和升级流程，支持安装Helm Chart包设置更多自定义参数，主要包括：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;通过使用helm hook机制，成功安装Volcano后，自动删除volcano-admission-init作业，避免后续使用helm升级升级失败，相关PR: &lt;a href=&#34;https://github.com/volcano-sh/volcano/pull/3504&#34;&gt;为 Monokaix 的准入初始化作业添加预安装和预升级挂钩 · Pull Request #3504 ·volcano-sh/火山（github.com）&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;每次成功安装后更新Volcano准入所需的secret文件，避免在未指定helm包名的情况下重复安装和卸载Volcano，从而导致Volcano准入过程失败的问题，相关PR：&lt;a href= &#34;https://github.com/volcano-sh/volcano/pull/3653&#34;&gt;Monokaix 已存在火山入场秘密 · Pull Request #3653 · Volcano-sh/volcano (github.com)&lt;/a &gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;支持为helm包中的资源对象设置通用标签，相关PR：&lt;a href=&#34;https://github.com/volcano-sh/volcano/pull/3511&#34;&gt;为图表对象添加通用标签，作者：Aakcht · Pull 请求#3511·volcano-sh/volcano (github.com)&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;支持通过helm设置Volcano组件的日志级别，相关PR：&lt;a href=&#34;https://github.com/volcano-sh/volcano/pull/3656&#34;&gt;暴露volcano组件（控制器、调度器等） ) 通过 chenshiwei-io 对 helm 聊天值进行日志级别控制 · Pull Request #3656 · Volcano-sh/volcano (github.com)&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;支持通过helm指定Volcano组件的镜像registry，相关PR：&lt;a href=&#34;https://github.com/volcano-sh/volcano/pull/3436&#34;&gt;为helm添加镜像registry by calvin0327 · Pull请求#3436·volcano-sh/volcano (github.com)&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;支持通过helm设置容器级别的securityContext，相关PR：&lt;a href=&#34;https://github.com/volcano-sh/volcano/pull/3704&#34;&gt;feat：在helm图表中添加容器级别的securityContext支持模板由 lekaf974 提供 · Pull Request #3704 ·volcano-sh/volcano (github.com)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;贡献者&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Volcano 1.10.0 版本包含来自 36 位社区贡献者的数百项贡献。感谢您的贡献。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;GitHub 上的贡献者：&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-fixed-layout&#34;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;&lt;strong&gt;@googs1025&lt;/strong&gt;&lt;/th&gt;&lt;th&gt;&lt; strong&gt;@WulixuanS&lt;/strong&gt;&lt;/th&gt;&lt;th&gt;&lt;strong&gt;@SataQiu&lt;/strong&gt;&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;@guoqinwill &lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;@lowang-bh&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;@shruti2522&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt; td&gt;&lt;strong&gt;@lukasboettcher&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;@wangyysde&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;@bibibox&lt;/strong&gt;&lt;/td&gt;&lt;/tr &gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;@王凯&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;@y-ykcir&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;@lekaf974&lt;/强&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;@yeahdongcn&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;@Monokaix&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong &gt;@Aakcht&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;@yxxhero&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;@babugeet&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;&lt;strong&gt;@liuyuanchun11&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;@MichaelXcc&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;@william-wang&lt; /strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;@lengrongfu&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;@xieyanker&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;斯特罗ng&gt;@lx1036&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;@archlitchi&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;@hwdef&lt;/strong&gt;&lt;/td &gt;&lt;td&gt;&lt;strong&gt;@wangyang0616&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;@microyahoo&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;@snappyyouth&lt;/强&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;@harshitasao&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;@chenshiwei-io&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; &lt;strong&gt;@TaiPark&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;@Aakcht&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;@ykcai-daniel&lt;/strong&gt;&lt;/td&gt;&lt;/tr &gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;@lekaf974&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;@JesseStutler&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;@belo4ya&lt;/strong&gt;&lt;/ td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;参考&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;发行说明：v1.10.0&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/volcano-sh/volcano/releases/tag/v1.10.0&#34;&gt;https://github.com/volcano-sh/volcano/releases/tag/v1 .10.0&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;分支：release-1.10&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/volcano-sh/volcano/tree/release-1.10&#34;&gt;https://github.com/volcano-sh/volcano/tree/release-1.10&lt;/一个&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Thu, 03 Oct 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Reducing MTTD and increasing observability with Linkerd at loveholidays】在 loveholidays 中使用 Linkerd 减少 MTTD 并提高可观察性</title>
      <link>https://www.cncf.io/blog/2024/10/02/reducing-mttd-and-increasing-observability-with-linkerd-at-loveholidays/</link>
      <description>【&lt;p&gt;&lt;em&gt;End user post by Dan Williams, Senior Infrastructure Engineer at loveholidays&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In this blog post, we’ll share how loveholidays was able to utilise Linkerd to provide uniform metrics across all services, leading to a decrease in incident Mean Time To Discovery (MTTD) and an increased customer conversion rate by reducing search response times.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Introducing loveholidays&amp;nbsp;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Founded in 2012, loveholidays is the largest and fastest growing online travel agency in the UK and Ireland. Having launched in the German market in May 2023, we’re on a mission to open the world to everyone. Our goal is to offer our customers unlimited choice with unmatched ease and unmissable value, providing the perfect holiday experience. To achieve that, we process trillions(!) of hotel/flight combinations per day, with millions of passengers travelling with us annually.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Meet the engineering team&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;loveholidays has around 350 employees across London (UK) and Düsseldorf (Germany), with more than 100 of us in Tech and Product, and we are constantly growing. Our current engineering headcount sits at around 60 software engineers and 5 platform engineers.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Engineering at loveholidays is scaled based on &lt;a href=&#34;https://tech.loveholidays.com/the-5-principles-that-helped-scale-loveholidays-7ea0b0fd3df9&#34;&gt;5 simple principles&lt;/a&gt;, embodying our “you build it, you run it” engineering culture. Our engineers are empowered to own the full software delivery lifecycle (SDLC), meaning each and every engineer in our company is responsible for their services at every step of the journey, from initial design through to deploying to production, building monitoring alerts/dashboards and being on-call for all day-2 operations.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The platform infrastructure team at loveholidays works to enable developers to operate in a self-serve manner. We do this by identifying common problems and friction points, then solving them with infrastructure, process and tooling. We are huge advocates for open source tooling, meaning we are constantly pushing the boundaries and working on the cutting edge of technology.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Our infrastructure&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We are a team of Google Cloud Platform evangelists. In 2018, we migrated from on-prem to GCP (see our Google case study &lt;a href=&#34;https://cloud.google.com/customers/loveholidays&#34;&gt;here&lt;/a&gt;!), with 100% of our infrastructure now in the cloud. We run 5 GKE clusters spread across production, staging and development environments, with all services running in one primary region in London. We are actively working on introducing a multi-cluster, multi-region architecture. &lt;a href=&#34;https://tech.loveholidays.com/gke-multi-cluster-services-one-bad-probe-away-from-disaster-62051fafe84e&#34;&gt;Learn more about our multi-cluster expansion in this blog post&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We run somewhere in the region of 5000 production pods with around 300 Deployments / StatefulSets, all managed by our development teams. The languages, frameworks, and tooling used are all governed by the teams themselves, so we have services in Java, Go, Python, Rust, JavaScript, TypeScript, and more. One of our engineering principles is “Technology is a means to an end”, meaning teams are empowered to pick the correct language for the task rather than having to conform to existing standards.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We use Grafana’s &lt;a href=&#34;https://grafana.com/go/observabilitycon/2022/lgtm-scale-observability-with-mimir-loki-and-tempo/&#34;&gt;LGTM Stack&lt;/a&gt; (Loki, Grafana, Tempo, Mimir) for all of our observability needs, along with other open-source tools such as the &lt;a href=&#34;https://prometheus-operator.dev/&#34;&gt;Prometheus-Operator&lt;/a&gt; to scrape our application’s metrics, &lt;a href=&#34;https://argo-cd.readthedocs.io/en/stable/&#34;&gt;ArgoCD&lt;/a&gt; for GitOps along with &lt;a href=&#34;https://argoproj.github.io/rollouts/&#34;&gt;Argo Rollouts&lt;/a&gt; and &lt;a href=&#34;https://github.com/spinnaker/kayenta&#34;&gt;Kayenta&lt;/a&gt; powering our canary deployments.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;With GitOps powered deployments, we deploy to production over 1500 times a month. We move fast and we occasionally break stuff.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Time is money; latency is cost&amp;nbsp;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Search response time has a direct correlation with customer conversion rate — the likelihood for a customer to complete their purchase on our website. In other words, it’s absolutely vital for us to monitor the latency and uptime of our services to spot regressions or poorly behaving components.&amp;nbsp; Latency also correlates with infrastructure cost as faster services are cheaper to run.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Since teams are in charge of creating their own monitoring dashboards and alerts, historically, each team reinvented the wheel for monitoring their applications. This resulted in inconsistent visualisations, incorrect queries/calculations, or completely missing data. A simple example of this is one application reporting throughput in requests per minute, another with requests per second. Some applications would record latency in averages, some with percentiles such as P50/P95/P99, but not even consistently the same set of percentiles.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;These small details made it nearly impossible to quickly compare the performance of any given service, where the observer would have to learn the dashboards for each application before beginning to evaluate its health. We couldn’t quickly identify when one application was performing particularly badly, meaning our MTTD for regressions introduced with new deployments would have a direct impact on our sales / conversion rate.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Linkerd: the answer to our disparate metrics and observability problem&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Each language and framework we use brings with it a new set of metrics and observability challenges. Just creating common dashboards wouldn’t be an option, as no two applications present the same set of metrics, and this is where we decided that a service mesh could help us. Using a service mesh, we would immediately have a uniform set of &lt;a href=&#34;https://www.blameless.com/blog/4-sre-golden-signals-what-they-are-and-why-they-matter&#34;&gt;Golden Signals&lt;/a&gt; (latency, throughput, errors) for HTTP traffic, regardless of the underlying languages or tooling.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As well as uniform monitoring, we knew a service mesh would help us with a number of other items on our roadmap, such as mTLS authentication, automated retries, canary deploys, and even east-west multi-cluster traffic.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The next question was which service mesh? Like most companies, we decided to evaluate Linkerd and Istio, the only two CNCF-graduated service meshes. Our team had brief previous exposure to both Istio and Linkerd, having tried and failed to implement both meshes in the very early days of our GKE migration. We knew Linkerd had been completely rewritten with 2.0, so we decided to pursue this first as our Proof of Concept (PoC).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;One of our core principles is “Invest in simplicity”, and this is embodied throughout Linkerd’s entire philosophy and product. For our initial PoC, we installed Linkerd to our dev cluster using their CLI, we added the Viz plugin (which provides real-time traffic insights in a nice dashboard), and finally added the `linkerd/inject: enabled` annotation to a few deployments. That was it. &lt;em&gt;It just worked&lt;/em&gt;. We had standardised golden metrics being generated by the sidecar Linkerd proxies, mTLS securing pod-to-pod traffic and we could listen to live traffic using the tap feature, all within about 15 minutes of deciding to install Linkerd in dev.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Linkerd as a product aligned exactly with how we approach engineering, by investing in simplicity. We had a clear goal in mind of the problem we wanted to solve, without additional complexity or overhead, and our findings during the PoC stage made it immediately clear that Linkerd was the correct solution to the problems we set out to solve, and the entire open source community around Linkerd deserves a mention as everyone involved is incredibly open and willing to help.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;The implementation&amp;nbsp;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To roll out Linkerd into production, we took a very slow and calculated approach. It took us over six months to get to full coverage, as we onboarded a small number of applications at a time and then carefully monitored these in production for any regressions. Our implementation journey is detailed in a three part series on our tech blog: &lt;a href=&#34;https://tech.loveholidays.com/linkerd-at-loveholidays-our-journey-to-a-production-service-mesh-9a6cd478d395&#34;&gt;“Linkerd at loveholidays — Our journey to a production service mesh” blog post&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This slow approach may seem counterintuitive given we went with Linkerd for both ease and speed of deployment. The reality is that edge cases exist, and things will always break in ways you don’t expect as no two production environments are the same.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Throughout our onboarding journey, we identified and fixed a number of issues with edge case issues such as connection leaking and memory leaks, requests being dropped due to malformed headers and a number of other network related issues that were previously hidden before the Linkerd proxy exposed them.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;I like the following excerpt from the &lt;a href=&#34;https://linkerd.io/2-edge/tasks/debugging-502s/#why-do-these-errors-only-occur-when-linkerd-is-injected&#34;&gt;Debugging 502s&lt;/a&gt; page in Linkerd’s documentation: “&lt;em&gt;Linkerd turns connection errors into HTTP 502 responses. This can make issues which were previously undetected suddenly visible.&lt;/em&gt;”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Our efforts combined with the Linkerd maintainer’s receptiveness and willingness to help, led to code fixes both in ours and Linkerd’s code to address some of the issues we found. As we progressed through our onboarding journey and identified different failure modes, we added new Prometheus and Loki (logs) alerts to quickly alert us to issues related to the service mesh before they become problems.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Since finishing our onboarding in early 2023, `linkerd/inject: enabled`has become the default setting for all new applications deployed via our common Helm Chart and isn’t even something we think about anymore.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We built a common dashboard based on Linkerd metrics, automatically showing for all meshed applications:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;“Golden Signals” HTTP metrics (throughput, latency, errors, success rate)&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Service to service traffic:&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Inbound traffic &amp;amp; success rate per service&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Outbound traffic &amp;amp; success rate per service&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;TCP connections&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Per-Route HTTP metrics (driven by ServiceProfiles)&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Resource information (pods, CPU, memory etc via &lt;a href=&#34;https://github.com/kubernetes/kube-state-metrics&#34;&gt;kube-state-metrics&lt;/a&gt;)&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Linkerd-Proxy logs&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;…and more. All new services are automatically meshed, meaning we provide near-full observability for all services from the moment they are deployed.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXcV9s_11r416x0K2q2XFEY2gtcUIL9AcD_LCaTaDcLhtyB7JvBCWFYKJncsbqMvputNEflVhskIAr2pkh6ZcRLL5E-fqxILwXPFkKTiL_TEV9FylV3JZCUpkuY4JZ97liVBxnd3dv_33iPgndn1diVPB0Rz?key=SCUjkYyfQLckob6LPOHqLQ&#34; alt=&#34;dashboard&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For each service, we can see the traffic from and to different services, so we can quickly identify if, for example, a particular downstream service is responding slow or erroring. Previous dashboards might tell us requests were failing, but not be able to easily identify the source or destination service for those failing requests.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXckE4VMn7rKJxWWwO87VRcZmBxsXDiTd2msXf4LIDSsue5zxQ_yvuF7p9qKD60ayRx8ucI9qsHscL9PD0M5ISdb5ydtXa9iG_0ODIo8NEh7sveRVd7F7f7Qn4ixbyOaAVyTmLlpE8nxW6eneW_JLHClUsez?key=SCUjkYyfQLckob6LPOHqLQ&#34; alt=&#34;Inbound HTTP Requests&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;With Linkerd’s throughput metrics, combined with some pod labels from Kube State Metrics, we have been able to produce dashboards identifying cross-zone traffic inside the Cluster, which we’ve then used to optimise our traffic and save significant amounts on our networking spend. We plan to use Linkerd’s &lt;a href=&#34;https://docs.buoyant.io/buoyant-enterprise-linkerd/latest/tasks/enabling-hazl/&#34;&gt;HAZL&lt;/a&gt; to further reduce our cross-zone traffic.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXeXY-Madxo5DgLTOEehTDBtgcyfuBmA6ENnIO3GBfZ3v3U_1EfpR0di9JaO45ooWMqYBSHgvjwGzO_9S0lBW-f03GmON2AZVtxryIQckQelt7EJO1feCecqhW09SkBvaDIw-w78zsqUOCnjHNk9-wwyUoDX?key=SCUjkYyfQLckob6LPOHqLQ&#34; alt=&#34;Dashboard&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Using a combination of Argo Rollouts and Kayenta, we use the metrics provided by Linkerd to perform Canary deployments with automated rollbacks in case of failure. A new deployment will create 10% of pods using the new image, then we use the Linkerd metrics captured from the new and old pods to perform statistical analysis and identify issues before the new version is promoted to stable. This means if, for example, an application’s P95 response time increases by a certain % compared to the previous stable version, we can consider it a failed deployment and rollback automatically.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXeV9_6ksGczLISLj2K32R5xFEeMTGNMY2DWiFavBvS82Kw-eFZfq2v15f8XxE7Xy-P0l8KhLgAezwAYMAM1W--eAQXB3vkv7ve4gfFahn3sjd0GjhSL6ZDhLXBPzcZ6x-1iIEPXyyR5-8pQVBphKsMFyn2x?key=SCUjkYyfQLckob6LPOHqLQ&#34; alt=&#34;Dashboard&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We have caught hundreds of failed deployments with this approach, significantly reducing our MTTD and incident response time. Oftentimes, issues that would have become full-scale production outages, are caught and rolled back long before they would have been caught by an engineer. This type of metrics based analysis is only possible when you collect data from your applications in a consistent way.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We’ve also built automated latency and success SLIs and SLOs based on Linkerd metrics, using a combination of open source tools: &lt;a href=&#34;https://github.com/pyrra-dev/pyrra&#34;&gt;Pyrra&lt;/a&gt; and &lt;a href=&#34;https://sloth.dev/&#34;&gt;Sloth&lt;/a&gt;.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The final use case we’ll share is that we export all of the Linkerd metrics to BigQuery, and have an Application Performance Monitoring dashboard which shows us Latency and RPS for all applications since the start of us collecting Linkerd metrics. This is very useful for identifying regressions (or improvements as shown below!) over time:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXehHIprx6uX_vdy_6WJMq8YGMYwJCqxEwaDtuX38UuRmyYcsVpCRVzvakubj2uAMWPXZ51hkSxVyvZ63brzgaICpYGrPSZvCj7m0Imte9PRZiR9v2Iw5wSD4NYg8-v2ZtkqjH_mShNY2s4x6y3qrQAi5Fez?key=SCUjkYyfQLckob6LPOHqLQ&#34; alt=&#34;Dashboard&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Of course, Linkerd offers so much more than just metrics, and we have been able to utilise these features in other areas but we are barely scratching the surface of what is possible. We’ve utilised Service Profiles to define Retries and Timeouts at the Service level, meaning this becomes a uniform configuration to make an endpoint automatically retryable, allowing us to shift this logic out of application code.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;With the new advances in HTTPRoutes from Linkerd, we are excited to get into seeing how we can utilise new features such as Traffic Splitting and Fault Injection to further enhance our use of the service mesh.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;You can read more about our experience using Linkerd for monitoring at &lt;a href=&#34;https://tech.loveholidays.com/linkerd-at-loveholidays-monitoring-our-apps-using-linkerd-metrics-fa44c13bee49&#34;&gt;Linkerd at loveholidays — Monitoring our apps using Linkerd metrics&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Achieving metrics nirvana.. and increasing the conversion rate by 2.61%&amp;nbsp;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;A great user journey is at the heart of everything we do, with a fast search being crucial to the holiday browsing experience for our customers. And as mentioned above, search response time has a direct correlation with customer conversion rate. A refactor of our internal content repository tooling with a decreased P95 search time resulted in a 2.61% increase in conversion, based on a 50% traffic split A/B test. Based on the numbers published in the &lt;a href=&#34;https://www.caa.co.uk/atol-protection/check-an-atol/atol-reports/&#34;&gt;atol report&lt;/a&gt;, with loveholidays flying nearly 3 million passengers in 2023, this means an additional ~75,000 passengers travelled with us as a result of a faster search, all monitored and powered with the metrics produced by the Linkerd proxy.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;We love holidays and CNCF projects!&amp;nbsp;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;At loveholidays, we are big open source fans, and as such, we use many CNCF projects. Here’s a quick overview of our current CNCF stack. At the core of it all is, of course, Kubernetes. All of our production applications are hosted in Google Kubernetes Engine, with Gateway API used for all ingress traffic.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We’ve recently migrated from Flux to ArgoCD, which we use as our GitOps controller with a combination of Kustomize and Helm to deploy our manifests. We have canary analysis and automated rollbacks using Argo Rollouts, Kayenta and Spinnaker all powered by Linkerd metrics. We’ve also developed an in-house “common” Helm chart, powering all of our applications. This ensures consistent labels and resources for all applications.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Some of our workloads use KEDA to scale pods based on GCP’s Pub/Sub and/or RabbitMQ. We have processes which dump thousands of messages at once into a Pub/Sub Queue, so we use KEDA to scale up hundreds of pods at a time to rapidly handle this load.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We use Conftest / OPA as part of both our Kubernetes and Terraform pipelines. This enables us to enforce best practices as a platform team (check out &lt;a href=&#34;https://tech.loveholidays.com/enforcing-best-practice-on-self-serve-infrastructure-with-terraform-atlantis-and-policy-as-code-911f4f8c3e00&#34;&gt;Enforcing best practice on self-serve infrastructure with Terraform, Atlantis and Policy As Code&lt;/a&gt; for more details).&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We store our secrets in Hashicorp Vault, with Vault Secret Operator for Cluster integration.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Our monitoring system is fully open source. We built it with Grafana’s Mimir, Grafana, Prometheus, Loki, and Tempo. We use the prometheus-operator with kube-stack-prometheus. We also use OpenTelemetry and collect distributed tracing with otel-collector and Tempo, and Pyroscope for Application Performance Monitoring.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Known internally as Devportal, we use Backstage to keep track of our services as an internal service catalogue. We have tied Backstage “service” resources into our common Helm chart to ensure every deployment inside Kubernetes has a Backstage / Devportal reference, with quick links to the Github repository, logs, Grafana dashboards, Linkerd Viz, and so on.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Velero is used for our cluster backups, and Trivy is used to scan our container images. Kubeconform is used as part of our CI pipelines for K8s manifest validation.A combination of cert-manager and Google-managed certificates, both using Let’s Encrypt, power loveholidays’ certificates, and external-dns automates DNS record creation via Route53. We use cert-manager to generate the full certificate chain for Linkerd, which is the third part of our Linkerd blog series – &lt;a href=&#34;https://tech.loveholidays.com/linkerd-at-loveholidays-deploying-linkerd-in-a-gitops-world-c1840d7245a7&#34;&gt;Linkerd at loveholidays — Deploying Linkerd in a GitOps world&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;最终用户帖子，作者：loveholidays 高级基础设施工程师 Dan Williams&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在这篇博文中，我们将分享 loveholidays 如何利用 Linkerd 在所有服务中提供统一的指标，从而减少事件平均发现时间 (MTTD)，并通过减少搜索响应来提高客户转化率次。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;爱情假期简介&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;loveholidays 成立于 2012 年，是英国和爱尔兰最大、发展最快的在线旅行社。自 2023 年 5 月在德国市场推出以来，我们的使命是向所有人开放世界。我们的目标是为客户提供无限的选择、无与伦比的便利和不容错过的价值，提供完美的假期体验。为了实现这一目标，我们每天处理数万亿（！）个酒店/航班组合，每年有数百万乘客乘坐我们的航班。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;认识工程团队&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;loveholidays 在伦敦（英国）和杜塞尔多夫（德国）拥有约 350 名员工，其中技术和产品部门有 100 多名员工，并且我们在不断发展。我们目前的工程人员约有 60 名软件工程师和 5 名平台工程师。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;loveholidays 的工程设计基于&lt;a href=&#34;https://tech.loveholidays.com/the-5-principles-that-helped-scale-loveholidays-7ea0b0fd3df9&#34;&gt;5 个简单原则&lt;/a&gt;，体现了我们“你构建，你运行”的工程文化。我们的工程师有权拥有完整的软件交付生命周期 (SDLC)，这意味着我们公司的每位工程师都对整个旅程的每一步的服务负责，从初始设计到部署到生产、构建监控警报/仪表板和第二天的所有运营都待命。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;loveholidays 的平台基础设施团队致力于让开发者能够以自助方式进行操作。我们通过识别常见问题和摩擦点，然后使用基础设施、流程和工具来解决它们来做到这一点。我们是开源工具的大力倡导者，这意味着我们不断突破界限并致力于技术的前沿。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;我们的基础设施&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们是一支由 Google Cloud Platform 布道者组成的团队。 2018 年，我们从本地迁移到 GCP（请参阅&lt;a href=&#34;https://cloud.google.com/customers/loveholidays&#34;&gt;此处&lt;/a&gt;我们的 Google 案例研究！），我们的 100%基础设施现在位于云中。我们运行 5 个分布在生产、暂存和开发环境中的 GKE 集群，所有服务都在伦敦的一个主要区域中运行。我们正在积极致力于引入多集群、多区域架构。 &lt;a href=&#34;https://tech.loveholidays.com/gke-multi-cluster-services-one-bad-probe-away-from-disaster-62051fafe84e&#34;&gt;通过这篇博文详细了解我们的多集群扩展&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们在 5000 个产品区域内运行具有大约 300 个 Deployment/StatefulSet 的 Pod，全部由我们的开发团队管理。使用的语言、框架和工具都由团队自己管理，因此我们提供 Java、Go、Python、Rust、JavaScript、TypeScript 等语言的服务。我们的工程原则之一是“技术是达到目的的手段”，这意味着团队有权为任务选择正确的语言，而不必遵守现有标准。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们使用 Grafana 的 &lt;a href=&#34;https://grafana.com/go/observabilitycon/2022/lgtm-scale-observability-with-mimir-loki-and-tempo/&#34;&gt;LGTM 堆栈&lt;/a&gt;（ Loki、Grafana、Tempo、Mimir）可满足我们所有的可观测性需求，以及其他开源工具，例如 &lt;a href=&#34;https://prometheus-operator.dev/&#34;&gt;Prometheus-Operator&lt;/a&gt;抓取我们应用程序的指标，&lt;a href=&#34;https://argo-cd.readthedocs.io/en/stable/&#34;&gt;ArgoCD&lt;/a&gt; for GitOps 以及 &lt;a href=&#34;https://argoproj.github。 io/rollouts/&#34;&gt;Argo 部署&lt;/a&gt; 和 &lt;a href=&#34;https://github.com/spinnaker/kayenta&#34;&gt;Kayenta&lt;/a&gt; 为我们的金丝雀部署提供支持。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;借助 GitOps 支持的部署，我们每月部署到生产环境的次数超过 1500 次。我们行动迅速，但偶尔也会破坏一些东西。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;时间就是金钱；延迟就是成本&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;搜索响应时间与客户转化率（客户在我们网站上完成购买的可能性）直接相关。换句话说，监控服务的延迟和正常运行时间以发现回归或行为不良的组件对于我们来说绝对至关重要。  延迟还与基础设施成本相关，因为运行速度更快的服务成本更低。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;由于团队负责创建自己的监控仪表板和警报，因此从历史上看，每个团队都重新发明了轮子来监控其应用程序。这导致可视化不一致、查询/计算不正确或数据完全丢失。一个简单的例子是一个应用程序以每分钟请求数报告吞吐量，另一个应用程序以每秒请求数报告吞吐量。某些应用程序会以平均值记录延迟，有些应用程序会记录百分位数，例如 P5​​0/P95/P99，但甚至不会始终保持同一组百分位数。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这些小细节使得快速比较任何给定服务的性能几乎不可能，观察者必须先了解每个应用程序的仪表板，然后才能开始评估其运行状况。我们无法快速识别某个应用程序何时表现特别糟糕，这意味着新部署引入的回归的 MTTD 将对我们的销售/转化率产生直接影响。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Linkerd：解决我们不同的指标和可观察性问题&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们使用的每种语言和框架都会带来一系列新的指标和可观察性挑战。仅创建通用仪表板并不是一个选择，因为没有两个应用程序可以提供相同的功能一组指标，这就是我们决定服务网格可以帮助我们的地方。使用服务网格，我们将立即拥有一组统一的 &lt;a href=&#34;https://www.blameless.com/blog/4-sre-golden-signals-what-they-are-and-why-they-无论底层语言或工具如何，HTTP 流量的黄金信号&lt;/a&gt;（延迟、吞吐量、错误）。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;除了统一监控之外，我们知道服务网格还可以帮助我们完成路线图上的许多其他项目，例如 mTLS 身份验证、自动重试、金丝雀部署，甚至东西向多集群流量。&lt;/ p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;下一个问题是哪个服务网格？与大多数公司一样，我们决定评估 Linkerd 和 Istio，这是仅有的两个经过 CNCF 认证的服务网格。我们的团队之前曾短暂接触过 Istio 和 Linkerd，在 GKE 迁移的早期阶段尝试过实现这两种网格，但均以失败告终。我们知道 Linkerd 已被 2.0 完全重写，因此我们决定首先将其作为我们的概念验证 (PoC)。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们的核心原则之一是“投资简单”，这体现在 Linkerd 的整个理念和产品中。对于我们最初的 PoC，我们使用其 CLI 将 Linkerd 安装到我们的开发集群，添加了 Viz 插件（它在漂亮的仪表板中提供实时流量洞察），最后添加了“linkerd/inject:enabled”注释到一些部署。就是这样。 &lt;em&gt;它刚刚起作用&lt;/em&gt;。我们拥有由 sidecar Linkerd 代理生成的标准化黄金指标、保护 Pod 到 Pod 流量的 mTLS，并且我们可以使用 Tap 功能监听实时流量，所有这些都在决定在开发中安装 Linkerd 后大约 15 分钟内完成。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Linkerd 作为一款产品，通过投资于简单性，与我们处理工程的方式完全一致。我们对想要解决的问题有一个明确的目标，没有额外的复杂性或开销，我们在 PoC 阶段的发现立即表明 Linkerd 是我们要解决的问题的正确解决方案，并且整个过程Linkerd 周围的开源社区值得一提，因为每个参与其中的人都非常开放并且愿意提供帮助。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;实施&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;为了将 Linkerd 投入生产，我们采取了一种非常缓慢且经过深思熟虑的方法。我们花了六个多月的时间才实现全面覆盖，因为我们一次安装了少量应用程序，然后在生产中仔细监控这些应用程序是否有任何回归。我们的技术博客上的三部分系列详细介绍了我们的实施过程：&lt;a href=&#34;https://tech.loveholidays.com/linkerd-at-loveholidays-our-journey-to-a-product-service-mesh- 9a6cd478d395&#34;&gt;“Loveholidays 的 Linkerd — 我们的生产服务网格之旅”博客文章&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;鉴于我们出于部署的简便性和速度而选择 Linkerd，这种缓慢的方法可能看起来有悖常理。现实情况是，边缘情况是存在的，而且事情总是会发生变化。ak 以您意想不到的方式出现，因为没有两个生产环境是相同的。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在整个入门过程中，我们发现并修复了许多边缘情况问题，例如连接泄漏和内存泄漏、由于标头格式错误而导致请求被丢弃以及许多其他先前在 Linkerd 之前隐藏的网络相关问题代理暴露了它们。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我喜欢以下摘录自&lt;a href=&#34;https://linkerd.io/2-edge/tasks/debugging-502s/#why-do-these-errors-only-occur-when-linkerd- Linkerd 文档中的 is-injected&#34;&gt;调试 502s&lt;/a&gt; 页面：“&lt;em&gt;Linkerd 将连接错误转换为 HTTP 502 响应。这可能会使以前未检测到的问题突然变得可见。&lt;/em&gt;”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们的努力与 Linkerd 维护者的接受度和帮助意愿相结合，导致我们和 Linkerd 的代码中的代码修复，以解决我们发现的一些问题。随着我们的入门之旅取得进展并识别出不同的故障模式，我们添加了新的 Prometheus 和 Loki（日志）警报，以便在与服务网格相关的问题成为问题之前快速向我们发出警报。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;自 2023 年初完成上线以来，“linkerd/inject:enabled”已成为通过我们通用 Helm Chart 部署的所有新应用程序的默认设置，我们甚至不再考虑它。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们基于 Linkerd 指标构建了一个通用仪表板，自动显示所有网格应用程序：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;“黄金信号”HTTP 指标（吞吐量、延迟、错误、成功率）&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;服务到服务流量：&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;每项服务的入站流量和成功率&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;每项服务的出站流量和成功率&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;TCP 连接&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;每路由 HTTP 指标（由 ServiceProfile 驱动）&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;资源信息（Pod、CPU、内存等，通过 &lt;a href=&#34;https://github.com/kubernetes/kube-state-metrics&#34;&gt;kube-state-metrics&lt;/a&gt;）&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Linkerd 代理日志&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;...等等。所有新服务都会自动网格化，这意味着我们从部署那一刻起就为所有服务提供近乎完全的可观察性。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXcV9s_11r416x0K2q2XFEY2gtcUIL9AcD_LCaTaDcLhtyB7JvBCWFYKJncsbqMvputNEflVhskIAr2pkh6ZcRLL5E-fqxIL wXPFkKTiL_TEV9FylV3JZCUpkuY4JZ97liVBxnd3dv_33iPgndn1diVPB0Rz?key=SCUjkYyfQLckob6LPOHqLQ&#34; alt=&#34;仪表板&#34;referrerpolicy =&#34;无引荐&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;对于每个服务，我们可以查看来自和流向不同服务的流量，因此我们可以快速识别特定下游服务是否响应缓慢或出错。以前的仪表板可能会告诉我们请求失败，但无法轻松识别这些失败请求的源或目标服务。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img 解码=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXckE4VMn7rKJxWWwO87VRcZmBxsXDiTd2msXf4LIDSsue5zxQ_yvuF7p9qKD60ayRx8ucI9qsHscL9PD0M5ISdb5ydtXa9iG_0ODIo8NE h7sveRVd7F7f7Qn4ixbyOaAVyTmLlpE8nxW6eneW_JLHClUsez?key=SCUjkYyfQLckob6LPOHqLQ&#34; alt=&#34;入站 HTTP 请求&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;借助 Linkerd 的吞吐量指标，结合 Kube State Metrics 的一些 Pod 标签，我们已经能够生成识别集群内跨区域流量的仪表板，然后我们用它来优化流量并节省大量费用。网络支出。我们计划使用 Linkerd 的 &lt;a href=&#34;https://docs.buoyant.io/buoyant-enterprise-linkerd/latest/tasks/enabling-hazl/&#34;&gt;HAZL&lt;/a&gt; 来进一步减少跨区域流量。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXeXY-Madxo5DgLTOEehTDBtgcyfuBmA6ENnIO3GBfZ3v3U_1EfpR0di9JaO45ooWMqYBSHgvjwGzO_9S0lBW-f03GmON2AZV txryIQckQelt7EJO1feCecqhW09SkBvaDIw-w78zsqUOCnjHNk9-wwyUoDX?key=SCUjkYyfQLckob6LPOHqLQ&#34; alt=&#34;仪表板&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;结合使用 Argo Rollouts 和 Kayenta，我们使用 Linkerd 提供的指标来执行 Canary 部署，并在出现故障时自动回滚。新部署将使用新镜像创建 10% 的 pod，然后我们使用从新旧 pod 捕获的 Linkerd 指标来执行统计分析并在新版本升级到稳定之前识别问题。这意味着，例如，如果应用程序的 P95 响应时间与之前的稳定版本相比增加了一定%，我们可以将其视为部署失败并自动回滚。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXeV9_6ksGczLISLj2K32R5xFEeMTGNMY2DWiFavBvS82Kw-eFZfq2v15f8XxE7Xy-P0l8KhLgAezwAYMAM1W--eAQ XB3vkv7ve4gfFahn3sjd0GjhSL6ZDhLXBPzcZ6x-1iIEPXyyR5-8pQVBphKsMFyn2x?key =SCUjkYyfQLckob6LPOHqLQ&#34; alt=&#34;仪表板&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们通过这种方法发现了数百个失败的部署，显着缩短了我们的 MTTD 和事件响应时间。通常，可能会导致全面生产中断的问题早在工程师发现之前就被发现并回滚了。只有当您以一致的方式从应用程序收集数据时，这种基于指标的分析才可能实现。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们还使用开源工具组合，基于 Linkerd 指标构建了自动延迟和成功 SLI 和 SLO：&lt;a href=&#34;https://github.com/pyrra-dev/pyrra&#34;&gt;Pyrra&lt; /a&gt; 和&lt;a href=&#34;https://sloth.dev/&#34;&gt;树懒&lt;/a&gt;。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们要分享的最后一个用例是，我们将所有 Linkerd 指标导出到 BigQuery，并拥有一个应用程序性能监控仪表板，该仪表板向我们显示自我们开始收集 Linkerd 指标以来所有应用程序的延迟和 RPSs。这对于识别一段时间内的回归（或如下所示的改进！）非常有用：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXehHIprx6uX_vdy_6WJMq8YGMYwJCqxEwaDtuX38UuRmyYcsVpCRVzvakubj2uAMWPXZ51hkSxVyvZ63brzgaICpYGrPSZv Cj7m0Imte9PRZiR9v2Iw5wSD4NYg8-v2ZtkqjH_mShNY2s4x6y3qrQAi5Fez?key=SCUjkYyfQLckob6LPOHqLQ&#34; alt=&#34;仪表板&#34;referrerpolicy =&#34;无引荐&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;当然，Linkerd 提供的不仅仅是指标，我们已经能够在其他领域利用这些功能，但我们仅仅触及了可能的表面。我们利用服务配置文件在服务级别定义重试和超时，这意味着这成为使端点自动可重试的统一配置，从而允许我们将此逻辑从应用程序代码中移出。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;随着 Linkerd 在 HTTPRoutes 方面的新进展，我们很高兴看到如何利用流量分割和故障注入等新功能来进一步增强我们对服务网格的使用。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;您可以在 &lt;a href=&#34;https://tech.loveholidays.com/linkerd-at-loveholidays-monitoring-our-apps-using-linkerd-metrics-fa44c13bee49&#34; 中详细了解我们使用 Linkerd 进行监控的经验&gt;loveholidays 的 Linkerd — 使用 Linkerd 指标监控我们的应用&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;实现指标涅槃..并将转化率提高 2.61%&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;出色的用户旅程是我们所做一切的核心，快速搜索对于客户的假日浏览体验至关重要。如上所述，搜索响应时间与客户转化率直接相关。根据 50% 流量分割 A/B 测试，我们对内部内容存储库工具进行了重构，减少了 P95 搜索时间，转化率提高了 2.61%。根据 &lt;a href=&#34;https://www.caa.co.uk/atol-protection/check-an-atol/atol-reports/&#34;&gt;atol 报告&lt;/a&gt;中公布的数字，loveholidays 飞速发展到 2023 年，将有近 300 万名乘客，这意味着由于更快的搜索，将有约 75,000 名额外的乘客搭乘我们的航班，所有乘客均由 Linkerd 代理生成的指标进行监控和支持。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;我们喜欢假期和 CNCF 项目！ &lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在loveholidays，我们是开源的忠实粉丝，因此，我们使用许多 CNCF 项目。以下是我们当前 CNCF 堆栈的快速概述。当然，这一切的核心是 Kubernetes。我们所有的生产应用程序都托管在 Google Kubernetes Engine 中，网关 API 用于所有入口流量。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们最近从 Flux 迁移到 ArgoCD，我们将其用作 GitOps 控制器，并结合 Kustomize 和 Helm 来部署我们的清单。我们使用 Argo Rollouts、Kayenta 和 Spinnaker 进行金丝雀分析和自动回滚，所有这些均由 Linkerd 指标提供支持。我们还开发了一个内部 �“通用”Helm 图表，为我们所有的应用程序提供支持。这可以确保所有应用程序的标签和资源保持一致。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们的一些工作负载使用 KEDA 来扩展基于 GCP 的 Pub/Sub 和/或 RabbitMQ 的 Pod。我们的进程可以一次将数千条消息转储到 Pub/Sub 队列中，因此我们使用 KEDA 一次扩展数百个 pod，以快速处理此负载。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们使用 Conftest / OPA 作为 Kubernetes 和 Terraform 管道的一部分。这使我们能够作为平台团队实施最佳实践（查看&lt;a href=&#34;https://tech.loveholidays.com/enforcing-best-practice-on-self-serve-infrastruct-with-terraform-atlantis-and -policy-as-code-911f4f8c3e00&#34;&gt;使用 Terraform、Atlantis 和策略即代码在自助基础设施上实施最佳实践&lt;/a&gt;了解更多详细信息）。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们将机密存储在 Hashicorp Vault 中，并使用 Vault Secret Operator 进行集群集成。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们的监控系统是完全开源的。我们用 Grafana 的 Mimir、Grafana、Prometheus、Loki 和 Tempo 构建了它。我们将 prometheus-operator 与 kube-stack-prometheus 一起使用。我们还使用 OpenTelemetry 并通过 otel-collector 和 Tempo 收集分布式跟踪，以及用于应用程序性能监控的 Pyrscope。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;内部称为 Devportal，我们使用 Backstage 作为内部服务目录来跟踪我们的服务。我们已将 Backstage“服务”资源绑定到我们的通用 Helm 图表中，以确保 Kubernetes 内的每个部署都有 Backstage / Devportal 参考，以及指向 Github 存储库、日志、Grafana 仪表板、Linkerd Viz 等的快速链接。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Velero 用于我们的集群备份，Trivy 用于扫描我们的容器映像。 Kubeconform 用作我们用于 K8s 清单验证的 CI 管道的一部分。证书管理器和 Google 管理的证书的组合，两者都使用 Let’s Encrypt，为 loveholidays 的证书提供支持，而 external-dns 通过 Route53 自动创建 DNS 记录。我们使用 cert-manager 为 Linkerd 生成完整的证书链，这是我们 Linkerd 博客系列的第三部分 – &lt;a href=&#34;https://tech.loveholidays.com/linkerd-at-loveholidays-deploying-linkerd- in-a-gitops-world-c1840d7245a7&#34;&gt;loveholidays 上的 Linkerd — 在 GitOps 世界中部署 Linkerd&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Tue, 01 Oct 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【OpenTelemetry Collector: everything a developer needs to know】OpenTelemetry Collector：开发人员需要了解的一切</title>
      <link>https://www.cncf.io/blog/2024/10/07/opentelemetry-collector-everything-a-developer-needs-to-know/</link>
      <description>【&lt;p&gt;&lt;em&gt;Member post originally published on the &lt;a href=&#34;https://middleware.io/blog/opentelemetry-collector/&#34;&gt;Middleware blog&lt;/a&gt; by &lt;a href=&#34;https://middleware.io/blog/authors/keval/&#34;&gt;Keval Bhogayata&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In distributed applications with complex, resource-intensive&amp;nbsp;&lt;a href=&#34;https://middleware.io/blog/microservices-architecture/&#34;&gt;microservices&lt;/a&gt;—each of which generates a mountain of telemetry data—collecting and managing telemetry with your application can be cumbersome and inefficient. It may also lead to CPU consumption and high latency.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As a Software Development Engineer (SDE), assigning this job to the OpenTelemetry Collector is your ideal solution to tackle telemetric overload.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Read on to understand what the OpenTelemetry Collector is, how it works, its benefits, and its deployment methods.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;what-is-opentelemetry?&#34;&gt;What is OpenTelemetry?&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://middleware.io/blog/what-is-opentelemetry/&#34;&gt;OpenTelemetry (OTel)&lt;/a&gt;&amp;nbsp;is an open-source project that provides a set of APIs, libraries, SDKs, and tools for instrumenting applications and generating, collecting and exporting telemetry data (like metrics, traces and logs) to backend systems. These backend systems can include&amp;nbsp;&lt;a href=&#34;https://middleware.io/&#34;&gt;observability platforms&lt;/a&gt;, logging systems, and&amp;nbsp;&lt;a href=&#34;https://middleware.io/blog/what-is-distributed-tracing/&#34;&gt;tracing tools&lt;/a&gt;.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;OTel spawned out of the OpenTracing and OpenCensus merge with an aim to provide universal observability instrumentation for software apps while creating a unified, vendor-neutral standard for telemetry gathering, processing and collection.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;what-is-the-opentelemetry-collector-and-how-does-it-work?&#34;&gt;What is the OpenTelemetry Collector and how does it work?&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The OpenTelemetry Collector processes telemetry data from instrumented applications, acting as a vendor-agnostic hub within OTel. It eliminates the necessity for multiple agents, supporting various open-source formats and exporting data to diverse backends within the ecosystem.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://middleware.io/wp-content/uploads/2023/11/OTel-collector-architecture-diagram-1024x703.jpg&#34; alt=&#34;OTel collector architecture diagram&#34; class=&#34;wp-image-6535&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The Collector receives, processes and exports telemetry through one or more pipelines. Each pipeline contains receivers, processors, exporters, and connectors. The Collector filters, aggregates and transforms within the pipeline.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Let’s take a look at the collector’s architecture to see how it works:&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-instrumenting-applications&#34;&gt;Instrumenting applications&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Instrumentation is the first step. Instrumented apps are software applications integrated with the OpenTelemetry instrumentation library to generate telemetry data. SDEs can instrument their app manually or automatically.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Manual instrumentation involves adding&amp;nbsp;&lt;a href=&#34;https://middleware.io/blog/observability/&#34;&gt;observability&lt;/a&gt;&amp;nbsp;code to the app, then using the OTel SDK to initialize the OTel Collector and the API to instrument the app code. Automatic instrumentation involves attaching a language-specific agent to the application. The OTel agent used depends on the app’s programming language.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Receivers&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This is the first component of the OTel Collector. A Collector Pipeline must have at least one configured receiver to be valid. Receivers are responsible for ingesting telemetry data from various sources into the OTel Collector.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;They accept telemetry in preconfigured formats, translate it into formats that the OTel Collector can understand, and then send it to processors.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The OpenTelemetry Collector supports over 40 types of receivers, including the OTLP Receiver, which collects telemetry data using the OpenTelemetry Protocol (OTLP),&amp;nbsp;&lt;a href=&#34;https://zipkin.io/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Zipkin&lt;/a&gt;,&amp;nbsp;&lt;a href=&#34;https://www.jaegertracing.io/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Jaeger&lt;/a&gt;, and Prometheus.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Processors&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Processors are optional OpenTelemetry Collector Pipeline components used to perform specific tasks on telemetry data.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Where available, telemetry is sent from the receivers to processors. A processor can aggregate metrics, enrich trace data, or apply custom filtering rules.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Processors can be chained together to create a processing pipeline and are used to remove users’ PII from the collected data to enable regulatory compliance.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The OTel Collector supports several processors, three of which are:&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;The batch processor for batching telemetry before sending them out.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;The resource detection processor for collecting and identifying the instrumented app’s resource information.&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;The attribute processor for adding/modifying span,&amp;nbsp;&lt;a href=&#34;https://middleware.io/product/log-monitoring/&#34;&gt;log&lt;/a&gt;&amp;nbsp;or metric attributes for easy contextualization.&amp;nbsp;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Exporters&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Processed telemetry data is sent to exporters, which transmits them to desired backends on a pull or push basis.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;SDEs can configure different exporters for various backends. Each exporter converts telemetry from the OTLP format to the preconfigured backend-compatible format.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The OpenTelemetry Collector supports various exporter plugins and allows SDEs to customize their data based on your needs and requirements.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Connectors&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Connectors function as bridges between components of the telemetry pipelines, allowing each component to communicate with the next.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Connectors serve as exporters and receivers, consuming bogus telemetry from instrumented apps and summarizing them for faster identification of app behavior issues or consuming telemetry in one format (e.g., traces from exporters) and producing it in a different format (e.g., converted to metrics for receivers) as required.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Connectors may also be used to control telemetry routing or replicate telemetry across different&amp;nbsp;&lt;a href=&#34;https://middleware.io/platform/observability-pipeline/&#34;&gt;pipelines&lt;/a&gt;.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Simply put, once apps are instrumented using tools and frameworks from the instrumentation libraries, they generate telemetry data. The OTel Collector then receives this data (via the receiver), performs any necessary transformations or filtering (with the processor), and exports it to various backends.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The connector links each stage and converts data from one telemetry type to another where necessary.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;why-use-opentelemetry-collector?&#34;&gt;Why use OpenTelemetry Collector?&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Here are four important reasons to use the OpenTelemetry Collector in your observability environment.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Simplified instrumentation&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The OpenTelemetry Collector allows you to separate the instrumentation logic from your applications. This simplifies observability and eliminates the complexity of configuring individual instrumentation points.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Once you instrument your applications with the OpenTelemetry SDK, the Collector handles data collection, transformation, and exporting. This allows you to&amp;nbsp;&lt;a href=&#34;https://middleware.io/blog/data-driven-approach-engineering/&#34;&gt;focus on analyzing and gaining insights&lt;/a&gt;&amp;nbsp;from the collected data without worrying about the intricacies of data collection and export processes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Vendor-agnostic&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The OpenTelemetry Collector supports various data formats and backends, enabling you to switch between observability platforms or tools without modifying your applications’ instrumentation. This interoperability and compatibility feature makes it easier to integrate with your existing systems or change platforms in the future.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Performance optimization&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The Collector optimizes the telemetry data by filtering or aggregating it before exporting it, thereby reducing telemetry traffic, making it easier to identify and&amp;nbsp;&lt;a href=&#34;https://middleware.io/product/apm/&#34;&gt;resolve performance issues&lt;/a&gt;&amp;nbsp;and improving the overall performance of your&amp;nbsp;&lt;a href=&#34;https://middleware.io/product/infrastructure-monitoring/&#34;&gt;monitoring infrastructure&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Flexibility and extensibility&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The OpenTelemetry Collector offers a pluggable architecture that allows you to customize and extend its functionalities, such as adding or developing your own exporters, processors, or plugins as required. This flexibility makes it easy for you to adapt the Collector to different use cases.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;when-to-use-the-opentelemetry-collector?&#34;&gt;When to use the OpenTelemetry Collector?&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;OpenTelemetry Collector can be used in various scenarios. Listed below are some examples:&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Distributed applications&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In a distributed application, the OTel Collector can be used as a centralized component to collect telemetry data from all&amp;nbsp;&lt;a href=&#34;https://middleware.io/blog/microservices-architecture/&#34;&gt;microservices&lt;/a&gt;&amp;nbsp;and export telemetry data to the desired backends.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Multi-language environments&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;When working with applications that use different programming languages, the OpenTelemetry Collector is a consistent instrumentation approach. It can be used to standardize telemetry data collection across various languages to enable&amp;nbsp;&lt;a href=&#34;https://middleware.io/blog/opentelemetry-observability/&#34;&gt;seamless observability&amp;nbsp;&lt;/a&gt;across the entire application stack.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Legacy systems&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you have legacy systems that lack telemetry capability, the OpenTelemetry Collector can retroactively add observability without requiring significant modifications to the existing codebase.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Advanced data processing and filtering&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you need to perform data aggregation, filtering, masking or transformation, the Collector’s flexible processing capabilities allow you to tailor the telemetry data to your specific needs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Vendor-neutral instrumentation&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you are building an application that needs to work with different observability platforms or tools, using the OTel Collector ensures vendor neutrality.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Real World Example&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;At the recent&amp;nbsp;&lt;a href=&#34;https://thenewstack.io/how-adobe-uses-opentelemetry-collector/&#34;&gt;Open Source Summit North America&lt;/a&gt;, Chris Featherstone and Shubhanshu Surana stated that they use OTel Collector to track massive amounts of observability data their company collects, including metrics—330 million unique series a day, span data of 3.6 terabytes a day, and log data of over 1 petabyte a day.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Adobe implemented OpenTelemetry Collector in 2020, starting with trace ingestion and expanding to include metrics in 2021, with plans for log data integration.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Instrumentation played a pivotal role in Adobe’s strategy, with a focus on auto-instrumentation, primarily in&amp;nbsp;&lt;a href=&#34;https://middleware.io/blog/java-performance-monitoring/&#34;&gt;Java&lt;/a&gt;, using OpenTelemetry libraries. The team used custom extensions and processors, managing configurations through GitOps.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The dynamic nature of the OTel collector, which extends data to multiple destinations, earned it the moniker “Swiss Army knife of observability” in Adobe’s toolkit.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Adobe boosted operational efficiency through configuration management using Git, alongside the adoption of OpenTelemetry Operator Helm charts for infrastructure use cases.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Auto-instrumentation using OpenTelemetry Operator significantly streamlined the process, allowing engineers to instrument services automatically and marking a notable enhancement in developer productivity.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Furthermore, Adobe implemented data management and enrichment processes to handle the vast amounts of observability data. Reduction and custom processors in the OpenTelemetry Collector facilitated the enrichment and elimination of sensitive information.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Adobe employed a unique service registry to prevent service name collisions, ensuring each service’s unique identification in the tracing backend.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In terms of data distribution, the OTel Collector proved instrumental in sending data to multiple export destinations, simplifying the process for engineering teams accustomed to different processes and libraries.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Looking forward, Adobe outlined several key initiatives. Firstly, a focus on improving data quality involves eliminating unnecessary data and implementing rules to limit spans at the edge.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Secondly, rate limiting spans at the edge aim to manage the substantial data volume efficiently. Adobe envisions the shift towards trace-first troubleshooting to accelerate issue resolution within its intricate service ecosystem.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As Adobe explores further integration, including OpenTelemetry logging libraries with core application libraries, running OTel collectors as sidecars, and building trace sampling extensions at the edge, the&amp;nbsp;&lt;strong&gt;OpenTelemetry Collector&lt;/strong&gt;&amp;nbsp;remains a crucial component in their evolving observability practices.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;opentelemetry-collector-deployment-methods&#34;&gt;OpenTelemetry Collector deployment methods&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The OpenTelemetry Collector can be deployed using any of the following three methods.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Standalone deployment&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In a standalone deployment, the OpenTelemetry Collector is deployed as a separate process consisting of one or more instances of the Collector.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Distribute the load among all available collector instances using a load balancer to ensure reliable telemetry collection in standalone deployments. Standalone deployment allows SDEs to allocate dedicated resources specifically for the Collector.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;It also allows for the independent management of the collector, making it easier to update or scale as per requirement. However, this method prevents the Collector from having full visibility into the state of the system. Standalone Collectors can be run on any host or in a containerized environment, such as Docker or Kubernetes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Deploy the Collector as a standalone process by using the Docker image or binary distribution provided on the official OpenTelemetry website. To configure the collector by using a YAML configuration file, run the following command:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;yaml &#xA;version: &#39;3.8&#39;&#xA;&#xA;services: &#xA;  otel-collector:&#xA;    image: otel/opentelemetry-collector&#xA;    volumes:&#xA;      - ./config.yaml:/etc/otel/config.yaml&#xA;    ports:&#xA;      - 4317:4317&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Sidecar deployment&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In a sidecar deployment, the OpenTelemetry Collector is deployed alongside your application as a separate container or process.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Each&amp;nbsp;&lt;a href=&#34;https://middleware.io/blog/microservices-architecture/&#34;&gt;microservice&lt;/a&gt;&amp;nbsp;in your app will have a specific Collector instance, and a local host connects all instances. The collector collects telemetry data directly from the application and exports it to the desired backends.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;An advantage of this method is the Collector’s improved visibility into the state of the system.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;With a sidecar deployment, SDEs can encapsulate the telemetry collection logic within the Collector, reducing the complexity of their application code.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;It also provides isolation between the telemetry collection and the application, making it easier to add or remove instrumentation without modifying the application itself.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Configure the sidecar deployment using the following code:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;`yaml &#xA;version: &#39;3.8&#39;&#xA;&#xA;services: &#xA;  my-app:&#xA;    image: my-app-image:latest&#xA;    ports:&#xA;      - 8080:8080&#xA;  otel-collector:&#xA;    image: otel/opentelemetry-collector&#xA;    volumes:&#xA;      - ./config.yaml:/etc/otel/config.yaml&#xA;    depends_on:&#xA;      - my-app&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Agent deployment&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The&amp;nbsp;&lt;strong&gt;OpenTelemetry Collector&lt;/strong&gt;&amp;nbsp;is embedded within an existing monitoring agent or agent framework in an agent deployment. This deployment method provides a&amp;nbsp;&lt;a href=&#34;https://middleware.io/platform/unified-experience/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;unified solution for monitoring&lt;/a&gt;&amp;nbsp;and telemetry data collection.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The agent utilizes existing infrastructure and monitoring tools to collect and export telemetry data. This approach consolidates data collection and reduces the complexity of managing separate components for monitoring and telemetry collection.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Configure the collector by extending the agent’s configuration file or utilizing specific configuration properties provided by the agent framework.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Here’s a sample configuration file for the agent with an embedded OpenTelemetry Collector.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;&#xA; yaml &#xA;agent:&#xA;  collectors:&#xA;    telemetry:&#xA;      otel:&#xA;        config:&#xA;          receivers:&#xA;            otlp:&#xA;              protocols:&#xA;                grpc:&#xA;          exporters:&#xA;            jaeger:&#xA;              endpoint: http://jaeger:14268/api/traces&#xA;          processors:&#xA;            batch:&#xA;              timeout: 1s&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Here is a sample application code for an agent deployment with an embedded OpenTelemetry Collector using Python:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;&#xA;`python &#xA;from opentelemetry import trace&#xA;from opentelemetry.exporter.otlp.trace_exporter import OTLPSpanExporter&#xA;from opentelemetry.sdk.trace import TracerProvider&#xA;from opentelemetry.sdk.trace.export import BatchSpanProcessor&#xA;&#xA;# Initialize the agent with an embedded OpenTelemetry Collector&#xA;agent_config = {&#xA;    # Specify the agent configuration&#xA;    &#34;config&#34;: &#34;&#34;&#xA;}&#xA;&#xA;agent.init_agent(agent_config)&#xA;&#xA;# Configure the OpenTelemetry SDK&#xA;provider = TracerProvider()&#xA;trace.set_tracer_provider(provider)&#xA;&#xA;# Configure the OTLP exporter&#xA;exporter = OTLPSpanExporter(endpoint=&#34;http://localhost:4317&#34;)&#xA;span_processor = BatchSpanProcessor(exporter)&#xA;provider.add_span_processor(span_processor)&#xA;&#xA;# Your application code here&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Ensure you have your `config.yaml` file properly configured and adjust paths, image names, and ports based on your specific setup.&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Agent deployments are secure, flexible and efficient for telemetry collection. Agents can be configured to operate within set boundaries to avoid security breaches.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;They can be configured to work with other tools or customized as required. Since they do not run on multiple collector instances and are lightweight, they consume very minimal system resources.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;connecting-opentelemetry-collector-with-middleware&#34;&gt;Connecting OpenTelemetry Collector with Middleware&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://middleware.io/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Middleware&lt;/a&gt;&amp;nbsp;is an AI-powered monitoring and observability platform that allows developers to visualize and analyze collected telemetry data.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Connecting OTel Collector with Middleware&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;To connect the OpenTelemetry Collector with Middleware,&amp;nbsp;&lt;a href=&#34;https://app.middleware.io/auth/register/&#34;&gt;create an account&lt;/a&gt;&amp;nbsp;or log in to Middleware.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;You will start off on the unified view dashboard once you have logged in:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://middleware.io/wp-content/uploads/2023/11/MW-Unified-Platform-1-1024x870.png&#34; alt=&#34;Default dashboard in Middleware&#34; class=&#34;wp-image-6496&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;2. Navigate to the installation page in the bottom left corner to&amp;nbsp;&lt;a href=&#34;https://docs.middleware.io/agent-installation/overview&#34;&gt;Install the Middleware agent&lt;/a&gt;&amp;nbsp;(MW Agent) on your host infrastructure and begin to explore your data.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://middleware.io/wp-content/uploads/2023/11/MW-Installation-1-1024x572.png&#34; alt=&#34;How to install Middleware agent&#34; class=&#34;wp-image-6497&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;The MW Agent is a lightweight software that runs on your host infrastructure, collecting and sending events and metrics to Middleware. It collects real-time data at the system and process levels to provide detailed insights into host performance and behavior.&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;3. &amp;nbsp;Copy and run the installation command. If you’re using docker, run the command example below. Copying the command directly from the installation page ensures your API key and UID are accurately inputted.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p&gt;Check our documentation for installation commands for other environments such as&amp;nbsp;&lt;a href=&#34;https://docs.middleware.io/agent-installation/windows&#34;&gt;Windows&lt;/a&gt;,&amp;nbsp;&lt;a href=&#34;https://docs.middleware.io/agent-installation/linux&#34;&gt;Linux&lt;/a&gt;, etc.&amp;nbsp;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt; MW_API_KEY=   MW_TARGET=https://.middleware.io:443 bash -c &#34;$(curl -L https://install.middleware.io/scripts/docker-install.sh)&#34;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;4. Verify the status of the MW Agent with the following command.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;docker  ps -a --filter ancestor=ghcr.io/middleware-labs/mw-host-agent:master&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&amp;nbsp;A successful installation returns the status ‘Up’ or ‘Exited’. If the installation is unsuccessful, the status will be blank.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://middleware.io/wp-content/uploads/2023/11/MW-Status-up-1-1024x338.jpg&#34; alt=&#34;Middleware Agent Installation successful message&#34; class=&#34;wp-image-6498&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Configuring Middleware’s OTel Data Injection API&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Configure custom metrics using OpenTelemetry and the Middleware data ingestion API.&amp;nbsp;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The OpenTelemetry Ingestion API has two endpoints: metrics and logs. For both endpoints, the resource type attribute groups the ingested data under the specified label on Middleware dashboards and reports.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol start=&#34;2&#34; class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;The Metrics endpoint lets you send custom metrics to the Middleware backend. To send custom metrics to Middleware, POST to the following endpoint.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;POST https://&amp;lt;UID&amp;gt;.middleware.io/v1/metrics&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol start=&#34;3&#34; class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Navigate to OpenTelemetry Metrics to view the following example of a curl request sending a custom metric, swap-usage, to Middleware.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://middleware.io/wp-content/uploads/2023/11/MW-OTel-Metrics-1-1024x641.png&#34; alt=&#34; OpenTelemetry Collector for Metrics&#34; class=&#34;wp-image-6499&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;&#xA; curl -X POST  &#34;https://demo.middleware.io/v1/metrics&#34; \&#xA;-H &#34;Accept: application.json&#34; \&#xA;-H &#34;Content-type: application.json&#34; \&#xA;-d @ &amp;lt;&amp;lt; EOF&#xA;{&#xA;    &#34;resource_metrics&#34;: [&#xA;        {&#xA;            &#34;resource&#34;: {&#xA;                &#34;attributes&#34;: [&#xA;                    {&#xA;                        &#34;key&#34;: &#34;mw.account_key&#34;,&#xA;                        &#34;value&#34;: {&#xA;                            &#34;string_value&#34;: &#34;xxxxxxxxxx&#34;&#xA;                        }&#xA;                    },&#xA;                    {&#xA;                        &#34;key&#34;: &#34;mw.resource_type&#34;,&#xA;                        &#34;value&#34;: {&#xA;                            &#34;string_value&#34;: &#34;custom&#34;&#xA;                        }&#xA;                    }&#xA;                ]&#xA;            },&#xA;            &#34;scope_metrics&#34;: [&#xA;                {&#xA;                    &#34;metrics&#34;: [&#xA;                        {&#xA;                            &#34;name&#34;: &#34;swap-usage&#34;,&#xA;                            &#34;description&#34;: &#34;SWAP Usage&#34;,&#xA;                            &#34;unit&#34;: &#34;bytes&#34;,&#xA;                            &#34;gauge&#34;: {&#xA;                                &#34;data_points&#34;: [&#xA;                                    {&#xA;                                        &#34;attributes&#34;: [&#xA;                                            {&#xA;                                                &#34;key&#34;: &#34;device&#34;,&#xA;                                                &#34;value&#34;: {&#xA;                                                    &#34;string_value&#34;: &#34;nvme0n1p4&#34;&#xA;                                                }&#xA;                                            }&#xA;                                        ],&#xA;                                        &#34;start_time_unix_nano&#34;: 1673435153000000000,&#xA;                                        &#34;time_unix_nano&#34;: 1673435153000000000,&#xA;                                        &#34;asInt&#34;: 400500678&#xA;                                    }&#xA;                                ]&#xA;                            }&#xA;                        }&#xA;                    ]&#xA;                }&#xA;            ]&#xA;        }&#xA;    ]&#xA;}&#xA;EOF &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;4. There are two components for metrics: metadata and datapoint. The metadata fields are attributes that define the metric and determine how it will appear in Middleware. The datapoint fields are defined within the data attribute. The datapoint fields are consistent across all data attribute types and can be Gauges, Sums, Histograms or Summaries.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;5. The Logs endpoint lets you send custom logs to the Middleware backend. To send custom logs to Middleware, POST to the following endpoint.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;POST https://&amp;lt;UID&amp;gt;.middleware.io:443/v1/logs&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;6. Navigate to OpenTelemetry Logs to view the following example of a curl request sending custom logs to Middleware.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://middleware.io/wp-content/uploads/2023/11/MW-OTel-Logs-1-1024x571.png&#34; alt=&#34; OpenTelemetry Collector for Logs&#34; class=&#34;wp-image-6500&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;&#xA;curl -X POST  &#34;https://demo.middleware.io:443/v1/logs&#34; \&#xA;-H &#34;Accept: application/json&#34; \&#xA;-H &#34;Content-type: application/json&#34; \&#xA;-d @- &amp;lt;&amp;lt; EOF&#xA;{&#xA;   &#34;resource_logs&#34;: [&#xA;      {&#xA;         &#34;resource&#34;: {&#xA;            &#34;attributes&#34;: [&#xA;               {&#xA;                  &#34;key&#34;: &#34;mw.account_key&#34;,&#xA;                  &#34;value&#34;: {&#xA;                     &#34;string_value&#34;: &#34;xxxxxxxxxx&#34;&#xA;                  }&#xA;               },&#xA;               {&#xA;                  &#34;key&#34;: &#34;mw.resource_type&#34;,&#xA;                  &#34;value&#34;: {&#xA;                     &#34;string_value&#34;: &#34;custom&#34;&#xA;                  }&#xA;               },&#xA;               {&#xA;                  &#34;key&#34;: &#34;service_name&#34;,&#xA;                  &#34;value&#34;: {&#xA;                     &#34;string_value&#34;: &#34;nginx-123&#34;&#xA;                  }&#xA;               }&#xA;            ]&#xA;         },&#xA;         &#34;scope_logs&#34;: [&#xA;            {&#xA;               &#34;log_records&#34;: [&#xA;                  {&#xA;                     &#34;severity_text&#34;: &#34;WARN&#34;,&#xA;                     &#34;body&#34;: {&#xA;                        &#34;string_value&#34;: &#34;upstream server not accepting request&#34;&#xA;                     },&#xA;                     &#34;severity_number&#34;: &#34;11&#34;,&#xA;                     &#34;attributes&#34;: [&#xA;                        {&#xA;                           &#34;key&#34;: &#34;server&#34;,&#xA;                           &#34;value&#34;: {&#xA;                              &#34;string_value&#34;: &#34;nginx&#34;&#xA;                           }&#xA;                        }&#xA;                     ],&#xA;                     &#34;time_unix_nano&#34;: &#34;1694030143000&#34;&#xA;                  }&#xA;               ]&#xA;            }&#xA;         ]&#xA;      }&#xA;   ]&#xA;}&#xA;EOF  &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;7. Navigate to the Middleware app’s homepage and scroll to “view dashboard.” Click on it to ensure metrics, traces, and logs are appearing in the Unified Dashboard.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://middleware.io/wp-content/uploads/2023/11/MW-View-Dashboard-1-1024x476.png&#34; alt=&#34;Navigating to view custom dashboard&#34; class=&#34;wp-image-6501&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;8. Click on Unified Dashboard:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://middleware.io/wp-content/uploads/2023/11/OTel-Unified-Dashboard-1-1024x476.png&#34; alt=&#34;Unified Dashboard, Middleware&#34; class=&#34;wp-image-6502&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;9. You’ll see your metrics, logs, and traces on the Middleware Unified Dashboard with end-to-end visibility.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://middleware.io/wp-content/uploads/2023/11/MW-Unified-OTel-1-1024x476.png&#34; alt=&#34;Middleware Unified Dashboard with end-to-end visibility&#34; class=&#34;wp-image-6503&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;For more about Middleware configuration, check our&amp;nbsp;&lt;a href=&#34;https://docs.middleware.io/docs/&#34;&gt;documentation&lt;/a&gt;.&amp;nbsp;&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;final-thoughts-on-opentelemetry-collector&#34;&gt;Final thoughts on OpenTelemetry Collector&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The OTel Collector simplifies and harmonizes the SDE’s observability responsibilities. Middleware further improves the Collector’s efficiency with its unified end-to-end view of telemetry data in a single user-friendly dashboard.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The AI-based platform allows you to customize telemetry gathering and visualization, ensuring that the telemetry you collect serves your specific use case.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://middleware.io/&#34;&gt;Middleware&lt;/a&gt;&amp;nbsp;regularly updates its agent with new, exciting features for improved observability into app performance.&amp;nbsp;&lt;a href=&#34;https://app.middleware.io/auth/register/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Try Middleware for free&lt;/a&gt;!&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;成员帖子最初由 &lt;a href=&#34;https://middleware 发布在 &lt;a href=&#34;https://middleware.io/blog/opentelemetry-collector/&#34;&gt;中间件博客&lt;/a&gt;上.io/blog/authors/keval/&#34;&gt;Keval Bhogayata&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在具有复杂、资源密集型&lt;a href=&#34;https://middleware.io/blog/microservices-architecture/&#34;&gt;微服务&lt;/a&gt;的分布式应用程序中（每个微服务都会生成大量遥测数据）使用应用程序管理遥测可能既麻烦又低效。它还可能导致 CPU 消耗和高延迟。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;作为软件开发工程师 (SDE)，将此工作分配给 OpenTelemetry Collector 是解决遥测过载问题的理想解决方案。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;继续阅读以了解 OpenTelemetry Collector 是什么、它的工作原理、它的优点以及它的部署方法。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;what-is-opentelemetry?&#34;&gt;什么是 OpenTelemetry？&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://middleware.io/blog/what-is-opentelemetry/&#34;&gt;OpenTelemetry (OTel)&lt;/a&gt; 是一个开源项目，提供一组 API、库、SDK以及用于检测应用程序以及生成、收集遥测数据并将其导出到后端系统的工具。这些后端系统可以包括&lt;a href=&#34;https://middleware.io/&#34;&gt;可观察性平台&lt;/a&gt;、日志系统和&lt;a href=&#34;https://middleware.io/blog/what-is-分布式跟踪/&#34;&gt;跟踪工具&lt;/a&gt;。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;OTel 源于 OpenTracing 和 OpenCensus 合并，旨在为软件应用程序提供通用的可观测性工具，同时为遥测收集、处理和收集创建统一的、供应商中立的标准。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;what-is-the-opentelemetry-collector-and-how-does-it-work?&#34;&gt;什么是 OpenTelemetry Collector 以及它如何工作？&lt;/h2 &gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;OpenTelemetry Collector 处理来自仪表化应用程序的遥测数据，充当 OTel 内与供应商无关的中心。它消除了使用多个代理的必要性，支持各种开源格式并将数据导出到生态系统内的不同后端。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://middleware.io/wp-content/uploads/2023/11/OTel-collector-architecture-diagram-1024x703。 jpg&#34; alt=&#34;OTel 采集器架构图&#34; class=&#34;wp-image-6535&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;收集器通过一个或多个管道接收、处理和导出遥测数据。每个管道包含接收器、处理器、导出器和连接器。收集器在管道内进行过滤、聚合和转换。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;让我们看一下收集器的架构，看看它是如何工作的：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;h-instrumenting-applications&#34;&gt;检测应用程序&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;检测是第一步。仪表化应用程序是与集成的软件应用程序h OpenTelemetry 仪器库来生成遥测数据。 SDE 可以手动或自动检测其应用程序。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;手动检测涉及向应用添加&lt;a href=&#34;https://middleware.io/blog/observability/&#34;&gt;可观察性&lt;/a&gt;代码，然后使用 OTel SDK 初始化 OTel Collector 和 API检测应用程序代码。自动检测涉及将特定于语言的代理附加到应用程序。使用的 OTel 代理取决于应用程序的编程语言。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;接收者&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这是 OTel Collector 的第一个组件。收集器管道必须至少有一个已配置的接收器才有效。接收器负责将各种来源的遥测数据采集到 OTel 收集器中。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;它们接受预配置格式的遥测数据，将其转换为 OTel 收集器可以理解的格式，然后将其发送到处理器。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;OpenTelemetry Collector 支持 40 多种类型的接收器，包括 OTLP 接收器，它使用 OpenTelemetry 协议 (OTLP) 收集遥测数据，&lt;a href=&#34;https://zipkin.io/&#34; target=&#34;_blank&#34; rel =&#34;noreferrer noopener&#34;&gt;Zipkin&lt;/a&gt;、&lt;a href=&#34;https://www.jaegertracing.io/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Jaeger&lt;/a&gt; 和 Prometheus。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;处理器&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;处理器是可选的 OpenTelemetry Collector Pipeline 组件，用于对遥测数据执行特定任务。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果可用，遥测数据会从接收器发送到处理器。处理器可以聚合指标、丰富跟踪数据或应用自定义过滤规则。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;处理器可以链接在一起以创建处理管道，并用于从收集的数据中删除用户的 PII，以实现监管合规性。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;OTel Collector 支持多种处理器，其中三个是：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;批处理器，用于在发送遥测数据之前对其进行批处理。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;资源检测处理器，用于收集和识别已检测应用的资源信息。 &lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;属性处理器，用于添加/修改跨度、&lt;a href=&#34;https://middleware.io/product/log-monitoring/&#34;&gt;日志&lt;/a&gt;或指标属性，以方便上下文化。 &lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;出口商&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;处理后的遥测数据被发送到导出器，导出器以拉或推的方式将它们传输到所需的后端。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;SDE 可以为不同的后端配置不同的导出器。每个导出器将遥测数据从 OTLP 格式转换为预配置的后端兼容格式。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;OpenTelemetry Collector 支持各种导出器插件，并允许 SDE 根据您的需要和要求自定义其数据。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;连接器&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;连接器充当组件之间的桥梁遥测管道，允许每个组件与下一个组件进行通信。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;连接器充当导出器和接收器，使用来自仪表应用程序的虚假遥测数据并对其进行汇总，以便更快地识别应用程序行为问题或以一种格式（例如，来自导出器的跟踪）使用遥测数据并以不同的格式（例如，转换后的数据）生成它根据需要调整接收者的指标。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;连接器还可用于控制遥测路由或跨不同&lt;a href=&#34;https://middleware.io/platform/observability-pipeline/&#34;&gt;管道&lt;/a&gt;复制遥测。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;简单地说，一旦使用检测库中的工具和框架对应用程序进行检测，它们就会生成遥测数据。然后，OTel Collector 接收该数据（通过接收器），执行任何必要的转换或过滤（使用处理器），并将其导出到各个后端。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;连接器链接每个阶段，并在必要时将数据从一种遥测类型转换为另一种遥测类型。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;why-use-opentelemetry-collector?&#34;&gt;为什么使用 OpenTelemetry Collector？&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;以下是在可观测环境中使用 OpenTelemetry Collector 的四个重要原因。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;简化的检测&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;OpenTelemetry Collector 允许您将检测逻辑与应用程序分开。这简化了可观测性并消除了配置单个检测点的复杂性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;使用 OpenTelemetry SDK 检测应用程序后，收集器将处理数据收集、转换和导出。这样您就可以&lt;a href=&#34;https://middleware.io/blog/data-driven-approach-engineering/&#34;&gt;专注于从收集的数据中分析和获取见解&lt;/a&gt;，而无需担心数据的复杂性收集和导出流程。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;与供应商无关&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;OpenTelemetry Collector 支持各种数据格式和后端，使您能够在可观测平台或工具之间切换，而无需修改应用程序的仪器。这种互操作性和兼容性功能使您可以更轻松地与现有系统集成或将来更改平台。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;性能优化&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;收集器通过在导出之前过滤或聚合遥测数据来优化遥测数据，从而减少遥测流量，从而更容易识别和解决性能问题问题&lt;/a&gt;并提高&lt;a href=&#34;https://middleware.io/product/infrastruct-monitoring/&#34;&gt;监控基础设施&lt;/a&gt;的整体性能。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;灵活性和可扩展性&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;OpenTelemetry Collector 提供可插入架构，允许您自定义和扩展其功能，例如根据需要添加或开发您自己的导出器、处理器或插件。这种灵活性使您可以轻松地使收集器适应不同的用例。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;when-to-use-the-opentelemetry-collector?&#34;&gt;何时使用 OpenTelemetry Collector？&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;OpenTelemetry Collector可用于各种场景。下面列出了一些示例：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;分布式应用程序&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在分布式应用程序中，OTel Collector 可用作集中式组件，从所有&lt;a href=&#34;https://middleware.io/blog/microservices-architecture/&#34;&gt;微服务&lt;/a&gt;收集遥测数据并将遥测数据导出到所需的后端。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;多语言环境&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在处理使用不同编程语言的应用程序时，OpenTelemetry Collector 是一种一致的检测方法。它可用于标准化各种语言的遥测数据收集，从而在整个应用程序堆栈中实现&lt;a href=&#34;https://middleware.io/blog/opentelemetry-observability/&#34;&gt;无缝可观察性&lt;/a&gt;。&lt;/p &gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;旧系统&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您的旧系统缺乏遥测功能，OpenTelemetry Collector 可以追溯性地添加可观测性，而无需对现有代码库进行重大修改。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;高级数据处理和过滤&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您需要执行数据聚合、过滤、屏蔽或转换，收集器灵活的处理功能可让您根据您的特定需求定制遥测数据。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;供应商中立的工具&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您正在构建需要与不同可观测平台或工具配合使用的应用程序，则使用 OTel Collector 可确保供应商中立性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;现实世界示例&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在最近的&lt;a href=&#34;https://thenewstack.io/how-adobe-uses-opentelemetry-collector/&#34;&gt;北美开源峰会&lt;/a&gt;上，Chris Featherstone 和 Shubhanshu Surana 表示他们使用OTel Collector 用于跟踪其公司收集的大量可观测数据，包括指标 - 每天 3.3 亿个独特的系列、每天 3.6 TB 的跨度数据以及每天超过 1 PB 的日志数据。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Adobe 于 2020 年实施了 OpenTelemetry Collector，从跟踪摄取开始，并在 2021 年扩展到包括指标，并计划进行日志数据集成。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;检测在 Adob​​e 的战略中发挥了关键作用，重点是自动检测，主要是在&lt;a href=&#34;https://middleware.io/blog/java-performance-monitoring/&#34;&gt;Java&lt;/a&gt; ，使用 OpenTelemetry 库。该团队使用自定义扩展和处理器，通过 GitOps 管理配置。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;OTel 收集器的动态特性，可将数据扩展到 m多个目的地，使其在 Adob​​e 工具包中赢得了“可观察性瑞士军刀”的绰号。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Adobe 通过使用 Git 进行配置管理以及针对基础设施用例采用 OpenTelemetry Operator Helm 图表来提高运营效率。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;使用 OpenTelemetry Operator 进行自动检测显着简化了流程，使工程师能够自动检测服务，并显着提高了开发人员的工作效率。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;此外，Adobe 还实施了数据管理和丰富流程来处理大量可观测数据。 OpenTelemetry Collector 中的减少和自定义处理器有助于丰富和消除敏感信息。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Adobe 采用了独特的服务注册表来防止服务名称冲突，确保每个服务在跟踪后端中具有唯一的标识。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在数据分发方面，事实证明，OTel Collector 在将数据发送到多个导出目的地方面发挥了重要作用，简化了习惯于不同流程和库的工程团队的流程。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;展望未来，Adobe 概述了几项关键举措。首先，注重提高数据质量，包括消除不必要的数据并实施规则来限制边缘的跨度。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;其次，边缘的速率限制旨在有效管理大量数据。 Adobe 设想转向跟踪优先故障排除，以加速其复杂的服务生态系统中的问题解决。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;随着 Adob​​e 探索进一步集成，包括 OpenTelemetry 日志记录库与核心应用程序库、将 OTel 收集器作为 sidecar 运行以及在边缘构建跟踪采样扩展，&lt;strong&gt;OpenTelemetry Collector&lt;/strong&gt; 仍然是其不断发展的关键组件可观察性实践。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;opentelemetry-collector-deployment-methods&#34;&gt;OpenTelemetry Collector 部署方法&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;可以使用以下三种方法中的任何一种来部署 OpenTelemetry Collector。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;独立部署&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在独立部署中，OpenTelemetry Collector 部署为由一个或多个收集器实例组成的单独进程。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;使用负载均衡器在所有可用收集器实例之间分配负载，以确保独立部署中可靠的遥测收集。独立部署允许 SDE 专门为收集器分配专用资源。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;它还允许独立管理收集器，从而更容易根据要求进行更新或扩展。但是，此方法会阻止收集器完全了解系统状态。独立收集器可以在任何主机或容器化环境（例如 Docker 或 Kubernetes）中运行。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;D使用官方 OpenTelemetry 网站上提供的 Docker 映像或二进制发行版将收集器部署为独立进程。要使用 YAML 配置文件配置收集器，请运行以下命令：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;yaml &#xA;版本：&#39;3.8&#39;&#xA;&#xA;服务： &#xA;  酒店收藏家：&#xA;    图片：otel/opentelemetry-collector&#xA;    卷：&#xA;      - ./config.yaml:/etc/otel/config.yaml&#xA;    端口：&#xA;      - 4317:4317&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Sidecar 部署&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在 sidecar 部署中，OpenTelemetry Collector 作为单独的容器或进程与您的应用程序一起部署。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;应用中的每个&lt;a href=&#34;https://middleware.io/blog/microservices-architecture/&#34;&gt;微服务&lt;/a&gt;都会有一个特定的Collector实例，并且本地主机连接所有实例。收集器直接从应用程序收集遥测数据并将其导出到所需的后端。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;此方法的优点是收集器提高了对系统状态的可见性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;通过 sidecar 部署，SDE 可以将遥测收集逻辑封装在收集器中，从而降低应用程序代码的复杂性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;它还提供遥测收集和应用程序之间的隔离，从而可以更轻松地添加或删除检测，而无需修改应用程序本身。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;使用以下代码配置 sidecar 部署：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;`yaml &#xA;版本：&#39;3.8&#39;&#xA;&#xA;服务： &#xA;  我的应用程序：&#xA;    图像：我的应用程序图像：最新&#xA;    端口：&#xA;      - 8080:8080&#xA;  酒店收藏家：&#xA;    图片：otel/opentelemetry-collector&#xA;    卷：&#xA;      - ./config.yaml:/etc/otel/config.yaml&#xA;    取决于：&#xA;      - 我的应用程序&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;代理部署&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;OpenTelemetry Collector&lt;/strong&gt;嵌入在代理部署中的现有监控代理或代理框架中。此部署方法提供&lt;a href=&#34;https://middleware.io/platform/unified-experience/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;用于监控和遥测数据收集的统一解决方案&lt;/a&gt;。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;代理利用现有的基础设施和监控工具来收集和导出遥测数据。这种方法整合了数据收集，并降低了管理用于监控和遥测收集的单独组件的复杂性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;通过扩展代理的配置文件或利用代理框架提供的特定配置属性来配置收集器。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;以下是带有嵌入式 OpenTelemetry Collector 的代理的示例配置文件。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;&#xA; yaml &#xA;代理人：&#xA;  收藏家：&#xA;    遥测：&#xA;      酒店：&#xA;        配置：&#xA;          接收者：&#xA;            奥特普：&#xA;              协议：&#xA;                组：&#xA;          出口商：&#xA;            耶格尔：端点：http://jaeger:14268/api/traces&#xA;          处理器：&#xA;            批：&#xA;              超时时间：1秒&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;以下是使用 Python 进行带有嵌入式 OpenTelemetry Collector 的代理部署的示例应用程序代码：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;&#xA;`蟒蛇 &#xA;从 opentelemetry 导入跟踪&#xA;从 opentelemetry.exporter.otlp.trace_exporter 导入 OTLPSpanExporter&#xA;从 opentelemetry.sdk.trace 导入 TracerProvider&#xA;从 opentelemetry.sdk.trace.export 导入 BatchSpanProcessor&#xA;&#xA;# 使用嵌入式 OpenTelemetry Collector 初始化代理&#xA;代理配置={&#xA;    # 指定代理配置&#xA;    “配置”：“”&#xA;}&#xA;&#xA;代理.init_agent(代理配置)&#xA;&#xA;# 配置 OpenTelemetry SDK&#xA;提供者 = TracerProvider()&#xA;跟踪.set_tracer_provider（提供者）&#xA;&#xA;# 配置 OTLP 导出器&#xA;导出器 = OTLPSpanExporter(端点=“http://localhost:4317”)&#xA;span_processor = BatchSpanProcessor（导出器）&#xA;提供商.add_span_processor（span_processor）&#xA;&#xA;# 这里是你的应用程序代码&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;确保您正确配置了“config.yaml”文件，并根据您的具体设置调整路径、图像名称和端口。&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;代理部署对于遥测收集来说是安全、灵活和高效的。代理可以配置为在设定的边界内运行，以避免安全漏洞。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;它们可以配置为与其他工具一起使用或根据需要进行自定义。由于它们不在多个收集器实例上运行并且是轻量级的，因此它们消耗的系统资源非常少。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;connecting-opentelemetry-collector-with-middleware&#34;&gt;将 OpenTelemetry Collector 与中间件连接&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://middleware.io/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;中间件&lt;/a&gt; 是一个人工智能驱动的监控和可观察平台，允许开发者可视化和分析收集的遥测数据。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;将 OTel Collector 与中间件连接&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;要将 OpenTelemetry Collector 与中间件连接，请&lt;a href=&#34;https://app.middleware.io/auth/register/&#34;&gt;创建帐户&lt;/a&gt;或登录中间件。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;登录后，您将开始使用统一视图仪表板：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://middleware.io/wp-content/uploads/2023/11/MW-Unified-Platform-1-1024x870。 png&#34; alt=&#34;中间件中的默认仪表板&#34; class=&#34;wp-image-6496&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;2.导航至左下角的安装页面，在主机基础架构上&lt;a href=&#34;https://docs.middleware.io/agent-installation/overview&#34;&gt;安装中间件代理&lt;/a&gt;（MW Agent），然后开始探索您的数据。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://middleware.io/wp-content/uploads/2023/11/MW-Installation-1-1024x572.png&#34; alt=&#34;如何安装中间件代理&#34; class=&#34;wp-image-6497&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;MW Agent 是一款轻量级软件，在您的主机基础设施上运行，收集事件和指标并将其发送到中间件。它收集系统和进程级别的实时数据，以提供有关主机性能和行为的详细见解。&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;3.  复制并运行安装命令。如果您使用的是 docker，请运行下面的命令示例。直接从安装页面复制命令可确保您的 API 密钥和 UID 准确输入。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p&gt;查看我们的文档，了解其他环境的安装命令，例如 &lt;a href=&#34;https://docs.middleware.io/agent-installation/windows&#34;&gt;Windows&lt;/a&gt;、&lt;a href=&#34;https:// /docs.middleware.io/agent-installation/linux&#34;&gt;Linux&lt;/a&gt; 等&lt;/p&gt;&#xA;&lt;/块引用&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt; MW_API_KEY= MW_TARGET=https://.middleware.io:443 bash -c &#34;$(curl -L https://install.middleware. io/scripts/docker-install.sh)&#34;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;4.使用以下命令验证 MW Agent 的状态。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;docker ps -a --filter祖先=ghcr.io/middleware-labs/mw-host-agent:master&lt;/code&gt;&lt;/pre &gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt; 成功安装会返回状态“Up”或“Exited”。如果安装不成功，状态将为空白。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://middleware.io/wp-content/uploads/2023/11/MW-Status-up-1-1024x338。 jpg&#34; alt=&#34;中间件代理安装成功消息&#34; class=&#34;wp-image-6498&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;配置中间件的 OTel 数据注入 API&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;使用 OpenTelemetry 和中间件数据提取 API 配置自定义指标。 &lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;OpenTelemetry Ingestion API 有两个端点：指标和日志。对于这两个端点，资源类型属性将摄取的数据分组到中间件仪表板和报告上的指定标签下。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol start=&#34;2&#34; class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;指标端点允许您将自定义指标发送到中间件后端。要将自定义指标发送到中间件，请 POST 到以下端点。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;POST https://&lt;UID&gt;.middleware.io/v1/metrics&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol start=&#34;3&#34; class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;导航到 OpenTelemetry Metrics 查看以下向中间件发送自定义指标（交换使用情况）的curl 请求示例。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://middleware.io/wp-content/uploads/2023/11/MW-OTel-Metrics-1-1024x641。 png&#34; alt=&#34; OpenTelemetry Collector for Metrics&#34; class=&#34;wp-image-6499&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;&#xA; 卷曲-X POST“https://demo.middleware.io/v1/metrics”\&#xA;-H“接受：application.json”\&#xA;-H“内容类型：application.json”\&#xA;-d@&lt;&lt;EOF&#xA;{&#xA;    “资源指标”：[&#xA;        {&#xA;            “资源”：{&#xA;                “属性”： [&#xA;                    {&#xA;                        &#34;key&#34;: &#34;mw.account_key&#34;,&#xA;                        “价值”： {&#xA;                            “字符串值”：“xxxxxxxxx”&#xA;                        }&#xA;                    },&#xA;                    {&#xA;                        &#34;key&#34;: &#34;mw.resource_type&#34;,&#xA;                        “价值”： {&#xA;                            “字符串值”：“自定义”&#xA;                        }&#xA;                    }&#xA;                ]&#xA;            },&#xA;            “范围指标”：[&#xA;                {&#xA;                    “指标”：[&#xA;                        {&#xA;                            &#34;name&#34;: &#34;交换使用&#34;,&#xA;                            &#34;description&#34;: &#34;交换使用&#34;,&#xA;                            “单位”：“字节”，&#xA;                            “测量”： {&#xA;                                “数据点”：[&#xA;                                    {&#xA;                                        “属性”： [&#xA;                                            {&#xA;                                                “密钥”：“设备”，&#xA;                                                “价值”： {&#xA;                                                    “字符串值”：“nvme0n1p4”&#xA;                                                }&#xA;                                            }&#xA;                                        ],&#xA;                                        “start_time_unix_nano”：1673435153000000000，&#xA;                                        “time_unix_nano”：1673435153000000000，&#xA;                                        “asInt”：400500678&#xA;                                    }&#xA;                                ]&#xA;                            }&#xA;                        }&#xA;                    ]&#xA;                }&#xA;            ]&#xA;        }&#xA;    ]&#xA;}&#xA;EOF &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;4.指标有两个组成部分：元数据和数据点。元数据字段是定义指标并确定其在中间件中显示方式的属性。数据点字段在数据属性内定义。数据点字段在所有数据属性类型中都是一致的，可以是仪表、总和、直方图或摘要。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;5.日志端点允许您将自定义日志发送到中间件后端。要将自定义日志发送到中间件，请 POST 到以下端点。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;POST https://&lt;UID&gt;.middleware.io:443/v1/logs&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;6.导航到 OpenTelemetry Logs 以查看以下将自定义日志发送到中间件的curl 请求示例。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://middleware.io/wp-content/uploads/2023/11/MW-OTel-Logs-1-1024x571。 png&#34; alt=&#34; OpenTelemetry Collector for Logs&#34; class=&#34;wp-image-6500&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;&#xA;卷曲-X POST“https://demo.middleware.io:443/v1/logs”\&#xA;-H“接受：application/json”\&#xA;-H“内容类型：application/json”\&#xA;-d @- &lt;&lt; EOF&#xA;{&#xA;   “资源日志”：[&#xA;      {&#xA;         “资源”：{&#xA;            “属性”： [&#xA;               {&#xA;                  &#34;key&#34;: &#34;mw.account_key&#34;,&#xA;                  “价值”： {&#xA;                     “字符串值”：“xxxxxxxxx”&#xA;                  }&#xA;               },&#xA;               {&#xA;                  &#34;key&#34;: &#34;mw.resource_type&#34;,&#xA;                  “价值”： {&#xA;                     “字符串值”：“自定义”&#xA;                  }&#xA;               },&#xA;               {&#xA;                  “密钥”：“服务名称”，&#xA;                  “价值”： {&#xA;                     “字符串值”：“nginx-123”&#xA;                  }&#xA;               }&#xA;            ]&#xA;         },&#xA;         “范围日志”：[&#xA;            {&#xA;               “日志记录”：[&#xA;                  {&#xA;                     &#34;severity_text&#34;: &#34;警告&#34;,&#xA;                     “身体”： {&#xA;                        &#34;string_value&#34;: &#34;上游服务器不接受请求&#34;&#xA;                     },&#xA;                     “severity_number”：“11”，&#xA;                     “属性”： [&#xA;                        {&#xA;                           “密钥”：“服务器”，&#xA;                           “价值”： {&#xA;                              “字符串值”：“nginx”&#xA;                           }&#xA;                        }&#xA;                     ],&#xA;                     “time_unix_nano”：“1694030143000”&#xA;                  }&#xA;               ]&#xA;            }&#xA;         ]&#xA;      }&#xA;   ]&#xA;}&#xA;EOF  &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;7.导航到中间件应用程序的主页并滚动到“查看仪表板”。单击它可确保指标、跟踪和日志显示在统一仪表板中。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://middleware.io/wp-content/uploads/2023/11/MW-View-Dashboard-1-1024x476。 png&#34; alt=&#34;导航到查看自定义仪表板&#34; class=&#34;wp-image-6501&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;8.单击统一仪表板：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://middleware.io/wp-content/uploads/2023/11/OTel-Unified-Dashboard-1-1024x476。 png&#34; alt=&#34;统一仪表板，中间件&#34; class=&#34;wp-image-6502&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;9.您将在中间件统一仪表板上看到具有端到端可见性的指标、日志和跟踪。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://middleware.io/wp-content/uploads/2023/11/MW-Unified-OTel-1-1024x476。 png&#34; alt=&#34;具有端到端可见性的中间件统一仪表板&#34; class=&#34;wp-image-6503&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;有关中间件配置的更多信息请查看我们的&lt;a href=&#34;https://docs.middleware.io/docs/&#34;&gt;文档&lt;/a&gt;。 &lt;/图标题&gt;&lt;/图&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;final-thoughts-on-opentelemetry-collector&#34;&gt;关于 OpenTelemetry Collector 的最终想法&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;OTel Collector 简化并协调了 SDE 的可观测性职责。中间件进一步提高了Collector 在单个用户友好的仪表板中通过统一的端到端遥测数据视图提高了效率。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;基于人工智能的平台允许您自定义遥测数据收集和可视化，确保您收集的遥测数据服务于您的特定用例。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://middleware.io/&#34;&gt;中间件&lt;/a&gt;定期更新其代理，提供令人兴奋的新功能，以提高应用性能的可观察性。 &lt;a href=&#34;https://app.middleware.io/auth/register/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;免费试用中间件&lt;/a&gt;！&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Sun, 06 Oct 2024 16:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>