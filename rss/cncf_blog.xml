<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>CNCF - Blog</title>
    <link>http://rsshub.rssforever.com/cncf</link>
    <description>CNCF - Blog - Powered by RSSHub</description>
    <managingEditor>contact@rsshub.app (RSSHub)</managingEditor>
    <item>
      <title>【Announcing the results of the Karmada security audit】宣布Karmada安全审核的结果</title>
      <link>https://www.cncf.io/blog/2025/01/16/announcing-the-results-of-the-karmada-security-audit/</link>
      <description>【&lt;p&gt;&lt;em&gt;Community post cross-posted on the &lt;a href=&#34;https://ostif.org/karmada-audit-complete/&#34;&gt;OSTIF blog&lt;/a&gt; by Helen Woeste, Communications Manager, the Open Source Technology Improvement Fund&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://ostif.org/&#34;&gt;OSTIF&lt;/a&gt; is proud to share the results of our security audit of &lt;a href=&#34;https://karmada.io/&#34;&gt;Karmada&lt;/a&gt;. Karmada is an open source Kubernetes orchestration system for running cloud-native applications seamlessly across different clouds and clusters. With the help of &lt;a href=&#34;https://www.shielder.com/&#34;&gt;Shielder&lt;/a&gt; and the &lt;a href=&#34;https://www.cncf.io/&#34;&gt;Cloud Native Computing Foundation (CNCF)&lt;/a&gt;, this project offers users improved open, multi-cloud, multi-cluster Kubernetes management.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Audit Process:&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;While Karmada is a part of the Kubernetes ecosystem and therefore utilizes Kubernetes libraries and implementations, the focus of this particular work was on the overall security health of the custom implementations of Karmada and its third party dependencies. Karmada’s function utilizes multiple components, CLI tools, and add ons to extend the standard Kubernetes features, which can be customized from deployment to deployment. This makes Karmada’s attack scenarios complex, so it was necessary to perform a scoped threat modelling in order to evaluate potential attack surfaces. Utilizing this custom threat model and a combination of manual, tooling, and dynamic review, Shielder identified six findings with security impact on the project.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Audit Results:&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;6 Findings&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;1 High, 1 Medium, 2 Low, 2 Informational&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Recommendations for Future Efforts&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Proposal for Long-term Improvements to Overall Security&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The Karmada maintainer team worked quickly and in tandem with Shielder to resolve and fix the reported issues. Their work on behalf of the project was meticulous and mindful of users as well as relevant third-party dependencies and projects. They published necessary advisories and alerted users as to the impact and resolution of this audit. OSTIF wishes them the best of luck on their journey to graduated status with the CNCF.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Thank you&lt;/strong&gt; to the individuals and groups that made this engagement possible:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Karmada maintainers and community: especially Hongcai Ren, Kevin Wang, and Zhuang Zhang&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Shielder: Abdel Adim “Smaury” Oisfi, Pietro Tirenna, Davide Silvetti&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;The Cloud Native Computing Foundation&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Everyone around the world depends on open source software. If you’re interested in financially supporting this critical work, contact amir@ostif.org.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;开源社区通信经理 Helen Woeste 在 &lt;a href=&#34;https://ostif.org/karmada-audit-complete/&#34;&gt;OSTIF 博客&lt;/a&gt;上交叉发布的社区帖子技术改进基金&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://ostif.org/&#34;&gt;OSTIF&lt;/a&gt; 很自豪地分享我们对 &lt;a href=&#34;https://karmada.io/&#34;&gt;Karmada 进行安全审核的结果&lt;/a&gt;。 Karmada 是一个开源 Kubernetes 编排系统，用于跨不同云和集群无缝运行云原生应用程序。在 &lt;a href=&#34;https://www.shielder.com/&#34;&gt;Shielder&lt;/a&gt; 和 &lt;a href=&#34;https://www.cncf.io/&#34;&gt;云原生计算基金会 ( CNCF）&lt;/a&gt;，该项目为用户提供改进的开放、多云、多集群 Kubernetes 管理。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;审核流程：&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;虽然 Karmada 是 Kubernetes 生态系统的一部分，因此利用 Kubernetes 库和实现，但这项特定工作的重点是 Karmada 自定义实现及其第三方依赖项的整体安全健康状况。 Karmada 的功能利用多个组件、CLI 工具和附加组件来扩展标准 Kubernetes 功能，这些功能可以在部署之间进行自定义。这使得 Karmada 的攻击场景变得复杂，因此有必要执行范围威胁建模来评估潜在的攻击面。利用此自定义威胁模型以及手动、工具和动态审查的组合，Shielder 确定了对项目安全影响的六项发现。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;审核结果：&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;6 项调查结果&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;1 个高、1 个中、2 个低、2 个信息&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;对未来工作的建议&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;关于长期改进整体安全性的提案&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Karmada 维护团队与 Shielder 快速合作，解决并修复了报告的问题。他们代表该项目的工作非常细致，并考虑到用户以及相关的第三方依赖项和项目。他们发布了必要的建议，并提醒用户此次审计的影响和解决方案。 OSTIF 祝愿他们在 CNCF 毕业之路上一切顺利。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;感谢&lt;/strong&gt;促成此次参与的个人和团体：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Karmada 维护者和社区：尤其是 Hongcai Ren、Kevin Wang 和 Zhuang Zhu&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Shielder：Abdel Adim “Smaury” Oisfi、Pietro Tirenna、Davide Silvetti&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;云原生计算基金会&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;世界各地的每个人都依赖开源软件。如果您有兴趣为这项重要工作提供经济支持，请联系 amir@ostif.org。&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-风格-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Wed, 15 Jan 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Meet the winners of our first Cloud Native Heroes Challenge】认识我们第一个云土著英雄挑战赛的获胜者</title>
      <link>https://www.cncf.io/blog/2025/01/22/meet-the-winners-of-our-first-cloud-native-heroes-challenge/</link>
      <description>【&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;em&gt;Get their best advice on beating patent trolls at their own game&lt;/em&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We’re delighted to announce the winners of our first Cloud Native Heroes Challenge!&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In that &lt;a href=&#34;https://www.cncf.io/blog/2024/11/13/announcing-the-cloud-native-heroes-challenge/&#34;&gt;first challenge&lt;/a&gt;, we asked participants to find prior art that would undermine the patent on a distributed software networking system. With a new contest of a type that’s new to our community, we weren’t sure what to expect, but, no surprise the CNCF community came through and in the end we had three winners from 3 different continents, two of whom were happy to share insights about their process and experiences.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;In first place&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Our first place winner, who asked not to be identified, found &lt;a href=&#34;https://www.cncf.io/heroes/participation-instructions/#what-is-prior-art&#34;&gt;prior art&lt;/a&gt; from a virtualization environment that analyzes and manages data from virtual machines. Like the target patent, it allows for the use of APIs, and it was filed a few months before the target patent. Our partner in this process, &lt;a href=&#34;https://www.unifiedpatents.com/&#34;&gt;Unified Patents&lt;/a&gt;, was satisfied this submission would “check all the boxes” and undermine the validity of the patent troll’s efforts.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Battling patent trolls by *diagramming sentences*&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Chris Buccella, one of our two-second place winners, has searched for prior art as part of a previous job, so he’s no stranger to this. He decided to join the challenge because he has a “personal disdain” for patent trolls and also because he wants to contribute to CNCF. “I’m a user of CNCF projects, but not a code contributor,” he wrote. “So I was looking for some other way I could make a positive impact.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The biggest challenge he ran into was actually deciphering the patent claims because “the terminology used is often intentionally vague and non-standard. No one would write a user story like this!” His old school tactic? Diagram the sentence structure, rewrite the clauses and then paraphrase. Those efforts broke down the complicated claims into something that was just plain English.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;He also warned about the reality of “link rot.”&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“Release notes from just five years ago are ancient history, and can be difficult to surface,” Buccella wrote in an email. “Domains expire, redirects fail, and code repos are sometimes restructured. It takes some detective work.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For those new to looking for prior art, Buccella strongly suggests looking beyond patents. “Prior art doesn’t have to be other patents. The main asset we have being in the tech community is that we’ve all used and developed lots of different software over the course of our careers. New projects pop up frequently. With that broad exposure to different technologies, we have first-hand knowledge of how a lot of different technologies work. There are many nearly-forgotten (or even failed) projects from the past that are good examples of prior art. And thanks to being open source, publicly-accessible code repos provide timestamped proof of when the software was written. This is ideal. The code is out there… the key part we can play is to connect the dots.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Academic research skills for the win&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Our other second-place winner, Emidio Neto, was brand new to the world of patent trolls and prior art but he described the entire process as very “fun” and he enjoyed it so much he hopes to participate in the next challenge.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Neto, who was talked into this contest by a professor, said he leaned into his background in SDN to help him find the winning prior art. The biggest challenge was wading through all the papers trying to find something that pre-dated the target patent.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;His best advice for those new to searching for prior art? Always check the references! “Authors of papers usually have references, so check those references and see where they lead you to on the Internet,” Neto suggested. “And don’t overlook powerpoints or other presentations – those are all good places to look for prior art.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Feeling inspired to go after some patent trolls? It’s not too late to enter our &lt;a href=&#34;https://www.cncf.io/blog/2025/01/22/announcing-the-second-cloud-native-heroes-challenge/&#34;&gt;current Cloud Native Heroes Challenge&lt;/a&gt;!&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;em&gt;获取他们关于在自己的游戏中击败专利流氓的最佳建议&lt;/em&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们很高兴宣布首届云原生英雄挑战赛的获奖者！&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在&lt;a href=&#34;https://www.cncf.io/blog/2024/11/13/announcing-the-cloud-native-heroes-challenge/&#34;&gt;第一个挑战&lt;/a&gt;中，我们要求参与者找到会破坏分布式软件网络系统专利的现有技术。对于我们的社区来说，这是一种全新类型的新竞赛，我们不确定会发生什么，但是 CNCF 社区的成功并不令人意外，最终我们选出了来自 3 个不同大洲的三名获胜者，其中两人很高兴分享有关他们的流程和经验的见解。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;第一名&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们要求匿名的第一名获奖者发现了&lt;a href=&#34;https://www.cncf.io/heroes/participation-instructions/#what-is-prior-art&#34;&gt;现有技术&lt; /a&gt; 来自分析和管理来自虚拟机的数据的虚拟化环境。与目标专利一样，它允许使用 API，并且是在目标专利前几个月提交的。我们在此过程中的合作伙伴 &lt;a href=&#34;https://www.unifiedpatents.com/&#34;&gt;Unified Patents&lt;/a&gt; 很满意此提交内容将“选中所有复选框”并破坏专利流氓努力的有效性.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;通过*图解句子*打击专利流氓&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;克里斯·布塞拉（Chris Buccella）是我们的二等奖获得者之一，他在之前的工作中曾搜索过现有技术，所以他对此并不陌生。他决定加入挑战，因为他对专利流氓有“个人蔑视”，也因为他想为 CNCF 做出贡献。 “我是 CNCF 项目的用户，但不是代码贡献者，”他写道。 “所以我一直在寻找其他可以产生积极影响的方式。”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;他遇到的最大挑战实际上是破译专利权利要求，因为“所使用的术语通常故意含糊且不标准。没有人会写这样的用户故事！”他的老派策略？绘制句子结构图，重写从句，然后进行释义。这些努力将复杂的主张分解为简单的英语。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;他还警告了“链接失效”的现实。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“五年前的发行说明已经成为古老的历史，可能很难浮出水面，”布塞拉在一封电子邮件中写道。 “域名过期、重定向失败、代码存储库有时会被重组。这需要一些侦探工作。”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;对于那些刚开始寻找现有技术的人，Buccella 强烈建议不要只关注专利。 “现有技术不一定是其他专利。我们在技术社区拥有的主要资产是，我们在职业生涯中都使用和开发了许多不同的软件。新项目频繁涌现。凭借如此广泛的接触不同的技术，我们拥有许多不同技术如何工作的第一手知识。过去有许多几乎被遗忘（甚至失败）的项目都是现有技术的好例子。由于是开源的，可公开访问的代码存储库提供了软件编写时间的带时间戳的证明。这是理想的。代码就在那里……我们可以发挥的关键部分是将这些点连接起来。”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;获胜的学术研究技能&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们的另一位第二名获得者 Emidio Neto 对专利流氓和现有技术的世界是全新的，但他形容整个过程非常“有趣”，他非常喜欢它，他希望参加下一个挑战.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Neto 在一位教授的劝说下参加了这次比赛，他说他依靠自己的 SDN 背景来帮助他找到获胜的现有技术。最大的挑战是费力地浏览所有论文，试图找到早于目标专利的内容。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;对于那些刚开始搜索现有技术的人来说，他的最佳建议是什么？一定要检查参考文献！ “论文的作者通常都有参考文献，因此请检查这些参考文献，看看它们会引导您在互联网上找到什么，”内托建议道。 “并且不要忽视幻灯片或其他演示文稿 - 这些都是寻找现有技术的好地方。”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;受到启发去追捕一些专利流氓吗？现在加入我们的&lt;a href=&#34;https://www.cncf.io/blog/2025/01/22/announcing-the-second-cloud-native-heroes-challenge/&#34;&gt;当前的云原生英雄还为时不晚挑战&lt;/a&gt;！&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Tue, 21 Jan 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Migrating from DIY ELK to a full SaaS platform】从 DIY ELK 迁移到完整的 SaaS 平台</title>
      <link>https://www.cncf.io/blog/2025/01/24/migrating-from-diy-elk-to-a-full-saas-platform/</link>
      <description>【&lt;p&gt;&lt;em&gt;Member post originally published on the &lt;a href=&#34;https://logz.io/blog/migrating-from-diy-elk-to-a-full-saas-platform/?utm_medium=referral&amp;amp;utm_source=cncf&#34;&gt;Logz.io blog&lt;/a&gt; by Jade Lassery&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Managing modern systems requires a constant balance between operational efficiency and innovation; going a little further, maintaining seamless operations and delivering exceptional customer experiences increasingly depend on ensuring robust observability.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For years, the ELK stack (Elasticsearch, Logstash, Kibana) has been the go-to solution for many organizations for log management and observability, offering flexibility control and an open source approach. However, as organizations scale and their data demands grow, maintaining ELK often becomes a real challenge, requiring more resources, generating higher costs and driving increasing complexity.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Shifting to a full SaaS observability platform — purpose-built solutions designed to simplify operations, enhance insights and scale effortlessly — offers a strategic alternative. The shift allows businesses to&amp;nbsp;&lt;a href=&#34;https://logz.io/case-studies/eliminating-elk-downtime-and-improving-productivity/?utm_medium=referral&amp;amp;utm_source=TNS&amp;amp;utm_campaign=tns_spon_4&amp;amp;utm_content=case-study&#34;&gt;offload the operational challenges of DIY ELK&lt;/a&gt;, enabling teams to focus on delivering value instead of maintaining infrastructure.&amp;nbsp; It’s not just about swapping tools, it’s about transforming the way you approach observability to support long-term business success by aggregating innovation and managed capabilities.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Common Issues Teams Face with DIY ELK&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To begin understanding the migration process, it’s important to understand the common issues teams face with ELK that cause them to look at migrating in the first place.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As organizations expand, their data requirements become more demanding. Scaling a DIY ELK stack to handle increasing log volumes and infrastructure requirements can lead to performance issues, data loss, downtime and creating a constant need for manual intervention. SaaS platforms, on the other hand, manage all the hurdles for you, automatically scaling to accommodate growing data levels, reducing operational complexity and ensuring near-seamless performance.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In addition, operating and maintaining a DIY ELK stack also means handling constant updates, security patches and rebalancing of infrastructure — tasks that consume time and resources. SaaS platforms handle these tasks in the background, allowing teams to focus on strategic work. Moreover, while DIY ELK might seem cost-effective initially, hidden expenses for scaling, maintenance and management can add up. SaaS platforms offer&amp;nbsp;&lt;a href=&#34;https://logz.io/solutions/reduce-observability-costs/&#34;&gt;predictable observability pricing, simplifying budget management&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;SaaS Observability Platform Benefits Over DIY ELK&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;A significant benefit of moving to a SaaS platform is access to advanced features that go beyond traditional log management. Many SaaS observability platforms provide&amp;nbsp;&lt;a href=&#34;https://logz.io/platform/?utm_medium=referral&amp;amp;utm_source=TNS&amp;amp;utm_campaign=tns_spon_4&amp;amp;utm_content=platform&amp;amp;utm_term=unified&#34;&gt;integrated solutions for logs, metrics and traces&lt;/a&gt;&amp;nbsp;in one unified interface. These platforms now also frequently leverage&amp;nbsp;&lt;a href=&#34;https://logz.io/platform/features/observability-iq/?utm_medium=referral&amp;amp;utm_source=TNS&amp;amp;utm_campaign=tns_spon_4&amp;amp;utm_content=feature&amp;amp;utm_term=IQ&#34;&gt;AI-powered observability tools&lt;/a&gt;&amp;nbsp;for anomaly detection and root cause analysis (RCA) to quickly surface issues —- reducing time spent troubleshooting and enabling proactive incident management.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Beyond these operational benefits, SaaS platforms also offer enhanced security and compliance features that can be difficult and costly to implement with a DIY stack. With built-in encryption, access controls and industry certifications (such as SOC 2, GDPR compliance, etc), SaaS providers help ensure that your data remains secure and meets regulatory standards, without requiring additional overhead from your internal teams.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;When is it Time to Migrate from DIY ELK?&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;There are many factors to consider for when it might be the correct time to migrate from a DIY ELK stack to a SaaS platform. Here are some things to watch out for:&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;📈&amp;nbsp;&lt;a href=&#34;https://logz.io/case-studies/how-ziprecruiter-boosted-sre-productivity-with-logz-io/?utm_medium=referral&amp;amp;utm_source=TNS&amp;amp;utm_campaign=tns_spon_4&amp;amp;utm_content=case-study&#34;&gt;&lt;strong&gt;Data growth is overwhelming&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;:&lt;/strong&gt;&amp;nbsp;Your ELK stack struggles to keep up with increasing data volumes, leading to slow query times and infrastructure strain.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;🤯&amp;nbsp;&lt;a href=&#34;https://logz.io/case-studies/eliminating-elk-downtime-and-improving-productivity/&#34;&gt;&lt;strong&gt;Operational complexity is draining resources&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;:&lt;/strong&gt;&amp;nbsp;Managing and maintaining the stack is consuming your DevOps team’s time, leaving little room for innovation.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;💰&amp;nbsp;&lt;a href=&#34;https://logz.io/case-studies/essential-observability-from-logz-io-helps-monoova-keep-the-money-flowing/?utm_medium=referral&amp;amp;utm_source=TNS&amp;amp;utm_campaign=tns_spon_4&amp;amp;utm_content=case-study&#34;&gt;&lt;strong&gt;Costs are escalating or unpredictable&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;:&lt;/strong&gt;&amp;nbsp;Infrastructure, storage and operational expenses are becoming unpredictable and hard to justify.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;⚙️&amp;nbsp;&lt;a href=&#34;https://logz.io/case-studies/egress-partners-with-logz-io-for-easy-cost-effective-observability/&#34;&gt;&lt;strong&gt;Unified and advanced observability is needed&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;:&lt;/strong&gt;&amp;nbsp;Siloed tools for logs, metrics and traces make it challenging to diagnose and resolve issues quickly.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;🛡️&amp;nbsp;&lt;a href=&#34;https://logz.io/case-studies/jacada-reduce-security-risks/&#34;&gt;&lt;strong&gt;Security or compliance is a concern&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;:&lt;/strong&gt;&amp;nbsp;You need advanced security features or compliance certifications that are difficult to implement in a DIY stack.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Once you’ve identified that your stack is no longer meeting your needs — whether due to scaling issues, rising costs, or operational inefficiencies — the next step is to start planning your migration to a SaaS platform. Making this shift doesn’t have to be overwhelming, but it does require careful consideration and a strategic approach.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Here are the key steps that you can use as a baseline to ensure a smooth transition:&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt;: &lt;strong&gt;Evaluate your needs:&lt;/strong&gt;&amp;nbsp;Understand what you need from your observability stack. Are you looking for better scalability, advanced features, simplified management? What else?&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;2&lt;/strong&gt;: &lt;strong&gt;Choose the right platform:&amp;nbsp;&lt;/strong&gt;Not all SaaS platforms are built equal. Here’s a tip: look for one that offers:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Native integrations with your current tools such as Logstash, Beats or OpenTelemetry.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Unified support for logs, metrics, traces and extra visualizations.&amp;nbsp;&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;AI-powered insights and automation.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://logz.io/from-diy-elk-to-effortless-observability/?utm_medium=referral&amp;amp;utm_source=TNS&amp;amp;utm_campaign=tns_spon_4&amp;amp;utm_content=lp&amp;amp;utm_term=elk&#34;&gt;Platforms like Logz.io&lt;/a&gt;, for example, support the same ingestion methods as ELK, so you can reuse your existing configurations with minimal changes, besides providing advanced capabilities like root cause analysis to help businesses proactively manage their systems with minimal effort.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;3&lt;/strong&gt;: &lt;strong&gt;Plan and test:&amp;nbsp;&lt;/strong&gt;Begin by setting up the SaaS platform alongside your existing ELK stack. Test data ingestion using a subset of your logs or metrics to validate compatibility and performance.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;4&lt;/strong&gt;: &lt;strong&gt;Migrate gradually:&amp;nbsp;&lt;/strong&gt;Move workloads incrementally, starting with non-critical systems. Once the process is stable and workflows are optimized, transition critical systems.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;5&lt;/strong&gt;: &lt;strong&gt;Recreate dashboards and alerts:&amp;nbsp;&lt;/strong&gt;Export dashboards and alerts from ELK and import them into the new managed platform. Take advantage of pre-built templates and advanced alerting options to refine your observability strategy.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;6&lt;/strong&gt;: &lt;strong&gt;Optimize and train:&lt;/strong&gt;&amp;nbsp;Ensure your team is trained on the new platform and continue optimizing configurations to align with your needs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;7&lt;/strong&gt;: &lt;strong&gt;Decommission DIY ELK:&amp;nbsp;&lt;/strong&gt;Once all systems are successfully migrated, phase out your ELK infrastructure, archiving historical data in an external storage if needed.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Unlocking Long Term Observability Value&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://logz.io/from-diy-elk-to-effortless-observability/?utm_medium=referral&amp;amp;utm_source=TNS&amp;amp;utm_campaign=tns_spon_4&amp;amp;utm_content=lp&amp;amp;utm_term=elk&#34;&gt;Migrating to a SaaS observability platform&lt;/a&gt;&amp;nbsp;is more than just a technical upgrade or getting everything up and running. It’s a strategic decision that drives long-term value. By offloading operational complexity, businesses can focus on innovation, improve system reliability and enhance customer experiences.Organizations that make this shift often find they’re not just solving operational headaches, they’re positioning themselves for&amp;nbsp;&lt;a href=&#34;https://logz.io/case-studies/rubrik-case-study/?utm_medium=referral&amp;amp;utm_source=TNS&amp;amp;utm_campaign=tns_spon_4&amp;amp;utm_content=case-study&#34;&gt;scalable, data-driven growth&lt;/a&gt;. It’s a step toward making observability a seamless enabler of success, rather than a persistent challenge.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;会员帖子最初发布于&lt;a href=&#34;https://logz.io/blog/migration-from-diy-elk-to-a-full-saas-platform/?utm_medium=referral&amp;utm_source= cncf&#34;&gt;Logz.io 博客&lt;/a&gt; 作者：Jade Lassery&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;管理现代系统需要在运营效率和创新之间保持持续的平衡；更进一步，维持无缝运营和提供卓越的客户体验越来越依赖于确保强大的可观察性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;多年来，ELK 堆栈（Elasticsearch、Logstash、Kibana）一直是许多组织的日志管理和可观察性首选解决方案，提供灵活性控制和开源方法。然而，随着组织规模的扩大和数据需求的增长，维护 ELK 通常成为一个真正的挑战，需要更多的资源，产生更高的成本并导致复杂性不断增加。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;转向完整的 SaaS 可观察性平台（旨在简化运营、增强洞察力并轻松扩展的专用解决方案）提供了一种战略替代方案。这一转变允许企业&lt;a href=&#34;https://logz.io/case-studies/elimination-elk-downtime-and-improving-productivity/?utm_medium=referral&amp;utm_source=TNS&amp;utm_campaign=tns_spon_4&amp;utm_content=case-study&#34;&gt;卸载DIY ELK&lt;/a&gt; 的运营挑战，使团队能够专注于提供价值而不是维护基础设施。  这不仅仅是交换工具，而是改变您实现可观察性的方式，通过聚合创新和管理能力来支持长期业务成功。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;团队在使用 DIY ELK 时面临的常见问题&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;要开始了解迁移过程，重要的是要了解团队在使用 ELK 时面临的常见问题，这些问题促使他们首先考虑迁移。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;随着组织规模的扩大，其数据要求变得更加苛刻。扩展 DIY ELK 堆栈来处理不断增加的日志量和基础设施要求可能会导致性能问题、数据丢失、停机，并不断需要手动干预。另一方面，SaaS 平台可以为您解决所有障碍，自动扩展以适应不断增长的数据水平，降低运营复杂性并确保近乎无缝的性能。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;此外，操作和维护 DIY ELK 堆栈还意味着处理不断的更新、安全补丁和基础设施的重新平衡，这些任务会消耗时间和资源。 SaaS 平台在后台处理这些任务，使团队能够专注于战略工作。此外，虽然 DIY ELK 最初看起来可能具有成本效益，但扩展、维护和管理的隐性费用可能会增加。 SaaS 平台提供&lt;a href=&#34;https://logz.io/solutions/reduce-observability-costs/&#34;&gt;可预测的可观测性定价，简化预算管理&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;SaaS 可观察性与 DIY ELK 相比的平台优势&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;迁移到 SaaS 平台的一个显着好处是可以访问超越传统日志管理的高级功能。许多 SaaS 可观测性平台在一个统一的界面中提供&lt;a href=&#34;https://logz.io/platform/?utm_medium=referral&amp;utm_source=TNS&amp;utm_campaign=tns_spon_4&amp;utm_content=platform&amp;utm_term=unified&#34;&gt;日志、指标和跟踪的集成解决方案&lt;/a&gt; 。这些平台现在还经常利用&lt;a href=&#34;https://logz.io/platform/features/observability-iq/?utm_medium=referral&amp;utm_source=TNS&amp;utm_campaign=tns_spon_4&amp;utm_content=feature&amp;utm_term=IQ&#34;&gt;人工智能驱动的可观察性工具&lt;/a&gt;用于异常检测和根本原因分析 (RCA)，以快速发现问题 —- 减少故障排除和实现主动事件所花费的时间管理。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;除了这些运营优势之外，SaaS 平台还提供增强的安全性和合规性功能，而使用 DIY 堆栈实施这些功能可能会很困难且成本高昂。借助内置加密、访问控制和行业认证（例如 SOC 2、GDPR 合规性等），SaaS 提供商可帮助确保您的数据保持安全并符合监管标准，而无需内部团队承担额外费用。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;什么时候从 DIY ELK 迁移？&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;何时是从 DIY ELK 堆栈迁移到 SaaS 平台的正确时机需要考虑许多因素。以下是一些需要注意的事项：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;📈 &lt;a href=&#34;https://logz.io/case-studies/how-ziprecruiter-boosted-sre-productivity-with-logz-io/?utm_medium=referral&amp;utm_source=TNS&amp;utm_campaign=tns_spon_4&amp;utm_content=case-study&#34; &gt;&lt;strong&gt;数据增长势不可挡&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;：&lt;/strong&gt;您的ELK 堆栈难以跟上不断增长的数据量，导致查询时间缓慢和基础设施紧张。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;🤯 &lt;a href=&#34;https://logz.io/case-studies/elimination-elk-downtime-and-improving-productivity/&#34;&gt;&lt;strong&gt;操作复杂性正在耗尽资源&lt;/strong&gt;&lt;/a &gt;&lt;strong&gt;：&lt;/strong&gt; 管理和维护堆栈会消耗 DevOps 团队的时间，几乎没有创新空间。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;💰 &lt;a href=&#34;https://logz.io/case-studies/essential-observability-from-logz-io-helps-monoova-keep-the-money-flowing/?utm_medium=referral&amp;utm_source=TNS&amp;utm_campaign= tns_spon_4&amp;utm_content=case-study&#34;&gt;&lt;strong&gt;成本不断上升或不可预测&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;：&lt;/strong&gt;基础设施、存储和运营费用变得不可预测且难以证明其合理性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;⚙️ &lt;a href=&#34;https://logz.io/case-studies/egress-partners-with-logz-io-for-easy-cost-efficient-observability/&#34;&gt;&lt;strong&gt;统一且先进的可观察性需要&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;：&lt;/strong&gt; 日志、指标和跟踪的孤立工具使得诊断和解决问题变得困难很快。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;🛡️ &lt;a href=&#34;https://logz.io/case-studies/jacada-reduce-security-risks/&#34;&gt;&lt;strong&gt;安全或合规性是一个问题&lt;/strong&gt;&lt;/a&gt;&lt;strong &gt;：&lt;/strong&gt; 您需要高级安全功能或合规性认证，而这些功能很难在 DIY 堆栈中实现。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;一旦您发现您的堆栈不再满足您的需求（无论是由于扩展问题、成本上升还是运营效率低下），下一步就是开始规划向 SaaS 平台的迁移。做出这种转变不一定要势不可挡，但确实需要仔细考虑和战略方法。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;以下是您可以用作确保顺利过渡的基准的关键步骤：&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt;：&lt;strong&gt;评估您的需求&lt;/strong&gt;：从可观测性堆栈中了解您需要什么。您是否正在寻求更好的可扩展性、高级功能、简化的管理？还有什么？&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;2&lt;/strong&gt;：&lt;strong&gt;选择正确的平台：&lt;/strong&gt;并非所有 SaaS 平台都是一样的。这里有一个提示：寻找一个提供以下功能的产品：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;与您当前的工具（例如 Logstash、Beats 或 OpenTelemetry）进行原生集成。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;对日志、指标、跟踪和额外可视化的统一支持。  &lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;人工智能驱动的洞察和自动化。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://logz.io/from-diy-elk-to-effortless-observability/?utm_medium=referral&amp;utm_source=TNS&amp;utm_campaign=tns_spon_4&amp;utm_content=lp&amp;utm_term=elk&#34;&gt;Logz.io 等平台&lt;/a &gt; 例如，支持与 ELK 相同的摄取方法，因此您可以以最少的成本重用现有配置除了提供根本原因分析等高级功能之外，还可以帮助企业以最少的努力主动管理其系统。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;3&lt;/strong&gt;：&lt;strong&gt;计划和测试：&lt;/strong&gt;首先在现有的 ELK 堆栈旁边设置 SaaS 平台。使用日志或指标的子集测试数据提取，以验证兼容性和性能。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;4&lt;/strong&gt;：&lt;strong&gt;逐步迁移：&lt;/strong&gt;从非关键系统开始逐步迁移工作负载。一旦流程稳定并且工作流程得到优化，就可以过渡关键系统。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;5&lt;/strong&gt;：&lt;strong&gt;重新创建仪表板和警报：&lt;/strong&gt;从 ELK 导出仪表板和警报并将其导入新的托管平台。利用预构建的模板和高级警报选项来完善您的可观察性策略。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;6&lt;/strong&gt;：&lt;strong&gt;优化和培训&lt;/strong&gt;：确保您的团队接受新平台的培训，并继续优化配置以满足您的需求。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;7&lt;/strong&gt;：&lt;strong&gt;退役 DIY ELK：&lt;/strong&gt;所有系统成功迁移后，逐步淘汰您的 ELK 基础设施，如果需要，在外部存储中搅动历史数据。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class =“ wp-block头”&gt;解锁长期可观察性值&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;在A&gt;不仅仅是技术升级，或者使所有内容启动并运行。这是一个促进长期价值的战略决定。通过卸载运营复杂性，企业可以专注于创新，提高系统可靠性并增强客户体验。使这种转变的组织经常发现它们不仅仅是解决操作头痛，还为&lt;a href =&#39;https：// ship to https =&#39;https：// logz.io/case-studies/rubrik-case-study/?utm_medium = referral＆utm_source = tns＆utm_campaign=tns_spon_spon_4&amp;utm_content = case-study&#34;&gt; scalable &#34;&gt; scalable，数据驱动的，数据驱动的增长&lt;/a&gt;。这是使观察性成为成功的无缝推动者的一步，而不是持续的挑战。&lt;/p&gt;&#xA;&#xA;在&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;在&#xA;&lt;/div&gt;</description>
      <pubDate>Thu, 23 Jan 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Announcing the second Cloud Native Heroes Challenge】宣布第二个云土著英雄挑战赛</title>
      <link>https://www.cncf.io/blog/2025/01/22/announcing-the-second-cloud-native-heroes-challenge/</link>
      <description>【&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;em&gt;Help us defeat a patent troll claiming “network isolation with cloud networks” was invented in 2017&lt;/em&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We’re excited to launch another &lt;a href=&#34;http://cncf.io/heroes&#34;&gt;Cloud Native Heroes Challenge&lt;/a&gt; contest in which you can earn swag, a ticket to attend KubeCon+CloudNativeCon, and/or a US $3,000 cash prize by helping defend our ecosystem from patent trolls.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;The Challenged Patent&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We’re seeking information to invalidate Claim 1 of US Patent &lt;a href=&#34;https://portal.unifiedpatents.com/patents/patent/11178104&#34;&gt;11,178,104&lt;/a&gt;, asserted by patent troll Croga Innovations. This patent describes a host computer system designed to enhance network security. The primary goal is to securely access Internet-based cloud services through authenticated and firewalled isolation.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;&lt;em&gt;This patent potentially impacts all container technology and numerous open source projects including Kubernetes, containerd, Docker, Flatcar, and more.&amp;nbsp;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Key Context&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;At a glance this seems like a relatively innocent patent. But let’s look at the patent in the context of recent technology history..&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Here is claim 1 of the challenged patent:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-gray-300-background-color has-background has-fixed-layout&#34;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;1. A host computer system:a memory; anda processor configured to:implement a workspace, wherein the workspace is configured to enable operation of a first set of one or more applications or processes via a first memory space;implement an isolated computing environment, the isolated computing environment using a host operating system and comprising a sandboxed computing environment that uses a second memory space to enable operation of a second set of one or more applications or processes, wherein the isolated computing environment is configured to access an Internet-based cloud service via at least one application of the second set of one or more applications or processes;isolate the isolated computing environment from the workspace using an internal isolation firewall;authenticate the isolated computing environment with an authentication device; andcommunicate with a proxy server to access the Internet-based cloud service to allow communication between at least one application and the Internet-based cloud service when the isolated computing environment has been authenticated.&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If this sounds familiar to you you’re probably thinking “that sounds a lot like containers,” given the references to process, and namespaces, cgroups, etc. This patent was awarded in 2017. Kubernetes itself was created in 2014, Docker in 2013, and LXC (Linux Containers) were created in roughly 2008 by a group of engineers from IBM. Obviously the patent is so generic it could even be applied to virtual machines!&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Call for Prior Art&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.cncf.io/heroes/#what-is-prior-art&#34;&gt;“Prior art”&lt;/a&gt; is a legal term that refers to technical know-how that predated the patent application. Prior art can be used to invalidate or weaken a troll’s patent by demonstrating that the patented invention already existed and wasn’t “new” when the application for a patent was filed.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you are aware of any publicly available materials demonstrating that know-how regarding all of the elements of the invention described above already existed &lt;strong&gt;prior to September 26, 2017 &lt;/strong&gt;(the priority date of the challenged patent), please submit that evidence as “prior art” in this contest. However, please note that materials already listed in the “known references” tab of the &lt;a href=&#34;https://patroll.unifiedpatents.com/contests/mJ5QT4wkDCCjhy9xb&#34;&gt;Contest Description&lt;/a&gt; do not qualify and cannot be submitted in this contest.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Examples of materials that can be provided as prior art include:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Open source documentation, including release notes&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Articles, books, and other publications&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Written records of presentations at tech conferences&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Product manuals or descriptions&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Standards and specification documents&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Any other publicly available documentation (in English) that existed prior to September 26, 2017&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Other patents with a priority date earlier than September 26, 2017&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Instructions for Participating&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Please see our &lt;a href=&#34;http://cncf.io/heroes/participation-instructions&#34;&gt;Participation Instructions&lt;/a&gt; and &lt;a href=&#34;http://cncf.io/heroes&#34;&gt;the Heroes Challenge program page&lt;/a&gt; for more information and step-by-step instructions for entering &lt;a href=&#34;https://patroll.unifiedpatents.com/contests/mJ5QT4wkDCCjhy9xb&#34;&gt;this contest&lt;/a&gt;. Remember, a variety of prizes are available, and all entrants will receive a free Cloud Native Hero t-shirt.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you have questions or would like to request a 1:1 help session where a member of our Heroes Challenge team walks you through any aspect of the contest entry process, please message us at the CNCF slack channel &lt;a href=&#34;https://cloud-native.slack.com/archives/C07UZJRHZPY&#34;&gt;#heroes-challenge&lt;/a&gt; or at &lt;a href=&#34;mailto:heroes@cncf.io&#34;&gt;heroes@cncf.io&lt;/a&gt;.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Know of Prior Art but don’t want to enter the Contest?&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you would like to inform us of prior art without entering the contest, please email us at &lt;a href=&#34;mailto:heroes@cncf.io&#34;&gt;heroes@cncf.io&lt;/a&gt;.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;About Our Co-Host for the Cloud Native Heroes Challenge&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;CNCF is co-hosting this program with &lt;a href=&#34;https://www.unifiedpatents.com/&#34;&gt;Unified Patents&lt;/a&gt;, the Linux Foundation’s partner in patent troll deterrence since 2019. Unified Patents is the &lt;strong&gt;&lt;em&gt;only&lt;/em&gt;&lt;/strong&gt; organization that uses offensive community-driven strategies to deter patent trolls.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Other relevant posts&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.cncf.io/blog/2024/11/13/announcing-the-cloud-native-heroes-challenge/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Announcing the Cloud Native Heroes Challenge&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.cncf.io/blog/2024/09/16/cncf-and-the-linux-foundation-partner-with-unified-patents-on-a-community-driven-approach-to-safeguard-open-source-innovation-from-patent-trolls/&#34;&gt;CNCF Partners with Unified Patents on a Community-Driven Approach to Safeguard Open Source from Patent Trolls&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.cncf.io/blog/2025/01/22/meet-the-winners-of-our-first-cloud-native-heroes-challenge/&#34;&gt;Meet the winners of our first Cloud Native Heroes Challenge&amp;nbsp;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;h3 class =“ WP-block-heading”&gt; &lt;em&gt;帮助我们击败专利巨魔，声称“与云网络隔离网络隔离”在2017年发明了&lt;/em&gt; &lt;/em&gt; &lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们很高兴推出另一个&lt;a href =“ http://cncf.io/heroes”&gt; Cloud Native Heroes Challenge &lt;/a&gt;您可以在其中赢得赃物的比赛，这是一张参加Kubecon+Cloudnativecon的门票，和/或3,000美元的现金奖励，帮助捍卫我们的生态系统免受专利巨魔的影响。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;H2 class =“ WP-block-neading”&gt;挑战的专利&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们正在寻求信息，以使美国专利的权利要求1无效&lt;a href =“ https://portal.unifiedpatents.com/patents/patents/patent/11178104”&gt; 11,178,104 &lt;/a&gt;，由专利的Troll Croga Innovations所主张。该专利描述了旨在增强网络安全性的主机计算机系统。主要目标是通过身份验证和防火墙隔离安全地访问基于Internet的云服务。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt; &lt;strong&gt; &lt;em&gt;该专利可能会影响所有容器技术和许多开源项目，包括Kubernetes，Containerd，Docker，Flatcar等。 &lt;/em&gt; &lt;/strong&gt; &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class =“ wp-block头”&gt;关键上下文&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;一目了然，这似乎是一项相对无辜的专利。但是，让我们看一下最近技术历史上的专利。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这是挑战专利的权利要求1：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figie class =“ wp-block-table”&gt; &lt;table class =“ has-gray-300-background-color has-background具有固定的layout”&gt; &lt;tbody&gt; &lt;try&gt; &lt;tr&gt; &lt;td&gt; 1。主机计算机系统：内存； ANDA处理器配置为：实现一个工作区，其中所述工作空间配置为通过第一个内存空间启用一组或多种应用程序或进程的操作；包括使用第二个内存空间的沙盒计算环境，启用第二组或多种应用程序或过程的操作，其中隔离的计算环境配置为通过第二组的至少一个应用程序配置为基于Internet的云服务访问基于Internet的云服务一个或多个应用程序或过程；使用内部隔离防火墙将隔离的计算环境从工作区隔离；用身份验证设备对隔离的计算环境进行身份验证；与代理服务器进行通信，以访问基于Internet的云服务，以允许至少一个应用程序和基于Internet的云服务进行通信。 /table&gt; &lt;/figus&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您熟悉这听起来您可能会在想“听起来很像容器”，并且给定对过程的参考以及名称空间，cgroups等。该专利于2017年授予。Kubernetes本身是在2014年创建的Docker在2013年，LXC（Linux容器）是由IBM的一组工程师在2008年创建的。显然，专利是如此通用，甚至可以应用于虚拟机！&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;征集现有技术&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.cncf.io/heroes/#what-is-prior-art&#34;&gt;“现有技术”&lt;/a&gt;是一个法律术语，指的是技术知识早于专利申请。现有技术可以通过证明专利发明在提交专利申请时已经存在并且不是“新的”，从而使巨魔的专利无效或削弱。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您知道任何公开材料表明上述发明所有要素的专有技术在&lt;strong&gt;2017 年 9 月 26 日&lt;/strong&gt;（受质疑专利的优先权日期）之前就已存在），请在本次竞赛中将该证据作为“现有技术”提交。但请注意，&lt;a href=&#34;https://patroll.unifiedpatents.com/contests/mJ5QT4wkDCCjhy9xb&#34;&gt;竞赛说明&lt;/a&gt;“已知参考资料”选项卡中已列出的材料不符合资格，无法提交在本次比赛中。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;可以作为现有技术提供的材料示例包括：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;开源文档，包括发行说明&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;文章、书籍和其他出版物&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;技术会议演讲的书面记录&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;产品手册或说明&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;标准和规范文件&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;2017 年 9 月 26 日之前存在的任何其他公开文档（英文）&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;优先权日期早于 2017 年 9 月 26 日的其他专利&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;参与说明&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;请参阅我们的&lt;a href=&#34;http://cncf.io/heroes/participation-instructions&#34;&gt;参与说明&lt;/a&gt;和&lt;a href=&#34;http://cncf.io/heroes&#34;&gt;英雄挑战计划页面&lt;/a&gt;了解更多信息以及参加&lt;a href=&#34;https://patroll.unifiedpatents.com/contests/mJ5QT4wkDCCjhy9xb&#34;&gt;此的分步说明竞赛&lt;/a&gt;。请记住，奖品多种多样，所有参赛者都将获得一件免费的云原生英雄 T 恤。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您有疑问或想要请求 1:1 帮助会议，由我们的 Heroes Challenge 团队成员指导您完成比赛报名流程的任何方面，请在 CNCF slack 频道给我们留言 &lt;a href=&#34; https://cloud-native.slack.com/archives/C07UZJRHZPY&#34;&gt;#heroes-challenge&lt;/a&gt; 或位于 &lt;a href=&#34;mailto:heroes@cncf.io&#34;&gt;heroes@cncf.io&lt;/a&gt;。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;了解现有技术但不想参加比赛？&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您想在不参加比赛的情况下告知我们现有技术，请发送电子邮件至&lt;a href=&#34;mailto:heroes@cncf.io&#34;&gt;heroes@cncf.io&lt;/a&gt;。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;关于我们云原生英雄挑战赛的联合主办方&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;CNCF 与 &lt;a href=&#34;https://www.unifiedpatents.com/&#34;&gt;Unified Patents&lt;/a&gt; 共同主办该计划，&lt;a href=&#34;https://www.unifiedpatents.com/&#34;&gt;Unified Patents&lt;/a&gt; 是 Linux 基金会自 2019 年以来在专利流氓威慑方面的合作伙伴。 Unified Patents 是&lt;strong&gt;&lt;em&gt;唯一&lt;/em&gt;&lt;/strong&gt;使用攻击性社区驱动策略来威慑专利流氓的组织。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;其他相关帖子&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.cncf.io/blog/2024/11/13/announcing-the-cloud-native-heroes-challenge/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34; &gt;宣布云原生英雄挑战赛&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.cncf.io/blog/2024/09/16/cncf-and-the-linux-foundation-partner-with-unified-patents-on-a-community- driven-approach-to-safeguard-open-source-innovation-from-patent-trolls/&#34;&gt;CNCF 与 Unified Patent 合作，采用社区驱动的方法来保护开源免受专利侵害巨魔&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.cncf.io/blog/2025/01/22/meet-the-winners-of-our-first-cloud-native-heroes-challenge/&#34;&gt;认识我们首届云原生英雄挑战赛的获奖者&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Tue, 21 Jan 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Notary Project completes its second audit!】公证项目完成第二次审核！</title>
      <link>https://www.cncf.io/blog/2025/01/21/notary-project-completes-its-second-audit/</link>
      <description>【&lt;p&gt;&lt;em&gt;Community post cross-posted on the &lt;a href=&#34;https://ostif.org/notaryproject-cryptography-audit-2025&#34;&gt;OSTIF blog&lt;/a&gt; by Helen Woeste, Communications Manager, the Open Source Technology Improvement Fund&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;OSTIF&lt;/strong&gt; is proud to share the results of our second security audit of &lt;a href=&#34;https://notaryproject.dev/&#34;&gt;&lt;strong&gt;Notary&lt;/strong&gt; &lt;strong&gt;Project&lt;/strong&gt;&lt;/a&gt;. Notary Project is “a set of specifications and tools intended to provide a cross-industry standard for securing software supply chains by using authentic container images and other OCI artifacts.” With the help of &lt;a href=&#34;https://www.quarkslab.com/&#34;&gt;&lt;strong&gt;Quarkslab&lt;/strong&gt;&lt;/a&gt; and the &lt;a href=&#34;https://www.cncf.io/&#34;&gt;&lt;strong&gt;Cloud Native Computing Foundation (CNCF)&lt;/strong&gt;&lt;/a&gt;, this project continues to provide users with trusted software supply chain management.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Audit Process&lt;/strong&gt;:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This audit of Notary Project was specifically scoped around two new cryptographic features. The audit team, Quarkslab, was chosen for their practical cryptography experience to work on this engagement. The audit report presents how Quarkslab installed and performed discovery of Notary Project tooling Notation, reviewed the code structure and quality, and analyzed the timestamping and certificate revocation. The audit team also created multiple figures to help illustrate Notation with examples of overall project functionality, flow of certificate chain verification, and global overview of the CRL verification.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Audit Results&lt;/strong&gt;:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;11 findings with Security Impact and Recommended Fixes&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;1 Medium, 1 Low, 9 Informational&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;2 CVEs issued for audit findings&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://nvd.nist.gov/vuln/detail/CVE-2024-56138&#34;&gt;CVE-2024-56138: notation-go timestamp signature generation lacks certificate revocation check&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://nvd.nist.gov/vuln/detail/CVE-2024-51491&#34;&gt;CVE-2024-51491: notation-go process crash during CRL-based revocation check on OS using separate mount point for temp Directory&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Review and Recommendations for 2 new Cryptographic Features&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Timestamping Support&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Time-Stamp Protocol Compliance&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Time Stamp Analysis in &lt;a href=&#34;https://github.com/notaryproject/notation?tab=readme-ov-file&#34;&gt;Notation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Revocation Checking with Certificate Revocation List&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Certificate Revocation List Compliance&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;CRL Analysis in &lt;a href=&#34;https://github.com/notaryproject/notation?tab=readme-ov-file&#34;&gt;Notation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Future Security Work Recommendations&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This was Notary Project’s third security audit and second audit in partnership with OSTIF. Practicing mature security practices, the three audits were all undertaken after implementation of new features with security impact. Notary Projects’s efforts to provide secure code to users was observable to the audit team, and is reflected by the reported findings and further recommendations for future security work. OSTIF wishes Notary Project the best on its path towards Graduation through the CNCF Incubating Projects program.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Thank you&lt;/strong&gt; to the individuals and groups that made this engagement possible:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Notary&lt;/strong&gt; &lt;strong&gt;Project&lt;/strong&gt; maintainers and community, notably: Pritesh Bandi, Junjie Gao, Vani Rao, Shiwei Zhang, Yi Zha, Patrick Zheng, and Feynman Zhou&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Quarkslab&lt;/strong&gt;: Dahmun Goudarzi, Sébastien Rolland, and Ramtine Tofighi Shirazi&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Cloud Native Computing Foundation&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;You can read the Audit Report &lt;a href=&#34;https://ostif.org/wp-content/uploads/2025/01/24-10-1825-LIV-v1.5.pdf&#34;&gt;&lt;strong&gt;HERE&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Read Quarkslab’s blog &lt;a href=&#34;https://blog.quarkslab.com/&#34;&gt;&lt;strong&gt;HERE&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Everyone around the world depends on open source software. If you’re interested in financially supporting this critical work, contact amir@ostif.org.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt; &lt;em&gt;社区帖子在&lt;a href =“ https://ostif.org/notaryproject-cryptography-2025”&gt; ostif博客&lt;/a&gt; Helen Woeste，通信经理，公开赛经理Helen Woeste &lt;/a&gt;来源技术改进基金&lt;/em&gt; &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt; &lt;strong&gt; ostif &lt;/strong&gt;很荣幸能分享我们的第二次安全审核的结果，&lt;a href =“ https://notaryproject.dev/”&gt; &lt;strong&gt; notary &lt;/strong&gt; &lt;strong&gt;项目&lt;/strong&gt; &lt;/a&gt;。公证项目是“一套规格和工具，旨在通过使用真实的容器图像和其他OCI工件来提供跨行业标准，以确保软件供应链。”借助&lt;a href =“ https://www.quarkslab.com/”&gt; &lt;strong&gt; quarkslab &lt;/strong&gt; &lt;/a&gt;和&lt;a href =“ https://www.cncf.io/ “&gt; &lt;strong&gt;云本地计算基金会（CNCF）&lt;/strong&gt; &lt;/a&gt;，该项目继续为用户提供可信赖的软件供应链管理。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt; &lt;strong&gt;审核过程&lt;/strong&gt;：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;该公证项目的审核专门围绕两个新的加密功能进行了范围。审计团队Quarkslab因其实用的加密经验而被选为从事这种参与的工作。审计报告介绍了Quarkslab如何安装和执行公证项目工具符号，审查了代码结构和质量，并分析了时间戳和证书撤销。审计团队还创建了多个数字，以帮助说明符号，其中包括整体项目功能，证书链验证流以及CRL验证的全局概述。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt; &lt;strong&gt;审核结果&lt;/strong&gt;：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class =“ wp-block-list”&gt;&#xA;&lt;li&gt; 11的调查结果具有安全影响和建议的修复&#xA;&lt;ul class =“ wp-block-list”&gt;&#xA;&lt;li&gt; 1个媒介，1低，9信息&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; 2个CVE发行了审核调查结果&#xA;&lt;ul class =“ wp-block-list”&gt;&#xA;&lt;li&gt; &lt;a href =“ https://nvd.nist.gov/vuln/detail/cve-2024-56138”&gt; cve-2024-56138：notation-go timestamp签名代理缺乏证书检查&lt;/a&gt; &lt;/a&gt; &lt;/a&gt; &lt;/a&gt; &lt;/a&gt; /li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;a href =“ https://nvd.nist.gov/vuln/detail/cve-2024-51491”&gt; CVE-2024-51491：基于CRL的decocation在CRL基于CRL的撤销检查OS上的notation-go Process崩溃临时目录的安装点&lt;/a&gt; &lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;审查和建议2个新密码功能的建议&#xA;&lt;ul class =“ wp-block-list”&gt;&#xA;&lt;li&gt;时间戳支持&#xA;&lt;ul class =“ wp-block-list”&gt;&#xA;&lt;li&gt;时间戳记协议合规&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;a href =“ https://github.com/notaryproject/notation？tab=readme-readme-ov-file”&gt; niem &lt;/a&gt; &lt;/a&gt; &lt;/a&gt; &lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;用证书撤销列表撤销检查&#xA;&lt;ul class =“ wp-block-list”&gt;&#xA;&lt;li&gt;证书撤销清单合规&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;a href =“ https://github.com/notaryproject/notation？tab=readme-readme-ov-file”&gt;表示法&lt;/a&gt; &lt;/a&gt; &lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;未来的安全工作建议&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这是公证项目与OSTIF合作的第三次安全审核和第二次审核。练习成熟的安全惯例，这三个审核在实施具有安全影响的新功能后，全部进行了。公证项目为向用户提供安全代码的努力是审计团队可观察到的，并由报告的发现和未来安全工作的进一步建议反映出。 OSTIF希望Notary Project通过CNCF孵化项目计划毕业的道路上最好的项目。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt; &lt;strong&gt;感谢您&lt;/strong&gt;对这次参与的个人和团体都成为可能：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class =“ wp-block-list”&gt;&#xA;&lt;li&gt; &lt;strong&gt;公证&lt;/strong&gt; &lt;strong&gt;项目&lt;/strong&gt;维护者和社区，尤其是：Pritesh Bandi，Junjie Gao，Vani Rao，Shiwei Zhang，Yi Zha，Patrick Zheng，Patrick Zheng和Feynman Zhout&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;strong&gt; Quarkslab &lt;/strong&gt;：Dahmun Goudarzi，SébastienRolland和Ramtine Tofighi Shirazi &lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;strong&gt;云本机计算基础&lt;/strong&gt; &lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;您可以阅读审核报告&lt;a href =“ https://ostif.org/wp-content/uploads/2025/01/24-101/24-10-1825-liv-v1.5.pdf”&gt; &lt;strong&gt; &lt;strong&gt;这里&lt;/strong&gt; &lt;/a&gt; &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;阅读Quarkslab的博客&lt;A href =“ https://blog.quarkslab.com/”&gt; &lt;strong&gt;在这里&lt;/strong&gt; &lt;/a&gt; &lt;/a&gt; &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;世界各地的每个人都取决于开源软件。如果您有兴趣在财务上支持这项关键工作，请联系amir@ostif.org。&lt;/p&gt;&#xA;&#xA;在&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;在&#xA;&lt;/div&gt;</description>
      <pubDate>Mon, 20 Jan 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Kubernetes in 2025: are you ready for these top 5 trends and predictions?】2025 年的 Kubernetes：您准备好应对这 5 大趋势和预测了吗？</title>
      <link>https://www.cncf.io/blog/2025/01/22/kubernetes-in-2025-are-you-ready-for-these-top-5-trends-and-predictions/</link>
      <description>【&lt;p&gt;&lt;em&gt;Member post originally published on the &lt;a href=&#34;https://www.fairwinds.com/blog/kubernetes-2025-top-5-trends-predictions&#34;&gt;Fairwinds blog&lt;/a&gt; by Andy Suderman&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Now that Kubernetes has turned&amp;nbsp;&lt;a href=&#34;https://www.fairwinds.com/blog/kubernetes-decade-container-orchestration&#34;&gt;10&lt;/a&gt;, it has firmly established itself as a cornerstone of cloud-native deployment. That means it’s finally fair to request ten years of Kubernetes experience when writing job descriptions! While Kubernetes is undeniably complex, it also enables organizations to implement and customize it to fit their individual business needs. Looking ahead to 2025, we expect Kubernetes and the cloud-native ecosystem to continue to grow and evolve. Drawing on our own experience and&amp;nbsp;&lt;a href=&#34;https://www.fairwinds.com/dzone-kube-in-enterprise-email&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;DZone’s Kubernetes in the Enterprise report&lt;/a&gt;, here are five things we expect to focus on in the Kubernetes ecosystem in the year ahead.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;1. Containers &amp;amp; Container Management&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Containers exploded in popularity in 2013 when&amp;nbsp;&lt;a href=&#34;https://www.docker.com/&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;Docker&lt;/a&gt;&amp;nbsp;emerged, and often people use the words Docker and container interchangeably. The key difference is that Docker also offered an ecosystem for container management. Kubernetes then emerged as a container orchestration system in 2014.&amp;nbsp;&lt;a href=&#34;https://www.fairwinds.com/blog/kubernetes-basics-tutorial-ensure-containers-do-not-run-as-root&#34;&gt;Containers&lt;/a&gt;&amp;nbsp;remain a staple in modern software architectures because they include everything an application needs to run (including libraries, system tools, code, and runtime), making it easier to deploy consistently across different environments. Container use has grown consistently over the years and is now holding steady at about 84%.&amp;nbsp;&lt;strong&gt;Expect Docker and Kubernetes use in development and production environments to continue to rise as the technology and ecosystem mature.&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;624&#34; height=&#34;396&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2025/01/ContainerManagementTools.webp&#34; alt=&#34;Table showing Container Management Tools in Dev &amp;amp; Prod&#34; class=&#34;wp-image-123863&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2025/01/ContainerManagementTools.webp 624w, https://www.cncf.io/wp-content/uploads/2025/01/ContainerManagementTools-300x190.webp 300w, https://www.cncf.io/wp-content/uploads/2025/01/ContainerManagementTools-315x200.webp 315w&#34; sizes=&#34;auto, (max-width: 624px) 100vw, 624px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;2. Kubernetes Use Cases&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you’re reading this, you probably already know that&amp;nbsp;&lt;a href=&#34;https://kubernetes.io/&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;Kubernetes&lt;/a&gt;&amp;nbsp;automates the deployment, scaling, and management of containerized applications across clusters. This ensures high availability and fault tolerance, and that’s why K8s is the most commonly used container management technology in production environments. The DZone report showed 76% of developers had personal experience working with Kubernetes, almost exactly the same percentage of organizations that indicated they were running K8s clusters (75%). There are many common use cases respondents shared, but the top three were hybrid/&lt;a href=&#34;https://www.fairwinds.com/blog/how-to-operate-kubernetes-in-a-multi-cluster-multi-cloud-world&#34;&gt;multi-cloud&lt;/a&gt;&amp;nbsp;(54%), new cloud-native apps (49%), and modernizing existing apps (46%).&amp;nbsp;&lt;strong&gt;Expect these use cases to remain stable and&amp;nbsp;&lt;/strong&gt;&lt;a href=&#34;https://www.fairwinds.com/blog/4-best-practices-cloud-native-infrastructure-ai-workloads&#34;&gt;&lt;strong&gt;Artificial Intelligence (AI) / Machine Learning (ML)&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;&amp;nbsp;and Edge / Internet of Things (IoT) use cases to rise in the year ahead.&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;624&#34; height=&#34;277&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2025/01/image.png&#34; alt=&#34;Bar chart showing Kubernetes use cases survey result&#34; class=&#34;wp-image-123865&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2025/01/image.png 624w, https://www.cncf.io/wp-content/uploads/2025/01/image-300x133.png 300w, https://www.cncf.io/wp-content/uploads/2025/01/image-451x200.png 451w&#34; sizes=&#34;auto, (max-width: 624px) 100vw, 624px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;3. Developer Sentiment&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Development teams continue to struggle with some aspects of Kubernetes. While they love the scalability, high availability, and fault tolerance it offers, many developers find that setting up, configuring, and&amp;nbsp;&lt;a href=&#34;https://www.fairwinds.com/blog/when-why-hand-keys-kubernetes-infrastructure&#34;&gt;managing Kubernetes&lt;/a&gt;&amp;nbsp;is time consuming and resource intensive. The latest survey shows some areas where more than half of respondents believe Kubernetes has improved things for devs (CI/CD, deployment in general, auto scaling, and building microservices). There are other areas where it hasn’t helped, however. More than half of respondents shared that K8s had neither improved nor worsened architectural refactoring, security, application modularity, and overall system design. In some areas, notably cost (25%), architectural refactoring (15%), and security (13%), developers think Kubernetes has actually made things worse.&amp;nbsp;&lt;strong&gt;In the year ahead, dev teams are going to push back on the requirement to learn K8s and ask for&amp;nbsp;&lt;/strong&gt;&lt;a href=&#34;https://www.fairwinds.com/managed-kubernetes&#34;&gt;&lt;strong&gt;Managed Kubernetes-as-a-Service&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;&amp;nbsp;and&amp;nbsp;&lt;/strong&gt;&lt;a href=&#34;https://www.fairwinds.com/insights&#34;&gt;&lt;strong&gt;tools&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;&amp;nbsp;to make deploying to Kubernetes infrastructure easier so they can focus on building applications and services.&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;624&#34; height=&#34;347&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2025/01/image-1.png&#34; alt=&#34;Bar chart showing &amp;quot;What Kubernetes has improved vs worsened&amp;quot; survey result&#34; class=&#34;wp-image-123866&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2025/01/image-1.png 624w, https://www.cncf.io/wp-content/uploads/2025/01/image-1-300x167.png 300w, https://www.cncf.io/wp-content/uploads/2025/01/image-1-360x200.png 360w&#34; sizes=&#34;auto, (max-width: 624px) 100vw, 624px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;4. Monitoring &amp;amp; Observability&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes is a dynamic and distributed environment, which can make it more difficult to get insights into application performance, health, and resource utilization.&amp;nbsp;&lt;a href=&#34;https://www.fairwinds.com/blog/top-9-questions-kubernetes-monitoring&#34;&gt;Monitoring and observability&lt;/a&gt;&amp;nbsp;make it easier to identify the root cause of performance bottlenecks, failures, or misconfigurations. Most DZone respondents (69%) are already using tools to monitor Kubernetes, relying on a variety of tools to monitor cloud-native and containerized apps (Grafana 65%, Prometheus 62%, followed by Splunk with 24%, and&amp;nbsp;&lt;a href=&#34;https://www.fairwinds.com/blog/prevent-risk-monitor-kubernetes-fairwinds-datadog&#34;&gt;Datadog&lt;/a&gt;&amp;nbsp;with 21%, and many other tools). This year, the majority of respondents (56%) indicated that their organization is also using AI for monitoring and observability.&amp;nbsp;&lt;strong&gt;Right now, the most common uses of AI are for anomaly detection and performance analysis, but we expect this to change as more companies adopt AI-enabled tools to help them make the most of their Kubernetes investment.&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;847&#34; height=&#34;364&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2025/01/AIforMonitoring.webp&#34; alt=&#34;Bar chart showing Adoption of AI survey report&#34; class=&#34;wp-image-123688&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2025/01/AIforMonitoring.webp 847w, https://www.cncf.io/wp-content/uploads/2025/01/AIforMonitoring-300x129.webp 300w, https://www.cncf.io/wp-content/uploads/2025/01/AIforMonitoring-768x330.webp 768w, https://www.cncf.io/wp-content/uploads/2025/01/AIforMonitoring-465x200.webp 465w&#34; sizes=&#34;auto, (max-width: 847px) 100vw, 847px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;5. K8s’ Impact on Other Development Trends&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes both impacts and is impacted by software development systems, tools, and practices. The DZone report focused on three of these areas: cost optimization techniques, security, and microservices.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Cost Optimization&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes can help with&amp;nbsp;&lt;a href=&#34;https://www.fairwinds.com/blog/6-kubernetes-cost-control-strategies-you-need-for-2025&#34;&gt;cost optimization&lt;/a&gt;&amp;nbsp;by automating resource allocation, scaling based on demand, and distributing workloads efficiently across nodes. In cloud environments, expenses can rise quickly, and it can be hard to determine where costs are coming from (and how to attribute them) in these ephemeral environments. Respondents shared that the top ways they’re managing and optimizing costs are through automation of manual processes (65%), containerization (62%), CI/CD (61%), with Infrastructure as Code (IaC) and monitoring and analytics tied for fourth (59%).&lt;strong&gt;&amp;nbsp;In 2025, we expect IaC and cloud optimization (currently at 56%) to rise significantly as well as failover and disaster recovery (currently 33%).&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Security&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes security can be challenging, but it’s important to protect&amp;nbsp;&lt;a href=&#34;https://insights.docs.fairwinds.com/first-steps/container-security/&#34;&gt;containerized&lt;/a&gt;&amp;nbsp;applications and infrastructure from unauthorized access, vulnerabilities, and potential malicious attacks. Organizations must implement network policies, secure container images, and regularly&amp;nbsp;&lt;a href=&#34;https://www.fairwinds.com/blog/upgrading-kubernetes&#34;&gt;update Kubernetes&lt;/a&gt;&amp;nbsp;itself and all related add-ons, APIs, and other components to minimize the risk of breaches and data leaks. Respondents shared that the top three ways they manage K8s’ security include updating Kubernetes regularly (67%), blocking or limiting&amp;nbsp;&lt;a href=&#34;https://www.fairwinds.com/blog/nsa-hardening-guide-locking-down-network-access-with-fairwinds-insights&#34;&gt;network access&lt;/a&gt;&amp;nbsp;to exposed ports (53%), and enabling&amp;nbsp;&lt;a href=&#34;https://www.fairwinds.com/blog/kubernetes-security-policy&#34;&gt;role-based access control&lt;/a&gt;&amp;nbsp;(52%). Fortunately, only 25% of respondents shared that they needed to reassess planned Kubernetes and/or container deployments to production due to security concerns in the past year.&amp;nbsp;&lt;strong&gt;While most organizations may not have encountered a problem with Kubernetes security in 2024, expect malicious attackers to focus more on targeting K8s infrastructure as enterprises increasingly deploy mission-critical applications to production.&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Microservices&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Many teams already run microservices on Kubernetes to take advantage of the simplified management of complex applications as well as improved scalability and reliability. Kubernetes automates microservice deployment, scaling, and monitoring, so each service runs independently and can be updated, scaled, or restarted without impacting other microservices. The DZone report showed that 87% of respondents use microservices, with 95% of them running microservices on Kubernetes.&amp;nbsp;&lt;strong&gt;In 2025, expect the use of microservices on K8s to remain the same unless a new technology emerges to change the game.&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Five Fairwinds Predictions for 2025&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As Kubernetes practitioners who have helped clients manage hundreds of clusters, here are five more predictions for the year ahead based on our hands-on experience:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;The use of&amp;nbsp;&lt;a href=&#34;https://www.fairwinds.com/blog/aws-karpenter-readiness-6-ways-to-make-sure-youre-ready-for-the-move&#34;&gt;Karpenter&lt;/a&gt;&amp;nbsp;will explode, helping users improve both application availability and cluster efficiency based on application workloads in AWS environments.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Organizations using Kubernetes will consolidate clusters to increase efficiency and simplify management.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Our clients and others relying on K8s infrastructure will experiment more with multi-cloud and hybrid strategies as well as with on-prem/bare metal deployments.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;VMware clients will begin migrating away from the platform due to rising costs, licensing changes, support concerns, and vendor lock-in. Those looking for alternatives now have mature and robust virtualization alternatives that support the shift to cloud-native and containerization. Those choosing to migrate to Kubernetes will find the journey worthwhile.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Modern DevOps teams will augment teams with&amp;nbsp;&lt;a href=&#34;https://www.fairwinds.com/managed-kubernetes&#34;&gt;external expertise&lt;/a&gt;&amp;nbsp;to allow key SREs time to focus on application tuning, reliability, and developer experience.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Kubernetes in 2025&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In 2025, Kubernetes will further cement its position as a critical technology in enterprise software development. Its role in enabling scalable, portable, and efficient container and microservices orchestration across various environments will ensure its place as an indispensable tool for modern application deployment and management. As the ecosystem continues to evolve, we can expect to see improvements in ease of use, security, and support for emerging use cases like AI/ML and edge computing.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If your organization is ready to focus on building out your differentiators and optimizing development processes and release times instead of maintaining infrastructure in 2025,&amp;nbsp;&lt;a href=&#34;https://www.fairwinds.com/fairwinds-managed-kubernetes-request&#34;&gt;reach out&lt;/a&gt;. Fairwinds Managed Kubernetes-as-a-Service can architect, build, and maintain your Kubernetes infrastructure so you can focus on what you do best.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;CTA: &lt;a href=&#34;https://www.fairwinds.com/cs/c/?cta_guid=a38c3010-286e-4e25-a4fb-3cba552a76ea&amp;amp;signature=AAH58kGLvdnrH1IdtCG9D_uemhCKYPfDUw&amp;amp;utm_referrer=https%3A%2F%2Fwww.google.com%2F&amp;amp;portal_id=2184645&amp;amp;pageId=184500024693&amp;amp;placement_guid=ba89163c-1a5a-48d2-9658-f57d44396877&amp;amp;click=06e99503-7ea0-4a1a-8106-b9dc51ff0081&amp;amp;redirect_url=APefjpFZw_9eYdlq7vsyn32EfGQCdGejNwaNA71FG2ABoDFetAze_cSNwMkLTKNKoKI-vX6VLvsKNmLUZeLZ2kJVFAJZa6CC0UgORvfuapop1VE09m1-CIY5RQhhFYTAU1B_FNbd0RAhTP7m5SCtbr5D7m76X7sha9Q_DeUYClS0KHbsmTal7e1uX0RhmkwV67GavMXH95JjuEpuYlAuJVW1Ncloh3c9IeuDCbX-0qOQSvUAv9Lh8wwWRcEkqWIvtZZFLA5Lbsw4&amp;amp;hsutk=146169ef54ea906c5feeff5fd98a2e7c&amp;amp;canon=https%3A%2F%2Fwww.fairwinds.com%2Fblog%2Fkubernetes-2025-top-5-trends-predictions&amp;amp;ts=1737449750725&amp;amp;__hstc=91154437.146169ef54ea906c5feeff5fd98a2e7c.1736874032452.1736874032452.1737449752187.2&amp;amp;__hssc=91154437.1.1737449752187&amp;amp;__hsfp=810579359&amp;amp;contentType=blog-post&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;&lt;strong&gt;Explore Managed Kubernetes-as-a-Service&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;成员帖子最初由 Andy 发布在 &lt;a href=&#34;https://www.fairwinds.com/blog/kubernetes-2025-top-5-trends-predictions&#34;&gt;Fairwinds 博客&lt;/a&gt;上苏德曼&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;现在 Kubernetes 已经&lt;a href=&#34;https://www.fairwinds.com/blog/kubernetes-decade-container-orchestration&#34;&gt;十岁&lt;/a&gt;了，它已经牢固地确立了自己作为云基石的地位-本机部署。这意味着在撰写职位描述时要求拥有十年 Kubernetes 经验终于是公平的了！虽然 Kubernetes 无可否认是复杂的，但它也使组织能够实施和定制它以满足各自的业务需求。展望 2025 年，我们预计 Kubernetes 和云原生生态系统将继续发展和发展。借鉴我们自己的经验以及&lt;a href=&#34;https://www.fairwinds.com/dzone-kube-in-enterprise-email&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;企业报告中的 DZone Kubernetes&lt; /a&gt;，我们预计未来一年 Kubernetes 生态系统将重点关注以下五件事。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;1.容器和容器管理&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;2013 年，&lt;a href=&#34;https://www.docker.com/&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;Docker&lt;/a&gt; 出现后，容器迅速普及，人们经常使用Docker 和容器这两个词可以互换。主要区别在于 Docker 还提供了容器管理的生态系统。随后，Kubernetes 在 2014 年作为容器编排系统出现。&lt;a href=&#34;https://www.fairwinds.com/blog/kubernetes-basics-tutorial-ensure-containers-do-not-run-as-root&#34;&gt;容器&lt;/a&gt;仍然是现代软件架构的主要组成部分，因为它们包含应用程序运行所需的一切（包括库、系统工具、代码和运行时），从而更容易在不同环境中一致部署。多年来，集装箱使用量持续增长，目前稳定在 84% 左右。 &lt;strong&gt;随着技术和生态系统的成熟，预计 Docker 和 Kubernetes 在开发和生产环境中的使用将继续上升。&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“624”高度=“396”src=“https://www.cncf.io/ wp-content/uploads/2025/01/ContainerManagementTools.webp&#34; alt=&#34;显示开发和生产中容器管理工具的表格&#34; class=&#34;wp-image-123863&#34; srcset =“https://www.cncf.io/wp-content/uploads/2025/01/ContainerManagementTools.webp 624w，https://www.cncf.io/wp-content/uploads/2025/01/ContainerManagementTools- 300x190.webp 300w, https://www.cncf.io/wp-content/uploads/2025/01/ContainerManagementTools-315x200.webp 315w“尺寸=”自动，（最大宽度：624px）100vw，624px“referrerpolicy=”无引用“ &gt;&lt;/图&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;2. Kubernetes 用例&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您正在阅读本文，您可能已经知道&lt;a href=&#34;https://kubernetes.io/&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;Kubernetes&lt;/a&gt;会自动执行部署，跨集群的容器化应用程序的扩展和管理。这保证了高可用性和容错能力，这就是为什么 K8s 是生产环境中最常用的容器管理技术。 DZone 报告显示，76% 的开发人员有使用 Kubernetes 的个人经验，几乎与表示他们正在运行 K8s 集群的组织比例 (75%) 完全相同。受访者分享了许多常见用例，但前三个是混合/&lt;a href=&#34;https://www.fairwinds.com/blog/how-to-operate-kubernetes-in-a-multi-cluster-multi -cloud-world&#34;&gt;多云&lt;/a&gt;（54%）、新的云原生应用（49%）以及对现有应用进行现代化改造（46%）。 &lt;strong&gt;预计这些用例保持稳定&lt;/strong&gt;&lt;a href=&#34;https://www.fairwinds.com/blog/4-best-practices-cloud-native-infrastruct-ai-workloads&#34;&gt;&lt; strong&gt;人工智能 (AI)/机器学习 (ML)&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;和边缘/物联网 (IoT) 用例在未来一年将会增加。&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“624”高度=“277”src=“https://www.cncf.io/ wp-content/uploads/2025/01/image.png&#34; alt=&#34;显示 Kubernetes 用例调查结果的条形图&#34; class=&#34;wp-image-123865&#34; srcset =“https://www.cncf.io/wp-content/uploads/2025/01/image.png 624w，https://www.cncf.io/wp-content/uploads/2025/01/image- 300x133.png 300w, https://www.cncf.io/wp-content/uploads/2025/01/image-451x200.png 451w“尺寸=”自动，（最大宽度：624px）100vw，624px“referrerpolicy=”无引用“ &gt;&lt;/图&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;3.开发者情绪&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;开发团队继续在 Kubernetes 的某些方面苦苦挣扎。虽然他们喜欢它提供的可扩展性、高可用性和容错能力，但许多开发人员发现设置、配置和&lt;a href=&#34;https://www.fairwinds.com/blog/when-why-hand-keys- kubernetes-infrastructure&#34;&gt;管理 Kubernetes&lt;/a&gt; 非常耗时且占用资源。最新调查显示，超过一半的受访者认为 Kubernetes 为开发人员改进了一些领域（CI/CD、一般部署、自动扩展和构建微服务）。然而，它在其他领域却没有帮助。超过一半的受访者表示，K8 在架构重构、安全性、应用程序模块化和整体系统设计方面既没有改善也没有恶化。在某些领域，特别是成本（25%）、架构重构（15%）和安全性（13%），开发人员认为 Kubernetes 实际上让事情变得更糟。 &lt;strong&gt;在未来的一年中，开发团队将取消学习 K8 的要求并要求&lt;/strong&gt;&lt;a href=&#34;https://www.fairwinds.com/management-kubernetes&#34;&gt;&lt;strong &gt;托管 Kubernetes 即服务&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;和&lt;/strong&gt;&lt;a href=&#34;https://www.fairwinds.com/insights&#34;&gt;&lt;strong&gt;工具&lt;/strong &gt;&lt;/a&gt;&lt;strong&gt; 使轻松部署到 Kubernetes 基础设施以便他们能够专注于构建应用程序和服务。&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“624”高度=“347”src=“https://www.cncf.io/ wp-content/uploads/2025/01/image-1.png&#34; alt=&#34;显示“Kubernetes 改进与恶化的情况”调查结果的条形图&#34; class=&#34;wp-image-123866&#34; srcset =“https://www.cncf.io/wp-content/uploads/2025/01/image-1.png 624w，https://www.cncf.io/wp-content/uploads/2025/01/图片-1-300x167.png 300w, https://www.cncf.io/wp-content/uploads/2025/01/image-1-360x200.png 360w“尺寸=”自动，（最大宽度：624px）100vw，624px“referrerpolicy=”无-推荐人&#34;&gt;&lt;/图&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;4.监控和可观察性&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes 是一个动态的分布式环境，这使得深入了解应用程序性能、运行状况和资源利用率变得更加困难。 &lt;a href=&#34;https://www.fairwinds.com/blog/top-9-questions-kubernetes-monitoring&#34;&gt;监控和可观察性&lt;/a&gt;可以更轻松地识别性能瓶颈、故障或问题的根本原因配置错误。大多数 DZone 受访者 (69%) 已经在使用工具来监控 Kubernetes，依靠各种工具来监控云原生和容器化应用程序（Grafana 65%、Prometheus 62%，其次是 Splunk，占 24%，&lt;a href= “https://www.fairwinds.com/blog/prevent-risk-monitor-kubernetes-fairwinds-datadog&#34;&gt;Datadog&lt;/a&gt; 21%，以及许多其他工具）。今年，大多数受访者 (56%) 表示他们的组织也在使用人工智能进行监控和观察。 &lt;strong&gt;目前，人工智能最常见的用途是异常检测和性能分析，但我们预计，随着越来越多的公司采用支持人工智能的工具来帮助他们充分利用 Kubernetes 投资，这种情况将会改变。&lt;/strong&gt;&lt; /p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“847”高度=“364”src=“https://www.cncf.io/ wp-content/uploads/2025/01/AIforMonitoring.webp&#34; alt=&#34;显示人工智能采用率调查报告的条形图&#34; class=&#34;wp-image-123688&#34; srcset =“https://www.cncf.io/wp-content/uploads/2025/01/AIforMonitoring.webp 847w，https://www.cncf.io/wp-content/uploads/2025/01/AIforMonitoring- 300x129.webp 300w, https://www.cncf.io/wp-content/uploads/2025/01/AIforMonitoring-768x330.webp 768w，https://www.cncf.io/wp-content/uploads/2025/01/AIforMonitoring-465x200 .webp 465w“尺寸=”自动，（最大宽度：847px）100vw， 847px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;5. K8s 对其他发展趋势的影响&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes 既影响软件开发系统、工具和实践，又受到软件开发系统、工具和实践的影响。 DZone 报告重点关注其中三个领域：成本优化技术、安全性和微服务。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;成本优化&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes 可以提供帮助&lt;a href=&#34;https://www.fairwinds.com/blog/6-kubernetes-cost-control-strategieS-You-need 2025“&gt;成本优化&lt;/a&gt;通过自动化资源分配，根据需求进行扩展以及在跨节点上有效分配工作负载。在云环境中，费用可能会迅速上升，并且很难确定在这些短暂的环境中，成本来自（以及如何归因）。 （61％），基础架构为代码（IAC），监测和分析（59％）（59％）。&lt;strong&gt; 2025年，我们预计IAC和云优化（目前为56％）会显着上升，并且发生故障和故障和故障和灾难恢复（目前为33％）。&lt;/strong&gt; &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class =“ wp-block头”&gt;安全性&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt; kubernetes安全可能具有挑战性，但是保护&lt;a href =“ https://insights.docs.fairwinds.com/first-steps/container-security/”未经授权的访问，漏洞和潜在的恶意攻击。组织必须实施网络策略，安全的容器映像以及定期&lt;a href =“ https://www.fairwinds.com/blog/blog/upgrading-kubernetes”&gt;更新kubernetes &lt;/a&gt;以及其他组件，以最大程度地减少漏洞和数据泄漏的风险。受访者分享说，他们管理K8S安全性的前三种方法包括定期更新Kubernetes（67％），阻止或限制&lt;a href =“ https://www.fairwinds.com/blog/blog/nsa-hardening-guide-guide-locking-locking-down-down-down- -network-access-with-fairwinds-Inglights“&gt;网络访问&lt;/a&gt;对暴露端口（53％），并启用&lt;a href =“ https://wwwww.fairwinds.com/blog/blog/kubernetes-security-policy-security-policy-security-policy-security-policy- “&gt;基于角色的访问控制&lt;/a&gt;（52％）。幸运的是，由于过去一年的安全问题，只有25％的受访者分享了他们需要重新评估生产的Kubernetes和/或容器部署到生产中。 &lt;strong&gt;，尽管大多数组织可能在2024年没有遇到Kubernetes安全问题，但随着企业越来越多地将关键任务应用程序部署到生产中时，恶意攻击者将更多地专注于针对K8S基础设施。&lt;/strong&gt; &lt;/strong&gt; &lt;/p&gt; &lt;/strong&gt; &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class =“ wp-block头”&gt;微服务&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;许多团队已经在Kubernetes上运行了微服务，以利用复杂应用程序的简化管理以及提高的可伸缩性和可靠性。 Kubernetes自动化微服务部署，缩放和监视，因此每个服务都可以独立运行，并且可以在不影响其他微服务的情况下更新，缩放或重新启动。 Dzone报告显示，有87％的受访者使用微服务，其中95％的受访者在Kubernetes上运行微服务。 &lt;strong&gt;在2025年，除非出现新技术来改变游戏。&lt;/strong&gt; &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class =“ wp-block头”&gt;五个Fairwinds预测2025 年&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;作为帮助客户管理数百个集群的 Kubernetes 从业者，根据我们的实践经验，对未来一年还有以下五个预测：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;使用&lt;a href=&#34;https://www.fairwinds.com/blog/aws-karpenter-readiness-6-ways-to-make-sure-youre-ready-for-the-move&#34;&gt; Karpenter&lt;/a&gt;将爆发式增长，帮助用户根据 AWS 环境中的应用程序工作负载提高应用程序可用性和集群效率。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;使用 Kubernetes 的组织将整合集群以提高效率并简化管理。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;我们的客户和其他依赖 K8s 基础设施的客户将更多地尝试多云和混合策略以及本地/裸机部署。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;由于成本上升、许可变更、支持问题和供应商锁定，VMware 客户端将开始从该平台迁移。那些寻找替代方案的人现在拥有成熟且强大的虚拟化替代方案，支持向云原生和容器化的转变。那些选择迁移到 Kubernetes 的人会发现这段旅程是值得的。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;现代 DevOps 团队将通过&lt;a href=&#34;https://www.fairwinds.com/management-kubernetes&#34;&gt;外部专业知识&lt;/a&gt;来增强团队实力，让关键 SRE 有时间专注于应用程序调优、可靠性和安全性开发人员经验。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;2025 年的 Kubernetes&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;2025年，Kubernetes将进一步巩固其作为企业软件开发关键技术的地位。它在跨各种环境中实现可扩展、可移植和高效的容器和微服务编排方面的作用将确保其作为现代应用程序部署和管理不可或缺的工具的地位。随着生态系统的不断发展，我们预计会看到易用性、安全性以及对人工智能/机器学习和边缘计算等新兴用例的支持方面的改进。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您的组织已准备好在 2025 年专注于打造差异化优势、优化开发流程和发布时间，而不是维护基础设施，&lt;a href=&#34;https://www.fairwinds.com/fairwinds-management-kubernetes-请求&#34;&gt;联系&lt;/a&gt;。 Fairwinds Managed Kubernetes-as-a-Service 可以架构、构建和维护您的 Kubernetes 基础设施，以便您可以专注于自己最擅长的事情。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;号召性用语：&lt;a href=&#34;https://www.fairwinds.com/cs/c/?cta_guid=a38c3010-286e-4e25-a4fb-3cba552a76ea&amp;signature=AAH58kGLvdnrH1IdtCG9D_uemhCKYPfDUw&amp;utm_ref errer=https%3A%2F%2Fwww.google.com%2F&amp;portal_id=2184645&amp;pageId=184500024693&amp;placement_guid=ba89163c-1a5a-48d2-9658-f57d44396877&amp;click=06e 99503-7ea0-4a1a-8106-b9dc51ff0081&amp;redirect_url=APefjpFZw_9eYdlq7vsyn32EfGQCdGejNwaNA71FG2ABoDFetAze_cSNwMkLTKNKoKI-vX6VLvsKNmLUZeLZ2kJVF AJZa6CC0UgORvfuapop1VE09m1-CIY5RQhhFYTAU1B_FNbd0RAhTP7m5SCtbr5D7m76X7sha9Q_DeUYClS0KHbsmTal7e1uX0RhmkwV67GavMXH95JjuEpuYlAuJVW1Ncloh3c9IeuDCbX-0qOQSvUAv9Lh8wwWRcEkqWIvtZZFLA5Lbsw4&amp;hsutk=146169ef54ea906c5feeff5fd98a2e7c&amp;佳能=https%3A%2F%2Fwww.fairwinds.com%2Fblog%2Fkubernetes-2025-top-5-trends-predictions&amp;ts=17 37449750725&amp;__hstc=91154437.146169ef54ea906c5feeff5fd98a2e7c.1736874032452.1736874032452 .1737449752187.2&amp;__hssc=91154437.1.1737449752187&amp;__hsfp=810579359&amp;contentType=博客文章&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;&lt;strong&gt;探索托管 Kubernetes 即服务&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Tue, 21 Jan 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【What is GitLab Runner?】什么是 GitLab Runner？</title>
      <link>https://www.cncf.io/blog/2025/01/17/what-is-gitlab-runner/</link>
      <description>【&lt;p&gt;&lt;em&gt;Ambassador post by Natalia Granato, CNCF Ambassador&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;GitLab Runner is an open-source application that runs jobs defined in your GitLab CI/CD pipelines. It can be installed on different platforms, including virtual machines, bare-metal servers, and Kubernetes.&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Registering the Runner in Your Projects&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;After deploying GitLab Runner on Kubernetes, you need to register the runner in your projects so it can execute jobs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Go to the &lt;code&gt;Settings &amp;gt; CI/CD&lt;/code&gt; section of your project in GitLab.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Expand the &lt;code&gt;Runners&lt;/code&gt; section.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Click on &lt;code&gt;Register a runner&lt;/code&gt;.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Copy the displayed registration token.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Run the following command on your Kubernetes cluster, replacing &lt;code&gt;YOUR_REGISTRATION_TOKEN&lt;/code&gt; with the copied token:&lt;br&gt;&lt;code&gt;sh kubectl exec -it gitlab-runner-gitlab-runner-XXXXX-XXXXX -- gitlab-runner register \ --non-interactive \ --url https://gitlab.example.com/ \ --registration-token YOUR_REGISTRATION_TOKEN \ --executor kubernetes&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Deploying GitLab Runner on Kubernetes Using Helm&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To install GitLab Runner on Kubernetes using Helm, follow these steps:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Add the Helm repository: &lt;code&gt;helm repo add gitlab https://charts.gitlab.io/&lt;/code&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Update the repositories: &lt;code&gt;helm repo update&lt;/code&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Install GitLab Runner:&lt;br&gt;&lt;code&gt;sh helm install gitlab-runner gitlab/gitlab-runner \ --set gitlabUrl=https://gitlab.example.com/ \ --set runnerRegistrationToken=YOUR_REGISTRATION_TOKEN&lt;/code&gt;&lt;br&gt;Replace &lt;code&gt;https://gitlab.example.com/&lt;/code&gt; with your GitLab URL.&lt;br&gt;Replace &lt;code&gt;YOUR_REGISTRATION_TOKEN&lt;/code&gt; with the runner registration token obtained in the CI/CD section of your GitLab project.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Key Points in the &lt;code&gt;values.yaml&lt;/code&gt; Configuration File&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Rules (&lt;code&gt;rules&lt;/code&gt;)&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This section defines permissions for accessing Kubernetes resources.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;resources&lt;/strong&gt;: Lists the Kubernetes resources the runner can access, such as &lt;code&gt;configmaps&lt;/code&gt;, &lt;code&gt;pods&lt;/code&gt;, &lt;code&gt;pods/attach&lt;/code&gt;, &lt;code&gt;secrets&lt;/code&gt;, and &lt;code&gt;services&lt;/code&gt;.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;verbs&lt;/strong&gt;: Actions that can be performed on the above resources, like &lt;code&gt;get&lt;/code&gt;, &lt;code&gt;list&lt;/code&gt;, &lt;code&gt;watch&lt;/code&gt;, &lt;code&gt;create&lt;/code&gt;, &lt;code&gt;patch&lt;/code&gt;, &lt;code&gt;update&lt;/code&gt;, and &lt;code&gt;delete&lt;/code&gt;.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;apiGroups&lt;/strong&gt;: Specifies API groups in Kubernetes. Here, it’s empty (&lt;code&gt;&#39;&#39;&lt;/code&gt;), indicating the core API group.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;resources&lt;/strong&gt;: Lists specific resources of the above API group, such as &lt;code&gt;pods/exec&lt;/code&gt;.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;verbs&lt;/strong&gt;: Actions allowed for the &lt;code&gt;pods/exec&lt;/code&gt; resource, such as &lt;code&gt;create&lt;/code&gt;, &lt;code&gt;patch&lt;/code&gt;, and &lt;code&gt;delete&lt;/code&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Runners (&lt;code&gt;runners&lt;/code&gt;)&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Defines the runner configuration.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;cache&lt;/strong&gt;: Cache configuration, currently empty (&lt;code&gt;{}&lt;/code&gt;).&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;config&lt;/strong&gt;: Runner configuration in TOML format.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;runners.kubernetes&lt;/strong&gt;: Configuration specific to Kubernetes runners.&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;image&lt;/strong&gt;: Container image to use (&lt;code&gt;ubuntu:20.04&lt;/code&gt;).&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;wait_for_services_timeout&lt;/strong&gt;: Timeout for waiting on services (&lt;code&gt;-1&lt;/code&gt; indicates infinite).&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;privileged&lt;/strong&gt;: Enables privileged mode for the container (&lt;code&gt;true&lt;/code&gt;).&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;allow_privilege_escalation&lt;/strong&gt;: Allows privilege escalation (&lt;code&gt;true&lt;/code&gt;).&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;image_pull_secrets&lt;/strong&gt;: Specifies secrets for pulling container images (&lt;code&gt;aws-ecr&lt;/code&gt;).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;configPath&lt;/strong&gt;: Configuration path, currently empty (&lt;code&gt;&#39;&#39;&lt;/code&gt;).&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;name&lt;/strong&gt;: Runner name (&lt;code&gt;globalweb-gitlab-runner&lt;/code&gt;).&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;privileged&lt;/strong&gt;: Indicates privileged execution (&lt;code&gt;true&lt;/code&gt;).&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;runUntagged&lt;/strong&gt;: Indicates whether to run untagged jobs (&lt;code&gt;true&lt;/code&gt;).&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;tags&lt;/strong&gt;: Tags associated with the runner (&lt;code&gt;docker, share_cache, share_cache1, amd64&lt;/code&gt;).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Secrets (&lt;code&gt;secrets&lt;/code&gt;)&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;List of secrets, currently empty (&lt;code&gt;[]&lt;/code&gt;).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;SecurityContext (&lt;code&gt;securityContext&lt;/code&gt;)&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Security configurations for the containers.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;allowPrivilegeEscalation&lt;/strong&gt;: Permission for privilege escalation (&lt;code&gt;false&lt;/code&gt;).&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;capabilities&lt;/strong&gt;: Container capabilities.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;drop&lt;/strong&gt;: Capabilities to be removed (&lt;code&gt;ALL&lt;/code&gt;).&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;privileged&lt;/strong&gt;: Indicates if the container is privileged (&lt;code&gt;false&lt;/code&gt;).&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;readOnlyRootFilesystem&lt;/strong&gt;: Indicates if the root filesystem is read-only (&lt;code&gt;false&lt;/code&gt;).&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;runAsNonRoot&lt;/strong&gt;: Indicates if the container should run as a non-root user (&lt;code&gt;true&lt;/code&gt;).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Other Key Configurations&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Service (&lt;code&gt;service&lt;/code&gt;)&lt;/strong&gt;: Service settings. &lt;code&gt;enabled: false&lt;/code&gt;, &lt;code&gt;type: ClusterIP&lt;/code&gt;.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;SessionServer (&lt;code&gt;sessionServer&lt;/code&gt;)&lt;/strong&gt;: Disabled by default (&lt;code&gt;enabled: false&lt;/code&gt;).&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Termination Grace Period Seconds (&lt;code&gt;terminationGracePeriodSeconds&lt;/code&gt;)&lt;/strong&gt;: Graceful termination timeout (&lt;code&gt;3600&lt;/code&gt; seconds).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Using the New Runner in GitLab CI Pipelines&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To use the new runner in your GitLab CI pipelines, add the &lt;code&gt;kubernetes&lt;/code&gt; tag to the job you want to execute on Kubernetes. For example:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;build_image:&#xA;  stage: build&#xA;  image: alpine:latest&#xA;  tags:&#xA;    - kubernetes&#xA;  script:&#xA;    - echo &#34;Building image...&#34;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Kubernetes Doesn’t Use Docker as Container Runtime? Kaniko to the Rescue&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes doesn’t use Docker as its default container runtime, which can pose a challenge for CI/CD pipelines that depend on Docker for building images. Kaniko is a tool that allows building container images without Docker.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;What is Kaniko and How Does it Work?&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kaniko is an open-source tool that builds container images from a Dockerfile inside a container or Kubernetes cluster. It works by extracting the base container filesystem, executing Dockerfile commands, and packaging the result into a container image.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Configuring Environment Variables in GitLab CI&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To use Kaniko effectively, configure the necessary environment variables in GitLab CI. These variables include credentials for accessing your container registry and project-specific information.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Steps to Configure Environment Variables for Your Pipeline&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Go to the &lt;code&gt;Settings &amp;gt; CI/CD&lt;/code&gt; section of your GitLab project.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Expand the &lt;code&gt;Variables&lt;/code&gt; section.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Add the following variables without the protected flag:&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;code&gt;AWS_REGION&lt;/code&gt;: Specifies the AWS region where resources will be managed.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;code&gt;AWS_ACCESS_KEY_ID&lt;/code&gt;: AWS public access key for authentication.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;code&gt;AWS_SECRET_ACCESS_KEY&lt;/code&gt;: AWS secret access key for authentication.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;code&gt;REGISTRY&lt;/code&gt;: The container registry where Docker images are stored.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Example &lt;code&gt;.gitlab-ci.yml&lt;/code&gt; for Building and Pushing Container Images with Kaniko&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;build:&#xA;  stage: build&#xA;  image:&#xA;    name: gcr.io/kaniko-project/executor:debug&#xA;    entrypoint: [&#34;&#34;]&#xA;  script:&#xA;    - mkdir -p /kaniko/.docker&#xA;    - echo &#34;{\&#34;credsStore\&#34;:\&#34;ecr-login\&#34;,\&#34;credHelpers\&#34;:{\&#34;$REGISTRY/portal-colaborador-hml\&#34;:\&#34;ecr-login\&#34;}}&#34; &amp;gt; /kaniko/.docker/config.json&#xA;    - &amp;gt;-&#xA;      /kaniko/executor&#xA;      --context &#34;${CI_PROJECT_DIR}&#34; \&#xA;      --dockerfile &#34;${CI_PROJECT_DIR}/Dockerfile&#34; \&#xA;      --build-arg AWS_REGION=$AWS_REGION \&#xA;      --build-arg AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID \&#xA;      --build-arg AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY \&#xA;      --destination &#34;${REGISTRY}/portal-colaborador-hml:${CI_COMMIT_SHORT_SHA:0:5}&#34;&#xA;&#xA;  tags:&#xA;    - docker, share_cache, share_cache1, amd64&#xA;  only:&#xA;    - main&#xA;    - develop&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Conclusion&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Using GitLab Runner in conjunction with Kaniko on Kubernetes enables efficient and secure container image building and pushing without relying on Docker as a runtime. This configuration leverages Kubernetes’ power to scale and manage CI/CD builds, offering greater flexibility and performance in your pipelines.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;CNCF 大使 Natalia Granato 担任大使职务&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;GitLab Runner 是一个开源应用程序，它运行在 GitLab CI/CD 管道中定义的作业。它可以安装在不同的平台上，包括虚拟机、裸机服务器和 Kubernetes。&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;在您的项目中注册 Runner&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在 Kubernetes 上部署 GitLab Runner 后，您需要在项目中注册 Runner，以便它可以执行作业。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;转到 GitLab 中项目的&lt;code&gt;Settings &gt; CI/CD&lt;/code&gt; 部分。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;展开&lt;code&gt;跑步者&lt;/code&gt;部分。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;点击&lt;code&gt;注册跑步者&lt;/code&gt;。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;复制显示的注册令牌。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;在 Kubernetes 集群上运行以下命令，将 &lt;code&gt;YOUR_REGISTRATION_TOKEN&lt;/code&gt; 替换为复制的令牌：&lt;br&gt;&lt;code&gt;sh kubectl exec -it gitlab-runner-gitlab-runner-XXXXX-XXXXX -- gitlab-runner register \ --non-interactive \ --url https://gitlab.example.com/ \ --registration-token YOUR_REGISTRATION_TOKEN \ --执行器 kubernetes&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;使用 Helm 在 Kubernetes 上部署 GitLab Runner&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;要使用 Helm 在 Kubernetes 上安装 GitLab Runner，请按照以下步骤操作：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;添加 Helm 存储库：&lt;code&gt;helm repo add gitlab https://charts.gitlab.io/&lt;/code&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;更新存储库：&lt;code&gt;helm repo update&lt;/code&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;安装 GitLab Runner：&lt;br&gt;&lt;code&gt;sh helm install gitlab-runner gitlab/gitlab-runner \ --set gitlabUrl=https://gitlab.example.com/ \ --set runnerRegistrationToken=YOUR_REGISTRATION_TOKEN&lt;/code &gt;&lt;br&gt;将 &lt;code&gt;https://gitlab.example.com/&lt;/code&gt; 替换为您的 GitLab URL。&lt;br&gt;替换&lt;code&gt;YOUR_REGISTRATION_TOKEN&lt;/code&gt; 包含在 GitLab 项目的 CI/CD 部分中获取的运行者注册令牌。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;code&gt;values.yaml&lt;/code&gt; 配置文件中的要点&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;规则（&lt;code&gt;规则&lt;/code&gt;）&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;此部分定义访问 Kubernetes 资源的权限。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;资源&lt;/strong&gt;：列出运行程序可以访问的 Kubernetes 资源，例如 &lt;code&gt;configmaps&lt;/code&gt;、&lt;code&gt;pods&lt;/code&gt;、&lt;code&gt;pods/attach&lt;/code &gt;、&lt;code&gt;秘密&lt;/code&gt;和&lt;code&gt;服务&lt;/code&gt;。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;动词&lt;/strong&gt;：可以对上述资源执行的操作，例如&lt;code&gt;get&lt;/code&gt;、&lt;code&gt;list&lt;/code&gt;、&lt;code&gt;watch&lt;/code&gt;、 &lt;code&gt;创建&lt;/code&gt;、&lt;code&gt;修补&lt;/code&gt;、&lt;code&gt;更新&lt;/code&gt;和&lt;code&gt;删除&lt;/code&gt;。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;apiGroups&lt;/strong&gt;：指定 Kubernetes 中的 API 组。此处为空 (&lt;code&gt;&#39;&#39;&lt;/code&gt;)，表示核心 API 组。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;资源&lt;/strong&gt;：列出上述 API 组的特定资源，例如 &lt;code&gt;pods/exec&lt;/code&gt;。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;动词&lt;/strong&gt;：&lt;code&gt;pod 允许执行的操作/exec &lt;/code&gt;资源，例如&lt;code&gt;创建&lt;/code&gt;，&lt;code&gt; patch &lt;/code&gt;和&lt;code&gt; delete &lt;/code&gt;。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class =“ wp-block头”&gt; &lt;strong&gt;跑步者（&lt;code&gt;跑步者&lt;/code&gt;）&lt;/strong&gt; &lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;定义跑步者配置。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class =“ wp-block-list”&gt;&#xA;&lt;li&gt; &lt;strong&gt;缓存&lt;/strong&gt;：缓存配置，当前为空（&lt;code&gt; {} &lt;/code&gt;）。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;strong&gt; config &lt;/strong&gt;：toml格式的跑步者配置。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;strong&gt; runners.kubernetes &lt;/strong&gt;：Kubernetes跑步者的配置。&#xA;&lt;ul class =“ wp-block-list”&gt;&#xA;&lt;li&gt; &lt;strong&gt;图像&lt;/strong&gt;：要使用的容器图像（&lt;code&gt; ubuntu：20.04 &lt;/code&gt;）。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;strong&gt; wait_for_services_timeout &lt;/strong&gt;：等待服务的超时（&lt;code&gt; -1 &lt;/code&gt;指示Infinite）。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;strong&gt;特权&lt;/strong&gt;：启用容器的特权模式（&lt;code&gt; true &lt;/code&gt;）。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;越&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;strong&gt; image_pull_secrets &lt;/strong&gt;：指定拉动容器图像的秘密（&lt;code&gt; aws-ecr &lt;/code&gt;）。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;strong&gt; configpath &lt;/strong&gt;：配置路径，当前为空（&lt;code&gt;&#39;&#39;&lt;/code&gt;）。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;strong&gt;名称&lt;/strong&gt;：跑步者名称（&lt;code&gt; globalweb-gitlab-runner &lt;/code&gt;）。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;strong&gt;特权&lt;/strong&gt;：指示特权执行（&lt;code&gt; true &lt;/code&gt;）。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;strong&gt; rununtagged &lt;/strong&gt;：指示是否运行未标记的作业（&lt;code&gt; true &lt;/code&gt;）。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;strong&gt;标签&lt;/strong&gt;：与跑步者关联​​的标签（&lt;code&gt; docker，share_cache，share_cache1，amd64 &lt;/code&gt;）。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class =“ wp-block头”&gt; &lt;strong&gt;秘密（&lt;code&gt; secrets &lt;/code&gt;）&lt;/strong&gt; &lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;秘密列表，当前为空（&lt;code&gt; [] &lt;/code&gt;）。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class =“ wp-block头”&gt; &lt;strong&gt; securityContext（&lt;code&gt; securitycontext &lt;/code&gt;）&lt;/strong&gt; &lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;容器的安全配置。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class =“ wp-block-list”&gt;&#xA;&lt;li&gt; &lt;strong&gt;允许privilegeEscalation &lt;/strong&gt;：特权升级的权限（&lt;code&gt; false &lt;/code&gt;）。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;strong&gt;功能&lt;/strong&gt;：容器功能。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;strong&gt; drop &lt;/strong&gt;：要删除的功能（&lt;code&gt; ALL &lt;/code&gt;）。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;strong&gt;特权&lt;/strong&gt;：指示容器是否特权（&lt;code&gt; false &lt;/code&gt;）。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;strong&gt; readonlylootfilesystem &lt;/strong&gt;：指示根文件系统是否仅读取（&lt;code&gt; false &lt;/code&gt;）。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;strong&gt; runasnonroot &lt;/strong&gt;：指示容器是否应作为非root用户运行（&lt;code&gt; true &lt;/code&gt;）。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class =“ wp-block头”&gt; &lt;strong&gt;其他密钥配置&lt;/strong&gt; &lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class =“ wp-block-list”&gt;&#xA;&lt;li&gt; &lt;strong&gt;服务（&lt;code&gt;服务&lt;/code&gt;）&lt;/strong&gt;：服务设置。 &lt;code&gt;启用：false &lt;/code&gt;，&lt;代码&gt;类型：clusterip &lt;/code&gt;。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;strong&gt; sessionserver（&lt;code&gt; sessionserver &lt;/code&gt;）&lt;/strong&gt;：默认禁用（&lt;code&gt; enabled：false &lt;/code&gt;）。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;strong&gt;终止宽限期秒秒（&lt;code&gt; terminationGracePeriodSecoNDS &lt;/code&gt;）&lt;/strong&gt;：优雅的终止超时（&lt;code&gt; 3600 &lt;/code&gt;秒）。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;H2 class =“ WP-block-heading”&gt;使用Gitlab CI Pipelines中的新跑步者&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;要在gitlab ci管道中使用新跑步者，请将&lt;code&gt; kubernetes &lt;/code&gt;标记添加到要在Kubernetes上执行的作业。例如：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class =“ wp-block-code”&gt; &lt;code class =“”&gt; build_image：&#xA;  阶段：构建&#xA;  图像：高山：最新&#xA;  标签：&#xA;    -Kubernetes&#xA;  脚本：&#xA;     - 回声“构建图像...” &lt;/code&gt; &lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr class =“ wp-block-separator has-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class =“ wp-block头”&gt; kubernetes不使用docker作为容器运行时？卡尼科进行救援&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt; kubernetes不使用Docker作为其默认容器运行时，这可能会对依靠Docker构建图像的CI/CD管道构成挑战。 Kaniko是一种工具，允许在没有Docker的情况下构建容器图像。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class =“ wp-block头”&gt;什么是kaniko，它如何工作？&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt; kaniko是一种开源工具，可从容器或kubernetes群集内的dockerfile构建容器图像。它通过提取基本容器文件系统，执行DockerFile命令并将结果包装到容器映像中来起作用。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class =“ wp-block头”&gt;在gitlab ci &lt;/h2&gt;中配置环境变量&#xA;&#xA;&#xA;&#xA;&lt;p&gt;要有效地使用kaniko，请在gitlab ci中配置必要的环境变量。这些变量包括用于访问您的容器注册表和特定项目信息的凭据。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class =“ WP-block-heading”&gt; &lt;strong&gt;配置管道环境变量的步骤&lt;/strong&gt; &lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class =“ wp-block-list”&gt;&#xA;&lt;li&gt;转到&lt;code&gt;设置&gt; gitlab项目的CI/CD &lt;/code&gt;。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;展开&lt;code&gt;变量&lt;/code&gt;章节。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;添加以下变量没有受保护的标志：&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class =“ wp-block-list”&gt;&#xA;&lt;li&gt; &lt;code&gt; aws_region &lt;/code&gt;：指定将管理资源的AWS区域。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;code&gt; AWS_ACCESS_KEY_ID &lt;/code&gt;：AWS public Access key for Authentication。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;code&gt; aws_secret_access_key &lt;/code&gt;：AWS秘密访问权限键。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;code&gt;注册表&lt;/code&gt;：存储Docker图像的容器注册表。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class =“ wp-block-heading”&gt;示例&lt;code&gt; .gitlab-ci.yml &lt;/code&gt;用于使用kaniko &lt;/h2&gt;构建和推动容器图像&#xA;&#xA;&#xA;&#xA;&lt;pre class =“ wp-block-code”&gt; &lt;code class =“”&gt;构建：&#xA;  阶段：构建&#xA;  图像：&#xA;    名称：gcr.io/kaniko-project/executor:debug&#xA;    入口点：[“”]&#xA;  脚本：&#xA;    -Mkdir -p /kaniko/.docker&#xA;     -  echo“ {\” Credsstore \“：\” ecr-login \“，\” Credhelpers \“：{\” $ gungrist /portal-colaborador-hml \ \“：\” ecr-login \“ ecr-login \”}}}}}}}} kaniko/.docker/config.json&#xA;     - &gt;  - &#xA;      /kaniko/executor&#xA;       -  context“ $ {ci_project_dir}” \&#xA;      -dockerfile“ $ {ci_project_dir}/dockerfile” \&#xA;      -build-arg aws_region = $ aws_region \&#xA;      -build-arg aws_access_key_id = $ aws_access_key_id \&#xA;       -  build-arg aws_secret_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY \&#xA;      --destination &#34;${REGISTRY}/portal-colaborador-hml:${CI_COMMIT_SHORT_SHA:0:5}&#34;&#xA;&#xA;  标签：&#xA;    - docker、share_cache、share_cache1、amd64&#xA;  仅有的：&#xA;    - 主要的&#xA;    - 开发&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;结论&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在 Kubernetes 上将 GitLab Runner 与 Kaniko 结合使用，可以实现高效、安全的容器映像构建和推送，而无需依赖 Docker 作为运行时。此配置利用 Kubernetes 的能力来扩展和管理 CI/CD 构建，从而为您的管道提供更大的灵活性和性能。&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Thu, 16 Jan 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【From PCAP to SCAP: how Falco’s libraries, registries, and plugins enable cloud native insights】从 PCAP 到 SCAP：Falco 的库、注册表和插件如何实现云原生洞察</title>
      <link>https://www.cncf.io/blog/2025/01/22/from-pcap-to-scap-how-falcos-libraries-registries-and-plugins-enable-cloud-native-insights/</link>
      <description>【&lt;p&gt;&lt;em&gt;Member post by &lt;a href=&#34;https://www.linkedin.com/in/nigel-douglas-sysdig/?originalSubdomain=ie&#34;&gt;Nigel Douglas&lt;/a&gt;, Sysdig&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-embed is-type-wp-embed is-provider-wistia-inc wp-block-embed-wistia-inc&#34;&gt;&lt;div class=&#34;wp-block-embed__wrapper&#34;&gt;&#xA;&lt;iframe loading=&#34;lazy&#34; class=&#34;wp-embedded-content&#34; sandbox=&#34;allow-scripts&#34; security=&#34;restricted&#34; title=&#34;Stratoshark – What&#39;s really happening in your cloud? Video&#34; src=&#34;https://fast.wistia.net/embed/iframe/m8klskgnjh?dnt=1#?secret=nrseT3UjIG&#34; data-secret=&#34;nrseT3UjIG&#34; frameborder=&#34;0&#34; scrolling=&#34;no&#34; width=&#34;500&#34; height=&#34;313&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In cloud-native systems, understanding the behaviour of complex, distributed web apps requires powerful tools that can dissect system activity down to its core. As the &lt;a href=&#34;https://www.cncf.io/announcements/2024/02/29/cloud-native-computing-foundation-announces-falco-graduation/&#34;&gt;&lt;strong&gt;CNCF graduate&lt;/strong&gt;&lt;/a&gt; project &lt;a href=&#34;http://falco.org/&#34;&gt;&lt;strong&gt;Falco&lt;/strong&gt;&lt;/a&gt; demonstrates, this often begins with monitoring system calls from the Linux kernel and &lt;strong&gt;enriching that data&lt;/strong&gt; across cloud and Kubernetes to provide actionable runtime insights. Falco’s libraries, registries, and plugins have not only revolutionised Linux runtime security but have also laid the groundwork for a growing ecosystem of tools capable of analysing system behaviour in cloud-native infrastructure.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio&#34;&gt;&lt;div class=&#34;wp-block-embed__wrapper&#34;&gt;&#xA;&lt;iframe loading=&#34;lazy&#34; title=&#34;Falco Features: Enrichment&#34; width=&#34;500&#34; height=&#34;281&#34; src=&#34;https://www.youtube.com/embed/VzSMCr2mZ6A?feature=oembed&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; referrerpolicy=&#34;no-referrer&#34; allowfullscreen=&#34;&#34;&gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Falco’s Foundations: libsinsp and libscap&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;At the heart of Falco are two foundational libraries: &lt;a href=&#34;https://github.com/falcosecurity/libsinsp&#34;&gt;&lt;strong&gt;libsinsp&lt;/strong&gt;&lt;/a&gt; (System INSPection LIBrary) and &lt;a href=&#34;https://github.com/falcosecurity/libscap&#34;&gt;&lt;strong&gt;libscap&lt;/strong&gt;&lt;/a&gt; (System CAPture LIBrary). These libraries enable Falco and other tools to extract, enrich, and analyse system call events from the operating system.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;libscap&lt;/strong&gt; operates as the low-level backbone, handling live capture control, trace file management, event retrieval, and OS state extraction. By communicating directly with drivers — such as kernel modules or eBPF probes — libscap captures syscall events and manages their storage in System CAPture (&lt;a href=&#34;https://sysdig.com/learn-cloud-native/what-is-an-scap-file/&#34;&gt;&lt;strong&gt;.scap&lt;/strong&gt;&lt;/a&gt;) files.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;libsinsp&lt;/strong&gt; builds on libscap by enriching raw syscall data with context, such as process metadata, file descriptors, and user associations. It mirrors the OS state, enabling users to treat low-level system primitives as high-level entities like programs or files. With advanced event filtering and a rule engine, libsinsp simplifies analysis, converting raw system data into meaningful insights.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Together, these libraries form the backbone of Falco’s runtime security capabilities, while also empowering other open-source projects.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;The Role of Plugins in Extending Capabilities&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Falco’s plugin framework makes these libraries adaptable to various data sources beyond system calls. &lt;a href=&#34;https://github.com/falcosecurity/plugins&#34;&gt;&lt;strong&gt;Plugins&lt;/strong&gt;&lt;/a&gt; can be created to ingest and process cloud audit logs, container events, and other telemetry, extending Falco’s functionality far beyond traditional syscall monitoring. This flexibility has opened the door for new tools and integrations, making Falco’s ecosystem more versatile and valuable.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Stratoshark: From PCAP to SCAP&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;One of the most exciting developments leveraging Falco’s libraries is &lt;a href=&#34;https://sysdig.com/opensource/Stratoshark&#34;&gt;&lt;strong&gt;Stratoshark&lt;/strong&gt;&lt;/a&gt;, an open-source project from the Sysdig team. Stratoshark takes the familiar Packet CAPture (&lt;a href=&#34;https://sysdig.com/learn-cloud-native/what-is-a-pcap-file/&#34;&gt;&lt;strong&gt;PCAP&lt;/strong&gt;&lt;/a&gt;) analysis experience of tools like Wireshark and brings it into the modern era of cloud-native systems with &lt;a href=&#34;https://github.com/draios/sysdig-workshop-forensics/blob/master/example0/commands&#34;&gt;&lt;strong&gt;SCAP&lt;/strong&gt;&lt;/a&gt; files.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Using &lt;strong&gt;libsinsp&lt;/strong&gt; and &lt;strong&gt;libscap&lt;/strong&gt;, Stratoshark captures and analyses syscall activity and cloud audit logs, providing a powerful yet user-friendly interface for dissecting these datasets. It supports the same file formats as &lt;a href=&#34;https://sysdig.com/blog/falco-vs-sysdig-oss&#34;&gt;&lt;strong&gt;Falco and Sysdig CLI&lt;/strong&gt;&lt;/a&gt;, allowing seamless transitions between tools. With Stratoshark, users can filter and analyse system call activity just as network administrators have long done with packet captures, enabling new insights into application-level behaviour in cloud environments.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Comparing Ecosystem Approaches: Tracee, Tetragon, and Falco&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Falco and Sysdig aren’t the only tools exploring the power of system call monitoring. Tracee and Tetragon are notable alternatives that provide unique approaches:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/aquasecurity/tracee&#34;&gt;&lt;strong&gt;Tracee&lt;/strong&gt;&lt;/a&gt; uses eBPF to monitor runtime activity and detect security events. It emphasises real-time visibility into system behaviour and uncovers suspicious runtime activity patterns.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/cilium/tetragon&#34;&gt;&lt;strong&gt;Tetragon&lt;/strong&gt;&lt;/a&gt; promises Kubernetes-aware observability and security enforcement. By applying policies directly within eBPF, it claims to reduce overhead while providing real-time runtime enforcement.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Where &lt;strong&gt;Falco&lt;/strong&gt; and &lt;strong&gt;Stratoshark&lt;/strong&gt; differentiate themselves is in their approachability and flexibility. Falco’s plugin architecture and Stratoshark’s ability to read SCAPs for post-incident forensics brings a Wireshark-like experience to the Linux kernel and cloud-native world. The pair also bridges the gap between system call data and the overlying abstractions of cloud and Kubernetes logs for both security and performance tuning.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Why Understanding System Calls in a Cloud-Native Context Matters&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://sysdig.com/blog/kernel-introspection-from-linux-to-windows/#:~:text=System%20calls%20(syscalls%20for%20short,space%20applications%20and%20the%20kernel.&#34;&gt;&lt;strong&gt;System calls&lt;/strong&gt;&lt;/a&gt;, the interface between applications and the operating system, are fundamental to understanding container workload behaviour. Tools like Falco, Tracee, and Tetragon allow developers and operators to peer into these interactions, uncovering anomalies, optimising performance, and improving security observability.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Falco’s libraries and plugins provide the foundation for this analysis, making system calls both accessible and actionable. By supporting tools like Stratoshark, they enable deeper exploration of cloud-native systems while maintaining the flexibility to integrate with other data sources and ecosystems.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;The Road Ahead&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As cloud-native adoption continues to grow, tools like Falco and Stratoshark will become increasingly critical. Their ability to unify system call data, enrich it with context, and present it in an accessible way empowers teams to troubleshoot, secure, and optimize modern applications.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.cncf.io/blog/2024/11/06/why-falcos-new-response-engine-is-a-game-changer-for-open-source-cloud-native-security/&#34;&gt;&lt;strong&gt;Falco’s contributions&lt;/strong&gt;&lt;/a&gt; to the CNCF ecosystem exemplify the power of open-source collaboration and the importance of building foundational tools that inspire innovation. With projects like Stratoshark leading the way, the evolution from PCAP to SCAP is a leap forward for security and observability in the cloud-native era.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you’re interested in trying out Stratoshark today, you can check it out at &lt;a href=&#34;https://stratoshark.org/&#34;&gt;&lt;strong&gt;https://stratoshark.org&lt;/strong&gt;&lt;/a&gt;.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt; &lt;em&gt;成员帖子&lt;a href =“ https://www.linkedin.com/in/nigel-douglas-sysdig/?originalsubdomain=ie”&gt; nigel douglas &lt;/a&gt;，sysdig &lt;/a&gt; &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figie class =“ wp-block-embed is-type-wp-embed是provider-wistia-inc-inc wp-block-embed-wistia-inc”&gt; &lt;div class =“ wp-block-embed __wrapper”&gt;&#xA;&lt;iframe loading =“ lazy” class =“ wp-embedded-content” sandbox =“ allow-scripts” security =“限制” title =“ stratoshark  - 您的云中发生了什么？ 。 no-Referrer“&gt; &lt;/iframe&gt;&#xA;&lt;/div&gt; &lt;/figie&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在云本地系统中，了解复杂的，分布式Web应用程序的行为需要强大的工具，可以将系统活动剖析到其核心。如&lt;a href =“ https://www.cncf.io/announcements/2024/02/02/02/02/cloud-native-computing-foundation-foundation-announces-falco-gradation/&gt; &lt;strong&gt; &lt;strong&gt; &lt;/a&gt;项目&lt;a href =“ http://falco.org/”&gt; &lt;strong&gt; falco &lt;/strong&gt; &lt;/a&gt;证明，这通常始于监视Linux内核和&lt;strong&gt; Enriching的系统调用这些数据&lt;/strong&gt;跨越云和Kubernetes提供可行的运行时见解。 Falco的图书馆，注册表和插件不仅彻底改变了Linux运行时安全性，而且为不断增长的工具生态系统奠定了基础，能够分析云本地基础架构中的系统行为。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figie class =“ wp-block-embed iS-type-video是provider-youtube wp-block-embed-youtube wp-embed-embed-16-9 wp-has-pect-apept-apept-ratio”&gt; &lt;div class =&#39;&gt; &lt;div class =“ wp-block-embed__wrapper”&gt;&#xA;&lt;iframe loading =“ lazy” title =“ falco feature：富集” width =“ 500” height =“ 281” src =“ https://www.youtube.com/embed/vzsmcr2mz6a？feature = oembed = “ =”加速度计；&#xA;&lt;/div&gt; &lt;/figie&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class =“ wp-block头”&gt; Falco的基础：libsinsp和libscap &lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt; Falco的核心是两个基础图书馆：&lt;a href =“ https://github.com/falcosecurity/libsinsp”&gt; &lt;strong&gt; libsinsp &lt;/strong&gt; &lt;/a&gt;（系统检查库）和&lt; a href =“ https://github.com/falcosecurity/libscap”&gt; &lt;strong&gt; libscap &lt;/strong&gt; &lt;/a&gt;（系统捕获库）。这些库使FALCO和其他工具能够从操作系统提取，丰富和分析系统呼叫事件。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class =“ wp-block-list”&gt;&#xA;&lt;li&gt; &lt;strong&gt; libscap &lt;/strong&gt;作为低级骨干，处理实时捕获控制，跟踪文件管理，事件检索和OS状态提取。通过直接与驱动程序（例如内核模块或EBPF探针）进行通信，libscap捕获SYSCALL事件并管理其在系统捕获中的存储（&lt;a href =“ https://sysdig.com/learn-cloud-native/what what what -scap-file/“”&gt; &lt;strong&gt; .scap &lt;/strong&gt; &lt;/a&gt;）文件。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class =“ wp-block-list”&gt;&#xA;&lt;li&gt; &lt;strong&gt; libsinsp &lt;/sTRONG&gt;通过使用上下文（例如过程元数据，文件描述符和用户关联）丰富原始的SYSCALL数据来构建LIBSCAP。它反映了操作系统状态，使用户能够将低级系统基础视为程序或文件等高级实体。通过高级事件过滤和规则引擎，Libsinsp简化了分析，将原始系统数据转换为有意义的见解。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在一起，这些库构成了Falco运行时安全功能的骨干，同时还赋予其他开源项目。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class =“ wp-block头”&gt;插件在扩展功能中的作用&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt; Falco的插件框架使这些库可适应系统调用以外的各种数据源。 &lt;a href =“ https://github.com/falcosecurity/plugins”&gt; &lt;strong&gt; plugins &lt;/strong&gt; &lt;/a&gt;可以创建以摄入和处理云审核日志，容器事件和其他遥测，并扩展Falco&#39;s功能远远超出了传统的SYSCALL监控。这种灵活性为新工具和集成开辟了大门，使Falco的生态系统更加通用和有价值。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class =“ wp-block头”&gt; StratoShark：从PCAP到SCAP &lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;利用Falco图书馆的最激动人心的发展之一是&lt;a href =“ https://sysdig.com/opensource/stratoshark”&gt; &lt;strong&gt; Stratoshark &lt;/strong&gt; &lt;/a&gt; Sysdig团队。 StratoShark进行熟悉的数据包捕获（&lt;a href =“ https://sysdig.com/learn-cloud-native/what-is-a-pcap-file/”&gt; &lt;strong&gt; pcap &lt;/strong&gt; &lt;/a&gt; ）分析WireShark等工具的分析经验，并将其带入现代云本地系统的现代时代，&lt;a href =“ https://github.com/draios/sysdig-workshop-forensics/blob/master/master/master/example0/command0/commands”&gt; &lt;strong&gt; scap &lt;/strong&gt; &lt;/a&gt;文件。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;使用&lt;strribsinsp &lt;/strong&gt;和&lt;strong&gt; libscap &lt;/strong&gt;，StratoShark捕获和分析Syscall活动和云审核日志，提供了一个功能强大但用户友好的界面来剖析这些数据集。它支持与&lt;a href =“ https://sysdig.com/blog/falco-vs-sysdig-oss”&gt; &lt;strong&gt; falco and sysdig cli &lt;/strong&gt; &lt;/a&gt;，允许无缝过渡，在工具之间。使用StratoShark，用户可以过滤和分析系统调用活动，就像网络管理员长期以来对数据包捕获完成的工作，从而为云环境中的应用程序级行为提供了新的见解。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;H3 class =“ WP-block-neading”&gt;比较生态系统方法：Tracee，Tetragon和Falco &lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt; Falco和Sysdig并不是探索系统呼叫监视功能的唯一工具。 Tracee和Tetragon是提供独特方法的显着替代方法：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class =“ wp-block-list”&gt;&#xA;&lt;li&gt; &lt;a href =“ https://github.com/aquasecurity/tracee”&gt; &lt;strong&gt; tracee &lt;/strong&gt; &lt;/a&gt;使用EBPF监视运行时活动并检测安全事件。它强调了对系统行为的实时可见性，并发现可疑的运行时活动模式。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class =“ wp-block-list”&gt;&#xA;&lt;li&gt;&lt;a href =“ https://github.com/cilium/tetragon”&gt; &lt;strong&gt; tetragon &lt;/strong&gt; &lt;/a&gt;承诺Kubernetes-WAWARE可观察性和安全执行。通过直接在EBPF中应用策略，它声称在提供实时运行时执行时减少开销。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;其中&lt;strong&gt; falco &lt;/strong&gt;和&lt;strtroshark &lt;/strong&gt;与众不同的是它们的可接近性和灵活性。 Falco的插件架构和Stratoshark能够阅读SCAP的Inctintion Postefent Forensics的能力为Linux内核和云本地世界带来了类似Wireshark的体验。两人还弥合了系统调用数据之间的差距以及云和Kubernetes日志上的上覆的抽象，以进行安全性和性能调整。&lt;/p&gt; &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class =“ wp-block头”&gt;为什么理解系统在云本地上下文中呼叫&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt; &lt;a href =“ https://sysdig.com/blog/kernel-introspection-from-linux-to-windows/#:~: text=syxt=systemp.syscalls%20(Syscalls%20For%20For%20For%20Space space space； 20 Applications％20和％20％20KERNEL。”&gt; &lt;strong&gt;系统调用&lt;/strong&gt; &lt;/a&gt;，应用程序和操作系统之间的界面对于了解容器工作负载行为至关重要。Falco，Tracee和Tetragon等工具允许开发人员和运营商可以凝视这些交互，发现异常，优化性能并提高安全性可观察性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt; Falco的库和插件为此分析提供了基础，使系统调用既可以访问又可操作。通过支持StratoShark之​​类的工具，它们可以更深入地探索云本地系统，同时保持与其他数据源和生态系统集成的灵活性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class =“ wp-block头”&gt;前方的道路&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;随着云本地采用的不断增长，Falco和Stratoshark等工具将变得越来越关键。他们统一系统调用数据，用上下文丰富它的能力，并以可访问的方式呈现它，使团队能够对现代应用程序进行故障排除，安全和优化。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt; &lt;a href =“ https://www.cncf.io/blog/2024/2024/11/11/11/why-falcos-new-response-eengine-engine-eengine-is-is-a-a-game-changer-for-changer-for-open-source-source-source-source-source-source-source-source-source-source-source-source-source-对CNCF生态系统的Falco的贡献&lt;/strong&gt; &lt;/a&gt; &lt;strong&gt; &lt;strong&gt; &lt;strong&gt; &lt;strong&gt; &lt;/strong&gt; &lt;/a&gt;体现了开源协作的力量以及构建激发创新创新的基础工具的重要性。随着StratoShark之​​类的项目领先，从PCAP到SCAP的演变是云本地时代的安全性和可观察性的飞跃。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您有兴趣今天尝试StratoShark，则可以在&lt;a href =“ https://stratoshark.org/”上查看它。 /a&gt;。 &lt;/p&gt;&#xA;&#xA;在&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;在&#xA;&lt;/div&gt;</description>
      <pubDate>Tue, 21 Jan 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Observing and monitoring Large Language Model workloads with Ray】使用射线观察和监视大型语言模型工作负载</title>
      <link>https://www.cncf.io/blog/2025/01/16/observing-and-monitoring-large-language-model-workloads-with-ray/</link>
      <description>【&lt;p&gt;&lt;em&gt;Ambassador post by &lt;a href=&#34;https://github.com/swastik959&#34;&gt;Swastik Gour&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Introduction&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#introduction&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The emergence of Large Language Models (LLMs) such as GPT-4, PHI2, BERT, and T5 revolutionized natural language processing, with these models empowering high-end applications, including chatbots, recommendation systems, and analytics. Yet the scale and complexity of workloads in LLMs make them a great challenge to guarantee performance and reliability. It is under such circumstances that monitoring and observability practices are more than essential while deploying workloads using frameworks such as Ray.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Ray is a distributed computing framework that offers a powerful platform to scale LLM workloads efficiently across clusters. Therefore, it becomes an excellent choice for hosting, managing, and observing LLMs. The observability of critical metrics with Ray’s built-in features in conjunction with Prometheus and Grafana will help users to monitor them efficiently, optimize the use of resources, and rapidly diagnose problems in production.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This article explores the importance of observability in Ray-hosted LLM workloads, key metrics to monitor, and a detailed guide to setting up observability using Prometheus and Grafana.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Why Ray for LLM Workloads?&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#why-ray-for-llm-workloads&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Ray is designed for distributed, scalable applications, making it ideal for hosting and managing LLM workloads. Key features that make Ray an excellent choice include:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Dynamic Task Scheduling:&lt;/strong&gt;&amp;nbsp;Ray’s fine-grained task scheduling ensures efficient resource utilization, especially when processing LLM inference tasks that can vary significantly in size and complexity.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Ease of Integration:&lt;/strong&gt;&amp;nbsp;Ray integrates seamlessly with frameworks like Hugging Face Transformers, enabling easy deployment of pre-trained LLMs.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Autoscaling:&lt;/strong&gt;&amp;nbsp;Ray’s cluster autoscaler dynamically adjusts resources based on workload demands, ensuring cost-effectiveness and scalability.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Observability Support:&lt;/strong&gt;&amp;nbsp;Ray provides metrics endpoints compatible with Prometheus, simplifying the monitoring setup for distributed systems.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;These features make Ray not just a compute framework but a foundational tool for running, monitoring, and scaling LLMs in real-world applications.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Key Metrics for Observing Ray-Hosted LLM Workloads&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#key-metrics-for-observing-ray-hosted-llm-workloads&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To ensure the smooth operation of Ray-hosted LLM workloads, it’s critical to track a range of performance, resource utilization, and operational metrics. Below are the key categories:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;Performance Metrics&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#performance-metrics&#34;&gt;&lt;/a&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Task Latency:&lt;/strong&gt;&amp;nbsp;Measures the time taken for individual Ray tasks to complete, essential for identifying bottlenecks in the inference pipeline.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Throughput:&lt;/strong&gt;&amp;nbsp;Tracks the number of tasks completed per second, reflecting the system’s ability to handle high request volumes.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Token Processing Rate:&lt;/strong&gt;&amp;nbsp;Measures the number of tokens processed per second, particularly relevant for transformer-based models like GPT-4.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;Resource Utilization Metrics&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#resource-utilization-metrics&#34;&gt;&lt;/a&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;CPU and GPU Utilization:&lt;/strong&gt;&amp;nbsp;Monitors resource usage across the cluster to ensure efficient workload distribution.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Memory Usage:&lt;/strong&gt;&amp;nbsp;Tracks memory consumption to prevent out-of-memory errors, especially critical for hosting large models.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Object Store Utilization:&lt;/strong&gt;&amp;nbsp;Observes the usage of Ray’s in-memory object store for efficient data sharing across tasks.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;Operational Metrics&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#operational-metrics&#34;&gt;&lt;/a&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Error Rates:&lt;/strong&gt;&amp;nbsp;Monitors task failure rates to detect and resolve issues quickly.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Node Availability:&lt;/strong&gt;&amp;nbsp;Tracks the health of nodes in the Ray cluster, ensuring reliability.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Queue Length:&lt;/strong&gt;&amp;nbsp;Measures the number of pending tasks, signaling potential bottlenecks in processing.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Setting Up Observability for Ray-Hosted Workloads&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#setting-up-observability-for-ray-hosted-workloads&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Observability in Ray involves using metrics to understand system performance and diagnose issues. By integrating Ray with Prometheus and Grafana, you can gain deep insights into workload behavior.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;Step 1: Setting Up Prometheus Monitoring&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#step-1-setting-up-prometheus-monitoring&#34;&gt;&lt;/a&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Prometheus is an open-source monitoring system that collects metrics from Ray’s endpoints. Follow the guide below to set up Prometheus with Ray on Kubernetes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Install Prometheus with KubeRay:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;# Path: kuberay/&#xA;./install/prometheus/install.sh&#xA;&#xA;# Check the installation&#xA;kubectl get all -n prometheus-system&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;Configure Pod and Service Monitors&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#configure-pod-and-service-monitors&#34;&gt;&lt;/a&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Set up PodMonitor and ServiceMonitor resources to scrape metrics from Ray head and worker nodes:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;apiVersion: monitoring.coreos.com/v1&#xA;kind: PodMonitor&#xA;metadata:&#xA;  name: ray-workers-monitor&#xA;  namespace: prometheus-system&#xA;  labels:&#xA;    release: prometheus&#xA;    ray.io/cluster: rayservice-sample-raycluster-bpkgv&#xA;spec:&#xA;  jobLabel: ray-workers&#xA;  namespaceSelector:&#xA;    matchNames:&#xA;      - raysvc&#xA;  selector:&#xA;    matchLabels:&#xA;      ray.io/node-type: worker&#xA;  podMetricsEndpoints:&#xA;    - port: metrics&#xA;---&#xA;apiVersion: monitoring.coreos.com/v1&#xA;kind: ServiceMonitor&#xA;metadata:&#xA;  name: resume-analyzer-monitor&#xA;  namespace: prometheus-system&#xA;  labels:&#xA;    release: prometheus&#xA;spec:&#xA;  jobLabel: resume-analyzer&#xA;  namespaceSelector:&#xA;    matchNames:&#xA;      - raysvc&#xA;  selector:&#xA;    matchLabels:&#xA;      ray.io/node-type: head&#xA;    endpoints:&#xA;      - port: metrics&#xA;    targetLabels:&#xA;      - ray.io/cluster&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;Step 2: Configure Recording Rules&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#step-2-configure-recording-rules&#34;&gt;&lt;/a&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Recording rules allow you to precompute PromQL expressions for faster queries. For example, calculating the availability of the Ray Global Control Store (GCS):&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;apiVersion: monitoring.coreos.com/v1&#xA;kind: PrometheusRule&#xA;metadata:&#xA;  name: ray-cluster-gcs-rules&#xA;  namespace: prometheus-system&#xA;  labels:&#xA;    release: prometheus&#xA;spec:&#xA;  groups:&#xA;  - name: ray-cluster-main-staging-gcs.rules&#xA;    interval: 30s&#xA;    rules:&#xA;    - record: ray_gcs_availability_30d&#xA;      expr: |&#xA;        (&#xA;          100 * (&#xA;            sum(rate(ray_gcs_update_resource_usage_time_bucket{container=&#34;ray-head&#34;, le=&#34;20.0&#34;}[30d]))&#xA;            /&#xA;            sum(rate(ray_gcs_update_resource_usage_time_count{container=&#34;ray-head&#34;}[30d]))&#xA;          )&#xA;        )&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Explanation of the Expression:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;code&gt;ray_gcs_update_resource_usage_time_bucket&lt;/code&gt;: Tracks the latency of resource usage updates.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;code&gt;ray_gcs_update_resource_usage_time_count&lt;/code&gt;: Counts the total number of updates.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;The expression calculates the percentage of updates completed within a specific latency threshold over the last 30 days.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;Step 3: Set Up Alerting Rules&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#step-3-set-up-alerting-rules&#34;&gt;&lt;/a&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Alert rules help identify issues proactively. For example, detecting missing GCS metrics:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;apiVersion: monitoring.coreos.com/v1&#xA;kind: PrometheusRule&#xA;metadata:&#xA;  name: ray-cluster-gcs-rules&#xA;  namespace: prometheus-system&#xA;  labels:&#xA;    release: prometheus&#xA;spec:&#xA;  groups:&#xA;  - name: ray-cluster-main-staging-gcs.rules&#xA;    interval: 30s&#xA;    rules:&#xA;    - alert: MissingMetricRayGlobalControlStore&#xA;      expr: |&#xA;        absent(ray_gcs_update_resource_usage_time_count)&#xA;      for: 1m&#xA;      labels:&#xA;        severity: warning&#xA;      annotations:&#xA;        summary: &#34;Missing Ray GCS metrics&#34;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Setting Up Grafana Dashboards&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#setting-up-grafana-dashboards&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Grafana provides rich visualizations for metrics. Here’s how to set up dashboards for Ray:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;Step 1: Capture Default Dashboards&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#step-1-capture-default-dashboards&#34;&gt;&lt;/a&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Copy default dashboards from the Ray head pods:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;kubectl cp &amp;lt;head-pod&amp;gt;:/tmp/ray/session_latest/metrics/grafana/dashboards/ ./dashboards&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;Step 2: Access the Grafana Dashboard&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#step-2-access-the-grafana-dashboard&#34;&gt;&lt;/a&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;kubectl port-forward deployment/prometheus-grafana -n prometheus-system 3000:3000&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Default login credentials:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Username:&amp;nbsp;&lt;code&gt;admin&lt;/code&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Password:&amp;nbsp;&lt;code&gt;prom-operator&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Enable Profiling in Ray Serve Pods&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#enable-profiling-in-ray-serve-pods&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Advanced Profiling in Ray Serve Pods The profiling of inference workloads relies on sophisticated techniques for monitoring, debugging, and optimizing performance. This section digs into specific tools, configurations, and scenarios to augment your profiling abilities.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;Memory Profiling&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#memory-profiling&#34;&gt;&lt;/a&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Memory profiling is essential for memory leaks detection and usage optimization. For example, with Memray, trace memory allocations and understand the behavior of inference tasks. To enable memory profiling in Ray Serve pods, update the container’s security context to allow tracing:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;securityContext:&#xA;  capabilities:&#xA;    add:&#xA;    - SYS_PTRACE&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Once configured, Memray can be used to generate memory usage reports, which can help identify high-memory-consuming tasks or bottlenecks in the system.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Example Use Case:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Profiling memory usage during a batch inference task with a large transformer model to optimize batch sizes and reduce memory overhead.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;CPU Profiling&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#cpu-profiling&#34;&gt;&lt;/a&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For CPU profiling, tools like&amp;nbsp;&lt;code&gt;gdb&lt;/code&gt;,&amp;nbsp;&lt;code&gt;lldb&lt;/code&gt;, or&amp;nbsp;&lt;code&gt;py-spy&lt;/code&gt;&amp;nbsp;can be installed within the worker pods to collect detailed CPU usage data. These tools allow you to monitor which functions consume the most CPU time, enabling targeted optimizations.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To set up CPU profiling:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Install&amp;nbsp;&lt;code&gt;gdb&lt;/code&gt;&amp;nbsp;or&amp;nbsp;&lt;code&gt;lldb&lt;/code&gt;&amp;nbsp;in the ray worker pod.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Use profiling scripts or tools to capture CPU usage snapshots during inference tasks.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Example Use Case:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Identifying CPU-bound operations in pre-processing pipelines to offload them to GPUs or optimize their implementation.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;End-to-End Profiling Example&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#end-to-end-profiling-example&#34;&gt;&lt;/a&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;When you integrate memory and CPU profiling, it gives you an overarching view of system performance. To illustrate this better, consider an LLM inference task where you have latency spikes. If you correlate your memory and CPU profiles you will find:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The main culprit behind the memory usage is that huge batches of input data.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;CPU bottlenecks are caused due to inefficiencies in tokenization functions.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you optimize batch sizes and refactor bottleneck functions your performance might increase up to a considerable extent.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Conclusion&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#conclusion&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Using Ray’s distributed LLM workloads with the observability of robust tools will ensure that teams get performance, reliability, and scalability out of these systems. This is a guide to set up and monitor LLM workloads on Ray in a very practical way. Proper observability will help developers and operators find issues early, optimize the use of resources, and further improve the experience users get when using NLP applications.&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#observing-and-monitoring-large-language-model-workloads-with-ray&#34;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;大使帖子，作者：&lt;a href=&#34;https://github.com/swastik959&#34;&gt;Swastik Gour&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;简介&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#introduction&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;GPT-4、PHI2、BERT 和 T5 等大型语言模型 (LLM) 的出现彻底改变了自然语言处理，这些模型支持高端应用程序，包括聊天机器人、推荐系统和分析。然而，法学硕士工作负载的规模和复杂性使它们在保证性能和可靠性方面面临巨大挑战。在这种情况下，使用 Ray 等框架部署工作负载时，监控和可观察性实践就变得非常重要。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Ray 是一个分布式计算框架，它提供了一个强大的平台，可以跨集群有效地扩展 LLM 工作负载。因此，它成为举办、管理和观察法学硕士的绝佳选择。 Ray 的内置功能与 Prometheus 和 Grafana 结合实现关键指标的可观察性，将帮助用户有效地监控它们，优化资源的使用，并快速诊断生产中的问题。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;本文探讨了 Ray 托管的 LLM 工作负载中可观察性的重要性、要监控的关键指标以及使用 Prometheus 和 Grafana 设置可观察性的详细指南。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;为什么选择 Ray for LLM 工作负载？&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#why-ray-for-llm -工作负载&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Ray 专为分布式、可扩展的应用程序而设计，非常适合托管和管理 LLM 工作负载。使 Ray 成为绝佳选择的主要功能包括：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;动态任务调度&lt;/strong&gt;：Ray 的细粒度任务调度可确保高效的资源利用，尤其是在处理大小和复杂性差异很大的 LLM 推理任务时。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;易于集成&lt;/strong&gt;：Ray 与 Hugging Face Transformers 等框架无缝集成，可轻松部署预先训练的 LLM。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;自动扩缩&lt;/strong&gt;：Ray 的集群自动扩缩器可根据工作负载需求动态调整资源，确保成本效益和可扩展性。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;可观测性支持&lt;/strong&gt;：Ray 提供与 Prometheus 兼容的指标端点，简化了分布式系统的监控设置。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这些功能使 Ray 不仅仅是一个计算框架，而且是在现实应用程序中运行、监控和扩展 LLM 的基础工具。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;观察 Ray 托管的 LLM 工作负载的关键指标&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#key-metrics- for-observing-ray-hosted-llm-workloads&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;为了确保 Ray 托管的 LLM 工作负载顺利运行，至关重要的是跟踪一系列性能，资源利用和操作指标。以下是关键类别：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class =“ wp-block-heading”&gt;性能指标&lt;a href =“ https://github.com/swastik959/blogs/tree/main/main/main/ray-ray-observibility#performance-metrics-metrics”&gt; &lt;/a&gt; &lt;/a&gt; &lt;/a&gt; &lt;/&gt; &lt;/&gt; &lt;/&gt; &lt;/&gt; &lt;/&gt; &lt;/&gt; &lt;/&gt; &lt;/ H4&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class =“ wp-block-list”&gt;&#xA;&lt;li&gt; &lt;strong&gt;任务延迟：&lt;/strong&gt;测量单个光线任务完成的时间，对于识别推理管道中的瓶颈至关重要。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;strong&gt;吞吐量：&lt;/strong&gt;跟踪每秒完成的任务数量，反映了系统处理高请求量的能力。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;strong&gt;令牌处理率：&lt;/strong&gt;测量每秒处理的令牌数量，尤其与基于变压器的模型（如GPT-4）相关。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class =“ wp-block-heading”&gt;资源利用度量&lt;a href =“ https://github.com/swastik959/blogs/tree/main/main/ray-observiality#resource-resource-resource-resource-utilization-utilization-utilization-metrics”&gt; &lt;/a&gt; &lt;/a &gt; &lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class =“ wp-block-list”&gt;&#xA;&lt;li&gt; &lt;strong&gt; CPU和GPU利用率：&lt;/strong&gt;监视整个集群的资源使用，以确保有效的工作负载分布。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;strong&gt;内存使用量：&lt;/strong&gt;跟踪记忆消耗以防止记忆误差，尤其对于托管大型模型至关重要。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;strong&gt;对象存储的利用：&lt;/strong&gt;观察Ray的内存对象存储的用法，以跨任务共享有效的数据。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class =“ wp-block-heading”&gt;操作指标&lt;a href =“ https://github.com/swastik959/blogs/tree/main/main/main/ray-observibality#operational-metrication-metrications”&gt; &lt;/a&gt; &lt;/a&gt; &lt;/&gt; &lt;/&gt; &lt;/&gt; &lt;/&gt; &lt;/&gt; &lt;/&gt; &lt;/&gt; &lt;/&gt; &lt;/ H4&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class =“ wp-block-list”&gt;&#xA;&lt;li&gt; &lt;strong&gt;错误率：&lt;/strong&gt;监视任务失败率以快速检测和解决问题。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;strong&gt;节点可用性：&lt;/strong&gt;跟踪射线簇中的节点的健康，可确保可靠性。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;strong&gt;队列长度：&lt;/strong&gt;测量未决任务的数量，发出了处理中潜在的瓶颈。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class =“ wp-block-heading”&gt;设置射线 - 固定工作负载的可观察性&lt;a href =“ https://github.com/swastik959/blogs/blogs/tree/tree/main/main/ray-ray-brea-broser-ray-observibility#setting-setting-up-pobservipity-up-pobservapiety -For-ray-hosted-workloads“&gt; &lt;/a&gt; &lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;射线中的可观察性涉及使用指标来了解系统性能和诊断问题。通过将Ray与Prometheus和Grafana集成，您可以深入了解工作量行为。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class =“ wp-block-heading”&gt;步骤1：设置Prometheus监视&lt;a href =“ https://github.com/swastik959/blogs/tree/tree/main/main/ray-observibility#step-steppep-step-step-step-step-1-setting-setting-setting-setting-setting-setting-setting-setting-上索斯 - 莫恩特（&gt; &lt;/a&gt; &lt;/h4&gt;）&#xA;&#xA;&#xA;&#xA;&lt;p&gt; Prometheus是一种开源监控系统，可从Ray的端点收集指标。按照下面的指南在kubernetes上使用射线设置Prometheus。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt; &lt;strong&gt;用kuberay安装Prometheus：&lt;/strong&gt; &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class =“ wp-block-code”&gt; &lt;code class =“”&gt;＃路径：kuberay/&#xA;./install/prometheus/install.sh&#xA;&#xA;＃检查安装&#xA;kubectl get所有-n Prometheus -System &lt;/code&gt; &lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class =“ wp-block-heading”&gt;配置POD和服务监视器&lt;A href =“ https://github.com/swastik959/blogs/tree/tree/main/main/ray-observialice#configure-pod-pod-pod-and-service-service--service--service--service--service-监视器“&gt; &lt;/a&gt; &lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;设置podmonitor和ServiceMonitor资源以从射线头和工人节点刮擦指标：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;在&#xA;KIND：PODMONITOR&#xA;元数据：&#xA;  名称：射线工人监测器&#xA;  名称空间：Prometheus-System&#xA;  标签：&#xA;    发行：普罗米修斯&#xA;    Ray.io/cluster：Rayservice-Sample-RayCluster-BPKGV&#xA;规格：&#xA;  玻璃旗：射线工人&#xA;  namespaceselector：&#xA;    匹配名称：&#xA;      -raysvc&#xA;  选择器：&#xA;    MatchLabels：&#xA;      ray.io/node-type：工人&#xA;  podmetricsendpoints：&#xA;     - 端口：指标&#xA;---&#xA;apiversion：Menualing.coreos.com/V1&#xA;KIND：ServiceMonitor&#xA;元数据：&#xA;  姓名：简历 - 分析仪图&#xA;  名称空间：Prometheus-System&#xA;  标签：&#xA;    发行：普罗米修斯&#xA;规格：&#xA;  玻璃标签：简历 - 分析仪&#xA;  namespaceselector：&#xA;    匹配名称：&#xA;      -raysvc&#xA;  选择器：&#xA;    MatchLabels：&#xA;      ray.io/node-type：头&#xA;    端点：&#xA;       - 端口：指标&#xA;    目标标签：&#xA;      -Ray.io/cluster&lt;/Code&gt; &lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class =“ wp-block-heading”&gt;步骤2：配置录制规则&lt;a href =“ https://github.com/swastik959/blogs/tree/tree/main/main/ray-observiality#step-2-configure-configure-recorting -rules“&gt; &lt;/a&gt; &lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;记录规则允许您预先计算更快查询的PROMQL表达式。例如，计算射线全局控制存储（GCS）的可用性：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;在&#xA;善良：普罗米修&#xA;元数据：&#xA;  名称：Ray-Cluster-GCS规则&#xA;  名称空间：Prometheus-System&#xA;  标签：&#xA;    发行：普罗米修斯&#xA;规格：&#xA;  组：&#xA;   - 名称：Ray-Cluster-Main stipang-gcs.rules&#xA;    间隔：30年代&#xA;    规则：&#xA;     - 记录：ray_gcs_availability_30d&#xA;      expr：|&#xA;        （（&#xA;          100 *（（&#xA;            sum（速率（ray_gcs_update_resource_usage_time_bucket {container =“ ray-head”，le =“ 20.0”} [30d]）））））&#xA;            /&#xA;            sum（rate（ray_gcs_update_resource_usage_time_count {container =“ ray-head”} [30d]）））））&#xA;          ）&#xA;        ）&lt;/code&gt; &lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt; &lt;strong&gt;表达式的解释：&lt;/strong&gt; &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class =“ wp-block-list”&gt;&#xA;&lt;li&gt; &lt;code&gt; ray_gcs_update_resource_usage_time_bucket &lt;/code&gt;：跟踪资源用法更新的延迟。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;code&gt; ray_gcs_update_resource_usage_time_count &lt;/code&gt;：计数更新的总数。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;表达式计算过去30天内在特定潜伏阈值中完成的更新百分比。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class =“ wp-block-heading”&gt;步骤3：设置警报规则&lt;a href =“ https://github.com/swastik959/blogs/tree/tree/main/main/ray-observiality#step-step-3-set-set-set-set-set--set--set--set--set--上升符号“&gt; &lt;/a&gt; &lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;警报规则有助于主动识别问题。例如，检测缺失的GCS指标：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;在&#xA;善良：普罗米修&#xA;元数据：&#xA;  名称：射线群 - gcs规则&#xA;  命名空间：普罗米修斯系统&#xA;  标签：&#xA;    发布： 普罗米修斯&#xA;规格：&#xA;  团体：&#xA;  - 名称：ray-cluster-main-staging-gcs.rules&#xA;    间隔：30秒&#xA;    规则：&#xA;    - 警报：缺少MetricRayGlobalControlStore&#xA;      表达式: |&#xA;        缺席（ray_gcs_update_resource_usage_time_count）&#xA;      用于：1m&#xA;      标签：&#xA;        严重性：警告&#xA;      注释：&#xA;        摘要：“缺少 Ray GCS 指标”&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;设置 Grafana 仪表板&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#setting-up-grafana-dashboards&#34;&gt; &lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Grafana 提供了丰富的指标可视化效果。以下是为 Ray 设置仪表板的方法：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;第 1 步：捕获默认仪表板&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#step-1-capture-default -仪表板&#34;&gt;&lt;/a&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;从 Ray head pod 复制默认仪表板：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;kubectl cp &lt;head-pod&gt;:/tmp/ray/session_latest/metrics/grafana/dashboards/ ./dashboards&lt;/code&gt;&lt;/pre &gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;第 2 步：访问 Grafana 仪表板&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#step-2-access- the-grafana-仪表板&#34;&gt;&lt;/a&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;kubectl 端口转发部署/prometheus-grafana -n prometheus-system 3000:3000&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;默认登录凭据：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;用户名：&lt;code&gt;admin&lt;/code&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;密码：&lt;code&gt;舞会操作员&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;在 Ray Serve Pod 中启用分析&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#enable-profiling-in-ray -serve-pods&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;Ray Serve Pod 中的高级分析推理工作负载的分析依赖于用于监控、调试和优化性能的复杂技术。本部分深入研究特定的工具、配置和场景，以增强您的分析能力。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;内存分析&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#memory-profiling&#34;&gt;&lt;/a&gt;&lt;/ H4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;内存分析对于内存泄漏检测和使用优化至关重要。例如，使用 Memray，跟踪内存分配并了解推理任务的行为。要在 Ray Serve Pod 中启用内存分析，请更新容器的安全上下文以允许跟踪：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;securityContext：&#xA;  能力：&#xA;    添加：&#xA;    - SYS_PTRACE&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;配置完成后，Memray 可用于生成内存使用情况报告，这有助于识别系统中的高内存消耗任务或瓶颈。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;示例用例：&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;使用大型转换器模型分析批量推理任务期间的内存使用情况，以优化批量大小并减少内存开销。&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;h4 class=&#34;wp-block-heading&#34;&gt;CPU 分析&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#cpu-profiling&#34;&gt;&lt;/a&gt;&lt;/ H4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;对于 CPU 分析，可以在工作 Pod 中安装 &lt;code&gt;gdb&lt;/code&gt;、&lt;code&gt;lldb&lt;/code&gt; 或 &lt;code&gt;py-spy&lt;/code&gt; 等工具来收集详细的 CPU 使用情况数据。这些工具允许您监控哪些函数消耗最多的 CPU 时间，从而实现有针对性的优化。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;要设置 CPU 分析：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;在 ray Worker Pod 中安装 &lt;code&gt;gdb&lt;/code&gt; 或 &lt;code&gt;lldb&lt;/code&gt;。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;使用分析脚本或工具在推理任务期间捕获 CPU 使用情况快照。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;示例用例：&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;识别预处理管道中受 CPU 限制的操作，将其卸载到 GPU 或优化其实现。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;端到端分析示例&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#end-to-end-分析示例&#34;&gt;&lt;/a&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;当您集成内存和 CPU 分析时，它可以让您全面了解系统性能。为了更好地说明这一点，请考虑一个存在延迟峰值的 LLM 推理任务。如果您将内存和 CPU 配置文件关联起来，您会发现：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;内存使用背后的罪魁祸首是大量的输入数据。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;CPU 瓶颈是由于标记化函数效率低下造成的。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您优化批量大小并重构瓶颈函数，您的性能可能会大幅提高。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;结论&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#conclusion&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;使用 Ray 的分布式 LLM 工作负载和强大工具的可观察性将确保团队从这些系统中获得性能、可靠性和可扩展性。这是以非常实用的方式在 Ray 上设置和监控 LLM 工作负载的指南。适当的可观察性将有助于开发者和运维者尽早发现问题，优化资源的使用，进一步改善用户在使用 NLP 应用时的体验。&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ ray-observability#observing-and-monitoring-large-language-model-workloads-with-ray&#34;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Wed, 15 Jan 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【OpenTelemetry for generative AI】用于生成 AI 的 OpenTelemetry</title>
      <link>https://www.cncf.io/blog/2025/01/20/opentelemetry-for-generative-ai/</link>
      <description>【&lt;p&gt;&lt;em&gt;Project post originally published on the &lt;a href=&#34;https://opentelemetry.io/blog/2024/otel-generative-ai/&#34;&gt;OpenTelemetry blog&lt;/a&gt; by &lt;a href=&#34;https://github.com/drewby&#34;&gt;Drew Robbins&lt;/a&gt; (Microsoft), &lt;a href=&#34;https://github.com/lmolkova&#34;&gt;Liudmila Molkova&lt;/a&gt; (Microsoft)&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As organizations increasingly adopt Large Language Models (LLMs) and other generative AI technologies, ensuring reliable performance, efficiency, and safety is essential to meet user expectations, optimize resource costs, and safeguard against unintended outputs. Effective observability for AI operations, behaviors, and outcomes can help meet these goals. OpenTelemetry is being enhanced to support these needs specifically for generative AI.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Two primary assets are in development to make this possible:&amp;nbsp;&lt;strong&gt;Semantic Conventions&lt;/strong&gt;&amp;nbsp;and&amp;nbsp;&lt;strong&gt;Instrumentation Libraries&lt;/strong&gt;. The first instrumentation library targets the&amp;nbsp;&lt;a href=&#34;https://pypi.org/project/openai/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;OpenAI Python API library&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://opentelemetry.io/docs/concepts/semantic-conventions/&#34;&gt;&lt;strong&gt;Semantic Conventions&lt;/strong&gt;&lt;/a&gt;&amp;nbsp;establish standardized guidelines for how telemetry data is structured and collected across platforms, defining inputs, outputs, and operational details. For generative AI, these conventions streamline monitoring, troubleshooting, and optimizing AI models by standardizing attributes such as model parameters, response metadata, and token usage. This consistency supports better observability across tools, environments, and APIs, helping organizations track performance, cost, and safety with ease.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The&amp;nbsp;&lt;a href=&#34;https://opentelemetry.io/docs/specs/otel/overview/#instrumentation-libraries&#34;&gt;&lt;strong&gt;Instrumentation Library&lt;/strong&gt;&lt;/a&gt;&amp;nbsp;is being developed within the&amp;nbsp;&lt;a href=&#34;https://github.com/open-telemetry/opentelemetry-python-contrib&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;OpenTelemetry Python Contrib&lt;/a&gt;&amp;nbsp;under&amp;nbsp;&lt;a href=&#34;https://github.com/open-telemetry/opentelemetry-python-contrib/tree/main/instrumentation-genai&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;instrumentation-genai&lt;/a&gt;&amp;nbsp;project to automate telemetry collection for generative AI applications. The first release is a Python library for instrumenting OpenAI client calls. This library captures spans and events, gathering essential data like model inputs, response metadata, and token usage in a structured format.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;key-signals-for-generative-ai&#34;&gt;Key Signals for Generative AI&lt;a href=&#34;https://opentelemetry.io/blog/2024/otel-generative-ai/#key-signals-for-generative-ai&#34;&gt;&lt;/a&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The&amp;nbsp;&lt;a href=&#34;https://opentelemetry.io/docs/specs/semconv/gen-ai/&#34;&gt;Semantic Conventions for Generative AI&lt;/a&gt;&amp;nbsp;focus on capturing insights into AI model behavior through three primary signals:&amp;nbsp;&lt;a href=&#34;https://opentelemetry.io/docs/concepts/signals/traces/&#34;&gt;Traces&lt;/a&gt;,&amp;nbsp;&lt;a href=&#34;https://opentelemetry.io/docs/concepts/signals/metrics/&#34;&gt;Metrics&lt;/a&gt;, and&amp;nbsp;&lt;a href=&#34;https://opentelemetry.io/docs/specs/otel/logs/event-api/&#34;&gt;Events&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Together, these signals provide a comprehensive monitoring framework, enabling better cost management, performance tuning, and request tracing.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;traces-tracing-model-interactions&#34;&gt;Traces: Tracing Model Interactions&lt;a href=&#34;https://opentelemetry.io/blog/2024/otel-generative-ai/#traces-tracing-model-interactions&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Traces track each model interaction’s lifecycle, covering input parameters (for example, temperature, top_p) and response details like token count or errors. They provide visibility into each request, aiding in identifying bottlenecks and analyzing the impact of settings on model output.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;metrics-monitoring-usage-and-performance&#34;&gt;Metrics: Monitoring Usage and Performance&lt;a href=&#34;https://opentelemetry.io/blog/2024/otel-generative-ai/#metrics-monitoring-usage-and-performance&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Metrics aggregate high-level indicators like request volume, latency, and token counts, essential for managing costs and performance. This data is particularly critical for API-dependent AI applications with rate limits and cost considerations.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;events-capturing-detailed-interactions&#34;&gt;Events: Capturing Detailed Interactions&lt;a href=&#34;https://opentelemetry.io/blog/2024/otel-generative-ai/#events-capturing-detailed-interactions&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Events log detailed moments during model execution, such as user prompts and model responses, providing a granular view of model interactions. These insights are invaluable for debugging and optimizing AI applications where unexpected behaviors may arise.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;Note&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Note that we decided to use&amp;nbsp;&lt;a href=&#34;https://opentelemetry.io/docs/specs/otel/logs/api/#emit-an-event&#34;&gt;events emitted&lt;/a&gt;&amp;nbsp;with the&amp;nbsp;&lt;a href=&#34;https://opentelemetry.io/docs/specs/otel/logs/api/&#34;&gt;Logs API&lt;/a&gt;&amp;nbsp;specification in the Semantic Conventions for Generative AI. Events allows for us to define specific&amp;nbsp;&lt;a href=&#34;https://opentelemetry.io/docs/specs/semconv/general/events/&#34;&gt;semantic conventions&lt;/a&gt;&amp;nbsp;for the user prompts and model responses that we capture. This addition to the API is in development and considered unstable.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;extending-observability-with-vendor-specific-attributes&#34;&gt;Extending Observability with Vendor-Specific Attributes&lt;a href=&#34;https://opentelemetry.io/blog/2024/otel-generative-ai/#extending-observability-with-vendor-specific-attributes&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The Semantic Conventions also define vendor-specific attributes for platforms like OpenAI and Azure Inference API, ensuring telemetry captures both general and provider-specific details. This added flexibility supports multi-platform monitoring and in-depth insights.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;building-the-python-instrumentation-library-for-openai&#34;&gt;Building the Python Instrumentation Library for OpenAI&lt;a href=&#34;https://opentelemetry.io/blog/2024/otel-generative-ai/#building-the-python-instrumentation-library-for-openai&#34;&gt;&lt;/a&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This Python-based library for OpenTelemetry captures key telemetry signals for OpenAI models, providing developers with an out-of-the-box observability solution tailored to AI workloads. The library,&amp;nbsp;&lt;a href=&#34;https://github.com/open-telemetry/opentelemetry-python-contrib/tree/opentelemetry-instrumentation-openai-v2%3D%3D2.0b0/instrumentation-genai/opentelemetry-instrumentation-openai-v2&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;hosted within the OpenTelemetry Python Contrib repository&lt;/a&gt;, automatically collects telemetry from OpenAI model interactions, including request and response metadata and token usage.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As generative AI applications grow, additional instrumentation libraries for other languages will follow, extending OpenTelemetry support across more tools and environments. The current library’s focus on OpenAI highlights its popularity and demand within AI development, making it a valuable initial implementation.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;example-usage&#34;&gt;Example Usage&lt;a href=&#34;https://opentelemetry.io/blog/2024/otel-generative-ai/#example-usage&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Here’s an example of using the OpenTelemetry Python library to monitor a generative AI application with the OpenAI client.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Install the OpenTelemetry dependencies:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;pip install opentelemetry-distro&#xA;opentelemetry-bootstrap -a install&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Set the following environment variables, updating the endpoint and protocol as appropriate:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;OPENAI_API_KEY&lt;strong&gt;=&lt;/strong&gt;&amp;lt;replace_with_your_openai_api_key&amp;gt;&#xA;&#xA;OTEL_EXPORTER_OTLP_ENDPOINT&lt;strong&gt;=&lt;/strong&gt;http://localhost:4318&#xA;OTEL_EXPORTER_OTLP_PROTOCOL&lt;strong&gt;=&lt;/strong&gt;http/protobuf&#xA;OTEL_SERVICE_NAME&lt;strong&gt;=&lt;/strong&gt;python-opentelemetry-openai&#xA;OTEL_LOGS_EXPORTER&lt;strong&gt;=&lt;/strong&gt;otlp_proto_http&#xA;OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED&lt;strong&gt;=&lt;/strong&gt;true&#xA;&lt;em&gt;# Set to false or remove to disable log events&lt;/em&gt;&#xA;OTEL_INSTRUMENTATION_GENAI_CAPTURE_MESSAGE_CONTENT&lt;strong&gt;=&lt;/strong&gt;true&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Then include the following code in your Python application:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;&lt;strong&gt;import&lt;/strong&gt; os&#xA;&lt;strong&gt;from&lt;/strong&gt; openai &lt;strong&gt;import&lt;/strong&gt; OpenAI&#xA;&#xA;client &lt;strong&gt;=&lt;/strong&gt; OpenAI&lt;strong&gt;()&lt;/strong&gt;&#xA;chat_completion &lt;strong&gt;=&lt;/strong&gt; client&lt;strong&gt;.&lt;/strong&gt;chat&lt;strong&gt;.&lt;/strong&gt;completions&lt;strong&gt;.&lt;/strong&gt;create&lt;strong&gt;(&lt;/strong&gt;&#xA;    model&lt;strong&gt;=&lt;/strong&gt;os&lt;strong&gt;.&lt;/strong&gt;getenv&lt;strong&gt;(&lt;/strong&gt;&#34;CHAT_MODEL&#34;&lt;strong&gt;,&lt;/strong&gt; &#34;gpt-4o-mini&#34;&lt;strong&gt;),&lt;/strong&gt;&#xA;    messages&lt;strong&gt;=&lt;/strong&gt;&lt;strong&gt;[&lt;/strong&gt;&#xA;        &lt;strong&gt;{&lt;/strong&gt;&#xA;            &#34;role&#34;&lt;strong&gt;:&lt;/strong&gt; &#34;user&#34;&lt;strong&gt;,&lt;/strong&gt;&#xA;            &#34;content&#34;&lt;strong&gt;:&lt;/strong&gt; &#34;Write a short poem on OpenTelemetry.&#34;&lt;strong&gt;,&lt;/strong&gt;&#xA;        &lt;strong&gt;},&lt;/strong&gt;&#xA;    &lt;strong&gt;],&lt;/strong&gt;&#xA;&lt;strong&gt;)&lt;/strong&gt;&#xA;print&lt;strong&gt;(&lt;/strong&gt;chat_completion&lt;strong&gt;.&lt;/strong&gt;choices&lt;strong&gt;[&lt;/strong&gt;&lt;strong&gt;0&lt;/strong&gt;&lt;strong&gt;]&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;message&lt;strong&gt;.&lt;/strong&gt;content&lt;strong&gt;)&lt;/strong&gt;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;And then run the example using&amp;nbsp;&lt;code&gt;opentelemetry-instrument&lt;/code&gt;:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;opentelemetry-instrument python main.py&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you do not have a service running to collect telemetry, you can export to the console using the following:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;opentelemetry-instrument --traces_exporter console --metrics_exporter console python main.py&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;There is a complete example&amp;nbsp;&lt;a href=&#34;https://github.com/open-telemetry/opentelemetry-python-contrib/tree/main/instrumentation-genai/opentelemetry-instrumentation-openai-v2/examples/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;available here&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;With this simple instrumentation, one can begin capture traces from their generative AI application. Here is an example from the&amp;nbsp;&lt;a href=&#34;https://learn.microsoft.com/dotnet/aspire/fundamentals/dashboard/standalone?tabs=bash&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Aspire Dashboard&lt;/a&gt;&amp;nbsp;for local debugging.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To start Jaeger, run the following&amp;nbsp;&lt;code&gt;docker&lt;/code&gt;&amp;nbsp;command and open your web browser the&amp;nbsp;&lt;code&gt;localhost:18888&lt;/code&gt;:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;docker run --rm -it -d -p 18888:18888 -p 4317:18889 -p 4318:18890 --name aspire-dashboard mcr.microsoft.com/dotnet/aspire-dashboard:9.0&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1913&#34; height=&#34;973&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2025/01/aspire-dashboard-trace.png&#34; alt=&#34;Screenshot showing chatgpt-40-mini page on Aspire&#34; class=&#34;wp-image-123868&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2025/01/aspire-dashboard-trace.png 1913w, https://www.cncf.io/wp-content/uploads/2025/01/aspire-dashboard-trace-300x153.png 300w, https://www.cncf.io/wp-content/uploads/2025/01/aspire-dashboard-trace-1024x521.png 1024w, https://www.cncf.io/wp-content/uploads/2025/01/aspire-dashboard-trace-768x391.png 768w, https://www.cncf.io/wp-content/uploads/2025/01/aspire-dashboard-trace-900x458.png 900w, https://www.cncf.io/wp-content/uploads/2025/01/aspire-dashboard-trace-1800x916.png 1800w, https://www.cncf.io/wp-content/uploads/2025/01/aspire-dashboard-trace-393x200.png 393w, https://www.cncf.io/wp-content/uploads/2025/01/aspire-dashboard-trace-786x400.png 786w&#34; sizes=&#34;auto, (max-width: 1913px) 100vw, 1913px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Here is a similar trace captured in&amp;nbsp;&lt;a href=&#34;https://www.jaegertracing.io/docs/1.63/getting-started/#all-in-one&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Jaeger&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To start Jaeger, run the following&amp;nbsp;&lt;code&gt;docker&lt;/code&gt;&amp;nbsp;command and open your web browser the&amp;nbsp;&lt;code&gt;localhost:16686&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;docker run --rm -it -d -p 16686:16686 -p 4317:4317 -p 4318:4318 --name jaeger jaegertracing/all-in-one:latest&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1913&#34; height=&#34;973&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2025/01/jaeger-trace.png&#34; alt=&#34;Screenshot showing chatgpt-40-mini page on Aspire&#34; class=&#34;wp-image-123870&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2025/01/jaeger-trace.png 1913w, https://www.cncf.io/wp-content/uploads/2025/01/jaeger-trace-300x153.png 300w, https://www.cncf.io/wp-content/uploads/2025/01/jaeger-trace-1024x521.png 1024w, https://www.cncf.io/wp-content/uploads/2025/01/jaeger-trace-768x391.png 768w, https://www.cncf.io/wp-content/uploads/2025/01/jaeger-trace-900x458.png 900w, https://www.cncf.io/wp-content/uploads/2025/01/jaeger-trace-1800x916.png 1800w, https://www.cncf.io/wp-content/uploads/2025/01/jaeger-trace-393x200.png 393w, https://www.cncf.io/wp-content/uploads/2025/01/jaeger-trace-786x400.png 786w&#34; sizes=&#34;auto, (max-width: 1913px) 100vw, 1913px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;It’s also easy to capture the content history of the chat for debugging and improving your application. Simply set the environment variable&amp;nbsp;&lt;code&gt;OTEL_INSTRUMENTATION_GENAI_CAPTURE_MESSAGE_CONTENT&lt;/code&gt;&amp;nbsp;as follows:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;export OTEL_INSTRUMENTATION_GENAI_CAPTURE_MESSAGE_CONTENT&lt;strong&gt;=&lt;/strong&gt;True&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This will turn on content capture which collects OpenTelemetry events containing the payload:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;2074&#34; height=&#34;720&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2025/01/aspire-dashboard-content-capture.jpg&#34; alt=&#34;Content Capture Aspire Dashboard&#34; class=&#34;wp-image-123871&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2025/01/aspire-dashboard-content-capture.jpg 2074w, https://www.cncf.io/wp-content/uploads/2025/01/aspire-dashboard-content-capture-300x104.jpg 300w, https://www.cncf.io/wp-content/uploads/2025/01/aspire-dashboard-content-capture-1024x355.jpg 1024w, https://www.cncf.io/wp-content/uploads/2025/01/aspire-dashboard-content-capture-768x267.jpg 768w, https://www.cncf.io/wp-content/uploads/2025/01/aspire-dashboard-content-capture-900x312.jpg 900w, https://www.cncf.io/wp-content/uploads/2025/01/aspire-dashboard-content-capture-1800x625.jpg 1800w, https://www.cncf.io/wp-content/uploads/2025/01/aspire-dashboard-content-capture-576x200.jpg 576w, https://www.cncf.io/wp-content/uploads/2025/01/aspire-dashboard-content-capture-1152x400.jpg 1152w&#34; sizes=&#34;auto, (max-width: 2074px) 100vw, 2074px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;join-us-in-shaping-the-future-of-generative-ai-observability&#34;&gt;Join Us in Shaping the Future of Generative AI Observability&lt;a href=&#34;https://opentelemetry.io/blog/2024/otel-generative-ai/#join-us-in-shaping-the-future-of-generative-ai-observability&#34;&gt;&lt;/a&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Community collaboration is key to OpenTelemetry’s success. We invite developers, AI practitioners, and organizations to contribute, share feedback, or participate in discussions. Explore the OpenTelemetry Python Contrib project, contribute code, or help shape observability for AI as it continues to evolve.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We now have contributors from&amp;nbsp;&lt;a href=&#34;https://aws.amazon.com/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Amazon&lt;/a&gt;,&amp;nbsp;&lt;a href=&#34;https://www.elastic.co/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Elastic&lt;/a&gt;,&amp;nbsp;&lt;a href=&#34;https://www.google.com/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Google&lt;/a&gt;,&amp;nbsp;&lt;a href=&#34;https://www.ibm.com/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;IBM&lt;/a&gt;,&amp;nbsp;&lt;a href=&#34;https://www.langtrace.ai/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Langtrace&lt;/a&gt;,&amp;nbsp;&lt;a href=&#34;https://www.microsoft.com/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Microsoft&lt;/a&gt;,&amp;nbsp;&lt;a href=&#34;https://openlit.io/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;OpenLIT&lt;/a&gt;,&amp;nbsp;&lt;a href=&#34;https://www.scorecard.io/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Scorecard&lt;/a&gt;,&amp;nbsp;&lt;a href=&#34;https://www.traceloop.com/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Traceloop&lt;/a&gt;, and more!&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;You are welcome to join the community! More information can be found at the&amp;nbsp;&lt;a href=&#34;https://github.com/open-telemetry/community/blob/main/projects/gen-ai.md&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Generative AI Observability project page&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;项目帖子最初由 &lt;a href=&#34;https://opentelemetry.io/blog/2024/otel-generative-ai/&#34;&gt;OpenTelemetry 博客&lt;/a&gt;发布://github.com/drewby&#34;&gt;德鲁·罗宾斯&lt;/a&gt;（微软），&lt;a href=&#34;https://github.com/lmolkova&#34;&gt;Liudmila Molkova&lt;/a&gt;（微软）&lt;/em&gt;&lt; /p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;随着组织越来越多地采用大型语言模型 (LLM) 和其他生成式 AI 技术，确保可靠的性能、效率和安全性对于满足用户期望、优化资源成本和防止意外输出至关重要。人工智能操作、行为和结果的有效可观察性有助于实现这些目标。 OpenTelemetry 正在得到增强，以支持专门针对生成式 AI 的这些需求。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;为了实现这一目标，正在开发两个主要资产：&lt;strong&gt;语义约定&lt;/strong&gt;和&lt;strong&gt;仪器库&lt;/strong&gt;。第一个检测库面向 &lt;a href=&#34;https://pypi.org/project/openai/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;OpenAI Python API 库&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://opentelemetry.io/docs/concepts/semantic-conventions/&#34;&gt;&lt;strong&gt;语义约定&lt;/strong&gt;&lt;/a&gt; 为遥测数据的构建和收集方式制定标准化指南跨平台，定义输入、输出和操作细节。对于生成式 AI，这些约定通过标准化模型参数、响应元数据和令牌使用等属性来简化监控、故障排除和优化 AI 模型。这种一致性支持跨工具、环境和 API 更好的可观察性，帮助组织轻松跟踪性能、成本和安全性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://opentelemetry.io/docs/specs/otel/overview/#instrumentation-libraries&#34;&gt;&lt;strong&gt;仪器库&lt;/strong&gt;&lt;/a&gt;正在&lt; a href=&#34;https://github.com/open-telemetry/opentelemetry-python-contrib&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;OpenTelemetry Python &lt;a href=&#34;https://github.com/open-telemetry/opentelemetry-python-contrib/tree/main/instrumentation-genai&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;仪器下的贡献&lt;/a&gt; -genai&lt;/a&gt; 项目用于自动生成人工智能应用程序的遥测收集。第一个版本是一个用于检测 OpenAI 客户端调用的 Python 库。该库捕获跨度和事件，以结构化格式收集模型输入、响应元数据和令牌使用等基本数据。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;key-signals-for-generative-ai&#34;&gt;生成式人工智能的关键信号&lt;a href=&#34;https://opentelemetry.io/blog/2024/otel-generative -ai/#key-signals-for-generative-ai&#34;&gt;&lt;/a&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://opentelemetry.io/docs/specs/semconv/gen-ai/&#34;&gt;生成式 AI 语义约定&lt;/a&gt;专注于通过三个主要信号捕获对 AI 模型行为的洞察：&lt;a href=&#34;https://opentelemetry.io/docs/concepts/signals/traces/“&gt; traces &lt;/a&gt;，&lt;a href =” https://opentelemetry.io/docs/concepts/concepts/signals/metrics/“&gt; Metrics &lt;/a&gt;和&lt;a href =” https：/ /OpentElemetry.io/docs/specs/otel/logs/event-api/&#34;&gt; events &lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;一起，这些信号提供了一个全面的监视框架，实现了更好的成本管理，绩效调整和请求跟踪。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class =“ wp-block-heading” id =“ traces-tracing-tracing-model-interactions”&gt;跟踪：跟踪模型交互&lt;a href =“ https://opentelemetry.io/blog/2024/2024/ /＃痕迹 - 追踪模型 - 交流“&gt; &lt;/a&gt; &lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;跟踪每个模型交互的生命周期，涵盖输入参数（例如温度，top_p）以及响应细节，例如令牌计数或错误。它们提供了每个请求的可见性，有助于识别瓶颈并分析设置对模型输出的影响。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class =“ wp-block-heading” id =“指标 - 穆特林 -  usage-and-performance”&gt;度量：监视用法和性能&lt;a href =“ https://opentelemetry.io/blog/blog/2024/2024/otel-otel-otel--tel-生成 -  ai/＃度量 - 穆恩特（Monitoring-Monitoring-usage-usage and-performance）”&gt; &lt;/a&gt; &lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;指标汇总了高级指标，例如请求量，延迟和令牌计数，对于管理成本和绩效至关重要。该数据对于依赖于速率限制和成本考虑的API依赖性AI应用特别重要。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class =“ wp-block-heading” id =“ events-captring-detailed-interactions”&gt;事件：捕获详细的交互&lt;a href =“ https://opentelemetry.io/blog/blog/2024/2024/otel-generative-generative-generative-generative-generative-generative-generative-generative-generative-generative-generative-generative-generative-ai， /＃捕获事件的尾巴交织“&gt; &lt;/a&gt; &lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;事件在模型执行过程中日志详细的时刻，例如用户提示和模型响应，提供了模型交互的精细视图。这些见解对于可能出现意外行为的调试和优化AI应用程序是无价的。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class =“ wp-block头”&gt; note &lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;请注意，我们决定使用&lt;a href =“ https://opentelemetry.io/docs/specs/specs/otel/logs/api/papi/#emit/papi/#emit-an-1&gt; href =“ https://opentelemetry.io/docs/specs/otel/logs/api/”&gt; logs api &lt;/a&gt;在生成AI的语义惯例中规范。事件允许我们定义特定&lt;a href =“ https://opentelemetry.io/docs/specs/semconv/general/gen/events/”&gt;语义约定我们捕获的用户提示和模型响应。 API的这种增加正在开发并被认为是不稳定的。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class =“ wp-block-heading” id =“扩展 - 观察性with-with-with-with-with-with-with-with-with-with-with-with-with-tributes”&gt;使用供应商特定属性扩展可观察性&lt;a href =” /otel-generative-ai/＃扩展 - 观察性 - 供应商特定于特定于属性”&gt; &lt;/a&gt; &lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;语义惯例还为OpenAI和Azure推理API等平台定义了特定于供应商的属性，从而确保遥测可以捕获一般和提供者特定的细节。这增加了灵活性支持多平台监视和IN-DEPTH Insights。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class =“ wp-block-heading” id =“ building the-python-instrumentation-library-for-openai”&gt;构建python仪器库&lt;a a href =“ https://opentelemetry.io/blog /2024/Otel-generative-ai/＃building-the-python-instrumentation-library-for-openai“&gt; &lt;/a&gt; &lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这个基于Python的OpenTelemetry库捕获了OpenAI型号的关键遥测信号，为开发人员提供了针对AI工作负载量身定制的开箱即用的可观察性解决方案。图书馆，&lt;a href =“ https://github.com/open-telemetry/opentelemetry-python-python-contrib/tree/opentelemetry-strymetry-instrumentation-popenai-openai-v2%3D2.0B0B0B0B0B0B0B0B0/ OpenAI-V2“ target =” _ blank“ rel =“ noreferrer noopener”&gt;托管在OpenTelemetry Python prow库存储库中&lt;/a&gt;，自动从OpenAI模型交互中收集遥测，包括请求和响应元数据和响应元数据和tokenata and tokenata and token and token and poken。&#xA;&#xA;&#xA;&#xA;&lt;p&gt;随着生成AI应用程序的增长，将遵循其他语言的其他仪器库，从而在更多的工具和环境中扩展了OpentElemetry的支持。当前图书馆对OpenAI的关注强调了其在AI开发中的普及和需求，使其成为有价值的初始实施。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;在&lt;/a&gt; &lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这是使用OpenTelemetry Python库与OpenAI客户端监视生成AI应用程序的示例。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;安装opentelemetry依赖项：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class =“ wp-block-code”&gt; &lt;code class =“”&gt; pip安装opentelemetry-distro&#xA;OpentElemetry -Bootstrap -a安装&#xA;&lt;/code&gt; &lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;设置以下环境变量，适当更新端点和协议：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class =“ wp-block-code”&gt; &lt;code class =“”&gt; openai_api_key &lt;strong&gt; = &lt;/strong&gt; &lt;repents_with_your_openai_api_key&gt;&#xA;&#xA;otel_exporter_otlp_endpoint &lt;strong&gt; = &lt;/strong&gt; http：// localhost：4318&#xA;otel_exporter_otlp_protocol &lt;strong&gt; = &lt;/strong&gt; http/protobuf&#xA;otel_service_name &lt;strong&gt; = &lt;/strong&gt; python-opentelemetry-openai&#xA;otel_logs_exporter &lt;strong&gt; = &lt;/strong&gt; otlp_proto_http&#xA;otel_python_logging_auto_instrumentation_enabled &lt;strong&gt; = &lt;/strong&gt; true&#xA;&lt;em&gt;＃设置为false或删除禁用日志事件&lt;/em&gt;&#xA;otel_instrumentation_genai_capture_message_content &lt;strong&gt; = &lt;/strong&gt; true&#xA;&lt;/code&gt; &lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;然后在您的Python应用程序中包含以下代码：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class =“ wp-block-code”&gt; &lt;code class =“”&gt; &lt;strong&gt;导入&lt;/strong&gt; os&#xA;&lt;strong&gt;来自&lt;/strong&gt; OpenAi &lt;strong&gt;进口&lt;/strong&gt; OpenAi&#xA;&#xA;客户端&lt;strong&gt; = &lt;/strong&gt; OpenAi &lt;strong&gt;（）&lt;/strong&gt;&#xA;chat_completion &lt;strong&gt; = &lt;/strong&gt; client &lt;strong&gt;。&lt;/strong&gt; chat &lt;strong&gt;。&lt;/strong&gt;完成&lt;strong&gt;。&lt;/strong&gt;创建&lt;strong&gt;（&lt;/strong&gt;）&#xA;    模型&lt;strong&gt; = &lt;/strong&gt; os &lt;strong&gt;。&lt;/strong&gt; getenv &lt;strong&gt;（&lt;/strong&gt;“ chat_model” &lt;strong&gt;，&lt;/strong&gt;“ gpt-4o-mini” &lt;strong&gt;）， &lt;/strong&gt;&#xA;    消息&lt;strong&gt; = &lt;/strong&gt; &lt;strong&gt; [&lt;/strong&gt;&#xA;        &lt;strong&gt; {&lt;/strong&gt;“角色” &lt;strong&gt;：&lt;/strong&gt;“用户” &lt;strong&gt;，&lt;/strong&gt;&#xA;            “内容” &lt;strong&gt;：&lt;/strong&gt;“写一首关于Opentelemetry的简短诗。” &lt;strong&gt;，&lt;/strong&gt;&#xA;        &lt;strong&gt;}，&lt;/strong&gt;&#xA;    &lt;strong&gt;]，&lt;/strong&gt;&#xA;&lt;strong&gt;）&lt;/strong&gt;&#xA;打印&lt;strong&gt;（&lt;/strong&gt; chat_completion &lt;strong&gt;。&lt;/strong&gt;选择&lt;strong&gt; [&lt;/strong&gt; &lt;strong&gt; 0 &lt;/strong&gt; &lt;strong&gt;] &lt;/strong&gt; &lt;/strong&gt; &lt;strong&gt;。&lt;/strong &gt;消息&lt;strong&gt;。&lt;/strong&gt;内容&lt;strong&gt;）&lt;/strong&gt;&#xA;&lt;/code&gt; &lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;然后使用&lt;code&gt; OpentElemetry-Insprument &lt;/code&gt;：&lt;/p&gt;运行示例&#xA;&#xA;&#xA;&#xA;&lt;pre class =“ wp-block-code”&gt; &lt;code class =“”&gt; opentelemetry-interment python main.py&#xA;&lt;/code&gt; &lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您没有运行以收集遥测的服务，则可以使用以下内容导出到控制台：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class =“ wp-block-code”&gt; &lt;code class =“”&gt; opentelemetry-instrument -traces_exporter console -metrics_exporter Console python main.py&#xA;&lt;/code&gt; &lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;有一个完整的示例&lt;a a href =“ https://github.com/open-telemetry/opentelemetry-python-python-contrib/tree/main/main/main/minstrmentation-genai/opentelemetry-emetelemetry-instry--in-strumentation-openai-openai-openai-v2/examples/ target =“ _ blank” rel =“ noreferrer noopener”&gt;可在此处提供&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;使用这种简单的仪器，可以开始从其生成AI应用程序中捕获痕迹。这是&lt;a href =“ https://learn.microsoft.com/dotnet/aspire/fundamentals/dashboard/dashboard/dandalone?tabs = bash” target =“ _ blank” rel =“ noreferrer noopener”&gt; aspire dashboard &lt;aspire dashboard &lt; /a&gt;用于本地调试。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;要启动jaeger，请运行以下&lt;code&gt; docker &lt;/code&gt;命令并打开您的Web浏览器&lt;code&gt; localhost：18888 &lt;/code&gt;：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class =“ wp -block -code”&gt; &lt;code class =“”&gt; docker run -rm -it -d -d -p 18888：18888 -p 4317：18889 -p 4318：18890 -name aspire aspire -aspire -dash -dash -dash -dashboard mcr .microsoft.com/dotnet/aspire-dashboard：9.0&#xA;&lt;/code&gt; &lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;figie class =“ wp-block-image size-full”&gt; &lt;img loading =“ lazy” dododing =“ async” width =“ 1913” height =“ 973” src =“ https://www.cncf.io/ wp-content/uploads/2025/01/aspire-dashboard-trace.png“ alt =”屏幕截图显示Aspire上的Chatgpt-40-Mini页面class =“ wp-image-123868” srcset =“ srcset =” srcset =“ https：// wwwww。 cncf.io/wp-content/uploads/2025/01/aspire-dashboard-trace.png 1913w，https://wwwww.cncf.io/wp-content/uploads/2025/2025/01/aspire-dashboild-dashboard-trace-trace-300x153。 。 /2025/01/aspire-dashboard-trace-768x391.png 768W，https://www.cncf.io/wp-content/wp-content/uploads/2025/01/aspire-dashboard-dashboard-trace-trace-trace-trace-900x458.png 900w，https：/https：/https：/https：/https：/ /www.cncf.io/wp-content/uploads/2025/01/aspire-dashboard-trace-1800x916.png 1800W，https://www.cncf.io/wp.io/wp-content/wp-content/wp-content/255/255/2025/2025/01/asasipe/01/asasipe/01/asasipe-pirepire- dashboard-trace-393x200.png 393W，https：//www.cncf.io/wp-content/uploads/2025/01/aspire-dashboard-dashboard-trace-786x400.png 1913px）100VW，1913px“ referrerpolicy =“ no-treferrer”&gt; &lt;/fige&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这是在&lt;a href =“ https://www.jaegertracing.io/docs/1.63/getting-started/#all-unpl.all#all-in-in-i-o中捕获的类似跟踪ne&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Jaeger&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;要启动 Jaeger，请运行以下&lt;code&gt;docker&lt;/code&gt;命令并打开网络浏览器&lt;code&gt;localhost:16686&lt;/code&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;docker run --rm -it -d -p 16686:16686 -p 4317:4317 -p 4318:4318 --name jaeger jaegertracing/all合一：最新&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“1913”高度=“973”src=“https://www.cncf.io/ wp-content/uploads/2025/01/jaeger-trace.png&#34; alt=&#34;Aspire 上显示 chatgpt-40-mini 页面的屏幕截图&#34; class=&#34;wp-image-123870&#34; srcset =“https://www.cncf.io/wp-content/uploads/2025/01/jaeger-trace.png 1913w，https://www.cncf.io/wp-content/uploads/2025/01/ jaeger-trace-300x153.png 300w, https://www.cncf.io/wp-content/uploads/2025/01/jaeger-trace-1024x521.png 1024w，https://www.cncf.io/wp-content/uploads/2025/01/jaeger -trace-768x391.png 768w, https://www.cncf.io/wp-content/uploads/2025/01/jaeger-trace-900x458.png 900w，https://www.cncf.io/wp-content/uploads/2025/01/jaeger -trace-1800x916.png 1800w, https://www.cncf.io/wp-content/uploads/2025/01/jaeger-trace-393x200.png 393w，https://www.cncf.io/wp-content/uploads/2025/01/jaeger -trace-786x400.png 786w“尺寸=”自动，（最大宽度：1913px） 100vw，1913px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;还可以轻松捕获聊天内容历史记录，以调试和改进您的应用程序。只需按如下方式设置环境变量 &lt;code&gt;OTEL_INSTRUMENTATION_GENAI_CAPTURE_MESSAGE_CONTENT&lt;/code&gt;：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;导出 OTEL_INSTRUMENTATION_GENAI_CAPTURE_MESSAGE_CONTENT&lt;strong&gt;=&lt;/strong&gt;True&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这将打开内容捕获，收集包含有效负载的 OpenTelemetry 事件：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“2074”高度=“720”src=“https://www.cncf.io/ wp-content/uploads/2025/01/aspire-dashboard-content-capture.jpg&#34; alt=&#34;内容捕获 Aspire Dashboard&#34; class=&#34;wp-image-123871&#34; srcset =“https://www.cncf.io/wp-content/uploads/2025/01/aspire-dashboard-content-capture.jpg 2074w，https://www.cncf.io/wp-content/uploads/ 2025/01/aspire-dashboard-content-capture-300x104.jpg 300w, https://www.cncf.io/wp-content/uploads/2025/01/aspire-dashboard-content-capture-1024x355.jpg 1024w，https://www.cncf.io/wp-content/uploads/2025 /01/aspire-dashboard-content-capture-768x267.jpg 768w, https://www.cncf.io/wp-content/uploads/2025/01/aspire-dashboard-content-capture-900x312.jpg 900w，https://www.cncf.io/wp-content/uploads/2025 /01/aspire-dashboard-content-capture-1800x625.jpg 1800w, https://www.cncf.io/wp-content/uploads/2025/01/aspire-dashboard-content-capture-576x200.jpg 576w，https://www.cncf.io/wp-content/uploads/2025 /01/aspire-dashboard-content-capture-1152x400.jpg 1152w&#34; 尺寸 = &#34;自动, (最大宽度: 2074px) 100vw, 2074px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 类=“wp-block-headin”g“ id =” join-us-In-In-In-in-In-the-future-of-enerative-ai-observability&#39;&gt;加入我们，塑造生成AI可观察性的未来&lt;a href =“ https://opentelemetry.io/blog /2024/Otel-generative-ai/＃join-us-In-In-In-In-In-In-In-In-the-future-ai-ai-obserservability&#39;&gt; &lt;/a&gt; &lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;社区合作是Opentelemetry成功的关键。我们邀请开发人员，AI从业人员和组织贡献，分享反馈或参与讨论。探索opentelemetry python贡献项目，贡献代码或帮助塑造AI的可观察性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们现在有来自&lt;a href =“ https://aws.amazon.com/”的贡献者。 /www.elastic.co/“ target =” _ blank“ rel =” noreferrer noopener“&gt;弹性&lt;/a&gt;，&lt;a href =” https://www.google.com/“ target =” _ _空白“ noreferrer nooopener”&gt; google &lt;/a&gt;，&lt;a href =“ https://www.ibm.com/” target =“ _ blank” rel =“ noreferrer noopener”&gt; ibm &lt;/a&gt;，&lt;a href =“ href =” https https ：//www.langtrace.ai/“ target =” _ blank“ rel =” noreferrer noopener“&gt; langtrace &lt;/a&gt;，&lt;a href =” https://www.microsoft.com/ =“ noreferrer noopener”&gt; Microsoft &lt;/a&gt;，&lt;a href =“ https://openlit.io/” target =“ _ blank” rel =“ noreferrer noopener”&gt; openlit &lt;/a&gt; ：//www.scorecard.io/“ target =“ _ blank” rel =“ noreferrer noopener”&gt;记分卡&lt;/a&gt;，&lt;a href =“ https://www.traceloop.com/” =“ noreferrer noopener”&gt; traceloop &lt;/a&gt;，以及更多！&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;欢迎您加入社区！更多信息可以在&lt;a href =“ https://github.com/open-telemetry/community/community/blob/main/projects/gen-ai.md” target =“ _ blank” rel =“ noreferrer noopener”&gt;生成AI可观察性项目页面&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;在&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;在&#xA;&lt;/div&gt;</description>
      <pubDate>Sun, 19 Jan 2025 16:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>