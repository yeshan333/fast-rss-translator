<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>CNCF - Blog</title>
    <link>http://rsshub.rssforever.com/cncf</link>
    <description>CNCF - Blog - Powered by RSSHub</description>
    <managingEditor>contact@rsshub.app (RSSHub)</managingEditor>
    <item>
      <title>【Notary Project completes its second audit!】公证项目完成第二次审核！</title>
      <link>https://www.cncf.io/blog/2025/01/21/notary-project-completes-its-second-audit/</link>
      <description>【&lt;p&gt;&lt;em&gt;Community post cross-posted on the &lt;a href=&#34;https://ostif.org/notaryproject-cryptography-audit-2025&#34;&gt;OSTIF blog&lt;/a&gt; by Helen Woeste, Communications Manager, the Open Source Technology Improvement Fund&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;OSTIF&lt;/strong&gt; is proud to share the results of our second security audit of &lt;a href=&#34;https://notaryproject.dev/&#34;&gt;&lt;strong&gt;Notary&lt;/strong&gt; &lt;strong&gt;Project&lt;/strong&gt;&lt;/a&gt;. Notary Project is “a set of specifications and tools intended to provide a cross-industry standard for securing software supply chains by using authentic container images and other OCI artifacts.” With the help of &lt;a href=&#34;https://www.quarkslab.com/&#34;&gt;&lt;strong&gt;Quarkslab&lt;/strong&gt;&lt;/a&gt; and the &lt;a href=&#34;https://www.cncf.io/&#34;&gt;&lt;strong&gt;Cloud Native Computing Foundation (CNCF)&lt;/strong&gt;&lt;/a&gt;, this project continues to provide users with trusted software supply chain management.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Audit Process&lt;/strong&gt;:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This audit of Notary Project was specifically scoped around two new cryptographic features. The audit team, Quarkslab, was chosen for their practical cryptography experience to work on this engagement. The audit report presents how Quarkslab installed and performed discovery of Notary Project tooling Notation, reviewed the code structure and quality, and analyzed the timestamping and certificate revocation. The audit team also created multiple figures to help illustrate Notation with examples of overall project functionality, flow of certificate chain verification, and global overview of the CRL verification.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Audit Results&lt;/strong&gt;:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;11 findings with Security Impact and Recommended Fixes&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;1 Medium, 1 Low, 9 Informational&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;2 CVEs issued for audit findings&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://nvd.nist.gov/vuln/detail/CVE-2024-56138&#34;&gt;CVE-2024-56138: notation-go timestamp signature generation lacks certificate revocation check&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://nvd.nist.gov/vuln/detail/CVE-2024-51491&#34;&gt;CVE-2024-51491: notation-go process crash during CRL-based revocation check on OS using separate mount point for temp Directory&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Review and Recommendations for 2 new Cryptographic Features&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Timestamping Support&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Time-Stamp Protocol Compliance&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Time Stamp Analysis in &lt;a href=&#34;https://github.com/notaryproject/notation?tab=readme-ov-file&#34;&gt;Notation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Revocation Checking with Certificate Revocation List&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Certificate Revocation List Compliance&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;CRL Analysis in &lt;a href=&#34;https://github.com/notaryproject/notation?tab=readme-ov-file&#34;&gt;Notation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Future Security Work Recommendations&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This was Notary Project’s third security audit and second audit in partnership with OSTIF. Practicing mature security practices, the three audits were all undertaken after implementation of new features with security impact. Notary Projects’s efforts to provide secure code to users was observable to the audit team, and is reflected by the reported findings and further recommendations for future security work. OSTIF wishes Notary Project the best on its path towards Graduation through the CNCF Incubating Projects program.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Thank you&lt;/strong&gt; to the individuals and groups that made this engagement possible:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Notary&lt;/strong&gt; &lt;strong&gt;Project&lt;/strong&gt; maintainers and community, notably: Pritesh Bandi, Junjie Gao, Vani Rao, Shiwei Zhang, Yi Zha, Patrick Zheng, and Feynman Zhou&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Quarkslab&lt;/strong&gt;: Dahmun Goudarzi, Sébastien Rolland, and Ramtine Tofighi Shirazi&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Cloud Native Computing Foundation&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;You can read the Audit Report &lt;a href=&#34;https://ostif.org/wp-content/uploads/2025/01/24-10-1825-LIV-v1.5.pdf&#34;&gt;&lt;strong&gt;HERE&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Read Quarkslab’s blog &lt;a href=&#34;https://blog.quarkslab.com/&#34;&gt;&lt;strong&gt;HERE&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Everyone around the world depends on open source software. If you’re interested in financially supporting this critical work, contact amir@ostif.org.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;由 Open 组织通信经理 Helen Woeste 在 &lt;a href=&#34;https://ostif.org/notaryproject-cryptography-audit-2025&#34;&gt;OSTIF 博客&lt;/a&gt;上交叉发布的社区帖子来源技术改进基金&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;OSTIF&lt;/strong&gt; 很自豪地分享我们对 &lt;a href=&#34;https://notaryproject.dev/&#34;&gt;&lt;strong&gt;Notary&lt;/strong&gt; &lt;strong&gt;项目进行第二次安全审核的结果&lt;/strong&gt;&lt;/a&gt;。 Notary 项目是“一组规范和工具，旨在提供跨行业标准，通过使用真实的容器映像和其他 OCI 工件来保护软件供应链。”在 &lt;a href=&#34;https://www.quarkslab.com/&#34;&gt;&lt;strong&gt;Quarkslab&lt;/strong&gt;&lt;/a&gt; 和 &lt;a href=&#34;https://www.cncf.io/ &#34;&gt;&lt;strong&gt;云原生计算基金会(CNCF)&lt;/strong&gt;&lt;/a&gt;，该项目持续为用户提供可信的软件供应链管理。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;审核流程&lt;/strong&gt;：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;对 Notary 项目的审计主要围绕两个新的加密功能。审计团队 Quarkslab 因其实际密码学经验而被选中来从事这项工作。审计报告介绍了 Quarkslab 如何安装和执行 Notary Project 工具 Notation 的发现、审查代码结构和质量以及分析时间戳和证书吊销。审计团队还创建了多个图表来帮助说明 Notation，其中包含总体项目功能的示例、证书链验证流程以及 CRL 验证的全局概述。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;审核结果&lt;/strong&gt;：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;11 项安全影响调查结果和修复建议&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;1 个中，1 个低，9 个信息&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;针对审计结果发布了 2 个 CVE&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://nvd.nist.gov/vuln/detail/CVE-2024-56138&#34;&gt;CVE-2024-56138：notation-go 时间戳签名生成缺少证书吊销检查&lt;/a&gt;&lt; /里&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://nvd.nist.gov/vuln/detail/CVE-2024-51491&#34;&gt;CVE-2024-51491：在使用单独的操作系统进行基于 CRL 的吊销检查期间，notation-go 进程崩溃临时目录的挂载点&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;对 2 项新加密功能的审核和建议&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;时间戳支持&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;时间戳协议合规性&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/notaryproject/notation?tab=readme-ov-file&#34;&gt;符号&lt;/a&gt;中的时间戳分析&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;使用证书吊销列表进行吊销检查&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;证书吊销列表合规性&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/notaryproject/notation?tab=readme-ov-file&#34;&gt;符号&lt;/a&gt;中的 CRL 分析&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;未来安全工作建议&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这是 Notary Project 的第三次安全审计，也是与 OSTIF 合作的第二次审计。践行成熟的安全实践，三审核在实施具有安全影响的新功能后，全部进行了。公证项目为向用户提供安全代码的努力是审计团队可观察到的，并由报告的发现和未来安全工作的进一步建议反映出。 OSTIF希望Notary Project通过CNCF孵化项目计划毕业的道路上最好的项目。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt; &lt;strong&gt;感谢您&lt;/strong&gt;对这次参与的个人和团体都成为可能：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class =“ wp-block-list”&gt;&#xA;&lt;li&gt; &lt;strong&gt;公证&lt;/strong&gt; &lt;strong&gt;项目&lt;/strong&gt;维护者和社区，尤其是：Pritesh Bandi，Junjie Gao，Vani Rao，Shiwei Zhang，Yi Zha，Patrick Zheng，Patrick Zheng和Feynman Zhout&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;strong&gt; Quarkslab &lt;/strong&gt;：Dahmun Goudarzi，SébastienRolland和Ramtine Tofighi Shirazi &lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;strong&gt;云本机计算基础&lt;/strong&gt; &lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;您可以阅读审核报告&lt;a href =“ https://ostif.org/wp-content/uploads/2025/01/24-101/24-10-1825-liv-v1.5.pdf”&gt; &lt;strong&gt; &lt;strong&gt;这里&lt;/strong&gt; &lt;/a&gt; &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;阅读Quarkslab的博客&lt;A href =“ https://blog.quarkslab.com/”&gt; &lt;strong&gt;在这里&lt;/strong&gt; &lt;/a&gt; &lt;/a&gt; &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;世界各地的每个人都取决于开源软件。如果您有兴趣在财务上支持这项关键工作，请联系amir@ostif.org。&lt;/p&gt;&#xA;&#xA;在&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;在&#xA;&lt;/div&gt;</description>
      <pubDate>Mon, 20 Jan 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Announcing the results of the Karmada security audit】公布Karmada安全审核结果</title>
      <link>https://www.cncf.io/blog/2025/01/16/announcing-the-results-of-the-karmada-security-audit/</link>
      <description>【&lt;p&gt;&lt;em&gt;Community post cross-posted on the &lt;a href=&#34;https://ostif.org/karmada-audit-complete/&#34;&gt;OSTIF blog&lt;/a&gt; by Helen Woeste, Communications Manager, the Open Source Technology Improvement Fund&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://ostif.org/&#34;&gt;OSTIF&lt;/a&gt; is proud to share the results of our security audit of &lt;a href=&#34;https://karmada.io/&#34;&gt;Karmada&lt;/a&gt;. Karmada is an open source Kubernetes orchestration system for running cloud-native applications seamlessly across different clouds and clusters. With the help of &lt;a href=&#34;https://www.shielder.com/&#34;&gt;Shielder&lt;/a&gt; and the &lt;a href=&#34;https://www.cncf.io/&#34;&gt;Cloud Native Computing Foundation (CNCF)&lt;/a&gt;, this project offers users improved open, multi-cloud, multi-cluster Kubernetes management.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Audit Process:&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;While Karmada is a part of the Kubernetes ecosystem and therefore utilizes Kubernetes libraries and implementations, the focus of this particular work was on the overall security health of the custom implementations of Karmada and its third party dependencies. Karmada’s function utilizes multiple components, CLI tools, and add ons to extend the standard Kubernetes features, which can be customized from deployment to deployment. This makes Karmada’s attack scenarios complex, so it was necessary to perform a scoped threat modelling in order to evaluate potential attack surfaces. Utilizing this custom threat model and a combination of manual, tooling, and dynamic review, Shielder identified six findings with security impact on the project.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Audit Results:&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;6 Findings&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;1 High, 1 Medium, 2 Low, 2 Informational&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Recommendations for Future Efforts&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Proposal for Long-term Improvements to Overall Security&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The Karmada maintainer team worked quickly and in tandem with Shielder to resolve and fix the reported issues. Their work on behalf of the project was meticulous and mindful of users as well as relevant third-party dependencies and projects. They published necessary advisories and alerted users as to the impact and resolution of this audit. OSTIF wishes them the best of luck on their journey to graduated status with the CNCF.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Thank you&lt;/strong&gt; to the individuals and groups that made this engagement possible:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Karmada maintainers and community: especially Hongcai Ren, Kevin Wang, and Zhuang Zhang&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Shielder: Abdel Adim “Smaury” Oisfi, Pietro Tirenna, Davide Silvetti&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;The Cloud Native Computing Foundation&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Everyone around the world depends on open source software. If you’re interested in financially supporting this critical work, contact amir@ostif.org.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt; &lt;em&gt;社区帖子在&lt;a href =“ https://ostif.org/karmada-audit-complete/”&gt; ostif博客&lt;/a&gt; Helen Woeste by Communications Manager，开放源代码经理Helen Woeste by，技术改进基金&lt;/em&gt; &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt; &lt;a href =“ https://ostif.org/”&gt; ostif &lt;/a&gt;很荣幸地分享我们的安全审计结果&lt;a href =“ https://karmada.io/”&gt; karmarada &lt;/a&gt;。 Karmada是一种开源Kubernetes编排系统，用于在不同的云和集群中无缝运行云的本地应用程序。借助&lt;a href =“ https://www.shielder.com/”&gt; shielder &lt;/a&gt;和&lt;a href =“ https://www.cncf.io/&gt; CNCF）&lt;/a&gt;，该项目为用户提供了改进的开放，多云的多群体Kubernetes Management。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;H2 class =“ WP-block-neading”&gt;审核过程：&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt; Karmada是Kubernetes生态系统的一部分，因此使用Kubernetes库和实施，这项特定工作的重点是Karmada及其第三方依赖性定制实施的整体安全健康。 Karmada的功能利用多个组件，CLI工具和添加ONS扩展标准的Kubernetes功能，可以从部署到部署进行自定义。这使Karmada的攻击场景变得复杂，因此有必要进行范围的威胁建模，以评估潜在的攻击表面。 Shielder利用这种自定义威胁模型以及手动，工具和动态审查的结合，确定了六个发现对项目的安全影响。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;H2 class =“ WP-block-neading”&gt;审核结果：&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class =“ wp-block-list”&gt;&#xA;&lt;li&gt; 6个发现&#xA;&lt;ul class =“ wp-block-list”&gt;&#xA;&lt;li&gt; 1高，1个中，2个低，2信息&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;未来努力的建议&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;提出长期改进整体安全的建议&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt; Karmada维护者团队与Shielder迅速合作，解决并解决报告的问题。他们代表该项目的工作是一丝不苟的，并且是用户以及相关的第三方依赖和项目。他们发表了必要的咨询，并向用户提醒了此审核的影响和解决。 OSTIF祝他们在CNCF毕业的旅程中一切顺利。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt; &lt;strong&gt;感谢您&lt;/strong&gt;对这次参与的个人和团体都成为可能：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class =“ wp-block-list”&gt;&#xA;&lt;li&gt; Karmada维护者和社区：尤其是Hongcai Ren，Kevin Wang和Zhuang Zhang &lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; Shielder：Abdel Adim“ Smaury” Oisfi，Pietro Tirenna，Davide Silvetti &lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;云本机计算基础&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;世界各地的每个人都取决于开源软件。如果您有兴趣在财务上支持这项关键工作，请联系amir@ostif.org。&lt;/p&gt;&#xA;&#xA;在&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style =“高度：80px” aria-hidded =“ true” class =“ wp-block-stacer iS风格80-120“&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Wed, 15 Jan 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Meet the winners of our first Cloud Native Heroes Challenge】认识我们第一个云土著英雄挑战赛的获胜者</title>
      <link>https://www.cncf.io/blog/2025/01/22/meet-the-winners-of-our-first-cloud-native-heroes-challenge/</link>
      <description>【&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;em&gt;Get their best advice on beating patent trolls at their own game&lt;/em&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We’re delighted to announce the winners of our first Cloud Native Heroes Challenge!&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In that &lt;a href=&#34;https://www.cncf.io/blog/2024/11/13/announcing-the-cloud-native-heroes-challenge/&#34;&gt;first challenge&lt;/a&gt;, we asked participants to find prior art that would undermine the patent on a distributed software networking system. With a new contest of a type that’s new to our community, we weren’t sure what to expect, but, no surprise the CNCF community came through and in the end we had three winners from 3 different continents, two of whom were happy to share insights about their process and experiences.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;In first place&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Our first place winner, who asked not to be identified, found &lt;a href=&#34;https://www.cncf.io/heroes/participation-instructions/#what-is-prior-art&#34;&gt;prior art&lt;/a&gt; from a virtualization environment that analyzes and manages data from virtual machines. Like the target patent, it allows for the use of APIs, and it was filed a few months before the target patent. Our partner in this process, &lt;a href=&#34;https://www.unifiedpatents.com/&#34;&gt;Unified Patents&lt;/a&gt;, was satisfied this submission would “check all the boxes” and undermine the validity of the patent troll’s efforts.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Battling patent trolls by *diagramming sentences*&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Chris Buccella, one of our two-second place winners, has searched for prior art as part of a previous job, so he’s no stranger to this. He decided to join the challenge because he has a “personal disdain” for patent trolls and also because he wants to contribute to CNCF. “I’m a user of CNCF projects, but not a code contributor,” he wrote. “So I was looking for some other way I could make a positive impact.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The biggest challenge he ran into was actually deciphering the patent claims because “the terminology used is often intentionally vague and non-standard. No one would write a user story like this!” His old school tactic? Diagram the sentence structure, rewrite the clauses and then paraphrase. Those efforts broke down the complicated claims into something that was just plain English.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;He also warned about the reality of “link rot.”&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“Release notes from just five years ago are ancient history, and can be difficult to surface,” Buccella wrote in an email. “Domains expire, redirects fail, and code repos are sometimes restructured. It takes some detective work.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For those new to looking for prior art, Buccella strongly suggests looking beyond patents. “Prior art doesn’t have to be other patents. The main asset we have being in the tech community is that we’ve all used and developed lots of different software over the course of our careers. New projects pop up frequently. With that broad exposure to different technologies, we have first-hand knowledge of how a lot of different technologies work. There are many nearly-forgotten (or even failed) projects from the past that are good examples of prior art. And thanks to being open source, publicly-accessible code repos provide timestamped proof of when the software was written. This is ideal. The code is out there… the key part we can play is to connect the dots.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Academic research skills for the win&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Our other second-place winner, Emidio Neto, was brand new to the world of patent trolls and prior art but he described the entire process as very “fun” and he enjoyed it so much he hopes to participate in the next challenge.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Neto, who was talked into this contest by a professor, said he leaned into his background in SDN to help him find the winning prior art. The biggest challenge was wading through all the papers trying to find something that pre-dated the target patent.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;His best advice for those new to searching for prior art? Always check the references! “Authors of papers usually have references, so check those references and see where they lead you to on the Internet,” Neto suggested. “And don’t overlook powerpoints or other presentations – those are all good places to look for prior art.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Feeling inspired to go after some patent trolls? It’s not too late to enter our &lt;a href=&#34;https://www.cncf.io/blog/2025/01/22/announcing-the-second-cloud-native-heroes-challenge/&#34;&gt;current Cloud Native Heroes Challenge&lt;/a&gt;!&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;h3 class =“ WP-block-heading”&gt; &lt;em&gt;在自己的游戏中击败专利巨魔&lt;/em&gt; &lt;/h3&gt;，获得了他们的最佳建议&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们很高兴地宣布我们的第一个云土著英雄挑战的获胜者！&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在那个&lt;a href =“ https://www.cncf.io/blog/2024/11/11/11/11/11/11/announcing-the-cloud-native-native-heroes-challenge/&gt;第一个挑战&lt;/a&gt;，我们要求参与者找到会破坏分布式软件网络系统专利的现有艺术。有了一场新的竞赛，我们不确定会发生什么，我们不确定会发生什么，但是，CNCF社区的经历并不奇怪，最后我们有3个来自3个不同大陆的赢家，其中两个很高兴分享有关其过程和经验的见解。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class =“ wp-block头”&gt; &lt;strong&gt;首先&lt;/strong&gt; &lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们的第一个冠军，要求不被识别，找到&lt;a href =“ https://www.cncf.io/heroes/participation-instructions/prarticipation-instructions/#what-what-is-prior-art”&gt;先前的ART &lt; /a&gt;来自分析和管理虚拟机数据的虚拟化环境。像目标专利一样，它允许使用API​​，并且是在目标专利前几个月提交的。我们在此过程中的合作伙伴，&lt;a href =“ https://www.unifiedpatents.com/”&gt;统一专利&lt;/a&gt;感到满意，此提交将“检查所有框”并破坏专利巨魔努力的有效性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class =“ wp-block头”&gt; &lt;strong&gt;用 *图表句子与专利巨魔作斗争 *&lt;/strong&gt; &lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;克里斯·布塞拉（Chris Buccella）是我们两秒钟的获奖者之一，他曾在上一份工作中寻找先前的艺术，因此他对此并不陌生。他决定参加挑战，因为他对专利巨魔具有“个人鄙视”，也是因为他想为CNCF做出贡献。他写道：“我是CNCF项目的用户，但不是代码贡献者。” “所以我正在寻找其他方式可以产生积极影响。” &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;他所遇到的最大挑战实际上是解密了专利主张，因为“所使用的术语通常是故意含糊不清且不标准的。没有人会写这样的用户故事！”他的旧学校战术？绘制句子结构，重写子句，然后解释。这些努力将复杂的主张归结为简单的英语。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;他还警告了“链接腐烂”的现实。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“五年前的发行笔记是古老的历史，很难浮出水面，”布塞拉在一封电子邮件中写道。 “域到期，重定向失败，有时会重组代码存储量。这需要一些侦探工作。” &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;对于那些刚寻求先前艺术的人来说，布塞拉强烈建议您超越专利。 “先前的艺术不必是其他专利。我们在科技界拥有的主要资产是，在整个职业生涯中，我们都使用并开发了许多不同的软件。新项目经常弹出。随着广泛的接触不同的技术，我们拥有许多不同技术如何工作的第一手知识。过去有许多几乎被遗忘（甚至失败）的项目都是现有技术的好例子。由于是开源的，可公开访问的代码存储库提供了软件编写时间的带时间戳的证明。这是理想的。代码就在那里……我们可以发挥的关键部分是将这些点连接起来。”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;获胜的学术研究技能&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们的另一位第二名获得者 Emidio Neto 对专利流氓和现有技术的世界是全新的，但他形容整个过程非常“有趣”，他非常喜欢它，他希望参加下一个挑战.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Neto 在一位教授的劝说下参加了这次比赛，他说他依靠自己的 SDN 背景来帮助他找到获胜的现有技术。最大的挑战是费力地浏览所有论文，试图找到早于目标专利的内容。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;对于那些刚开始搜索现有技术的人来说，他的最佳建议是什么？一定要检查参考文献！ “论文的作者通常都有参考文献，因此请检查这些参考文献，看看它们会引导您在互联网上找到什么，”内托建议道。 “并且不要忽视幻灯片或其他演示文稿 - 这些都是寻找现有技术的好地方。”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;受到启发去追捕一些专利流氓吗？现在加入我们的&lt;a href=&#34;https://www.cncf.io/blog/2025/01/22/announcing-the-second-cloud-native-heroes-challenge/&#34;&gt;当前的云原生英雄还为时不晚挑战&lt;/a&gt;！&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Tue, 21 Jan 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Announcing the second Cloud Native Heroes Challenge】宣布第二届云原生英雄挑战赛</title>
      <link>https://www.cncf.io/blog/2025/01/22/announcing-the-second-cloud-native-heroes-challenge/</link>
      <description>【&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;em&gt;Help us defeat a patent troll claiming “network isolation with cloud networks” was invented in 2017&lt;/em&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We’re excited to launch another &lt;a href=&#34;http://cncf.io/heroes&#34;&gt;Cloud Native Heroes Challenge&lt;/a&gt; contest in which you can earn swag, a ticket to attend KubeCon+CloudNativeCon, and/or a US $3,000 cash prize by helping defend our ecosystem from patent trolls.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;The Challenged Patent&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We’re seeking information to invalidate Claim 1 of US Patent &lt;a href=&#34;https://portal.unifiedpatents.com/patents/patent/11178104&#34;&gt;11,178,104&lt;/a&gt;, asserted by patent troll Croga Innovations. This patent describes a host computer system designed to enhance network security. The primary goal is to securely access Internet-based cloud services through authenticated and firewalled isolation.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;&lt;em&gt;This patent potentially impacts all container technology and numerous open source projects including Kubernetes, containerd, Docker, Flatcar, and more.&amp;nbsp;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Key Context&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;At a glance this seems like a relatively innocent patent. But let’s look at the patent in the context of recent technology history..&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Here is claim 1 of the challenged patent:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-gray-300-background-color has-background has-fixed-layout&#34;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;1. A host computer system:a memory; anda processor configured to:implement a workspace, wherein the workspace is configured to enable operation of a first set of one or more applications or processes via a first memory space;implement an isolated computing environment, the isolated computing environment using a host operating system and comprising a sandboxed computing environment that uses a second memory space to enable operation of a second set of one or more applications or processes, wherein the isolated computing environment is configured to access an Internet-based cloud service via at least one application of the second set of one or more applications or processes;isolate the isolated computing environment from the workspace using an internal isolation firewall;authenticate the isolated computing environment with an authentication device; andcommunicate with a proxy server to access the Internet-based cloud service to allow communication between at least one application and the Internet-based cloud service when the isolated computing environment has been authenticated.&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If this sounds familiar to you you’re probably thinking “that sounds a lot like containers,” given the references to process, and namespaces, cgroups, etc. This patent was awarded in 2017. Kubernetes itself was created in 2014, Docker in 2013, and LXC (Linux Containers) were created in roughly 2008 by a group of engineers from IBM. Obviously the patent is so generic it could even be applied to virtual machines!&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Call for Prior Art&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.cncf.io/heroes/#what-is-prior-art&#34;&gt;“Prior art”&lt;/a&gt; is a legal term that refers to technical know-how that predated the patent application. Prior art can be used to invalidate or weaken a troll’s patent by demonstrating that the patented invention already existed and wasn’t “new” when the application for a patent was filed.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you are aware of any publicly available materials demonstrating that know-how regarding all of the elements of the invention described above already existed &lt;strong&gt;prior to September 26, 2017 &lt;/strong&gt;(the priority date of the challenged patent), please submit that evidence as “prior art” in this contest. However, please note that materials already listed in the “known references” tab of the &lt;a href=&#34;https://patroll.unifiedpatents.com/contests/mJ5QT4wkDCCjhy9xb&#34;&gt;Contest Description&lt;/a&gt; do not qualify and cannot be submitted in this contest.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Examples of materials that can be provided as prior art include:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Open source documentation, including release notes&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Articles, books, and other publications&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Written records of presentations at tech conferences&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Product manuals or descriptions&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Standards and specification documents&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Any other publicly available documentation (in English) that existed prior to September 26, 2017&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Other patents with a priority date earlier than September 26, 2017&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Instructions for Participating&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Please see our &lt;a href=&#34;http://cncf.io/heroes/participation-instructions&#34;&gt;Participation Instructions&lt;/a&gt; and &lt;a href=&#34;http://cncf.io/heroes&#34;&gt;the Heroes Challenge program page&lt;/a&gt; for more information and step-by-step instructions for entering &lt;a href=&#34;https://patroll.unifiedpatents.com/contests/mJ5QT4wkDCCjhy9xb&#34;&gt;this contest&lt;/a&gt;. Remember, a variety of prizes are available, and all entrants will receive a free Cloud Native Hero t-shirt.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you have questions or would like to request a 1:1 help session where a member of our Heroes Challenge team walks you through any aspect of the contest entry process, please message us at the CNCF slack channel &lt;a href=&#34;https://cloud-native.slack.com/archives/C07UZJRHZPY&#34;&gt;#heroes-challenge&lt;/a&gt; or at &lt;a href=&#34;mailto:heroes@cncf.io&#34;&gt;heroes@cncf.io&lt;/a&gt;.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Know of Prior Art but don’t want to enter the Contest?&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you would like to inform us of prior art without entering the contest, please email us at &lt;a href=&#34;mailto:heroes@cncf.io&#34;&gt;heroes@cncf.io&lt;/a&gt;.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;About Our Co-Host for the Cloud Native Heroes Challenge&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;CNCF is co-hosting this program with &lt;a href=&#34;https://www.unifiedpatents.com/&#34;&gt;Unified Patents&lt;/a&gt;, the Linux Foundation’s partner in patent troll deterrence since 2019. Unified Patents is the &lt;strong&gt;&lt;em&gt;only&lt;/em&gt;&lt;/strong&gt; organization that uses offensive community-driven strategies to deter patent trolls.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Other relevant posts&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.cncf.io/blog/2024/11/13/announcing-the-cloud-native-heroes-challenge/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Announcing the Cloud Native Heroes Challenge&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.cncf.io/blog/2024/09/16/cncf-and-the-linux-foundation-partner-with-unified-patents-on-a-community-driven-approach-to-safeguard-open-source-innovation-from-patent-trolls/&#34;&gt;CNCF Partners with Unified Patents on a Community-Driven Approach to Safeguard Open Source from Patent Trolls&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.cncf.io/blog/2025/01/22/meet-the-winners-of-our-first-cloud-native-heroes-challenge/&#34;&gt;Meet the winners of our first Cloud Native Heroes Challenge&amp;nbsp;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;em&gt;帮助我们击败声称“云网络的网络隔离”于 2017 年发明的专利流氓&lt;/em&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们很高兴推出另一场&lt;a href=&#34;http://cncf.io/heroes&#34;&gt;云原生英雄挑战赛&lt;/a&gt;竞赛，您可以在其中赢得赠品、参加 KubeCon+CloudNativeCon 的门票，和/或通过帮助保护我们的生态系统免受专利流氓侵害而获得 3,000 美元现金奖励。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;受到质疑的专利&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们正在寻找信息来使专利巨魔 Croga Innovations 声称的美国专利 &lt;a href=&#34;https://portal.unifiedpatents.com/patents/patent/11178104&#34;&gt;11,178,104&lt;/a&gt; 的权利要求 1 无效。该专利描述了一种旨在增强网络安全性的主机系统。主要目标是通过经过身份验证和防火墙隔离来安全地访问基于 Internet 的云服务。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;&lt;em&gt;该专利可能会影响所有容器技术和众多开源项目，包括 Kubernetes、containerd、Docker、Flatcar 等。 &lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;关键上下文&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;乍一看，这似乎是一项相对无辜的专利。但让我们在最近的技术历史的背景下看看该专利..&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;以下是受质疑专利的权利要求 1：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-gray-300-background-color has-background has-fixed-layout&#34;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;1.主机系统：存储器；处理器，被配置为：实现工作空间，其中该工作空间被配置为能够经由第一存储器空间实现第一组一个或多个应用程序或进程的操作；实现隔离计算环境，该隔离计算环境使用主机操作系统，以及包括沙盒计算环境，其使用第二存储器空间来实现第二组一个或多个应用程序或进程的操作，其中隔离计算环境被配置为经由第二组中的至少一个应用程序访问基于互联网的云服务一个或多个应用程序或进程；隔离孤立的使用内部隔离防火墙将计算环境与工作空间隔离；使用身份验证设备对隔离的计算环境进行身份验证； &lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt; /表&gt;&lt;/图&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果这听起来很熟悉，您可能会想“这听起来很像容器”，考虑到对进程、命名空间、cgroup 等的引用。这项专利于 2017 年授予。Kubernetes 本身于 2014 年创建， Docker 于 2013 年诞生，LXC（Linux Containers）则由 IBM 的一群工程师于 2008 年左右创建。显然，该专利非常通用，甚至可以应用于虚拟机！&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;在&#xA;&#xA;&#xA;&#xA;在早于专利申请。可以通过证明已有专利的发明已经存在，并且在提交专利的申请时并不是“新的”，可以使用先前的艺术来使巨魔的专利无效或削弱巨魔的专利。&lt;/p&gt; &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您知道任何公开可用的材料，证明了有关上述本发明的所有元素的专业知识，则在2017年9月26日之前已经存在&lt;strong&gt; &lt;/strong&gt;（优先挑战专利的优先日期），请在本次比赛中将证据作为“先前的艺术”。但是，请注意，&lt;a href =“ https://patroll.unifiedpatents.com/contests/mj5qt4wkdccjhy9xb”的“已知参考”选项卡中已列出的材料在这场比赛中。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;可以提供的材料的示例包括：&lt;/p&gt;：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class =“ wp-block-list”&gt;&#xA;&lt;li&gt;开源文档，包括发行笔记&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;文章，书籍和其他出版物&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;在技术会议上的演示文稿的书面记录&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;产品手册或描述&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;标准和规范文档&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; 2017年9月26日之前存在的任何其他公开可用的文档（英文）&lt;/li&gt; &lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;其他优先级的专利早于2017年9月26日&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;H2 class =“ WP-block-neading”&gt;参与的说明&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;请参阅我们的&lt;a href =“ http://cncf.io/heroes/participatipation-instructions”&gt;参与指令&lt;/a&gt;和&lt;a href =“ http://cncf.io/heroes”&gt;英雄挑战计划页面&lt;/a&gt;有关输入&lt;a href =“ https://patroll.unificedpatents.com/contests/mj5qt4wkdccjhy9xb”的更多信息和逐步说明&lt;/a&gt;。请记住，有各种各样的奖品，所有参赛者都会收到一件免费的云本地英雄T恤。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您有疑问或想请求1：1帮助会话，我们的英雄挑战团队会带您了解比赛的任何方面，请通过CNCF Slack channel &lt;a href =&#39; https://cloud-native.slack.com/archives/c07uzjrhzpy&#34;&gt;#heroes-challenge &lt;/a&gt;或at &lt;a href =“ mailto：mailto：heree to：herees@cncf.io”&gt; hiperes@cncf.io &lt;/a&gt; 。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class =“ wp-block头”&gt;知道先前的艺术，但不想参加比赛？&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您想在没有参加比赛的情况下向我们通知我们先前的艺术，请给我们发送电子邮件&lt;a href =“ mailto：heroes@cncf.io”&gt; herioes@cncf.io &lt;/a&gt;。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class =“ WP-block-heading”&gt;关于我们的云土著英雄挑战赛的共同主持人&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt; cncf正在与&lt;a href =“ https://www.unifiedpatents.com/”&gt; Unified Pertinent &lt;/a&gt;，Linux基金会自2019年以来在专利巨魔威慑的合作伙伴。 Unified Patents 是&lt;strong&gt;&lt;em&gt;唯一&lt;/em&gt;&lt;/strong&gt;使用攻击性社区驱动策略来威慑专利流氓的组织。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;其他相关帖子&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.cncf.io/blog/2024/11/13/announcing-the-cloud-native-heroes-challenge/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34; &gt;宣布云原生英雄挑战赛&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.cncf.io/blog/2024/09/16/cncf-and-the-linux-foundation-partner-with-unified-patents-on-a-community- driven-approach-to-safeguard-open-source-innovation-from-patent-trolls/&#34;&gt;CNCF 与 Unified Patent 合作，采用社区驱动的方法来保护开源免受专利侵害巨魔&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.cncf.io/blog/2025/01/22/meet-the-winners-of-our-first-cloud-native-heroes-challenge/&#34;&gt;认识我们首届云原生英雄挑战赛的获奖者&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Tue, 21 Jan 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【From PCAP to SCAP: how Falco’s libraries, registries, and plugins enable cloud native insights】从PCAP到SCAP：Falco的图书馆，注册表和插件如何启用Cloud Native Insights</title>
      <link>https://www.cncf.io/blog/2025/01/22/from-pcap-to-scap-how-falcos-libraries-registries-and-plugins-enable-cloud-native-insights/</link>
      <description>【&lt;p&gt;&lt;em&gt;Member post by &lt;a href=&#34;https://www.linkedin.com/in/nigel-douglas-sysdig/?originalSubdomain=ie&#34;&gt;Nigel Douglas&lt;/a&gt;, Sysdig&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-embed is-type-wp-embed is-provider-wistia-inc wp-block-embed-wistia-inc&#34;&gt;&lt;div class=&#34;wp-block-embed__wrapper&#34;&gt;&#xA;&lt;iframe loading=&#34;lazy&#34; class=&#34;wp-embedded-content&#34; sandbox=&#34;allow-scripts&#34; security=&#34;restricted&#34; title=&#34;Stratoshark – What&#39;s really happening in your cloud? Video&#34; src=&#34;https://fast.wistia.net/embed/iframe/m8klskgnjh?dnt=1#?secret=nrseT3UjIG&#34; data-secret=&#34;nrseT3UjIG&#34; frameborder=&#34;0&#34; scrolling=&#34;no&#34; width=&#34;500&#34; height=&#34;313&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In cloud-native systems, understanding the behaviour of complex, distributed web apps requires powerful tools that can dissect system activity down to its core. As the &lt;a href=&#34;https://www.cncf.io/announcements/2024/02/29/cloud-native-computing-foundation-announces-falco-graduation/&#34;&gt;&lt;strong&gt;CNCF graduate&lt;/strong&gt;&lt;/a&gt; project &lt;a href=&#34;http://falco.org/&#34;&gt;&lt;strong&gt;Falco&lt;/strong&gt;&lt;/a&gt; demonstrates, this often begins with monitoring system calls from the Linux kernel and &lt;strong&gt;enriching that data&lt;/strong&gt; across cloud and Kubernetes to provide actionable runtime insights. Falco’s libraries, registries, and plugins have not only revolutionised Linux runtime security but have also laid the groundwork for a growing ecosystem of tools capable of analysing system behaviour in cloud-native infrastructure.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio&#34;&gt;&lt;div class=&#34;wp-block-embed__wrapper&#34;&gt;&#xA;&lt;iframe loading=&#34;lazy&#34; title=&#34;Falco Features: Enrichment&#34; width=&#34;500&#34; height=&#34;281&#34; src=&#34;https://www.youtube.com/embed/VzSMCr2mZ6A?feature=oembed&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; referrerpolicy=&#34;no-referrer&#34; allowfullscreen=&#34;&#34;&gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Falco’s Foundations: libsinsp and libscap&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;At the heart of Falco are two foundational libraries: &lt;a href=&#34;https://github.com/falcosecurity/libsinsp&#34;&gt;&lt;strong&gt;libsinsp&lt;/strong&gt;&lt;/a&gt; (System INSPection LIBrary) and &lt;a href=&#34;https://github.com/falcosecurity/libscap&#34;&gt;&lt;strong&gt;libscap&lt;/strong&gt;&lt;/a&gt; (System CAPture LIBrary). These libraries enable Falco and other tools to extract, enrich, and analyse system call events from the operating system.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;libscap&lt;/strong&gt; operates as the low-level backbone, handling live capture control, trace file management, event retrieval, and OS state extraction. By communicating directly with drivers — such as kernel modules or eBPF probes — libscap captures syscall events and manages their storage in System CAPture (&lt;a href=&#34;https://sysdig.com/learn-cloud-native/what-is-an-scap-file/&#34;&gt;&lt;strong&gt;.scap&lt;/strong&gt;&lt;/a&gt;) files.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;libsinsp&lt;/strong&gt; builds on libscap by enriching raw syscall data with context, such as process metadata, file descriptors, and user associations. It mirrors the OS state, enabling users to treat low-level system primitives as high-level entities like programs or files. With advanced event filtering and a rule engine, libsinsp simplifies analysis, converting raw system data into meaningful insights.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Together, these libraries form the backbone of Falco’s runtime security capabilities, while also empowering other open-source projects.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;The Role of Plugins in Extending Capabilities&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Falco’s plugin framework makes these libraries adaptable to various data sources beyond system calls. &lt;a href=&#34;https://github.com/falcosecurity/plugins&#34;&gt;&lt;strong&gt;Plugins&lt;/strong&gt;&lt;/a&gt; can be created to ingest and process cloud audit logs, container events, and other telemetry, extending Falco’s functionality far beyond traditional syscall monitoring. This flexibility has opened the door for new tools and integrations, making Falco’s ecosystem more versatile and valuable.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Stratoshark: From PCAP to SCAP&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;One of the most exciting developments leveraging Falco’s libraries is &lt;a href=&#34;https://sysdig.com/opensource/Stratoshark&#34;&gt;&lt;strong&gt;Stratoshark&lt;/strong&gt;&lt;/a&gt;, an open-source project from the Sysdig team. Stratoshark takes the familiar Packet CAPture (&lt;a href=&#34;https://sysdig.com/learn-cloud-native/what-is-a-pcap-file/&#34;&gt;&lt;strong&gt;PCAP&lt;/strong&gt;&lt;/a&gt;) analysis experience of tools like Wireshark and brings it into the modern era of cloud-native systems with &lt;a href=&#34;https://github.com/draios/sysdig-workshop-forensics/blob/master/example0/commands&#34;&gt;&lt;strong&gt;SCAP&lt;/strong&gt;&lt;/a&gt; files.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Using &lt;strong&gt;libsinsp&lt;/strong&gt; and &lt;strong&gt;libscap&lt;/strong&gt;, Stratoshark captures and analyses syscall activity and cloud audit logs, providing a powerful yet user-friendly interface for dissecting these datasets. It supports the same file formats as &lt;a href=&#34;https://sysdig.com/blog/falco-vs-sysdig-oss&#34;&gt;&lt;strong&gt;Falco and Sysdig CLI&lt;/strong&gt;&lt;/a&gt;, allowing seamless transitions between tools. With Stratoshark, users can filter and analyse system call activity just as network administrators have long done with packet captures, enabling new insights into application-level behaviour in cloud environments.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Comparing Ecosystem Approaches: Tracee, Tetragon, and Falco&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Falco and Sysdig aren’t the only tools exploring the power of system call monitoring. Tracee and Tetragon are notable alternatives that provide unique approaches:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/aquasecurity/tracee&#34;&gt;&lt;strong&gt;Tracee&lt;/strong&gt;&lt;/a&gt; uses eBPF to monitor runtime activity and detect security events. It emphasises real-time visibility into system behaviour and uncovers suspicious runtime activity patterns.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/cilium/tetragon&#34;&gt;&lt;strong&gt;Tetragon&lt;/strong&gt;&lt;/a&gt; promises Kubernetes-aware observability and security enforcement. By applying policies directly within eBPF, it claims to reduce overhead while providing real-time runtime enforcement.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Where &lt;strong&gt;Falco&lt;/strong&gt; and &lt;strong&gt;Stratoshark&lt;/strong&gt; differentiate themselves is in their approachability and flexibility. Falco’s plugin architecture and Stratoshark’s ability to read SCAPs for post-incident forensics brings a Wireshark-like experience to the Linux kernel and cloud-native world. The pair also bridges the gap between system call data and the overlying abstractions of cloud and Kubernetes logs for both security and performance tuning.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Why Understanding System Calls in a Cloud-Native Context Matters&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://sysdig.com/blog/kernel-introspection-from-linux-to-windows/#:~:text=System%20calls%20(syscalls%20for%20short,space%20applications%20and%20the%20kernel.&#34;&gt;&lt;strong&gt;System calls&lt;/strong&gt;&lt;/a&gt;, the interface between applications and the operating system, are fundamental to understanding container workload behaviour. Tools like Falco, Tracee, and Tetragon allow developers and operators to peer into these interactions, uncovering anomalies, optimising performance, and improving security observability.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Falco’s libraries and plugins provide the foundation for this analysis, making system calls both accessible and actionable. By supporting tools like Stratoshark, they enable deeper exploration of cloud-native systems while maintaining the flexibility to integrate with other data sources and ecosystems.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;The Road Ahead&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As cloud-native adoption continues to grow, tools like Falco and Stratoshark will become increasingly critical. Their ability to unify system call data, enrich it with context, and present it in an accessible way empowers teams to troubleshoot, secure, and optimize modern applications.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.cncf.io/blog/2024/11/06/why-falcos-new-response-engine-is-a-game-changer-for-open-source-cloud-native-security/&#34;&gt;&lt;strong&gt;Falco’s contributions&lt;/strong&gt;&lt;/a&gt; to the CNCF ecosystem exemplify the power of open-source collaboration and the importance of building foundational tools that inspire innovation. With projects like Stratoshark leading the way, the evolution from PCAP to SCAP is a leap forward for security and observability in the cloud-native era.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you’re interested in trying out Stratoshark today, you can check it out at &lt;a href=&#34;https://stratoshark.org/&#34;&gt;&lt;strong&gt;https://stratoshark.org&lt;/strong&gt;&lt;/a&gt;.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;Sysdig &lt;a href=&#34;https://www.linkedin.com/in/nigel-douglas-sysdig/?originalSubdomain=ie&#34;&gt;Nigel Douglas&lt;/a&gt; 的会员帖子&lt;/em&gt; &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-embed is-type-wp-embed is-provider-wistia-inc wp-block-embed-wistia-inc&#34;&gt;&lt;div class=&#34;wp-block-embed__wrapper&#34;&gt;&#xA;&lt;iframe loading=&#34;lazy&#34; class=&#34;wp-embedded-content&#34; sandbox=&#34;allow-scripts&#34; security=&#34;restricted&#34; title=&#34;Stratoshark – 您的云中到底发生了什么？ Video&#34; src=&#34;https://fast .wistia.net/embed/iframe/m8klskgnjh?dnt=1#?secret=nrseT3UjIG&#34; data-secret=&#34;nrseT3UjIG&#34;frameborder=&#34;0&#34;滚动=“否”宽度=“500”高度=“313”referrerpolicy=“no-referrer”&gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&lt;/图&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在云原生系统中，了解复杂的分布式 Web 应用程序的行为需要强大的工具来剖析系统活动的核心。作为 &lt;a href=&#34;https://www.cncf.io/announcements/2024/02/29/cloud-native-computing-foundation-announces-falco-graduation/&#34;&gt;&lt;strong&gt;CNCF 毕业生&lt;/strong&gt; &lt;/a&gt; 项目 &lt;a href=&#34;http://falco.org/&#34;&gt;&lt;strong&gt;Falco&lt;/strong&gt;&lt;/a&gt; 演示了，这通常从监视 Linux 内核的系统调用开始，并&lt;strong&gt;丰富那跨云和 Kubernetes 的数据，以提供可操作的运行时见解。 Falco 的库、注册表和插件不仅彻底改变了 Linux 运行时安全性，而且还为不断发展的能够分析云原生基础设施中系统行为的工具生态系统奠定了基础。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio&#34;&gt;&lt;div class=&#34; wp-block-embed__wrapper&#34;&gt;&#xA;&lt;iframeloading=&#34;lazy&#34;title=&#34;Falco 功能：丰富&#34;width=&#34;500&#34;height=&#34;281&#34;src=&#34;https://www.youtube.com/embed/VzSMCr2mZ6A?feature=oembed&#34;frameborder=&#34;0 “允许=”加速度计; 加密陀螺仪;允许fullscreen=&#34;&#34;&gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&lt;/图&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Falco 的基础：libsinsp 和 libscap&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Falco 的核心是两个基础库：&lt;a href=&#34;https://github.com/falcosecurity/libsinsp&#34;&gt;&lt;strong&gt;libsinsp&lt;/strong&gt;&lt;/a&gt;（系统 INSPection LIBrary）和 &lt; a href=&#34;https://github.com/falcosecurity/libscap&#34;&gt;&lt;strong&gt;libscap&lt;/strong&gt;&lt;/a&gt;（系统捕获库）。这些库使 Falco 和其他工具能够从操作系统中提取、丰富和分析系统调用事件。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;libscap&lt;/strong&gt; 作为低级主干运行，处理实时捕获控制、跟踪文件管理、事件检索和操作系统状态提取。通过直接与驱动程序（例如内核模块或 eBPF 探针）通信，libscap 捕获系统调用事件并管理其在 System CAPture 中的存储（&lt;a href=&#34;https://sysdig.com/learn-cloud-native/what-is-an -scap-file/&#34;&gt;&lt;strong&gt;.scap&lt;/strong&gt;&lt;/a&gt;) 文件。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;libsinsp&lt;/sTRONG&gt;通过使用上下文（例如过程元数据，文件描述符和用户关联）丰富原始的SYSCALL数据来构建LIBSCAP。它反映了操作系统状态，使用户能够将低级系统基础视为程序或文件等高级实体。通过高级事件过滤和规则引擎，Libsinsp简化了分析，将原始系统数据转换为有意义的见解。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在一起，这些库构成了Falco运行时安全功能的骨干，同时还赋予其他开源项目。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class =“ wp-block头”&gt;插件在扩展功能中的作用&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt; Falco的插件框架使这些库可适应系统调用以外的各种数据源。 &lt;a href =“ https://github.com/falcosecurity/plugins”&gt; &lt;strong&gt; plugins &lt;/strong&gt; &lt;/a&gt;可以创建以摄入和处理云审核日志，容器事件和其他遥测，并扩展Falco&#39;s功能远远超出了传统的SYSCALL监控。这种灵活性为新工具和集成开辟了大门，使Falco的生态系统更加通用和有价值。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class =“ wp-block头”&gt; StratoShark：从PCAP到SCAP &lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;利用Falco图书馆的最激动人心的发展之一是&lt;a href =“ https://sysdig.com/opensource/stratoshark”&gt; &lt;strong&gt; Stratoshark &lt;/strong&gt; &lt;/a&gt; Sysdig团队。 StratoShark进行熟悉的数据包捕获（&lt;a href =“ https://sysdig.com/learn-cloud-native/what-is-a-pcap-file/”&gt; &lt;strong&gt; pcap &lt;/strong&gt; &lt;/a&gt; ）分析WireShark等工具的分析经验，并将其带入现代云本地系统的现代时代，&lt;a href =“ https://github.com/draios/sysdig-workshop-forensics/blob/master/master/master/example0/command0/commands”&gt; &lt;strong&gt; scap &lt;/strong&gt; &lt;/a&gt;文件。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;使用&lt;strribsinsp &lt;/strong&gt;和&lt;strong&gt; libscap &lt;/strong&gt;，StratoShark捕获和分析Syscall活动和云审核日志，提供了一个功能强大但用户友好的界面来剖析这些数据集。它支持与&lt;a href =“ https://sysdig.com/blog/falco-vs-sysdig-oss”&gt; &lt;strong&gt; falco and sysdig cli &lt;/strong&gt; &lt;/a&gt;，允许无缝过渡，在工具之间。使用StratoShark，用户可以过滤和分析系统调用活动，就像网络管理员长期以来对数据包捕获完成的工作，从而为云环境中的应用程序级行为提供了新的见解。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;H3 class =“ WP-block-neading”&gt;比较生态系统方法：Tracee，Tetragon和Falco &lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt; Falco和Sysdig并不是探索系统呼叫监视功能的唯一工具。 Tracee和Tetragon是提供独特方法的显着替代方法：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class =“ wp-block-list”&gt;&#xA;&lt;li&gt; &lt;a href =“ https://github.com/aquasecurity/tracee”&gt; &lt;strong&gt; tracee &lt;/strong&gt; &lt;/a&gt;使用EBPF监视运行时活动并检测安全事件。它强调了对系统行为的实时可见性，并发现可疑的运行时活动模式。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class =“ wp-block-list”&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/cilium/tetragon&#34;&gt;&lt;strong&gt;Tetragon&lt;/strong&gt;&lt;/a&gt; 承诺 Kubernetes 感知的可观察性和安全执行。通过直接在 eBPF 中应用策略，它声称可以减少开销，同时提供实时运行时执行。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Falco&lt;/strong&gt; 和 &lt;strong&gt;Stratoshark&lt;/strong&gt; 的独特之处在于其平易近人性和灵活性。 Falco 的插件架构和 Stratoshark 读取 SCAP 进行事件后取证的能力为 Linux 内核和云原生世界带来了类似 Wireshark 的体验。这对还弥合了系统调用数据与云和 Kubernetes 日志的叠加抽象之间的差距，以实现安全性和性能调整。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;为什么理解云原生上下文中的系统调用很重要&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://sysdig.com/blog/kernel-introspection-from-linux-to-windows/#:~:text=System%20calls%20(syscalls%20for%20short,space% 20applications%20and%20the%20kernel。&#34;&gt;&lt;strong&gt;系统调用&lt;/strong&gt;&lt;/a&gt;是应用程序和操作系统之间的接口，是理解容器工作负载行为的基础。诸如此类的工具Falco、Tracee 和 Tetragon 允许开发人员和操作人员深入了解这些交互，发现异常、优化性能并提高安全可观察性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Falco 的库和插件为此分析提供了基础，使系统调用既可访问又可操作。通过支持 Stratoshark 等工具，它们可以更深入地探索云原生系统，同时保持与其他数据源和生态系统集成的灵活性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;前方的路&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;随着云原生采用的不断增长，Falco 和 Stratoshark 等工具将变得越来越重要。它们能够统一系统调用数据、通过上下文丰富数据并以可访问的方式呈现数据，使团队能够排除故障、保护和优化现代应用程序。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.cncf.io/blog/2024/11/06/why-falcos-new-response-engine-is-a-game-changer-for-open-source- cloud-native-security/&#34;&gt;&lt;strong&gt;Falco 对 CNCF 生态系统的贡献&lt;/strong&gt;&lt;/a&gt;体现了开源协作的力量以及构建激发创新的基础工具的重要性。在 Stratoshark 等项目的引领下，从 PCAP 到 SCAP 的演变是云原生时代安全性和可观察性的飞跃。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您今天有兴趣尝试 Stratoshark，可以访问 &lt;a href=&#34;https://stratoshark.org/&#34;&gt;&lt;strong&gt;https://stratoshark.org&lt;/strong&gt;&lt; /a&gt;. &lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Tue, 21 Jan 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Kubernetes in 2025: are you ready for these top 5 trends and predictions?】2025 年的 Kubernetes：您准备好迎接这 5 大趋势和预测了吗？</title>
      <link>https://www.cncf.io/blog/2025/01/22/kubernetes-in-2025-are-you-ready-for-these-top-5-trends-and-predictions/</link>
      <description>【&lt;p&gt;&lt;em&gt;Member post originally published on the &lt;a href=&#34;https://www.fairwinds.com/blog/kubernetes-2025-top-5-trends-predictions&#34;&gt;Fairwinds blog&lt;/a&gt; by Andy Suderman&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Now that Kubernetes has turned&amp;nbsp;&lt;a href=&#34;https://www.fairwinds.com/blog/kubernetes-decade-container-orchestration&#34;&gt;10&lt;/a&gt;, it has firmly established itself as a cornerstone of cloud-native deployment. That means it’s finally fair to request ten years of Kubernetes experience when writing job descriptions! While Kubernetes is undeniably complex, it also enables organizations to implement and customize it to fit their individual business needs. Looking ahead to 2025, we expect Kubernetes and the cloud-native ecosystem to continue to grow and evolve. Drawing on our own experience and&amp;nbsp;&lt;a href=&#34;https://www.fairwinds.com/dzone-kube-in-enterprise-email&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;DZone’s Kubernetes in the Enterprise report&lt;/a&gt;, here are five things we expect to focus on in the Kubernetes ecosystem in the year ahead.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;1. Containers &amp;amp; Container Management&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Containers exploded in popularity in 2013 when&amp;nbsp;&lt;a href=&#34;https://www.docker.com/&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;Docker&lt;/a&gt;&amp;nbsp;emerged, and often people use the words Docker and container interchangeably. The key difference is that Docker also offered an ecosystem for container management. Kubernetes then emerged as a container orchestration system in 2014.&amp;nbsp;&lt;a href=&#34;https://www.fairwinds.com/blog/kubernetes-basics-tutorial-ensure-containers-do-not-run-as-root&#34;&gt;Containers&lt;/a&gt;&amp;nbsp;remain a staple in modern software architectures because they include everything an application needs to run (including libraries, system tools, code, and runtime), making it easier to deploy consistently across different environments. Container use has grown consistently over the years and is now holding steady at about 84%.&amp;nbsp;&lt;strong&gt;Expect Docker and Kubernetes use in development and production environments to continue to rise as the technology and ecosystem mature.&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://www.fairwinds.com/hs-fs/hubfs/ContainerManagementTools.png?width=624&amp;amp;height=397&amp;amp;name=ContainerManagementTools.png&#34; alt=&#34;Container Management Tools in Dev &amp;amp; Prod&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;2. Kubernetes Use Cases&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you’re reading this, you probably already know that&amp;nbsp;&lt;a href=&#34;https://kubernetes.io/&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;Kubernetes&lt;/a&gt;&amp;nbsp;automates the deployment, scaling, and management of containerized applications across clusters. This ensures high availability and fault tolerance, and that’s why K8s is the most commonly used container management technology in production environments. The DZone report showed 76% of developers had personal experience working with Kubernetes, almost exactly the same percentage of organizations that indicated they were running K8s clusters (75%). There are many common use cases respondents shared, but the top three were hybrid/&lt;a href=&#34;https://www.fairwinds.com/blog/how-to-operate-kubernetes-in-a-multi-cluster-multi-cloud-world&#34;&gt;multi-cloud&lt;/a&gt;&amp;nbsp;(54%), new cloud-native apps (49%), and modernizing existing apps (46%).&amp;nbsp;&lt;strong&gt;Expect these use cases to remain stable and&amp;nbsp;&lt;/strong&gt;&lt;a href=&#34;https://www.fairwinds.com/blog/4-best-practices-cloud-native-infrastructure-ai-workloads&#34;&gt;&lt;strong&gt;Artificial Intelligence (AI) / Machine Learning (ML)&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;&amp;nbsp;and Edge / Internet of Things (IoT) use cases to rise in the year ahead.&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://www.fairwinds.com/hs-fs/hubfs/K8sUseCases.png?width=624&amp;amp;height=278&amp;amp;name=K8sUseCases.png&#34; alt=&#34;Kubernetes Use Cases&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;3. Developer Sentiment&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Development teams continue to struggle with some aspects of Kubernetes. While they love the scalability, high availability, and fault tolerance it offers, many developers find that setting up, configuring, and&amp;nbsp;&lt;a href=&#34;https://www.fairwinds.com/blog/when-why-hand-keys-kubernetes-infrastructure&#34;&gt;managing Kubernetes&lt;/a&gt;&amp;nbsp;is time consuming and resource intensive. The latest survey shows some areas where more than half of respondents believe Kubernetes has improved things for devs (CI/CD, deployment in general, auto scaling, and building microservices). There are other areas where it hasn’t helped, however. More than half of respondents shared that K8s had neither improved nor worsened architectural refactoring, security, application modularity, and overall system design. In some areas, notably cost (25%), architectural refactoring (15%), and security (13%), developers think Kubernetes has actually made things worse.&amp;nbsp;&lt;strong&gt;In the year ahead, dev teams are going to push back on the requirement to learn K8s and ask for&amp;nbsp;&lt;/strong&gt;&lt;a href=&#34;https://www.fairwinds.com/managed-kubernetes&#34;&gt;&lt;strong&gt;Managed Kubernetes-as-a-Service&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;&amp;nbsp;and&amp;nbsp;&lt;/strong&gt;&lt;a href=&#34;https://www.fairwinds.com/insights&#34;&gt;&lt;strong&gt;tools&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;&amp;nbsp;to make deploying to Kubernetes infrastructure easier so they can focus on building applications and services.&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://www.fairwinds.com/hs-fs/hubfs/K8sImproved-Worsened.png?width=624&amp;amp;height=347&amp;amp;name=K8sImproved-Worsened.png&#34; alt=&#34;What has Kubernetes Improved or Worsened?&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;4. Monitoring &amp;amp; Observability&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes is a dynamic and distributed environment, which can make it more difficult to get insights into application performance, health, and resource utilization.&amp;nbsp;&lt;a href=&#34;https://www.fairwinds.com/blog/top-9-questions-kubernetes-monitoring&#34;&gt;Monitoring and observability&lt;/a&gt;&amp;nbsp;make it easier to identify the root cause of performance bottlenecks, failures, or misconfigurations. Most DZone respondents (69%) are already using tools to monitor Kubernetes, relying on a variety of tools to monitor cloud-native and containerized apps (Grafana 65%, Prometheus 62%, followed by Splunk with 24%, and&amp;nbsp;&lt;a href=&#34;https://www.fairwinds.com/blog/prevent-risk-monitor-kubernetes-fairwinds-datadog&#34;&gt;Datadog&lt;/a&gt;&amp;nbsp;with 21%, and many other tools). This year, the majority of respondents (56%) indicated that their organization is also using AI for monitoring and observability.&amp;nbsp;&lt;strong&gt;Right now, the most common uses of AI are for anomaly detection and performance analysis, but we expect this to change as more companies adopt AI-enabled tools to help them make the most of their Kubernetes investment.&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;847&#34; height=&#34;364&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2025/01/AIforMonitoring.webp&#34; alt=&#34;Adoption of AI&#34; class=&#34;wp-image-123688&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2025/01/AIforMonitoring.webp 847w, https://www.cncf.io/wp-content/uploads/2025/01/AIforMonitoring-300x129.webp 300w, https://www.cncf.io/wp-content/uploads/2025/01/AIforMonitoring-768x330.webp 768w, https://www.cncf.io/wp-content/uploads/2025/01/AIforMonitoring-465x200.webp 465w&#34; sizes=&#34;auto, (max-width: 847px) 100vw, 847px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;5. K8s’ Impact on Other Development Trends&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes both impacts and is impacted by software development systems, tools, and practices. The DZone report focused on three of these areas: cost optimization techniques, security, and microservices.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Cost Optimization&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes can help with&amp;nbsp;&lt;a href=&#34;https://www.fairwinds.com/blog/6-kubernetes-cost-control-strategies-you-need-for-2025&#34;&gt;cost optimization&lt;/a&gt;&amp;nbsp;by automating resource allocation, scaling based on demand, and distributing workloads efficiently across nodes. In cloud environments, expenses can rise quickly, and it can be hard to determine where costs are coming from (and how to attribute them) in these ephemeral environments. Respondents shared that the top ways they’re managing and optimizing costs are through automation of manual processes (65%), containerization (62%), CI/CD (61%), with Infrastructure as Code (IaC) and monitoring and analytics tied for fourth (59%).&lt;strong&gt;&amp;nbsp;In 2025, we expect IaC and cloud optimization (currently at 56%) to rise significantly as well as failover and disaster recovery (currently 33%).&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Security&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes security can be challenging, but it’s important to protect&amp;nbsp;&lt;a href=&#34;https://insights.docs.fairwinds.com/first-steps/container-security/&#34;&gt;containerized&lt;/a&gt;&amp;nbsp;applications and infrastructure from unauthorized access, vulnerabilities, and potential malicious attacks. Organizations must implement network policies, secure container images, and regularly&amp;nbsp;&lt;a href=&#34;https://www.fairwinds.com/blog/upgrading-kubernetes&#34;&gt;update Kubernetes&lt;/a&gt;&amp;nbsp;itself and all related add-ons, APIs, and other components to minimize the risk of breaches and data leaks. Respondents shared that the top three ways they manage K8s’ security include updating Kubernetes regularly (67%), blocking or limiting&amp;nbsp;&lt;a href=&#34;https://www.fairwinds.com/blog/nsa-hardening-guide-locking-down-network-access-with-fairwinds-insights&#34;&gt;network access&lt;/a&gt;&amp;nbsp;to exposed ports (53%), and enabling&amp;nbsp;&lt;a href=&#34;https://www.fairwinds.com/blog/kubernetes-security-policy&#34;&gt;role-based access control&lt;/a&gt;&amp;nbsp;(52%). Fortunately, only 25% of respondents shared that they needed to reassess planned Kubernetes and/or container deployments to production due to security concerns in the past year.&amp;nbsp;&lt;strong&gt;While most organizations may not have encountered a problem with Kubernetes security in 2024, expect malicious attackers to focus more on targeting K8s infrastructure as enterprises increasingly deploy mission-critical applications to production.&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Microservices&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Many teams already run microservices on Kubernetes to take advantage of the simplified management of complex applications as well as improved scalability and reliability. Kubernetes automates microservice deployment, scaling, and monitoring, so each service runs independently and can be updated, scaled, or restarted without impacting other microservices. The DZone report showed that 87% of respondents use microservices, with 95% of them running microservices on Kubernetes.&amp;nbsp;&lt;strong&gt;In 2025, expect the use of microservices on K8s to remain the same unless a new technology emerges to change the game.&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Five Fairwinds Predictions for 2025&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As Kubernetes practitioners who have helped clients manage hundreds of clusters, here are five more predictions for the year ahead based on our hands-on experience:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;The use of&amp;nbsp;&lt;a href=&#34;https://www.fairwinds.com/blog/aws-karpenter-readiness-6-ways-to-make-sure-youre-ready-for-the-move&#34;&gt;Karpenter&lt;/a&gt;&amp;nbsp;will explode, helping users improve both application availability and cluster efficiency based on application workloads in AWS environments.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Organizations using Kubernetes will consolidate clusters to increase efficiency and simplify management.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Our clients and others relying on K8s infrastructure will experiment more with multi-cloud and hybrid strategies as well as with on-prem/bare metal deployments.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;VMware clients will begin migrating away from the platform due to rising costs, licensing changes, support concerns, and vendor lock-in. Those looking for alternatives now have mature and robust virtualization alternatives that support the shift to cloud-native and containerization. Those choosing to migrate to Kubernetes will find the journey worthwhile.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Modern DevOps teams will augment teams with&amp;nbsp;&lt;a href=&#34;https://www.fairwinds.com/managed-kubernetes&#34;&gt;external expertise&lt;/a&gt;&amp;nbsp;to allow key SREs time to focus on application tuning, reliability, and developer experience.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Kubernetes in 2025&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In 2025, Kubernetes will further cement its position as a critical technology in enterprise software development. Its role in enabling scalable, portable, and efficient container and microservices orchestration across various environments will ensure its place as an indispensable tool for modern application deployment and management. As the ecosystem continues to evolve, we can expect to see improvements in ease of use, security, and support for emerging use cases like AI/ML and edge computing.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If your organization is ready to focus on building out your differentiators and optimizing development processes and release times instead of maintaining infrastructure in 2025,&amp;nbsp;&lt;a href=&#34;https://www.fairwinds.com/fairwinds-managed-kubernetes-request&#34;&gt;reach out&lt;/a&gt;. Fairwinds Managed Kubernetes-as-a-Service can architect, build, and maintain your Kubernetes infrastructure so you can focus on what you do best.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;CTA: &lt;a href=&#34;https://www.fairwinds.com/cs/c/?cta_guid=a38c3010-286e-4e25-a4fb-3cba552a76ea&amp;amp;signature=AAH58kGLvdnrH1IdtCG9D_uemhCKYPfDUw&amp;amp;utm_referrer=https%3A%2F%2Fwww.google.com%2F&amp;amp;portal_id=2184645&amp;amp;pageId=184500024693&amp;amp;placement_guid=ba89163c-1a5a-48d2-9658-f57d44396877&amp;amp;click=06e99503-7ea0-4a1a-8106-b9dc51ff0081&amp;amp;redirect_url=APefjpFZw_9eYdlq7vsyn32EfGQCdGejNwaNA71FG2ABoDFetAze_cSNwMkLTKNKoKI-vX6VLvsKNmLUZeLZ2kJVFAJZa6CC0UgORvfuapop1VE09m1-CIY5RQhhFYTAU1B_FNbd0RAhTP7m5SCtbr5D7m76X7sha9Q_DeUYClS0KHbsmTal7e1uX0RhmkwV67GavMXH95JjuEpuYlAuJVW1Ncloh3c9IeuDCbX-0qOQSvUAv9Lh8wwWRcEkqWIvtZZFLA5Lbsw4&amp;amp;hsutk=146169ef54ea906c5feeff5fd98a2e7c&amp;amp;canon=https%3A%2F%2Fwww.fairwinds.com%2Fblog%2Fkubernetes-2025-top-5-trends-predictions&amp;amp;ts=1737449750725&amp;amp;__hstc=91154437.146169ef54ea906c5feeff5fd98a2e7c.1736874032452.1736874032452.1737449752187.2&amp;amp;__hssc=91154437.1.1737449752187&amp;amp;__hsfp=810579359&amp;amp;contentType=blog-post&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;&lt;strong&gt;Explore Managed Kubernetes-as-a-Service&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;成员帖子最初由 Andy 发布在 &lt;a href=&#34;https://www.fairwinds.com/blog/kubernetes-2025-top-5-trends-predictions&#34;&gt;Fairwinds 博客&lt;/a&gt;上苏德曼&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;现在 Kubernetes 已经&lt;a href=&#34;https://www.fairwinds.com/blog/kubernetes-decade-container-orchestration&#34;&gt;十岁&lt;/a&gt;了，它已经牢固地确立了自己作为云基石的地位-本机部署。这意味着在撰写职位描述时要求拥有十年 Kubernetes 经验终于是公平的了！虽然 Kubernetes 无可否认是复杂的，但它也使组织能够实施和定制它以满足各自的业务需求。展望 2025 年，我们预计 Kubernetes 和云原生生态系统将继续发展和发展。借鉴我们自己的经验以及&lt;a href=&#34;https://www.fairwinds.com/dzone-kube-in-enterprise-email&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;企业报告中的 DZone Kubernetes&lt; /a&gt;，我们预计未来一年 Kubernetes 生态系统将重点关注以下五件事。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;1.容器和容器管理&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;2013 年，&lt;a href=&#34;https://www.docker.com/&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;Docker&lt;/a&gt; 出现后，容器迅速普及，人们经常使用Docker 和容器这两个词可以互换。主要区别在于 Docker 还提供了容器管理的生态系统。随后，Kubernetes 在 2014 年作为容器编排系统出现。&lt;a href=&#34;https://www.fairwinds.com/blog/kubernetes-basics-tutorial-ensure-containers-do-not-run-as-root&#34;&gt;容器&lt;/a&gt;仍然是现代软件架构的主要组成部分，因为它们包含应用程序运行所需的一切（包括库、系统工具、代码和运行时），从而更容易在不同环境中一致部署。多年来，集装箱使用量持续增长，目前稳定在 84% 左右。 &lt;strong&gt;随着技术和生态系统的成熟，预计 Docker 和 Kubernetes 在开发和生产环境中的使用将继续上升。&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://www.fairwinds.com/hs-fs/hubfs/ContainerManagementTools.png?width=624&amp;height=397&amp;name=ContainerManagementTools。 png&#34; alt=&#34;开发和生产中的容器管理工具&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;2. Kubernetes 用例&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您正在阅读本文，您可能已经知道&lt;a href=&#34;https://kubernetes.io/&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;Kubernetes&lt;/a&gt;会自动执行部署，跨集群的容器化应用程序的扩展和管理。这保证了高可用性和容错能力，这就是为什么 K8s 是生产环境中最常用的容器管理技术。 DZone 报告显示 76% 的开发人员有使用 Kubernetes 的个人经验，几乎完全相同的百分比表示正在运行 K8s 集群的组织 (75%)。受访者分享了许多常见用例，但前三个是混合/&lt;a href=&#34;https://www.fairwinds.com/blog/how-to-operate-kubernetes-in-a-multi-cluster-multi -cloud-world&#34;&gt;多云&lt;/a&gt;（54%）、新的云原生应用（49%）以及对现有应用进行现代化改造（46%）。 &lt;strong&gt;预计这些用例保持稳定&lt;/strong&gt;&lt;a href=&#34;https://www.fairwinds.com/blog/4-best-practices-cloud-native-infrastruct-ai-workloads&#34;&gt;&lt; strong&gt;人工智能 (AI)/机器学习 (ML)&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;和边缘/物联网 (IoT) 用例在未来一年将会增加。&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://www.fairwinds.com/hs-fs/hubfs/K8sUseCases.png?width=624&amp;height=278&amp;name=K8sUseCases。 png&#34; alt=&#34;Kubernetes 用例&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;3.开发者情绪&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;开发团队继续在 Kubernetes 的某些方面苦苦挣扎。虽然他们喜欢它提供的可扩展性、高可用性和容错能力，但许多开发人员发现设置、配置和&lt;a href=&#34;https://www.fairwinds.com/blog/when-why-hand-keys- kubernetes-infrastructure&#34;&gt;管理 Kubernetes&lt;/a&gt; 非常耗时且占用资源。最新调查显示，超过一半的受访者认为 Kubernetes 为开发人员改进了一些领域（CI/CD、一般部署、自动扩展和构建微服务）。然而，它在其他领域却没有帮助。超过一半的受访者表示，K8 在架构重构、安全性、应用程序模块化和整体系统设计方面既没有改善也没有恶化。在某些领域，特别是成本（25%）、架构重构（15%）和安全性（13%），开发人员认为 Kubernetes 实际上让事情变得更糟。 &lt;strong&gt;在未来的一年中，开发团队将取消学习 K8 的要求并要求&lt;/strong&gt;&lt;a href=&#34;https://www.fairwinds.com/management-kubernetes&#34;&gt;&lt;strong &gt;托管 Kubernetes 即服务&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;和&lt;/strong&gt;&lt;a href=&#34;https://www.fairwinds.com/insights&#34;&gt;&lt;strong&gt;工具&lt;/strong &gt;&lt;/a&gt;&lt;strong&gt; 使更轻松地部署到 Kubernetes 基础设施，以便他们可以专注于构建应用程序和服务。&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://www.fairwinds.com/hs-fs/hubfs/K8sImproved-Worsened.png?width=624&amp;height=347&amp;name= K8sImproved-Worsened.png&#34; alt=&#34;Kubernetes 改进或恶化了什么？&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;4.监控和可观察性&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes 是一个动态的分布式环境，这使得深入了解应用程序性能、运行状况和资源利用率变得更加困难。 &lt;a href=&#34;https://www.fairwinds.com/blog/top-9-questions-kubernetes-monitoring&#34;&gt;监视和可观察性&lt;/a&gt;使确定性能瓶颈，失败或配置错误的根本原因变得更加容易。大多数DZONE受访者（69％）已经在使用工具来监视Kubernetes，依靠多种工具来监视云本地和容器化应用程序（Grafana 65％，Prometheus 62％，其次是24％，&lt;a href = a href = “ https://www.fairwinds.com/blog/prevent-risk-monitor-kubernetes-fairwinds-datadog&#34;&gt; datadog &#34;&gt; datadog &lt;/a&gt;，&lt;/a&gt;有21％，还有许多其他工具）。今年，大多数受访者（56％）表示，他们的组织也使用AI来监视和可观察性。 &lt;strong&gt;目前，AI的最常见用途是用于异常检测和性能分析，但我们希望随着越来越多的公司采用AI-Spable工具来帮助他们充分利用其Kubernetes投资。&lt;/strong&gt; &lt;&lt;/strong&gt; &lt; /p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figie class =“ wp-block-image size-full”&gt; &lt;img loading =“ lazy” dexoding =“ async” width =“ 847” height =“ 364” src =“ https://www.cncf.io/ wp-content/uploads/2025/01/aibriontoring.webp“ alt =”采用AI class =“ WP-Image-1123688” srcset =“ https://www.cncf.io/wp-content/wp-content/wp-content/20255 /01/aibromonoring.webp 847W，https://www.cncf.io/wp-content/uploads/2025/01/aibromonoring-300x129.webp 300w，https：//////////////////////////////////////www.cncf.io/wp-contents/ /2025/01/aibrolonoring-768x330.webp 768W，https://www.cncf.io/wp-content/wp-content/uploads/2025/01/aimortionoring-465x200.webp 465w sizes ）100VW，847px“ reverrerpolicy =“ no-treferrer”&gt; &lt;/figife&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class =“ wp-block头”&gt; 5。 K8对其他发展趋势的影响&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt; kubernetes既有影响，又受到软件开发系统，工具和实践的影响。 DZONE报告的重点是其中三个领域：成本优化技术，安全性和微服务。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;H3 class =“ WP-block-neading”&gt;成本优化&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt; kubernetes可以帮助&lt;a href =“ https://www.fairwinds.com/blog/6-kubernetes-cost-cost-control-control-strategies-you-need-for-2025”&gt;成本优化&lt;/a&gt;自动化资源分配，根据需求进行扩展以及在节点之间有效分配工作负载。在云环境中，费用可以迅速上升，并且在这些短暂的环境中可能很难确定成本来自何处（以及如何归因于这些成本）。受访者分享说，他们管理和优化成本的最佳方式是通过手动流程自动化（65％），容器化（62％），CI/CD（61％）（61％），基础架构为代码（IAC）以及监视和分析。对于第四名（59％）。&lt;strong&gt; 2025年，我们预计IAC和云优化（目前为56％）以及故障转移和灾难恢复（目前为33％）。&lt;/strong&gt; &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class =“ wp-block头”&gt;安全性&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt; kubernetes安全可能具有挑战性，但是保护&lt;a href =“ https://insights.docs.fairwinds.com/first-steps/container-security/”联合国授权访问、漏洞和潜在的恶意攻击。组织必须实施网络策略、保护容器映像，并定期&lt;a href=&#34;https://www.fairwinds.com/blog/upgrading-kubernetes&#34;&gt;更新 Kubernetes&lt;/a&gt; 本身以及所有相关的插件、API、和其他组件，以最大限度地减少违规和数据泄露的风险。受访者表示，他们管理 K8s 安全性的三种主要方式包括定期更新 Kubernetes (67%)、阻止或限制&lt;a href=&#34;https://www.fairwinds.com/blog/nsa-hardening-guide-locking-down -network-access-with-fairwinds-insights&#34;&gt;对公开端口的网络访问&lt;/a&gt; (53%)，并启用&lt;a href=&#34;https://www.fairwinds.com/blog/kubernetes-security-policy&#34;&gt;基于角色的访问控制&lt;/a&gt;（52%）。幸运的是，只有 25% 的受访者表示，由于过去一年的安全问题，他们需要重新评估计划的 Kubernetes 和/或容器部署到生产环境。 &lt;strong&gt;虽然大多数组织在 2024 年可能不会遇到 Kubernetes 安全问题，但随着企业越来越多地将关键任务应用程序部署到生产环境，预计恶意攻击者将更多地关注 K8s 基础设施。&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;微服务&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;许多团队已经在 Kubernetes 上运行微服务，以利用复杂应用程序的简化管理以及提高的可扩展性和可靠性。 Kubernetes 自动化微服务部署、扩展和监控，因此每个服务独立运行，并且可以更新、扩展或重新启动，而不会影响其他微服务。 DZone 报告显示，87% 的受访者使用微服务，其中 95% 在 Kubernetes 上运行微服务。 &lt;strong&gt;到 2025 年，预计 K8 上微服务的使用将保持不变，除非出现新技术来改变游戏规则。&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;2025 年 Fairwinds 的五项预测&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;作为帮助客户管理数百个集群的 Kubernetes 从业者，根据我们的实践经验，对未来一年还有以下五个预测：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;使用&lt;a href=&#34;https://www.fairwinds.com/blog/aws-karpenter-readiness-6-ways-to-make-sure-youre-ready-for-the-move&#34;&gt; Karpenter&lt;/a&gt;将爆发式增长，帮助用户根据 AWS 环境中的应用程序工作负载提高应用程序可用性和集群效率。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;使用 Kubernetes 的组织将整合集群以提高效率并简化管理。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;我们的客户和其他依赖 K8s 基础设施的客户将更多地尝试多云和混合策略以及本地/裸机部署。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;由于成本上升、许可变更、支持问题和供应商锁定，VMware 客户端将开始从该平台迁移。那些寻找替代方案的人现在已经拥有成熟而强大的虚拟化技术支持向云原生和容器化转变的替代方案。那些选择迁移到 Kubernetes 的人会发现这段旅程是值得的。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;现代 DevOps 团队将通过&lt;a href=&#34;https://www.fairwinds.com/management-kubernetes&#34;&gt;外部专业知识&lt;/a&gt;来增强团队实力，让关键 SRE 有时间专注于应用程序调优、可靠性和安全性开发人员经验。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;2025 年的 Kubernetes&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;2025年，Kubernetes将进一步巩固其作为企业软件开发关键技术的地位。它在跨各种环境中实现可扩展、可移植和高效的容器和微服务编排方面的作用将确保其作为现代应用程序部署和管理不可或缺的工具的地位。随着生态系统的不断发展，我们预计会看到易用性、安全性以及对人工智能/机器学习和边缘计算等新兴用例的支持方面的改进。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您的组织已准备好在 2025 年专注于打造差异化优势、优化开发流程和发布时间，而不是维护基础设施，&lt;a href=&#34;https://www.fairwinds.com/fairwinds-management-kubernetes-请求&#34;&gt;联系&lt;/a&gt;。 Fairwinds Managed Kubernetes-as-a-Service 可以架构、构建和维护您的 Kubernetes 基础设施，以便您可以专注于自己最擅长的事情。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;号召性用语：&lt;a href=&#34;https://www.fairwinds.com/cs/c/?cta_guid=a38c3010-286e-4e25-a4fb-3cba552a76ea&amp;signature=AAH58kGLvdnrH1IdtC G9D_uemhCKYPfDUw&amp;utm_referrer=https%3A%2F%2Fwww.google.com%2F&amp;portal_id=2184645&amp;pageId=184500024693&amp;placement_gu id=ba89163c-1a5a-48d2-9658-f57d44396877&amp;click=06e99503-7ea0-4a1a-8106-b9dc51ff0081&amp;redirect_url=APefjpFZw_9eYdlq 7vsyn32EfGQCdGejNwaNA71FG2ABoDFetAze_cSNwMkLTKNKoKI-vX6VLvsKNmLUZeLZ2kJVFAJZa6CC0UgORvfuapop1VE09m1-CIY5RQhhFYTA U1B_FNbd0RAhTP7m5SCtbr5D7m76X7sha9Q_DeUYClS0KHbsmTal7e1uX0RhmkwV67GavMXH95JjuEpuYlAuJVW1Ncloh3c9IeuDCbX-0qOQSvUA v9Lh8wwWRcEkqWIvtZZFLA5Lbsw4&amp;hsutk=146169ef54ea906c5feeff5fd98a2e7c&amp;canon=https%3A%2F%2Fwww.fairwinds.com%2Fblog %2Fkubernetes-2025-top-5-趋势预测&amp;ts=1737449750725&amp;__hstc=91154437.146169ef54ea906c5feeff5fd98a2e7c.17 36874032452.1736874032452.1737449752187.2&amp;__hssc=91154437.1.1737449752187&amp;__hsfp=810579359&amp;contentType=博客文章&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;&lt;strong&gt;探索托管 Kubernetes 即服务&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Tue, 21 Jan 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【What is GitLab Runner?】什么是Gitlab Runner？</title>
      <link>https://www.cncf.io/blog/2025/01/17/what-is-gitlab-runner/</link>
      <description>【&lt;p&gt;&lt;em&gt;Ambassador post by Natalia Granato, CNCF Ambassador&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;GitLab Runner is an open-source application that runs jobs defined in your GitLab CI/CD pipelines. It can be installed on different platforms, including virtual machines, bare-metal servers, and Kubernetes.&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Registering the Runner in Your Projects&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;After deploying GitLab Runner on Kubernetes, you need to register the runner in your projects so it can execute jobs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Go to the &lt;code&gt;Settings &amp;gt; CI/CD&lt;/code&gt; section of your project in GitLab.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Expand the &lt;code&gt;Runners&lt;/code&gt; section.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Click on &lt;code&gt;Register a runner&lt;/code&gt;.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Copy the displayed registration token.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Run the following command on your Kubernetes cluster, replacing &lt;code&gt;YOUR_REGISTRATION_TOKEN&lt;/code&gt; with the copied token:&lt;br&gt;&lt;code&gt;sh kubectl exec -it gitlab-runner-gitlab-runner-XXXXX-XXXXX -- gitlab-runner register \ --non-interactive \ --url https://gitlab.example.com/ \ --registration-token YOUR_REGISTRATION_TOKEN \ --executor kubernetes&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Deploying GitLab Runner on Kubernetes Using Helm&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To install GitLab Runner on Kubernetes using Helm, follow these steps:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Add the Helm repository: &lt;code&gt;helm repo add gitlab https://charts.gitlab.io/&lt;/code&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Update the repositories: &lt;code&gt;helm repo update&lt;/code&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Install GitLab Runner:&lt;br&gt;&lt;code&gt;sh helm install gitlab-runner gitlab/gitlab-runner \ --set gitlabUrl=https://gitlab.example.com/ \ --set runnerRegistrationToken=YOUR_REGISTRATION_TOKEN&lt;/code&gt;&lt;br&gt;Replace &lt;code&gt;https://gitlab.example.com/&lt;/code&gt; with your GitLab URL.&lt;br&gt;Replace &lt;code&gt;YOUR_REGISTRATION_TOKEN&lt;/code&gt; with the runner registration token obtained in the CI/CD section of your GitLab project.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Key Points in the &lt;code&gt;values.yaml&lt;/code&gt; Configuration File&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Rules (&lt;code&gt;rules&lt;/code&gt;)&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This section defines permissions for accessing Kubernetes resources.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;resources&lt;/strong&gt;: Lists the Kubernetes resources the runner can access, such as &lt;code&gt;configmaps&lt;/code&gt;, &lt;code&gt;pods&lt;/code&gt;, &lt;code&gt;pods/attach&lt;/code&gt;, &lt;code&gt;secrets&lt;/code&gt;, and &lt;code&gt;services&lt;/code&gt;.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;verbs&lt;/strong&gt;: Actions that can be performed on the above resources, like &lt;code&gt;get&lt;/code&gt;, &lt;code&gt;list&lt;/code&gt;, &lt;code&gt;watch&lt;/code&gt;, &lt;code&gt;create&lt;/code&gt;, &lt;code&gt;patch&lt;/code&gt;, &lt;code&gt;update&lt;/code&gt;, and &lt;code&gt;delete&lt;/code&gt;.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;apiGroups&lt;/strong&gt;: Specifies API groups in Kubernetes. Here, it’s empty (&lt;code&gt;&#39;&#39;&lt;/code&gt;), indicating the core API group.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;resources&lt;/strong&gt;: Lists specific resources of the above API group, such as &lt;code&gt;pods/exec&lt;/code&gt;.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;verbs&lt;/strong&gt;: Actions allowed for the &lt;code&gt;pods/exec&lt;/code&gt; resource, such as &lt;code&gt;create&lt;/code&gt;, &lt;code&gt;patch&lt;/code&gt;, and &lt;code&gt;delete&lt;/code&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Runners (&lt;code&gt;runners&lt;/code&gt;)&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Defines the runner configuration.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;cache&lt;/strong&gt;: Cache configuration, currently empty (&lt;code&gt;{}&lt;/code&gt;).&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;config&lt;/strong&gt;: Runner configuration in TOML format.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;runners.kubernetes&lt;/strong&gt;: Configuration specific to Kubernetes runners.&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;image&lt;/strong&gt;: Container image to use (&lt;code&gt;ubuntu:20.04&lt;/code&gt;).&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;wait_for_services_timeout&lt;/strong&gt;: Timeout for waiting on services (&lt;code&gt;-1&lt;/code&gt; indicates infinite).&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;privileged&lt;/strong&gt;: Enables privileged mode for the container (&lt;code&gt;true&lt;/code&gt;).&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;allow_privilege_escalation&lt;/strong&gt;: Allows privilege escalation (&lt;code&gt;true&lt;/code&gt;).&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;image_pull_secrets&lt;/strong&gt;: Specifies secrets for pulling container images (&lt;code&gt;aws-ecr&lt;/code&gt;).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;configPath&lt;/strong&gt;: Configuration path, currently empty (&lt;code&gt;&#39;&#39;&lt;/code&gt;).&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;name&lt;/strong&gt;: Runner name (&lt;code&gt;globalweb-gitlab-runner&lt;/code&gt;).&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;privileged&lt;/strong&gt;: Indicates privileged execution (&lt;code&gt;true&lt;/code&gt;).&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;runUntagged&lt;/strong&gt;: Indicates whether to run untagged jobs (&lt;code&gt;true&lt;/code&gt;).&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;tags&lt;/strong&gt;: Tags associated with the runner (&lt;code&gt;docker, share_cache, share_cache1, amd64&lt;/code&gt;).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Secrets (&lt;code&gt;secrets&lt;/code&gt;)&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;List of secrets, currently empty (&lt;code&gt;[]&lt;/code&gt;).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;SecurityContext (&lt;code&gt;securityContext&lt;/code&gt;)&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Security configurations for the containers.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;allowPrivilegeEscalation&lt;/strong&gt;: Permission for privilege escalation (&lt;code&gt;false&lt;/code&gt;).&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;capabilities&lt;/strong&gt;: Container capabilities.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;drop&lt;/strong&gt;: Capabilities to be removed (&lt;code&gt;ALL&lt;/code&gt;).&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;privileged&lt;/strong&gt;: Indicates if the container is privileged (&lt;code&gt;false&lt;/code&gt;).&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;readOnlyRootFilesystem&lt;/strong&gt;: Indicates if the root filesystem is read-only (&lt;code&gt;false&lt;/code&gt;).&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;runAsNonRoot&lt;/strong&gt;: Indicates if the container should run as a non-root user (&lt;code&gt;true&lt;/code&gt;).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Other Key Configurations&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Service (&lt;code&gt;service&lt;/code&gt;)&lt;/strong&gt;: Service settings. &lt;code&gt;enabled: false&lt;/code&gt;, &lt;code&gt;type: ClusterIP&lt;/code&gt;.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;SessionServer (&lt;code&gt;sessionServer&lt;/code&gt;)&lt;/strong&gt;: Disabled by default (&lt;code&gt;enabled: false&lt;/code&gt;).&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Termination Grace Period Seconds (&lt;code&gt;terminationGracePeriodSeconds&lt;/code&gt;)&lt;/strong&gt;: Graceful termination timeout (&lt;code&gt;3600&lt;/code&gt; seconds).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Using the New Runner in GitLab CI Pipelines&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To use the new runner in your GitLab CI pipelines, add the &lt;code&gt;kubernetes&lt;/code&gt; tag to the job you want to execute on Kubernetes. For example:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;build_image:&#xA;  stage: build&#xA;  image: alpine:latest&#xA;  tags:&#xA;    - kubernetes&#xA;  script:&#xA;    - echo &#34;Building image...&#34;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Kubernetes Doesn’t Use Docker as Container Runtime? Kaniko to the Rescue&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes doesn’t use Docker as its default container runtime, which can pose a challenge for CI/CD pipelines that depend on Docker for building images. Kaniko is a tool that allows building container images without Docker.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;What is Kaniko and How Does it Work?&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kaniko is an open-source tool that builds container images from a Dockerfile inside a container or Kubernetes cluster. It works by extracting the base container filesystem, executing Dockerfile commands, and packaging the result into a container image.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Configuring Environment Variables in GitLab CI&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To use Kaniko effectively, configure the necessary environment variables in GitLab CI. These variables include credentials for accessing your container registry and project-specific information.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Steps to Configure Environment Variables for Your Pipeline&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Go to the &lt;code&gt;Settings &amp;gt; CI/CD&lt;/code&gt; section of your GitLab project.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Expand the &lt;code&gt;Variables&lt;/code&gt; section.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Add the following variables without the protected flag:&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;code&gt;AWS_REGION&lt;/code&gt;: Specifies the AWS region where resources will be managed.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;code&gt;AWS_ACCESS_KEY_ID&lt;/code&gt;: AWS public access key for authentication.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;code&gt;AWS_SECRET_ACCESS_KEY&lt;/code&gt;: AWS secret access key for authentication.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;code&gt;REGISTRY&lt;/code&gt;: The container registry where Docker images are stored.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Example &lt;code&gt;.gitlab-ci.yml&lt;/code&gt; for Building and Pushing Container Images with Kaniko&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;build:&#xA;  stage: build&#xA;  image:&#xA;    name: gcr.io/kaniko-project/executor:debug&#xA;    entrypoint: [&#34;&#34;]&#xA;  script:&#xA;    - mkdir -p /kaniko/.docker&#xA;    - echo &#34;{\&#34;credsStore\&#34;:\&#34;ecr-login\&#34;,\&#34;credHelpers\&#34;:{\&#34;$REGISTRY/portal-colaborador-hml\&#34;:\&#34;ecr-login\&#34;}}&#34; &amp;gt; /kaniko/.docker/config.json&#xA;    - &amp;gt;-&#xA;      /kaniko/executor&#xA;      --context &#34;${CI_PROJECT_DIR}&#34; \&#xA;      --dockerfile &#34;${CI_PROJECT_DIR}/Dockerfile&#34; \&#xA;      --build-arg AWS_REGION=$AWS_REGION \&#xA;      --build-arg AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID \&#xA;      --build-arg AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY \&#xA;      --destination &#34;${REGISTRY}/portal-colaborador-hml:${CI_COMMIT_SHORT_SHA:0:5}&#34;&#xA;&#xA;  tags:&#xA;    - docker, share_cache, share_cache1, amd64&#xA;  only:&#xA;    - main&#xA;    - develop&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Conclusion&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Using GitLab Runner in conjunction with Kaniko on Kubernetes enables efficient and secure container image building and pushing without relying on Docker as a runtime. This configuration leverages Kubernetes’ power to scale and manage CI/CD builds, offering greater flexibility and performance in your pipelines.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;CNCF 大使 Natalia Granato 担任大使职务&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;GitLab Runner 是一个开源应用程序，它运行在 GitLab CI/CD 管道中定义的作业。它可以安装在不同的平台上，包括虚拟机、裸机服务器和 Kubernetes。&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;在您的项目中注册 Runner&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在 Kubernetes 上部署 GitLab Runner 后，您需要在项目中注册 Runner，以便它可以执行作业。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;转到 GitLab 中项目的&lt;code&gt;Settings &gt; CI/CD&lt;/code&gt; 部分。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;展开&lt;code&gt;跑步者&lt;/code&gt;部分。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;点击&lt;code&gt;注册跑步者&lt;/code&gt;。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;复制显示的注册令牌。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;在 Kubernetes 集群上运行以下命令，将 &lt;code&gt;YOUR_REGISTRATION_TOKEN&lt;/code&gt; 替换为复制的令牌：&lt;br&gt;&lt;code&gt;sh kubectl exec -it gitlab-runner-gitlab-runner-XXXXX-XXXXX -- gitlab-runner register \ --non-interactive \ --url https://gitlab.example.com/ \ --registration-token YOUR_REGISTRATION_TOKEN \ --执行器 kubernetes&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;使用 Helm 在 Kubernetes 上部署 GitLab Runner&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;要使用 Helm 在 Kubernetes 上安装 GitLab Runner，请按照以下步骤操作：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;添加 Helm 存储库：&lt;code&gt;helm repo add gitlab https://charts.gitlab.io/&lt;/code&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;更新存储库：&lt;code&gt;helm repo update&lt;/code&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;安装 GitLab Runner：&lt;br&gt;&lt;code&gt;sh helm install gitlab-runner gitlab/gitlab-runner \ --set gitlabUrl=https://gitlab.example.com/ \ --set runnerRegistrationToken=YOUR_REGISTRATION_TOKEN&lt;/code &gt;&lt;br&gt;将 &lt;code&gt;https://gitlab.example.com/&lt;/code&gt; 替换为您的 GitLab URL。&lt;br&gt;替换&lt;code&gt;YOUR_REGISTRATION_TOKEN&lt;/code&gt; 包含在 GitLab 项目的 CI/CD 部分中获取的运行者注册令牌。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;code&gt;values.yaml&lt;/code&gt; 配置文件中的要点&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;规则（&lt;code&gt;规则&lt;/code&gt;）&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;此部分定义访问 Kubernetes 资源的权限。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;资源&lt;/strong&gt;：列出运行程序可以访问的 Kubernetes 资源，例如 &lt;code&gt;configmaps&lt;/code&gt;、&lt;code&gt;pods&lt;/code&gt;、&lt;code&gt;pods/attach&lt;/code &gt;、&lt;code&gt;秘密&lt;/code&gt;和&lt;code&gt;服务&lt;/code&gt;。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;动词&lt;/strong&gt;：可以对上述资源执行的操作，例如&lt;code&gt;get&lt;/code&gt;、&lt;code&gt;list&lt;/code&gt;、&lt;code&gt;watch&lt;/code&gt;、 &lt;code&gt;创建&lt;/code&gt;、&lt;code&gt;修补&lt;/code&gt;、&lt;code&gt;更新&lt;/code&gt;和&lt;code&gt;删除&lt;/code&gt;。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;apiGroups&lt;/strong&gt;：指定 Kubernetes 中的 API 组。此处为空 (&lt;code&gt;&#39;&#39;&lt;/code&gt;)，表示核心 API 组。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;资源&lt;/strong&gt;：列出上述 API 组的特定资源，例如 &lt;code&gt;pods/exec&lt;/code&gt;。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;动词&lt;/strong&gt;：&lt;code&gt;pod 允许执行的操作/exec &lt;/code&gt;资源，例如&lt;code&gt;创建&lt;/code&gt;，&lt;code&gt; patch &lt;/code&gt;和&lt;code&gt; delete &lt;/code&gt;。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class =“ wp-block头”&gt; &lt;strong&gt;跑步者（&lt;code&gt;跑步者&lt;/code&gt;）&lt;/strong&gt; &lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;定义跑步者配置。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class =“ wp-block-list”&gt;&#xA;&lt;li&gt; &lt;strong&gt;缓存&lt;/strong&gt;：缓存配置，当前为空（&lt;code&gt; {} &lt;/code&gt;）。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;strong&gt; config &lt;/strong&gt;：toml格式的跑步者配置。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;strong&gt; runners.kubernetes &lt;/strong&gt;：Kubernetes跑步者的配置。&#xA;&lt;ul class =“ wp-block-list”&gt;&#xA;&lt;li&gt; &lt;strong&gt;图像&lt;/strong&gt;：要使用的容器图像（&lt;code&gt; ubuntu：20.04 &lt;/code&gt;）。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;strong&gt; wait_for_services_timeout &lt;/strong&gt;：等待服务的超时（&lt;code&gt; -1 &lt;/code&gt;指示Infinite）。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;strong&gt;特权&lt;/strong&gt;：启用容器的特权模式（&lt;code&gt; true &lt;/code&gt;）。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;越&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;strong&gt; image_pull_secrets &lt;/strong&gt;：指定拉动容器图像的秘密（&lt;code&gt; aws-ecr &lt;/code&gt;）。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;strong&gt; configpath &lt;/strong&gt;：配置路径，当前为空（&lt;code&gt;&#39;&#39;&lt;/code&gt;）。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;strong&gt;名称&lt;/strong&gt;：跑步者名称（&lt;code&gt; globalweb-gitlab-runner &lt;/code&gt;）。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;strong&gt;特权&lt;/strong&gt;：指示特权执行（&lt;code&gt; true &lt;/code&gt;）。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;strong&gt; rununtagged &lt;/strong&gt;：指示是否运行未标记的作业（&lt;code&gt; true &lt;/code&gt;）。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;strong&gt;标签&lt;/strong&gt;：与跑步者关联​​的标签（&lt;code&gt; docker，share_cache，share_cache1，amd64 &lt;/code&gt;）。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class =“ wp-block头”&gt; &lt;strong&gt;秘密（&lt;code&gt; secrets &lt;/code&gt;）&lt;/strong&gt; &lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;秘密列表，当前为空（&lt;code&gt; [] &lt;/code&gt;）。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class =“ wp-block头”&gt; &lt;strong&gt; securityContext（&lt;code&gt; securitycontext &lt;/code&gt;）&lt;/strong&gt; &lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;容器的安全配置。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class =“ wp-block-list”&gt;&#xA;&lt;li&gt; &lt;strong&gt;允许privilegeEscalation &lt;/strong&gt;：特权升级的权限（&lt;code&gt; false &lt;/code&gt;）。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;strong&gt;功能&lt;/strong&gt;：容器功能。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;strong&gt; drop &lt;/strong&gt;：要删除的功能（&lt;code&gt; ALL &lt;/code&gt;）。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;strong&gt;特权&lt;/strong&gt;：指示容器是否特权（&lt;code&gt; false &lt;/code&gt;）。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;strong&gt; readonlylootfilesystem &lt;/strong&gt;：指示根文件系统是否仅读取（&lt;code&gt; false &lt;/code&gt;）。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;strong&gt; runasnonroot &lt;/strong&gt;：指示容器是否应作为非root用户运行（&lt;code&gt; true &lt;/code&gt;）。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class =“ wp-block头”&gt; &lt;strong&gt;其他密钥配置&lt;/strong&gt; &lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class =“ wp-block-list”&gt;&#xA;&lt;li&gt; &lt;strong&gt;服务（&lt;code&gt;服务&lt;/code&gt;）&lt;/strong&gt;：服务设置。 &lt;code&gt;启用：false &lt;/code&gt;，&lt;代码&gt;类型：clusterip &lt;/code&gt;。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;strong&gt; sessionserver（&lt;code&gt; sessionserver &lt;/code&gt;）&lt;/strong&gt;：默认禁用（&lt;code&gt; enabled：false &lt;/code&gt;）。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;strong&gt;终止宽限期秒秒（&lt;code&gt; terminationGracePeriodSeconds&lt;/code&gt;)&lt;/strong&gt;：优雅终止超时（&lt;code&gt;3600&lt;/code&gt; 秒）。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;在 GitLab CI 管道中使用新的运行器&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;要在 GitLab CI 管道中使用新的运行程序，请将 &lt;code&gt;kubernetes&lt;/code&gt; 标签添加到要在 Kubernetes 上执行的作业。例如：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;build_image：&#xA;  阶段：构建&#xA;  图片：高山：最新&#xA;  标签：&#xA;    - 库伯内特斯&#xA;  脚本：&#xA;    - echo“构建图像...”&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Kubernetes 不使用 Docker 作为容器运行时？卡尼科来救援&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes 不使用 Docker 作为其默认容器运行时，这可能会给依赖 Docker 构建镜像的 CI/CD 管道带来挑战。 Kaniko 是一个无需 Docker 即可构建容器镜像的工具。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;什么是 Kaniko 及其工作原理？&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kaniko 是一个开源工具，可从容器或 Kubernetes 集群内的 Dockerfile 构建容器映像。它的工作原理是提取基本容器文件系统、执行 Dockerfile 命令并将结果打包到容器映像中。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;在 GitLab CI 中配置环境变量&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;要有效使用 Kaniko，请在 GitLab CI 中配置必要的环境变量。这些变量包括用于访问容器注册表和项目特定信息的凭据。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;为管道配置环境变量的步骤&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;转到 GitLab 项目的&lt;code&gt;Settings &gt; CI/CD&lt;/code&gt; 部分。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;展开&lt;code&gt;变量&lt;/code&gt;部分。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;添加以下不带 protected 标志的变量：&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;code&gt;AWS_REGION&lt;/code&gt;：指定将管理资源的 AWS 区域。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;code&gt;AWS_ACCESS_KEY_ID&lt;/code&gt;：用于身份验证的 AWS 公共访问密钥。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;code&gt;AWS_SECRET_ACCESS_KEY&lt;/code&gt;：用于身份验证的 AWS 秘密访问密钥。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;code&gt;REGISTRY&lt;/code&gt;：存储 Docker 映像的容器注册表。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;使用 Kaniko 构建和推送容器镜像的示例 &lt;code&gt;.gitlab-ci.yml&lt;/code&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;构建：&#xA;  阶段：构建&#xA;  图像：&#xA;    名称：gcr.io/kaniko-project/executor:debug&#xA;    入口点：[&#34;&#34;]&#xA;  脚本：&#xA;    - mkdir -p /kaniko/.docker&#xA;    - echo &#34;{\&#34;credsStore\&#34;:\&#34;ecr-login\&#34;,\&#34;credHelpers\&#34;:{\&#34;$REGISTRY/portal-colaborador-hml\&#34;:\&#34;ecr-login\&#34;}}&#34; &gt; / kaniko/.docker/config.json&#xA;    -&gt;-&#xA;      /kaniko/执行者&#xA;      --context &#34;${CI_PROJECT_DIR}&#34; \&#xA;      --dockerfile &#34;${CI_PROJECT_DIR}/Dockerfile&#34; \&#xA;      --build-arg AWS_REGION=$AWS_REGION \&#xA;      --build-arg AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID \&#xA;      --build-arg AWS_SECRET_access_key = $ aws_secret_access_key \&#xA;       - 末端“ $ {copration}/portal-colaborador-hml：$ {ci_commit_short_sha：0：5}”&#xA;&#xA;  标签：&#xA;     -  docker，share_cache，share_cache1，amd64&#xA;  仅有的：&#xA;    - 主要的&#xA;     - 开发&lt;/code&gt; &lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class =“ wp-block头”&gt;结论&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在Kubernetes上使用gitlab Runner与Kaniko结合使用，可实现高效且安全的容器图像构建和推动，而无需依赖Docker作为运行时。这种配置利用Kubernetes的功能来扩展和管理CI/CD构建，在管道中提供更大的灵活性和性能。&lt;/p&gt;&#xA;&#xA;在&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;在&#xA;&lt;/div&gt;</description>
      <pubDate>Thu, 16 Jan 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Observing and monitoring Large Language Model workloads with Ray】使用 Ray 观察和监控大型语言模型工作负载</title>
      <link>https://www.cncf.io/blog/2025/01/16/observing-and-monitoring-large-language-model-workloads-with-ray/</link>
      <description>【&lt;p&gt;&lt;em&gt;Ambassador post by &lt;a href=&#34;https://github.com/swastik959&#34;&gt;Swastik Gour&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Introduction&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#introduction&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The emergence of Large Language Models (LLMs) such as GPT-4, PHI2, BERT, and T5 revolutionized natural language processing, with these models empowering high-end applications, including chatbots, recommendation systems, and analytics. Yet the scale and complexity of workloads in LLMs make them a great challenge to guarantee performance and reliability. It is under such circumstances that monitoring and observability practices are more than essential while deploying workloads using frameworks such as Ray.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Ray is a distributed computing framework that offers a powerful platform to scale LLM workloads efficiently across clusters. Therefore, it becomes an excellent choice for hosting, managing, and observing LLMs. The observability of critical metrics with Ray’s built-in features in conjunction with Prometheus and Grafana will help users to monitor them efficiently, optimize the use of resources, and rapidly diagnose problems in production.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This article explores the importance of observability in Ray-hosted LLM workloads, key metrics to monitor, and a detailed guide to setting up observability using Prometheus and Grafana.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Why Ray for LLM Workloads?&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#why-ray-for-llm-workloads&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Ray is designed for distributed, scalable applications, making it ideal for hosting and managing LLM workloads. Key features that make Ray an excellent choice include:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Dynamic Task Scheduling:&lt;/strong&gt;&amp;nbsp;Ray’s fine-grained task scheduling ensures efficient resource utilization, especially when processing LLM inference tasks that can vary significantly in size and complexity.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Ease of Integration:&lt;/strong&gt;&amp;nbsp;Ray integrates seamlessly with frameworks like Hugging Face Transformers, enabling easy deployment of pre-trained LLMs.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Autoscaling:&lt;/strong&gt;&amp;nbsp;Ray’s cluster autoscaler dynamically adjusts resources based on workload demands, ensuring cost-effectiveness and scalability.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Observability Support:&lt;/strong&gt;&amp;nbsp;Ray provides metrics endpoints compatible with Prometheus, simplifying the monitoring setup for distributed systems.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;These features make Ray not just a compute framework but a foundational tool for running, monitoring, and scaling LLMs in real-world applications.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Key Metrics for Observing Ray-Hosted LLM Workloads&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#key-metrics-for-observing-ray-hosted-llm-workloads&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To ensure the smooth operation of Ray-hosted LLM workloads, it’s critical to track a range of performance, resource utilization, and operational metrics. Below are the key categories:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;Performance Metrics&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#performance-metrics&#34;&gt;&lt;/a&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Task Latency:&lt;/strong&gt;&amp;nbsp;Measures the time taken for individual Ray tasks to complete, essential for identifying bottlenecks in the inference pipeline.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Throughput:&lt;/strong&gt;&amp;nbsp;Tracks the number of tasks completed per second, reflecting the system’s ability to handle high request volumes.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Token Processing Rate:&lt;/strong&gt;&amp;nbsp;Measures the number of tokens processed per second, particularly relevant for transformer-based models like GPT-4.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;Resource Utilization Metrics&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#resource-utilization-metrics&#34;&gt;&lt;/a&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;CPU and GPU Utilization:&lt;/strong&gt;&amp;nbsp;Monitors resource usage across the cluster to ensure efficient workload distribution.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Memory Usage:&lt;/strong&gt;&amp;nbsp;Tracks memory consumption to prevent out-of-memory errors, especially critical for hosting large models.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Object Store Utilization:&lt;/strong&gt;&amp;nbsp;Observes the usage of Ray’s in-memory object store for efficient data sharing across tasks.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;Operational Metrics&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#operational-metrics&#34;&gt;&lt;/a&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Error Rates:&lt;/strong&gt;&amp;nbsp;Monitors task failure rates to detect and resolve issues quickly.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Node Availability:&lt;/strong&gt;&amp;nbsp;Tracks the health of nodes in the Ray cluster, ensuring reliability.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Queue Length:&lt;/strong&gt;&amp;nbsp;Measures the number of pending tasks, signaling potential bottlenecks in processing.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Setting Up Observability for Ray-Hosted Workloads&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#setting-up-observability-for-ray-hosted-workloads&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Observability in Ray involves using metrics to understand system performance and diagnose issues. By integrating Ray with Prometheus and Grafana, you can gain deep insights into workload behavior.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;Step 1: Setting Up Prometheus Monitoring&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#step-1-setting-up-prometheus-monitoring&#34;&gt;&lt;/a&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Prometheus is an open-source monitoring system that collects metrics from Ray’s endpoints. Follow the guide below to set up Prometheus with Ray on Kubernetes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Install Prometheus with KubeRay:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;# Path: kuberay/&#xA;./install/prometheus/install.sh&#xA;&#xA;# Check the installation&#xA;kubectl get all -n prometheus-system&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;Configure Pod and Service Monitors&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#configure-pod-and-service-monitors&#34;&gt;&lt;/a&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Set up PodMonitor and ServiceMonitor resources to scrape metrics from Ray head and worker nodes:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;apiVersion: monitoring.coreos.com/v1&#xA;kind: PodMonitor&#xA;metadata:&#xA;  name: ray-workers-monitor&#xA;  namespace: prometheus-system&#xA;  labels:&#xA;    release: prometheus&#xA;    ray.io/cluster: rayservice-sample-raycluster-bpkgv&#xA;spec:&#xA;  jobLabel: ray-workers&#xA;  namespaceSelector:&#xA;    matchNames:&#xA;      - raysvc&#xA;  selector:&#xA;    matchLabels:&#xA;      ray.io/node-type: worker&#xA;  podMetricsEndpoints:&#xA;    - port: metrics&#xA;---&#xA;apiVersion: monitoring.coreos.com/v1&#xA;kind: ServiceMonitor&#xA;metadata:&#xA;  name: resume-analyzer-monitor&#xA;  namespace: prometheus-system&#xA;  labels:&#xA;    release: prometheus&#xA;spec:&#xA;  jobLabel: resume-analyzer&#xA;  namespaceSelector:&#xA;    matchNames:&#xA;      - raysvc&#xA;  selector:&#xA;    matchLabels:&#xA;      ray.io/node-type: head&#xA;    endpoints:&#xA;      - port: metrics&#xA;    targetLabels:&#xA;      - ray.io/cluster&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;Step 2: Configure Recording Rules&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#step-2-configure-recording-rules&#34;&gt;&lt;/a&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Recording rules allow you to precompute PromQL expressions for faster queries. For example, calculating the availability of the Ray Global Control Store (GCS):&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;apiVersion: monitoring.coreos.com/v1&#xA;kind: PrometheusRule&#xA;metadata:&#xA;  name: ray-cluster-gcs-rules&#xA;  namespace: prometheus-system&#xA;  labels:&#xA;    release: prometheus&#xA;spec:&#xA;  groups:&#xA;  - name: ray-cluster-main-staging-gcs.rules&#xA;    interval: 30s&#xA;    rules:&#xA;    - record: ray_gcs_availability_30d&#xA;      expr: |&#xA;        (&#xA;          100 * (&#xA;            sum(rate(ray_gcs_update_resource_usage_time_bucket{container=&#34;ray-head&#34;, le=&#34;20.0&#34;}[30d]))&#xA;            /&#xA;            sum(rate(ray_gcs_update_resource_usage_time_count{container=&#34;ray-head&#34;}[30d]))&#xA;          )&#xA;        )&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Explanation of the Expression:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;code&gt;ray_gcs_update_resource_usage_time_bucket&lt;/code&gt;: Tracks the latency of resource usage updates.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;code&gt;ray_gcs_update_resource_usage_time_count&lt;/code&gt;: Counts the total number of updates.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;The expression calculates the percentage of updates completed within a specific latency threshold over the last 30 days.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;Step 3: Set Up Alerting Rules&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#step-3-set-up-alerting-rules&#34;&gt;&lt;/a&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Alert rules help identify issues proactively. For example, detecting missing GCS metrics:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;apiVersion: monitoring.coreos.com/v1&#xA;kind: PrometheusRule&#xA;metadata:&#xA;  name: ray-cluster-gcs-rules&#xA;  namespace: prometheus-system&#xA;  labels:&#xA;    release: prometheus&#xA;spec:&#xA;  groups:&#xA;  - name: ray-cluster-main-staging-gcs.rules&#xA;    interval: 30s&#xA;    rules:&#xA;    - alert: MissingMetricRayGlobalControlStore&#xA;      expr: |&#xA;        absent(ray_gcs_update_resource_usage_time_count)&#xA;      for: 1m&#xA;      labels:&#xA;        severity: warning&#xA;      annotations:&#xA;        summary: &#34;Missing Ray GCS metrics&#34;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Setting Up Grafana Dashboards&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#setting-up-grafana-dashboards&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Grafana provides rich visualizations for metrics. Here’s how to set up dashboards for Ray:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;Step 1: Capture Default Dashboards&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#step-1-capture-default-dashboards&#34;&gt;&lt;/a&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Copy default dashboards from the Ray head pods:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;kubectl cp &amp;lt;head-pod&amp;gt;:/tmp/ray/session_latest/metrics/grafana/dashboards/ ./dashboards&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;Step 2: Access the Grafana Dashboard&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#step-2-access-the-grafana-dashboard&#34;&gt;&lt;/a&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;kubectl port-forward deployment/prometheus-grafana -n prometheus-system 3000:3000&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Default login credentials:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Username:&amp;nbsp;&lt;code&gt;admin&lt;/code&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Password:&amp;nbsp;&lt;code&gt;prom-operator&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Enable Profiling in Ray Serve Pods&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#enable-profiling-in-ray-serve-pods&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Advanced Profiling in Ray Serve Pods The profiling of inference workloads relies on sophisticated techniques for monitoring, debugging, and optimizing performance. This section digs into specific tools, configurations, and scenarios to augment your profiling abilities.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;Memory Profiling&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#memory-profiling&#34;&gt;&lt;/a&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Memory profiling is essential for memory leaks detection and usage optimization. For example, with Memray, trace memory allocations and understand the behavior of inference tasks. To enable memory profiling in Ray Serve pods, update the container’s security context to allow tracing:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;securityContext:&#xA;  capabilities:&#xA;    add:&#xA;    - SYS_PTRACE&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Once configured, Memray can be used to generate memory usage reports, which can help identify high-memory-consuming tasks or bottlenecks in the system.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Example Use Case:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Profiling memory usage during a batch inference task with a large transformer model to optimize batch sizes and reduce memory overhead.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;CPU Profiling&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#cpu-profiling&#34;&gt;&lt;/a&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For CPU profiling, tools like&amp;nbsp;&lt;code&gt;gdb&lt;/code&gt;,&amp;nbsp;&lt;code&gt;lldb&lt;/code&gt;, or&amp;nbsp;&lt;code&gt;py-spy&lt;/code&gt;&amp;nbsp;can be installed within the worker pods to collect detailed CPU usage data. These tools allow you to monitor which functions consume the most CPU time, enabling targeted optimizations.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To set up CPU profiling:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Install&amp;nbsp;&lt;code&gt;gdb&lt;/code&gt;&amp;nbsp;or&amp;nbsp;&lt;code&gt;lldb&lt;/code&gt;&amp;nbsp;in the ray worker pod.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Use profiling scripts or tools to capture CPU usage snapshots during inference tasks.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Example Use Case:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Identifying CPU-bound operations in pre-processing pipelines to offload them to GPUs or optimize their implementation.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;End-to-End Profiling Example&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#end-to-end-profiling-example&#34;&gt;&lt;/a&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;When you integrate memory and CPU profiling, it gives you an overarching view of system performance. To illustrate this better, consider an LLM inference task where you have latency spikes. If you correlate your memory and CPU profiles you will find:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The main culprit behind the memory usage is that huge batches of input data.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;CPU bottlenecks are caused due to inefficiencies in tokenization functions.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you optimize batch sizes and refactor bottleneck functions your performance might increase up to a considerable extent.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Conclusion&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#conclusion&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Using Ray’s distributed LLM workloads with the observability of robust tools will ensure that teams get performance, reliability, and scalability out of these systems. This is a guide to set up and monitor LLM workloads on Ray in a very practical way. Proper observability will help developers and operators find issues early, optimize the use of resources, and further improve the experience users get when using NLP applications.&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#observing-and-monitoring-large-language-model-workloads-with-ray&#34;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;大使帖子，作者：&lt;a href=&#34;https://github.com/swastik959&#34;&gt;Swastik Gour&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;简介&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#introduction&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;GPT-4、PHI2、BERT 和 T5 等大型语言模型 (LLM) 的出现彻底改变了自然语言处理，这些模型支持高端应用程序，包括聊天机器人、推荐系统和分析。然而，法学硕士工作负载的规模和复杂性使它们在保证性能和可靠性方面面临巨大挑战。在这种情况下，使用 Ray 等框架部署工作负载时，监控和可观察性实践就变得非常重要。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Ray 是一个分布式计算框架，它提供了一个强大的平台，可以跨集群有效地扩展 LLM 工作负载。因此，它成为举办、管理和观察法学硕士的绝佳选择。 Ray 的内置功能与 Prometheus 和 Grafana 结合实现关键指标的可观察性，将帮助用户有效地监控它们，优化资源的使用，并快速诊断生产中的问题。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;本文探讨了 Ray 托管的 LLM 工作负载中可观察性的重要性、要监控的关键指标以及使用 Prometheus 和 Grafana 设置可观察性的详细指南。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;为什么选择 Ray for LLM 工作负载？&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#why-ray-for-llm -工作负载&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Ray 专为分布式、可扩展的应用程序而设计，非常适合托管和管理 LLM 工作负载。使 Ray 成为绝佳选择的主要功能包括：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;动态任务调度&lt;/strong&gt;：Ray 的细粒度任务调度可确保高效的资源利用，尤其是在处理大小和复杂性差异很大的 LLM 推理任务时。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;易于集成&lt;/strong&gt;：Ray 与 Hugging Face Transformers 等框架无缝集成，可轻松部署预先训练的 LLM。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;自动扩缩&lt;/strong&gt;：Ray 的集群自动扩缩器可根据工作负载需求动态调整资源，确保成本效益和可扩展性。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;可观测性支持&lt;/strong&gt;：Ray 提供与 Prometheus 兼容的指标端点，简化了分布式系统的监控设置。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这些功能使 Ray 不仅仅是一个计算框架，而且是在现实应用程序中运行、监控和扩展 LLM 的基础工具。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;观察 Ray 托管的 LLM 工作负载的关键指标&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#key-metrics- for-observing-ray-hosted-llm-workloads&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;为了确保 Ray 托管的 LLM 工作负载顺利运行，至关重要的是跟踪一系列性能、资源利用率和运营指标。以下是关键类别：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;性能指标&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#performance-metrics&#34;&gt;&lt;/a&gt;&lt;/ H4&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;任务延迟&lt;/strong&gt;：衡量单个 Ray 任务完成所需的时间，这对于识别推理管道中的瓶颈至关重要。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;吞吐量&lt;/strong&gt;：跟踪每秒完成的任务数，反映系统处理高请求量的能力。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;令牌处理率&lt;/strong&gt;：衡量每秒处理的令牌数量，特别与 GPT-4 等基于转换器的模型相关。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;资源利用率指标&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#resource-utilization-metrics&#34;&gt;&lt;/a &gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;CPU 和 GPU 利用率：&lt;/strong&gt;监控整个集群的资源使用情况，以确保高效的工作负载分配。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;内存使用情况&lt;/strong&gt;：跟踪内存消耗情况以防止出现内存不足错误，这对于托管大型模型尤其重要。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;对象存储利用率：&lt;/strong&gt;观察 Ray 内存中对象存储的使用情况，以实现跨任务的高效数据共享。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;操作指标&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#operational-metrics&#34;&gt;&lt;/a&gt;&lt;/ H4&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;错误率&lt;/strong&gt;：监控任务失败率以快速检测和解决问题。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;节点可用性&lt;/strong&gt;：跟踪 Ray 集群中节点的运行状况，确保可靠性。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;队列长度&lt;/strong&gt;：衡量待处理任务的数量，表明处理中的潜在瓶颈。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;为 Ray 托管工作负载设置可观测性&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#setting-up-observability -for-ray-hosted-workloads&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;Ray 中的可观察性涉及使用指标来了解系统性能和诊断问题。通过将 Ray 与 Prometheus 和 Grafana 集成，您可以深入了解工作负载行为。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;第 1 步：设置 Prometheus 监控&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#step-1-setting-上普罗米修斯监控&#34;&gt;&lt;/a&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Prometheus 是一个开源监控系统，可从 Ray 的端点收集指标。请按照以下指南在 Kubernetes 上使用 Ray 设置 Prometheus。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;使用 KubeRay 安装 Prometheus：&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;# 路径：kuberay/&#xA;./安装/普罗米修斯/install.sh&#xA;&#xA;# 检查安装情况&#xA;库贝克格t所有-n Prometheus -System &lt;/code&gt; &lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class =“ wp-block-heading”&gt;配置POD和服务监视器&lt;A href =“ https://github.com/swastik959/blogs/tree/tree/main/main/ray-observialice#configure-pod-pod-pod-and-service-service--service--service--service--service-监视器“&gt; &lt;/a&gt; &lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;设置podmonitor和ServiceMonitor资源以从射线头和工人节点刮擦指标：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;在&#xA;KIND：PODMONITOR&#xA;元数据：&#xA;  名称：射线工人监测器&#xA;  名称空间：Prometheus-System&#xA;  标签：&#xA;    发行：普罗米修斯&#xA;    Ray.io/cluster：Rayservice-Sample-RayCluster-BPKGV&#xA;规格：&#xA;  玻璃旗：射线工人&#xA;  namespaceselector：&#xA;    匹配名称：&#xA;      -raysvc&#xA;  选择器：&#xA;    MatchLabels：&#xA;      ray.io/node-type：工人&#xA;  podmetricsendpoints：&#xA;     - 端口：指标&#xA;---&#xA;apiversion：Menualing.coreos.com/V1&#xA;KIND：ServiceMonitor&#xA;元数据：&#xA;  姓名：简历 - 分析仪图&#xA;  名称空间：Prometheus-System&#xA;  标签：&#xA;    发行：普罗米修斯&#xA;规格：&#xA;  玻璃标签：简历 - 分析仪&#xA;  namespaceselector：&#xA;    匹配名称：&#xA;      -raysvc&#xA;  选择器：&#xA;    MatchLabels：&#xA;      ray.io/node-type：头&#xA;    端点：&#xA;       - 端口：指标&#xA;    目标标签：&#xA;      -Ray.io/cluster&lt;/Code&gt; &lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class =“ wp-block-heading”&gt;步骤2：配置录制规则&lt;a href =“ https://github.com/swastik959/blogs/tree/tree/main/main/ray-observiality#step-2-configure-configure-recorting -rules“&gt; &lt;/a&gt; &lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;记录规则允许您预先计算更快查询的PROMQL表达式。例如，计算射线全局控制存储（GCS）的可用性：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;在&#xA;善良：普罗米修&#xA;元数据：&#xA;  名称：Ray-Cluster-GCS规则&#xA;  名称空间：Prometheus-System&#xA;  标签：&#xA;    发行：普罗米修斯&#xA;规格：&#xA;  组：&#xA;   - 名称：Ray-Cluster-Main stipang-gcs.rules&#xA;    间隔：30年代&#xA;    规则：&#xA;     - 记录：ray_gcs_availability_30d&#xA;      expr：|&#xA;        （（&#xA;          100 *（（&#xA;            sum（速率（ray_gcs_update_resource_usage_time_bucket {container =“ ray-head”，le =“ 20.0”} [30d]）））））&#xA;            /&#xA;            sum（rate（ray_gcs_update_resource_usage_time_count {container =“ ray-head”} [30d]）））））&#xA;          ）&#xA;        ）&lt;/code&gt; &lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt; &lt;strong&gt;表达式的解释：&lt;/strong&gt; &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class =“ wp-block-list”&gt;&#xA;&lt;li&gt; &lt;code&gt; ray_gcs_update_resource_usage_time_bucket &lt;/code&gt;：跟踪资源用法更新的延迟。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; &lt;code&gt; ray_gcs_update_resource_usage_time_count &lt;/code&gt;：计数更新的总数。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;表达式计算过去30天内在特定潜伏阈值中完成的更新百分比。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class =“ wp-block-heading”&gt;步骤3：设置警报规则&lt;a href =“ https://github.com/swastik959/blogs/tree/tree/main/main/ray-observiality#step-step-3-set-set-set-set-set--set--set--set--set--上升符号“&gt; &lt;/a&gt; &lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;警报规则有助于主动识别问题。例如，检测缺失的GCS指标：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;在&#xA;善良：普罗米修&#xA;元数据：&#xA;  名称：射线群 - GCS规则&#xA;  名称空间：Prometheus-System&#xA;  标签：&#xA;    发行：普罗米修斯&#xA;规格：&#xA;  组：&#xA;   - 名称：Ray-Cluster-Main stipang-gcs.rules&#xA;    间隔：30年代&#xA;    规则：&#xA;     - 警报：失踪metrricRayGlobalControlStore&#xA;      expr：|&#xA;        缺席（ray_gcs_update_resource_usage_time_count）&#xA;      对于：1m&#xA;      标签：&#xA;        严重性：警告&#xA;      注释：&#xA;        摘要：“缺少射线GCS指标” &lt;/code&gt; &lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class =“ wp-block-heading”&gt;设置grafana仪表板&lt;a href =“ https://github.com/swastik959/blogs/tree/tree/main/main/ray-observiality#settingtingtingtingtingtingtingtingting-prafana-dashboards”&gt; &lt;/a&gt; &lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt; Grafana为指标提供了丰富的可视化。这是为Ray设置仪表板的方法：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class =“ wp-block-heading”&gt;步骤1：捕获默认仪表板&lt;a href =“ https://github.com/swastik959/blogs/tree/tree/main/main/ray-observiality/Ray-Observiality#step-1-capture-default-default -dashboards“&gt; &lt;/a&gt; &lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;复制射线头舱的默认仪表板：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class =“ wp-block-code”&gt; &lt;code class =“”&gt; kubectl cp &lt;head-pod&gt;：/tmp/ray/session_latest/metrics/grafana/dashboards/./ dashboards/./ dashboards &lt;/code&gt; &lt;/pre &gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class =“ wp-block-heading”&gt;步骤2：访问grafana仪表板&lt;a href =“ https://github.com/swastik959/blogs/tree/tree/main/main/ray-observibility#step-step-step-step-step-2-yccess-access-access-access-access-access-access-access-access-access-access-access-access-access-access-access-access-access-access-access-access-access-access-access-access-accesst- grafana-dashboard”&gt; &lt;/a&gt; &lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class =“ wp-block-code”&gt; &lt;code class =“”&gt; kubectl port-ford部署/prometheus-grafana -n Prometheus-System 3000：3000 &lt;/code&gt; &lt;/pre&gt; &lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;默认登录凭据：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class =“ wp-block-list”&gt;&#xA;&lt;li&gt;用户名：&lt;code&gt; admin &lt;/code&gt; &lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;密码：&lt;code&gt; Prom-Operator &lt;/code&gt; &lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class =“ wp-block-heading”&gt;在射线中启用pods pods &lt;a href =“ https://github.com/swastik959/blogs/blogs/tree/tree/main/main/ray-observibility#enable-profling-profling-in-ray-ray -serve-pods“&gt; &lt;/a&gt; &lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;射线中的高级分析pods推理工作负载的分析依赖于用于监视，调试和优化性能的复杂技术。本节挖掘特定的工具，配置和方案以增强您的分析能力。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;在H4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;内存分析对于内存泄漏检测和使用优化至关重要。例如，使用memray，跟踪内存分配并了解推理任务的行为。要在射线中启用内存分析，请更新容器的安全上下文以允许跟踪：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class =“ wp-block-code”&gt; &lt;code class =“”&gt; SecurityContext：&#xA;  功能：&#xA;    添加：&#xA;    -SYS_PTRACE &lt;/code&gt; &lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;一旦配置，MEMRAY可用于生成内存使用报告，这可以帮助识别系统中的高音耗费任务或瓶颈。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt; &lt;strong&gt;示例用例：&lt;/strong&gt; &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class =“ wp-block-list”&gt;&#xA;&lt;li&gt;使用大型变压器模型在批处理推理任务期间进行分析内存使用，以优化批处理大小并减少内存开销。&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;h4 class=&#34;wp-block-heading&#34;&gt;CPU 分析&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#cpu-profiling&#34;&gt;&lt;/a&gt;&lt;/ H4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;对于 CPU 分析，可以在工作 Pod 中安装 &lt;code&gt;gdb&lt;/code&gt;、&lt;code&gt;lldb&lt;/code&gt; 或 &lt;code&gt;py-spy&lt;/code&gt; 等工具来收集详细的 CPU 使用情况数据。这些工具允许您监控哪些函数消耗最多的 CPU 时间，从而实现有针对性的优化。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;要设置 CPU 分析：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;在 ray Worker Pod 中安装 &lt;code&gt;gdb&lt;/code&gt; 或 &lt;code&gt;lldb&lt;/code&gt;。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;使用分析脚本或工具在推理任务期间捕获 CPU 使用情况快照。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;示例用例：&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;识别预处理管道中受 CPU 限制的操作，将其卸载到 GPU 或优化其实现。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;端到端分析示例&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#end-to-end-分析示例&#34;&gt;&lt;/a&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;当您集成内存和 CPU 分析时，它可以让您全面了解系统性能。为了更好地说明这一点，请考虑一个存在延迟峰值的 LLM 推理任务。如果您将内存和 CPU 配置文件关联起来，您会发现：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;内存使用背后的罪魁祸首是大量的输入数据。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;CPU 瓶颈是由于标记化函数效率低下造成的。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您优化批量大小并重构瓶颈函数，您的性能可能会大幅提高。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;结论&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ray-observability#conclusion&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;使用 Ray 的分布式 LLM 工作负载和强大工具的可观察性将确保团队从这些系统中获得性能、可靠性和可扩展性。这是以非常实用的方式在 Ray 上设置和监控 LLM 工作负载的指南。适当的可观察性将有助于开发者和运维者尽早发现问题，优化资源的使用，进一步改善用户在使用 NLP 应用时的体验。&lt;a href=&#34;https://github.com/swastik959/Blogs/tree/main/ ray-observability#observing-and-monitoring-large-language-model-workloads-with-ray&#34;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Wed, 15 Jan 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Migrating from DIY ELK to a full SaaS platform】从 DIY ELK 迁移到完整的 SaaS 平台</title>
      <link>https://www.cncf.io/blog/2025/01/24/migrating-from-diy-elk-to-a-full-saas-platform/</link>
      <description>【&lt;p&gt;&lt;em&gt;Member post originally published on the &lt;a href=&#34;https://logz.io/blog/migrating-from-diy-elk-to-a-full-saas-platform/?utm_medium=referral&amp;amp;utm_source=cncf&#34;&gt;Logz.io blog&lt;/a&gt; by Jade Lassery&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Managing modern systems requires a constant balance between operational efficiency and innovation; going a little further, maintaining seamless operations and delivering exceptional customer experiences increasingly depend on ensuring robust observability.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For years, the ELK stack (Elasticsearch, Logstash, Kibana) has been the go-to solution for many organizations for log management and observability, offering flexibility control and an open source approach. However, as organizations scale and their data demands grow, maintaining ELK often becomes a real challenge, requiring more resources, generating higher costs and driving increasing complexity.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Shifting to a full SaaS observability platform — purpose-built solutions designed to simplify operations, enhance insights and scale effortlessly — offers a strategic alternative. The shift allows businesses to&amp;nbsp;&lt;a href=&#34;https://logz.io/case-studies/eliminating-elk-downtime-and-improving-productivity/?utm_medium=referral&amp;amp;utm_source=TNS&amp;amp;utm_campaign=tns_spon_4&amp;amp;utm_content=case-study&#34;&gt;offload the operational challenges of DIY ELK&lt;/a&gt;, enabling teams to focus on delivering value instead of maintaining infrastructure.&amp;nbsp; It’s not just about swapping tools, it’s about transforming the way you approach observability to support long-term business success by aggregating innovation and managed capabilities.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Common Issues Teams Face with DIY ELK&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To begin understanding the migration process, it’s important to understand the common issues teams face with ELK that cause them to look at migrating in the first place.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As organizations expand, their data requirements become more demanding. Scaling a DIY ELK stack to handle increasing log volumes and infrastructure requirements can lead to performance issues, data loss, downtime and creating a constant need for manual intervention. SaaS platforms, on the other hand, manage all the hurdles for you, automatically scaling to accommodate growing data levels, reducing operational complexity and ensuring near-seamless performance.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In addition, operating and maintaining a DIY ELK stack also means handling constant updates, security patches and rebalancing of infrastructure — tasks that consume time and resources. SaaS platforms handle these tasks in the background, allowing teams to focus on strategic work. Moreover, while DIY ELK might seem cost-effective initially, hidden expenses for scaling, maintenance and management can add up. SaaS platforms offer&amp;nbsp;&lt;a href=&#34;https://logz.io/solutions/reduce-observability-costs/&#34;&gt;predictable observability pricing, simplifying budget management&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;SaaS Observability Platform Benefits Over DIY ELK&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;A significant benefit of moving to a SaaS platform is access to advanced features that go beyond traditional log management. Many SaaS observability platforms provide&amp;nbsp;&lt;a href=&#34;https://logz.io/platform/?utm_medium=referral&amp;amp;utm_source=TNS&amp;amp;utm_campaign=tns_spon_4&amp;amp;utm_content=platform&amp;amp;utm_term=unified&#34;&gt;integrated solutions for logs, metrics and traces&lt;/a&gt;&amp;nbsp;in one unified interface. These platforms now also frequently leverage&amp;nbsp;&lt;a href=&#34;https://logz.io/platform/features/observability-iq/?utm_medium=referral&amp;amp;utm_source=TNS&amp;amp;utm_campaign=tns_spon_4&amp;amp;utm_content=feature&amp;amp;utm_term=IQ&#34;&gt;AI-powered observability tools&lt;/a&gt;&amp;nbsp;for anomaly detection and root cause analysis (RCA) to quickly surface issues —- reducing time spent troubleshooting and enabling proactive incident management.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Beyond these operational benefits, SaaS platforms also offer enhanced security and compliance features that can be difficult and costly to implement with a DIY stack. With built-in encryption, access controls and industry certifications (such as SOC 2, GDPR compliance, etc), SaaS providers help ensure that your data remains secure and meets regulatory standards, without requiring additional overhead from your internal teams.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;When is it Time to Migrate from DIY ELK?&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;There are many factors to consider for when it might be the correct time to migrate from a DIY ELK stack to a SaaS platform. Here are some things to watch out for:&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;📈&amp;nbsp;&lt;a href=&#34;https://logz.io/case-studies/how-ziprecruiter-boosted-sre-productivity-with-logz-io/?utm_medium=referral&amp;amp;utm_source=TNS&amp;amp;utm_campaign=tns_spon_4&amp;amp;utm_content=case-study&#34;&gt;&lt;strong&gt;Data growth is overwhelming&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;:&lt;/strong&gt;&amp;nbsp;Your ELK stack struggles to keep up with increasing data volumes, leading to slow query times and infrastructure strain.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;🤯&amp;nbsp;&lt;a href=&#34;https://logz.io/case-studies/eliminating-elk-downtime-and-improving-productivity/&#34;&gt;&lt;strong&gt;Operational complexity is draining resources&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;:&lt;/strong&gt;&amp;nbsp;Managing and maintaining the stack is consuming your DevOps team’s time, leaving little room for innovation.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;💰&amp;nbsp;&lt;a href=&#34;https://logz.io/case-studies/essential-observability-from-logz-io-helps-monoova-keep-the-money-flowing/?utm_medium=referral&amp;amp;utm_source=TNS&amp;amp;utm_campaign=tns_spon_4&amp;amp;utm_content=case-study&#34;&gt;&lt;strong&gt;Costs are escalating or unpredictable&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;:&lt;/strong&gt;&amp;nbsp;Infrastructure, storage and operational expenses are becoming unpredictable and hard to justify.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;⚙️&amp;nbsp;&lt;a href=&#34;https://logz.io/case-studies/egress-partners-with-logz-io-for-easy-cost-effective-observability/&#34;&gt;&lt;strong&gt;Unified and advanced observability is needed&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;:&lt;/strong&gt;&amp;nbsp;Siloed tools for logs, metrics and traces make it challenging to diagnose and resolve issues quickly.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;🛡️&amp;nbsp;&lt;a href=&#34;https://logz.io/case-studies/jacada-reduce-security-risks/&#34;&gt;&lt;strong&gt;Security or compliance is a concern&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;:&lt;/strong&gt;&amp;nbsp;You need advanced security features or compliance certifications that are difficult to implement in a DIY stack.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Once you’ve identified that your stack is no longer meeting your needs — whether due to scaling issues, rising costs, or operational inefficiencies — the next step is to start planning your migration to a SaaS platform. Making this shift doesn’t have to be overwhelming, but it does require careful consideration and a strategic approach.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Here are the key steps that you can use as a baseline to ensure a smooth transition:&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt;: &lt;strong&gt;Evaluate your needs:&lt;/strong&gt;&amp;nbsp;Understand what you need from your observability stack. Are you looking for better scalability, advanced features, simplified management? What else?&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;2&lt;/strong&gt;: &lt;strong&gt;Choose the right platform:&amp;nbsp;&lt;/strong&gt;Not all SaaS platforms are built equal. Here’s a tip: look for one that offers:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Native integrations with your current tools such as Logstash, Beats or OpenTelemetry.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Unified support for logs, metrics, traces and extra visualizations.&amp;nbsp;&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;AI-powered insights and automation.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://logz.io/from-diy-elk-to-effortless-observability/?utm_medium=referral&amp;amp;utm_source=TNS&amp;amp;utm_campaign=tns_spon_4&amp;amp;utm_content=lp&amp;amp;utm_term=elk&#34;&gt;Platforms like Logz.io&lt;/a&gt;, for example, support the same ingestion methods as ELK, so you can reuse your existing configurations with minimal changes, besides providing advanced capabilities like root cause analysis to help businesses proactively manage their systems with minimal effort.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;3&lt;/strong&gt;: &lt;strong&gt;Plan and test:&amp;nbsp;&lt;/strong&gt;Begin by setting up the SaaS platform alongside your existing ELK stack. Test data ingestion using a subset of your logs or metrics to validate compatibility and performance.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;4&lt;/strong&gt;: &lt;strong&gt;Migrate gradually:&amp;nbsp;&lt;/strong&gt;Move workloads incrementally, starting with non-critical systems. Once the process is stable and workflows are optimized, transition critical systems.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;5&lt;/strong&gt;: &lt;strong&gt;Recreate dashboards and alerts:&amp;nbsp;&lt;/strong&gt;Export dashboards and alerts from ELK and import them into the new managed platform. Take advantage of pre-built templates and advanced alerting options to refine your observability strategy.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;6&lt;/strong&gt;: &lt;strong&gt;Optimize and train:&lt;/strong&gt;&amp;nbsp;Ensure your team is trained on the new platform and continue optimizing configurations to align with your needs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;7&lt;/strong&gt;: &lt;strong&gt;Decommission DIY ELK:&amp;nbsp;&lt;/strong&gt;Once all systems are successfully migrated, phase out your ELK infrastructure, archiving historical data in an external storage if needed.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Unlocking Long Term Observability Value&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://logz.io/from-diy-elk-to-effortless-observability/?utm_medium=referral&amp;amp;utm_source=TNS&amp;amp;utm_campaign=tns_spon_4&amp;amp;utm_content=lp&amp;amp;utm_term=elk&#34;&gt;Migrating to a SaaS observability platform&lt;/a&gt;&amp;nbsp;is more than just a technical upgrade or getting everything up and running. It’s a strategic decision that drives long-term value. By offloading operational complexity, businesses can focus on innovation, improve system reliability and enhance customer experiences.Organizations that make this shift often find they’re not just solving operational headaches, they’re positioning themselves for&amp;nbsp;&lt;a href=&#34;https://logz.io/case-studies/rubrik-case-study/?utm_medium=referral&amp;amp;utm_source=TNS&amp;amp;utm_campaign=tns_spon_4&amp;amp;utm_content=case-study&#34;&gt;scalable, data-driven growth&lt;/a&gt;. It’s a step toward making observability a seamless enabler of success, rather than a persistent challenge.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt; &lt;em&gt;成员帖子最初发表在&lt;a href =“ https://logz.io/blog/migrating-from-diy--diy-elk-to-a-a-saas-platform/?utm_medium = referral＆utm_source = = cncf“&gt; logz.io博客&lt;/a&gt; jade lassery &lt;/em&gt; &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;管理现代系统需要在运营效率和创新之间持续平衡；进一步发展，保持无缝操作并越来越多地依赖于确保可观察到的可观察性。&lt;/p&gt; &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;多年来，Elk Stack（Elasticsearch，Logstash，Kibana）一直是许多组织进行日志管理和可观察性的首选解决方案，提供灵活性控制和开源方法。但是，随着组织规模及其数据需求的增长，维持麋鹿通常会成为一个真正的挑战，需要更多的资源，产生更高的成本并推动增加复杂性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;转移到一个完整的SaaS可观察性平台（旨在简化操作，增强见解和毫不费力地扩展）的专用解决方案 - 提供了战略替代方案。转变允许企业到&lt;a href =“ https://logz.io/case-studies/eliminating-elk-downtime-and-time-and-improving-productivity/?utm_medium = referral＆utm_source = tns＆utm_campaign DIY Elk的操作挑战&lt;/a&gt;，使团队能够专注于提供价值而不是维持基础架构。  这不仅仅是交换工具，还包括改变观察性通过汇总创新和托管功能来支持长期业务成功的方式。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;H2 class =“ WP-block-heading”&gt;常见问题团队与DIY Elk &lt;/h2&gt;面对&#xA;&#xA;&#xA;&#xA;&lt;p&gt;要开始理解迁移过程，重要的是要了解团队与麋鹿面临的常见问题，这使他们首先要考虑迁移。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;随着组织的扩展，他们的数据要求变得越来越苛刻。缩放DIY麋鹿堆栈以处理增加的日志量和基础架构要求，可能会导致性能问题，数据丢失，停机时间以及对手动干预的持续需求。另一方面，SaaS平台为您管理所有障碍，自动扩展以适应不断增长的数据水平，降低运营复杂性并确保近乎无缝的性能。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;此外，操作和维护DIY麋鹿堆栈还意味着处理恒定更新，安全补丁和基础架构的重新平衡 - 消耗时间和资源的任务。 SaaS平台在后台处理这些任务，使团队可以专注于战略工作。此外，尽管最初，DIY麋鹿似乎成本效益，但用于扩展，维护和管理的隐藏费用可以加起来。 SaaS平台提供&lt;a href =“ https://logz.io/solutions/reduce-observability-costs/”&gt;可预测的可观察性定价，简化预算管理&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class =“ wp-block头”&gt; SaaS可观察性平台利益比DIY麋鹿&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;转到SaaS平台的一个重大好处是访问超出传统日志管理的高级功能。许多SaaS可观察性平台提供&lt;a href =“ https://logz.io/platform/?utm_medium = referral＆utm_source = tns＆utm_campaign = tns_spon_spon_4&amp;utm_contm_content = content = content = plattort = platm_term = 。现在，这些平台也经常利用&lt;a href =“ https://logz.io/platform/features/observability-iq/?utm_medium = referral＆utm_source = tns＆utm_campaigh = tns = tns_campaign = tns_spon_spon_spon_sspon_4＆utm_content = feature = feature permitiality permer ustemitiely ustemitiely utmmiitient对于异常检测和根本原因分析（RCA），可以快速表面问题 - 减少对积极的事件进行故障排除和实现主动事件管理的时间。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;除了这些操作福利之外，SaaS平台还提供了增强的安全性和合规性功能，而使用DIY堆栈可能很难实现。通过内置加密，访问控制和行业认证（例如SOC 2，GDPR合规性等），SaaS提供商有助于确保您的数据保持安全并符合监管标准，而无需内部团队的额外开销。&lt;/p&gt; &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class =“ wp-block头”&gt;什么时候该从diy麋鹿迁移？&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;有很多因素需要考虑何时可能是从DIY麋鹿堆栈迁移到SaaS平台的正确时间。这是一些要注意的事情：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;📈&lt;a href =“ https://logz.io/case-studies/how-ziprecruiter-boosted-sre-productivity-with-with-logz-io/?utm_medium=referral&amp;utm_soutm_sourpe = tns &gt; &lt;strong&gt;数据增长压倒性&lt;/strong&gt; &lt;/a&gt; &lt;strong&gt;：&lt;/strong&gt;您的麋鹿堆栈难以跟上数据量的增加，从而导致查询时间和基础设施较慢。&lt;/p&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;🤯&lt;a href =“ https://logz.io/case-studies/eliminating-elk-downtime-and-roductivity/”&gt; &lt;strong&gt;操作复杂性正在排出资源&lt;/strong&gt; &lt;/a &gt; &lt;strong&gt;：&lt;/strong&gt;管理和维护堆栈正在消耗您的DevOps团队的时间，几乎没有创新的空间。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;💰&lt;a href =“ https://logz.io/case-studies/essential-observiability-from-logz-io-helps-monoova-keep--keep-the-money-flowing/?utm_medium = referral&amp;utm_sourm_source = tns = tns&amp;utm_campaign= tns_spon_4＆utm_content =案例策划“&gt; &lt;strong&gt;成本正在上升或无法预测&lt;/strong&gt; &lt;/a&gt; &lt;gront&gt;：&lt;/strong&gt;基础架构，存储和运营费用变得无法预测，难以合理，并且很难合理。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;⚙️&lt;a href =“ https://logz.io/case-studies/egress-partners-with-logz-io-for-easy-cost-cost-effective-observability/”&gt; &lt;strong&gt;需要&lt;/strong&gt; &lt;/a&gt; &lt;strong&gt;：&lt;/strong&gt;用于日志，指标和痕迹的孤立工具使诊断和解决问题的挑战q很快。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;🛡️ &lt;a href=&#34;https://logz.io/case-studies/jacada-reduce-security-risks/&#34;&gt;&lt;strong&gt;安全或合规性是一个问题&lt;/strong&gt;&lt;/a&gt;&lt;strong &gt;：&lt;/strong&gt; 您需要高级安全功能或合规性认证，而这些功能很难在 DIY 堆栈中实现。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;一旦您发现您的堆栈不再满足您的需求（无论是由于扩展问题、成本上升还是运营效率低下），下一步就是开始规划向 SaaS 平台的迁移。做出这种转变不一定要势不可挡，但确实需要仔细考虑和战略方法。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;以下是您可以用作确保平稳过渡的基准的关键步骤：&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt;：&lt;strong&gt;评估您的需求&lt;/strong&gt;：从可观测性堆栈中了解您需要什么。您是否正在寻找更好的可扩展性、高级功能、简化的管理？还有什么？&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;2&lt;/strong&gt;：&lt;strong&gt;选择正确的平台：&lt;/strong&gt;并非所有 SaaS 平台都是一样的。这里有一个提示：寻找一个提供以下功能的产品：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;与您当前的工具（例如 Logstash、Beats 或 OpenTelemetry）进行原生集成。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;对日志、指标、跟踪和额外可视化的统一支持。  &lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;人工智能驱动的洞察和自动化。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://logz.io/from-diy-elk-to-effortless-observability/?utm_medium=referral&amp;utm_source=TNS&amp;utm_campaign=tns_spon_4&amp;utm_content=lp&amp;utm_term=elk&#34;&gt;Logz.io 等平台&lt;/a &gt; 例如，支持与 ELK 相同的摄取方法，因此您可以以最少的成本重用现有配置除了提供根本原因分析等高级功能之外，还可以帮助企业以最少的努力主动管理其系统。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;3&lt;/strong&gt;：&lt;strong&gt;计划和测试：&lt;/strong&gt;首先在现有 ELK 堆栈旁边设置 SaaS 平台。使用日志或指标的子集测试数据提取，以验证兼容性和性能。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;4&lt;/strong&gt;：&lt;strong&gt;逐步迁移：&lt;/strong&gt;从非关键系统开始逐步迁移工作负载。一旦流程稳定且工作流程得到优化，即可过渡关键系统。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;5&lt;/strong&gt;：&lt;strong&gt;重新创建仪表板和警报：&lt;/strong&gt;从 ELK 导出仪表板和警报并将其导入新的托管平台。利用预构建的模板和高级警报选项来完善您的可观察性策略。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;6&lt;/strong&gt;：&lt;strong&gt;优化和培训&lt;/strong&gt;：确保您的团队接受新平台的培训，并继续优化配置以满足您的需求。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;7&lt;/strong&gt;：&lt;strong&gt;退役 DIY ELK：&lt;/strong&gt;所有系统成功迁移后，逐步淘汰您的 ELK 基础设施，如果需要，在外部存储中搅动历史数据。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class =“ wp-block头”&gt;解锁长期可观察性值&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;在A&gt;不仅仅是技术升级，或者使所有内容启动并运行。这是一个促进长期价值的战略决定。通过卸载运营复杂性，企业可以专注于创新，提高系统可靠性并增强客户体验。使这种转变的组织经常发现它们不仅仅是解决操作头痛，还为&lt;a href =&#39;https：// ship to https =&#39;https：// logz.io/case-studies/rubrik-case-study/?utm_medium = referral＆utm_source = tns＆utm_campaign=tns_spon_spon_4&amp;utm_content = case-study&#34;&gt; scalable &#34;&gt; scalable，数据驱动的，数据驱动的增长&lt;/a&gt;。这是使观察性成为成功的无缝推动者的一步，而不是持续的挑战。&lt;/p&gt;&#xA;&#xA;在&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;在&#xA;&lt;/div&gt;</description>
      <pubDate>Thu, 23 Jan 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【OpenTelemetry for generative AI】opentelemetry用于生成AI</title>
      <link>https://www.cncf.io/blog/2025/01/20/opentelemetry-for-generative-ai/</link>
      <description>【&lt;p&gt;&lt;em&gt;Project post originally published on the &lt;a href=&#34;https://opentelemetry.io/blog/2024/otel-generative-ai/&#34;&gt;OpenTelemetry blog&lt;/a&gt; by &lt;a href=&#34;https://github.com/drewby&#34;&gt;Drew Robbins&lt;/a&gt; (Microsoft), &lt;a href=&#34;https://github.com/lmolkova&#34;&gt;Liudmila Molkova&lt;/a&gt; (Microsoft)&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As organizations increasingly adopt Large Language Models (LLMs) and other generative AI technologies, ensuring reliable performance, efficiency, and safety is essential to meet user expectations, optimize resource costs, and safeguard against unintended outputs. Effective observability for AI operations, behaviors, and outcomes can help meet these goals. OpenTelemetry is being enhanced to support these needs specifically for generative AI.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Two primary assets are in development to make this possible:&amp;nbsp;&lt;strong&gt;Semantic Conventions&lt;/strong&gt;&amp;nbsp;and&amp;nbsp;&lt;strong&gt;Instrumentation Libraries&lt;/strong&gt;. The first instrumentation library targets the&amp;nbsp;&lt;a href=&#34;https://pypi.org/project/openai/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;OpenAI Python API library&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://opentelemetry.io/docs/concepts/semantic-conventions/&#34;&gt;&lt;strong&gt;Semantic Conventions&lt;/strong&gt;&lt;/a&gt;&amp;nbsp;establish standardized guidelines for how telemetry data is structured and collected across platforms, defining inputs, outputs, and operational details. For generative AI, these conventions streamline monitoring, troubleshooting, and optimizing AI models by standardizing attributes such as model parameters, response metadata, and token usage. This consistency supports better observability across tools, environments, and APIs, helping organizations track performance, cost, and safety with ease.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The&amp;nbsp;&lt;a href=&#34;https://opentelemetry.io/docs/specs/otel/overview/#instrumentation-libraries&#34;&gt;&lt;strong&gt;Instrumentation Library&lt;/strong&gt;&lt;/a&gt;&amp;nbsp;is being developed within the&amp;nbsp;&lt;a href=&#34;https://github.com/open-telemetry/opentelemetry-python-contrib&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;OpenTelemetry Python Contrib&lt;/a&gt;&amp;nbsp;under&amp;nbsp;&lt;a href=&#34;https://github.com/open-telemetry/opentelemetry-python-contrib/tree/main/instrumentation-genai&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;instrumentation-genai&lt;/a&gt;&amp;nbsp;project to automate telemetry collection for generative AI applications. The first release is a Python library for instrumenting OpenAI client calls. This library captures spans and events, gathering essential data like model inputs, response metadata, and token usage in a structured format.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;key-signals-for-generative-ai&#34;&gt;Key Signals for Generative AI&lt;a href=&#34;https://opentelemetry.io/blog/2024/otel-generative-ai/#key-signals-for-generative-ai&#34;&gt;&lt;/a&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The&amp;nbsp;&lt;a href=&#34;https://opentelemetry.io/docs/specs/semconv/gen-ai/&#34;&gt;Semantic Conventions for Generative AI&lt;/a&gt;&amp;nbsp;focus on capturing insights into AI model behavior through three primary signals:&amp;nbsp;&lt;a href=&#34;https://opentelemetry.io/docs/concepts/signals/traces/&#34;&gt;Traces&lt;/a&gt;,&amp;nbsp;&lt;a href=&#34;https://opentelemetry.io/docs/concepts/signals/metrics/&#34;&gt;Metrics&lt;/a&gt;, and&amp;nbsp;&lt;a href=&#34;https://opentelemetry.io/docs/specs/otel/logs/event-api/&#34;&gt;Events&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Together, these signals provide a comprehensive monitoring framework, enabling better cost management, performance tuning, and request tracing.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;traces-tracing-model-interactions&#34;&gt;Traces: Tracing Model Interactions&lt;a href=&#34;https://opentelemetry.io/blog/2024/otel-generative-ai/#traces-tracing-model-interactions&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Traces track each model interaction’s lifecycle, covering input parameters (for example, temperature, top_p) and response details like token count or errors. They provide visibility into each request, aiding in identifying bottlenecks and analyzing the impact of settings on model output.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;metrics-monitoring-usage-and-performance&#34;&gt;Metrics: Monitoring Usage and Performance&lt;a href=&#34;https://opentelemetry.io/blog/2024/otel-generative-ai/#metrics-monitoring-usage-and-performance&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Metrics aggregate high-level indicators like request volume, latency, and token counts, essential for managing costs and performance. This data is particularly critical for API-dependent AI applications with rate limits and cost considerations.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;events-capturing-detailed-interactions&#34;&gt;Events: Capturing Detailed Interactions&lt;a href=&#34;https://opentelemetry.io/blog/2024/otel-generative-ai/#events-capturing-detailed-interactions&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Events log detailed moments during model execution, such as user prompts and model responses, providing a granular view of model interactions. These insights are invaluable for debugging and optimizing AI applications where unexpected behaviors may arise.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;Note&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Note that we decided to use&amp;nbsp;&lt;a href=&#34;https://opentelemetry.io/docs/specs/otel/logs/api/#emit-an-event&#34;&gt;events emitted&lt;/a&gt;&amp;nbsp;with the&amp;nbsp;&lt;a href=&#34;https://opentelemetry.io/docs/specs/otel/logs/api/&#34;&gt;Logs API&lt;/a&gt;&amp;nbsp;specification in the Semantic Conventions for Generative AI. Events allows for us to define specific&amp;nbsp;&lt;a href=&#34;https://opentelemetry.io/docs/specs/semconv/general/events/&#34;&gt;semantic conventions&lt;/a&gt;&amp;nbsp;for the user prompts and model responses that we capture. This addition to the API is in development and considered unstable.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;extending-observability-with-vendor-specific-attributes&#34;&gt;Extending Observability with Vendor-Specific Attributes&lt;a href=&#34;https://opentelemetry.io/blog/2024/otel-generative-ai/#extending-observability-with-vendor-specific-attributes&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The Semantic Conventions also define vendor-specific attributes for platforms like OpenAI and Azure Inference API, ensuring telemetry captures both general and provider-specific details. This added flexibility supports multi-platform monitoring and in-depth insights.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;building-the-python-instrumentation-library-for-openai&#34;&gt;Building the Python Instrumentation Library for OpenAI&lt;a href=&#34;https://opentelemetry.io/blog/2024/otel-generative-ai/#building-the-python-instrumentation-library-for-openai&#34;&gt;&lt;/a&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This Python-based library for OpenTelemetry captures key telemetry signals for OpenAI models, providing developers with an out-of-the-box observability solution tailored to AI workloads. The library,&amp;nbsp;&lt;a href=&#34;https://github.com/open-telemetry/opentelemetry-python-contrib/tree/opentelemetry-instrumentation-openai-v2%3D%3D2.0b0/instrumentation-genai/opentelemetry-instrumentation-openai-v2&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;hosted within the OpenTelemetry Python Contrib repository&lt;/a&gt;, automatically collects telemetry from OpenAI model interactions, including request and response metadata and token usage.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As generative AI applications grow, additional instrumentation libraries for other languages will follow, extending OpenTelemetry support across more tools and environments. The current library’s focus on OpenAI highlights its popularity and demand within AI development, making it a valuable initial implementation.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;example-usage&#34;&gt;Example Usage&lt;a href=&#34;https://opentelemetry.io/blog/2024/otel-generative-ai/#example-usage&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Here’s an example of using the OpenTelemetry Python library to monitor a generative AI application with the OpenAI client.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Install the OpenTelemetry dependencies:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;pip install opentelemetry-distro&#xA;opentelemetry-bootstrap -a install&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Set the following environment variables, updating the endpoint and protocol as appropriate:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;OPENAI_API_KEY&lt;strong&gt;=&lt;/strong&gt;&amp;lt;replace_with_your_openai_api_key&amp;gt;&#xA;&#xA;OTEL_EXPORTER_OTLP_ENDPOINT&lt;strong&gt;=&lt;/strong&gt;http://localhost:4318&#xA;OTEL_EXPORTER_OTLP_PROTOCOL&lt;strong&gt;=&lt;/strong&gt;http/protobuf&#xA;OTEL_SERVICE_NAME&lt;strong&gt;=&lt;/strong&gt;python-opentelemetry-openai&#xA;OTEL_LOGS_EXPORTER&lt;strong&gt;=&lt;/strong&gt;otlp_proto_http&#xA;OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED&lt;strong&gt;=&lt;/strong&gt;true&#xA;&lt;em&gt;# Set to false or remove to disable log events&lt;/em&gt;&#xA;OTEL_INSTRUMENTATION_GENAI_CAPTURE_MESSAGE_CONTENT&lt;strong&gt;=&lt;/strong&gt;true&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Then include the following code in your Python application:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;&lt;strong&gt;import&lt;/strong&gt; os&#xA;&lt;strong&gt;from&lt;/strong&gt; openai &lt;strong&gt;import&lt;/strong&gt; OpenAI&#xA;&#xA;client &lt;strong&gt;=&lt;/strong&gt; OpenAI&lt;strong&gt;()&lt;/strong&gt;&#xA;chat_completion &lt;strong&gt;=&lt;/strong&gt; client&lt;strong&gt;.&lt;/strong&gt;chat&lt;strong&gt;.&lt;/strong&gt;completions&lt;strong&gt;.&lt;/strong&gt;create&lt;strong&gt;(&lt;/strong&gt;&#xA;    model&lt;strong&gt;=&lt;/strong&gt;os&lt;strong&gt;.&lt;/strong&gt;getenv&lt;strong&gt;(&lt;/strong&gt;&#34;CHAT_MODEL&#34;&lt;strong&gt;,&lt;/strong&gt; &#34;gpt-4o-mini&#34;&lt;strong&gt;),&lt;/strong&gt;&#xA;    messages&lt;strong&gt;=&lt;/strong&gt;&lt;strong&gt;[&lt;/strong&gt;&#xA;        &lt;strong&gt;{&lt;/strong&gt;&#xA;            &#34;role&#34;&lt;strong&gt;:&lt;/strong&gt; &#34;user&#34;&lt;strong&gt;,&lt;/strong&gt;&#xA;            &#34;content&#34;&lt;strong&gt;:&lt;/strong&gt; &#34;Write a short poem on OpenTelemetry.&#34;&lt;strong&gt;,&lt;/strong&gt;&#xA;        &lt;strong&gt;},&lt;/strong&gt;&#xA;    &lt;strong&gt;],&lt;/strong&gt;&#xA;&lt;strong&gt;)&lt;/strong&gt;&#xA;print&lt;strong&gt;(&lt;/strong&gt;chat_completion&lt;strong&gt;.&lt;/strong&gt;choices&lt;strong&gt;[&lt;/strong&gt;&lt;strong&gt;0&lt;/strong&gt;&lt;strong&gt;]&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;message&lt;strong&gt;.&lt;/strong&gt;content&lt;strong&gt;)&lt;/strong&gt;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;And then run the example using&amp;nbsp;&lt;code&gt;opentelemetry-instrument&lt;/code&gt;:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;opentelemetry-instrument python main.py&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you do not have a service running to collect telemetry, you can export to the console using the following:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;opentelemetry-instrument --traces_exporter console --metrics_exporter console python main.py&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;There is a complete example&amp;nbsp;&lt;a href=&#34;https://github.com/open-telemetry/opentelemetry-python-contrib/tree/main/instrumentation-genai/opentelemetry-instrumentation-openai-v2/examples/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;available here&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;With this simple instrumentation, one can begin capture traces from their generative AI application. Here is an example from the&amp;nbsp;&lt;a href=&#34;https://learn.microsoft.com/dotnet/aspire/fundamentals/dashboard/standalone?tabs=bash&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Aspire Dashboard&lt;/a&gt;&amp;nbsp;for local debugging.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To start Jaeger, run the following&amp;nbsp;&lt;code&gt;docker&lt;/code&gt;&amp;nbsp;command and open your web browser the&amp;nbsp;&lt;code&gt;localhost:18888&lt;/code&gt;:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;docker run --rm -it -d -p 18888:18888 -p 4317:18889 -p 4318:18890 --name aspire-dashboard mcr.microsoft.com/dotnet/aspire-dashboard:9.0&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://opentelemetry.io/blog/2024/otel-generative-ai/aspire-dashboard-trace.png&#34; alt=&#34;Chat trace in Aspire Dashboard&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Here is a similar trace captured in&amp;nbsp;&lt;a href=&#34;https://www.jaegertracing.io/docs/1.63/getting-started/#all-in-one&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Jaeger&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To start Jaeger, run the following&amp;nbsp;&lt;code&gt;docker&lt;/code&gt;&amp;nbsp;command and open your web browser the&amp;nbsp;&lt;code&gt;localhost:16686&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;docker run --rm -it -d -p 16686:16686 -p 4317:4317 -p 4318:4318 --name jaeger jaegertracing/all-in-one:latest&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://opentelemetry.io/blog/2024/otel-generative-ai/jaeger-trace.png&#34; alt=&#34;Chat trace in Jaeger&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;It’s also easy to capture the content history of the chat for debugging and improving your application. Simply set the environment variable&amp;nbsp;&lt;code&gt;OTEL_INSTRUMENTATION_GENAI_CAPTURE_MESSAGE_CONTENT&lt;/code&gt;&amp;nbsp;as follows:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;export OTEL_INSTRUMENTATION_GENAI_CAPTURE_MESSAGE_CONTENT&lt;strong&gt;=&lt;/strong&gt;True&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This will turn on content capture which collects OpenTelemetry events containing the payload:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://opentelemetry.io/blog/2024/otel-generative-ai/aspire-dashboard-content-capture.png&#34; alt=&#34;Content Capture Aspire Dashboard&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;join-us-in-shaping-the-future-of-generative-ai-observability&#34;&gt;Join Us in Shaping the Future of Generative AI Observability&lt;a href=&#34;https://opentelemetry.io/blog/2024/otel-generative-ai/#join-us-in-shaping-the-future-of-generative-ai-observability&#34;&gt;&lt;/a&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Community collaboration is key to OpenTelemetry’s success. We invite developers, AI practitioners, and organizations to contribute, share feedback, or participate in discussions. Explore the OpenTelemetry Python Contrib project, contribute code, or help shape observability for AI as it continues to evolve.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We now have contributors from&amp;nbsp;&lt;a href=&#34;https://aws.amazon.com/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Amazon&lt;/a&gt;,&amp;nbsp;&lt;a href=&#34;https://www.elastic.co/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Elastic&lt;/a&gt;,&amp;nbsp;&lt;a href=&#34;https://www.google.com/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Google&lt;/a&gt;,&amp;nbsp;&lt;a href=&#34;https://www.ibm.com/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;IBM&lt;/a&gt;,&amp;nbsp;&lt;a href=&#34;https://www.langtrace.ai/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Langtrace&lt;/a&gt;,&amp;nbsp;&lt;a href=&#34;https://www.microsoft.com/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Microsoft&lt;/a&gt;,&amp;nbsp;&lt;a href=&#34;https://openlit.io/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;OpenLIT&lt;/a&gt;,&amp;nbsp;&lt;a href=&#34;https://www.scorecard.io/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Scorecard&lt;/a&gt;,&amp;nbsp;&lt;a href=&#34;https://www.traceloop.com/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Traceloop&lt;/a&gt;, and more!&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;You are welcome to join the community! More information can be found at the&amp;nbsp;&lt;a href=&#34;https://github.com/open-telemetry/community/blob/main/projects/gen-ai.md&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Generative AI Observability project page&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;项目帖子最初由 &lt;a href=&#34;https://opentelemetry.io/blog/2024/otel-generative-ai/&#34;&gt;OpenTelemetry 博客&lt;/a&gt;发布://github.com/drewby&#34;&gt;德鲁·罗宾斯&lt;/a&gt;（微软），&lt;a href=&#34;https://github.com/lmolkova&#34;&gt;Liudmila Molkova&lt;/a&gt;（微软）&lt;/em&gt;&lt; /p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;随着组织越来越多地采用大型语言模型 (LLM) 和其他生成式 AI 技术，确保可靠的性能、效率和安全性对于满足用户期望、优化资源成本和防止意外输出至关重要。人工智能操作、行为和结果的有效可观察性有助于实现这些目标。 OpenTelemetry 正在得到增强，以支持专门针对生成式 AI 的这些需求。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;为了实现这一目标，正在开发两个主要资产：&lt;strong&gt;语义约定&lt;/strong&gt;和&lt;strong&gt;仪器库&lt;/strong&gt;。第一个检测库面向 &lt;a href=&#34;https://pypi.org/project/openai/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;OpenAI Python API 库&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://opentelemetry.io/docs/concepts/semantic-conventions/&#34;&gt;&lt;strong&gt;语义约定&lt;/strong&gt;&lt;/a&gt; 为遥测数据的构建和收集方式制定标准化指南跨平台，定义输入、输出和操作细节。对于生成式 AI，这些约定通过标准化模型参数、响应元数据和令牌使用等属性来简化监控、故障排除和优化 AI 模型。这种一致性支持跨工具、环境和 API 更好的可观察性，帮助组织轻松跟踪性能、成本和安全性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://opentelemetry.io/docs/specs/otel/overview/#instrumentation-libraries&#34;&gt;&lt;strong&gt;仪器库&lt;/strong&gt;&lt;/a&gt;正在&lt; a href=&#34;https://github.com/open-telemetry/opentelemetry-python-contrib&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;OpenTelemetry Python &lt;a href=&#34;https://github.com/open-telemetry/opentelemetry-python-contrib/tree/main/instrumentation-genai&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;仪器下的贡献&lt;/a&gt; -genai&lt;/a&gt; 项目用于自动生成人工智能应用程序的遥测收集。第一个版本是一个用于检测 OpenAI 客户端调用的 Python 库。该库捕获跨度和事件，以结构化格式收集模型输入、响应元数据和令牌使用等基本数据。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;key-signals-for-generative-ai&#34;&gt;生成式人工智能的关键信号&lt;a href=&#34;https://opentelemetry.io/blog/2024/otel-generative -ai/#key-signals-for-generative-ai&#34;&gt;&lt;/a&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://opentelemetry.io/docs/specs/semconv/gen-ai/&#34;&gt;生成式 AI 语义约定&lt;/a&gt;专注于通过三个主要信号捕获对 AI 模型行为的洞察：&lt;a href=&#34;https://opentelemetry.io/docs/concepts/signals/traces/“&gt; traces &lt;/a&gt;，&lt;a href =” https://opentelemetry.io/docs/concepts/concepts/signals/metrics/“&gt; Metrics &lt;/a&gt;和&lt;a href =” https：/ /OpentElemetry.io/docs/specs/otel/logs/event-api/&#34;&gt; events &lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;一起，这些信号提供了一个全面的监视框架，实现了更好的成本管理，绩效调整和请求跟踪。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class =“ wp-block-heading” id =“ traces-tracing-tracing-model-interactions”&gt;跟踪：跟踪模型交互&lt;a href =“ https://opentelemetry.io/blog/2024/2024/ /＃痕迹 - 追踪模型 - 交流“&gt; &lt;/a&gt; &lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;跟踪每个模型交互的生命周期，涵盖输入参数（例如温度，top_p）以及响应细节，例如令牌计数或错误。它们提供了每个请求的可见性，有助于识别瓶颈并分析设置对模型输出的影响。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class =“ wp-block-heading” id =“指标 - 穆特林 -  usage-and-performance”&gt;度量：监视用法和性能&lt;a href =“ https://opentelemetry.io/blog/blog/2024/2024/otel-otel-otel--tel-生成 -  ai/＃度量 - 穆恩特（Monitoring-Monitoring-usage-usage and-performance）”&gt; &lt;/a&gt; &lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;指标汇总了高级指标，例如请求量，延迟和令牌计数，对于管理成本和绩效至关重要。该数据对于依赖于速率限制和成本考虑的API依赖性AI应用特别重要。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class =“ wp-block-heading” id =“ events-captring-detailed-interactions”&gt;事件：捕获详细的交互&lt;a href =“ https://opentelemetry.io/blog/blog/2024/2024/otel-generative-generative-generative-generative-generative-generative-generative-generative-generative-generative-generative-generative-generative-ai， /＃捕获事件的尾巴交织“&gt; &lt;/a&gt; &lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;事件在模型执行过程中日志详细的时刻，例如用户提示和模型响应，提供了模型交互的精细视图。这些见解对于可能出现意外行为的调试和优化AI应用程序是无价的。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class =“ wp-block头”&gt; note &lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;请注意，我们决定使用&lt;a href =“ https://opentelemetry.io/docs/specs/specs/otel/logs/api/papi/#emit/papi/#emit-an-1&gt; href =“ https://opentelemetry.io/docs/specs/otel/logs/api/”&gt; logs api &lt;/a&gt;在生成AI的语义惯例中规范。事件允许我们定义特定&lt;a href =“ https://opentelemetry.io/docs/specs/semconv/general/gen/events/”&gt;语义约定我们捕获的用户提示和模型响应。 API的这种增加正在开发并被认为是不稳定的。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class =“ wp-block-heading” id =“扩展 - 观察性with-with-with-with-with-with-with-with-with-with-with-with-with-tributes”&gt;使用供应商特定属性扩展可观察性&lt;a href =” /otel-generative-ai/＃扩展 - 观察性 - 供应商特定于特定于属性”&gt; &lt;/a&gt; &lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;语义惯例还为OpenAI和Azure推理API等平台定义了特定于供应商的属性，从而确保遥测可以捕获一般和提供者特定的细节。这增加了灵活性支持多平台监视和IN-DEPTH Insights。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class =“ wp-block-heading” id =“ building the-python-instrumentation-library-for-openai”&gt;构建python仪器库&lt;a a href =“ https://opentelemetry.io/blog /2024/Otel-generative-ai/＃building-the-python-instrumentation-library-for-openai“&gt; &lt;/a&gt; &lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这个基于Python的OpenTelemetry库捕获了OpenAI型号的关键遥测信号，为开发人员提供了针对AI工作负载量身定制的开箱即用的可观察性解决方案。图书馆，&lt;a href =“ https://github.com/open-telemetry/opentelemetry-python-python-contrib/tree/opentelemetry-strymetry-instrumentation-popenai-openai-v2%3D2.0B0B0B0B0B0B0B0B0/ OpenAI-V2“ target =” _ blank“ rel =“ noreferrer noopener”&gt;托管在OpenTelemetry Python prow库存储库中&lt;/a&gt;，自动从OpenAI模型交互中收集遥测，包括请求和响应元数据和响应元数据和tokenata and tokenata and token and token and poken。&#xA;&#xA;&#xA;&#xA;&lt;p&gt;随着生成AI应用程序的增长，将遵循其他语言的其他仪器库，从而在更多的工具和环境中扩展了OpentElemetry的支持。当前图书馆对OpenAI的关注强调了其在AI开发中的普及和需求，使其成为有价值的初始实施。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;在&lt;/a&gt; &lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这是使用OpenTelemetry Python库与OpenAI客户端监视生成AI应用程序的示例。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;安装opentelemetry依赖项：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class =“ wp-block-code”&gt; &lt;code class =“”&gt; pip安装opentelemetry-distro&#xA;OpentElemetry -Bootstrap -a安装&#xA;&lt;/code&gt; &lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;设置以下环境变量，适当更新端点和协议：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class =“ wp-block-code”&gt; &lt;code class =“”&gt; openai_api_key &lt;strong&gt; = &lt;/strong&gt; &lt;repents_with_your_openai_api_key&gt;&#xA;&#xA;otel_exporter_otlp_endpoint &lt;strong&gt; = &lt;/strong&gt; http：// localhost：4318&#xA;otel_exporter_otlp_protocol &lt;strong&gt; = &lt;/strong&gt; http/protobuf&#xA;otel_service_name &lt;strong&gt; = &lt;/strong&gt; python-opentelemetry-openai&#xA;otel_logs_exporter &lt;strong&gt; = &lt;/strong&gt; otlp_proto_http&#xA;otel_python_logging_auto_instrumentation_enabled &lt;strong&gt; = &lt;/strong&gt; true&#xA;&lt;em&gt;＃设置为false或删除禁用日志事件&lt;/em&gt;&#xA;otel_instrumentation_genai_capture_message_content &lt;strong&gt; = &lt;/strong&gt; true&#xA;&lt;/code&gt; &lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;然后在您的Python应用程序中包含以下代码：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class =“ wp-block-code”&gt; &lt;code class =“”&gt; &lt;strong&gt;导入&lt;/strong&gt; os&#xA;&lt;strong&gt;来自&lt;/strong&gt; OpenAi &lt;strong&gt;进口&lt;/strong&gt; OpenAi&#xA;&#xA;客户端&lt;strong&gt; = &lt;/strong&gt; OpenAi &lt;strong&gt;（）&lt;/strong&gt;&#xA;chat_completion &lt;strong&gt; = &lt;/strong&gt; client &lt;strong&gt;。&lt;/strong&gt; chat &lt;strong&gt;。&lt;/strong&gt;完成&lt;strong&gt;。&lt;/strong&gt;创建&lt;strong&gt;（&lt;/strong&gt;）&#xA;    模型&lt;strong&gt; = &lt;/strong&gt; os &lt;strong&gt;。&lt;/strong&gt; getenv &lt;strong&gt;（&lt;/strong&gt;“ chat_model” &lt;strong&gt;，&lt;/strong&gt;“ gpt-4o-mini” &lt;strong&gt;）， &lt;/strong&gt;&#xA;    消息&lt;strong&gt; = &lt;/strong&gt; &lt;strong&gt; [&lt;/strong&gt;&#xA;        &lt;strong&gt; {&lt;/strong&gt;“角色” &lt;strong&gt;：&lt;/strong&gt;“用户” &lt;strong&gt;，&lt;/strong&gt;&#xA;            “内容” &lt;strong&gt;：&lt;/strong&gt;“写一首关于Opentelemetry的简短诗。” &lt;strong&gt;，&lt;/strong&gt;&#xA;        &lt;strong&gt;}，&lt;/strong&gt;&#xA;    &lt;strong&gt;]，&lt;/strong&gt;&#xA;&lt;strong&gt;）&lt;/strong&gt;&#xA;打印&lt;strong&gt;（&lt;/strong&gt; chat_completion &lt;strong&gt;。&lt;/strong&gt;选择&lt;strong&gt; [&lt;/strong&gt; &lt;strong&gt; 0 &lt;/strong&gt; &lt;strong&gt;] &lt;/strong&gt; &lt;/strong&gt; &lt;strong&gt;。&lt;/strong &gt;消息&lt;strong&gt;。&lt;/strong&gt;内容&lt;strong&gt;）&lt;/strong&gt;&#xA;&lt;/code&gt; &lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;然后使用&lt;code&gt; OpentElemetry-Insprument &lt;/code&gt;：&lt;/p&gt;运行示例&#xA;&#xA;&#xA;&#xA;&lt;pre class =“ wp-block-code”&gt; &lt;code class =“”&gt; opentelemetry-interment python main.py&#xA;&lt;/code&gt; &lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您没有运行以收集遥测的服务，则可以使用以下内容导出到控制台：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class =“ wp-block-code”&gt; &lt;code class =“”&gt; opentelemetry-instrument -traces_exporter console -metrics_exporter Console python main.py&#xA;&lt;/code&gt; &lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;有一个完整的示例&lt;a a href =“ https://github.com/open-telemetry/opentelemetry-python-python-contrib/tree/main/main/main/minstrmentation-genai/opentelemetry-emetelemetry-instry--in-strumentation-openai-openai-openai-v2/examples/ target =“ _ blank” rel =“ noreferrer noopener”&gt;可在此处提供&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;使用这种简单的仪器，可以开始从其生成AI应用程序中捕获痕迹。这是&lt;a href =“ https://learn.microsoft.com/dotnet/aspire/fundamentals/dashboard/dashboard/dandalone?tabs = bash” target =“ _ blank” rel =“ noreferrer noopener”&gt; aspire dashboard &lt;aspire dashboard &lt; /a&gt;用于本地调试。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;要启动jaeger，请运行以下&lt;code&gt; docker &lt;/code&gt;命令并打开您的Web浏览器&lt;code&gt; localhost：18888 &lt;/code&gt;：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class =“ wp -block -code”&gt; &lt;code class =“”&gt; docker run -rm -it -d -d -p 18888：18888 -p 4317：18889 -p 4318：18890 -name aspire aspire -aspire -dash -dash -dash -dashboard mcr .microsoft.com/dotnet/aspire-dashboard：9.0&#xA;&lt;/code&gt; &lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;figie class =“ wp-block-image”&gt; &lt;img decoding =“ async” src =“ https://opentelemetry.io/blog/2024/otel-generative-generative-ai/aspire-dashboard-dashboard-toblabord-trace-trace.png” alt = “ Aspire仪表板中的聊天跟踪” referrerpolicy =“ no-treferrer”&gt; &lt;/fige&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这是在&lt;a href =“ https://www.jaegertracing.io/docs/1.63/getting-started/#all-in-in-in-------------- “&gt; Jaeger &lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;要启动jaeger，请运行以下&lt;code&gt; docker &lt;/code&gt;命令并打开您的Web浏览器&lt;code&gt; localhost：16686 &lt;/code&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class =“ wp -block -code”&gt; &lt;code class =“”&gt; docker run -rm -rm -d -d -p -p 16686：16686 -p 4317：4317 -p 4318：4318 -name jaeger jaeger jaeger jaegertracing/ash -in-in-In：最新&#xA;&lt;/code&gt; &lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;figig class =“ wp-block-image”&gt; &lt;img decoding =“ async” src =“ https://opentelemetry.io/blog/2024/otel-generative-generative-generative-aeger-aiger-aeger-trace-trace-trace.png，png” jaeger中的跟踪“ reverrerpolicy =” no-treferrer“&gt; &lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;也很容易捕获聊天的内容历史记录，以调试和改进您的应用程序。只需设置环境变量&lt;code&gt; otel_instrumentation_genai_capture_message_content &lt;/code&gt;如下：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class =“ wp-block代码&#34;&gt;&lt;code class=&#34;&#34;&gt;导出 OTEL_INSTRUMENTATION_GENAI_CAPTURE_MESSAGE_CONTENT&lt;strong&gt;=&lt;/strong&gt;True&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这将打开内容捕获，收集包含有效负载的 OpenTelemetry 事件：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://opentelemetry.io/blog/2024/otel-generative-ai/aspire-dashboard-content-capture.png&#34; alt=&#34;内容捕获 Aspire 仪表板&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;join-us-in-shaping-the-future-of-generative-ai-observability&#34;&gt;与我们一起塑造生成式 AI 可观测性的未来&lt;a href=&#34;https://opentelemetry.io/blog/2024/otel-generative-ai/#join-us-in-shaping-the-future-of-generative-ai-observability&#34;&gt;&lt;/a&gt;&lt;/h2 &gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;社区协作是 OpenTelemetry 成功的关键。我们邀请开发者、人工智能从业者和组织做出贡献、分享反馈或参与讨论。探索 OpenTelemetry Python Contrib 项目、贡献代码或帮助塑造不断发展的 AI 的可观察性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们现在有来自 &lt;a href=&#34;https://aws.amazon.com/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Amazon&lt;/a&gt;、&lt;a href=&#34;https:// /www.elastic.co/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;弹性&lt;/a&gt;，&lt;a href=&#34;https://www.google.com/&#34; target=&#34;_blank&#34; rel=&#34;没有推荐人noopener&#34;&gt;Google&lt;/a&gt;、&lt;a href=&#34;https://www.ibm.com/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;IBM&lt;/a&gt;、&lt;a href=&#34;https: //www.langtrace.ai/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Langtrace&lt;/a&gt;，&lt;a href=&#34;https://www.microsoft.com/&#34; target=&#34;_blank&#34; rel= “无推荐人noopener&#34;&gt;Microsoft&lt;/a&gt;、&lt;a href=&#34;https://openlit.io/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;OpenLIT&lt;/a&gt;、&lt;a href=&#34;https:// www.scorecard.io/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;记分卡&lt;/a&gt;，&lt;a href=&#34;https://www.traceloop.com/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Traceloop&lt;/a&gt;，以及更多！&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;欢迎您加入社区！如需了解更多信息，请访问 &lt;a href=&#34;https://github.com/open-telemetry/community/blob/main/projects/gen-ai.md&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;生成式人工智能可观察性项目页面&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Sun, 19 Jan 2025 16:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>