<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>CNCF - Blog</title>
    <link>http://rsshub.rssforever.com/cncf</link>
    <description>CNCF - Blog - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)</description>
    <managingEditor>i@diygod.me (DIYgod)</managingEditor>
    <item>
      <title>【Your guide to observability engineering in 2024】2024 年可观测性工程指南</title>
      <link>https://www.cncf.io/blog/2024/06/25/your-guide-to-observability-engineering-in-2024/</link>
      <description>【&lt;p&gt;&lt;em&gt;Member post originally published on the &lt;a href=&#34;https://logz.io/blog/observability-engineering/?utm_medium=referral&amp;amp;utm_source=cncf&#34;&gt;Logz.io blog&lt;/a&gt;&lt;/em&gt; &lt;em&gt;by Jake O’Donnell&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;It may sound complicated and daunting, but so much of observability is about discovering the unknown unknowns in your critical systems.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The capabilities of observability engineering can help you make those discoveries.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Most organizations have some form of monitoring, alerting and troubleshooting, which can be adequate to a point but fall short when trying to determine the root cause of unexpected outages. Observability engineering, on the other hand, provides a swift means to evolving process and tooling to uncover the reasons behind these issues.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Using this approach, teams can more effectively query their telemetry data, visualize anomalies, isolate peculiarities, spikes and bottlenecks, and then explore possibilities to solve them. In fact, observability engineering was specifically designed to tackle these unique, one-off incidents within the context of today’s complex cloud environments.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;What exactly does it take to embrace observability engineering in 2024, and how can you harness its power for your organization? We’ll get into that shortly, but let’s first set some parameters for exactly what we mean when we talk about full stack observability.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;m_-4735072010867219956gmail-definition-and-scope-of-observability&#34;&gt;Definition and Scope of Observability&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://logz.io/learn/modern-observability-101/?utm_medium=referral&amp;amp;utm_source=cncf&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Observability&lt;/a&gt;&amp;nbsp;is defined as the ability to measure the internal states of a system by examining its outputs. It’s how modern organizations approach the process of discovering issues with a given service, understanding their nature, and determining the best course of action for resolution.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;There’s a common misconception that observability and monitoring are synonymous, but that’s not the case. Observability extends the concept of monitoring by not just detecting when something goes wrong but by providing the necessary data to understand why and how it happened – hopefully before it impacts production systems.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The scope of observability specifically encompasses the collection, analysis, and visualization of telemetry data, including metrics, logs, and traces and other signals. This holistic view allows teams to diagnose issues more efficiently and ensure systems are running as expected. This is especially necessary when there are potentially thousands of events in a given service that need to be analyzed and understood for proper, functioning observability.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;m_-4735072010867219956gmail-key-components-of-observability&#34;&gt;Key Components of Observability&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The key components of observability are often defined as the “three pillars” of telemetry data—logs, metrics and traces. But those signals do not, in and of themselves, make up the components of observability, nor do they mean that by solely looking at and analyzing that data you are truly executing an observability practice.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Instead, you utilize those components as part of an overall observability data correlation strategy that must also include other critical components such as continuous profiling, business metrics,&amp;nbsp;&lt;a href=&#34;https://logz.io/blog/continuous-observability-cicd-pipelines/?utm_medium=referral&amp;amp;utm_source=cncf&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;CI/CD pipeline&lt;/a&gt;&amp;nbsp;performance and interactions with and feedback from customers.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;m_-4735072010867219956gmail-the-role-of-an-observability-engineer&#34;&gt;The Role of an Observability Engineer&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;There is no one definition of the role of an “observability engineer.” In our space, we see quite a few different titles for customers with these roles and responsibilities—these include site reliability engineers (SREs), platform engineers, DevOps engineers, system architects, software engineers and more.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In any event, an observability engineer is someone who is responsible for building, maintaining, monitoring and/or observing data pipelines, and working with the involved telemetry data (see the aforementioned components of observability).&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The observability engineer needs to know how to analyze and interpret the data provided by systems. At the very least, they need to know the right questions to ask about the status of systems and what if any measures need to be taken to correct any issues that materialize.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;m_-4735072010867219956gmail-challenges-in-observability-engineering&#34;&gt;Challenges in Observability Engineering&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Observability engineers are required to wear many hats in an organization, from managing and understanding systems to troubleshooting and problem-solving some of the most critical issues that can come up for any cloud-centric business.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Selling the business case for observability can be a significant challenge for any observability champion in an organization driven by a breadth of issues ranging from questions about its overall impact to potential costs. This can involve advocating for technology that will advance observability goals, or for a mindset shift that will enable better processes around the concept.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Specific challenges in these areas include:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Data overload.&amp;nbsp;One of the primary challenges in observability is managing the sheer volume of data generated by modern systems. It can be difficult to filter out noise and focus on the most relevant information. Observability engineering aims to tackle this issue.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Complexity of distributed systems. As systems become more distributed, understanding the interactions between components becomes increasingly complex. Ensuring end-to-end observability across multiple services and platforms can be a significant challenge for observability engineers.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Tool integration. Integrating various observability tools and ensuring they work seamlessly together requires careful planning and execution. Incompatibilities and integration issues can hinder the effectiveness of many observability solutions.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;m_-4735072010867219956gmail-best-practices-in-observability&#34;&gt;Best Practices in Observability&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;A proven set of best practices for observability engineering is critical for any organization to follow. These include processes, technology and ensuring you have the right people and expertise in place to ensure success.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This list is by no means exhaustive, but organizations need to consider the following best practices steps to get an observability strategy off the ground:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Define clear objectives. Establish what you want to achieve with observability. What do you want to get out of your practice? What will you be measuring and how will you achieve success? Define specific goals and key performance indicators (KPIs) that align with your business objectives.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Standardize data collection. Implement standardized methods for collecting metrics, logs, and traces across your systems. This keeps the organization aligned and keeps everyone involved on the same page. Consistency is key to effective analysis and troubleshooting.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Automate alerting. Set up automated alerts based on predefined thresholds to ensure timely detection of issues. Use machine learning to reduce false positives and prioritize critical alerts. It’s critical not to set up too many alerts so as to create alert fatigue in your organization—focus on the things you need to alert on and nothing else.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Invest in training. Ensure your team is well-versed in observability tools and practices. Continuous training and knowledge sharing are essential for maintaining effective observability. The world of observability constantly changes, so staying ahead of trends is critical.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Regularly review and refine.&amp;nbsp;&lt;a href=&#34;https://logz.io/blog/what-does-observability-mean-for-developers/?utm_medium=referral&amp;amp;utm_source=cncf&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Observability for developers&lt;/a&gt;&amp;nbsp;and other stakeholders is not a one-time setup. Regularly review your observability practices and refine them based on feedback and changing system requirements.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;m_-4735072010867219956gmail-benefits-of-effective-observability-engineering&#34;&gt;Benefits of Effective Observability Engineering&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;When you’ve successfully implemented observability engineering in your organization, the benefits are myriad and lasting. They’ll directly impact your bottom line, and help your business not only bounce back faster from production issues but help prevent them from happening in the first place.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Improved incident response.&amp;nbsp;&lt;a href=&#34;https://logz.io/observability-pulse-2024/?utm_medium=referral&amp;amp;utm_source=cncf&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;The 2024 Observability Pulse survey report&lt;/a&gt;&amp;nbsp;showed that 82% of organizations see mean time to resolution (MTTR) from production incidents of over an hour. Effective observability enables teams to quickly identify and diagnose issues, reducing MTTR and minimizing downtime.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Enhanced performance. By monitoring key metrics and analyzing system behavior, teams can identify performance bottlenecks and optimize their systems for better efficiency.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Proactive issue detection. Observability allows teams to detect anomalies and potential issues before they escalate into critical problems, leading to a more stable and reliable system.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Better decision-making. With a comprehensive view of system performance and behavior, organizations can make more informed decisions about architecture, scaling, and resource allocation.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;m_-4735072010867219956gmail-future-trends-in-observability-engineering&#34;&gt;Future Trends in Observability Engineering&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The future is here when it comes to observability:&amp;nbsp;&lt;a href=&#34;https://logz.io/blog/observability-iq-assistant/?utm_medium=referral&amp;amp;utm_source=cncf&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;most vendors today, including Logz.io, have integrated generative AI into their platforms&lt;/a&gt;, alongside long-standing proprietary AI capabilities.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Generative AI integration is intended to give observability engineers the opportunity to extend their teams and eliminate some tasks to get to the bottom of issues faster. These technologies can help predict issues before they occur and provide intelligent recommendations for remediation.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Some other future trends to monitor in observability include:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Unified observability platforms. The trend towards unified observability platforms that integrate metrics, logs, and traces into a single interface — supporting key use cases such as applications and Kubernetes analysis — is likely to continue. These platforms simplify the observability process and provide a holistic view of system performance.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Increased focus on security. With growing concerns around cybersecurity, observability engineering will increasingly incorporate security monitoring. Detecting and responding to security incidents in real-time will become a critical aspect of observability.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;m_-4735072010867219956gmail-how-Logz.io-can-help-you&#34;&gt;How Logz.io Can Help You Reach Observability Engineering Goals&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Effective observability engineering can only be achieved with the right tools and expertise from partners who can help extend your in-house capabilities. That’s what we try to provide at Logz.io through our platform.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://logz.io/platform/?utm_medium=referral&amp;amp;utm_source=cncf&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Logz.io Open 360™&lt;/a&gt;&amp;nbsp;is a cloud-native observability platform that gives you the tools to visualize, troubleshoot and remediate issues that show up in your telemetry data in future-facing ways to monitor your critical applications and infrastructure. Our platform is intuitive to use and it’s very easy to set up and start shipping your data in minutes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;With Open 360, you’ll meet your observability engineering goals with a platform that helps you:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Automate querying and interaction&amp;nbsp;with your platform through AI-powered, conversational terms to get to the bottom of issues fast&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Explore logging, metrics and trace data quickly with intuitive, high-performance search filters so you can accelerate troubleshooting and reduce MTTR through visualizations of spikes, dips and other trends&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Quickly drill into individual transactions&amp;nbsp;to diagnose root cause issues&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Get the most out of your open source tools and processes&amp;nbsp;via a unified platform that correlates event data&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Gain full visualization of your environment&amp;nbsp;tailored to specific needs and use cases via pre-built or customizable monitoring dashboards&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Filter out irrelevant telemetry data&amp;nbsp;so you can separate signal from noise and drastically reduce your data management, analysis and storage costs&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Combine Kubernetes logs, metrics, and traces&amp;nbsp;for unified analysis, troubleshooting and gain automatic contextualization with relevant data organized by node or deployment&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Discover full visibility into application health and performance&amp;nbsp;with an observability-based alternative to traditional APM, alongside automatic service discovery, instrumentation and collection for telemetry data&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Continuously optimize data and cost efficiency&amp;nbsp;to ensure that you focus on and pay for only the telemetry data that matters most to your unique requirements&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;See how Logz.io Open 360 can help you reach your goals for modern observability,&amp;nbsp;&lt;a href=&#34;https://logz.io/lp/free-trial/?utm_medium=referral&amp;amp;utm_source=cncf&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;sign up for a free trial today&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;Member post originally published on the &lt;a href=&#34;https://logz.io/blog/observability-engineering/?utm_medium=referral&amp;amp;utm_source=cncf&#34;&gt;Logz.io blog&lt;/a&gt;&lt;/em&gt; &lt;em&gt;by Jake O’Donnell&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;It may sound complicated and daunting, but so much of observability is about discovering the unknown unknowns in your critical systems.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The capabilities of observability engineering can help you make those discoveries.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Most organizations have some form of monitoring, alerting and troubleshooting, which can be adequate to a point but fall short when trying to determine the root cause of unexpected outages. Observability engineering, on the other hand, provides a swift means to evolving process and tooling to uncover the reasons behind these issues.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Using this approach, teams can more effectively query their telemetry data, visualize anomalies, isolate peculiarities, spikes and bottlenecks, and then explore possibilities to solve them. In fact, observability engineering was specifically designed to tackle these unique, one-off incidents within the context of today’s complex cloud environments.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;What exactly does it take to embrace observability engineering in 2024, and how can you harness its power for your organization? We’ll get into that shortly, but let’s first set some parameters for exactly what we mean when we talk about full stack observability.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;m_-4735072010867219956gmail-definition-and-scope-of-observability&#34;&gt;Definition and Scope of Observability&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://logz.io/learn/modern-observability-101/?utm_medium=referral&amp;amp;utm_source=cncf&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Observability&lt;/a&gt;&amp;nbsp;is defined as the ability to measure the internal states of a system by examining its outputs. It’s how modern organizations approach the process of discovering issues with a given service, understanding their nature, and determining the best course of action for resolution.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;There’s a common misconception that observability and monitoring are synonymous, but that’s not the case. Observability extends the concept of monitoring by not just detecting when something goes wrong but by providing the necessary data to understand why and how it happened – hopefully before it impacts production systems.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The scope of observability specifically encompasses the collection, analysis, and visualization of telemetry data, including metrics, logs, and traces and other signals. This holistic view allows teams to diagnose issues more efficiently and ensure systems are running as expected. This is especially necessary when there are potentially thousands of events in a given service that need to be analyzed and understood for proper, functioning observability.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;m_-4735072010867219956gmail-key-components-of-observability&#34;&gt;Key Components of Observability&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The key components of observability are often defined as the “three pillars” of telemetry data—logs, metrics and traces. But those signals do not, in and of themselves, make up the components of observability, nor do they mean that by solely looking at and analyzing that data you are truly executing an observability practice.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Instead, you utilize those components as part of an overall observability data correlation strategy that must also include other critical components such as continuous profiling, business metrics,&amp;nbsp;&lt;a href=&#34;https://logz.io/blog/continuous-observability-cicd-pipelines/?utm_medium=referral&amp;amp;utm_source=cncf&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;CI/CD pipeline&lt;/a&gt;&amp;nbsp;performance and interactions with and feedback from customers.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;m_-4735072010867219956gmail-the-role-of-an-observability-engineer&#34;&gt;The Role of an Observability Engineer&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;There is no one definition of the role of an “observability engineer.” In our space, we see quite a few different titles for customers with these roles and responsibilities—these include site reliability engineers (SREs), platform engineers, DevOps engineers, system architects, software engineers and more.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In any event, an observability engineer is someone who is responsible for building, maintaining, monitoring and/or observing data pipelines, and working with the involved telemetry data (see the aforementioned components of observability).&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The observability engineer needs to know how to analyze and interpret the data provided by systems. At the very least, they need to know the right questions to ask about the status of systems and what if any measures need to be taken to correct any issues that materialize.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;m_-4735072010867219956gmail-challenges-in-observability-engineering&#34;&gt;Challenges in Observability Engineering&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Observability engineers are required to wear many hats in an organization, from managing and understanding systems to troubleshooting and problem-solving some of the most critical issues that can come up for any cloud-centric business.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Selling the business case for observability can be a significant challenge for any observability champion in an organization driven by a breadth of issues ranging from questions about its overall impact to potential costs. This can involve advocating for technology that will advance observability goals, or for a mindset shift that will enable better processes around the concept.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Specific challenges in these areas include:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Data overload.&amp;nbsp;One of the primary challenges in observability is managing the sheer volume of data generated by modern systems. It can be difficult to filter out noise and focus on the most relevant information. Observability engineering aims to tackle this issue.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Complexity of distributed systems. As systems become more distributed, understanding the interactions between components becomes increasingly complex. Ensuring end-to-end observability across multiple services and platforms can be a significant challenge for observability engineers.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Tool integration. Integrating various observability tools and ensuring they work seamlessly together requires careful planning and execution. Incompatibilities and integration issues can hinder the effectiveness of many observability solutions.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;m_-4735072010867219956gmail-best-practices-in-observability&#34;&gt;Best Practices in Observability&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;A proven set of best practices for observability engineering is critical for any organization to follow. These include processes, technology and ensuring you have the right people and expertise in place to ensure success.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This list is by no means exhaustive, but organizations need to consider the following best practices steps to get an observability strategy off the ground:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Define clear objectives. Establish what you want to achieve with observability. What do you want to get out of your practice? What will you be measuring and how will you achieve success? Define specific goals and key performance indicators (KPIs) that align with your business objectives.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Standardize data collection. Implement standardized methods for collecting metrics, logs, and traces across your systems. This keeps the organization aligned and keeps everyone involved on the same page. Consistency is key to effective analysis and troubleshooting.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Automate alerting. Set up automated alerts based on predefined thresholds to ensure timely detection of issues. Use machine learning to reduce false positives and prioritize critical alerts. It’s critical not to set up too many alerts so as to create alert fatigue in your organization—focus on the things you need to alert on and nothing else.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Invest in training. Ensure your team is well-versed in observability tools and practices. Continuous training and knowledge sharing are essential for maintaining effective observability. The world of observability constantly changes, so staying ahead of trends is critical.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Regularly review and refine.&amp;nbsp;&lt;a href=&#34;https://logz.io/blog/what-does-observability-mean-for-developers/?utm_medium=referral&amp;amp;utm_source=cncf&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Observability for developers&lt;/a&gt;&amp;nbsp;and other stakeholders is not a one-time setup. Regularly review your observability practices and refine them based on feedback and changing system requirements.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;m_-4735072010867219956gmail-benefits-of-effective-observability-engineering&#34;&gt;Benefits of Effective Observability Engineering&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;When you’ve successfully implemented observability engineering in your organization, the benefits are myriad and lasting. They’ll directly impact your bottom line, and help your business not only bounce back faster from production issues but help prevent them from happening in the first place.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Improved incident response.&amp;nbsp;&lt;a href=&#34;https://logz.io/observability-pulse-2024/?utm_medium=referral&amp;amp;utm_source=cncf&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;The 2024 Observability Pulse survey report&lt;/a&gt;&amp;nbsp;showed that 82% of organizations see mean time to resolution (MTTR) from production incidents of over an hour. Effective observability enables teams to quickly identify and diagnose issues, reducing MTTR and minimizing downtime.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Enhanced performance. By monitoring key metrics and analyzing system behavior, teams can identify performance bottlenecks and optimize their systems for better efficiency.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Proactive issue detection. Observability allows teams to detect anomalies and potential issues before they escalate into critical problems, leading to a more stable and reliable system.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Better decision-making. With a comprehensive view of system performance and behavior, organizations can make more informed decisions about architecture, scaling, and resource allocation.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;m_-4735072010867219956gmail-future-trends-in-observability-engineering&#34;&gt;Future Trends in Observability Engineering&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The future is here when it comes to observability:&amp;nbsp;&lt;a href=&#34;https://logz.io/blog/observability-iq-assistant/?utm_medium=referral&amp;amp;utm_source=cncf&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;most vendors today, including Logz.io, have integrated generative AI into their platforms&lt;/a&gt;, alongside long-standing proprietary AI capabilities.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Generative AI integration is intended to give observability engineers the opportunity to extend their teams and eliminate some tasks to get to the bottom of issues faster. These technologies can help predict issues before they occur and provide intelligent recommendations for remediation.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Some other future trends to monitor in observability include:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Unified observability platforms. The trend towards unified observability platforms that integrate metrics, logs, and traces into a single interface — supporting key use cases such as applications and Kubernetes analysis — is likely to continue. These platforms simplify the observability process and provide a holistic view of system performance.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Increased focus on security. With growing concerns around cybersecurity, observability engineering will increasingly incorporate security monitoring. Detecting and responding to security incidents in real-time will become a critical aspect of observability.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;m_-4735072010867219956gmail-how-Logz.io-can-help-you&#34;&gt;How Logz.io Can Help You Reach Observability Engineering Goals&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Effective observability engineering can only be achieved with the right tools and expertise from partners who can help extend your in-house capabilities. That’s what we try to provide at Logz.io through our platform.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://logz.io/platform/?utm_medium=referral&amp;amp;utm_source=cncf&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Logz.io Open 360™&lt;/a&gt;&amp;nbsp;is a cloud-native observability platform that gives you the tools to visualize, troubleshoot and remediate issues that show up in your telemetry data in future-facing ways to monitor your critical applications and infrastructure. Our platform is intuitive to use and it’s very easy to set up and start shipping your data in minutes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;With Open 360, you’ll meet your observability engineering goals with a platform that helps you:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Automate querying and interaction&amp;nbsp;with your platform through AI-powered, conversational terms to get to the bottom of issues fast&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Explore logging, metrics and trace data quickly with intuitive, high-performance search filters so you can accelerate troubleshooting and reduce MTTR through visualizations of spikes, dips and other trends&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Quickly drill into individual transactions&amp;nbsp;to diagnose root cause issues&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Get the most out of your open source tools and processes&amp;nbsp;via a unified platform that correlates event data&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Gain full visualization of your environment&amp;nbsp;tailored to specific needs and use cases via pre-built or customizable monitoring dashboards&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Filter out irrelevant telemetry data&amp;nbsp;so you can separate signal from noise and drastically reduce your data management, analysis and storage costs&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Combine Kubernetes logs, metrics, and traces&amp;nbsp;for unified analysis, troubleshooting and gain automatic contextualization with relevant data organized by node or deployment&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Discover full visibility into application health and performance&amp;nbsp;with an observability-based alternative to traditional APM, alongside automatic service discovery, instrumentation and collection for telemetry data&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Continuously optimize data and cost efficiency&amp;nbsp;to ensure that you focus on and pay for only the telemetry data that matters most to your unique requirements&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;See how Logz.io Open 360 can help you reach your goals for modern observability,&amp;nbsp;&lt;a href=&#34;https://logz.io/lp/free-trial/?utm_medium=referral&amp;amp;utm_source=cncf&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;sign up for a free trial today&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Mon, 24 Jun 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Building the future of 5G with cloud native tech: insights from Joel and Ashan from Swisscom】利用云原生技术构建 5G 的未来：Swisscom 的 Joel 和 Ashan 的见解</title>
      <link>https://www.cncf.io/blog/2024/07/02/building-the-future-of-5g-with-cloud-native-tech-insights-from-joel-and-ashan-from-swisscom/</link>
      <description>【&lt;p&gt;&lt;em&gt;Member post by &lt;a href=&#34;https://www.linkedin.com/in/anjali-udasi/&#34;&gt;Anjali Udasi&lt;/a&gt;, Technical Writer, Zenduty and &lt;a href=&#34;https://www.linkedin.com/in/shubham67/&#34;&gt;Shubham Srivastava&lt;/a&gt;, Developer Relations Engineer, Zenduty&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.linkedin.com/in/joelstudler/&#34;&gt;Joel Studler&lt;/a&gt; and &lt;a href=&#34;https://www.linkedin.com/in/ashan-senevirathne/&#34;&gt;Ashan Senevirathne&lt;/a&gt; took the stage at KubeCon + CloudNativeCon Europe in Paris with their presentation, “&lt;a href=&#34;https://www.youtube.com/watch?v=crmTnB6Zwt8&#34;&gt;From GitOps to Kubernetes Resource Model&lt;/a&gt;,” highlighting Swisscom’s automation journey in the 5G Core and reflecting the company’s evolution from telco to TechCo.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Their talk was truly compelling, sparking our interest in learning more about their experiences and journey at &lt;a href=&#34;https://www.linkedin.com/company/swisscom/&#34;&gt;Swisscom&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.linkedin.com/in/shubham67/&#34;&gt;Shubham Srivastava&lt;/a&gt;, who currently leads Developer Relations at &lt;a href=&#34;https://www.zenduty.com/&#34;&gt;Zenduty&lt;/a&gt;, had the pleasure of speaking with this dynamic duo: Joel, a DevOps Engineer and System Architect dedicated to building the next generation of mobile networking using cloud-native technologies, and Ashan, a Product Owner overseeing the design, implementation, and delivery of a cloud-native orchestration framework for the mobile organization.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1600&#34; height=&#34;988&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/07/image-6-2.jpg&#34; alt=&#34;Building the Future of 5G with Cloud-Native Tech presented by Ashan Senevirathne and Joel Studler from swisscom&#34; class=&#34;wp-image-113961&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/07/image-6-2.jpg 1600w, https://www.cncf.io/wp-content/uploads/2024/07/image-6-2-300x185.jpg 300w, https://www.cncf.io/wp-content/uploads/2024/07/image-6-2-1024x632.jpg 1024w, https://www.cncf.io/wp-content/uploads/2024/07/image-6-2-768x474.jpg 768w, https://www.cncf.io/wp-content/uploads/2024/07/image-6-2-900x556.jpg 900w, https://www.cncf.io/wp-content/uploads/2024/07/image-6-2-324x200.jpg 324w, https://www.cncf.io/wp-content/uploads/2024/07/image-6-2-648x400.jpg 648w&#34; sizes=&#34;(max-width: 1600px) 100vw, 1600px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In this blog featuring Joel and Ashan, we peel the layers of the telco world, the struggles of modernization, and the cutting-edge tools these minds put to use. This is a conversation you don’t want to miss!&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Shubham&lt;/strong&gt;: It’s great to chat with you both. We’d love to know what an average day for you both looks like. You’re leading DevOps and reliability at Telco with very tight error budgets and room for failure. So what does that look like behind the scenes?&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Ashan: &lt;/strong&gt;For us, our main focus is on developing tooling capabilities for the upcoming 5G core technology, which we find applicable to other areas of the business as well. We put a lot of emphasis on community-driven initiatives. While our main focus is on Kubernetes environments, we also address the transition from legacy-based change management to cloud-native approaches, which requires a shift in organizational mindset.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Joel&lt;/strong&gt;: My role involves handling technical interfaces with the product, and collaborating closely with Ashan on architecture and engineering. Our daily tasks involve building reliable tools and automation, predominantly through &lt;a href=&#34;https://kubernetes.io/&#34;&gt;Kubernetes&lt;/a&gt; operators. We prioritize designing sustainable and efficient solutions while optimizing existing workloads. Testing and deployment typically occur on live or pre-production clusters.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Shubham&lt;/strong&gt;: Ashan, you mentioned that half of the job is not migrating processes, it’s also migrating the mindsets of the people. So stemming from that, what do you think is the hardest part about maintaining and updating reliability and tooling in a telecom industry that’s typically viewed as being very archaic and having a lot of legacy processes?&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Ashan: &lt;/strong&gt;The biggest hurdle in the telecom industry is adapting to a more open and flexible approach to network management. Traditionally, telecom relies on vendor-provided “black box” software, making it difficult to maintain and update tools reliably.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;But, now we’re tackling this by:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Greenfield approach:&lt;/strong&gt; Building new 5G core tools from scratch instead of relying on legacy systems.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;CNCF adoption:&lt;/strong&gt; Utilizing tools and concepts from the Cloud Native Computing Foundation (CNCF) for automation and containerization.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Shifting mindset:&lt;/strong&gt; Moving from a “black box” to a “white box” mentality, where software is open and modifiable for better control and reliability.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Joel:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;And also with the fact that we strategically decided to go forward with Kubernetes operators and the Kubernetes concepts for automation, has a big impact on many other topics like change management.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For instance: How do you implement a change? How do you plan with Kubernetes resources? You don’t control when the change happens. The operator just rolls it out now and then. You don’t control it.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;It’s a dynamic system, sparking a range of questions that we’ll be discussing a lot in the near future. This shift impacts not just technology but also requires a cultural change within the organization. The company is focusing on education and demonstrations to promote this new way of working.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Shubham&lt;/strong&gt;&lt;strong&gt;:&lt;/strong&gt; As an organization that’s so large and serves millions of people every day with mission-critical services, how do you handle the transition to Kubernetes? Specifically, how do you support Kubernetes and other open-source tools that enhance its capabilities? How do you vet open-source tools and new technologies from the CNCF ecosystem or elsewhere to ensure they’re stable and suitable for our organization?&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Ashan:&lt;/strong&gt; From a Kubernetes perspective, we use a vendor-provided distribution for our infrastructure. For deployment, we utilize &lt;a href=&#34;https://fluxcd.io/&#34;&gt;Flux&lt;/a&gt;, along with the external secret operator, cert-manager, and several other mature tools within the ecosystem.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For anything telco-specific, we often develop our solutions and have strong support internally to open-source these projects. This allows us to contribute to the community and encourage contributions from other operators, integrating telco-specific use cases into the Kubernetes ecosystem.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;When selecting tools, we prioritize maturity and support from the community and other industry players over novelty. This ensures we choose reliable, well-supported tools rather than simply the latest trends.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Shubham&lt;/strong&gt;: Joel, are there any tools that have caught your eye recently, tools that you’d love to play around with and are watching closely?&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Joel&lt;/strong&gt;: For the development flow, I’m interested in &lt;a href=&#34;https://microcks.io/&#34;&gt;Microcks&lt;/a&gt;. It’s a mocking framework and its innovation lies in its usability both within your IDE and on the Kubernetes cluster.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We’re also exploring testing tools like &lt;a href=&#34;https://litmuschaos.io/&#34;&gt;Litmus&lt;/a&gt; for &lt;a href=&#34;https://www.zenduty.com/blog/chaos-engineering/&#34;&gt;chaos engineering&lt;/a&gt; and &lt;a href=&#34;https://testkube.io/&#34;&gt;Testkube&lt;/a&gt;, a testing wrapper.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For instance, we’re adopting cert-manager, but in a Mobile Core on-prem environment with black box applications, it’s challenging. We’re pushing vendors to ensure compatibility with cert-manager, despite their tendency to fork and maintain their own versions.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Ashan&lt;/strong&gt;: Additionally, we’re looking into a project called &lt;a href=&#34;https://nephio.org/&#34;&gt;Nephio&lt;/a&gt;, driven by the Linux Foundation. It’s designed for deploying and managing the 5G core in a cloud-native way. While we don’t use Nephio tooling directly, we adapt its framework and thinking. For instance, we’re contributing to and leveraging the &lt;a href=&#34;https://docs.sdcio.dev/&#34;&gt;SDC (Schema Driven Configuration)&lt;/a&gt; tool within the project.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Shubham&lt;/strong&gt;: Are there any problems that you guys face currently and you’re waiting for a tool to come up and solve it? Like a hard problem that you guys would not want to build something to solve and you’re looking for someone else to come up and solve?&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Ashan&lt;/strong&gt;: The problem that we’re seeing is, or the technical challenge that we have is, we have these telco applications and it’s treated as an appliance. And during the lifecycle space or the deployment and the configuration phase, we need to do the deployment in a cloud-native way.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;And then what comes on top on the appliance level or the configuration, it’s done in a telco way. So there’s this proprietary interface defined by the telco standards and you need to do this configuration or apply or define these network services outside of the Kubernetes layer. And to achieve this, you need to do all these workarounds on top of that where we need to implement custom operators or find certain ways to bring this, what’s done outside of the Kubernetes layer, more into the in-bed Kubernetes layer.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If there’s an ask, the ask would be to have this configuration done in a Kubernetes native way, which means moving away from these &lt;a href=&#34;https://en.wikipedia.org/wiki/NETCONF&#34;&gt;NETCONF&lt;/a&gt;-based files, into a Kubernetes resource model. This shift would provide significant benefits, especially considering the time and effort we currently invest in making the configuration Kubernetes-native.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Joel&lt;/strong&gt;: Our biggest pain point right now is that we can’t handle our applications as true cloud-native citizens. The applications we receive from vendors are still treated like traditional hardware, with manual configurations akin to putting a server into a rack or setting up a bare metal appliance.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The mindset remains tied to the idea of a permanent system, like a &lt;a href=&#34;https://helm.sh/&#34;&gt;Helm&lt;/a&gt; release, where changes are made directly on the running system. This approach prevents us from implementing practices like blue-green deployments, and even a simple redeployment becomes a huge effort due to the manual steps involved.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We believe that introducing a cloud-native configuration interface would simplify lifecycle management, updates, and configurations.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Shubham&lt;/strong&gt;&lt;strong&gt;: &lt;/strong&gt;Observability must be crucial in your journey, especially as you ramp up. What does your observability framework look like? What metrics are you spending most of your time monitoring? We’d love to know more about how you handle &lt;a href=&#34;https://www.zenduty.com/blog/observability-vs-monitoring/&#34;&gt;monitoring and observability&lt;/a&gt; at Swisscom.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Joel: &lt;/strong&gt;Currently, we use a standard observability stack with &lt;a href=&#34;https://prometheus.io/&#34;&gt;Prometheus&lt;/a&gt; in our clusters and &lt;a href=&#34;https://grafana.com/oss/loki/&#34;&gt;Loki&lt;/a&gt; for logging. For centralized deployment, we use &lt;a href=&#34;https://thanos.io/&#34;&gt;Thanos&lt;/a&gt;. Additionally, we consume an internal Observability-as-a-Service stack that any Swisscom team can use, built on the standard Prometheus-Grafana stack, which integrates well with our Incident Management tooling.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We focus on a minimal, relevant subset of metrics to ensure service health. The 5G core and applications are more complex due to their black-box nature, so we work closely with vendors to identify the right metrics.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Ashan:&lt;/strong&gt; We use HTTP-based requests to monitor golden signals and key performance indicators (KPIs) such as user attachments, latency, and DNS metrics. For example in 5G core, we will have how many users are attached, what’s the latency or some metrics on the DNS.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;While some metrics are standard, others are more telco-specific, requiring vendor collaboration.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Shubham&lt;/strong&gt;&lt;strong&gt;:&lt;/strong&gt; You mentioned a while ago that you’re spending a lot of effort bolstering site reliability movements within your organization. SRE can be very demanding, as we’re all familiar with it. What’s the story at your org? How are you managing work-life balance, especially in a Telco environment where nothing can go wrong?&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Ashan&lt;/strong&gt;: I can speak on behalf of the mobile organization at Swisscom. We have a significant IT side as well, but our focus here is on the mobile sector.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Throughout our SRE journey, we’ve learned that not all Google-defined site reliability engineering practices directly apply to the Telco space. Instead, we’ve shifted our focus to service reliability, defining specific services offered by our mobile organization.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For instance, 5G is infrastructure, but the service is mobile data—like users browsing YouTube. We start by defining these services, identifying the underlying resources, and establishing &lt;a href=&#34;https://www.zenduty.com/blog/understanding-sla-slo-and-sli/&#34;&gt;SLAs and SLOs&lt;/a&gt; for each service. From there, we implement best practices in release engineering, observability, reliability, and security.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In the 4G era, particularly with the Evolved Packet Core on virtual machines, we’ve heavily invested in these principles. As we transition to the 5G core, we will apply the same principles, but in a cloud-native way, simplifying processes. This convergence of SRE and cloud-native transformations is key to our approach in the 5G domain.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Joel&lt;/strong&gt;: Another unique aspect of Swisscom’s approach is encouraging a cultural shift among our engineers. We emphasize that every decision in engineering or operations has a reliability impact. Encouraging individual responsibility and continuous improvement in operations is crucial. Moreover, having management that supports and encourages this mindset is crucial. This cultural shift has had the most significant impact on our organization.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We’ve started defining SLOs and maintaining error budgets for our services, but we apply them selectively, not at every resource level. When moving to Kubernetes operators, many SRE concepts, such as reconciliation, are automated by the Kubernetes layer. This automation puts us on the right track, and we’re excited to see the benefits it will bring to the organization.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;And that wraps up our conversation with Joel and Ashan! It’s always insightful to discuss observability, the demanding nature of SRE, and the innovative tools these reliability heroes are using to build products used by millions of people.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you’re fascinated by reliability and the intricate process of recovering from downtime, check out our &lt;a href=&#34;https://www.zenduty.com/podcast/&#34;&gt;podcast – Incidentally Reliable&lt;/a&gt;, where veterans from Docker, Amazon, Walmart, and other industry-leading organizations, share their experiences, challenges, and success stories from the Cloud Native world.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Authors:&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.linkedin.com/in/anjali-udasi/&#34;&gt;Anjali Udasi&lt;/a&gt; (Technical Writer), &lt;a href=&#34;https://www.linkedin.com/in/shubham67/&#34;&gt;Shubham Srivastava&lt;/a&gt; (Developer Relations Engineer)&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Author’s headshot:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image aligncenter size-full is-resized&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1104&#34; height=&#34;1600&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/07/image.jpeg&#34; alt=&#34;Anjali Udasi&#34; class=&#34;wp-image-113963&#34; style=&#34;width:220px;height:auto&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/07/image.jpeg 1104w, https://www.cncf.io/wp-content/uploads/2024/07/image-207x300.jpeg 207w, https://www.cncf.io/wp-content/uploads/2024/07/image-707x1024.jpeg 707w, https://www.cncf.io/wp-content/uploads/2024/07/image-768x1113.jpeg 768w, https://www.cncf.io/wp-content/uploads/2024/07/image-900x1304.jpeg 900w, https://www.cncf.io/wp-content/uploads/2024/07/image-138x200.jpeg 138w, https://www.cncf.io/wp-content/uploads/2024/07/image-276x400.jpeg 276w&#34; sizes=&#34;(max-width: 1104px) 100vw, 1104px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;&lt;strong&gt;Anjali Udasi &lt;/strong&gt;&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image aligncenter size-full is-resized&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;746&#34; height=&#34;1004&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/06/Screenshot-2024-06-28-at-07.31.19.jpg&#34; alt=&#34;Shubham Srivastava &#34; class=&#34;wp-image-113537&#34; style=&#34;width:218px;height:auto&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/06/Screenshot-2024-06-28-at-07.31.19.jpg 746w, https://www.cncf.io/wp-content/uploads/2024/06/Screenshot-2024-06-28-at-07.31.19-223x300.jpg 223w, https://www.cncf.io/wp-content/uploads/2024/06/Screenshot-2024-06-28-at-07.31.19-149x200.jpg 149w, https://www.cncf.io/wp-content/uploads/2024/06/Screenshot-2024-06-28-at-07.31.19-297x400.jpg 297w&#34; sizes=&#34;(max-width: 746px) 100vw, 746px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;&lt;strong&gt;Shubham Srivastava&lt;/strong&gt;&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;Member post by &lt;a href=&#34;https://www.linkedin.com/in/anjali-udasi/&#34;&gt;Anjali Udasi&lt;/a&gt;, Technical Writer, Zenduty and &lt;a href=&#34;https://www.linkedin.com/in/shubham67/&#34;&gt;Shubham Srivastava&lt;/a&gt;, Developer Relations Engineer, Zenduty&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.linkedin.com/in/joelstudler/&#34;&gt;Joel Studler&lt;/a&gt; and &lt;a href=&#34;https://www.linkedin.com/in/ashan-senevirathne/&#34;&gt;Ashan Senevirathne&lt;/a&gt; took the stage at KubeCon + CloudNativeCon Europe in Paris with their presentation, “&lt;a href=&#34;https://www.youtube.com/watch?v=crmTnB6Zwt8&#34;&gt;From GitOps to Kubernetes Resource Model&lt;/a&gt;,” highlighting Swisscom’s automation journey in the 5G Core and reflecting the company’s evolution from telco to TechCo.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Their talk was truly compelling, sparking our interest in learning more about their experiences and journey at &lt;a href=&#34;https://www.linkedin.com/company/swisscom/&#34;&gt;Swisscom&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.linkedin.com/in/shubham67/&#34;&gt;Shubham Srivastava&lt;/a&gt;, who currently leads Developer Relations at &lt;a href=&#34;https://www.zenduty.com/&#34;&gt;Zenduty&lt;/a&gt;, had the pleasure of speaking with this dynamic duo: Joel, a DevOps Engineer and System Architect dedicated to building the next generation of mobile networking using cloud-native technologies, and Ashan, a Product Owner overseeing the design, implementation, and delivery of a cloud-native orchestration framework for the mobile organization.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1600&#34; height=&#34;988&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/07/image-6-2.jpg&#34; alt=&#34;Building the Future of 5G with Cloud-Native Tech presented by Ashan Senevirathne and Joel Studler from swisscom&#34; class=&#34;wp-image-113961&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/07/image-6-2.jpg 1600w, https://www.cncf.io/wp-content/uploads/2024/07/image-6-2-300x185.jpg 300w, https://www.cncf.io/wp-content/uploads/2024/07/image-6-2-1024x632.jpg 1024w, https://www.cncf.io/wp-content/uploads/2024/07/image-6-2-768x474.jpg 768w, https://www.cncf.io/wp-content/uploads/2024/07/image-6-2-900x556.jpg 900w, https://www.cncf.io/wp-content/uploads/2024/07/image-6-2-324x200.jpg 324w, https://www.cncf.io/wp-content/uploads/2024/07/image-6-2-648x400.jpg 648w&#34; sizes=&#34;(max-width: 1600px) 100vw, 1600px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In this blog featuring Joel and Ashan, we peel the layers of the telco world, the struggles of modernization, and the cutting-edge tools these minds put to use. This is a conversation you don’t want to miss!&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Shubham&lt;/strong&gt;: It’s great to chat with you both. We’d love to know what an average day for you both looks like. You’re leading DevOps and reliability at Telco with very tight error budgets and room for failure. So what does that look like behind the scenes?&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Ashan: &lt;/strong&gt;For us, our main focus is on developing tooling capabilities for the upcoming 5G core technology, which we find applicable to other areas of the business as well. We put a lot of emphasis on community-driven initiatives. While our main focus is on Kubernetes environments, we also address the transition from legacy-based change management to cloud-native approaches, which requires a shift in organizational mindset.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Joel&lt;/strong&gt;: My role involves handling technical interfaces with the product, and collaborating closely with Ashan on architecture and engineering. Our daily tasks involve building reliable tools and automation, predominantly through &lt;a href=&#34;https://kubernetes.io/&#34;&gt;Kubernetes&lt;/a&gt; operators. We prioritize designing sustainable and efficient solutions while optimizing existing workloads. Testing and deployment typically occur on live or pre-production clusters.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Shubham&lt;/strong&gt;: Ashan, you mentioned that half of the job is not migrating processes, it’s also migrating the mindsets of the people. So stemming from that, what do you think is the hardest part about maintaining and updating reliability and tooling in a telecom industry that’s typically viewed as being very archaic and having a lot of legacy processes?&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Ashan: &lt;/strong&gt;The biggest hurdle in the telecom industry is adapting to a more open and flexible approach to network management. Traditionally, telecom relies on vendor-provided “black box” software, making it difficult to maintain and update tools reliably.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;But, now we’re tackling this by:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Greenfield approach:&lt;/strong&gt; Building new 5G core tools from scratch instead of relying on legacy systems.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;CNCF adoption:&lt;/strong&gt; Utilizing tools and concepts from the Cloud Native Computing Foundation (CNCF) for automation and containerization.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Shifting mindset:&lt;/strong&gt; Moving from a “black box” to a “white box” mentality, where software is open and modifiable for better control and reliability.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Joel:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;And also with the fact that we strategically decided to go forward with Kubernetes operators and the Kubernetes concepts for automation, has a big impact on many other topics like change management.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For instance: How do you implement a change? How do you plan with Kubernetes resources? You don’t control when the change happens. The operator just rolls it out now and then. You don’t control it.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;It’s a dynamic system, sparking a range of questions that we’ll be discussing a lot in the near future. This shift impacts not just technology but also requires a cultural change within the organization. The company is focusing on education and demonstrations to promote this new way of working.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Shubham&lt;/strong&gt;&lt;strong&gt;:&lt;/strong&gt; As an organization that’s so large and serves millions of people every day with mission-critical services, how do you handle the transition to Kubernetes? Specifically, how do you support Kubernetes and other open-source tools that enhance its capabilities? How do you vet open-source tools and new technologies from the CNCF ecosystem or elsewhere to ensure they’re stable and suitable for our organization?&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Ashan:&lt;/strong&gt; From a Kubernetes perspective, we use a vendor-provided distribution for our infrastructure. For deployment, we utilize &lt;a href=&#34;https://fluxcd.io/&#34;&gt;Flux&lt;/a&gt;, along with the external secret operator, cert-manager, and several other mature tools within the ecosystem.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For anything telco-specific, we often develop our solutions and have strong support internally to open-source these projects. This allows us to contribute to the community and encourage contributions from other operators, integrating telco-specific use cases into the Kubernetes ecosystem.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;When selecting tools, we prioritize maturity and support from the community and other industry players over novelty. This ensures we choose reliable, well-supported tools rather than simply the latest trends.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Shubham&lt;/strong&gt;: Joel, are there any tools that have caught your eye recently, tools that you’d love to play around with and are watching closely?&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Joel&lt;/strong&gt;: For the development flow, I’m interested in &lt;a href=&#34;https://microcks.io/&#34;&gt;Microcks&lt;/a&gt;. It’s a mocking framework and its innovation lies in its usability both within your IDE and on the Kubernetes cluster.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We’re also exploring testing tools like &lt;a href=&#34;https://litmuschaos.io/&#34;&gt;Litmus&lt;/a&gt; for &lt;a href=&#34;https://www.zenduty.com/blog/chaos-engineering/&#34;&gt;chaos engineering&lt;/a&gt; and &lt;a href=&#34;https://testkube.io/&#34;&gt;Testkube&lt;/a&gt;, a testing wrapper.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For instance, we’re adopting cert-manager, but in a Mobile Core on-prem environment with black box applications, it’s challenging. We’re pushing vendors to ensure compatibility with cert-manager, despite their tendency to fork and maintain their own versions.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Ashan&lt;/strong&gt;: Additionally, we’re looking into a project called &lt;a href=&#34;https://nephio.org/&#34;&gt;Nephio&lt;/a&gt;, driven by the Linux Foundation. It’s designed for deploying and managing the 5G core in a cloud-native way. While we don’t use Nephio tooling directly, we adapt its framework and thinking. For instance, we’re contributing to and leveraging the &lt;a href=&#34;https://docs.sdcio.dev/&#34;&gt;SDC (Schema Driven Configuration)&lt;/a&gt; tool within the project.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Shubham&lt;/strong&gt;: Are there any problems that you guys face currently and you’re waiting for a tool to come up and solve it? Like a hard problem that you guys would not want to build something to solve and you’re looking for someone else to come up and solve?&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Ashan&lt;/strong&gt;: The problem that we’re seeing is, or the technical challenge that we have is, we have these telco applications and it’s treated as an appliance. And during the lifecycle space or the deployment and the configuration phase, we need to do the deployment in a cloud-native way.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;And then what comes on top on the appliance level or the configuration, it’s done in a telco way. So there’s this proprietary interface defined by the telco standards and you need to do this configuration or apply or define these network services outside of the Kubernetes layer. And to achieve this, you need to do all these workarounds on top of that where we need to implement custom operators or find certain ways to bring this, what’s done outside of the Kubernetes layer, more into the in-bed Kubernetes layer.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If there’s an ask, the ask would be to have this configuration done in a Kubernetes native way, which means moving away from these &lt;a href=&#34;https://en.wikipedia.org/wiki/NETCONF&#34;&gt;NETCONF&lt;/a&gt;-based files, into a Kubernetes resource model. This shift would provide significant benefits, especially considering the time and effort we currently invest in making the configuration Kubernetes-native.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Joel&lt;/strong&gt;: Our biggest pain point right now is that we can’t handle our applications as true cloud-native citizens. The applications we receive from vendors are still treated like traditional hardware, with manual configurations akin to putting a server into a rack or setting up a bare metal appliance.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The mindset remains tied to the idea of a permanent system, like a &lt;a href=&#34;https://helm.sh/&#34;&gt;Helm&lt;/a&gt; release, where changes are made directly on the running system. This approach prevents us from implementing practices like blue-green deployments, and even a simple redeployment becomes a huge effort due to the manual steps involved.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We believe that introducing a cloud-native configuration interface would simplify lifecycle management, updates, and configurations.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Shubham&lt;/strong&gt;&lt;strong&gt;: &lt;/strong&gt;Observability must be crucial in your journey, especially as you ramp up. What does your observability framework look like? What metrics are you spending most of your time monitoring? We’d love to know more about how you handle &lt;a href=&#34;https://www.zenduty.com/blog/observability-vs-monitoring/&#34;&gt;monitoring and observability&lt;/a&gt; at Swisscom.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Joel: &lt;/strong&gt;Currently, we use a standard observability stack with &lt;a href=&#34;https://prometheus.io/&#34;&gt;Prometheus&lt;/a&gt; in our clusters and &lt;a href=&#34;https://grafana.com/oss/loki/&#34;&gt;Loki&lt;/a&gt; for logging. For centralized deployment, we use &lt;a href=&#34;https://thanos.io/&#34;&gt;Thanos&lt;/a&gt;. Additionally, we consume an internal Observability-as-a-Service stack that any Swisscom team can use, built on the standard Prometheus-Grafana stack, which integrates well with our Incident Management tooling.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We focus on a minimal, relevant subset of metrics to ensure service health. The 5G core and applications are more complex due to their black-box nature, so we work closely with vendors to identify the right metrics.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Ashan:&lt;/strong&gt; We use HTTP-based requests to monitor golden signals and key performance indicators (KPIs) such as user attachments, latency, and DNS metrics. For example in 5G core, we will have how many users are attached, what’s the latency or some metrics on the DNS.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;While some metrics are standard, others are more telco-specific, requiring vendor collaboration.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Shubham&lt;/strong&gt;&lt;strong&gt;:&lt;/strong&gt; You mentioned a while ago that you’re spending a lot of effort bolstering site reliability movements within your organization. SRE can be very demanding, as we’re all familiar with it. What’s the story at your org? How are you managing work-life balance, especially in a Telco environment where nothing can go wrong?&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Ashan&lt;/strong&gt;: I can speak on behalf of the mobile organization at Swisscom. We have a significant IT side as well, but our focus here is on the mobile sector.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Throughout our SRE journey, we’ve learned that not all Google-defined site reliability engineering practices directly apply to the Telco space. Instead, we’ve shifted our focus to service reliability, defining specific services offered by our mobile organization.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For instance, 5G is infrastructure, but the service is mobile data—like users browsing YouTube. We start by defining these services, identifying the underlying resources, and establishing &lt;a href=&#34;https://www.zenduty.com/blog/understanding-sla-slo-and-sli/&#34;&gt;SLAs and SLOs&lt;/a&gt; for each service. From there, we implement best practices in release engineering, observability, reliability, and security.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In the 4G era, particularly with the Evolved Packet Core on virtual machines, we’ve heavily invested in these principles. As we transition to the 5G core, we will apply the same principles, but in a cloud-native way, simplifying processes. This convergence of SRE and cloud-native transformations is key to our approach in the 5G domain.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Joel&lt;/strong&gt;: Another unique aspect of Swisscom’s approach is encouraging a cultural shift among our engineers. We emphasize that every decision in engineering or operations has a reliability impact. Encouraging individual responsibility and continuous improvement in operations is crucial. Moreover, having management that supports and encourages this mindset is crucial. This cultural shift has had the most significant impact on our organization.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We’ve started defining SLOs and maintaining error budgets for our services, but we apply them selectively, not at every resource level. When moving to Kubernetes operators, many SRE concepts, such as reconciliation, are automated by the Kubernetes layer. This automation puts us on the right track, and we’re excited to see the benefits it will bring to the organization.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;And that wraps up our conversation with Joel and Ashan! It’s always insightful to discuss observability, the demanding nature of SRE, and the innovative tools these reliability heroes are using to build products used by millions of people.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you’re fascinated by reliability and the intricate process of recovering from downtime, check out our &lt;a href=&#34;https://www.zenduty.com/podcast/&#34;&gt;podcast – Incidentally Reliable&lt;/a&gt;, where veterans from Docker, Amazon, Walmart, and other industry-leading organizations, share their experiences, challenges, and success stories from the Cloud Native world.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Authors:&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.linkedin.com/in/anjali-udasi/&#34;&gt;Anjali Udasi&lt;/a&gt; (Technical Writer), &lt;a href=&#34;https://www.linkedin.com/in/shubham67/&#34;&gt;Shubham Srivastava&lt;/a&gt; (Developer Relations Engineer)&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Author’s headshot:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image aligncenter size-full is-resized&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1104&#34; height=&#34;1600&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/07/image.jpeg&#34; alt=&#34;Anjali Udasi&#34; class=&#34;wp-image-113963&#34; style=&#34;width:220px;height:auto&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/07/image.jpeg 1104w, https://www.cncf.io/wp-content/uploads/2024/07/image-207x300.jpeg 207w, https://www.cncf.io/wp-content/uploads/2024/07/image-707x1024.jpeg 707w, https://www.cncf.io/wp-content/uploads/2024/07/image-768x1113.jpeg 768w, https://www.cncf.io/wp-content/uploads/2024/07/image-900x1304.jpeg 900w, https://www.cncf.io/wp-content/uploads/2024/07/image-138x200.jpeg 138w, https://www.cncf.io/wp-content/uploads/2024/07/image-276x400.jpeg 276w&#34; sizes=&#34;(max-width: 1104px) 100vw, 1104px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;&lt;strong&gt;Anjali Udasi &lt;/strong&gt;&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image aligncenter size-full is-resized&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;746&#34; height=&#34;1004&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/06/Screenshot-2024-06-28-at-07.31.19.jpg&#34; alt=&#34;Shubham Srivastava &#34; class=&#34;wp-image-113537&#34; style=&#34;width:218px;height:auto&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/06/Screenshot-2024-06-28-at-07.31.19.jpg 746w, https://www.cncf.io/wp-content/uploads/2024/06/Screenshot-2024-06-28-at-07.31.19-223x300.jpg 223w, https://www.cncf.io/wp-content/uploads/2024/06/Screenshot-2024-06-28-at-07.31.19-149x200.jpg 149w, https://www.cncf.io/wp-content/uploads/2024/06/Screenshot-2024-06-28-at-07.31.19-297x400.jpg 297w&#34; sizes=&#34;(max-width: 746px) 100vw, 746px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;&lt;strong&gt;Shubham Srivastava&lt;/strong&gt;&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Mon, 01 Jul 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Slurm: An HPC workload manager】Slurm：HPC 工作负载管理器</title>
      <link>https://www.cncf.io/blog/2024/07/08/slurm-an-hpc-workload-manager/</link>
      <description>【&lt;p&gt;&lt;em&gt;Member post originally published on &lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/&#34;&gt;SuperOrbital’s blog&lt;/a&gt; by Sean Kane&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/cover.jpg&#34; alt=&#34;datacenter servers&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In this article, we are going to explore&amp;nbsp;&lt;a href=&#34;https://github.com/SchedMD/slurm&#34;&gt;Slurm&lt;/a&gt;, a popular open-source high-performance computing (HPC&lt;sup&gt;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fn:hpc&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;) workload manager, and discover what it is, why people use it, and how it differs from Kubernetes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For context, when we talk about high-performance computing, we are primarily talking about computational tasks that require a lot of time on very powerful computer systems and are often designed, so that they can be&amp;nbsp;&lt;a href=&#34;https://en.wikipedia.org/wiki/Parallel_computing&#34;&gt;highly parallelized&lt;/a&gt;, across resources within a super-computer or large cluster.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;These sorts of jobs are very common in scientific research,&amp;nbsp;&lt;a href=&#34;https://en.wikipedia.org/wiki/Computer_simulation&#34;&gt;computer simulation&lt;/a&gt;,&amp;nbsp;&lt;a href=&#34;https://en.wikipedia.org/wiki/Artificial_intelligence&#34;&gt;artificial intelligence&lt;/a&gt;, and&amp;nbsp;&lt;a href=&#34;https://en.wikipedia.org/wiki/Machine_learning&#34;&gt;machine learning&lt;/a&gt;&amp;nbsp;tasks.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;what-is-slurm&#34;&gt;What is Slurm?&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To almost directly quote the Slurm repository&amp;nbsp;&lt;a href=&#34;https://github.com/SchedMD/slurm/blob/master/README.rst#slurm-workload-manager&#34;&gt;README&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p class=&#34;has-normal-font-size&#34;&gt;Slurm is an open-source cluster resource management and job scheduling system for Linux (&lt;em&gt;primarily&lt;/em&gt;) that strives to be simple, scalable, portable, fault-tolerant, and interconnect agnostic. As a cluster resource manager, Slurm provides three key functions:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li class=&#34;has-normal-font-size&#34;&gt;First, it allocates exclusive and/or non-exclusive access to resources (compute nodes) to users for some duration of time so they can perform work.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li class=&#34;has-normal-font-size&#34;&gt;Second, it provides a framework for starting, executing, and monitoring work (&lt;em&gt;normally a parallel job&lt;/em&gt;) on the set of allocated nodes.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li class=&#34;has-normal-font-size&#34;&gt;And finally, it arbitrates conflicting requests for resources by managing a queue of pending work.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In short, Slurm is a system that is primarily designed to manage&amp;nbsp;&lt;a href=&#34;https://en.wikipedia.org/wiki/Batch_processing&#34;&gt;batch processing&lt;/a&gt;&amp;nbsp;workloads running in a shared&amp;nbsp;&lt;a href=&#34;https://en.wikipedia.org/wiki/Computer_cluster&#34;&gt;computing cluster&lt;/a&gt;. Slurm can be configured to run any type of batch job but is often utilized on systems that support multiple users with parallel computing tasks to run.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;According to&amp;nbsp;&lt;a href=&#34;https://www.schedmd.com/&#34;&gt;SchedMD&lt;/a&gt;, the primary support and development company for the Slurm community, Slurm is being used on approximately 65% of the&amp;nbsp;&lt;a href=&#34;https://top500.org/lists/top500/2024/06/&#34;&gt;TOP500 supercomputers in the world&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;a-bit-of-history&#34;&gt;A bit of history&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In the mid-1990s, as Linux became more popular, there was an increased interest in making large-scale computer processing more accessible through the use of commodity hardware and projects like&amp;nbsp;&lt;a href=&#34;https://en.wikipedia.org/wiki/Beowulf_cluster&#34;&gt;Beowulf&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In 2001, engineers at the&amp;nbsp;&lt;a href=&#34;https://www.llnl.gov/&#34;&gt;Lawrence Livermore National Laboratory&lt;/a&gt;&amp;nbsp;(LLNL&lt;sup&gt;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fn:llnl&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;) in the United States, started looking into how they might migrate from proprietary HPC systems to open-source solutions. They determined that there weren’t any good resource managers available at the time, and this directly led to the creation of Slurm, which was initially released in 2002.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p class=&#34;has-normal-font-size&#34;&gt;&lt;a href=&#34;https://slurm.schedmd.com/slurm_design.pdf&#34;&gt;The name Slurm is a reference&lt;/a&gt;&amp;nbsp;to the&amp;nbsp;&lt;a href=&#34;https://futurama.fandom.com/wiki/Slurm&#34;&gt;soda&lt;/a&gt;&amp;nbsp;in&amp;nbsp;&lt;a href=&#34;https://www.imdb.com/title/tt0149460/&#34;&gt;Futurama&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Over the years, Slurm has evolved to support a wide variety of hardware configurations and in 2010, some initial scheduling logic was added to Slurm, enabling it to function as both a stand-alone resource manager and a scheduler&lt;sup&gt;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fn:history&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;the-architecture&#34;&gt;The Architecture&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Like many similar systems, a Slurm setup consists of at least one controller node, and at least one compute node, which can be on the same physical systems.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/slurm-layout.gif&#34; alt=&#34;Diagram of the basic Slurm architecture&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;the-controller&#34;&gt;The Controller&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Two daemons are responsible for managing the cluster. These two processes can be run on a single node or separated, depending on the performance and resiliency required by the administrator.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34; id=&#34;slurmctld&#34;&gt;slurmctld&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;code&gt;slurmctld&lt;/code&gt;&amp;nbsp;is the primary management daemon for Slurm. It is responsible for all the daemons, resources, and jobs, within the cluster. Because it is a critical component in the cluster, it is often configured with a passive backup that can take over management if the primary daemon ever fails.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34; id=&#34;slurmdbd&#34;&gt;slurmdbd&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;code&gt;slurmdbd&lt;/code&gt;&amp;nbsp;provides an interface for the&amp;nbsp;&lt;a href=&#34;https://en.wikipedia.org/wiki/MySQL&#34;&gt;MySQL database&lt;/a&gt;&amp;nbsp;that Slurm uses for stateful data, like job accounting records.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;compute-nodes&#34;&gt;Compute Nodes&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;These represent the nodes whose resources are available to any jobs that might need to be scheduled in the cluster.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34; id=&#34;slurmd&#34;&gt;slurmd&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;code&gt;slurmd&lt;/code&gt;&amp;nbsp;is the daemon that runs on each compute node and is responsible for accepting work, launching tasks, and generally managing the workloads on each node.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;installation&#34;&gt;Installation&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;SchedMD maintains the core documentation for Slurm and the&amp;nbsp;&lt;a href=&#34;https://slurm.schedmd.com/quickstart_admin.html#quick_start&#34;&gt;current installation documentation&lt;/a&gt;&amp;nbsp;can be found on their website.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Getting Slurm working is not particularly difficult, but fine-tuning it for your requirements can be a time-consuming task. Since performance is often a primary focus with these clusters and Slurm is designed to work with a very wide set of hardware and software libraries, it can take a lot of effort to fine-tune the installation, so that it utilizes the hardware to the best of its ability, and all the proper software is available to streamline the types of jobs that will be run on the cluster.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;At a minimum clusters will require node name resolution, a MySQL instance, shared block storage, a synchronized time source, synchronized users, the&amp;nbsp;&lt;a href=&#34;https://dun.github.io/munge/&#34;&gt;Munge&lt;/a&gt;&amp;nbsp;daemon for user authentication, a full set of custom-built Slurm executables, and various configuration files.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In addition to this, the nodes will need to contain the various hardware, programming languages, libraries, and other tools that the majority of jobs will require to run. This could include things like GPUs&lt;sup&gt;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fn:gpu&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;&amp;nbsp;and their related toolchains (CUDA&lt;sup&gt;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fn:cuda&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;/cuDNN&lt;sup&gt;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fn:cudnn&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;), MPI&lt;sup&gt;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fn:mpi&#34;&gt;7&lt;/a&gt;&lt;/sup&gt;&amp;nbsp;libraries, OCI&lt;sup&gt;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fn:oci&#34;&gt;8&lt;/a&gt;&lt;/sup&gt;&amp;nbsp;runtimes for&amp;nbsp;&lt;a href=&#34;https://slurm.schedmd.com/containers.html&#34;&gt;container support&lt;/a&gt;, and much more.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Slurm’s greatest asset and liability is how flexible it is. This makes it something that can be highly optimized for the requirements of the organization, while also making it susceptible to misconfiguration.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;workloads&#34;&gt;Workloads&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To provide some context, let’s take a look at an example user job and workflow that utilizes some of the features of Slurm.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In the&amp;nbsp;&lt;code&gt;mpi-ping-pong.py&lt;/code&gt;&amp;nbsp;code below, you will find a&amp;nbsp;&lt;a href=&#34;https://www.python.org/&#34;&gt;Python&lt;/a&gt;&amp;nbsp;script that simulates a pseudo-game of&amp;nbsp;&lt;a href=&#34;https://en.wikipedia.org/wiki/Table_tennis&#34;&gt;Ping Pong/Table Tennis&lt;/a&gt;&amp;nbsp;by making use of MPI to pass a message (&lt;em&gt;“ball”&lt;/em&gt;) between as many processes as we have configured to participate in the parallel job.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;local-testing&#34;&gt;Local Testing&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To run this code, you simply need to have&amp;nbsp;&lt;a href=&#34;https://www.python.org/downloads/&#34;&gt;Python&lt;/a&gt;,&amp;nbsp;&lt;a href=&#34;https://docs.open-mpi.org/en/v5.0.x/installing-open-mpi/quickstart.html&#34;&gt;OpenMPI&lt;/a&gt;, and&amp;nbsp;&lt;a href=&#34;https://mpi4py.readthedocs.io/en/stable/install.html&#34;&gt;mpi4py&lt;/a&gt;&amp;nbsp;installed on your system.mpi-ping-pong.py&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/superorbital/mpi-playground/blob/main/containers/mpi-ping-pong/mpi-ping-pong.py&#34;&gt;mpi-ping-pong.py&lt;/a&gt;&amp;nbsp;is what many would refer to as an&amp;nbsp;&lt;a href=&#34;https://en.wikipedia.org/wiki/Embarrassingly_parallel&#34;&gt;embarrassingly parallel&lt;/a&gt;&amp;nbsp;workload because it can be scaled with no real effort at all.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you run this Python application on your local system, you will see something like this:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;$ python ./mpi-ping-pong.py&#xA;&#xA;Hello, World! I am 🏓 Player (Rank)  0 . Process  1  of  1  on  laptop.local&#xA;Player (Rank)  0 &#39;s receiving 🏓 neighbor is Player (Rank) 0 and my sending 🏓 neighbor is Player (Rank) 0.&#xA;Player 0 started round 1 by hitting the 🏓 ball towards the wall.&#xA;Player 0 received the 🏓 ball that bounced off the wall.&#xA;Player 0 started round 2 by hitting the 🏓 ball towards the wall.&#xA;Player 0 received the 🏓 ball that bounced off the wall.&#xA;…&#xA;Player 0 started round 299 by hitting the 🏓 ball towards the wall.&#xA;Player 0 received the 🏓 ball that bounced off the wall.&#xA;🎉 Player 0 won the game of 🏓 ping pong, since they were playing alone! 🎉&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As you can see the application runs perfectly fine, and uses a single rank&lt;sup&gt;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fn:rank&#34;&gt;9&lt;/a&gt;&lt;/sup&gt;/process (&lt;em&gt;CPU&lt;sup&gt;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fn:cpu&#34;&gt;10&lt;/a&gt;&lt;/sup&gt;&amp;nbsp;core, in this case&lt;/em&gt;). Since we only have a single process participating in this game of Ping Pong, the program simply sends and receives messages to and from from itself.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;However, assuming that we have at least two CPU cores, then we can run this application utilizing as many of them as we want, by leveraging the MPI command line tool&amp;nbsp;&lt;code&gt;mpirun&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To run 12 instances of our application, which will all communicate with each other in parallel across 12 cores on our system, we can do the following on our local system:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p class=&#34;has-normal-font-size&#34;&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: These messages will be somewhat out of order. This is the nature of parallel computing, buffers, etc. To deal with this you would likely need to send all the messages back to single process for ordering and printing.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;$ mpirun -np 12 ./mpi-ping-pong.py&#xA;&#xA;Player (Rank)  0 &#39;s receiving 🏓 neighbor is Player (Rank) 11 and my sending 🏓 neighbor is Player (Rank) 1.&#xA;Hello, World! I am 🏓 Player (Rank)  0 . Process  1  of  12  on  laptop.local&#xA;Player (Rank)  1 &#39;s receiving 🏓 neighbor is Player (Rank) 0 and my sending 🏓 neighbor is Player (Rank) 2.&#xA;Hello, World! I am 🏓 Player (Rank)  1 . Process  2  of  12  on  laptop.local&#xA;Player (Rank)  2 &#39;s receiving 🏓 neighbor is Player (Rank) 1 and my sending 🏓 neighbor is Player (Rank) 3.&#xA;Hello, World! I am 🏓 Player (Rank)  2 . Process  3  of  12  on  laptop.local&#xA;…&#xA;🛑 Player 0 is bored of 🏓 ping pong and is quitting! 🛑&#xA;🛑 Player 1 is bored of 🏓 ping pong and is quitting! 🛑&#xA;🛑 Player 2 is bored of 🏓 ping pong and is quitting! 🛑&#xA;…&#xA;🎉 Player 11 won the game of 🏓 ping pong, since everyone else quit! 🎉&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;massive-scale-with-slurm&#34;&gt;Massive Scale with Slurm&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Now, imagine that we want to run this across hundreds of CPUs. Slurm makes this trivial as long as you have enough systems in your cluster to support this work.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In Slurm, you can define a batch job with a shell script (&lt;em&gt;e.g. /shared_storage/mpi-ping-pong.slurm&lt;/em&gt;) that looks something like this:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;#!/bin/bash&#xA;&#xA;#SBATCH -J mpi-ping-pong                         # Name the job&#xA;#SBATCH -o /shared_storage/mpi-ping-pong-%j.out  # The standard output file&#xA;#SBATCH -e /shared_storage/mpi-ping-pong-%j.err  # The standard error file&#xA;#SBATCH -t 0-2:00:00         # Run for a max time of 0d, 2h, 0m, 0s&#xA;#SBATCH --nodes=3            # Request 3 nodes&#xA;#SBATCH --ntasks-per-node=1  # Request 1 cores or task per node&#xA;&#xA;echo &#34;Date start                = $(date)&#34;&#xA;echo &#34;Initiating Host           = $(hostname)&#34;&#xA;echo &#34;Working Directory         = $(pwd)&#34;&#xA;echo &#34;&#34;&#xA;echo &#34;Number of Nodes Allocated = ${SLURM_JOB_NUM_NODES}&#34;&#xA;echo &#34;Number of Tasks Allocated = ${SLURM_NTASKS}&#34;&#xA;echo &#34;&#34;&#xA;&#xA;mpirun python /shared_storage/mpi-ping-pong.py&#xA;RETURN=${?}&#xA;&#xA;echo &#34;&#34;&#xA;echo &#34;Exit code                 = ${RETURN}&#34;&#xA;echo &#34;Date end                  = $(date)&#34;&#xA;echo &#34;&#34;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Each&amp;nbsp;&lt;code&gt;#SBATCH&lt;/code&gt;&amp;nbsp;line defines an&amp;nbsp;&lt;a href=&#34;https://slurm.schedmd.com/sbatch.html&#34;&gt;&lt;code&gt;sbatch&lt;/code&gt;&lt;/a&gt;&amp;nbsp;command line argument to be used for the job. In this case, we are going to request that the workload run on three nodes and that it will only use a single core on each node.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Assuming that all the compute nodes in our cluster are configured correctly and our Python script exists on the shared storage at&amp;nbsp;&lt;em&gt;/shared_storage/mpi-ping-pong.py&lt;/em&gt;&amp;nbsp;then we can submit this job to the cluster, by running:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;$ sbatch /shared_storage/mpi-ping-pong.slurm&#xA;&#xA;Submitted batch job 87&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This job will run very fast, but if we needed to we could use commands like&amp;nbsp;&lt;code&gt;squeue&lt;/code&gt;&amp;nbsp;and&amp;nbsp;&lt;code&gt;sinfo&lt;/code&gt;&amp;nbsp;to examine the state of the cluster and jobs while it was running.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;When the job is finished we can look at&amp;nbsp;&lt;code&gt;/shared_storage/mpi-ping-pong-87.err&lt;/code&gt;&amp;nbsp;and&amp;nbsp;&lt;code&gt;/shared_storage/mpi-ping-pong-87.out&lt;/code&gt;&amp;nbsp;to see all the output from our application. In this case, the error file is empty, but our output file looks like this:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;Date start                = Tue May 14 10:15:02 PM UTC 2024&#xA;Initiating Host           = worker-0&#xA;Working Directory         = /shared_storage&#xA;&#xA;Number of Nodes Allocated = 3&#xA;Number of Tasks Allocated = 3&#xA;&#xA;Hello, World! I am 🏓 Player (Rank)  1 . Process  2  of  3  on  worker-1&#xA;Player (Rank)  1 &#39;s receiving 🏓 neighbor is Player (Rank) 0 and my sending 🏓 neighbor is Player (Rank) 2.&#xA;Hello, World! I am 🏓 Player (Rank)  2 . Process  3  of  3  on  worker-2&#xA;Player (Rank)  2 &#39;s receiving 🏓 neighbor is Player (Rank) 1 and my sending 🏓 neighbor is Player (Rank) 0.&#xA;Hello, World! I am 🏓 Player (Rank)  0 . Process  1  of  3  on  worker-0&#xA;Player (Rank)  0 &#39;s receiving 🏓 neighbor is Player (Rank) 2 and my sending 🏓 neighbor is Player (Rank) 1.&#xA;Player 0 sent the 🏓 ball to Player 1.&#xA;Player 1 received the 🏓 ball from Player 0.&#xA;Player 1 sent the 🏓 ball to Player 2.&#xA;Player 2 received the 🏓 ball from Player 1.&#xA;Player 2 sent the 🏓 ball to Player 0.&#xA;Player 0 received the 🏓 ball from Player 2.&#xA;Player 0 started round 2 by sending the 🏓 ball to Player 1.&#xA;…&#xA;Player 0 started round 900 by sending the 🏓 ball to Player 1.&#xA;🛑 Player 0 is bored of 🏓 ping pong and is quitting! 🛑&#xA;Player 1 received the 🏓 ball from Player 0.&#xA;Player 1 sent the 🏓 ball to Player 2.&#xA;🛑 Player 1 is bored of 🏓 ping pong and is quitting! 🛑&#xA;Player 2 received the 🏓 ball from Player 1.&#xA;🎉 Player 2 won the game of 🏓 ping pong, since everyone else quit! 🎉&#xA;&#xA;Exit code                 = 0&#xA;Date end                  = Tue May 14 10:15:03 PM UTC 2024&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you look closely at the&amp;nbsp;&lt;code&gt;Hello, World!&lt;/code&gt;&amp;nbsp;lines for each rank/process you will notice that they are all running on completely different nodes (&lt;em&gt;worker-[0-2]&lt;/em&gt;), but the application still behaves exactly as we expect it to, and the messages are happily passed between each process running on a different core on different systems. Because of this, we could use Slurm to easily run our application across hundreds or even thousands of cores if that is what we needed.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;kubernetes&#34;&gt;Kubernetes&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;So, could we do all of this with Kubernetes today? Well, yes and no.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The real power of Slurm is that you have so much control over how it is built, how you assign resources to your workloads, and how they are partitioned while running.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;mpi---message-passing-interface&#34;&gt;MPI – Message Passing Interface&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Although you could easily run this application inside a single pod on Kubernetes, to truly leverage the MPI capabilities that we are expecting we would need to install and utilize something like&amp;nbsp;&lt;a href=&#34;https://www.kubeflow.org/&#34;&gt;KubeFlow&lt;/a&gt;&amp;nbsp;along with&amp;nbsp;&lt;a href=&#34;https://github.com/kubeflow/mpi-operator&#34;&gt;KubeFlow’s beta MPI Operator&lt;/a&gt;&amp;nbsp;to even get started. You might also want to consider something like the&amp;nbsp;&lt;a href=&#34;https://kueue.sigs.k8s.io/&#34;&gt;Kubernetes-native Job Queueing support&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p class=&#34;has-normal-font-size&#34;&gt;At the time of writing this&amp;nbsp;&lt;a href=&#34;https://github.com/kubeflow/manifests/tree/v1.8.0?tab=readme-ov-file#prerequisites&#34;&gt;KubeFlow v.1.8.0 doesn’t support versions of Kubernetes greater than v1.26&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;One obvious side effect of using Kubernetes is that we&amp;nbsp;&lt;strong&gt;MUST&lt;/strong&gt;&amp;nbsp;run our code inside one or more containers. This is possible with Slurm but is not a hard requirement. We will also need to ensure that Python, MPI, and&amp;nbsp;&lt;code&gt;sshd&lt;/code&gt;&amp;nbsp;are all installed and configured correctly in our container, as we will need them all to run our application and manage each of the MPI worker pods.&amp;nbsp;&lt;code&gt;sshd&lt;/code&gt;&amp;nbsp;is required because this is how&amp;nbsp;&lt;code&gt;mpirun&lt;/code&gt;&amp;nbsp;will connect to each of the pods to launch the parallel instances of our application. The manifest that we will need to apply to our Kubernetes cluster for use with&amp;nbsp;&lt;code&gt;mpi-operator&lt;/code&gt;&amp;nbsp;is simply named&amp;nbsp;&lt;a href=&#34;https://github.com/superorbital/mpi-playground/blob/main/manifests/mpi-ping-pong/mpijob.yaml&#34;&gt;mpijob.yaml&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p class=&#34;has-normal-font-size&#34;&gt;You can also find&amp;nbsp;&lt;a href=&#34;https://github.com/superorbital/mpi-playground/blob/main/containers/mpi-ping-pong/Dockerfile&#34;&gt;the Dockerfile for the container that we are running&lt;/a&gt;&amp;nbsp;in&amp;nbsp;&lt;a href=&#34;https://github.com/superorbital/mpi-playground&#34;&gt;the GitHub repo&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;mpijob.yaml&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;em&gt;&lt;/em&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Assuming that Kubeflow and the mpi-operator are properly installed in our cluster, then applying the&amp;nbsp;&lt;strong&gt;MPIJob&lt;/strong&gt;&amp;nbsp;manifest should “just work”.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;$ git clone https://github.com/superorbital/mpi-playground.git&#xA;$ cd mpi-playground&#xA;$ kubectl apply -f ./manifests/mpi-ping-pong/mpijob.yaml&#xA;mpijob.kubeflow.org/mpi-ping-pong created&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p class=&#34;has-normal-font-size&#34;&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: If you want to try this out yourself, you will likely find that it is easiest to delete the&amp;nbsp;&lt;strong&gt;MPIJob&lt;/strong&gt;&amp;nbsp;and then re-apply it each time you want to run it.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p class=&#34;has-normal-font-size&#34;&gt;&lt;code&gt;kubectl delete mpijobs.kubeflow.org mpi-ping-pong&lt;/code&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In the animated GIF below you will see the manifest being launched, followed by the launcher and worker pods being spun up, once the workers are done, then the launcher will complete and the launcher logs will be displayed.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/demo.gif&#34; alt=&#34;MPI Ping Pong in Kubernetes demo&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The sequence of events looks something like this:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;The required number of workers are started and&amp;nbsp;&lt;code&gt;sshd&lt;/code&gt;&amp;nbsp;is run inside each worker container.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;The launcher is started and executes the desired&amp;nbsp;&lt;code&gt;mpirun&lt;/code&gt;&amp;nbsp;command.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;code&gt;mpirun&lt;/code&gt;&amp;nbsp;connects to each worker and starts the individual tasks.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;The workers complete their tasks and exit.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;The launcher completes and exits.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The pod logs for the launcher will contain all of the output that we would normally expect to see from an&amp;nbsp;&lt;code&gt;mpirun&lt;/code&gt;&amp;nbsp;session.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;So, today it is technically possible to run at least some MPI-style jobs inside Kubernetes, but how practical is it?&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Well, one of the big advantages of Kubernetes is its ability to scale. Unlike Slurm, which has no cluster scaling functionality, a Kubernetes cluster can be designed to scale up nodes for a very large workflow and then scale back down once that workflow is finished and those nodes are no longer required for any immediately upcoming workflows.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;But, I think the real answer here is that it depends a lot on what you are trying to do, how much control you have over the Kubernetes cluster setup, and how much effort you want to put into getting it all working.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;artificial-intelligence-and-machine-learning&#34;&gt;Artificial Intelligence and Machine Learning&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Although the technical details are different, most of the basic observations in this article also apply to artificial intelligence (AI&lt;sup&gt;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fn:ai&#34;&gt;11&lt;/a&gt;&lt;/sup&gt;), machine learning (ML&lt;sup&gt;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fn:ml&#34;&gt;12&lt;/a&gt;&lt;/sup&gt;), and deep learning (DL&lt;sup&gt;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fn:dl&#34;&gt;13&lt;/a&gt;&lt;/sup&gt;) applications. In most instances, these workloads will make heavy use of systems equipped with advanced GPUs to significantly improve the performance of their computation tasks. Ensuring that each process has exclusive access to the required hardware resources is often critical for the success and performance of the task.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;slurm-on-kubernetes&#34;&gt;Slurm on Kubernetes&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Over the last couple of years,&amp;nbsp;&lt;a href=&#34;https://www.linkedin.com/in/timwickberg/&#34;&gt;Tim Wickberg, SchedMD’s CTO&lt;/a&gt;, has given a talk entitled “&lt;a href=&#34;https://slurm.schedmd.com/SC23/Slurm-and-or-vs-Kubernetes.pdf&#34;&gt;Slurm and/or/vs Kubernetes&lt;/a&gt;”, which looks at Slurm and Kubernetes and explores how each of these tools could be extended to leverage their strengths and generally improve the current state of high-performance workload managers.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;One project that has come out of the effort to find synergy between these two tools and communities, is&amp;nbsp;&lt;a href=&#34;https://www.coreweave.com/blog/sunk-slurm-on-kubernetes-implementations&#34;&gt;SUNK&lt;/a&gt;, which stands for&amp;nbsp;&lt;em&gt;&lt;strong&gt;S&lt;/strong&gt;l&lt;strong&gt;U&lt;/strong&gt;rm o&lt;strong&gt;N&lt;/strong&gt;&amp;nbsp;&lt;strong&gt;K&lt;/strong&gt;ubernetes&lt;/em&gt;. It is a project in early development by&amp;nbsp;&lt;a href=&#34;https://www.schedmd.com/&#34;&gt;SchedMD&lt;/a&gt;&amp;nbsp;and&amp;nbsp;&lt;a href=&#34;https://www.coreweave.com/&#34;&gt;CoreWeave&lt;/a&gt;&amp;nbsp;to enable Slurm workloads in Kubernetes Clusters.&amp;nbsp;&lt;a href=&#34;https://www.youtube.com/watch?v=48ONt0UKiew&#34;&gt;The CoreWeave talk that officially introduced this project can viewed on YouTube&lt;/a&gt;&amp;nbsp;if you would like to hear more details about the work that is being done with this. You can also grab&amp;nbsp;&lt;a href=&#34;https://slurm.schedmd.com/SLUG23/CoreWeave-SLUG23.pdf&#34;&gt;a PDF of the slides&lt;/a&gt;&amp;nbsp;for the talk. Once the code is released it should be available at&amp;nbsp;&lt;a href=&#34;https://github.com/coreweave/sunk&#34;&gt;github.com/coreweave/sunk&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;kubernetes-device-management&#34;&gt;Kubernetes Device Management&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The&amp;nbsp;&lt;a href=&#34;https://community.arm.com/arm-research/b/articles/posts/a-smarter-device-manager-for-kubernetes-on-the-edge&#34;&gt;Smarter Device Project&lt;/a&gt;&amp;nbsp;from&amp;nbsp;&lt;a href=&#34;https://www.arm.com/resources/research&#34;&gt;ARM research&lt;/a&gt;&lt;sup&gt;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fn:arm&#34;&gt;14&lt;/a&gt;&lt;/sup&gt;&amp;nbsp;is also an interesting&amp;nbsp;&lt;a href=&#34;https://github.com/smarter-project/smarter-device-manager&#34;&gt;Kubernetes application&lt;/a&gt;&amp;nbsp;that might be useful for these sorts of workloads and makes it possible to expose, reserve, and manage any Linux device (&lt;em&gt;e.g. /dev/video*&lt;/em&gt;) within Kubernetes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For GPUs,&amp;nbsp;&lt;a href=&#34;https://catalog.ngc.nvidia.com/orgs/nvidia/containers/k8s-device-plugin&#34;&gt;NVIDIA has a device plugin&lt;/a&gt;&amp;nbsp;to provide similar functionality, which is often deployed along with their&amp;nbsp;&lt;a href=&#34;https://github.com/NVIDIA/gpu-operator&#34;&gt;gpu-operator&lt;/a&gt;. This also enables features in Kubernetes like GPU time-slicing, something similar to the generic&amp;nbsp;&lt;a href=&#34;https://slurm.schedmd.com/gres.html#Sharding&#34;&gt;GPU sharding&lt;/a&gt;&amp;nbsp;available in Slurm.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;in-conclusion&#34;&gt;In Conclusion&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Slurm is a very useful tool for running parallel applications that require very specific resources inside a compute cluster. It was designed for a set of workloads that are outside the standard stateless microservice focus of Kubernetes, but even today Kubernetes can be made to work with some of these workloads without too much hassle, however, truly leveraging the advantages of Kubernetes for these more traditional high-performance computing workloads will require projects like SUNK and&amp;nbsp;&lt;code&gt;mpi-operator&lt;/code&gt;&amp;nbsp;to reach a reasonable level of maturity and then in the future, there may be newer projects that rethink the current approaches and build Kubernetes-first tools from the ground-up that leverage the strengths that are already available in the platform while extending its ability to handle the type of workloads that have been traditionally handled by tools like Slurm.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;further-reading&#34;&gt;Further Reading&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://mitsloan.mit.edu/ideas-made-to-matter/machine-learning-explained&#34;&gt;Machine learning, explained&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.geeksforgeeks.org/machine-learning/&#34;&gt;Machine Learning Tutorial&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://carleton.ca/rcs/rcdc/introduction-to-mpi/&#34;&gt;Introduction to MPI&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://mpitutorial.com/&#34;&gt;A Comprehensive MPI Tutorial Resource&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Intro to Multi-Node Machine Learning&lt;/strong&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.unitary.ai/articles/intro-to-multi-node-machine-learning-1-setting-up-an-hpc-cluster&#34;&gt;1: Setting up an HPC cluster&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.unitary.ai/articles/intro-to-multi-node-machine-learning-2-using-slurm&#34;&gt;2: Using Slurm&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;em&gt;Unreleased as of 05/16/2024&lt;/em&gt;&amp;nbsp;–&amp;nbsp;&lt;a href=&#34;https://www.unitary.ai/articles/intro-to-multi-node-machine-learning-3-multi-node-training&#34;&gt;3: Multi-Node Training&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.kubeflow.org/integrations/operators/2020/03/16/mpi-operator.html&#34;&gt;Introduction to Kubeflow MPI Operator and Industry Adoption&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;acknowledgments&#34;&gt;Acknowledgments&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;ul&gt;&#xA;&lt;li class=&#34;has-normal-font-size&#34;&gt;Cover image by&amp;nbsp;&lt;a href=&#34;https://pixabay.com/users/dlohner-4631193/?utm_source=link-attribution&amp;amp;utm_medium=referral&amp;amp;utm_campaign=image&amp;amp;utm_content=3100049&#34;&gt;dlohner&lt;/a&gt;&amp;nbsp;from&amp;nbsp;&lt;a href=&#34;https://pixabay.com//?utm_source=link-attribution&amp;amp;utm_medium=referral&amp;amp;utm_campaign=image&amp;amp;utm_content=3100049&#34;&gt;Pixabay&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li class=&#34;has-normal-font-size&#34;&gt;Slurm architecture overview by SchedMD for their&amp;nbsp;&lt;a href=&#34;https://slurm.schedmd.com/network.html&#34;&gt;network overview&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;footnotes&#34;&gt;Footnotes&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/High-performance_computing&#34;&gt;HPC – high-performance computing&lt;/a&gt;&amp;nbsp;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fnref:hpc&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Lawrence_Livermore_National_Laboratory&#34;&gt;LLNL – Lawrence Livermore National Laboratory&lt;/a&gt;&amp;nbsp;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fnref:llnl&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.schedmd.com/about-schedmd/slurm-history&#34;&gt;Slurm history&lt;/a&gt;&amp;nbsp;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fnref:history&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Graphics_processing_unit&#34;&gt;GPU – graphics processing unit&lt;/a&gt;&amp;nbsp;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fnref:gpu&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://developer.nvidia.com/cuda-toolkit&#34;&gt;CUDA® – Compute Unified Device Architecture&lt;/a&gt;&amp;nbsp;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fnref:cuda&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://developer.nvidia.com/cudnn&#34;&gt;cuDNN – NVIDIA CUDA® Deep Neural Network library&lt;/a&gt;&amp;nbsp;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fnref:cudnn&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.open-mpi.org/&#34;&gt;MPI – Message Passing Interface&lt;/a&gt;&amp;nbsp;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fnref:mpi&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Open_Container_Initiative&#34;&gt;OCI – Open Container Initiative&lt;/a&gt;&amp;nbsp;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fnref:oci&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.uio.no/studier/emner/matnat/ifi/INF3380/v11/undervisningsmateriale/inf3380-week06.pdf&#34;&gt;Rank&lt;/a&gt;&amp;nbsp;– Each process has a unique rank, i.e. an integer identifier, within a communicator. The rank value is between zero and the number of processes minus one. The rank value is used to distinguish one process from another.&amp;nbsp;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fnref:rank&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Central_processing_unit&#34;&gt;CPU – central processing unit&lt;/a&gt;&amp;nbsp;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fnref:cpu&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.ibm.com/topics/artificial-intelligence&#34;&gt;AI – Artificial Intelligence&lt;/a&gt;&amp;nbsp;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fnref:ai&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.ibm.com/topics/machine-learning&#34;&gt;ML – Machine Learning&lt;/a&gt;&amp;nbsp;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fnref:ml&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.ibm.com/topics/deep-learning&#34;&gt;DL – Deep Learning&lt;/a&gt;&amp;nbsp;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fnref:dl&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/ARM_architecture_family&#34;&gt;ARM – Advanced RISC Machine&lt;/a&gt;&amp;nbsp;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fnref:arm&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;Member post originally published on &lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/&#34;&gt;SuperOrbital’s blog&lt;/a&gt; by Sean Kane&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/cover.jpg&#34; alt=&#34;datacenter servers&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In this article, we are going to explore&amp;nbsp;&lt;a href=&#34;https://github.com/SchedMD/slurm&#34;&gt;Slurm&lt;/a&gt;, a popular open-source high-performance computing (HPC&lt;sup&gt;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fn:hpc&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;) workload manager, and discover what it is, why people use it, and how it differs from Kubernetes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For context, when we talk about high-performance computing, we are primarily talking about computational tasks that require a lot of time on very powerful computer systems and are often designed, so that they can be&amp;nbsp;&lt;a href=&#34;https://en.wikipedia.org/wiki/Parallel_computing&#34;&gt;highly parallelized&lt;/a&gt;, across resources within a super-computer or large cluster.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;These sorts of jobs are very common in scientific research,&amp;nbsp;&lt;a href=&#34;https://en.wikipedia.org/wiki/Computer_simulation&#34;&gt;computer simulation&lt;/a&gt;,&amp;nbsp;&lt;a href=&#34;https://en.wikipedia.org/wiki/Artificial_intelligence&#34;&gt;artificial intelligence&lt;/a&gt;, and&amp;nbsp;&lt;a href=&#34;https://en.wikipedia.org/wiki/Machine_learning&#34;&gt;machine learning&lt;/a&gt;&amp;nbsp;tasks.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;what-is-slurm&#34;&gt;What is Slurm?&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To almost directly quote the Slurm repository&amp;nbsp;&lt;a href=&#34;https://github.com/SchedMD/slurm/blob/master/README.rst#slurm-workload-manager&#34;&gt;README&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p class=&#34;has-normal-font-size&#34;&gt;Slurm is an open-source cluster resource management and job scheduling system for Linux (&lt;em&gt;primarily&lt;/em&gt;) that strives to be simple, scalable, portable, fault-tolerant, and interconnect agnostic. As a cluster resource manager, Slurm provides three key functions:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li class=&#34;has-normal-font-size&#34;&gt;First, it allocates exclusive and/or non-exclusive access to resources (compute nodes) to users for some duration of time so they can perform work.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li class=&#34;has-normal-font-size&#34;&gt;Second, it provides a framework for starting, executing, and monitoring work (&lt;em&gt;normally a parallel job&lt;/em&gt;) on the set of allocated nodes.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li class=&#34;has-normal-font-size&#34;&gt;And finally, it arbitrates conflicting requests for resources by managing a queue of pending work.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In short, Slurm is a system that is primarily designed to manage&amp;nbsp;&lt;a href=&#34;https://en.wikipedia.org/wiki/Batch_processing&#34;&gt;batch processing&lt;/a&gt;&amp;nbsp;workloads running in a shared&amp;nbsp;&lt;a href=&#34;https://en.wikipedia.org/wiki/Computer_cluster&#34;&gt;computing cluster&lt;/a&gt;. Slurm can be configured to run any type of batch job but is often utilized on systems that support multiple users with parallel computing tasks to run.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;According to&amp;nbsp;&lt;a href=&#34;https://www.schedmd.com/&#34;&gt;SchedMD&lt;/a&gt;, the primary support and development company for the Slurm community, Slurm is being used on approximately 65% of the&amp;nbsp;&lt;a href=&#34;https://top500.org/lists/top500/2024/06/&#34;&gt;TOP500 supercomputers in the world&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;a-bit-of-history&#34;&gt;A bit of history&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In the mid-1990s, as Linux became more popular, there was an increased interest in making large-scale computer processing more accessible through the use of commodity hardware and projects like&amp;nbsp;&lt;a href=&#34;https://en.wikipedia.org/wiki/Beowulf_cluster&#34;&gt;Beowulf&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In 2001, engineers at the&amp;nbsp;&lt;a href=&#34;https://www.llnl.gov/&#34;&gt;Lawrence Livermore National Laboratory&lt;/a&gt;&amp;nbsp;(LLNL&lt;sup&gt;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fn:llnl&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;) in the United States, started looking into how they might migrate from proprietary HPC systems to open-source solutions. They determined that there weren’t any good resource managers available at the time, and this directly led to the creation of Slurm, which was initially released in 2002.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p class=&#34;has-normal-font-size&#34;&gt;&lt;a href=&#34;https://slurm.schedmd.com/slurm_design.pdf&#34;&gt;The name Slurm is a reference&lt;/a&gt;&amp;nbsp;to the&amp;nbsp;&lt;a href=&#34;https://futurama.fandom.com/wiki/Slurm&#34;&gt;soda&lt;/a&gt;&amp;nbsp;in&amp;nbsp;&lt;a href=&#34;https://www.imdb.com/title/tt0149460/&#34;&gt;Futurama&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Over the years, Slurm has evolved to support a wide variety of hardware configurations and in 2010, some initial scheduling logic was added to Slurm, enabling it to function as both a stand-alone resource manager and a scheduler&lt;sup&gt;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fn:history&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;the-architecture&#34;&gt;The Architecture&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Like many similar systems, a Slurm setup consists of at least one controller node, and at least one compute node, which can be on the same physical systems.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/slurm-layout.gif&#34; alt=&#34;Diagram of the basic Slurm architecture&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;the-controller&#34;&gt;The Controller&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Two daemons are responsible for managing the cluster. These two processes can be run on a single node or separated, depending on the performance and resiliency required by the administrator.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34; id=&#34;slurmctld&#34;&gt;slurmctld&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;code&gt;slurmctld&lt;/code&gt;&amp;nbsp;is the primary management daemon for Slurm. It is responsible for all the daemons, resources, and jobs, within the cluster. Because it is a critical component in the cluster, it is often configured with a passive backup that can take over management if the primary daemon ever fails.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34; id=&#34;slurmdbd&#34;&gt;slurmdbd&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;code&gt;slurmdbd&lt;/code&gt;&amp;nbsp;provides an interface for the&amp;nbsp;&lt;a href=&#34;https://en.wikipedia.org/wiki/MySQL&#34;&gt;MySQL database&lt;/a&gt;&amp;nbsp;that Slurm uses for stateful data, like job accounting records.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;compute-nodes&#34;&gt;Compute Nodes&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;These represent the nodes whose resources are available to any jobs that might need to be scheduled in the cluster.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34; id=&#34;slurmd&#34;&gt;slurmd&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;code&gt;slurmd&lt;/code&gt;&amp;nbsp;is the daemon that runs on each compute node and is responsible for accepting work, launching tasks, and generally managing the workloads on each node.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;installation&#34;&gt;Installation&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;SchedMD maintains the core documentation for Slurm and the&amp;nbsp;&lt;a href=&#34;https://slurm.schedmd.com/quickstart_admin.html#quick_start&#34;&gt;current installation documentation&lt;/a&gt;&amp;nbsp;can be found on their website.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Getting Slurm working is not particularly difficult, but fine-tuning it for your requirements can be a time-consuming task. Since performance is often a primary focus with these clusters and Slurm is designed to work with a very wide set of hardware and software libraries, it can take a lot of effort to fine-tune the installation, so that it utilizes the hardware to the best of its ability, and all the proper software is available to streamline the types of jobs that will be run on the cluster.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;At a minimum clusters will require node name resolution, a MySQL instance, shared block storage, a synchronized time source, synchronized users, the&amp;nbsp;&lt;a href=&#34;https://dun.github.io/munge/&#34;&gt;Munge&lt;/a&gt;&amp;nbsp;daemon for user authentication, a full set of custom-built Slurm executables, and various configuration files.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In addition to this, the nodes will need to contain the various hardware, programming languages, libraries, and other tools that the majority of jobs will require to run. This could include things like GPUs&lt;sup&gt;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fn:gpu&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;&amp;nbsp;and their related toolchains (CUDA&lt;sup&gt;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fn:cuda&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;/cuDNN&lt;sup&gt;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fn:cudnn&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;), MPI&lt;sup&gt;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fn:mpi&#34;&gt;7&lt;/a&gt;&lt;/sup&gt;&amp;nbsp;libraries, OCI&lt;sup&gt;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fn:oci&#34;&gt;8&lt;/a&gt;&lt;/sup&gt;&amp;nbsp;runtimes for&amp;nbsp;&lt;a href=&#34;https://slurm.schedmd.com/containers.html&#34;&gt;container support&lt;/a&gt;, and much more.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Slurm’s greatest asset and liability is how flexible it is. This makes it something that can be highly optimized for the requirements of the organization, while also making it susceptible to misconfiguration.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;workloads&#34;&gt;Workloads&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To provide some context, let’s take a look at an example user job and workflow that utilizes some of the features of Slurm.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In the&amp;nbsp;&lt;code&gt;mpi-ping-pong.py&lt;/code&gt;&amp;nbsp;code below, you will find a&amp;nbsp;&lt;a href=&#34;https://www.python.org/&#34;&gt;Python&lt;/a&gt;&amp;nbsp;script that simulates a pseudo-game of&amp;nbsp;&lt;a href=&#34;https://en.wikipedia.org/wiki/Table_tennis&#34;&gt;Ping Pong/Table Tennis&lt;/a&gt;&amp;nbsp;by making use of MPI to pass a message (&lt;em&gt;“ball”&lt;/em&gt;) between as many processes as we have configured to participate in the parallel job.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;local-testing&#34;&gt;Local Testing&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To run this code, you simply need to have&amp;nbsp;&lt;a href=&#34;https://www.python.org/downloads/&#34;&gt;Python&lt;/a&gt;,&amp;nbsp;&lt;a href=&#34;https://docs.open-mpi.org/en/v5.0.x/installing-open-mpi/quickstart.html&#34;&gt;OpenMPI&lt;/a&gt;, and&amp;nbsp;&lt;a href=&#34;https://mpi4py.readthedocs.io/en/stable/install.html&#34;&gt;mpi4py&lt;/a&gt;&amp;nbsp;installed on your system.mpi-ping-pong.py&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/superorbital/mpi-playground/blob/main/containers/mpi-ping-pong/mpi-ping-pong.py&#34;&gt;mpi-ping-pong.py&lt;/a&gt;&amp;nbsp;is what many would refer to as an&amp;nbsp;&lt;a href=&#34;https://en.wikipedia.org/wiki/Embarrassingly_parallel&#34;&gt;embarrassingly parallel&lt;/a&gt;&amp;nbsp;workload because it can be scaled with no real effort at all.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you run this Python application on your local system, you will see something like this:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;$ python ./mpi-ping-pong.py&#xA;&#xA;Hello, World! I am 🏓 Player (Rank)  0 . Process  1  of  1  on  laptop.local&#xA;Player (Rank)  0 &#39;s receiving 🏓 neighbor is Player (Rank) 0 and my sending 🏓 neighbor is Player (Rank) 0.&#xA;Player 0 started round 1 by hitting the 🏓 ball towards the wall.&#xA;Player 0 received the 🏓 ball that bounced off the wall.&#xA;Player 0 started round 2 by hitting the 🏓 ball towards the wall.&#xA;Player 0 received the 🏓 ball that bounced off the wall.&#xA;…&#xA;Player 0 started round 299 by hitting the 🏓 ball towards the wall.&#xA;Player 0 received the 🏓 ball that bounced off the wall.&#xA;🎉 Player 0 won the game of 🏓 ping pong, since they were playing alone! 🎉&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As you can see the application runs perfectly fine, and uses a single rank&lt;sup&gt;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fn:rank&#34;&gt;9&lt;/a&gt;&lt;/sup&gt;/process (&lt;em&gt;CPU&lt;sup&gt;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fn:cpu&#34;&gt;10&lt;/a&gt;&lt;/sup&gt;&amp;nbsp;core, in this case&lt;/em&gt;). Since we only have a single process participating in this game of Ping Pong, the program simply sends and receives messages to and from from itself.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;However, assuming that we have at least two CPU cores, then we can run this application utilizing as many of them as we want, by leveraging the MPI command line tool&amp;nbsp;&lt;code&gt;mpirun&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To run 12 instances of our application, which will all communicate with each other in parallel across 12 cores on our system, we can do the following on our local system:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p class=&#34;has-normal-font-size&#34;&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: These messages will be somewhat out of order. This is the nature of parallel computing, buffers, etc. To deal with this you would likely need to send all the messages back to single process for ordering and printing.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;$ mpirun -np 12 ./mpi-ping-pong.py&#xA;&#xA;Player (Rank)  0 &#39;s receiving 🏓 neighbor is Player (Rank) 11 and my sending 🏓 neighbor is Player (Rank) 1.&#xA;Hello, World! I am 🏓 Player (Rank)  0 . Process  1  of  12  on  laptop.local&#xA;Player (Rank)  1 &#39;s receiving 🏓 neighbor is Player (Rank) 0 and my sending 🏓 neighbor is Player (Rank) 2.&#xA;Hello, World! I am 🏓 Player (Rank)  1 . Process  2  of  12  on  laptop.local&#xA;Player (Rank)  2 &#39;s receiving 🏓 neighbor is Player (Rank) 1 and my sending 🏓 neighbor is Player (Rank) 3.&#xA;Hello, World! I am 🏓 Player (Rank)  2 . Process  3  of  12  on  laptop.local&#xA;…&#xA;🛑 Player 0 is bored of 🏓 ping pong and is quitting! 🛑&#xA;🛑 Player 1 is bored of 🏓 ping pong and is quitting! 🛑&#xA;🛑 Player 2 is bored of 🏓 ping pong and is quitting! 🛑&#xA;…&#xA;🎉 Player 11 won the game of 🏓 ping pong, since everyone else quit! 🎉&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;massive-scale-with-slurm&#34;&gt;Massive Scale with Slurm&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Now, imagine that we want to run this across hundreds of CPUs. Slurm makes this trivial as long as you have enough systems in your cluster to support this work.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In Slurm, you can define a batch job with a shell script (&lt;em&gt;e.g. /shared_storage/mpi-ping-pong.slurm&lt;/em&gt;) that looks something like this:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;#!/bin/bash&#xA;&#xA;#SBATCH -J mpi-ping-pong                         # Name the job&#xA;#SBATCH -o /shared_storage/mpi-ping-pong-%j.out  # The standard output file&#xA;#SBATCH -e /shared_storage/mpi-ping-pong-%j.err  # The standard error file&#xA;#SBATCH -t 0-2:00:00         # Run for a max time of 0d, 2h, 0m, 0s&#xA;#SBATCH --nodes=3            # Request 3 nodes&#xA;#SBATCH --ntasks-per-node=1  # Request 1 cores or task per node&#xA;&#xA;echo &#34;Date start                = $(date)&#34;&#xA;echo &#34;Initiating Host           = $(hostname)&#34;&#xA;echo &#34;Working Directory         = $(pwd)&#34;&#xA;echo &#34;&#34;&#xA;echo &#34;Number of Nodes Allocated = ${SLURM_JOB_NUM_NODES}&#34;&#xA;echo &#34;Number of Tasks Allocated = ${SLURM_NTASKS}&#34;&#xA;echo &#34;&#34;&#xA;&#xA;mpirun python /shared_storage/mpi-ping-pong.py&#xA;RETURN=${?}&#xA;&#xA;echo &#34;&#34;&#xA;echo &#34;Exit code                 = ${RETURN}&#34;&#xA;echo &#34;Date end                  = $(date)&#34;&#xA;echo &#34;&#34;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Each&amp;nbsp;&lt;code&gt;#SBATCH&lt;/code&gt;&amp;nbsp;line defines an&amp;nbsp;&lt;a href=&#34;https://slurm.schedmd.com/sbatch.html&#34;&gt;&lt;code&gt;sbatch&lt;/code&gt;&lt;/a&gt;&amp;nbsp;command line argument to be used for the job. In this case, we are going to request that the workload run on three nodes and that it will only use a single core on each node.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Assuming that all the compute nodes in our cluster are configured correctly and our Python script exists on the shared storage at&amp;nbsp;&lt;em&gt;/shared_storage/mpi-ping-pong.py&lt;/em&gt;&amp;nbsp;then we can submit this job to the cluster, by running:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;$ sbatch /shared_storage/mpi-ping-pong.slurm&#xA;&#xA;Submitted batch job 87&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This job will run very fast, but if we needed to we could use commands like&amp;nbsp;&lt;code&gt;squeue&lt;/code&gt;&amp;nbsp;and&amp;nbsp;&lt;code&gt;sinfo&lt;/code&gt;&amp;nbsp;to examine the state of the cluster and jobs while it was running.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;When the job is finished we can look at&amp;nbsp;&lt;code&gt;/shared_storage/mpi-ping-pong-87.err&lt;/code&gt;&amp;nbsp;and&amp;nbsp;&lt;code&gt;/shared_storage/mpi-ping-pong-87.out&lt;/code&gt;&amp;nbsp;to see all the output from our application. In this case, the error file is empty, but our output file looks like this:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;Date start                = Tue May 14 10:15:02 PM UTC 2024&#xA;Initiating Host           = worker-0&#xA;Working Directory         = /shared_storage&#xA;&#xA;Number of Nodes Allocated = 3&#xA;Number of Tasks Allocated = 3&#xA;&#xA;Hello, World! I am 🏓 Player (Rank)  1 . Process  2  of  3  on  worker-1&#xA;Player (Rank)  1 &#39;s receiving 🏓 neighbor is Player (Rank) 0 and my sending 🏓 neighbor is Player (Rank) 2.&#xA;Hello, World! I am 🏓 Player (Rank)  2 . Process  3  of  3  on  worker-2&#xA;Player (Rank)  2 &#39;s receiving 🏓 neighbor is Player (Rank) 1 and my sending 🏓 neighbor is Player (Rank) 0.&#xA;Hello, World! I am 🏓 Player (Rank)  0 . Process  1  of  3  on  worker-0&#xA;Player (Rank)  0 &#39;s receiving 🏓 neighbor is Player (Rank) 2 and my sending 🏓 neighbor is Player (Rank) 1.&#xA;Player 0 sent the 🏓 ball to Player 1.&#xA;Player 1 received the 🏓 ball from Player 0.&#xA;Player 1 sent the 🏓 ball to Player 2.&#xA;Player 2 received the 🏓 ball from Player 1.&#xA;Player 2 sent the 🏓 ball to Player 0.&#xA;Player 0 received the 🏓 ball from Player 2.&#xA;Player 0 started round 2 by sending the 🏓 ball to Player 1.&#xA;…&#xA;Player 0 started round 900 by sending the 🏓 ball to Player 1.&#xA;🛑 Player 0 is bored of 🏓 ping pong and is quitting! 🛑&#xA;Player 1 received the 🏓 ball from Player 0.&#xA;Player 1 sent the 🏓 ball to Player 2.&#xA;🛑 Player 1 is bored of 🏓 ping pong and is quitting! 🛑&#xA;Player 2 received the 🏓 ball from Player 1.&#xA;🎉 Player 2 won the game of 🏓 ping pong, since everyone else quit! 🎉&#xA;&#xA;Exit code                 = 0&#xA;Date end                  = Tue May 14 10:15:03 PM UTC 2024&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you look closely at the&amp;nbsp;&lt;code&gt;Hello, World!&lt;/code&gt;&amp;nbsp;lines for each rank/process you will notice that they are all running on completely different nodes (&lt;em&gt;worker-[0-2]&lt;/em&gt;), but the application still behaves exactly as we expect it to, and the messages are happily passed between each process running on a different core on different systems. Because of this, we could use Slurm to easily run our application across hundreds or even thousands of cores if that is what we needed.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;kubernetes&#34;&gt;Kubernetes&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;So, could we do all of this with Kubernetes today? Well, yes and no.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The real power of Slurm is that you have so much control over how it is built, how you assign resources to your workloads, and how they are partitioned while running.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;mpi---message-passing-interface&#34;&gt;MPI – Message Passing Interface&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Although you could easily run this application inside a single pod on Kubernetes, to truly leverage the MPI capabilities that we are expecting we would need to install and utilize something like&amp;nbsp;&lt;a href=&#34;https://www.kubeflow.org/&#34;&gt;KubeFlow&lt;/a&gt;&amp;nbsp;along with&amp;nbsp;&lt;a href=&#34;https://github.com/kubeflow/mpi-operator&#34;&gt;KubeFlow’s beta MPI Operator&lt;/a&gt;&amp;nbsp;to even get started. You might also want to consider something like the&amp;nbsp;&lt;a href=&#34;https://kueue.sigs.k8s.io/&#34;&gt;Kubernetes-native Job Queueing support&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p class=&#34;has-normal-font-size&#34;&gt;At the time of writing this&amp;nbsp;&lt;a href=&#34;https://github.com/kubeflow/manifests/tree/v1.8.0?tab=readme-ov-file#prerequisites&#34;&gt;KubeFlow v.1.8.0 doesn’t support versions of Kubernetes greater than v1.26&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;One obvious side effect of using Kubernetes is that we&amp;nbsp;&lt;strong&gt;MUST&lt;/strong&gt;&amp;nbsp;run our code inside one or more containers. This is possible with Slurm but is not a hard requirement. We will also need to ensure that Python, MPI, and&amp;nbsp;&lt;code&gt;sshd&lt;/code&gt;&amp;nbsp;are all installed and configured correctly in our container, as we will need them all to run our application and manage each of the MPI worker pods.&amp;nbsp;&lt;code&gt;sshd&lt;/code&gt;&amp;nbsp;is required because this is how&amp;nbsp;&lt;code&gt;mpirun&lt;/code&gt;&amp;nbsp;will connect to each of the pods to launch the parallel instances of our application. The manifest that we will need to apply to our Kubernetes cluster for use with&amp;nbsp;&lt;code&gt;mpi-operator&lt;/code&gt;&amp;nbsp;is simply named&amp;nbsp;&lt;a href=&#34;https://github.com/superorbital/mpi-playground/blob/main/manifests/mpi-ping-pong/mpijob.yaml&#34;&gt;mpijob.yaml&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p class=&#34;has-normal-font-size&#34;&gt;You can also find&amp;nbsp;&lt;a href=&#34;https://github.com/superorbital/mpi-playground/blob/main/containers/mpi-ping-pong/Dockerfile&#34;&gt;the Dockerfile for the container that we are running&lt;/a&gt;&amp;nbsp;in&amp;nbsp;&lt;a href=&#34;https://github.com/superorbital/mpi-playground&#34;&gt;the GitHub repo&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;mpijob.yaml&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;em&gt;&lt;/em&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Assuming that Kubeflow and the mpi-operator are properly installed in our cluster, then applying the&amp;nbsp;&lt;strong&gt;MPIJob&lt;/strong&gt;&amp;nbsp;manifest should “just work”.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;$ git clone https://github.com/superorbital/mpi-playground.git&#xA;$ cd mpi-playground&#xA;$ kubectl apply -f ./manifests/mpi-ping-pong/mpijob.yaml&#xA;mpijob.kubeflow.org/mpi-ping-pong created&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p class=&#34;has-normal-font-size&#34;&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: If you want to try this out yourself, you will likely find that it is easiest to delete the&amp;nbsp;&lt;strong&gt;MPIJob&lt;/strong&gt;&amp;nbsp;and then re-apply it each time you want to run it.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p class=&#34;has-normal-font-size&#34;&gt;&lt;code&gt;kubectl delete mpijobs.kubeflow.org mpi-ping-pong&lt;/code&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In the animated GIF below you will see the manifest being launched, followed by the launcher and worker pods being spun up, once the workers are done, then the launcher will complete and the launcher logs will be displayed.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/demo.gif&#34; alt=&#34;MPI Ping Pong in Kubernetes demo&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The sequence of events looks something like this:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;The required number of workers are started and&amp;nbsp;&lt;code&gt;sshd&lt;/code&gt;&amp;nbsp;is run inside each worker container.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;The launcher is started and executes the desired&amp;nbsp;&lt;code&gt;mpirun&lt;/code&gt;&amp;nbsp;command.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;code&gt;mpirun&lt;/code&gt;&amp;nbsp;connects to each worker and starts the individual tasks.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;The workers complete their tasks and exit.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;The launcher completes and exits.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The pod logs for the launcher will contain all of the output that we would normally expect to see from an&amp;nbsp;&lt;code&gt;mpirun&lt;/code&gt;&amp;nbsp;session.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;So, today it is technically possible to run at least some MPI-style jobs inside Kubernetes, but how practical is it?&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Well, one of the big advantages of Kubernetes is its ability to scale. Unlike Slurm, which has no cluster scaling functionality, a Kubernetes cluster can be designed to scale up nodes for a very large workflow and then scale back down once that workflow is finished and those nodes are no longer required for any immediately upcoming workflows.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;But, I think the real answer here is that it depends a lot on what you are trying to do, how much control you have over the Kubernetes cluster setup, and how much effort you want to put into getting it all working.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;artificial-intelligence-and-machine-learning&#34;&gt;Artificial Intelligence and Machine Learning&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Although the technical details are different, most of the basic observations in this article also apply to artificial intelligence (AI&lt;sup&gt;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fn:ai&#34;&gt;11&lt;/a&gt;&lt;/sup&gt;), machine learning (ML&lt;sup&gt;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fn:ml&#34;&gt;12&lt;/a&gt;&lt;/sup&gt;), and deep learning (DL&lt;sup&gt;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fn:dl&#34;&gt;13&lt;/a&gt;&lt;/sup&gt;) applications. In most instances, these workloads will make heavy use of systems equipped with advanced GPUs to significantly improve the performance of their computation tasks. Ensuring that each process has exclusive access to the required hardware resources is often critical for the success and performance of the task.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;slurm-on-kubernetes&#34;&gt;Slurm on Kubernetes&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Over the last couple of years,&amp;nbsp;&lt;a href=&#34;https://www.linkedin.com/in/timwickberg/&#34;&gt;Tim Wickberg, SchedMD’s CTO&lt;/a&gt;, has given a talk entitled “&lt;a href=&#34;https://slurm.schedmd.com/SC23/Slurm-and-or-vs-Kubernetes.pdf&#34;&gt;Slurm and/or/vs Kubernetes&lt;/a&gt;”, which looks at Slurm and Kubernetes and explores how each of these tools could be extended to leverage their strengths and generally improve the current state of high-performance workload managers.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;One project that has come out of the effort to find synergy between these two tools and communities, is&amp;nbsp;&lt;a href=&#34;https://www.coreweave.com/blog/sunk-slurm-on-kubernetes-implementations&#34;&gt;SUNK&lt;/a&gt;, which stands for&amp;nbsp;&lt;em&gt;&lt;strong&gt;S&lt;/strong&gt;l&lt;strong&gt;U&lt;/strong&gt;rm o&lt;strong&gt;N&lt;/strong&gt;&amp;nbsp;&lt;strong&gt;K&lt;/strong&gt;ubernetes&lt;/em&gt;. It is a project in early development by&amp;nbsp;&lt;a href=&#34;https://www.schedmd.com/&#34;&gt;SchedMD&lt;/a&gt;&amp;nbsp;and&amp;nbsp;&lt;a href=&#34;https://www.coreweave.com/&#34;&gt;CoreWeave&lt;/a&gt;&amp;nbsp;to enable Slurm workloads in Kubernetes Clusters.&amp;nbsp;&lt;a href=&#34;https://www.youtube.com/watch?v=48ONt0UKiew&#34;&gt;The CoreWeave talk that officially introduced this project can viewed on YouTube&lt;/a&gt;&amp;nbsp;if you would like to hear more details about the work that is being done with this. You can also grab&amp;nbsp;&lt;a href=&#34;https://slurm.schedmd.com/SLUG23/CoreWeave-SLUG23.pdf&#34;&gt;a PDF of the slides&lt;/a&gt;&amp;nbsp;for the talk. Once the code is released it should be available at&amp;nbsp;&lt;a href=&#34;https://github.com/coreweave/sunk&#34;&gt;github.com/coreweave/sunk&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;kubernetes-device-management&#34;&gt;Kubernetes Device Management&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The&amp;nbsp;&lt;a href=&#34;https://community.arm.com/arm-research/b/articles/posts/a-smarter-device-manager-for-kubernetes-on-the-edge&#34;&gt;Smarter Device Project&lt;/a&gt;&amp;nbsp;from&amp;nbsp;&lt;a href=&#34;https://www.arm.com/resources/research&#34;&gt;ARM research&lt;/a&gt;&lt;sup&gt;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fn:arm&#34;&gt;14&lt;/a&gt;&lt;/sup&gt;&amp;nbsp;is also an interesting&amp;nbsp;&lt;a href=&#34;https://github.com/smarter-project/smarter-device-manager&#34;&gt;Kubernetes application&lt;/a&gt;&amp;nbsp;that might be useful for these sorts of workloads and makes it possible to expose, reserve, and manage any Linux device (&lt;em&gt;e.g. /dev/video*&lt;/em&gt;) within Kubernetes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For GPUs,&amp;nbsp;&lt;a href=&#34;https://catalog.ngc.nvidia.com/orgs/nvidia/containers/k8s-device-plugin&#34;&gt;NVIDIA has a device plugin&lt;/a&gt;&amp;nbsp;to provide similar functionality, which is often deployed along with their&amp;nbsp;&lt;a href=&#34;https://github.com/NVIDIA/gpu-operator&#34;&gt;gpu-operator&lt;/a&gt;. This also enables features in Kubernetes like GPU time-slicing, something similar to the generic&amp;nbsp;&lt;a href=&#34;https://slurm.schedmd.com/gres.html#Sharding&#34;&gt;GPU sharding&lt;/a&gt;&amp;nbsp;available in Slurm.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;in-conclusion&#34;&gt;In Conclusion&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Slurm is a very useful tool for running parallel applications that require very specific resources inside a compute cluster. It was designed for a set of workloads that are outside the standard stateless microservice focus of Kubernetes, but even today Kubernetes can be made to work with some of these workloads without too much hassle, however, truly leveraging the advantages of Kubernetes for these more traditional high-performance computing workloads will require projects like SUNK and&amp;nbsp;&lt;code&gt;mpi-operator&lt;/code&gt;&amp;nbsp;to reach a reasonable level of maturity and then in the future, there may be newer projects that rethink the current approaches and build Kubernetes-first tools from the ground-up that leverage the strengths that are already available in the platform while extending its ability to handle the type of workloads that have been traditionally handled by tools like Slurm.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;further-reading&#34;&gt;Further Reading&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://mitsloan.mit.edu/ideas-made-to-matter/machine-learning-explained&#34;&gt;Machine learning, explained&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.geeksforgeeks.org/machine-learning/&#34;&gt;Machine Learning Tutorial&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://carleton.ca/rcs/rcdc/introduction-to-mpi/&#34;&gt;Introduction to MPI&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://mpitutorial.com/&#34;&gt;A Comprehensive MPI Tutorial Resource&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Intro to Multi-Node Machine Learning&lt;/strong&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.unitary.ai/articles/intro-to-multi-node-machine-learning-1-setting-up-an-hpc-cluster&#34;&gt;1: Setting up an HPC cluster&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.unitary.ai/articles/intro-to-multi-node-machine-learning-2-using-slurm&#34;&gt;2: Using Slurm&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;em&gt;Unreleased as of 05/16/2024&lt;/em&gt;&amp;nbsp;–&amp;nbsp;&lt;a href=&#34;https://www.unitary.ai/articles/intro-to-multi-node-machine-learning-3-multi-node-training&#34;&gt;3: Multi-Node Training&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.kubeflow.org/integrations/operators/2020/03/16/mpi-operator.html&#34;&gt;Introduction to Kubeflow MPI Operator and Industry Adoption&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;acknowledgments&#34;&gt;Acknowledgments&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;ul&gt;&#xA;&lt;li class=&#34;has-normal-font-size&#34;&gt;Cover image by&amp;nbsp;&lt;a href=&#34;https://pixabay.com/users/dlohner-4631193/?utm_source=link-attribution&amp;amp;utm_medium=referral&amp;amp;utm_campaign=image&amp;amp;utm_content=3100049&#34;&gt;dlohner&lt;/a&gt;&amp;nbsp;from&amp;nbsp;&lt;a href=&#34;https://pixabay.com//?utm_source=link-attribution&amp;amp;utm_medium=referral&amp;amp;utm_campaign=image&amp;amp;utm_content=3100049&#34;&gt;Pixabay&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li class=&#34;has-normal-font-size&#34;&gt;Slurm architecture overview by SchedMD for their&amp;nbsp;&lt;a href=&#34;https://slurm.schedmd.com/network.html&#34;&gt;network overview&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;footnotes&#34;&gt;Footnotes&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/High-performance_computing&#34;&gt;HPC – high-performance computing&lt;/a&gt;&amp;nbsp;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fnref:hpc&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Lawrence_Livermore_National_Laboratory&#34;&gt;LLNL – Lawrence Livermore National Laboratory&lt;/a&gt;&amp;nbsp;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fnref:llnl&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.schedmd.com/about-schedmd/slurm-history&#34;&gt;Slurm history&lt;/a&gt;&amp;nbsp;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fnref:history&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Graphics_processing_unit&#34;&gt;GPU – graphics processing unit&lt;/a&gt;&amp;nbsp;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fnref:gpu&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://developer.nvidia.com/cuda-toolkit&#34;&gt;CUDA® – Compute Unified Device Architecture&lt;/a&gt;&amp;nbsp;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fnref:cuda&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://developer.nvidia.com/cudnn&#34;&gt;cuDNN – NVIDIA CUDA® Deep Neural Network library&lt;/a&gt;&amp;nbsp;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fnref:cudnn&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.open-mpi.org/&#34;&gt;MPI – Message Passing Interface&lt;/a&gt;&amp;nbsp;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fnref:mpi&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Open_Container_Initiative&#34;&gt;OCI – Open Container Initiative&lt;/a&gt;&amp;nbsp;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fnref:oci&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.uio.no/studier/emner/matnat/ifi/INF3380/v11/undervisningsmateriale/inf3380-week06.pdf&#34;&gt;Rank&lt;/a&gt;&amp;nbsp;– Each process has a unique rank, i.e. an integer identifier, within a communicator. The rank value is between zero and the number of processes minus one. The rank value is used to distinguish one process from another.&amp;nbsp;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fnref:rank&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Central_processing_unit&#34;&gt;CPU – central processing unit&lt;/a&gt;&amp;nbsp;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fnref:cpu&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.ibm.com/topics/artificial-intelligence&#34;&gt;AI – Artificial Intelligence&lt;/a&gt;&amp;nbsp;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fnref:ai&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.ibm.com/topics/machine-learning&#34;&gt;ML – Machine Learning&lt;/a&gt;&amp;nbsp;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fnref:ml&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.ibm.com/topics/deep-learning&#34;&gt;DL – Deep Learning&lt;/a&gt;&amp;nbsp;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fnref:dl&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/ARM_architecture_family&#34;&gt;ARM – Advanced RISC Machine&lt;/a&gt;&amp;nbsp;&lt;a href=&#34;https://superorbital.io/blog/slurm-an-hpc-scheduler-for-batch-workloads/#fnref:arm&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Sun, 07 Jul 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Embracing the future: our online store moves to a print-on-demand model】拥抱未来：我们的在线商店转向按需打印模式</title>
      <link>https://www.cncf.io/blog/2024/07/08/embracing-the-future-our-online-store-moves-to-a-print-on-demand-model/</link>
      <description>【&lt;p&gt;In today’s fast-paced digital world, businesses must evolve and adapt to meet their customers’ changing needs. We are excited to announce that our &lt;a href=&#34;https://store.cncf.io/&#34;&gt;online store&lt;/a&gt; is transitioning to a Print On Demand (POD) model. This significant change brings numerous benefits for us and, more importantly, our vibrant community.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;What is Print On Demand?&lt;/strong&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Print On Demand is a fulfillment method in which items are printed as soon as an order is placed rather than stored in inventory. This model allows for greater flexibility and customization, ensuring each product is made specifically for the person who orders it.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;The Benefits of Moving to Print-On-Demand&lt;/strong&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;Sustainability&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Reduced Waste&lt;/strong&gt;: Traditional inventory systems often result in overproduction and excess stock, leading to waste. With POD, we only produce what is needed, minimizing our environmental footprint.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Eco-Friendly Materials&lt;/strong&gt;: Many POD services use sustainable materials and eco-friendly printing processes, reducing environmental impact.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Efficiency:&lt;/strong&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Reduced Overhead Costs&lt;/strong&gt;: By eliminating the need for warehousing and managing excess inventory, we can focus on improving other aspects of our service, such as customer support and product quality.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;How This Benefits Our Community&lt;/strong&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Our shift to a Print-on-Demand model is a testament to our commitment to our community. By reducing waste and promoting sustainability, we can allow more flexibility in our offerings and ensure we always have inventory.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We are excited about this new chapter and look forward to providing you an even better shopping experience. Your support and feedback have been invaluable in making this transition possible. Together, we can positively impact both the environment and the creative community.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Thank you for being a part of our journey. Explore our new&lt;a href=&#34;https://store.cncf.io/collections/all-projects&#34;&gt; Print-On-Demand offerings today&lt;/a&gt; and discover the endless possibilities!&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;In the Future&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In the coming months, we look forward to adding customization to our products and sourcing print-on-demand options with global partners to reduce shipping costs.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Stay tuned for more updates and exciting new products!&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;在当今快节奏的数字世界中，企业必须不断发展和适应，以满足客户不断变化的需求。我们很高兴地宣布，我们的&lt;a href=&#34;https://store.cncf.io/&#34;&gt;在线商店&lt;/a&gt;正在转变为按需打印 (POD) 模式。这一重大变化为我们带来了众多好处，更重要的是，为我们充满活力的社区带来了众多好处。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;什么是按需打印？&lt;/strong&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;按需打印是一种在下订单后立即打印商品的履行方法，而不是将其存储在库存中。这种模式提供了更大的灵活性和定制性，确保每件产品都是专门为订购者制造的。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;转向按需打印的好处&lt;/strong&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;可持续性&lt;/strong&gt;：&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;减少浪费&lt;/strong&gt;：传统库存系统通常会导致生产过剩和库存过剩，从而导致浪费。通过 POD，我们只生产所需的产品，最大限度地减少对环境的影响。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;环保材料&lt;/strong&gt;：许多 POD 服务都使用可持续材料和环保印刷工艺，减少对环境的影响。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;效率：&lt;/strong&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;降低管理成本&lt;/strong&gt;：通过消除仓储和管理过剩库存的需要，我们可以专注于改善服务的其他方面，例如客户支持和产品质量。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;这对我们的社区有何好处&lt;/strong&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们向按需打印模式的转变证明了我们对社区的承诺。通过减少浪费和促进可持续发展，我们可以在我们的产品中提供更大的灵活性，并确保我们始终有库存。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们对这个新篇章感到兴奋，并期待为您提供更好的购物体验。您的支持和反馈对于实现这一转变至关重要。我们可以齐心协力，对环境和创意社区产生积极影响。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;感谢您参与我们的旅程。立即探索我们新的&lt;a href=&#34;https://store.cncf.io/collections/all-projects&#34;&gt;按需打印产品&lt;/a&gt;并发现无限的可能性！&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;未来&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在接下来的几个月中，我们期待为我们的产品增加定制功能，并与全球合作伙伴一起采购按需打印选项，以降低运输成本。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;敬请关注更多更新和令人兴奋的新产品！&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Sun, 07 Jul 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【A new App Development WG has now been launched!】新的应用程序开发工作组现已启动！</title>
      <link>https://www.cncf.io/blog/2024/07/05/a-new-app-development-wg-has-now-been-launched/</link>
      <description>【&lt;p&gt;&lt;em&gt;TAG post from TAG App Delivery &lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Calling all developers!&lt;/strong&gt; We’re excited to announce the launch of the new &lt;a href=&#34;https://tag-app-delivery.cncf.io/wgs/app-development/&#34;&gt;App Development Working Group&lt;/a&gt; within the &lt;a href=&#34;https://tag-app-delivery.cncf.io/&#34;&gt;TAG App Delivery&lt;/a&gt;. This group is dedicated to bridging the gap between developers and CNCF projects directly affecting your daily workflow.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Get involved and help shape the future of cloud-native application development! The &lt;a href=&#34;https://tag-app-delivery.cncf.io/wgs/app-development/charter/charter.md/&#34;&gt;charter&lt;/a&gt; provides more information about the working group’s goals and direction.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The working group is co-chaired by Daniel Oh from Red Hat, Thomas Vitale from Systematic, and Mauricio Salatino from Diagrid. Leveraging the deep expertise of the co-chairs and group members (e.g., Ryan Nowak – Microsoft, Eli Aleyner – Docker, Marcos Lilljedahl – Dagger, Sonali Srivastava – InfraCloud Technologies, and Yacine Kheddache – Microcks) in development practices, platform engineering, and the CNCF ecosystem, the group is initially focused on highlighting Graduated and Incubating projects that directly benefit developers.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Beyond raising awareness, the working group actively shapes the cloud-native development landscape by classifying tools and fostering collaboration between CNCF projects and app developers. This makes it easier for the developers to find the right tools and share best practices. The working group also actively seeks out and integrates new projects prioritizing best practices for cloud-native application development.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Join the movement!&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Are you a cloud-native developer passionate about improving development? We’d love for you to be part of it!&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://tag-app-delivery.cncf.io/wgs/app-development/&#34;&gt;Bi-weekly meetings&lt;/a&gt;: Participate in our discussions on each month’s first and third Wednesdays.&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://docs.google.com/document/d/1L7e2szHX_gpYnC0cs_BTQH6hTNzh8acWzqkzhrPOJds/edit#wg-app-developmen&#34;&gt;CNCF Slack Channel&lt;/a&gt;: Connect with us on the #wg-app-development channel on the CNCF Slack workspace:&amp;nbsp;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Are you heading to &lt;a href=&#34;https://events.linuxfoundation.org/kubecon-cloudnativecon-north-america/&#34;&gt;KubeCon + CLoudNativeCon North America 2024&lt;/a&gt;? Don’t miss out on connecting with fellow developers at the co-located &lt;a href=&#34;https://events.linuxfoundation.org/kubecon-cloudnativecon-north-america/&#34;&gt;AppDevelopmentCon&lt;/a&gt; event! We’re also going to &lt;a href=&#34;https://events.linuxfoundation.org/kubecon-cloudnativecon-india/&#34;&gt;KubeCon + CloudNativeCon India 2024&lt;/a&gt;. Let’s meet up and chat about cloud-native development.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;来自 TAG App Delivery 的 TAG 帖子&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;呼叫所有开发者！&lt;/strong&gt;我们很高兴地宣布推出新的&lt;a href=&#34;https://tag-app-delivery.cncf.io/wgs/app-development/ &lt;a href=&#34;https://tag-app-delivery.cncf.io/&#34;&gt;TAG 应用交付&lt;/a&gt;内的&#34;&gt;应用开发工作组&lt;/a&gt;。该小组致力于弥合开发人员与直接影响您日常工作流程的 CNCF 项目之间的差距。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;参与并帮助塑造云原生应用程序开发的未来！ &lt;a href=&#34;https://tag-app-delivery.cncf.io/wgs/app-development/charter/charter.md/&#34;&gt;章程&lt;/a&gt;提供了有关工作组目标和方向的更多信息。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;该工作组由来自 Red Hat 的 Daniel Oh、来自 Systematic 的 Thomas Vitale 和来自 Diagrid 的 Mauricio Salatino 担任联合主席。利用联合主席和小组成员（例如，Ryan Nowak – Microsoft、Eli Aleyner – Docker、Marcos Lilljedahl – Dagger、Sonali Srivastava – InfraCloud Technologies 和 Yacine Kheddache – Microcks）在开发实践、平台工程和在 CNCF 生态系统中，该小组最初专注于突出直接使开发人员受益的毕业和孵化项目。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;除了提高认识之外，工作组还通过对工具进行分类并促进 CNCF 项目和应用开发人员之间的协作，积极塑造云原生开发格局。这使得开发人员更容易找到合适的工具并分享最佳实践。该工作组还积极寻找并整合新项目，优先考虑云原生应用程序开发的最佳实践。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;加入运动！&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;您是一位热衷于改进开发的云原生开发人员吗？我们希望您能参与其中！&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://tag-app-delivery.cncf.io/wgs/app-development/&#34;&gt;每两周一次的会议&lt;/a&gt;：参与我们每月第一个和第三个周三的讨论。 &lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://docs.google.com/document/d/1L7e2szHX_gpYnC0cs_BTQH6hTNzh8acWzqkzhrPOJds/edit#wg-app-developmen&#34;&gt;CNCF Slack 频道&lt;/a&gt;：通过 #wg-app 与我们联系-CNCF Slack 工作区上的开发频道：&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;您要去参加&lt;a href=&#34;https://events.linuxfoundation.org/kubecon-cloudnativecon-north-america/&#34;&gt;KubeCon + CLoudNativeCon North America 2024&lt;/a&gt;吗？不要错过在同期举行的 &lt;a href=&#34;https://events.linuxfoundation.org/kubecon-cloudnativecon-north-america/&#34;&gt;AppDevelopmentCon&lt;/a&gt; 活动中与其他开发人员交流！我们还将参加 &lt;a href=&#34;https://events.linuxfoundation.org/kubecon-cloudnativecon-india/&#34;&gt;KubeCon + CloudNativeCon India 2024&lt;/a&gt;。让我们聚在一起聊聊云原生开发吧。&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Thu, 04 Jul 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【How WebAssembly components extend the frontiers of Kubernetes to multi-cloud, edge, and beyond】WebAssembly 组件如何将 Kubernetes 的前沿扩展到多云、边缘及其他领域</title>
      <link>https://www.cncf.io/blog/2024/07/01/how-webassembly-components-extend-the-frontiers-of-kubernetes-to-multi-cloud-edge-and-beyond/</link>
      <description>【&lt;p&gt;&lt;em&gt;Ambassador post by Taylor Thomas, CNCF Ambassador and Director of Engineering at Cosmonic&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;WebAssembly (Wasm) components are here and already unlocking new computing patterns. Meanwhile, CNCF’s &lt;a href=&#34;https://wasmcloud.com/&#34;&gt;&lt;strong&gt;wasmCloud&lt;/strong&gt;&lt;/a&gt; offers Wasm-native orchestration for distributed components—in essence, a Kubernetes for WebAssembly.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;That’s great for using components in large-scale production environments, but there’s one question: &lt;em&gt;Why would you want to replace your entire infrastructure?&lt;/em&gt; If you’re invested in Kubernetes, you have robust infrastructure management solved, and you’d prefer not to make changes at the node level, much less switch up your orchestrator.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Fortunately, wasmCloud integrates seamlessly with your existing cloud native setup in a quick, non-invasive, Kubernetes-native way. There’s no fiddling with custom node pools or configuration: Kubernetes’ operator pattern gives us a way to treat WebAssembly as more than a runtime and take full advantage of components’ capabilities. With the flexibility of components, we can extend the frontiers of Kubernetes in traditional challenge areas like multi-region, multi-cluster, multi-cloud, and edge environments.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Kubernetes, meet components&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;WebAssembly components&lt;/strong&gt; are Wasm binaries that snap together like building blocks, regardless of the language in which they were first written. One service might be written in Go, another in Rust, and another in JavaScript, but they can all communicate with one another over shared APIs. Like any Wasm binary, they can run on any operating system and any architecture.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;2358&#34; height=&#34;992&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/07/compile.jpg&#34; alt=&#34;Multi-language diagram&#34; class=&#34;wp-image-113602&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/07/compile.jpg 2358w, https://www.cncf.io/wp-content/uploads/2024/07/compile-300x126.jpg 300w, https://www.cncf.io/wp-content/uploads/2024/07/compile-1024x431.jpg 1024w, https://www.cncf.io/wp-content/uploads/2024/07/compile-768x323.jpg 768w, https://www.cncf.io/wp-content/uploads/2024/07/compile-900x379.jpg 900w, https://www.cncf.io/wp-content/uploads/2024/07/compile-1800x757.jpg 1800w, https://www.cncf.io/wp-content/uploads/2024/07/compile-475x200.jpg 475w, https://www.cncf.io/wp-content/uploads/2024/07/compile-951x400.jpg 951w&#34; sizes=&#34;(max-width: 2358px) 100vw, 2358px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Components are portable, small (ranging from kilobytes to single-digit megabytes), and packaged as &lt;a href=&#34;https://tag-runtime.cncf.io/wgs/wasm/deliverables/wasm-oci-artifact/&#34;&gt;OCI artifacts&lt;/a&gt;, so a certain analogy with containers is inevitable. But they’re also something brand new: reusable building blocks written against well-known APIs and interfaces with real multi-language interoperability.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In a world with components, software development becomes much more flexible and platform engineering becomes much less of an exercise in bug-whacking. Developers don’t have to worry about rewriting something for their language of choice and platform engineers have the flexibility to compose their platform in the way that best suits their requirements.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The pluggable nature of components was designed with a cloud native world in mind. In cases where you want to minimize communication over network boundaries, you can &lt;a href=&#34;https://wasmcloud.com/docs/concepts/linking-components/linking-at-build#overview&#34;&gt;&lt;strong&gt;compose&lt;/strong&gt; all those services together into a single binary&lt;/a&gt;. In cases where you want to scale (or maintain) those services independently, or services need to run close to distributed data sources, you can run your various components distributedly with wasmCloud, which serves as an orchestrator for WebAssembly components. (Of course, you can run build-time composed components on wasmCloud, too.)&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If components are comparable to containers, then wasmCloud is analogous to Kubernetes, providing Wasm-native orchestration so teams can utilize components fully in distributed environments and at scale. The architecture bears some high-level similarities:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;2400&#34; height=&#34;1264&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/07/k8s-wasmCloud-v2.jpg&#34; alt=&#34;K8s &amp;amp; wasmCloud comparison diagram&#34; class=&#34;wp-image-113603&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/07/k8s-wasmCloud-v2.jpg 2400w, https://www.cncf.io/wp-content/uploads/2024/07/k8s-wasmCloud-v2-300x158.jpg 300w, https://www.cncf.io/wp-content/uploads/2024/07/k8s-wasmCloud-v2-1024x539.jpg 1024w, https://www.cncf.io/wp-content/uploads/2024/07/k8s-wasmCloud-v2-768x404.jpg 768w, https://www.cncf.io/wp-content/uploads/2024/07/k8s-wasmCloud-v2-194x102.jpg 194w, https://www.cncf.io/wp-content/uploads/2024/07/k8s-wasmCloud-v2-388x204.jpg 388w, https://www.cncf.io/wp-content/uploads/2024/07/k8s-wasmCloud-v2-776x408.jpg 776w, https://www.cncf.io/wp-content/uploads/2024/07/k8s-wasmCloud-v2-1552x816.jpg 1552w, https://www.cncf.io/wp-content/uploads/2024/07/k8s-wasmCloud-v2-900x474.jpg 900w, https://www.cncf.io/wp-content/uploads/2024/07/k8s-wasmCloud-v2-1800x948.jpg 1800w, https://www.cncf.io/wp-content/uploads/2024/07/k8s-wasmCloud-v2-380x200.jpg 380w, https://www.cncf.io/wp-content/uploads/2024/07/k8s-wasmCloud-v2-759x400.jpg 759w, https://www.cncf.io/wp-content/uploads/2024/07/k8s-wasmCloud-v2-590x310.jpg 590w, https://www.cncf.io/wp-content/uploads/2024/07/k8s-wasmCloud-v2-1180x620.jpg 1180w&#34; sizes=&#34;(max-width: 2400px) 100vw, 2400px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The &lt;strong&gt;wasmCloud Application Deployment Manager (wadm)&lt;/strong&gt; is the system’s orchestration layer and analogous to the Kubernetes scheduler, controller manager, and API server (for a subset of APIs) all in one.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;The &lt;strong&gt;control interface&lt;/strong&gt; for wasmCloud routes messages across the connectivity layer (called the “lattice”), much as the API server acts as Kubernetes’ air-traffic control system.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;wasmCloud’s workloads are components rather than containers in pods, but they are similarly packaged as &lt;strong&gt;OCI artifacts&lt;/strong&gt; (and can therefore be pulled down from the same registries).&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;In wasmCloud, the WebAssembly runtime &lt;strong&gt;Wasmtime&lt;/strong&gt; runs components in a given host environment, whereas the Kubelet mediates pod execution on a Kubernetes node.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As with components and containers, there are some important differences: for example, wasmCloud uses the CNCF’s &lt;a href=&#34;https://nats.io/&#34;&gt;NATS&lt;/a&gt; project as a connectivity layer for a “distributed-first” approach, &lt;em&gt;and&lt;/em&gt; as a distributed key-value store for state. These characteristics make wasmCloud extremely well-suited to distributing workloads easily and securely across clouds, clusters, and regions‐and Kubernetes’ extensibility means that it’s simple to bring those features to existing cloud native infrastructure using CRDs and the operator pattern.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Multi-cloud, edge, and beyond&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;By integrating with Kubernetes via the open source &lt;a href=&#34;https://github.com/wasmCloud/wasmcloud-operator&#34;&gt;&lt;strong&gt;&lt;code&gt;wasmcloud-operator&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt;, wasmCloud complements and extends Kubernetes in areas that have historically posed challenges like multi-cluster, multi-cloud, and edge. The size and efficiency of both WebAssembly binaries and wasmCloud makes it much more practical to run distributed apps in resource-constrained environments. Meanwhile, the wasmCloud lattice provides a means to not only connect Kubernetes clusters across various clouds or regions, but move mission-critical workloads safely and at scale.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;2048&#34; height=&#34;855&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/07/regions.png&#34; alt=&#34;Deployment diagram&#34; class=&#34;wp-image-113605&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/07/regions.png 2048w, https://www.cncf.io/wp-content/uploads/2024/07/regions-300x125.png 300w, https://www.cncf.io/wp-content/uploads/2024/07/regions-1024x428.png 1024w, https://www.cncf.io/wp-content/uploads/2024/07/regions-768x321.png 768w, https://www.cncf.io/wp-content/uploads/2024/07/regions-900x376.png 900w, https://www.cncf.io/wp-content/uploads/2024/07/regions-1800x751.png 1800w, https://www.cncf.io/wp-content/uploads/2024/07/regions-479x200.png 479w, https://www.cncf.io/wp-content/uploads/2024/07/regions-958x400.png 958w&#34; sizes=&#34;(max-width: 2048px) 100vw, 2048px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;With these tools, it becomes fairly straightforward to architect a “supercluster” composed of smaller clusters, with workloads scheduled to one cluster or another based on region or other criteria. Architectural patterns that were previously highly challenging are first-class use cases with wasmCloud and Kubernetes working together, with no changes to your underlying infrastructure.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;With &lt;code&gt;wasmcloud-operator&lt;/code&gt;, you can run component workloads &lt;em&gt;exactly the same way you would run anything else in Kubernetes&lt;/em&gt;. Moreover, you can deploy wasmCloud application manifests directly with &lt;code&gt;kubectl apply&lt;/code&gt; and check the status of wasmCloud apps with &lt;code&gt;kubectl get applications&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The operator is already in use on factory floors. With components, manufacturing analytics company &lt;a href=&#34;https://www.youtube.com/watch?v=fQdkNGZqYZA&amp;amp;list=PLj6h78yzYM2MQteKoXxICTWiUdZYEw6RI&amp;amp;index=6&#34;&gt;MachineMetrics&lt;/a&gt; can process high-frequency data directly on edge devices and stream to the cloud in real-time—running in environments that are highly challenging for containers, and integrating with Kubernetes all the while. MachineMetrics’ Data Platform Team Engineer Jochen Rau notes: “The wasmCloud-operator makes this really simple to manage with our existing tools. We deploy our compute workloads on the lattice on wasmCloud. We’re crossing the boundaries between edge and cloud.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Conclusion&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Components are ushering in a new wave of computing in which new patterns of interoperability and reusability are possible. Kubernetes’ extensibility means that teams who want to start leveraging components right now can do so without changes to their infrastructure—and with integrations for existing cloud-native tooling in areas like policy, observability, and packaging.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;You can try out wasmCloud on Kubernetes right now—check out the &lt;a href=&#34;https://wasmcloud.com/docs/deployment/k8s/&#34;&gt;walkthrough in the wasmCloud documentation&lt;/a&gt;. If you’re just getting started with WebAssembly components, the &lt;a href=&#34;https://wasmcloud.com/docs/tour/hello-world&#34;&gt;wasmCloud quickstart&lt;/a&gt; is a great place to get started. If you’d like to learn more about running components on Kubernetes, or you have questions about the ecosystem, &lt;a href=&#34;https://slack.wasmcloud.com/&#34;&gt;join the wasmCloud Slack&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;由 CNCF 大使兼 Cosmonic 工程总监 Taylor Thomas 担任大使职务&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;WebAssembly (Wasm) 组件已经出现，并且已经解锁了新的计算模式。与此同时，CNCF 的 &lt;a href=&#34;https://wasmcloud.com/&#34;&gt;&lt;strong&gt;wasmCloud&lt;/strong&gt;&lt;/a&gt; 为分布式组件提供 Wasm 原生编排，本质上是用于 WebAssembly 的 Kubernetes。&lt;/p &gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这对于在大规模生产环境中使用组件来说非常有用，但有一个问题：&lt;em&gt;您为什么要更换整个基础设施？&lt;/em&gt;如果您投资了 Kubernetes，那么您就拥有强大的基础设施管理已解决，并且您不希望在节点级别进行更改，更不用说切换您的编排器了。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;幸运的是，wasmCloud 以快速、非侵入性的 Kubernetes 原生方式与您现有的云原生设置无缝集成。无需摆弄自定义节点池或配置：Kubernetes 的运算符模式为我们提供了一种将 WebAssembly 视为不仅仅是运行时并充分利用组件功能的方法。凭借组件的灵活性，我们可以在多区域、多集群、多云和边缘环境等传统挑战领域扩展 Kubernetes 的前沿。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Kubernetes，满足组件&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;WebAssembly 组件&lt;/strong&gt;是 Wasm 二进制文件，它们像构建块一样组合在一起，无论它们最初是用什么语言编写的。一项服务可能是用 Go 编写的，另一项是用 Rust 编写的，另一项是用 JavaScript 编写的，但它们都可以通过共享 API 相互通信。与任何 Wasm 二进制文件一样，它们可以在任何操作系统和任何架构上运行。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“2358”高度=“992”src=“https://www.cncf.io/ wp-content/uploads/2024/07/compile.jpg&#34; alt=&#34;多语言图&#34; class=&#34;wp-image-113602&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/ 2024/07/compile.jpg 2358w，https://www.cncf.io/wp-content/uploads/2024/07/compile-300x126.jpg 300w，https://www.cncf.io/wp-content/ uploads/2024/07/compile-1024x431.jpg 1024w，https://www.cncf.io/wp-content/uploads/2024/07/compile-768x323.jpg 768w，https://www.cncf.io/ wp-content/uploads/2024/07/compile-900x379.jpg 900w，https://www.cncf.io/wp-content/uploads/2024/07/compile-1800x757.jpg 1800w，https://www. cncf.io/wp-content/uploads/2024/07/compile-475x200.jpg 475w，https://www.cncf.io/wp-content/uploads/2024/07/compile-951x400.jpg 951w&#34; 尺寸= “（最大宽度：2358px）100vw，2358px”referrerpolicy =“no-referrer”&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;组件是便携式的、小型的（范围从千字节到个位数兆字节），并打包为 &lt;a href=&#34;https://tag-runtime.cncf.io/wgs/wasm/deliverables/wasm-oci-artifact /&#34;&gt;OCI 工件&lt;/a&gt;，因此与容器的某种类比是不可避免的。但它们也是全新的：根据众所周知的 API 和接口编写的可重用构建块，具有真正的多语言互操作性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在一个有组件的世界中，软件开发变得更加灵活，平台工程也不再是一种修复错误的练习。开发人员不必担心为他们选择的语言重写某些内容，平台工程师可以灵活地以最适合他们要求的方式构建平台。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;组件的可插拔性质是在设计时考虑到云原生世界的。如果您希望最大程度地减少网络边界上的通信，您可以&lt;a href=&#34;https://wasmcloud.com/docs/concepts/linking-components/linking-at-build#overview&#34;&gt;&lt;strong&gt;撰写&lt;/ strong&gt;将所有这些服务整合到一个二进制文件中&lt;/a&gt;。如果您想要独立扩展（或维护）这些服务，或者服务需要在分布式数据源附近运行，您可以使用 wasmCloud 分布式运行各种组件，它充当 WebAssembly 组件的协调器。 （当然，您也可以在 wasmCloud 上运行构建时组合组件。）&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果组件比作容器，那么 wasmCloud 就类似于 Kubernetes，提供 Wasm 原生编排，以便团队可以在分布式环境中大规模地充分利用组件。该架构具有一些高级相似之处：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“2400”高度=“1264”src=“https://www.cncf.io/ wp-content/uploads/2024/07/k8s-wasmCloud-v2.jpg&#34; alt=&#34;K8s &amp; wasmCloud 对比图&#34; class=&#34;wp-image-113603&#34; srcset=&#34;https://www.cncf.io/wp -content/uploads/2024/07/k8s-wasmCloud-v2.jpg 2400w，https://www.cncf.io/wp-content/uploads/2024/07/k8s-wasmCloud-v2-300x158.jpg 300w，https ://www.cncf.io/wp-content/uploads/2024/07/k8s-wasmCloud-v2-1024x539.jpg 1024w，https://www.cncf.io/wp-content/uploads/2024/07/ k8s-wasmCloud-v2-768x404.jpg 768w，https://www.cncf.io/wp-content/uploads/2024/07/k8s-wasmCloud-v2-194x102.jpg 194w，https://www.cncf。 io/wp-content/uploads/2024/07/k8s-wasmCloud-v2-388x204.jpg 388w，https://www.cncf.io/wp-content/uploads/2024/07/k8s-wasmCloud-v2-776x408 .jpg 776w，https://www.cncf.io/wp-content/uploads/2024/07/k8s-wasmCloud-v2-1552x816.jpg 1552w，https://www.cncf.io/wp-content/uploads /2024/07/k8s-wasmCloud-v2-900x474.jpg 900w，https://www.cncf.io/wp-content/uploads/2024/07/k8s-wasmCloud-v2-1800x948.jpg 1800w，https:// /www.cncf.io/wp-content/uploads/2024/07/k8s-wasmCloud-v2-380x200.jpg 380w，https://www.cncf.io/wp-content/uploads/2024/07/k8s- wasmCloud-v2-759x400.jpg 759w，https://www.cncf.io/wp-content/uploads/2024/07/k8s-wasmCloud-v2-590x310.jpg 590w，https://www.cncf.io/ wp-content/uploads/2024/07/k8s-wasmCloud-v2-1180x620.jpg 1180w“尺寸=”（最大宽度：2400px）100vw，2400px“referrerpolicy=”no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;wasmCloud 应用程序部署管理器 (wadm)&lt;/strong&gt; 是系统的编排层，类似于 Kubernetes 调度程序、控制器管理器和 API 服务器（针对 API 的子集）。&lt;/li &gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;wasmCloud 的&lt;strong&gt;控制接口&lt;/strong&gt;在连接层（称为“网格”）上路由消息，就像 API 服务器充当 Kubernetes 的空中交通控制系统一样。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;wasmCloud 的工作负载是组件，而不是 Pod 中的容器，但它们类似地打包为 &lt;strong&gt;OCI 工件&lt;/strong&gt;（因此可以从相同的注册表中提取）。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;在 wasmCloud 中，WebAssembly 运行时 &lt;strong&gt;Wasmtime&lt;/strong&gt; 在给定主机环境中运行组件，而 Kubelet 则在 Kubernetes 节点上协调 Pod 执行。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;与组件和容器一样，存在一些重要的区别：例如，wasmCloud 使用 CNCF 的 &lt;a href=&#34;https://nats.io/&#34;&gt;NATS&lt;/a&gt; 项目作为“分布式优先”方法，&lt;em&gt;和&lt;/em&gt;作为状态的分布式键值存储。这些特性使得 wasmCloud 非常适合跨云、集群和区域轻松、安全地分配工作负载，而 Kubernetes 的可扩展性意味着可以使用 CRD 和运算符模式轻松地将这些功能引入现有的云原生基础设施。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;多云、边缘及其他&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;通过开源与 Kubernetes 集成&lt;a href=&#34;https://github.com/wasmCloud/wasmcloud-operator&#34;&gt;&lt;strong&gt;&lt;code&gt;wasmcloud-operator&lt;/code&gt;&lt;/strong&gt;&lt;/ a&gt;，wasmCloud 在多集群、多云和边缘等历史上提出挑战的领域补充和扩展了 Kubernetes。 WebAssembly 二进制文件和 wasmCloud 的大小和效率使得在资源受限的环境中运行分布式应用程序更加实用。同时，wasmCloud 网格提供了一种方法，不仅可以跨不同云或区域连接 Kubernetes 集群，还可以安全、大规模地移动关键任务工作负载。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“2048”高度=“855”src=“https://www.cncf.io/ wp-content/uploads/2024/07/regions.png&#34; alt=&#34;部署图&#34; class=&#34;wp-image-113605&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/ 07/regions.png 2048w，https://www.cncf.io/wp-content/uploads/2024/07/regions-300x125.png 300w，https://www.cncf.io/wp-content/uploads/ 2024/07/regions-1024x428.png 1024w，https://www.cncf.io/wp-content/uploads/2024/07/regions-768x321.png 768w，https://www.cncf.io/wp- content/uploads/2024/07/regions-900x376.png 900w，https://www.cncf.io/wp-content/uploads/2024/07/regions-1800x751.png 1800w，https://www.cncf。 io/wp-content/uploads/2024/07/regions-479x200.png 479w，https://www.cncf.io/wp-content/uploads/2024/07/regions-958x400.png 958w&#34; 尺寸 = &#34;(最大宽度：2048px) 100vw，2048px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;使用这些工具，构建一个由较小集群组成的“超级集群”变得相当简单，并根据区域或其他标准将工作负载安排到一个或另一个集群。以前极具挑战性的架构模式是 wasmCloud 和 Kubernetes 协同工作的一流用例，无需更改底层基础设施。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;使用 &lt;code&gt;wasmcloud-operator&lt;/code&gt;，您可以以与在 Kubernetes 中运行其他任何内容完全相同的方式运行组件工作负载&lt;/em&gt;。此外，您可以直接使用 &lt;code&gt;kubectl apply&lt;/code&gt; 部署 wasmCloud 应用程序清单，并使用 &lt;code&gt;kubectl get applications&lt;/code&gt; 检查 wasmCloud 应用程序的状态。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;操作员已在工厂车间使用。借助组件，制造分析公司 &lt;a href=&#34;https://www.youtube.com/watch?v=fQdkNGZqYZA&amp;list=PLj6h78yzYM2MQteKoXxICTWiUdZYEw6RI&amp;index=6&#34;&gt;MachineMetrics&lt;/a&gt; 可以直接在边缘设备上处理高频数据并将其流式传输到实时云——在对容器来说极具挑战性的环境中运行，并始终与 Kubernetes 集成。 MachineMetrics 的数据平台团队工程师 Jochen Rau 指出：“wasmCloud-operator 使使用我们现有工具的管理变得非常简单。我们将计算工作负载部署在 wasmCloud 上的网格上。我们正在跨越边缘和云之间的界限。”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;结论&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;组件正在引领新的计算浪潮，其中新的互操作性和可重用性模式成为可能。 Kubernetes 的可扩展性意味着想要立即开始利用组件的团队可以在不更改基础设施的情况下实现这一目标，并且可以在策略、可观察性和打包等领域集成现有的云原生工具。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;您现在就可以在 Kubernetes 上尝试 wasmCloud - 查看&lt;a href=&#34;https://wasmcloud.com/docs/deployment/k8s/&#34;&gt;wasmCloud 文档中的演练&lt;/a&gt;。如果您刚刚开始使用 WebAssembly 组件，&lt;a href=&#34;https://wasmcloud.com/docs/tour/hello-world&#34;&gt;wasmCloud 快速入门&lt;/a&gt; 是一个很好的起点。如果您想了解有关在 Kubernetes 上运行组件的更多信息，或者对生态系统有疑问，请&lt;a href=&#34;https://slack.wasmcloud.com/&#34;&gt;加入 wasmCloud Slack&lt;/a&gt;。&lt;/a&gt; p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Sun, 30 Jun 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Kubestronaut in Orbit: Peter Barczi】在轨道上的 Kubetronaut：Peter Barczi</title>
      <link>https://www.cncf.io/blog/2024/07/05/kubestronaut-in-orbit-peter-barczi/</link>
      <description>【&lt;h2 class=&#34;wp-block-heading&#34;&gt;Get to know Peter Barczi&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1650&#34; height=&#34;866&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/06/Kubestronaut-in-Orbit-4.jpg&#34; alt=&#34;Kubestronaut in Orbit - Peter Barczi&#34; class=&#34;wp-image-113542&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/06/Kubestronaut-in-Orbit-4.jpg 1650w, https://www.cncf.io/wp-content/uploads/2024/06/Kubestronaut-in-Orbit-4-300x157.jpg 300w, https://www.cncf.io/wp-content/uploads/2024/06/Kubestronaut-in-Orbit-4-1024x537.jpg 1024w, https://www.cncf.io/wp-content/uploads/2024/06/Kubestronaut-in-Orbit-4-768x403.jpg 768w, https://www.cncf.io/wp-content/uploads/2024/06/Kubestronaut-in-Orbit-4-194x102.jpg 194w, https://www.cncf.io/wp-content/uploads/2024/06/Kubestronaut-in-Orbit-4-388x204.jpg 388w, https://www.cncf.io/wp-content/uploads/2024/06/Kubestronaut-in-Orbit-4-776x408.jpg 776w, https://www.cncf.io/wp-content/uploads/2024/06/Kubestronaut-in-Orbit-4-1552x816.jpg 1552w, https://www.cncf.io/wp-content/uploads/2024/06/Kubestronaut-in-Orbit-4-900x472.jpg 900w, https://www.cncf.io/wp-content/uploads/2024/06/Kubestronaut-in-Orbit-4-381x200.jpg 381w, https://www.cncf.io/wp-content/uploads/2024/06/Kubestronaut-in-Orbit-4-762x400.jpg 762w, https://www.cncf.io/wp-content/uploads/2024/06/Kubestronaut-in-Orbit-4-590x310.jpg 590w, https://www.cncf.io/wp-content/uploads/2024/06/Kubestronaut-in-Orbit-4-1180x620.jpg 1180w&#34; sizes=&#34;(max-width: 1650px) 100vw, 1650px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Peter, one of our first Kubestronauts, has been working with Kubernetes only since 2021 but has still managed to pass all of CNCF’s Kubernetes certifications. He’s currently the Sr. DevOps Engineer / TechLead at a company building a cloud offering with focus on confidential computing. In his role, he also manages physical servers, clouds, operating Linux OSs and Kubernetes clusters at scale and is an Internal Linux Trainer.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you’d like to be a Kubestronaut, get more details on the&lt;a href=&#34;https://www.cncf.io/training/kubestronaut/&#34;&gt; CNCF Kubestronaut &lt;/a&gt;page.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;When did you get started with kubernetes–what was your first project?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;I started with K8s as self-learner in 2021.&amp;nbsp;My first project (not surprisingly) was the NGINX web server running on Kubernetes.&amp;nbsp; Later on, I used K8s during the migration of our infra services into Kubernetes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Nowadays, within my current project, almost everything is a Kubernetes object, even the network switches, so I use it daily.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;What are the primary CNCF projects you work on or use today?&amp;nbsp; What projects have you enjoyed the most in your career?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The primary CNCF projects I work with the most are:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/kubernetes&#34;&gt;Kubernetes&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/fluxcd/&#34;&gt;FluxCD&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/prometheus&#34;&gt;Prometheus&lt;/a&gt; &amp;amp; &lt;a href=&#34;https://github.com/grafana&#34;&gt;Grafana&lt;/a&gt; stack&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/cilium&#34;&gt;Cilium&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/rook&#34;&gt;Rook&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Discovering a GitOps approach was a real game-changer in my work life.&amp;nbsp; And thanks to tools like &lt;a href=&#34;https://github.com/argoproj/argo-cd&#34;&gt;ArgoCD &lt;/a&gt;and &lt;a href=&#34;https://github.com/fluxcd/&#34;&gt;FluxCD,&lt;/a&gt; I realised how “easy” it can be to deploy and track apps using git.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Furthermore, thanks to &lt;a href=&#34;https://rook.io/&#34;&gt;Rook-ceph storage provide&lt;/a&gt;r I’m now able to spin up and configure storage clusters in a matter of a few minutes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;What motivated you to get all the kubernetes certs?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Each certification has its own story.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;KCNA was my first certification. I took it right before a job interview for extra confidence in my Kubernetes skills.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;CKA &amp;amp; CKAD&amp;nbsp; were two certs I needed to help with a project I was working on.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;CKS was a cert I got as a personal goal.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;KCSA was my last one. I got this one right after Kubecon when the Kubestronaut program was announced and realized I only needed one more.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;How have the certs helped you in your career?&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The certifications allow me to practice and learn about technology and tools I do not use on a daily basis. Preparation for the certification is a way to get the education needed to be ready for future projects.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;What are some other books/sites/courses you recommend for people who want to work with k8s?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;I found these online courses were a good starting point for my Kubernetes learning journey:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;– CKA and CKAD courses from kodekloud.com&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;– CKS online course from Kim Wuestkamp on YouTube&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;– CKA/CKAD/CKS practise exams from aclodguru/pluralsight&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;What do you do in your free time?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;I spend all my free time with my family, my 15-month-old daughter is my single point of interest currently. I also spend time in my cottage house, so I balance my work time there.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;As you know Kubernetes is turning 10 this year, what are you most excited about for Kubernetes in the next 10 years?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;My magic ball doesn’t have answers so far into the future:)&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;What would you tell someone who is just starting their K8s certification journey? Any tips or tricks?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;There are no tips and tricks better than to practise, practise, practise.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Today the Cloud native ecosystem is way more than Kubernetes. Do you plan to get other cloud native certifications from the CNCF?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Absolutely, the next challenge for me is to dive into the Prometheus stack and become familiar enough with it to become a &lt;a href=&#34;https://www.cncf.io/training/certification/pca/&#34;&gt;Prometheus Certified Associate (PCA)&lt;/a&gt;&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;How did you get involved with cloud native and Kubernetes in general?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;I have a background in Linux administration, so from there it was a logical and natural to progress to Kubernetes and cloud native.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you’d like to be a Kubestronaut,&amp;nbsp;get more details on the&lt;a href=&#34;https://www.cncf.io/training/kubestronaut/&#34;&gt; CNCF Kubestronaut &lt;/a&gt;page.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;h2 class=&#34;wp-block-heading&#34;&gt;了解 Peter Barczi&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“1650”高度=“866”src=“https://www.cncf.io/ wp-content/uploads/2024/06/Kubestronaut-in-Orbit-4.jpg&#34; alt=&#34;轨道上的 Kubestronaut - Peter Barczi&#34; class=&#34;wp-image-113542&#34; srcset=&#34;https://www.cncf. io/wp-content/uploads/2024/06/Kubestronaut-in-Orbit-4.jpg 1650w，https://www.cncf.io/wp-content/uploads/2024/06/Kubestronaut-in-Orbit-4 -300x157.jpg 300w，https://www.cncf.io/wp-content/uploads/2024/06/Kubestronaut-in-Orbit-4-1024x537.jpg 1024w，https://www.cncf.io/wp -content/uploads/2024/06/Kubestronaut-in-Orbit-4-768x403.jpg 768w，https://www.cncf.io/wp-content/uploads/2024/06/Kubestronaut-in-Orbit-4- 194x102.jpg 194w，https://www.cncf.io/wp-content/uploads/2024/06/Kubestronaut-in-Orbit-4-388x204.jpg 388w，https://www.cncf.io/wp-内容/uploads/2024/06/Kubestronaut-in-Orbit-4-776x408.jpg 776w，https://www.cncf.io/wp-content/uploads/2024/06/Kubestronaut-in-Orbit-4-1552x816 .jpg 1552w，https://www.cncf.io/wp-content/uploads/2024/06/Kubestronaut-in-Orbit-4-900x472.jpg 900w，https://www.cncf.io/wp-content /uploads/2024/06/Kubestronaut-in-Orbit-4-381x200.jpg 381w，https://www.cncf.io/wp-content/uploads/2024/06/Kubestronaut-in-Orbit-4-762x400。 jpg 762w，https://www.cncf.io/wp-content/uploads/2024/06/Kubestronaut-in-Orbit-4-590x310.jpg 590w，https://www.cncf.io/wp-content/ uploads/2024/06/Kubestronaut-in-Orbit-4-1180x620.jpg 1180w&#34;sizes=&#34;(max-width: 1650px) 100vw, 1650px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Peter 是我们首批 Kubetronaut 之一，他从 2021 年才开始使用 Kubernetes，但仍然设法通过了 CNCF 的所有 Kubernetes 认证。他目前是一家公司的高级 DevOps 工程师/技术主管，该公司致力于构建专注于机密计算的云产品。在此职位上，他还管理物理服务器、云、大规模操作 Linux 操作系统和 Kubernetes 集群，并且是一名内部 Linux 培训师。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您想成为 Kubestronaut，请在&lt;a href=&#34;https://www.cncf.io/training/kubestronaut/&#34;&gt;CNCF Kubestronaut&lt;/a&gt;页面获取更多详细信息。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;您什么时候开始使用 kubernetes – 您的第一个项目是什么？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我于 2021 年开始自学 K8s。我的第一个项目（毫不奇怪）是在 Kubernetes 上运行的 NGINX Web 服务器。  后来，我在将基础设施服务迁移到 Kubernetes 的过程中使用了 K8s。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;现在，在我当前的项目中，几乎所有东西都是 Kubernetes 对象，甚至是网络交换机，所以我每天都使用它。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;您现在从事或使用的主要 CNCF 项目是什么？  在您的职业生涯中，您最喜欢哪些项目？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我参与最多的主要 CNCF 项目是：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/kubernetes&#34;&gt;Kubernetes&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/fluxcd/&#34;&gt;FluxCD&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/prometheus&#34;&gt;Prometheus&lt;/a&gt; 和 &lt;a href=&#34;https://github.com/grafana&#34;&gt;Grafana&lt;/a&gt; 堆栈&lt;/li &gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/cilium&#34;&gt;Cilium&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/rook&#34;&gt;Rook&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;发现 GitOps 方法真正改变了我的工作生活。  感谢 &lt;a href=&#34;https://github.com/argoproj/argo-cd&#34;&gt;ArgoCD &lt;/a&gt; 和 &lt;a href=&#34;https://github.com/fluxcd/&#34;&gt;FluxCD 等工具， &lt;/a&gt; 我意识到使用 git 部署和跟踪应用程序是多么“容易”。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;此外，感谢 &lt;a href=&#34;https://rook.io/&#34;&gt;Rook-ceph 存储提供商&lt;/a&gt;，我现在只需几分钟即可启动和配置存储集群分钟。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;是什么促使您获得所有 Kubernetes 证书？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;每个认证都有自己的故事。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;KCNA 是我的第一个认证。我在工作面试前拍摄了它，以便对我的 Kubernetes 技能更有信心。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;CKA 和 CKAD 是我需要帮助完成我正在开展的项目的两个证书。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;CKS 是我作为个人目标而获得的证书。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;KCSA 是我的最后一个。 Kubecon 结束后，当 Kubetronaut 计划宣布时，我得到了这个，并意识到我只需要再一个。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;这些证书对您的职业生涯有何帮助？ &lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这些认证使我能够练习和学习我日常不使用的技术和工具。准备认证是获得为未来项目做好准备所需教育的一种方式。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;您为想要使用 k8s 的人推荐了哪些其他书籍/网站/课程？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我发现这些在线课程是我的 Kubernetes 学习之旅的一个很好的起点：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;– 来自 kodekloud.com 的 CKA 和 CKAD 课程&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;– Kim Wuestkamp 在 YouTube 上提供的 CKS 在线课程&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;– 来自 aclodguru/pluralsight 的 CKA/CKAD/CKS 模拟考试&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;你空闲时间做什么？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我所有的空闲时间都和家人一起度过，我 15 个月大的女儿目前是我唯一的兴趣点。我也花时间在我的小屋里，所以我在那里平衡我的工作时间。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;正如您所知，Kubernetes 今年已满 10 岁了，您对 Kubernetes 未来 10 年最兴奋的是什么？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我的魔法球到目前为止还没有答案:)&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;您会对刚刚开始 K8s 认证之旅的人说些什么？有什么提示或技巧吗？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;没有比练习、练习、再练习更好的提示和技巧了。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;如今，云原生生态系统的意义远不止 Kubernetes。您是否计划获得 CNCF 的其他云原生认证？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;当然，我的下一个挑战是深入研究 Prometheus 堆栈并足够熟悉它，成为一名 &lt;a href=&#34;https://www.cncf.io/training/certification/pca/&#34;&gt;Prometheus认证助理 (PCA)&lt;/a&gt; &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;您是如何涉足云原生和 Kubernetes 的？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我有 Linux 管理背景，因此从那时起，发展到 Kubernetes 和云原生是合乎逻辑且自然的。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您想成为 Kubestronaut，请在&lt;a href=&#34;https://www.cncf.io/training/kubestronaut/&#34;&gt;CNCF Kubestronaut&lt;/a&gt;页面获取更多详细信息。 &lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Thu, 04 Jul 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Vitess 20 is now Generally Available】Vitess 20 现已全面上市</title>
      <link>https://www.cncf.io/blog/2024/06/27/vitess-20-is-now-generally-available/</link>
      <description>【&lt;p&gt;&lt;em&gt;Project post cross-posted on the &lt;a href=&#34;https://vitess.io/blog/2024-06-27-announcing-vitess-20/&#34;&gt;Vitess blog&lt;/a&gt;&lt;/em&gt; &lt;em&gt;by the Vitess Maintainer Team&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We’re delighted to announce the release of &lt;a href=&#34;https://github.com/vitessio/vitess/releases/tag/v20.0.0&#34;&gt;Vitess 20&lt;/a&gt; along with &lt;a href=&#34;https://github.com/planetscale/vitess-operator/releases/tag/v2.13.0&#34;&gt;version 2.13.0&lt;/a&gt; of the Vitess Kubernetes Operator.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Version 20 focuses on usability and maturity of existing features, and continues to build on the solid foundation of scalability and performance established in previous versions. Our commitment remains steadfast in providing a powerful, scalable, and reliable solution for your database scaling needs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;What’s New in Vitess 20&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Query Compatibility&lt;/strong&gt;: enhanced DML support including improved query compatibility, Vindex hints, and extended support for various sharded &lt;code&gt;update&lt;/code&gt; and &lt;code&gt;delete&lt;/code&gt; operations.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;VReplication&lt;/strong&gt;: multi-tenant imports (experimental).&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Online DDL&lt;/strong&gt;: improved support for various schema change scenarios, dropping support for &lt;code&gt;gh-ost&lt;/code&gt;.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Vitess Operator&lt;/strong&gt;: automated and scheduled backups.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Dive Deeper&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Let’s look into some key highlights of this release.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Query Compatibility&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The latest Vitess release enhances DML support with features like Vindex hints, sharded updates with limits, multi-table updates, and advanced delete operations.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Vindex hints enable users to influence shard routing:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;SELECT * FROM user USE VINDEX (hash_user_id, secondary_vindex) WHERE user_id = 123;&#xA;SELECT * FROM order IGNORE VINDEX (range_order_id) WHERE order_date = &#39;2021-01-01&#39;;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Sharded updates with limits are now supported:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;UPDATE t1 SET t1.foo = &#39;abc&#39;, t1.bar = 23 WHERE t1.baz &amp;gt; 5 LIMIT 1;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Multi-table updates and multi-target updates enhance flexibility:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;UPDATE t1 JOIN t2 ON t1.id = t2.id JOIN t3 ON t1.col = t3.col SET t1.baz = &#39;abc&#39;, t1.apa = 23 WHERE t3.foo = 5 AND t2.bar = 7;&#xA;UPDATE t1 JOIN t2 ON t1.id = t2.id SET t1.foo = &#39;abc&#39;, t2.bar = 23;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Advanced delete operations with subqueries and multi-target support are included:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;DELETE FROM t1 WHERE id IN (SELECT col FROM t2 WHERE foo = 32 AND bar = 43);&#xA;DELETE t1, t3 FROM t1 JOIN t2 ON t1.id = t2.id JOIN t3 ON t1.col = t3.col;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;These features provide greater control and efficiency for managing sharded data. For more details, please refer to the Vitess and MySQL documentation.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;VReplication: Multi-tenant Imports (experimental)&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Many web-scale applications use a multi-tenant architecture where each tenant has their own database (with identical schemas). There are several challenges with this approach like provisioning and scaling potentially tens of thousands of databases, and uniformly updating database schemas across them.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;A sharded Vitess &lt;a href=&#34;https://vitess.io/docs/concepts/keyspace/&#34;&gt;keyspace&lt;/a&gt; is a great option for such a system with a single logical database serving all tenants. Vitess 20 adds support for importing data from such a multi-tenant setup into a single Vitess &lt;a href=&#34;https://vitess.io/docs/concepts/keyspace/&#34;&gt;keyspace&lt;/a&gt;, with new &lt;a href=&#34;https://vitess.io/docs/reference/programs/vtctldclient/vtctldclient_movetables/vtctldclient_movetables_create/&#34;&gt;&lt;code&gt;--shards&lt;/code&gt; and &lt;code&gt;--tenant-id&lt;/code&gt; flags&lt;/a&gt; for the &lt;a href=&#34;https://vitess.io/docs/reference/vreplication/movetables/&#34;&gt;MoveTables workflow&lt;/a&gt;. You would run one such workflow for each tenant, with imported tenants being served by the Vitess cluster.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Online DDL&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Vitess migrations now support &lt;code&gt;enum&lt;/code&gt; definition reordering. Vitess opts to use &lt;code&gt;enum&lt;/code&gt;s by alias (their string representation) rather than by ordinal value (the internal integer representation).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Vitess now has better analysis for &lt;code&gt;INSTANT&lt;/code&gt; DDL scenarios, enabled with the &lt;code&gt;--prefer-instant-ddl&lt;/code&gt; DDL &lt;a href=&#34;https://vitess.io/docs/20.0/user-guides/schema-changes/ddl-strategy-flags/&#34;&gt;strategy flag&lt;/a&gt;. It is able to predict whether a migration can be fulfilled by the &lt;code&gt;INSTANT&lt;/code&gt; algorithm and use this algorithm if so.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;It also improves support for range partitioning migrations, and opts to use direct partitioning queries over Online DDL where appropriate.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;VDiffs can now be run on Online DDL Workflows which are still in progress (i.e. not yet cut-over).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Release 20.0 drops support for &lt;code&gt;gh-ost&lt;/code&gt; for Online DDL, as we continue to invest in &lt;code&gt;vitess&lt;/code&gt; migrations based on VReplication. The &lt;code&gt;gh-ost&lt;/code&gt; strategy is still recognized; however:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Vttablet binaries no longer bundle the &lt;code&gt;gh-ost&lt;/code&gt; binary. The user should provide their own &lt;code&gt;gh-ost&lt;/code&gt; binary, and supply &lt;code&gt;vttablet --gh-ost-path&lt;/code&gt;.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Vitess no longer tests &lt;code&gt;gh-ost&lt;/code&gt; in CI/endtoend tests.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Vitess-operator&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Automated and scheduled backups are now available as an experimental feature in v2.13.0. We have added a &lt;a href=&#34;https://vitess.io/docs/20.0/user-guides/operating-vitess/backup-and-restore/scheduled-backups/&#34;&gt;new user guide&lt;/a&gt; for this feature.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Vitess and the Community&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As an open-source project, Vitess thrives on the contributions, insights, and feedback from the community. Your experiences and input are invaluable in shaping the future of Vitess. We encourage you to share your stories and ask questions, on &lt;a href=&#34;https://github.com/vitessio/vitess&#34;&gt;GitHub&lt;/a&gt; or in our &lt;a href=&#34;http://vitess.io/slack&#34;&gt;Slack community&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Getting Started&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For a seamless transition to &lt;a href=&#34;https://github.com/vitessio/vitess/releases/tag/v20.0.0&#34;&gt;Vitess 20&lt;/a&gt;, we highly recommend reviewing the &lt;a href=&#34;https://github.com/vitessio/vitess/blob/main/changelog/20.0/20.0.0/release_notes.md&#34;&gt;detailed release notes&lt;/a&gt;. Additionally, you can explore &lt;a href=&#34;https://vitess.io/docs/20.0/&#34;&gt;our documentation&lt;/a&gt; for guides, best practices, and tips to make the most of Vitess 20. Whether you’re upgrading from a previous version or running Vitess for the first time, our resources are designed to support you every step of the way.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Thank you for your support and contributions to the Vitess project!&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;The Vitess Team&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;项目帖子交叉发布在 &lt;a href=&#34;https://vitess.io/blog/2024-06-27-announcing-vitess-20/&#34;&gt;Vitess 博客&lt;/a&gt;&lt;/ em&gt; &lt;em&gt;由 Vitess 维护者团队&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们很高兴地宣布发布 &lt;a href=&#34;https://github.com/vitessio/vitess/releases/tag/v20.0.0&#34;&gt;Vitess 20&lt;/a&gt; 以及 &lt;a href= “https://github.com/planetscale/vitess-operator/releases/tag/v2.13.0&#34;&gt;Vitess Kubernetes Operator 版本 2.13.0&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;版本 20 侧重于现有功能的可用性和成熟度，并继续建立在以前版本中建立的可扩展性和性能的坚实基础上。我们坚定不移地致力于为您的数据库扩展需求提供强大、可扩展且可靠的解决方案。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Vitess 20 的新增功能&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;查询兼容性&lt;/strong&gt;：增强的 DML 支持，包括改进的查询兼容性、Vindex 提示以及对各种分片&lt;code&gt;更新&lt;/code&gt;和&lt;code&gt;删除&lt;/code&gt;操作的扩展支持。&lt; /里&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;VReplication&lt;/strong&gt;：多租户导入（实验性）。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;在线 DDL&lt;/strong&gt;：改进了对各种架构更改场景的支持，放弃了对 &lt;code&gt;gh-ost&lt;/code&gt; 的支持。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Vitess Operator&lt;/strong&gt;：自动和定期备份。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;深入了解&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;让我们来看看此版本的一些主要亮点。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;查询兼容性&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;最新的 Vitess 版本通过 Vindex 提示、带限制的分片更新、多表更新和高级删除操作等功能增强了 DML 支持。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Vindex 提示使用户能够影响分片路由：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;SELECT * FROM 用户 USE VINDEX (hash_user_id, secondary_vindex) WHERE user_id = 123;&#xA;SELECT * FROM order IGNORE VINDEX (range_order_id) WHERE order_date = &#39;2021-01-01&#39;;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;现在支持有限制的分片更新：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;更新 t1 SET t1.foo = &#39;abc&#39;, t1.bar = 23 WHERE t1.baz &gt; 5 LIMIT 1;&lt;/code&gt;&lt;/上一篇&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;多表更新和多目标更新增强灵活性：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;更新 t1 加入 t2 上 t1.id = t2.id 加入 t3 上 t1.col = t3.col SET t1.baz = &#39;abc&#39;, t1.apa = 23，其中 t3.foo = 5 且 t2.bar = 7；&#xA;更新 t1 JOIN t2 ON t1.id = t2.id SET t1.foo = &#39;abc&#39;, t2.bar = 23;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;包括带有子查询和多目标支持的高级删除操作：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;DELETE FROM t1 WHERE id IN (SELECT col FROM t2 WHERE foo = 32 AND bar = 43);&#xA;从 t1 中删除 t1、t3 JOIN t2 ON t1.id = t2.id JOIN t3 ON t1.col = t3.col;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这些功能为管理分片数据提供了更好的控制和效率。更多详情请参考Vitess和MySQL文档。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;VReplication：多租户导入（实验性）&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;许多网络规模应用程序使用多租户架构，其中每个租户都有自己的数据库（具有相同的架构）。这种方法存在一些挑战，例如配置和扩展可能数以万计的数据库，以及跨这些数据库统一更新数据库架构。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;分片的 Vitess &lt;a href=&#34;https://vitess.io/docs/concepts/keyspace/&#34;&gt;keyspace&lt;/a&gt; 对于这样一个具有为所有租户提供服务的单一逻辑数据库的系统来说是一个很好的选择。 Vitess 20 添加了对将数据从此类多租户设置导入到单个 Vitess &lt;a href=&#34;https://vitess.io/docs/concepts/keyspace/&#34;&gt;keyspace&lt;/a&gt; 的支持，并带有新的 &lt;a href =&#34;https://vitess.io/docs/reference/programs/vtctldclient/vtctldclient_movetables/vtctldclient_movetables_create/&#34;&gt;&lt;code&gt;--shards&lt;/code&gt; 和 &lt;code&gt;--tenant-id&lt;/code&gt; 标志&lt;/ a&gt; &lt;a href=&#34;https://vitess.io/docs/reference/vreplication/movetables/&#34;&gt;MoveTables 工作流程&lt;/a&gt;。您将为每个租户运行一个这样的工作流程，导入的租户由 Vitess 集群提供服务。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;在线 DDL&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Vitess 迁移现在支持 &lt;code&gt;enum&lt;/code&gt; 定义重新排序。 Vitess 选择通过别名（其字符串表示形式）而不是序数值（内部整数表示形式）来使用枚举。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Vitess 现在可以更好地分析 &lt;code&gt;INSTANT&lt;/code&gt; DDL 场景，通过 &lt;code&gt;--prefer-instant-ddl&lt;/code&gt; DDL 启用 &lt;a href=&#34;https://vitess.io /docs/20.0/user-guides/schema-changes/ddl-strategy-flags/&#34;&gt;策略标志&lt;/a&gt;。它能够预测迁移是否可以通过&lt;code&gt;INSTANT&lt;/code&gt;算法完成，如果可以则使用该算法。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;它还改进了对范围分区迁移的支持，并在适当的情况下选择通过 Online DDL 使用直接分区查询。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;VDiff 现在可以在仍在进行中（即尚未切换）的在线 DDL 工作流程上运行。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;版本 20.0 不再支持 Online DDL 的 &lt;code&gt;gh-ost&lt;/code&gt;，因为我们继续投资基于 VReplication 的 &lt;code&gt;vitess&lt;/code&gt; 迁移。 &lt;code&gt;gh-ost&lt;/code&gt; 策略仍然被认可；然而：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Vttablet 二进制文件不再捆绑 &lt;code&gt;gh-ost&lt;/code&gt; 二进制文件。用户应提供自己的 &lt;code&gt;gh-ost&lt;/code&gt; 二进制文件，并提供 &lt;code&gt;vttablet --gh-ost-path&lt;/code&gt;。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Vitess 不再在 CI/endtoend 测试中测试 &lt;code&gt;gh-ost&lt;/code&gt;。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Vitess 运算符&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;自动和计划备份现已作为 v2.13.0 中的实验性功能提供。我们为此添加了&lt;a href=&#34;https://vitess.io/docs/20.0/user-guides/operating-vitess/backup-and-restore/scheduled-backups/&#34;&gt;新用户指南&lt;/a&gt;功能。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Vitess 和社区&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;作为一个开源项目，Vitess 依靠社区的贡献、见解和反馈而蓬勃发展。您的经验和投入对于塑造 Vitess 的未来非常宝贵。我们鼓励您在 &lt;a href=&#34;https://github.com/vitessio/vitess&#34;&gt;GitHub&lt;/a&gt; 或我们的 &lt;a href=&#34;http://vitess.io /slack&#34;&gt;Slack 社区&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;开始使用&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;为了无缝过渡到 &lt;a href=&#34;https://github.com/vitessio/vitess/releases/tag/v20.0.0&#34;&gt;Vitess 20&lt;/a&gt;，我们强烈建议您查看&lt;a href= “https://github.com/vitessio/vitess/blob/main/changelog/20.0/20.0.0/release_notes.md&#34;&gt;详细发行说明&lt;/a&gt;。此外，您还可以浏览&lt;a href=&#34;https://vitess.io/docs/20.0/&#34;&gt;我们的文档&lt;/a&gt;，获取指南、最佳实践和技巧，以充分利用 Vitess 20。从以前的版本升级或首次运行 Vitess，我们的资源旨在为您的每一步提供支持。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;感谢您对Vitess项目的支持和贡献！&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Vitess 团队&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Wed, 26 Jun 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Why you do not want a visualization of your Infrastructure as Code】为什么您不希望将基础架构可视化为代码</title>
      <link>https://www.cncf.io/blog/2024/06/24/why-you-do-not-want-a-visualization-of-your-infrastructure-as-code/</link>
      <description>【&lt;p&gt;&lt;em&gt;Originally published on the &lt;a href=&#34;https://blog.appcd.com/why-you-do-not-want-a-visualization-of-your-infrastructure-as-code&#34;&gt;appCD blog&lt;/a&gt; by Asif Awan&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1260&#34; height=&#34;630&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/07/Vector-1.webp&#34; alt=&#34;Screenshot mockup&#34; class=&#34;wp-image-113954&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/07/Vector-1.webp 1260w, https://www.cncf.io/wp-content/uploads/2024/07/Vector-1-300x150.webp 300w, https://www.cncf.io/wp-content/uploads/2024/07/Vector-1-1024x512.webp 1024w, https://www.cncf.io/wp-content/uploads/2024/07/Vector-1-768x384.webp 768w, https://www.cncf.io/wp-content/uploads/2024/07/Vector-1-900x450.webp 900w, https://www.cncf.io/wp-content/uploads/2024/07/Vector-1-400x200.webp 400w, https://www.cncf.io/wp-content/uploads/2024/07/Vector-1-800x400.webp 800w&#34; sizes=&#34;(max-width: 1260px) 100vw, 1260px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;You’ve been working on a new application for your company. It is going to address business requirements needed to delight customers. But while you are ready to ship your code, you now need to set up your infrastructure. The good news is that Infrastructure as Code (IaC) exists and promises to make it easier for you to codify all the components needed for your application to run smoothly: the compute cluster, network setup, and platform resources such as databases and storage buckets required to name a few. The idea is the development team spends less time on infrastructure and more time actually building and shipping cool stuff that helps drive sales.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;IaC promised to help all of us avoid mistakes through automation that can be easily tweaked and adjusted. The problem is that IaC is a huge list of all the parts of your infrastructure to be provisioned; you can’t technically see it so you have to keep all the separate components and how they relate to one another in your brain. Which means that you need to expand your expertise beyond development and into all facets of infrastructure so that you can code your infrastructure without making errors like over-permissioning or over-provisioning resources.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Infrastructure as Code Challenges&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Infrastructure as Code does speed up deployment, it’s definitely faster than manual provisioning. Users can more easily get an application or feature shipped using IaC. But it isn’t perfect and can still be a slow process to truly get the cloud infrastructure needed.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Most developers I know turn to templates that the platform eng or DevOps teams provide. These “&lt;a href=&#34;https://blog.appcd.com/infrastructure-as-code-standards-vs-templates&#34;&gt;golden templates”&lt;/a&gt;&amp;nbsp;are a point-in-time representation of how the infrastructure team wants infrastructure provisioned. But because we are all moving quickly, that template has been copied and pasted several times and modified by developers. It might be missing the latest update. It certainly doesn’t cover the new security requirements so the dev team is either:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Pushing IaC that is insecure, over provisioned or non-compliant OR&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Asking the infra team to serve as a helpdesk so apps can be shipped.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Devs are hired for their expertise in development. And while many have experience in infrastructure or have had to work with it, we are asking devs to also be infrastructure, security and compliance experts when we ask them to write IaC. What happens is a lot of guesswork, internet research and copy-paste from other sources that wastes every person’s time.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This guesswork is because once again we can’t see or touch our cloud infrastructure. Instead we have to write IaC and test and test and test…&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;An Architecture Deployment Visualization Could Help&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;A visualization of your IaC could help, but why would you want to add another step to deploy your application? Now you have to draw a topology to show what infrastructure you are provisioning. Or you could use Infrastructure from Code.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Infrastructure from Code uses your application code as the source of truth for the infrastructure that your application requires and needs to be secure, reliable and efficient. With Infrastructure from Code, you can save many hours, days or even weeks to deploy your application.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;With Infrastructure from Code you can actually view the IaC for your applications. Simply by connecting a repo, selecting your target compute service and policies (AWS well architected framework for example), you can create a visualization of your IaC.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;From there, you can enhance it with a drag and drop interface and actually validate that it is going to work. Say, for example, you are attempting to connect a resource with excessive permissions or a database that isn’t allowed, you won’t be allowed to make that connection. Infrastructure from Code won’t allow any IaC export if there are any validation or verification errors.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;But Why Do all That?&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;But why would you want to cheat yourself out of the delays in shipping your application? Why would you want to remove the guesswork from the infrastructure part of your job (that you dislike). A drag and drop interface might be robbing you of that tedious coding experience you really want.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Why would you want to avoid all that? Because if you can skip that pain and get the IaC generated from your application code, you can do the job you were hired to do. That means you are more valuable to your organization because you can draw a direct line between what you are coding to how your organization is servicing customers.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Plus, when you generate IaC that is correct, secure and compliant. You’ll look smart to those infrastructure peeps and that just feels good.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Try&amp;nbsp;&lt;a href=&#34;https://www.appcd.com/get-started&#34;&gt;infrastructure from code&lt;/a&gt;. Connect a repo, get your deployment architecture for free. You can get IaC generated in minutes without using Reddit, Hacker News or Google to help!&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;最初发布于&lt;a href=&#34;https://blog.appcd.com/why-you-do-not-want-a-visualization-of-your-infrastruct-as-code&#34;&gt; appCD 博客&lt;/a&gt;，作者：Asif Awan&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“1260”高度=“630”src=“https://www.cncf.io/ wp-content/uploads/2024/07/Vector-1.webp&#34; alt=&#34;屏幕截图模型&#34; class=&#34;wp-image-113954&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/ 2024/07/Vector-1.webp 1260w，https://www.cncf.io/wp-content/uploads/2024/07/Vector-1-300x150.webp 300w，https://www.cncf.io/ wp-content/uploads/2024/07/Vector-1-1024x512.webp 1024w，https://www.cncf.io/wp-content/uploads/2024/07/Vector-1-768x384.webp 768w，https： //www.cncf.io/wp-content/uploads/2024/07/Vector-1-900x450.webp 900w，https://www.cncf.io/wp-content/uploads/2024/07/Vector-1 -400x200.webp 400w，https://www.cncf.io/wp-content/uploads/2024/07/Vector-1-800x400.webp 800w“尺寸=”（最大宽度：1260px）100vw，1260px“引用策略=“无引用者”&gt;&lt;/图&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;您一直在为您的公司开发一个新应用程序。它将满足取悦客户所需的业务需求。但是，当您准备好交付代码时，您现在需要设置基础架构。好消息是基础设施即代码 (IaC) 的存在，并有望让您更轻松地编写应用程序平稳运行所需的所有组件：计算集群、网络设置以及所需的数据库和存储桶等平台资源仅举几例。我们的想法是，开发团队在基础设施上花费更少的时间，而花更多的时间来实际构建和交付有助于推动销售的酷东西。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;IaC 承诺通过可轻松调整和调整的自动化来帮助我们所有人避免错误。问题在于 IaC 是一个包含要配置的基础设施所有部分的庞大列表；从技术上讲，你无法看到它，因此你必须将所有单独的组件以及它们之间的相互关系保留在你的大脑中。这意味着您需要将您的专业知识扩展到开发以外的基础设施的各个方面，以便您可以对基础设施进行编码，而不会犯过度许可或过度配置资源等错误。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;基础设施即代码挑战&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;基础设施即代码确实可以加快部署速度，它绝对比手动配置更快。用户可以更轻松地使用 IaC 交付应用程序或功能。但这并不完美，真正获得所需的云基础设施仍然是一个缓慢的过程。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我认识的大多数开发人员都会转向平台工程师或 DevOps 团队提供的模板。这些&lt;a href=&#34;https://blog.appcd.com/infrastruct-as-code-standards-vs-templates&#34;&gt;黄金模板&lt;/a&gt;是基础架构团队如何希望提供基础设施。但由于我们都在快速行动，该模板已经被开发人员复制和粘贴了多次并进行了修改。可能缺少最新更新。它当然不涵盖新的安全要求，因此开发团队要么：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;推行不安全、过度配置或不合规的 IaC 或&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;要求基础设施团队充当帮助台，以便交付应用。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;开发人员因其开发方面的专业知识而被聘用。虽然许多人都有基础设施方面的经验或曾经使用过基础设施，但当我们要求开发人员编写 IaC 时，我们要求他们也成为基础设施、安全和合规性专家。发生的事情是大量的猜测、互联网研究和从其他来源复制粘贴，浪费了每个人的时间。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这种猜测是因为我们再次无法看到或触摸我们的云基础设施。相反，我们必须编写 IaC 并测试、测试、测试……&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;架构部署可视化可以提供帮助&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;IaC 的可视化可能会有所帮助，但为什么要添加另一个步骤来部署应用程序呢？现在您必须绘制一个拓扑来显示您正在配置的基础设施。或者您可以使用代码基础设施。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;代码基础架构使用您的应用程序代码作为您的应用程序所需且需要安全、可靠和高效的基础架构的真实来源。借助代码基础架构，您可以节省数小时、数天甚至数周的时间来部署应用程序。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;通过代码基础架构，您实际上可以查看应用程序的 IaC。只需连接存储库，选择目标计算服务和策略（例如 AWS 架构良好的框架），您就可以创建 IaC 的可视化。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;从那里，您可以通过拖放界面增强它，并实际验证它是否可以工作。例如，假设您尝试连接具有过多权限的资源或不允许的数据库，则将不允许您建立该连接。如果存在任何验证或验证错误，来自代码的基础设施将不允许导出任何 IaC。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;但是为什么要这么做呢？&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;但是您为什么要在申请发送延迟的情况下欺骗自己呢？为什么你想从你的工作的基础设施部分中消除猜测（你不喜欢）。拖放界面可能会剥夺您真正想要的乏味编码体验。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;你为什么要避免这一切？因为如果您可以跳过这个痛苦并从您的应用程序代码生成 IaC，您就可以完成您被雇用要做的工作。这意味着您对您的组织更有价值，因为您可以在您的编码内容与您的组织如何为客户提供服务之间建立直接的联系。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;此外，当您生成正确、安全且合规的 IaC 时。对于那些基础设施窥视者来说，你会显得很聪明，这感觉很好。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;尝试&lt;a href=&#34;https://www.appcd.com/get-started&#34;&gt;代码基础架构&lt;/a&gt;。连接存储库，免费获取您的部署架构。您可以在几分钟内生成 IaC，而无需使用 Reddit、Hacker News 或 Google 来提供帮助！&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Sun, 23 Jun 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Celebrating 10 years of Kubernetes: the evolution of database operators】庆祝 Kubernetes 十周年：数据库运营商的演变</title>
      <link>https://www.cncf.io/blog/2024/06/28/celebrating-10-years-of-kubernetes-the-evolution-of-database-operators/</link>
      <description>【&lt;p&gt;&lt;em&gt;Ambassador post by Edith Puclla, CNCF Ambassador and Tech Evangelist at Percona&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Since its launch in June 2014, Kubernetes has revolutionized container orchestration, transforming how applications are managed and scaled.&amp;nbsp; The Data on Kubernetes Community (DoKC) created an infographic to celebrate Kubernetes’ tenth anniversary and highlight key milestones and community contributions to the evolution of operators for managing stateful applications. This infographic was made possible through the collaboration of several members of the DoKC: Sergey Pronin, Robert Hodges, Gabriele Bartolini, Chris Malarky, &lt;a href=&#34;mailto:mark.kember@onebite.co.uk&#34;&gt;Mark Kember&lt;/a&gt;, &lt;a href=&#34;mailto:paul@constantia.io&#34;&gt;Paul Au&lt;/a&gt; and &lt;a href=&#34;mailto:luciano.stabel@percona.com&#34;&gt;Luciano Stabel&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1600&#34; height=&#34;1134&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/07/image-6.jpg&#34; alt=&#34;Timeline for Database on Kubernetes&#34; class=&#34;wp-image-113957&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/07/image-6.jpg 1600w, https://www.cncf.io/wp-content/uploads/2024/07/image-6-300x213.jpg 300w, https://www.cncf.io/wp-content/uploads/2024/07/image-6-1024x726.jpg 1024w, https://www.cncf.io/wp-content/uploads/2024/07/image-6-768x544.jpg 768w, https://www.cncf.io/wp-content/uploads/2024/07/image-6-900x638.jpg 900w, https://www.cncf.io/wp-content/uploads/2024/07/image-6-282x200.jpg 282w, https://www.cncf.io/wp-content/uploads/2024/07/image-6-564x400.jpg 564w&#34; sizes=&#34;(max-width: 1600px) 100vw, 1600px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Early Days and Key Developments&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;2014&lt;/strong&gt;: Kubernetes was introduced by Google as an open-source container orchestration platform. The initial version 1.0 was released in July 2015, supporting stateless applications but not stateful workloads like databases.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;2015&lt;/strong&gt;: Kubernetes 1.1 brought performance upgrades and new features. However, data and storage management remained underdeveloped.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;2016&lt;/strong&gt;: CoreOS introduced the operator concept, significantly simplifying the deployment and management of complex applications, including databases on Kubernetes. StatefulSets were also introduced providing stable network identifiers and persistent storage which are crucial for database management.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Database Operators and Community Innovations&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;2017&lt;/strong&gt;: The first Kubernetes Operators for databases emerged:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;MySQL Operator&lt;/strong&gt;: Launched by Oracle.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;MongoDB Operator&lt;/strong&gt;: Developed by MongoDB Inc.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;2018&lt;/strong&gt;: Couchbase and PostgreSQL Operators were introduced, enhancing the automated management of Couchbase clusters and providing support for PostgreSQL databases.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;2019&lt;/strong&gt;: ClickHouse and&lt;strong&gt; Cassandra Operators&lt;/strong&gt; were launched. &lt;a href=&#34;https://www.percona.com/software/percona-operators&#34;&gt;Percona&lt;/a&gt; introduced its own set of Kubernetes Operators for managing Percona server instances for MySQL and MongoDB, improving database management capabilities in Kubernetes environments.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Community Growth and Collaborative Efforts&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;By 2020, the Data on Kubernetes Community (DoKC) was established with the main goal of collaboration and sharing best practices for running data-intensive applications on Kubernetes.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Later, the Kubernetes Special Interest Groups (SIGs) focusing on storage, big data, and applications emerged as key collaborative working groups. These groups have produced valuable resources, such as the &lt;a href=&#34;https://github.com/cncf/tag-storage/blob/master/data-on-kubernetes-whitepaper/data-on-kubernetes-whitepaper-databases.md&#34;&gt;Data on Kubernetes Whitepaper&lt;/a&gt;, produced in collaboration with the CNCF Storage TAG.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Adoption and Impact&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;According to the CNCF, 84% of organizations are either using or evaluating Kubernetes, and 70% run stateful applications on Kubernetes in production. More users and containers have been added over time, evidenced by an increased number of contributors, greater adoption of cloud-native technologies, and more use cases for handling stateful applications in Kubernetes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Looking Ahead&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As we celebrate a decade of Kubernetes, the integration of databases continues to evolve driven by community collaboration and technological advancements. A good example of this is Percona Everest. Percona Everest goes beyond being just a Kubernetes Operator for databases. It represents the future of databases on Kubernetes. It provides an easy way to run any type of database on Kubernetes clusters in the cloud and is completely open-source. Would you like to give it a try? Feel free to visit our &lt;a href=&#34;https://github.com/percona/everest&#34;&gt;GitHub repository&lt;/a&gt; and give us a star if you find it useful. For any feedback or comments, you can write to us in our &lt;a href=&#34;https://forums.percona.com/c/percona-everest/81&#34;&gt;Pecona Forum for Percona Everest&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;945&#34; height=&#34;221&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/07/image-6-1.jpg&#34; alt=&#34;Percona forum on github for Perscona Everest&#34; class=&#34;wp-image-113958&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/07/image-6-1.jpg 945w, https://www.cncf.io/wp-content/uploads/2024/07/image-6-1-300x70.jpg 300w, https://www.cncf.io/wp-content/uploads/2024/07/image-6-1-768x180.jpg 768w, https://www.cncf.io/wp-content/uploads/2024/07/image-6-1-900x210.jpg 900w, https://www.cncf.io/wp-content/uploads/2024/07/image-6-1-600x140.jpg 600w&#34; sizes=&#34;(max-width: 945px) 100vw, 945px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For more details, explore the rich history and ongoing developments in the Kubernetes ecosystem at&lt;a href=&#34;https://dok.community/&#34;&gt; Data on Kubernetes Community&lt;/a&gt; and join the conversation for the future of database management on Kubernetes.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;由 CNCF 大使兼 Percona 技术布道师 Edith Puclla 担任大使职务&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;自 2014 年 6 月推出以来，Kubernetes 彻底改变了容器编排，改变了应用程序的管理和扩展方式。  Data on Kubernetes Community (DoKC) 创建了一个信息图来庆祝 Kubernetes 十周年，并强调了关键里程碑和社区对管理有状态应用程序的操作员发展的贡献。此信息图是通过 DoKC 的几位成员的合作而得以实现的：Sergey Pronin、Robert Hodges、Gabriele Bartolini、Chris Malarky、&lt;a href=&#34;mailto:mark.kember@onebite.co.uk&#34;&gt;Mark Kember&lt;/a &gt;、&lt;a href=&#34;mailto:paul@constantia.io&#34;&gt;Paul Au&lt;/a&gt; 和 &lt;a href=&#34;mailto:luciano.stabel@percona.com&#34;&gt;Luciano Stabel&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“1600”高度=“1134”src=“https://www.cncf.io/ wp-content/uploads/2024/07/image-6.jpg&#34; alt=&#34;Kubernetes 上数据库的时间线&#34; class=&#34;wp-image-113957&#34; srcset=&#34;https://www.cncf.io/wp-content /uploads/2024/07/image-6.jpg 1600w，https://www.cncf.io/wp-content/uploads/2024/07/image-6-300x213.jpg 300w，https://www.cncf .io/wp-content/uploads/2024/07/image-6-1024x726.jpg 1024w，https://www.cncf.io/wp-content/uploads/2024/07/image-6-768x544.jpg 768w ，https://www.cncf.io/wp-content/uploads/2024/07/image-6-900x638.jpg 900w，https://www.cncf.io/wp-content/uploads/2024/07/ image-6-282x200.jpg 282w，https://www.cncf.io/wp-content/uploads/2024/07/image-6-564x400.jpg 564w“尺寸=”（最大宽度：1600px）100vw， 1600px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;早期和主要发展&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;2014 年&lt;/strong&gt;：Google 推出 Kubernetes 作为开源容器编排平台。初始版本 1.0 于 2015 年 7 月发布，支持无状态应用程序，但不支持数据库等有状态工作负载。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;2015&lt;/strong&gt;：Kubernetes 1.1 带来了性能升级和新功能。然而，数据和存储管理仍然不发达。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;2016&lt;/strong&gt;：CoreOS 引入了 Operator 概念，显着简化了复杂应用程序的部署和管理，包括 Kubernetes 上的数据库。还引入了 StatefulSet，提供稳定的网络标识符和持久存储，这对于数据库管理至关重要。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;数据库运营商和社区创新&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;2017&lt;/strong&gt;：第一个数据库 Kubernetes Operator 出现：&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;MySQL Operator&lt;/strong&gt;：由 Oracle 推出。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;MongoDB Operator&lt;/strong&gt;：由 MongoDB Inc. 开发&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;2018&lt;/strong&gt;：推出 Couchbase 和 PostgreSQL Operator，增强了 Couchbase 集群的自动化管理并提供对 PostgreSQL 数据库的支持。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;2019&lt;/strong&gt;：ClickHouse 和&lt;strong&gt;Cassandra Operators&lt;/strong&gt; 推出。 &lt;a href=&#34;https://www.percona.com/software/percona-operators&#34;&gt;Percona&lt;/a&gt; 引入了自己的一组 Kubernetes Operators，用于管理 MySQL 和 MongoDB 的 Percona 服务器实例，从而提高 Kubernetes 中的数据库管理功能环境。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;社区发展和协作努力&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;到 2020 年，Data on Kubernetes Community (DoKC) 成立，主要目标是协作和分享在 Kubernetes 上运行数据密集型应用程序的最佳实践。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;后来，专注于存储、大数据和应用程序的 Kubernetes 特别兴趣组 (SIG) 成为关键的协作工作组。这些小组提供了宝贵的资源，例如 &lt;a href=&#34;https://github.com/cncf/tag-storage/blob/master/data-on-kubernetes-whitepaper/data-on-kubernetes-whitepaper-databases .md&#34;&gt;Kubernetes 白皮书上的数据&lt;/a&gt;，与 CNCF Storage TAG 合作制作。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;采用和影响&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;根据 CNCF 的数据，84% 的组织正在使用或评估 Kubernetes，70% 的组织在生产中在 Kubernetes 上运行有状态应用程序。随着时间的推移，添加了更多的用户和容器，贡献者数量的增加、云原生技术的更多采用以及在 Kubernetes 中处理有状态应用程序的更多用例就证明了这一点。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;展望未来&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在我们庆祝 Kubernetes 十周年之际，数据库的集成在社区协作和技术进步的推动下不断发展。 Percona Everest 就是一个很好的例子。 Percona Everest 不仅仅是一个数据库 Kubernetes Operator。它代表了 Kubernetes 上数据库的未来。它提供了一种在云中的 Kubernetes 集群上运行任何类型数据库的简单方法，并且完全开源。您想尝试一下吗？请随时访问我们的 &lt;a href=&#34;https://github.com/percona/everest&#34;&gt;GitHub 存储库&lt;/a&gt;，如果您觉得有用，请给我们一个星星。如需任何反馈或意见，您可以在我们的 &lt;a href=&#34;https://forums.percona.com/c/percona-everest/81&#34;&gt;Percona Everest 的 Pecona 论坛&lt;/a&gt;中给我们写信。&lt;/p &gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“945”高度=“221”src=“https://www.cncf.io/ wp-content/uploads/2024/07/image-6-1.jpg&#34; alt=&#34;Percona Everest github 上的 Percona 论坛&#34; class=&#34;wp-image-113958&#34; srcset=&#34;https://www.cncf.io /wp-content/uploads/2024/07/image-6-1.jpg 945w，https://www.cncf.io/wp-content/uploads/2024/07/image-6-1-300x70.jpg 300w ，https://www.cncf.io/wp-content/uploads/2024/07/image-6-1-768x180.jpg 768w，https://www.cncf.io/wp-content/uploads/2024/ 07/image-6-1-900x210.jpg 900w，https://www.cncf.io/wp-content/uploads/2024/07/image-6-1-600x140.jpg 600w&#34; 尺寸 = &#34;(最大-宽度：945px) 100vw，945px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如需了解更多详细信息，请访问&lt;a href=&#34;https://dok.community/&#34;&gt;Kubernetes 社区数据&lt;/a&gt;探索 Kubernetes 生态系统的悠久历史和持续发展，并加入关于未来的对话Kubernetes 上的数据库管理。&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Thu, 27 Jun 2024 16:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>