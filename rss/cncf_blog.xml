<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>CNCF - Blog</title>
    <link>http://cloudys-rsshub-ab061133bcab.herokuapp.com/cncf</link>
    <description>CNCF - Blog - Powered by RSSHub</description>
    <managingEditor>contact@rsshub.app (RSSHub)</managingEditor>
    <item>
      <title>【KubeCon + CloudNativeCon North America 2025 Co-Located Event Deep Dive: Platform Engineering Day】KubeCon + CloudNativeCon North America 2025 同期举办活动深入探讨：平台工程日</title>
      <link>https://www.cncf.io/blog/2025/10/17/kubecon-cloudnativecon-north-america-2025-co-located-event-deep-dive-platform-engineering-day/</link>
      <description>【&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1736&#34; height=&#34;352&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/image-2-8.jpg&#34; alt=&#34;Platform Engineer Day graphic with location, date and time&#34; class=&#34;wp-image-149525&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2025/10/image-2-8.jpg 1736w, https://www.cncf.io/wp-content/uploads/2025/10/image-2-8-300x61.jpg 300w, https://www.cncf.io/wp-content/uploads/2025/10/image-2-8-1024x208.jpg 1024w, https://www.cncf.io/wp-content/uploads/2025/10/image-2-8-768x156.jpg 768w, https://www.cncf.io/wp-content/uploads/2025/10/image-2-8-900x182.jpg 900w, https://www.cncf.io/wp-content/uploads/2025/10/image-2-8-600x122.jpg 600w, https://www.cncf.io/wp-content/uploads/2025/10/image-2-8-1200x243.jpg 1200w&#34; sizes=&#34;auto, (max-width: 1736px) 100vw, 1736px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This marks the fourth edition of Platform Engineering Day, following successful events in Paris (2024), Salt Lake City (2024), and London (2025). We’re excited to continue exploring case studies and deep technical dives as platform engineering practices mature.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In Atlanta, we’ll continue the expanded two-track format introduced in London earlier this year, giving attendees even more opportunities to explore topics most relevant to them.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Who will get the most out of attending this event?&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This event is really aimed at anyone who is building platforms, using platforms or trying to learn more about platform engineering, wherever they are on their journey. There will be content from end-user organizations and updates from the Platform Engineering Community Group, ensuring something valuable for attendees at every level.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;What is new and different this year?&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This year we’re aiming for content that goes deeper into the topics of platform maturity and more use cases of lessons that organisations have learnt. Expect even more real-world insights from practitioners who are shaping the next phase of platform engineering.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;What will the day look like?&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The day will feature two parallel tracks covering topics such as developer experience, API-driven infrastructure, and the evolving future of platform engineering. We’ll start and end the day together, giving attendees a shared sense of community while still allowing freedom to choose sessions that match their interests.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Should I do any homework first?&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;No pre-work is needed—just bring your curiosity! We have an incredible lineup of speakers who will be happy to answer questions and share insights.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We can’t wait to see you there—join us for an inspiring day of learning, connection, and platform innovation.&lt;br&gt;&lt;br&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; Decoding=&#34;async&#34; width=&#34;1736&#34; height=&#34;352&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/image-2-8.jpg&#34; alt=&#34;平台工程师日图形，包含位置、日期和 时间&#34; class=&#34;wp-image-149525&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2025/10/image-2-8.jpg 1736w, https://www.cncf.io/wp-content/uploads/2025/10/image-2-8-300x61.jpg 300w，https://www.cncf.io/wp-content/uploads/2025/10/image-2-8-1024x208.jpg 1024w， https://www.cncf.io/wp-content/uploads/2025/10/image-2-8-768x156.jpg 768w，https://www.cncf.io/wp-content/uploads/2025/10/image-2-8-900x182.jpg 900w， https://www.cncf.io/wp-content/uploads/2025/10/image-2-8-600x122.jpg 600w，https://www.cncf.io/wp-content/uploads/2025/10/image-2-8-1200x243.jpg 1200w“尺寸=”自动， （最大宽度：1736px）100vw，1736px“referrerpolicy =“no-referrer”&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;继巴黎（2024 年）、盐湖城（2024 年）和伦敦（2025 年）成功举办活动之后，这是第四届平台工程日。随着平台工程实践的成熟，我们很高兴能够继续探索案例研究和深入的技术研究。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在亚特兰大，我们将继续今年早些时候在伦敦推出的扩展的双轨形式，为与会者提供更多机会探索与他们最相关的主题。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;谁将从参加本次活动中获益最多？&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;本次活动实际上是针对任何正在构建平台、使用平台或试图了解更多平台工程知识的人，无论他们身处何处。将会有来自最终用户组织的内容和来自平台工程社区组的更新，确保为各个级别的与会者提供有价值的内容。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;今年有什么新的和不同的？&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;今年，我们的目标是提供更深入探讨平台成熟度主题的内容，以及更多组织吸取的经验教训的用例。期待塑造平台工程下一阶段的从业者提供更多现实世界的见解。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;这一天会是什么样子？&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这一天将有两个平行的主题，涵盖开发人员体验、API 驱动的基础设施以及平台工程不断发展的未来等主题。我们将一起开始和结束这一天，让与会者有一种共同的社区感，同时仍然允许自由选择符合他们兴趣的会议。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;我应该先做作业吗？&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;无需做任何准备工作——只需带上你的好奇心即可！我们拥有令人难以置信的演讲者阵容，他们很乐意回答问题并分享见解。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们迫不及待地想在那里见到您 - 与我们一起度过充满启发的学习、联系和平台创新的一天。&lt;br&gt;&lt;br&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div样式=“高度：8”0px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Thu, 16 Oct 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Why Autonomous Infrastructure is the future: From intent to self-operating systems】为什么自治基础设施是未来：从意图到自主操作系统</title>
      <link>https://www.cncf.io/blog/2025/10/17/why-autonomous-infrastructure-is-the-future-from-intent-to-self-operating-systems/</link>
      <description>【&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1310&#34; height=&#34;742&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-17-at-12.46.52-PM.jpg&#34; alt=&#34;Image: The future is autonomous infrastructure&#34; class=&#34;wp-image-149772&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-17-at-12.46.52-PM.jpg 1310w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-17-at-12.46.52-PM-300x170.jpg 300w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-17-at-12.46.52-PM-1024x580.jpg 1024w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-17-at-12.46.52-PM-768x435.jpg 768w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-17-at-12.46.52-PM-900x510.jpg 900w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-17-at-12.46.52-PM-353x200.jpg 353w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-17-at-12.46.52-PM-706x400.jpg 706w&#34; sizes=&#34;auto, (max-width: 1310px) 100vw, 1310px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;&lt;strong&gt;Executive summary:&lt;/strong&gt; We’re at an inflection point where AI-generated code meets AI-managed infrastructure, creating truly self-sustaining systems. This convergence transforms infrastructure from static pipelines to autonomous systems that build, govern, heal, and optimize themselves. Organizations have a narrow window to establish competitive advantage through autonomous infrastructure adoption—particularly in technology-driven industries where infrastructure agility directly impacts market responsiveness.&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;AI is increasingly being applied in infrastructure, moving from assistive tools toward systems that can make autonomous decisions. This shift builds on earlier conversations in the community around&lt;a href=&#34;https://platformengineering.org/blog/intent-to-infrastructure-platform-engineers-break-bottlenecks-with-ai&#34;&gt; intent-to-infrastructure approaches&lt;/a&gt;, such as those highlighted at PlatformCon this year, where platform engineers discussed using AI to address bottlenecks.&lt;br&gt;In this &lt;a href=&#34;https://stackgen.com/blog/introducing-stackgen-autonomous-infrastructure-platform&#34;&gt;post&lt;/a&gt;, we describe one implementation of that idea: infrastructure that can operate with minimal human intervention, guided by intent-driven inputs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;When AI development meets AI operations&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We’re approaching an inflection point where AI-generated code meets AI-managed infrastructure. This convergence is transforming infrastructure from static pipelines to intelligent systems that can generate, adapt, and evolve continuously.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/unleashing-developer-productivity-with-generative-ai&#34;&gt;While AI has accelerated development tasks by 2-3x&lt;/a&gt;, infrastructure bottlenecks continue to drain $2.5 million annually per 100 developers in lost productivity. But this isn’t just about efficiency—it’s about a fundamental transformation in how we conceive of infrastructure itself.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The shift from traditional automation to autonomous systems represents the next phase of infrastructure evolution. Where conventional automation manages what already exists, autonomous infrastructure builds, governs, heals, and optimizes itself. It’s the difference between a thermostat and a self-designing building that continuously optimizes itself for every condition while learning and improving over time.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Beyond automation: The three phases of infrastructure evolution&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Phase 1: Manual infrastructure (2010-2020)&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The era of point-and-click cloud consoles, where infrastructure experts manually provisioned resources through web interfaces and CLI commands. Knowledge was tribal, processes were documented in wikis, and scaling required hiring more infrastructure engineers.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Phase 2: Automated infrastructure (2020-2025)&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Infrastructure as Code revolutionized repeatability and version control. Tools like Terraform and Ansible enabled consistent deployments, but still required human orchestration, constant oversight, and manual intervention for drift detection and remediation.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Phase 3: Autonomous infrastructure (2025-2030)&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Infrastructure that builds, governs, heals, and optimizes itself. Systems that understand business intent, generate optimal configurations, enforce policies continuously, detect and remediate issues proactively, and learn from every interaction to improve future decisions.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We’re not just entering Phase 3—we’re defining it.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;The deterministic + probabilistic convergence&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The breakthrough that makes autonomous infrastructure possible is the marriage of deterministic reliability with probabilistic intelligence. &lt;a href=&#34;https://www.pwc.com/us/en/tech-effect/ai-analytics/ai-agent-survey.html&#34;&gt;As industry analysts note&lt;/a&gt;, this represents “the shift from infrastructure as a static pipeline to an autonomous system enabled by intelligent agents, at a time when 88% of IT leaders plan to adopt AI-driven capabilities within the next 12 months.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Autonomous infrastructure combines deterministic policy frameworks that ensure compliance, security, and reliability with AI agents that understand context, learn from outcomes, and make intelligent decisions. From our experience with early enterprise customers, this convergence addresses AI reliability concerns that have historically limited autonomous operations while meeting the governance requirements that auditors and compliance teams demand.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This convergence transforms infrastructure from a static pipeline into an autonomous system enabled by intelligent agents, creating what analysts are calling a fundamental shift in how enterprises approach cloud operations.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;The end of infrastructure as a limiting factor&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For decades, infrastructure complexity has grown exponentially while development velocity has been constrained by infrastructure delivery bottlenecks. Autonomous infrastructure inverts this relationship.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Consider the trajectory:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;2025&lt;/strong&gt;: Early adopters deploy AI agents for specific infrastructure tasks, &lt;a href=&#34;https://www.cloudera.com/about/news-and-blogs/press-releases/2025-04-16-96-percent-of-enterprises-are-expanding-use-of-ai-agents-according-to-latest-data-from-cloudera.html&#34;&gt;seeing 95% automated provisioning&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;2026&lt;/strong&gt;: Autonomous infrastructure becomes standard for leading tech companies, enabling infrastructure to scale dynamically with business needs&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;2027&lt;/strong&gt;: Manual infrastructure management becomes a competitive disadvantage as autonomous systems deliver 10x productivity gains&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;2028&lt;/strong&gt;: Fully autonomous infrastructure becomes the enterprise standard, with infrastructure decisions happening at machine speed&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The organizations making this transition today will define the competitive landscape for the next decade in technology and technology-driven industries.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;From reactive fire-fighting to proactive intelligence&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Traditional infrastructure management is inherently reactive. Issues are detected after they occur, drift is discovered during audits, and optimization happens during quarterly reviews. Autonomous infrastructure inverts this model entirely.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Imagine infrastructure that:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Prevents issues before they occur&lt;/strong&gt; by continuously analyzing patterns and proactively adjusting configurations&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Optimizes for changing business priorities&lt;/strong&gt; in real-time, balancing cost, performance, and reliability automatically&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Learns from every deployment and incident&lt;/strong&gt; to improve future decisions across the entire organization&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Scales expertise democratically&lt;/strong&gt; so every team benefits from the collective intelligence of the platform&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This isn’t science fiction—this is the natural evolution of infrastructure management in an AI-first world.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Theulti-agent infrastructure lifecycle&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To illustrate how autonomous infrastructure works in practice, consider this example workflow where multiple AI agents collaborate across a complete infrastructure lifecycle:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Developer Intent&lt;/strong&gt; → &lt;strong&gt;Infrastructure Generation&lt;/strong&gt; → &lt;strong&gt;Smart Provisioning&lt;/strong&gt; → &lt;strong&gt;Intelligent Monitoring&lt;/strong&gt; → &lt;strong&gt;AI Remediation&lt;/strong&gt; → &lt;strong&gt;Continuous Learning&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Each stage is powered by specialized agents that understand organizational context, enforce policies automatically, and continuously improve based on outcomes. This creates a self-reinforcing cycle where infrastructure becomes more intelligent and aligned with business objectives over time.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This multi-agent approach ensures that autonomous infrastructure isn’t just reactive automation—it’s proactive intelligence that prevents problems, optimizes continuously, and evolves with your organization’s needs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;What makes infrastructure truly autonomous&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The infrastructure market is experiencing a fundamental shift. Traditional DevOps platforms require human orchestration and constant oversight. Autonomous infrastructure represents a different architectural approach entirely.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;True autonomous infrastructure has four core capabilities:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Self-building&lt;/strong&gt;: Generates infrastructure from business intent rather than technical specifications&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Self-governing&lt;/strong&gt;: Enforces policies instantly and consistently without human intervention&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Self-healing&lt;/strong&gt;: Identifies root causes and implements safe remediations automatically&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Self-optimizing&lt;/strong&gt;: Continuously balances cost, performance, and reliability based on real-time conditions&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;These systems must also be self-learning, continuously improving their decision-making based on organizational patterns and outcomes, so that each capability becomes more intelligent and aligned with business objectives over time.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;The five levels of infrastructure autonomy&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Understanding autonomous infrastructure requires recognizing that organizations don’t transition overnight—they progress through distinct levels of operational autonomy. Unlike the&lt;a href=&#34;https://platformengineering.org/blog/intent-to-infrastructure-platform-engineers-break-bottlenecks-with-ai&#34;&gt; intent levels I described earlier&lt;/a&gt; which focus on how humans express infrastructure needs, these autonomy levels describe how systems actually operate and make decisions.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;L1 Manual&lt;/strong&gt; – Human-driven processes requiring direct intervention&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;L2 Automated&lt;/strong&gt; – Traditional automation without AI (Terraform, Ansible, CI/CD)&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;L3 Copilot&lt;/strong&gt; – AI recommends actions, humans approve and execute&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;L4 Autopilot with human goals&lt;/strong&gt; – AI operates autonomously within human-defined objectives&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;L5 Autopilot with AI-chosen goals&lt;/strong&gt; – AI sets its own optimization targets based on business context&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Organizations typically operate at different autonomy levels across the four pillars simultaneously. Here’s how this progression looks in practice:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Building infrastructure:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;em&gt;L2 Automated&lt;/em&gt;: Terraform modules deployed through CI/CD pipelines&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;em&gt;L4 Autopilot&lt;/em&gt;: AI generates infrastructure code from application requirements and deploys automatically within policy guardrails&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;em&gt;L5 Autopilot&lt;/em&gt;: AI determines optimal architecture patterns based on usage data, cost trends, and performance requirements&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Governing infrastructure:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;em&gt;L2 Automated&lt;/em&gt;: Policy-as-code tools scan for violations and generate reports&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;em&gt;L3 Copilot&lt;/em&gt;: AI identifies compliance drift and recommends specific remediation steps for human approval&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;em&gt;L4 Autopilot&lt;/em&gt;: AI automatically remediates policy violations within predefined risk boundaries&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Healing infrastructure:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;em&gt;L2 Automated&lt;/em&gt;: Monitoring alerts trigger predefined runbooks and rollback procedures&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;em&gt;L4 Autopilot&lt;/em&gt;: AI diagnoses incidents, correlates across systems, and implements fixes automatically&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;em&gt;L5 Autopilot&lt;/em&gt;: AI proactively prevents incidents by analyzing patterns and adjusting configurations before failures occur&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Most enterprises today operate primarily at L1-L2, with leading organizations beginning to experiment with L3 copilot capabilities. The next 24 months will see rapid progression toward L4 autopilot operations as AI reliability and organizational confidence increase.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;The farthest point we can envision today on this spectrum is what we call “Infrastructure AGI”—achieving Level 5 autonomy across all four pillars simultaneously.&lt;/strong&gt; This represents infrastructure systems that demonstrate human-level reasoning and decision-making capabilities: setting their own strategic objectives based on business context, reasoning about complex tradeoffs like an experienced architect, adapting to scenarios they’ve never encountered before, and learning across domains to improve all operational capabilities.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Infrastructure AGI is where we’re heading over the next decade, not what exists today. It provides a concrete north star for measuring progress toward the ultimate vision of truly intelligent infrastructure.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To illustrate this progression, consider how one enterprise customer transformed their multi-region deployment process. Previously, expanding to a new geographic market required 2-3 weeks of manual infrastructure work. With autonomous infrastructure, they now express business intent: “Deploy our e-commerce platform to EU-West with GDPR compliance and sub-200ms latency for major European cities.” The system automatically generates region-appropriate infrastructure, applies relevant compliance policies, and validates requirements—all within hours rather than weeks.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Addressing the reliability question:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The biggest concern we hear from engineering leaders is: “What happens when autonomous systems make mistakes?” This skepticism is healthy and necessary. Our approach addresses this through graduated autonomy levels, comprehensive audit trails, and what we call the Four Pillars of Trust.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;These pillars ensure organizational control, visibility, and safety while enabling intelligent AI infrastructure operations:&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Execution control&lt;/strong&gt;:fine-grained RBAC and human approval workflows&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;AI decision reliability&lt;/strong&gt;: explainability and deterministic behavior with comprehensive evaluation&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Data security &amp;amp; privacy&lt;/strong&gt;: session data protection and sovereignty compliance &lt;strong&gt;Compliance &amp;amp; audit&lt;/strong&gt;: policy-aware remediation with complete audit trail integration.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;L3 copilot operations always require human approval for significant changes. L4 autopilot systems operate within strict policy boundaries and maintain detailed decision logs. And L5 systems only emerge after extensive validation in controlled environments.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The goal isn’t to eliminate human judgment—it’s to amplify human intelligence by handling routine decisions automatically while escalating complex scenarios for human review. For engineering leaders who want to understand how we build trusted AI agents that maintain these safeguards, StackGen AI Product Manager Aaron Yang provides a detailed technical deep-dive at&lt;a href=&#34;https://stackgen.com/building-trusted-ai-agents&#34;&gt; stackgen.com/building-trusted-ai-agents&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This isn’t about better tooling—it’s about intelligent systems that understand context, learn from outcomes, and make autonomous decisions aligned with business objectives.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Beyond today: The infrastructure AGI vision&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Our vision extends beyond individual infrastructure components to entire ecosystems that evolve toward Infrastructure AGI. By the late 2020s, we envision infrastructure that automatically optimizes for changing business requirements, self-organizes for peak efficiency, and continuously improves based on operational learnings—all while setting its own strategic objectives.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Infrastructure AGI represents the farthest point we can envision today: systems that achieve human-level reasoning across building, governing, healing, and optimizing simultaneously. This isn’t about replacing human judgment—it’s about creating intelligent partners that can reason about complex tradeoffs, adapt to new scenarios, and learn across domains like the most experienced infrastructure architects.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;By 2030, the distinction between application code and infrastructure will blur. Developers will express business intent, and Infrastructure AGI systems will generate, deploy, and manage the complete technical stack required to deliver that intent at global scale, continuously optimizing based on real-world performance and changing business conditions.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Infrastructure will become an intelligent partner that amplifies human creativity rather than constraining it. The future of infrastructure is not just autonomous—it’s artificially intelligent by design.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Building the future together&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The transition to autonomous infrastructure won’t happen overnight, but it’s inevitable. As complexity continues to grow and the demand for rapid, reliable software delivery intensifies, organizations that embrace autonomous systems will have a fundamental competitive advantage.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We’re not just building technology—we’re reimagining the relationship between humans and infrastructure. In an autonomous future, infrastructure becomes an intelligent partner that understands business context, learns from experience, and continuously optimizes for success.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The future of infrastructure is autonomous, and it’s arriving faster than most organizations realize. The companies that recognize this shift now and begin building autonomous capabilities will define the next decade of technology competition.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The question isn’t whether this transformation will happen—it’s whether you’ll lead it or be left behind.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Making the transition: From vision to reality&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The path from today’s automated infrastructure to tomorrow’s autonomous systems requires more than new technology—it demands a fundamental shift in how platform teams approach their role. This transition is already happening through capabilities like AI-powered infrastructure generation, intelligent drift detection and remediation, and autonomous incident response that reduces mean time to resolution from hours to minutes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For organizations ready to begin this journey, the key is approaching this evolution systematically, building organizational confidence through graduated autonomy levels while maintaining the governance and reliability standards that enterprises require.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Ready to explore how autonomous infrastructure can transform your organization? Connect with me on&lt;a href=&#34;https://www.linkedin.com/in/asifawan/&#34;&gt; LinkedIn&lt;/a&gt; to continue this conversation about the future of infrastructure management.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“1310”高度=“742” src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-17-at-12.46.52-PM.jpg&#34; alt=&#34;Image：未来是自主基础设施&#34; class=&#34;wp-image-149772&#34; srcset =“https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-17-at-12.46.52-PM.jpg 1310w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-17-at-12.46.52-PM-300x170.jpg 300w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-17-at-12.46.52-PM-1024x580.jpg 1024w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-17-at-12.46.52-PM-768x435.jpg 768w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-17-at-12.46.52-PM-900x510.jpg 900w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-17-at-12.46.52-PM-353x200.jpg 353w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-17-at-12.46.52-PM-706x400.jpg 706w“尺寸=”自动，（最大宽度：1310px）100vw，1310px“ referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;&lt;strong&gt;执行摘要&lt;/strong&gt;：我们正处于一个转折点，人工智能生成的代码与人工智能管理的基础设施相结合，创建真正的自我维持系统。这种融合将基础设施从静态管道转变为能够构建、管理、修复和优化自身的自治系统。组织通过采用自主基础设施建立竞争优势的窗口很窄，特别是在基础设施敏捷性直接影响市场响应能力的技术驱动型行业。&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;人工智能越来越多地应用于基础设施中，从辅助工具转向可以自主决策的系统。这一转变建立在社区早期围绕&lt;a href=&#34;https://platformengineering.org/blog/intent-to-infrastruct-platform-engineers-break-bottlenecks-with-ai&#34;&gt;意向基础设施方法&lt;/a&gt;进行的对话的基础上，例如今年 PlatformCon 上强调的对话，其中平台工程师讨论了使用 AI 来解决瓶颈。&lt;br&gt;在此 &lt;a href=&#34;https://stackgen.com/blog/introducing-stackgen-autonomous-infrastruct-platform&#34;&gt;帖子&lt;/a&gt;，我们描述了该想法的一种实现：在意图驱动输入的指导下，可以在最少的人为干预下运行的基础设施。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;当AI开发遇到AI运营&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们正在接近一个拐点，人工智能生成的代码与人工智能管理的基础设施相结合。这种融合正在将基础设施从静态管道转变为可以不断生成、适应和发展的智能系统。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.mckinsey.com/capability/mckinsey-digital/our-insights/unleashing-developer-productivity-with-generative-ai&#34;&gt;虽然人工智能已将开发任务加快了 2-3 倍&lt;/a&gt;，但基础设施瓶颈仍然每年在产品损失中每 100 名开发人员消耗 250 万美元活动性。但这不仅仅是效率的问题，而是我们对基础设施本身的看法的根本转变。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;从传统自动化到自主系统的转变代表了基础设施发展的下一阶段。传统自动化管理已经存在的东西，而自主基础设施则构建、管理、修复和优化自身。这是恒温器和自我设计的建筑之间的区别，自我设计的建筑会根据各种条件不断优化自身，同时随着时间的推移学习和改进。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;超越自动化：基础设施演进的三个阶段&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;第一阶段：手动基础架构（2010-2020）&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;点击式云控制台时代，基础设施专家通过 Web 界面和 CLI 命令手动配置资源。知识是部落式的，流程记录在维基百科中，扩展需要雇用更多的基础设施工程师。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;第 2 阶段：自动化基础设施（2020-2025 年）&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;基础设施即代码彻底改变了可重复性和版本控制。 Terraform 和 Ansible 等工具可以实现一致的部署，但仍然需要人工编排、持续监督以及手动干预来进行偏差检测和修复。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;第 3 阶段：自主基础设施（2025-2030 年）&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;能够构建、管理、修复和优化自身的基础设施。系统能够理解业务意图、生成最佳配置、持续执行策略、主动检测和修复问题，并从每次交互中学习以改进未来的决策。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们不只是进入第三阶段，我们正在定义它。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;确定性+概率收敛&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;使自主基础设施成为可能的突破是确定性可靠性与概率智能的结合。 &lt;a href=&#34;https://www.pwc.com/us/en/tech-effect/ai-analytics/ai-agent-survey.html&#34;&gt;正如行业分析师指出的&lt;/a&gt;，这代表着“从作为静态管道的基础设施向由智能代理支持的自治系统的转变，同时 88% 的 IT 领导者计划采用人工智能驱动的功能 在接下来的 12 个月内。”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;自主基础设施将确保合规性、安全性和可靠性的确定性策略框架与了解上下文、从结果中学习并做出明智决策的人工智能代理相结合。根据我们与早期企业客户的经验，这种融合解决了人工智能可靠性问题，这些问题历来限制自主操作，同时满足审计师和合规团队要求的治理要求。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这种融合将基础设施从静态管道转变为由智能代理支持的自治系统，从而创建了分析师所说的企业云运营方式发生根本性转变。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;基础设施的终结是一个限制因素&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;几十年来，基础设施的复杂性呈指数级增长，而开发速度却受到基础设施交付瓶颈的限制。自治基础设施颠倒了这种关系。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;考虑轨迹：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;2025&lt;/strong&gt;：早期采用者为特定基础设施任务部署人工智能代理，&lt;a href=&#34;https://www.cloudera.com/about/news-and-blogs/press-releases/2025-04-16-96-percent-of-enterprises-are-expanding-use-of-ai-agents-according-to-latest-data-from-cloudera.html&#34;&gt;看到 95% 自动化 配置&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;2026 年&lt;/strong&gt;：自主基础设施成为领先科技公司的标准，使基础设施能够根据业务需求动态扩展&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;2027 年&lt;/strong&gt;：随着自主系统生产力提高 10 倍，手动基础设施管理将成为竞争劣势&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;2028&lt;/strong&gt;：完全自主的基础设施成为企业标准，基础设施决策以机器速度进行&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;今天进行这一转变的组织将定义技术和技术驱动型行业未来十年的竞争格局。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;从被动消防到主动情报&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;传统的基础设施管理本质上是反应性的。问题发生后才被发现，审计期间发现偏差，季度审查期间进行优化。自主基础设施完全颠覆了这种模式。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;想象一下基础设施：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;通过持续分析模式和主动调整配置来预防问题发生&lt;/strong&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;针对不断变化的业务优先级进行实时优化&lt;/strong&gt;，自动平衡成本、性能和可靠性&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;从每次部署和事件中学习&lt;/strong&gt;，以改进整个组织的未来决策&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;以民主方式扩展专业知识&lt;/strong&gt;，使每个团队都能从平台的集体智慧中受益&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这不是科幻小说，这是人工智能优先世界中基础设施管理的自然演变。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;多代理基础设施生命周期&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;为了说明自主基础设施在实践中如何工作，请考虑以下示例工作流程，其中多个 AI 代理在整个基础设施生命周期中进行协作：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;开发者意图&lt;/strong&gt;→&lt;strong&gt;基础设施生成&lt;/strong&gt;→&lt;strong&gt;智能配置&lt;/strong&gt;→&lt;strong&gt;智能监控&lt;/strong&gt;→&lt;strong&gt;AI修复&lt;/strong&gt;→&lt;strong&gt;持续学习&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;每个阶段都由专门的代理提供支持，这些代理了解组织环境、自动执行策略并根据结果不断改进。这会创建一个自我强化的循环，随着时间的推移，基础设施将变得更加智能并与业务目标保持一致。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这种多代理方法可确保自主基础设施不仅仅是反应性自动化，而是主动智能，可以预防问题、持续优化并根据组织的需求不断发展。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;是什么让基础设施真正实现自治&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;基础设施市场正在经历根本性转变。传统的 DevOps 平台需要人工编排和持续监督。自主基础设施代表了一种完全不同的架构方法。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;真正的自主基础设施有四个核心功能：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;&lt;strong&gt;自我构建&lt;/strong&gt;：根据业务意图而不是技术规范生成基础架构&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;自治&lt;/strong&gt;：立即、一致地执行政策，无需人工干预&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;自我修复&lt;/strong&gt;：识别根本原因并自动实施安全补救措施&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;自我优化&lt;/strong&gt;：根据实时情况持续平衡成本、性能和可靠性&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这些系统还必须能够自我学习，根据组织模式和结果不断改进其决策，以便随着时间的推移，每种功能变得更加智能并与业务目标保持一致。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;基础设施自治的五个级别&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;了解自主基础设施需要认识到组织不会一夜之间实现转型，它们会通过不同级别的运营自主权取得进展。与我之前描述的意图级别（重点关注人类如何表达基础设施需求）不同，这些自主级别描述了系统如何实际运行和做出决策。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;&lt;strong&gt;L1 手册&lt;/strong&gt; – 需要直接干预的人为驱动流程&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;L2 自动化&lt;/strong&gt; – 没有 AI 的传统自动化（Terraform、Ansible、CI/CD）&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;L3 Copilot&lt;/strong&gt; – 人工智能建议行动，人类批准并执行&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;具有人类目标的 L4 自动驾驶仪&lt;/strong&gt; - 人工智能在人类定义的目标内自主运行&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;具有 AI 选择目标的 L5 自动驾驶仪&lt;/strong&gt; - AI 根据业务环境设定自己的优化目标&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;组织通常同时在四大支柱的不同自治级别上运作。这是这个进展的样子练习：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;建设基础设施：&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;em&gt;L2 自动化&lt;/em&gt;：通过 CI/CD 管道部署的 Terraform 模块&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;em&gt;L4 Autopilot&lt;/em&gt;：人工智能根据应用需求生成基础设施代码，并在策略护栏内自动部署&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;em&gt;L5 Autopilot&lt;/em&gt;：人工智能根据使用数据、成本趋势和性能要求确定最佳架构模式&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;治理基础设施：&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;em&gt;L2 自动化&lt;/em&gt;：策略即代码工具扫描违规行为并生成报告&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;em&gt;L3 Copilot&lt;/em&gt;：AI 识别合规性偏差并建议具体的补救步骤以供人工批准&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;em&gt;L4 Autopilot&lt;/em&gt;：人工智能在预定义的风险边界内自动修复违反政策的行为&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;治疗基础设施：&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;em&gt;L2 自动化&lt;/em&gt;：监控警报触发预定义的运行手册和回滚过程&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;em&gt;L4 Autopilot&lt;/em&gt;：人工智能诊断事件、跨系统关联并自动实施修复&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;em&gt;L5 自动驾驶仪&lt;/em&gt;：人工智能通过在故障发生前分析模式和调整配置来主动预防事故&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;当今大多数企业主要在 L1-L2 上运营，领先的组织开始尝试 L3 副驾驶功能。随着人工智能可靠性和组织信心的增强，未来 24 个月将快速向 L4 自动驾驶操作迈进。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;我们今天在这个范围内可以设想的最远点是我们所说的“基础设施 AGI”——同时在所有四个支柱上实现 5 级自治。&lt;/strong&gt;这代表了展示人类水平推理和决策能力的基础设施系统：根据业务环境设定自己的战略目标，像经验丰富的架构师一样推理复杂的权衡，适应他们已经经历过的场景 以前没有遇到过，跨领域学习，提升各项运营能力。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;基础设施通用人工智能是我们未来十年的发展方向，而不是现在的现状。它为衡量真正智能基础设施最终愿景的进展提供了具体的北极星。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;为了说明这一进展，请考虑一个企业客户如何转变其多区域部署流程。以前，扩展到新的地理市场需要 2-3 周的手动基础设施工作。凭借自主基础设施，他们现在表达了业务意图：“将我们的电子商务平台部署到欧盟西部，并符合 GDPR 要求，并为欧洲主要城市提供低于 200 毫秒的延迟。”系统自动生成适合区域的基础设施、应用相关的合规策略并验证需求——所有这些都在几小时而不是几周内完成。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;解决可靠性问题：&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们从工程领导者那里听到的最大的担忧是：“当自主系统犯错时会发生什么？”这种怀疑是健康且必要的。我们的方法通过分级自治级别、全面的审计跟踪以及我们所说的信任的四大支柱来解决这个问题。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这些支柱可确保组织控制、可见性和安全性，同时实现智能 AI 基础设施运营：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;&lt;strong&gt;执行控制&lt;/strong&gt;：细粒度的 RBAC 和人工审批工作流程&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;人工智能决策可靠性&lt;/strong&gt;：综合评估的可解释性和确定性行为&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;数据安全和隐私&lt;/strong&gt;：会话数据保护和主权合规性&lt;strong&gt;合规性和审计&lt;/strong&gt;：通过完整的审计跟踪集成进行策略感知修复。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;L3 副驾驶操作始终需要人工批准才能进行重大更改。 L4 自动驾驶系统在严格的策略边界内运行，并维护详细的决策日志。 L5 系统只有在受控环境中进行广泛验证后才会出现。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们的目标不是消除人类判断，而是通过自动处理日常决策来增强人类智能，同时升级复杂场景以供人类审查。对于想要了解我们如何构建可信赖的 AI 代理来维护这些保护措施的工程领导者，StackGen AI 产品经理 Aaron Yang 在&lt;a href=&#34;https://stackgen.com/building-trusted-ai-agents&#34;&gt;stackgen.com/building-trusted-ai-agents&lt;/a&gt; 上提供了详细的技术深入探讨。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这不是关于更好的工具，而是关于理解上下文、从结果中学习并做出与业务目标一致的自主决策的智能系统。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;超越今天：基础设施 AGI 愿景&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们的愿景超越了单个基础设施组件，延伸至向基础设施 AGI 发展的整个生态系统。到 2020 年代末，我们设想基础设施能够自动优化以适应不断变化的业务需求、自我组织以实现最高效率，并根据运营学习不断改进，同时设定自己的战略目标。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;基础设施 AGI 代表了我们今天可以设想的最远点：同时实现跨构建、治理、修复和优化的人类级推理的系统。这并不是要取代人类的判断，而是要创建智能合作伙伴，这些合作伙伴可以像最有经验的基础设施架构师一样推理复杂的权衡、适应新场景并跨领域学习。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;到 2030 年，应用程序代码和基础设施之间的区别将变得模糊。开发人员将表达业务意图，基础设施 AGI 系统将生成、部署和管理在全球范围内实现这一意图所需的完整技术堆栈，根据实际性能和不断变化的业务条件不断优化。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;基础设施将成为一个聪明的合作伙伴，可以增强而不是限制人类的创造力。基础设施的未来不仅仅是自动化，而且是人工智能设计。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;共同建设未来&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;向自主基础设施的过渡不会在一夜之间发生，但这是不可避免的。随着复杂性的不断增长以及对快速、可靠的软件交付的需求的不断增加，采用自主系统的组织将拥有根本的竞争优势。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们不仅仅是在构建技术，我们还在重新构想人类与基础设施之间的关系。在自动化的未来，基础设施成为了解业务环境、从经验中学习并不断优化以获得成功的智能合作伙伴。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;基础设施的未来是自主的，而且它的到来速度比大多数组织意识到的要快。现在认识到这种转变并开始构建自主能力的公司将定义下一个十年的技术竞争。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;问题不在于这种转变是否会发生，而在于您是否会引领它还是被抛在后面。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;实现转变：从愿景到现实&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;从今天的自动化基础设施到明天的自主系统的道路需要的不仅仅是新技术，还需要平台团队处理其角色的方式发生根本性转变。这种转变已经通过人工智能驱动的基础设施生成、智能偏差检测和修复以及自主事件响应等功能实现，这些功能可将解决问题的平均时间从几小时缩短到几分钟。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;对于准备开始这一旅程的组织来说，关键是系统地应对这一演变，通过分级自治级别建立组织信心，同时维持企业所需的治理和可靠性标准。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;准备好探索自主基础设施如何改变您的组织了吗？在 &lt;a href=&#34;https://www.linkedin.com/in/asifawan/&#34;&gt;LinkedIn&lt;/a&gt; 上与我联系，继续有关基础设施管理未来的对话。&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Thu, 16 Oct 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Kyverno vs Kubernetes policies: How Kyverno complements and completes Kubernetes policy types】Kyverno 与 Kubernetes 策略：Kyverno 如何补充和完善 Kubernetes 策略类型</title>
      <link>https://www.cncf.io/blog/2025/10/16/kyverno-vs-kubernetes-policies-how-kyverno-complements-and-completes-kubernetes-policy-types/</link>
      <description>【&lt;p&gt;&lt;em&gt;&lt;a href=&#34;https://nirmata.com/2025/10/01/kyverno-vs-kubernetes-policies-how-it-complements-and-completes/&#34;&gt;Originally posted on Nirmata.com on October 1, 2025&lt;/a&gt;&lt;/em&gt;&lt;strong&gt;&lt;a href=&#34;https://nirmata.com/2025/10/01/kyverno-vs-kubernetes-policies-how-it-complements-and-completes/&#34;&gt; &lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;How Kyverno extends and integrates with Kubernetes policies&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;With the addition of ValidatingAdmissionPolicy and MutatingAdmissionPolicy in Kubernetes, do you still need Kyverno? This post answers the question by providing ten reasons why Kyverno is essential even when you are using Kubernetes policy types.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Introduction&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Prior to Kyverno, policy management in Kubernetes was complex and cumbersome. While the need for Policy as Code was clear, initial implementations required learning complex languages and did not implement the full policy as code lifecycle.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kyverno was created by Nirmata, and donated to the CNCF in November 2020. It rapidly gained popularity due to its embrace of Kubernetes resources for policy declarations, it’s easy-to-use syntax, and breadth of features that addressed all aspects of policy as code.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Recently, Kubernetes has also introduced native policy types which can be executed directly in the Kubernetes API server. This move validates that policies are a must have for Kubernetes, and now allows critical policies to be executed directly in the API server.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The Kubernetes API server is a critical resource that needs to be extremely efficient. To safely execute policies in the API server, the Kubernetes authors chose &lt;a href=&#34;https://github.com/google/cel-spec&#34;&gt;CEL (Common Expressions Language) &lt;/a&gt;to embed logic in policy YAML declarations. In addition to a familiar syntax, CEL programs can be pre-compiled and execution costs can be pre-calculated.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;With these changes in Kubernetes, the Kyverno has also evolved to stay true to its mission of providing the best policy engine and tools for Kubernetes native policy as code.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kyverno now supports five new policy types, two of which, ValidatingPolicy and MutatingPolicy, are extensions of Kubernetes policy types ValidatingAdmissionPolicy and MutatingAdmissionPolicy, respectively.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;NOTE: I will use the term “Kubernetes Policies” to refer to ValidatingAdmissionPolicies and MutatingAdmissionPolicies.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Here is a summary of the Kyverno policy types:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;ValidatingPolicy:&lt;/strong&gt; This policy type checks if a resource’s configuration adheres to predefined rules and can either &lt;strong&gt;enforce&lt;/strong&gt; or &lt;strong&gt;audit&lt;/strong&gt; compliance. This policy type is an extension of the Kubernetes ValidatingAdmissionPolicy.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;ImageValidatingPolicy:&lt;/strong&gt; A specialized validating policy that verifies a container image’s &lt;strong&gt;signatures&lt;/strong&gt; and &lt;strong&gt;attestations&lt;/strong&gt; to ensure its integrity and trustworthiness.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;MutatingPolicy:&lt;/strong&gt; This policy type &lt;strong&gt;modifies&lt;/strong&gt; a resource’s configuration as it’s being created or updated, applying changes like adding labels, annotations, or sidecar containers. This policy is an extension of the Kubernetes MutatingAdmissionPolicy.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;GeneratingPolicy:&lt;/strong&gt; This policy &lt;strong&gt;creates or clones&lt;/strong&gt; new resources in response to a trigger event, such as automatically generating a NetworkPolicy when a new Namespace is created.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;DeletingPolicy:&lt;/strong&gt; This policy automatically &lt;strong&gt;deletes&lt;/strong&gt; existing resources that match specific criteria on a predefined schedule, often used for garbage collection or enforcing retention policies&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;So, when should you choose to use Kyverno policies vs the Kubernetes policy types? The right answer is that if you believe that declarative Policy as Code is the right way to manage Kubernetes configuration complexity, you will need both!&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As you will see below, Kyverno provides critical features that are missing in Kubernetes policies and also helps with policy management at scale.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;1. Applying policies on existing resources&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;When new policies are created, they need to be applied on existing resources. Kubernetes Policies only apply on resource changes, and hence policy violations on existing resources are not reported.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kyverno applies policies, including Kubernetes Policies types, on all resources.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;2. Reapplying policies on changes&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Like code, policies change over time. This can be to adapt to updated or new features, or to fix issues in the policy. When a policy changes, it must be re-applied to all resources. Kubernetes Policies are embedded in the API server and not reapplied when the policy changes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;3. Applying policies pff cluster (shift-left)&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Providing feedback to developers as early as possible in a deployment pipeline is highly desirable and has tangible benefits of time and cost savings. The Kyverno CLI can apply Kyverno and Kubernetes Policy types in CI/CD and IaC pipelines.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;4. Testing policy as code&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Like all software, policies must be thoroughly tested prior to deployment. Kyverno provides tools for testing Kyverno and Kubernetes policy types. You can use the Kyverno CLI for unit tests, and Kyverno Chainsaw for e2e behavioral tests.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;5. Reporting policy results&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kyverno provides integrated reporting, where reports are namespaced Kubernetes resources and hence via the Kubernetes API and other tools to application owners. Kyverno reports are generated for both Kyverno and Kubernetes policy types.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;6. Managing fine-grained policy exceptions&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kyverno allows configuring policy exceptions to exclude some resources from policies. Kyverno exceptions are Kubernetes resources making it possible to view and manage via the Kubernetes API using standard tools.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kyverno exceptions can specify an image, so you can exclude certain containers in a pod while still applying the policy to other containers. Exceptions can also declare specific values that are allowed. Exceptions can also be time-bound, but adding a TTL (time to live).&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;These powerful capabilities allow enforcing policies and then use exceptions to exclude certain resources, or even parts of a resource declaration.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;7. Complex policy logic&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes policies are designed for simple checks, and can only apply to the admission payload. This is often insufficient, as policies may need to look up other resources or even reference external data. These types of checks are not possible with Kubernetes policies. Additionally, Kubernetes MutatingAdmissionPolicies cannot match sub-resources and apply to a resource.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kyverno supports features for complex policies, including API lookups and external data management. Kyverno also offers an extended CEL library with useful functions necessary for complex policies.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;8. Image verification&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kyverno offers built-in verification of &lt;a href=&#34;https://opencontainers.org/&#34;&gt;OCI (Open Container Initiative)&lt;/a&gt; image and artifact signatures, using &lt;a href=&#34;https://github.com/sigstore/cosign&#34;&gt;Sigstore’s Cosign&lt;/a&gt; or &lt;a href=&#34;https://notaryproject.dev/&#34;&gt;CNCF’s Notary&lt;/a&gt; projects. This allows implementing software supply chain security use cases and achieving high levels of &lt;a href=&#34;https://slsa.dev/&#34;&gt;SLSA (Supply-chain Levels for Software Artifacts.)&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;9. Policy-based automation&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Besides validating and mutating resources, policies are an essential tool for automating several complex platform engineering tasks. For example, policies can be used to automatically generate secure defaults, or resources like network policies, on flexible triggers such as a namespace creation or when a label is added. This allows a tight control loop, and can be used to replace custom controllers with declarative and scalable policy as code.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;10. Kyverno everywhere&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;While Kubernetes Policy types can only be applied to Kubernetes resources, Kyverno policies can be applied to any JSON or YAML payload including Terraform or OpenTofu manifests, other IaC manifests such as CDK,&amp;nbsp; and build artifacts such as Dockerfiles.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kyverno enables a unified policy as code approach, which is essential for platform engineering teams that manage both Kubernetes clusters, and pipelines for CI/CD and IaC.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Conclusion&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kyverno is fully compatible with Kubernetes policies, and is designed to seamlessly support and extend Kubernetes policy types. It applies Kubernetes policies to existing resources and can also provide policy reporting and exception management for Kubernetes policies.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Like Kubernetes policies, Kyverno policies also use the Common Expressions Language (CEL) and extend the Kubernetes policy declarations with additional fields, and extended CEL libraries, required for complex policies and advanced policy as code use cases.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This allows having a mix of Kubernetes and Kyverno policies managed by Kyverno. You can get started with Kubernetes policies and then upgrade to Kyverno policies for advanced use cases.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you have existing Kubernetes policies, you can use Kyverno to apply them to existing resources, produce reports, apply the policies off-cluster, and perform unit and behavioral tests.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you are starting out, you can use Kyverno policy types. Wherever possible Kyverno will automatically generate and manage Kubernetes policies for optimal performance. For complex policies, which cannot be handled in the API server, Kyverno will execute these during admission controls and periodically as background scans.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Regardless of where you start, with Kyverno you get a powerful and complete policy as code solution for Kubernetes and all your policy-based authorization needs!&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;&lt;a href=&#34;https://nirmata.com/2025/10/01/kyverno-vs-kubernetes-policies-how-it-complements-and-completes/&#34;&gt;最初于 2025 年 10 月 1 日发布在 Nirmata.com&lt;/a&gt;&lt;/em&gt;&lt;strong&gt;&lt;a href=&#34;https://nirmata.com/2025/10/01/kyverno-vs-kubernetes-policies-how-it-complements-and-completes/&#34;&gt;&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Kyverno 如何扩展并与 Kubernetes 策略集成&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在 Kubernetes 中添加了 ValidatingAdmissionPolicy 和 MutatingAdmissionPolicy 后，您还需要 Kyverno 吗？这篇文章通过提供 Kyverno 必不可少的十个理由来回答这个问题，即使您使用 Kubernetes 策略类型也是如此。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;简介&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在 Kyverno 之前，Kubernetes 中的策略管理复杂且繁琐。虽然政策即代码的需求很明确，但最初的实施需要学习复杂的语言，并且没有将完整的政策实施为代码生命周期。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kyverno 由 Nirmata 创建，并于 2020 年 11 月捐赠给 CNCF。由于采用 Kubernetes 资源进行策略声明、易于使用的语法以及以代码形式解决策略各个方面的广泛功能，它迅速流行起来。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;最近，Kubernetes 还引入了原生策略类型，可以直接在 Kubernetes API 服务器中执行。这一举措验证了策略是 Kubernetes 的必备条件，现在允许关键策略直接在 API 服务器中执行。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes API 服务器是一种需要极其高效的关键资源。为了在 API 服务器中安全地执行策略，Kubernetes 作者选择&lt;a href=&#34;https://github.com/google/cel-spec&#34;&gt;CEL（通用表达式语言）&lt;/a&gt;将逻辑嵌入到策略 YAML 声明中。除了熟悉的语法外，还可以预编译CEL程序并预计算执行成本。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;随着 Kubernetes 中的这些变化，Kyverno 也不断发展，以忠于其为 Kubernetes 原生策略即代码提供最佳策略引擎和工具的使命。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kyverno 现在支持五种新策略类型，其中 ValidatingPolicy 和 MutatingPolicy 两种，分别是 Kubernetes 策略类型 ValidatingAdmissionPolicy 和 MutatingAdmissionPolicy 的扩展。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;注意：我将使用术语“Kubernetes 策略”来指代 ValidatingAdmissionPolicies 和 MutatingAdmissionPolicies。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;以下是 Kyverno 策略类型的摘要：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;ValidatingPolicy&lt;/strong&gt;：此策略类型检查资源的配置是否符合预定义的规则，并且可以&lt;strong&gt;强制&lt;/strong&gt;或&lt;strong&gt;审核&lt;/strong&gt;合规性。此策略类型是 Kubernetes ValidatingAdmissionPolicy 的扩展。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;ImageValidatingPolicy&lt;/strong&gt;：一种专门的验证策略，用于验证容器映像的&lt;strong&gt;签名&lt;/strong&gt;和&lt;strong&gt;证明系统蒸发散，以确保其完整性和可信度。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;MutatingPolicy&lt;/strong&gt;：此策略类型会在创建或更新资源时&lt;strong&gt;修改&lt;/strong&gt;资源的配置，应用添加标签、注释或 sidecar 容器等更改。此策略是 Kubernetes MutatingAdmissionPolicy 的扩展。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;GeneratePolicy&lt;/strong&gt;：此策略&lt;strong&gt;创建或克隆&lt;/strong&gt;新资源以响应触发事件，例如在创建新命名空间时自动生成 NetworkPolicy。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;删除策略&lt;/strong&gt;：此策略会自动&lt;strong&gt;删除&lt;/strong&gt;符合预定义计划特定条件的现有资源，通常用于垃圾收集或执行保留策略&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;那么，什么时候应该选择使用 Kyverno 策略而不是 Kubernetes 策略类型？正确的答案是，如果您认为声明式策略即代码是管理 Kubernetes 配置复杂性的正确方法，那么您将需要两者！ &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;正如您将在下面看到的，Kyverno 提供了 Kubernetes 策略中缺少的关键功能，并且还有助于大规模的策略管理。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;1.对现有资源应用策略&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;创建新策略时，需要将其应用于现有资源。 Kubernetes 策略仅适用于资源更改，因此不会报告对现有资源的策略违规。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kyverno 对所有资源应用策略，包括 Kubernetes 策略类型。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;2.重新应用更改策略&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;与代码一样，策略也会随着时间而变化。这可以是为了适应更新或新功能，或者修复策略中的问题。当策略更改时，必须将其重新应用到所有资源。 Kubernetes 策略嵌入在 API 服务器中，当策略更改时不会重新应用。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;3.应用策略 pff cluster（左移）&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在部署管道中尽早向开发人员提供反馈是非常可取的，并且可以节省时间和成本。 Kyverno CLI 可以在 CI/CD 和 IaC 管道中应用 Kyverno 和 Kubernetes 策略类型。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;4.以代码形式测试策略&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;与所有软件一样，策略在部署之前必须经过彻底测试。 Kyverno 提供了用于测试 Kyverno 和 Kubernetes 策略类型的工具。您可以使用 Kyverno CLI 进行单元测试，使用 Kyverno Chainsaw 进行 e2e 行为测试。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;5.报告政策结果&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kyverno 提供集成报告，其中报告是命名空间的 Kubernetes 资源，因此可以通过 Kubernetes API 和其他工具提供给应用程序所有者。为 Kyverno 和 Kubernetes 策略类型生成 Kyverno 报告。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;6.管理细粒度的政策，除了离子&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kyverno 允许配置策略例外以从策略中排除某些资源。 Kyverno 的例外是 Kubernetes 资源，使得可以使用标准工具通过 Kubernetes API 查看和管理。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kyverno 例外可以指定一个映像，因此您可以排除 pod 中的某些容器，同时仍将策略应用于其他容器。异常还可以声明允许的特定值。异常也可以是有时间限制的，但要添加 TTL（生存时间）。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这些强大的功能允许执行策略，然后使用异常来排除某些资源，甚至资源声明的一部分。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;7.复杂的政策逻辑&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes 策略是为简单检查而设计的，并且只能应用于准入负载。这通常是不够的，因为策略可能需要查找其他资源，甚至引用外部数据。 Kubernetes 策略无法进行这些类型的检查。此外，Kubernetes MutatingAdmissionPolicies 无法匹配子资源并应用于资源。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kyverno 支持复杂策略的功能，包括 API 查找和外部数据管理。 Kyverno 还提供了一个扩展的 CEL 库，其中包含复杂策略所需的有用功能。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;8.图片验证&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kyverno 使用 &lt;a href=&#34;https://github.com/sigstore/cosign&#34;&gt;Sigstore 的 Cosign&lt;/a&gt; 或 &lt;a&gt; 提供对 &lt;a href=&#34;https://opencontainers.org/&#34;&gt;OCI（开放容器倡议）&lt;/a&gt; 图像和工件签名的内置验证 href=&#34;https://notaryproject.dev/&#34;&gt;CNCF 的 Notary&lt;/a&gt; 项目。这允许实施软件供应链安全用例并实现高水平的&lt;a href=&#34;https://slsa.dev/&#34;&gt;SLSA（软件工件的供应链级别。）&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;9.基于策略的自动化&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;除了验证和改变资源之外，策略还是自动化执行多个复杂平台工程任务的重要工具。例如，策略可用于在命名空间创建或添加标签等灵活触发器上自动生成安全默认值或网络策略等资源。这允许紧密的控制循环，并且可用于用声明性和可扩展的策略作为代码替换自定义控制器。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;10.基维尔诺无处不在&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;虽然 Kubernetes 策略类型只能应用于 Kubernetes 资源，但 Kyverno 策略可以应用于任何 JSON 或 YAML 负载，包括 Terraform 或 OpenTofu 清单、其他 IaC 清单（例如 CDK）以及构建工件（例如 Dockerfile）。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kyverno 支持统一的策略即代码方法，这对于管理 Kubernetes 集群以及 CI/CD 和 IaC 管道的平台工程团队至关重要。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;结论&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kyverno 与 Kuberne 完全兼容tes 策略，旨在无缝支持和扩展 Kubernetes 策略类型。它将Kubernetes策略应用于现有资源，还可以为Kubernetes策略提供策略报告和异常管理。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;与 Kubernetes 策略一样，Kyverno 策略也使用通用表达式语言 (CEL)，并使用复杂策略和高级策略作为代码用例所需的附加字段和扩展 CEL 库来扩展 Kubernetes 策略声明。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这允许混合使用由 Kyverno 管理的 Kubernetes 和 Kyverno 策略。您可以开始使用 Kubernetes 策略，然后升级到 Kyverno 策略以实现高级用例。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您有现有的 Kubernetes 策略，则可以使用 Kyverno 将它们应用到现有资源、生成报告、在集群外应用策略以及执行单元和行为测试。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您刚开始，可以使用 Kyverno 策略类型。只要有可能，Kyverno 就会自动生成和管理 Kubernetes 策略，以实现最佳性能。对于无法在 API 服务器中处理的复杂策略，Kyverno 将在准入控制期间执行这些策略，并定期作为后台扫描执行这些策略。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;无论您从哪里开始，借助 Kyverno，您都可以获得强大而完整的策略即代码解决方案，适用于 Kubernetes 和所有基于策略的授权需求！&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Wed, 15 Oct 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Efficient autoscaling: Keeping performance, reliability, and cost in mind with open source projects】高效的自动扩展：在开源项目中牢记性能、可靠性和成本</title>
      <link>https://www.cncf.io/blog/2025/10/16/efficient-autoscaling-keeping-performance-reliability-and-cost-in-mind-with-open-source-projects/</link>
      <description>【&lt;p&gt;&lt;em&gt;During ContainerDays in Hamburg, Kelsey Hightower posed a simple but powerful question: “Why are we still talking about containers?” His point resonated with me deeply — even in the AI era, the cloud-native community is still refining the fundamentals of container orchestration, scalability, and efficiency. In this post, I’ll explore how open source projects like KEDA and Karpenter can help you balance performance, reliability, and cost in Kubernetes autoscaling.&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Kubernetes autoscaling comes with trade-offs&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;When we talk about &lt;strong&gt;Kubernetes autoscaling&lt;/strong&gt;, it’s not just about adding replicas or nodes when demand grows and removing them when it shrinks. You have to balance &lt;strong&gt;performance&lt;/strong&gt;, &lt;strong&gt;reliability&lt;/strong&gt;, and &lt;strong&gt;cost&lt;/strong&gt; — three forces that constantly pull against each other.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The way I like to think about these three pillars is as a &lt;strong&gt;triangle&lt;/strong&gt;, like in the following figure.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1226&#34; height=&#34;746&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.20.25-AM.jpg&#34; alt=&#34;Kubernetes autoscaling triangle pillars&#34; class=&#34;wp-image-149687&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.20.25-AM.jpg 1226w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.20.25-AM-300x183.jpg 300w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.20.25-AM-1024x623.jpg 1024w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.20.25-AM-768x467.jpg 768w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.20.25-AM-900x548.jpg 900w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.20.25-AM-329x200.jpg 329w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.20.25-AM-657x400.jpg 657w&#34; sizes=&#34;auto, (max-width: 1226px) 100vw, 1226px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;These three pillars create natural tension. Before your application’s performance degrades, you need to add resources — which increases cost. To save on cost, you scale down resources — which can impact reliability. So how do we find the right balance? Let’s explore tools and recommendations for each pillar.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Performance&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Before you start scaling, you need to understand &lt;strong&gt;what truly impacts the performance&lt;/strong&gt; of your application — what matters to your users and stakeholders. Most of the time, they don’t care about CPU or memory usage directly. These may be indicators, but they don’t always tell the full story.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Teams that succeed with autoscaling often track metrics such as &lt;strong&gt;requests per second, latency, queue depth, time-to-first-token, tokens per second&lt;/strong&gt;, or even &lt;strong&gt;event-driven metrics from external sources&lt;/strong&gt; like cloud providers. There’s no single “golden” metric for every workload. Often, a combination works best.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;That’s where &lt;a href=&#34;https://keda.sh/&#34;&gt;&lt;strong&gt;KEDA&lt;/strong&gt;&lt;/a&gt; shines. Even if you currently scale on CPU or memory, KEDA supports those metrics — but also opens the door to &lt;strong&gt;custom triggers and composite scaling rules&lt;/strong&gt; for more complex workloads.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;When you know which metrics actually affect performance, you can design smarter scaling policies and thresholds. The goal is to ensure that you don’t shrink resources at the expense of user experience.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;A practical way to find the right scaling configuration is to &lt;strong&gt;test your workloads&lt;/strong&gt;:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Use load-testing tools like &lt;strong&gt;k6&lt;/strong&gt; to send synthetic traffic.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Experiment with &lt;strong&gt;VPA&lt;/strong&gt;, &lt;strong&gt;krr&lt;/strong&gt;, or &lt;strong&gt;Goldilocks&lt;/strong&gt; to understand resource efficiency.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Identify the breaking points for one-pod, multi-pod, or observed live scenarios.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1224&#34; height=&#34;736&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.21.55-AM.jpg&#34; alt=&#34;Example of Kubernetes autoscaling components and tools&#34; class=&#34;wp-image-149688&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.21.55-AM.jpg 1224w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.21.55-AM-300x180.jpg 300w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.21.55-AM-1024x616.jpg 1024w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.21.55-AM-768x462.jpg 768w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.21.55-AM-900x541.jpg 900w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.21.55-AM-333x200.jpg 333w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.21.55-AM-665x400.jpg 665w&#34; sizes=&#34;auto, (max-width: 1224px) 100vw, 1224px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Even if this sounds like a lot, starting with this method helps you better understand your scaling patterns — and you can automate later. A good example of automation is &lt;strong&gt;in-place pod resize&lt;/strong&gt; via VPA, which allows more dynamic tuning.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Cost&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;One of the biggest motivators for autoscaling is &lt;strong&gt;efficiency&lt;/strong&gt; — using only the resources you need, when you need them.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;KEDA&lt;/strong&gt; helps right-size workloads by scaling pods intelligently, while &lt;a href=&#34;https://karpenter.sh/&#34;&gt;&lt;strong&gt;Karpenter&lt;/strong&gt;&lt;/a&gt; complements it by &lt;strong&gt;provisioning just-in-time nodes&lt;/strong&gt; in a cost-optimized way.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Here’s how they work together:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;When demand grows, &lt;strong&gt;KEDA adds more pods&lt;/strong&gt; to handle the increased load.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As pods become unschedulable due to lack of capacity, &lt;strong&gt;Karpenter provisions new nodes&lt;/strong&gt; to meet that demand.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1334&#34; height=&#34;654&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.23.07-AM.jpg&#34; alt=&#34;Stages of autoscaling an application in Kubernetes&#34; class=&#34;wp-image-149689&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.23.07-AM.jpg 1334w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.23.07-AM-300x147.jpg 300w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.23.07-AM-1024x502.jpg 1024w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.23.07-AM-768x377.jpg 768w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.23.07-AM-900x441.jpg 900w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.23.07-AM-408x200.jpg 408w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.23.07-AM-816x400.jpg 816w&#34; sizes=&#34;auto, (max-width: 1334px) 100vw, 1334px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Karpenter ensures that only the &lt;strong&gt;necessary capacity&lt;/strong&gt; is launched — no more, no less.&lt;br&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1168&#34; height=&#34;626&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.24.13-AM.jpg&#34; alt=&#34;(continued) Stages of autoscaling an application in Kubernetes&#34; class=&#34;wp-image-149690&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.24.13-AM.jpg 1168w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.24.13-AM-300x161.jpg 300w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.24.13-AM-1024x549.jpg 1024w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.24.13-AM-768x412.jpg 768w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.24.13-AM-900x482.jpg 900w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.24.13-AM-373x200.jpg 373w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.24.13-AM-746x400.jpg 746w&#34; sizes=&#34;auto, (max-width: 1168px) 100vw, 1168px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;When demand decreases, &lt;strong&gt;KEDA scales pods down&lt;/strong&gt;, and &lt;strong&gt;Karpenter&lt;/strong&gt; can consolidate or remove underutilized nodes. It may simulate node evictions to determine whether workloads can be packed onto fewer, cheaper nodes, freeing up capacity.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you’d like to see this in action, check out the demo I recorded showing &lt;strong&gt;KEDA and Karpenter working together&lt;/strong&gt; — or the session I co-presented with Jan Wozniak (KEDA maintainer) at &lt;strong&gt;KCD Czech &amp;amp; Slovak&lt;/strong&gt;. Both highlight how intelligent scaling can lead to significant &lt;strong&gt;cost reductions and improved cluster efficiency&lt;/strong&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Reliability&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The third pillar — &lt;strong&gt;reliability&lt;/strong&gt; — is where things often get tricky. Autoscaling adds and removes Pods and Nodes dynamically, which can impact stability if your applications aren’t built to handle graceful terminations or sudden changes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Before tackling reliability, clearly define your &lt;strong&gt;SLAs and SLOs&lt;/strong&gt;. You don’t want to over-engineer or over-spend if your service-level expectations don’t require it. For instance, if your SLA is &lt;em&gt;500 ms latency at 3,500 requests per second&lt;/em&gt;, design accordingly — understand your &lt;strong&gt;error budget&lt;/strong&gt; and use it to guide trade-offs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Here are some practical ways to maintain reliability while scaling dynamically:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Spread pods across multiple zones.&lt;/strong&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;Use &lt;strong&gt;pod topology spread constraints&lt;/strong&gt; with whenUnsatisfiable: ScheduleAnyway to ensure high availability without over-provisioning. Be aware this can slightly increase cost as new nodes may be launched for even distribution.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Use Pod Disruption Budgets (PDBs)&lt;/strong&gt; and &lt;strong&gt;NodePool Disruption Budgets (NDBs)&lt;/strong&gt; (if using Karpenter).&lt;br&gt;These help manage voluntary disruptions like node consolidations or upgrades. But remember — for involuntary events like spot terminations, these budgets don’t apply. Always test your application’s tolerance to unexpected terminations.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Handle terminations gracefully.&lt;/strong&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;Configure terminationGracePeriodSeconds (default: 30s; consider extending to 90s), add a preStop hook for cleanup tasks, and implement a readinessProbe so traffic isn’t routed to terminating pods. If possible, handle the SIGTERM signal directly in your application code.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Monitor node health proactively.&lt;/strong&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;Tools like &lt;strong&gt;Node Problem Detector&lt;/strong&gt; can surface issues early, and &lt;strong&gt;Karpenter’s Node Auto Repair&lt;/strong&gt; can automatically replace unhealthy nodes.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;When done right, these strategies let you scale efficiently &lt;em&gt;without compromising reliability&lt;/em&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;It’s all about trade-offs&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;There’s no &lt;strong&gt;silver bullet&lt;/strong&gt; for autoscaling. Every optimization introduces trade-offs between &lt;strong&gt;cost&lt;/strong&gt;, &lt;strong&gt;performance&lt;/strong&gt;, and &lt;strong&gt;reliability&lt;/strong&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;You might start optimizing for cost, then realize performance suffers. Or you focus on performance, and costs balloon. The key is to &lt;strong&gt;treat autoscaling as an ongoing process&lt;/strong&gt; — a continuous journey of measurement, experimentation, and refinement.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Keep watching how &lt;strong&gt;KEDA and Karpenter evolve&lt;/strong&gt; — both projects are rapidly improving with new features that make scaling smarter and simpler. And remember: most of the principles here also apply to &lt;strong&gt;AI and ML workloads&lt;/strong&gt;, which bring new scaling challenges worth exploring in the future.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Meet with me at the AWS Booth #210&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;em&gt;Author bio&lt;/em&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;&lt;strong&gt;Christian Melendez&lt;/strong&gt; is Principal Specialist Solutions Architect and EMEA Lead for Compute at AWS, with a strong background in Kubernetes platform engineering and author of the Kubernetes Autoscaling book. Christian has been working with Kubernetes since 2017, helping large enterprises—including telecommunications, airline, and ride-hailing companies—optimize their workloads. He is the creator of the &lt;strong&gt;Karpenter Blueprints&lt;/strong&gt; project and an active contributor to autoscaling solutions in the cloud-native space. Christian frequently delivers talks and workshops on Karpenter and Kubernetes optimization strategies.&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;在汉堡的 ContainerDays 期间，Kelsey Hightower 提出了一个简单但有力的问题：“为什么我们仍在谈论容器？”他的观点引起了我的深刻共鸣——即使在人工智能时代，云原生社区仍在完善容器编排、可扩展性和效率的基础知识。在这篇文章中，我将探讨 KEDA 和 Karpenter 等开源项目如何帮助您平衡 Kubernetes 自动扩展的性能、可靠性和成本。&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Kubernetes 自动缩放需要权衡&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;当我们谈论 &lt;strong&gt;Kubernetes 自动扩展&lt;/strong&gt;时，它不仅仅是在需求增长时添加副本或节点，在需求减少时删除它们。您必须平衡&lt;strong&gt;性能&lt;/strong&gt;、&lt;strong&gt;可靠性&lt;/strong&gt;和&lt;strong&gt;成本&lt;/strong&gt;——这三种力量不断相互对抗。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我喜欢将这三个支柱视为一个&lt;strong&gt;三角形&lt;/strong&gt;，如下图所示。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“1226”高度=“746” src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.20.25-AM.jpg&#34; alt=&#34;Kubernetes 自动缩放三角柱&#34; class=&#34;wp-image-149687&#34; srcset =“https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.20.25-AM.jpg 1226w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.20.25-AM-300x183.jpg 300w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.20.25-AM-1024x623.jpg 1024w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.20.25-AM-768x467.jpg 768w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.20.25-AM-900x548.jpg 900w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.20.25-AM-329x200.jpg 329w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.20.25-AM-657x400.jpg 657w“尺寸=”自动，（最大宽度：1226px）100vw，1226px“ referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这三大支柱创造了自然的张力。在应用程序性能下降之前，您需要添加资源，这会增加成本。为了节省成本，您需要缩减资源，这可能会影响可靠性。那么我们如何找到合适的平衡点呢？让我们探索每个支柱的工具和建议。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;性能&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在开始扩展之前，您需要了解&lt;strong&gt;真正影响应用程序性能的因素&lt;/strong&gt;——什么对您的用户和利益相关者来说很重要。大多数时候，他们并不直接关心 CPU 或内存的使用情况。这些可能是指标，但它们并不总是能说明全部情况。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;成功实现自动扩展的团队通常会跟踪诸如&lt;strong&gt;每秒请求数、延迟、队列深度、首次令牌时间、每秒令牌数&lt;/strong&gt;，甚至&lt;strong&gt;事件发生率等指标来自云提供商等外部来源的撕裂指标。每个工作负载都没有单一的“黄金”指标。通常，组合效果最佳。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这就是&lt;a href=&#34;https://keda.sh/&#34;&gt;&lt;strong&gt;KEDA&lt;/strong&gt;&lt;/a&gt; 的闪光点。即使您当前在 CPU 或内存上进行扩展，KEDA 也支持这些指标，而且还为&lt;strong&gt;自定义触发器和复合扩展规则&lt;/strong&gt;打开了大门，以应对更复杂的工作负载。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;当您知道哪些指标实际影响性能时，您可以设计更智能的扩展策略和阈值。目标是确保您不会以牺牲用户体验为代价来缩减资源。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;找到正确扩展配置的实用方法是&lt;strong&gt;测试您的工作负载&lt;/strong&gt;：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;使用 &lt;strong&gt;k6&lt;/strong&gt; 等负载测试工具发送合成流量。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;使用 &lt;strong&gt;VPA&lt;/strong&gt;、&lt;strong&gt;krr&lt;/strong&gt; 或 &lt;strong&gt;Goldilocks&lt;/strong&gt; 进行实验以了解资源效率。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;确定单 Pod、多 Pod 或观察到的实时场景的临界点。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“1224”高度=“736” src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.21.55-AM.jpg&#34; alt=&#34;Kubernetes 自动缩放组件和工具示例&#34; class=&#34;wp-image-149688&#34; srcset =“https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.21.55-AM.jpg 1224w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.21.55-AM-300x180.jpg 300w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.21.55-AM-1024x616.jpg 1024w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.21.55-AM-768x462.jpg 768w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.21.55-AM-900x541.jpg 900w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.21.55-AM-333x200.jpg 333w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.21.55-AM-665x400.jpg 665w“尺寸=”自动，（最大宽度：1224px）100vw，1224px“ referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;即使这听起来很多，但从这种方法开始可以帮助您更好地理解您的缩放模式 - 并且您可以稍后实现自动化。自动化的一个很好的例子是通过 VPA 进行&lt;strong&gt;就地 pod 调整大小&lt;/strong&gt;，它允许进行更多动态调整。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;成本&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;自动扩展的最大动力之一是&lt;strong&gt;效率&lt;/strong&gt; - 在需要时仅使用您需要的资源。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;KEDA&lt;/strong&gt; 通过智能扩展 Pod 来帮助调整工作负载大小，而 &lt;a href=&#34;https://karpenter.sh/&#34;&gt;&lt;strong&gt;Karpenter&lt;/strong&gt;&lt;/a&gt; 通过以成本优化的方式&lt;strong&gt;配置即时节点&lt;/strong&gt;来补充它。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;以下是它们如何协同工作：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&lt;li&gt;当需求增长时，&lt;strong&gt;KEDA 会添加更多 Pod&lt;/strong&gt; 来处理增加的负载。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;当 Pod 由于容量不足而变得无法调度时，&lt;strong&gt;Karpenter 会提供新节点&lt;/strong&gt;来满足该需求。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“1334”高度=“654” src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.23.07-AM.jpg&#34; alt=&#34;Kubernetes 中自动缩放应用程序的阶段&#34; class=&#34;wp-image-149689&#34; srcset =“https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.23.07-AM.jpg 1334w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.23.07-AM-300x147.jpg 300w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.23.07-AM-1024x502.jpg 1024w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.23.07-AM-768x377.jpg 768w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.23.07-AM-900x441.jpg 900w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.23.07-AM-408x200.jpg 408w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.23.07-AM-816x400.jpg 816w“尺寸=”自动，（最大宽度：1334px）100vw，1334px“ referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Karpenter 确保仅启动&lt;strong&gt;必要的容量&lt;/strong&gt; - 不多也不少。&lt;br&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“1168”高度=“626” src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.24.13-AM.jpg&#34; alt=&#34;(续) Kubernetes 中自动缩放应用程序的阶段&#34; class=&#34;wp-image-149690&#34; srcset =“https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.24.13-AM.jpg 1168w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.24.13-AM-300x161.jpg 300w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.24.13-AM-1024x549.jpg 1024w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.24.13-AM-768x412.jpg 768w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.24.13-AM-900x482.jpg 900w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.24.13-AM-373x200.jpg 373w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-11.24.13-AM-746x400.jpg 746w“尺寸=”自动，（最大宽度：1168px）100vw，1168px“ referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;当需求下降时，&lt;strong&gt;KEDA 会缩小 Pod 规模&lt;/strong&gt;，&lt;strong&gt;Karpenter&lt;/strong&gt; 可以整合或删除未充分利用的节点。它可以模拟节点驱逐，以确定是否可以将工作负载打包到更少、更便宜的节点上，从而释放容量。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您想看到这一点的实际效果，请查看我录制的演示，其中展示了&lt;strong&gt;KEDA 和 Karpenter 的合作&lt;/strong&gt;，或者是我与 Jan Wozniak (KED) 共同主持的会议&lt;strong&gt;KCD Czech &amp; Slovak&lt;/strong&gt; 的维护者）。两者都强调了智能扩展如何显着&lt;strong&gt;降低成本并提高集群效率&lt;/strong&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;可靠性&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;第三个支柱 - &lt;strong&gt;可靠性&lt;/strong&gt; - 是事情经常变得棘手的地方。自动缩放会动态添加和删除 Pod 和节点，如果您的应用程序不是为处理正常终止或突然更改而构建的，这可能会影响稳定性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在解决可靠性问题之前，请明确定义您的&lt;strong&gt;SLA 和 SLO&lt;/strong&gt;。如果您的服务水平期望不需要，您不想过度设计或过度支出。例如，如果您的 SLA 是&lt;em&gt;每秒 3,500 个请求时的延迟为 500 毫秒&lt;/em&gt;，请进行相应的设计 - 了解您的&lt;strong&gt;错误预算&lt;/strong&gt;并用它来指导权衡。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;以下是一些在动态扩展的同时保持可靠性的实用方法：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;将 Pod 分布到多个区域。&lt;/strong&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;将&lt;strong&gt;Pod 拓扑分布约束&lt;/strong&gt;与whenUnsatisfiable: ScheduleAnyway 配合使用，以确保高可用性，而不会过度配置。请注意，这可能会稍微增加成本，因为可能会启动新节点以实现均匀分布。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;使用 Pod 中断预算 (PDB)&lt;/strong&gt; 和 &lt;strong&gt;NodePool 中断预算 (NDB)&lt;/strong&gt;（如果使用 Karpenter）。&lt;br&gt;这些有助于管理自愿中断，例如节点整合或升级。但请记住，对于现场终止等非自愿事件，这些预算不适用。始终测试应用程序对意外终止的容忍度。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;优雅地处理终止。&lt;/strong&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;配置 TerminationGracePeriodSeconds（默认值：30 秒；考虑延长至 90 秒），为清理任务添加 preStop 挂钩，并实现 readinessProbe，以便流量不会路由到终止 pod。如果可能，请直接在应用程序代码中处理 SIGTERM 信号。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;主动监控节点健康状况。&lt;/strong&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;&lt;strong&gt;节点问题检测器&lt;/strong&gt;等工具可以及早发现问题，&lt;strong&gt;Karpenter 的节点自动修复&lt;/strong&gt;可以自动替换不健康的节点。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果做得正确，这些策略可以让您在不影响可靠性的情况下高效扩展。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;一切都与权衡有关&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;自动缩放没有&lt;strong&gt;灵丹妙药&lt;/strong&gt;。每次优化都会在&lt;strong&gt;成本&lt;/strong&gt;、&lt;strong&gt;性能&lt;/strong&gt;和&lt;strong&gt;可靠性&lt;/strong&gt;之间进行权衡。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;您可能会开始针对成本进行优化，然后意识到性能会受到影响。或者您专注于性能，而成本却在膨胀。关键是&lt;strong&gt;将自动扩展视为一个持续的过程&lt;/strong&gt; - 一个持续的测量、实验和改进过程。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;保持警惕了解 &lt;strong&gt;KEDA 和 Karpenter 如何发展&lt;/strong&gt; - 这两个项目都在通过新功能快速改进，使扩展变得更智能、更简单。请记住：这里的大多数原则也适用于&lt;strong&gt;人工智能和机器学习工作负载&lt;/strong&gt;，这带来了值得未来探索的新的扩展挑战。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;在 AWS 210 号展位与我会面&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;em&gt;作者简介&lt;/em&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;&lt;strong&gt;Christian Melendez&lt;/strong&gt; 是 AWS 首席专家解决方案架构师兼 EMEA 计算主管，拥有深厚的 Kubernetes 平台工程背景，也是 Kubernetes Autoscaling 一书的作者。 Christian 自 2017 年以来一直与 Kubernetes 合作，帮助大型企业（包括电信、航空公司和叫车公司）优化其工作负载。他是 &lt;strong&gt;Karpenter Blueprints&lt;/strong&gt; 项目的创建者，也是云原生领域自动扩展解决方案的积极贡献者。 Christian 经常就 Karpenter 和 Kubernetes 优化策略发表演讲和研讨会。&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Wed, 15 Oct 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Automating stateful apps with Kubernetes Operators】使用 Kubernetes Operators 自动化有状态应用程序</title>
      <link>https://www.cncf.io/blog/2025/10/15/automating-stateful-apps-with-kubernetes-operators/</link>
      <description>【&lt;p&gt;&lt;em&gt;Member post originally published on the &lt;/em&gt;&lt;a href=&#34;https://middleware.io/&#34;&gt;&lt;strong&gt;&lt;em&gt;Middleware&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;&lt;em&gt; &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;blog by &lt;/em&gt;&lt;a href=&#34;https://middleware.io/blog/authors/keval/&#34;&gt;&lt;strong&gt;&lt;em&gt;Keval Bhogayata&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt;, covering &lt;a href=&#34;https://middleware.io/blog/kubernetes-operator/&#34;&gt;&lt;strong&gt;&lt;em&gt;Automating Stateful Apps with Kubernetes Operators.&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you’ve ever had issues with scaling databases or automating upgrades in Kubernetes, Operators can help by saving you time and effort. Handling complex Kubernetes applications like databases, message queues, and &lt;a href=&#34;https://middleware.io/blog/what-is-distributed-tracing/&#34;&gt;distributed systems&lt;/a&gt; can be really difficult. Kubernetes handles simple workloads well, while big apps suffer with failover, scaling, backups, and automated updates. These activities often demand operational expertise.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you’re new to container orchestration, you may want to start by understanding the difference between &lt;a href=&#34;https://middleware.io/blog/kubernetes-vs-docker/&#34;&gt;Kubernetes vs Docker&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This is where you need Kubernetes Operators, which we’ll cover in this article. You’ll learn what these Operators are, how they work, and why you need them.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Let’s get to it.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;What are Kubernetes Operators?&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Operators are extra tools that help you manage complex or stateful applications in Kubernetes. It is a combination of Controllers and Custom Resource Definitions (CRDs).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Controllers are the rules for deploying, setting up, scaling, healing, and updating resources. CRDs let you add a new object type to Kubernetes. CRDs also allow you to describe the type of object you want to manage, after which you proceed to create a Custom Resource (CR), which is an instance of the object type you have made.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;637&#34; height=&#34;450&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.16.40-PM.jpg&#34; alt=&#34;Kubernetes Operator Architecture&#34; class=&#34;wp-image-149577&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.16.40-PM.jpg 637w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.16.40-PM-300x212.jpg 300w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.16.40-PM-283x200.jpg 283w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.16.40-PM-566x400.jpg 566w&#34; sizes=&#34;auto, (max-width: 637px) 100vw, 637px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The primary purpose of operators is to simplify the management of complex Kubernetes applications, enabling tasks such as upgrades, failover management, backups, and scalability to be performed automatically.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Difference between traditional Kubernetes Controllers and Operators&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Here’s a breakdown of the difference between the Kubernetes Controller and Operators:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;644&#34; height=&#34;424&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.17.57-PM.jpg&#34; alt=&#34;Breakdown of the difference between the Kubernetes Controller and Operators&#34; class=&#34;wp-image-149578&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.17.57-PM.jpg 644w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.17.57-PM-300x198.jpg 300w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.17.57-PM-304x200.jpg 304w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.17.57-PM-608x400.jpg 608w&#34; sizes=&#34;auto, (max-width: 644px) 100vw, 644px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;How Kubernetes Operators work&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Assuming you have your app ready, a basic Kubernetes setup, and a working deployment. Without Operators, you’ll have to install and manage the app yourself manually. But with Operators, you can run these processes automatically. Here’s how it works:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;1. Set up a Custom Resource&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;A Custom Resource (CR) is an object you make to control a particular aspect of your application. You need to declare a CRD before you can create a CR. CRD tells Kubernetes about the new type of object you are making.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Here’s an example of a CRD that defines a CR called “MyAPP”:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;329&#34; height=&#34;530&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.19.23-PM.jpg&#34; alt=&#34;example of a CRD that defines a CR called “MyAPP”&#34; class=&#34;wp-image-149579&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.19.23-PM.jpg 329w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.19.23-PM-186x300.jpg 186w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.19.23-PM-124x200.jpg 124w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.19.23-PM-248x400.jpg 248w&#34; sizes=&#34;auto, (max-width: 329px) 100vw, 329px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This CRD defines a custom resource called “MyApp.” It has two major fields under spec: size and version.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Once the CRD is applied to the cluster, you can go ahead to create instances of “MyApp,” which represent your app configuration:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;272&#34; height=&#34;160&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.20.19-PM.jpg&#34; alt=&#34;image of instance of “MyApp,” which represent your app configuration&#34; class=&#34;wp-image-149580&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This CR declares that you want 3 replicas of example-app (an instance of MyApp) running with version 1.0.0. The Operator will then watch this resource and make sure your app matches what you declared.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;2. Deploy the Operator into the Kubernetes cluster&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;After defining your CR, the next thing is to deploy the Operator itself. This will monitor CR changes and ensure the cluster status matches your declaration.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;You usually use a set of Kubernetes configuration files (YAML files) to notify the cluster to run the Operator as a Pod. This includes setting up permissions so the Operator can watch and manage resources.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Example:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full is-resized&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;392&#34; height=&#34;34&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.21.16-PM.jpg&#34; alt=&#34;example of setting up permissions so the Operator can watch and manage resources&#34; class=&#34;wp-image-149581&#34; style=&#34;width:392px;height:auto&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.21.16-PM.jpg 392w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.21.16-PM-300x26.jpg 300w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.21.16-PM-388x34.jpg 388w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.21.16-PM-380x34.jpg 380w&#34; sizes=&#34;auto, (max-width: 392px) 100vw, 392px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;3. Continuous monitoring of CR by the Operator.&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;After deployment, the Operator will constantly monitor changes in the CRs it manages. This monitoring can be done using Kubernetes API. It watches for events such as creation, updates, or deletions of these CRs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The Operator looks out for real-time changes to ensure it can react as soon as something happens. With Kubernetes client, you can set up a watch on your CR like this:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;619&#34; height=&#34;574&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.22.30-PM.jpg&#34; alt=&#34;example of how to set up a watch on your CR&#34; class=&#34;wp-image-149582&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.22.30-PM.jpg 619w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.22.30-PM-300x278.jpg 300w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.22.30-PM-216x200.jpg 216w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.22.30-PM-431x400.jpg 431w&#34; sizes=&#34;auto, (max-width: 619px) 100vw, 619px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This code monitors the “MyApp” CRs in the specified namespace. The Operator will get an event with details when you add, change, or delete a CR. This lets it react fast and keep the app’s state in line with the specified setup.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;4. Reconciliation loop: Operator compares desired vs actual state&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The reconciliation loop is the main idea behind Operators. It makes sure that the actual state of your app matches the desired state you defined in the Custom Resource by re-running the whole process if it fails.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;648&#34; height=&#34;568&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.23.24-PM.jpg&#34; alt=&#34;Reconciliation Loop&#34; class=&#34;wp-image-149583&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.23.24-PM.jpg 648w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.23.24-PM-300x263.jpg 300w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.23.24-PM-228x200.jpg 228w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.23.24-PM-456x400.jpg 456w&#34; sizes=&#34;auto, (max-width: 648px) 100vw, 648px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Here’s how it works:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;The Operator reads the desired state of your CR.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Then it checks the actual state of the cluster.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;If they don’t match, it acts to fix it.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;It repeats this process continuously.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This reconciliation logic can be triggered by the watch events we set up earlier.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;625&#34; height=&#34;305&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.24.08-PM.jpg&#34; alt=&#34;example of reconciliation logic can be triggered by the watch events we set up earlier&#34; class=&#34;wp-image-149584&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.24.08-PM.jpg 625w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.24.08-PM-300x146.jpg 300w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.24.08-PM-410x200.jpg 410w&#34; sizes=&#34;auto, (max-width: 625px) 100vw, 625px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The reconciliation function guarantees your application works as expected.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;5. Error handling&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;One way or the other, you’ll still encounter problems when working with Operators. When issues come up, the Operator won’t just stop. They keep trying until they get the correct result.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For example, learn about diagnosing and fixing &lt;a href=&#34;https://middleware.io/blog/exit-code-137-in-kubernetes-causes-diagnosis-fixes/&#34;&gt;Exit Code 137 in Kubernetes&lt;/a&gt;, a common error when pods are OOMKilled.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Here’s the idea:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;The operator tries to make the actual state equal to the desired state&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;It logs an error if it fails&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;The reconciliation loop runs again after a while&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;The Operator tries again until it works.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Use cases of Kubernetes Operators&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Operators are mostly helpful when working with complex or stateful apps. Here are some practical scenarios where Operators provide great value and how Middleware helps teams get more visibility out of them:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Handling stateful apps&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Stateful workloads, such as databases, can be challenging to manage because data recovery is crucial. Operators help to manage these workloads even when a container or pod stops. It automatically does backups, restores, scaling, and upgrades. A good example is the Postgres and MySQL Operators.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Postgres Operator allows you to automate backups, failover, and scaling of PostgreSQL clusters. The Operator will automatically configure replicas or restore from snapshots, instead of SREs doing it manually.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Messaging systems&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Messaging platforms like Kafka require careful tuning and scaling, particularly under high traffic loads. The Strimzi Kafka Operator simplifies this by provisioning brokers, handling configuration, and managing users. This removes the stress of manually scaling and restarting on the &lt;a href=&#34;https://middleware.io/blog/what-is-devops/&#34;&gt;DevOps&lt;/a&gt; teams.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Monitoring and logging stacks&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Tools for monitoring and &lt;a href=&#34;https://middleware.io/blog/what-is-log-monitoring/&#34;&gt;logging&lt;/a&gt;, such as &lt;a href=&#34;https://middleware.io/blog/what-is-prometheus/&#34;&gt;Prometheus&lt;/a&gt; or ELK, must always be available and scalable to collect data effectively. Prometheus Operators automate upgrades, scaling, and configuration management. This makes sure that the monitoring pipeline is stable without human intervention.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Automating infrastructure&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Operators are not limited to apps; they can also automate repetitive infrastructure tasks, such as provisioning storage, configuring network policies, or managing certificates. This helps ensure consistency and security while reducing the risk of errors associated with manual processes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Again, Middleware displays these invisible tasks, which allows SREs to audit changes, track automation workflows, and &lt;a href=&#34;https://docs.middleware.io/workflow/alerting/setup-alert&#34;&gt;set up alerts&lt;/a&gt; when infrastructure doesn’t match the expected state.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Why do we need Operators?&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes controllers are mostly applicable when it comes to managing simple apps. But when dealing with complex or stateful apps, they have limitations. These native controllers cannot automate application-specific operations and workflows, making it difficult to manage tasks like database provisioning, upgrades, and failover reliably.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Without Operators, manual database recovery can lead to hours of &lt;a href=&#34;https://middleware.io/blog/observability-in-action-reducing-downtime-with-middleware/&#34;&gt;downtime&lt;/a&gt;. Kubernetes Operators automate these tasks, and Middleware real-time alerts ensure you catch issues early.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Challenges without Operators&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Without Operators, you will face these challenges:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Manual database setup and recovery: You have to create and fix databases yourself, which takes time and can cause mistakes.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Hard upgrades: Updating apps will require many steps and careful timing to avoid breaking things.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;No app-specific knowledge: Built-in controllers are unaware of your app’s unique rules, so they can’t fully automate it.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Explore common &lt;/em&gt;&lt;a href=&#34;https://middleware.io/blog/kubernetes-challenges-and-solutions/&#34;&gt;&lt;em&gt;Kubernetes challenges and solutions&lt;/em&gt;&lt;/a&gt;&lt;em&gt; that teams face without automation.&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Kubernetes Operators benefits&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;These are some of the benefits of using Operators:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Automating app lifecycle: Operators automate critical operations, such as installation, backup, upgrade, and failover, tailored to the application’s specific needs.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Enforcing consistency at scale: Operators ensure that the desired state is consistently maintained across multiple instances or clusters, simplifying large-scale management.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Reducing human error: Operators minimize manual interventions and reduce human error by applying expert operational knowledge.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Automate app lifecycle: Operators can reduce failover downtime by recovering stateful apps automatically. This will improve availability and reliability.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Operators automate management, but visibility is key. Discover the top &lt;/em&gt;&lt;a href=&#34;https://middleware.io/blog/kubernetes-monitoring/tools/&#34;&gt;&lt;em&gt;Kubernetes monitoring tools&lt;/em&gt;&lt;/a&gt;&lt;em&gt; that help you track app performance, spot issues early, and maintain cluster stability effortlessly.&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Conclusion&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Operators are a powerful addition to Kubernetes because they make it easier to handle stateful and complex tasks, which seem to be difficult for built-in controllers. While Operators make work easier inside Kubernetes, teams still need a way to monitor and make sure their app is working as expected.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Observability through metrics, logs, and traces becomes the bridge between automation and assurance. By integrating robust monitoring and alerting with your Operators, teams can quickly detect anomalies, validate desired states, and ensure that self-healing mechanisms are actually working as intended. In the end, Operators simplify the &lt;em&gt;how&lt;/em&gt; of running applications, but observability provides confidence in the &lt;em&gt;why&lt;/em&gt; and &lt;em&gt;when,&lt;/em&gt; turning Kubernetes into a truly resilient platform.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;最初在 &lt;/em&gt;&lt;a href=&#34;https://middleware.io/&#34;&gt;&lt;strong&gt;&lt;em&gt;中间件&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;&lt;em&gt; &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;博客上发布的成员帖子&lt;/em&gt;&lt;a href=&#34;https://middleware.io/blog/authors/keval/&#34;&gt;&lt;strong&gt;&lt;em&gt;Keval Bhogayata&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt;，涵盖&lt;a href=&#34;https://middleware.io/blog/authors/keval/&#34;&gt;&lt;strong&gt;&lt;em&gt;自动化有状态应用 Kubernetes 操作员。&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您在 Kubernetes 中扩展数据库或自动升级方面遇到过问题，Operators 可以帮助您节省时间和精力。处理复杂的 Kubernetes 应用程序（例如数据库、消息队列和分布式系统）可能非常困难。 Kubernetes 可以很好地处理简单的工作负载，而大型应用程序则受到故障转移、扩展、备份和自动更新的困扰。这些活动通常需要运营专业知识。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您不熟悉容器编排，您可能需要首先了解 &lt;a href=&#34;https://middleware.io/blog/kubernetes-vs-docker/&#34;&gt;Kubernetes 与 Docker&lt;/a&gt;&lt;/p&gt; 之间的区别&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这就是您需要 Kubernetes Operator 的地方，我们将在本文中介绍。您将了解这些 Operator 是什么、它们如何工作以及为什么需要它们。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;让我们开始吧。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;什么是 Kubernetes Operator？&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;运算符是额外的工具，可帮助您管理 Kubernetes 中的复杂或有状态应用程序。它是控制器和自定义资源定义 (CRD) 的组合。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;控制器是部署、设置、扩展、修复和更新资源的规则。 CRD 允许您向 Kubernetes 添加新的对象类型。 CRD 还允许您描述要管理的对象类型，然后您可以继续创建自定义资源 (CR)，它是您创建的对象类型的实例。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“637”高度=“450” src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.16.40-PM.jpg&#34; alt=&#34;Kubernetes 操作架构&#34; class=&#34;wp-image-149577&#34; srcset =“https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.16.40-PM.jpg 637w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.16.40-PM-300x212.jpg 300w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.16.40-PM-283x200.jpg 283w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.16.40-PM-566x400.jpg 566w“尺寸=”自动，（最大宽度：637px）100vw，637px“ referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Operator 的主要目的是简化复杂 Kubernetes 应用程序的管理，使升级、故障转移管理、备份和可扩展性等任务能够自动执行。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;传统 Kubernetes Controller 和 Operator 的区别&lt;/h3&gt;&lt;p&gt;以下是 Kubernetes 控制器和操作员之间差异的详细说明：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“644”高度=“424” src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.17.57-PM.jpg&#34; alt=&#34;Kubernetes Controller 和 Operator 之间的差异细分&#34; class=&#34;wp-image-149578&#34; srcset =“https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.17.57-PM.jpg 644w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.17.57-PM-300x198.jpg 300w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.17.57-PM-304x200.jpg 304w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.17.57-PM-608x400.jpg 608w“尺寸=”自动，（最大宽度：644px）100vw，644px“ referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Kubernetes Operator 的工作原理&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;假设您已准备好应用程序、基本的 Kubernetes 设置和有效的部署。如果没有 Operator，您将必须手动安装和管理应用程序。但使用 Operators，您可以自动运行这些流程。其工作原理如下：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;1.设置自定义资源&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;自定义资源 (CR) 是您为控制应用程序的特定方面而创建的对象。您需要先声明 CRD，然后才能创建 CR。 CRD 告诉 Kubernetes 您正在创建的新对象类型。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;以下是定义名为“MyAPP”的 CR 的 CRD 示例：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“329”高度=“530” src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.19.23-PM.jpg&#34; alt=&#34;定义名为“MyAPP”的 CR 的 CRD 示例&#34; class=&#34;wp-image-149579&#34; srcset =“https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.19.23-PM.jpg 329w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.19.23-PM-186x300.jpg 186w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.19.23-PM-124x200.jpg 124w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.19.23-PM-248x400.jpg 248w“尺寸=”自动，（最大宽度：329px）100vw，329px“ referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;此 CRD 定义了一个名为“MyApp”的自定义资源。它在规格下有两个主要字段：尺寸和版本。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;将 CRD 应用到集群后，您可以继续创建“MyApp”实例，它代表您的应用配置：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“272”高度=“160” src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.20.19-PM.jpg&#34; alt=&#34;“MyApp”实例的图像，代表您的应用程序配置&#34; class=&#34;wp-image-149580&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;此 CR 声明您你想要 3 个运行版本 1.0.0 的 example-app 副本（MyApp 的一个实例）。然后，运营商将监视此资源并确保您的应用与您声明的内容相符。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;2.将Operator部署到Kubernetes集群&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;定义 CR 后，下一步是部署 Operator 本身。这将监控 CR 更改并确保集群状态与您的声明相符。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;您通常使用一组 Kubernetes 配置文件（YAML 文件）来通知集群将 Operator 作为 Pod 运行。这包括设置权限，以便操作员可以监视和管理资源。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;示例：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full is-resized”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“392”高度=“34” src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.21.16-PM.jpg&#34; alt=&#34;设置权限的示例，以便操作员可以监视和管理资源&#34; class=&#34;wp-image-149581&#34; 样式=“宽度：392px；高度：自动”srcset=“https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.21.16-PM.jpg 392w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.21.16-PM-300x26.jpg 300w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.21.16-PM-388x34.jpg 388w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.21.16-PM-380x34.jpg 380w“尺寸=”自动，（最大宽度：392px）100vw，392px“ referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;3.运营商持续监控 CR。&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;部署后，Operator 将持续监控其管理的 CR 的变化。这种监控可以使用 Kubernetes API 来完成。它监视这些 CR 的创建、更新或删除等事件。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;操作员会留意实时变化，以确保在发生情况时能够立即做出反应。使用 Kubernetes 客户端，您可以在 CR 上设置监视，如下所示：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“619”高度=“574” src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.22.30-PM.jpg&#34; alt=&#34;如何在 CR 上设置手表的示例&#34; class=&#34;wp-image-149582&#34; srcset =“https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.22.30-PM.jpg 619w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.22.30-PM-300x278.jpg 300w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.22.30-PM-216x200.jpg 216w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.22.30-PM-431x400.jpg 431w“尺寸=”自动，（最大宽度：619px）100vw，619px“ referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;此代码监视指定命名空间中的“MyApp”CR。当您添加、更改或删除 CR 时，操作员将收到包含详细信息的事件。这使其能够快速反应并使应用程序的状态与指定的设置保持一致。&lt;/p&gt;&lt;h3 class=&#34;wp-block-heading&#34;&gt;4.协调循环：操作员比较期望状态与实际状态&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;协调循环是 Operators 背后的主要思想。它通过在失败时重新运行整个过程来确保应用程序的实际状态与您在自定义资源中定义的所需状态相匹配。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“648”高度=“568” src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.23.24-PM.jpg&#34; alt=&#34;协调循环&#34; class=&#34;wp-image-149583&#34; srcset =“https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.23.24-PM.jpg 648w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.23.24-PM-300x263.jpg 300w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.23.24-PM-228x200.jpg 228w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.23.24-PM-456x400.jpg 456w“尺寸=”自动，（最大宽度：648px）100vw，648px“ referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;它的工作原理如下：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;操作员读取您所需的 CR 状态。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;然后它会检查集群的实际状态。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;如果它们不匹配，它就会修复它。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;它不断重复这个过程。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这个协调逻辑可以由我们之前设置的监视事件触发。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“625”高度=“305” src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.24.08-PM.jpg&#34; alt=&#34;协调逻辑示例可以由我们之前设置的监视事件触发&#34; class=&#34;wp-image-149584&#34; srcset =“https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.24.08-PM.jpg 625w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.24.08-PM-300x146.jpg 300w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-1.24.08-PM-410x200.jpg 410w“尺寸=”自动，（最大宽度：625px）100vw，625px“ referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;协调功能保证您的应用程序按预期工作。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;5.错误处理&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;无论怎样，在与 Operator 合作时您仍然会遇到问题。当问题出现时，操作员不会停下来。他们不断尝试，直到得到正确的结果。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;例如，了解如何诊断和修复 &lt;a href=&#34;https://middleware.io/blog/exit-code-137-in-kubernetes-causes-diagnosis-fixes/&#34;&gt;Kubernetes 中的退出代码 137&lt;/a&gt;，这是 pod OOMKilled 时的常见错误。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这个想法是这样的：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;操作员试图使实际状态等于期望状态&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;如果失败，它会记录错误&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;调节循环在一段时间后再次运行&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;操作员会再次尝试，直到成功为止。&lt;/李&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Kubernetes Operator 的用例&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;操作员在处理复杂或有状态的应用程序时最有帮助。以下是一些运营商提供巨大价值的实际场景，以及中间件如何帮助团队获得更多可见性：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;处理有状态应用&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;有状态工作负载（例如数据库）可能难以管理，因为数据恢复至关重要。即使容器或 Pod 停止，操作员也可以帮助管理这些工作负载。它自动执行备份、恢复、扩展和升级。 Postgres 和 MySQL Operators 就是一个很好的例子。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Postgres Operator 允许您自动执行 PostgreSQL 集群的备份、故障转移和扩展。 Operator 将自动配置副本或从快照恢复，而不是 SRE 手动执行。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;消息系统&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;像 Kafka 这样的消息平台需要仔细调整和扩展，特别是在高流量负载下。 Strimzi Kafka Operator 通过配置代理、处理配置和管理用户来简化这一过程。这消除了 &lt;a href=&#34;https://middleware.io/blog/what-is-devops/&#34;&gt;DevOps&lt;/a&gt; 团队手动扩展和重新启动的压力。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;监控和记录堆栈&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;监控和日志记录工具（例如 Prometheus 或 ELK）必须始终可用且可扩展，才能有效收集数据。 Prometheus Operators 可自动执行升级、扩展和配置管理。这确保了监控管道在无需人工干预的情况下稳定。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;自动化基础设施&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;运营商不限于应用程序；他们还可以自动执行重复的基础设施任务，例如配置存储、配置网络策略或管理证书。这有助于确保一致性和安全性，同时降低与手动流程相关的错误风险。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;同样，中间件会显示这些不可见的任务，从而允许 SRE 审核更改、跟踪自动化工作流程，并在基础设施与预期状态不匹配时&lt;a href=&#34;https://docs.middleware.io/workflow/alerting/setup-alert&#34;&gt;设置警报&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;为什么我们需要 Operator？&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes 控制器主要适用于管理简单的应用程序。但在处理复杂或有状态的应用程序时，它们有局限性。这些本机控制器无法自动执行特定于应用程序的操作和工作流程，从而难以可靠地管理数据库配置、升级和故障转移等任务。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果没有 Operator，手动数据库恢复可能会导致数小时的&lt;a href=&#34;https://middleware.io/blog/observability-in-action-reducing-downtime-with-middleware/&#34;&gt;停机&lt;/a&gt;。Kubernetes Operator 可以自动执行这些任务，中间件实时警报可确保您及早发现问题。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;没有操作员的挑战&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果没有 Operator，您将面临以下挑战：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;手动数据库设置和恢复：您必须自己创建和修复数据库，这需要时间并且可能会导致错误。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;硬升级：更新应用需要执行许多步骤并仔细安排时间，以避免造成破坏。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;没有特定于应用的知识：内置控制器不知道您的应用的独特规则，因此无法完全自动化。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;探索团队在没有自动化的情况下面临的常见&lt;/em&gt;&lt;a href=&#34;https://middleware.io/blog/kubernetes-challenges-and-solutions/&#34;&gt;&lt;em&gt;Kubernetes 挑战和解决方案&lt;/em&gt;&lt;/a&gt;&lt;em&gt;。&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Kubernetes Operator 的优势&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;以下是使用 Operator 的一些好处：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;自动化应用生命周期：运营商可根据应用的特定需求自动执行关键操作，例如安装、备份、升级和故障转移。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;大规模实施一致性：运营商确保在多个实例或集群中一致维护所需的状态，从而简化大规模管理。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;减少人为错误：操作员通过运用专业操作知识，最大限度地减少人工干预并减少人为错误。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;自动化应用生命周期：运营商可以通过自动恢复有状态应用来减少故障转移停机时间。这将提高可用性和可靠性。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;运营商实现管理自动化，但可见性是关键。探索顶级 &lt;/em&gt;&lt;a href=&#34;https://middleware.io/blog/kubernetes-monitoring/tools/&#34;&gt;&lt;em&gt;Kubernetes 监控工具&lt;/em&gt;&lt;/a&gt;&lt;em&gt;帮助您轻松跟踪应用性能、及早发现问题并维护集群稳定性。&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;结论&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;操作符是 Kubernetes 的强大补充，因为它们使处理有状态和复杂的任务变得更容易，而这对于内置控制器来说似乎很困难。虽然 Operator 使 Kubernetes 内的工作变得更加轻松，但团队仍然需要一种方法来监控并确保他们的应用程序按预期运行。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;通过指标、日志和跟踪的可观察性成为自动化和保证之间的桥梁。通过将强大的监控和警报与操作员集成，团队可以快速检测异常，验证所需状态，并确保自我修复机制实际上按预期工作。最后，Operator 简化了运行应用程序的&lt;em&gt;方式&lt;/em&gt;，但可观察性提供了&lt;em&gt;为什么&lt;/em&gt;和&lt;em&gt;何时&lt;/em&gt;的信心，将 Kubernetes 变成一个真正有弹性的平台。&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div样式=”高度：80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Tue, 14 Oct 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【The tools for overcoming the top 10 DevOps challenges】克服十大 DevOps 挑战的工具</title>
      <link>https://www.cncf.io/blog/2025/10/14/the-tools-for-overcoming-the-top-10-devops-challenges/</link>
      <description>【&lt;p&gt;DevOps is a way of working that reduces waste. It uses smart tools and practices to build, test, and ship software faster. It makes teams quicker, systems stronger and problems smaller when done right. It’s not just one thing – it’s about making the whole machine run better. But this means that DevOps is not just a toolset or process. It’s a way of thinking and a culture born from the need to fix something broken: the wall between developers and operations.&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Companies understand the value DevOps brings to projects – which explains why its market value is growing so fast. In 2020, it was worth about &lt;strong&gt;$4.3 billion&lt;/strong&gt;. A year later, its value rose to &lt;strong&gt;$5.1 billion&lt;/strong&gt;.&lt;a href=&#34;https://www.strongdm.com/blog/devops-statistics#:~:text=DevOps%20Growth%20Statistics,USD%2012%2C215.54%20million%20by%202026.%22%20HYPERLINK%20%22https://www.strongdm.com/blog/devops-statistics#:~:text=DevOps%20Growth%20Statistics,USD%2012%2C215.54%20million%20by%202026.&#34;&gt; If the pace holds, it will hit &lt;strong&gt;$12.2 billion by 2026&lt;/strong&gt;&lt;/a&gt;. That’s almost tripled in six years. Teams understand what DevOps brings to projects .&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;But DevOps lives and dies on communication. Without it, even the best tools fail. With it, teams can spot issues sooner, fix them faster and deliver software that works. Read on to learn how communication drives DevOps and helps teams overcome challenges.&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;The DevOps infinity loop&amp;nbsp;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;DevOps is not a straight line. It moves in a loop – constant, connected, never done. The stages are simple: &lt;strong&gt;Plan. Develop. Test. Release. Deploy. Operate. Monitor. Feedback.&lt;/strong&gt; Then it begins again. Each stage feeds the next, and every one depends on the last. Like gears in a watch, the whole thing stutters if one slips.&amp;nbsp;&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This loop is not just about speed. It’s about rhythm, about teams working as one. If they stop talking – if planning doesn’t match the build, if operations don’t hear from developers – things break. Bugs hide. Releases fail. Customers leave. The loop is only strong when people speak up, listen and fix what needs fixing. Tools help, but communication keeps it turning.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;There are a number of CNCF tools for enhancing the loop:&lt;/strong&gt; &lt;strong&gt;Kubernetes (Graduated)&lt;/strong&gt; for orchestration, &lt;strong&gt;Argo and Flux (Incubating/Graduated)&lt;/strong&gt; for GitOps-driven CI/CD, &lt;strong&gt;Prometheus (Graduated)&lt;/strong&gt; and &lt;strong&gt;OpenTelemetry (Incubating)&lt;/strong&gt; for monitoring and observability, &lt;strong&gt;Jaeger (Graduated)&lt;/strong&gt; for tracing, and &lt;strong&gt;Linkerd (Graduated)&lt;/strong&gt; for secure service mesh communication.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Top challenges in DevOps&amp;nbsp;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Even the best tools can’t fix a broken culture. DevOps is built on people, not just pipelines. It needs teams to move together. But too often, things fall apart. Here are the most common ways the work gets stuck:&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Environment inconsistencies&amp;nbsp;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;When the development, test and production environments don’t match, nothing behaves as expected. Bugs appear in one place but not the other, and time is wasted chasing ghosts. The problem isn’t always the code – it’s where the code runs. &lt;strong&gt;Use CNCF tools like Kubernetes and Helm (Graduated) to standardize environments.&lt;/strong&gt;&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Team silos &amp;amp; skill gaps&amp;nbsp;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Developers and operations folks often speak different languages. One moves fast; the other keeps things steady. Without shared knowledge or cross-training, they pull in opposite directions, slowing progress and building tension. &lt;strong&gt;Adopting GitOps with Argo or Flux aligns both teams to a shared workflow.&lt;/strong&gt;&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Outdated practices&amp;nbsp;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Some teams still use old methods – manual processes, long release cycles and slow approvals. This is like trying to win a race in a rusted car. It stalls innovation and keeps teams from moving at DevOps speed. &lt;strong&gt;CNCF CI/CD tools like Argo Workflows can help modernize releases.&lt;/strong&gt;&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Monitoring blind spots&amp;nbsp;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you don’t see the problem, you can’t fix it. Teams without proper monitoring react too late – or not at all. Downtime drags on, and customers feel it before the team does. &lt;strong&gt;Prometheus, Grafana, OpenTelemetry and Jaeger provide full-stack observability.&lt;/strong&gt;&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;CI/CD performance bottlenecks&amp;nbsp;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Builds fail, tests drag on, deployments choke on pipeline bugs and poorly tuned CI/CD setups turn fast releases into gridlock. The system slows, and so does the team. &lt;strong&gt;Use Argo CD or Flux for cloud-native pipelines that scale.&lt;/strong&gt;&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Automation compatibility issues&amp;nbsp;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Not all tools play nice – one version conflicts with another, updates crash the system and automation breaks the flow instead of saving time. &lt;strong&gt;Crossplane (Incubating) enables consistent multi-cloud automation through Kubernetes-native infrastructure management.&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Security vulnerabilities&amp;nbsp;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;When security is an afterthought, cracks appear. One breach can undo everything. It’s not just a tech risk – it’s a trust risk. &lt;strong&gt;Falco (Incubating) provides runtime threat detection, and cert-manager (Graduated) automates certificate management.&lt;/strong&gt;&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Test infrastructure scalability&amp;nbsp;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As users grow, tests must grow, too. But many teams hit the ceiling. The test setup can’t keep up and bugs sneak through the cracks. &lt;strong&gt;Running tests on Kubernetes and leveraging KubeVirt (Incubating) for VM-based workloads scales test environments.&lt;/strong&gt;&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Unclear debugging reports&amp;nbsp;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Long log. Cryptic errors. No one knows what broke or why. When reports confuse more than they clarify, bugs linger – and tempers rise. &lt;strong&gt;Jaeger and OpenTelemetry improve debugging and trace visibility.&lt;/strong&gt;&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Decision-making bottlenecks&amp;nbsp;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;There is no clear owner, no fast, no, or yes, and teams stall waiting for permission. Work halts and releases lag. In the end, nobody is really in charge. &lt;strong&gt;Prometheus and Grafana dashboards provide clear metrics for faster decisions.&lt;/strong&gt;&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;How to overcome DevOps challenges (and why communication is key)&amp;nbsp;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;No magic tool fixes DevOps. But there is something that works: people talking to each other. Clear goals. Fewer silos. Shared work. Here’s a checklist of what helps and why it matters.&amp;nbsp;&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Create a shared language and shared goals&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Teams can’t build the same thing if they don’t speak the same language. Use common metrics – &lt;strong&gt;MTTR&lt;/strong&gt;, &lt;strong&gt;lead time&lt;/strong&gt;, &lt;strong&gt;error rate – &lt;/strong&gt;to anchor the work. These numbers keep everyone honest. Those goals clash when one team pushes features and the other patches fire. Don’t let teams optimize in isolation. Make them share the finish line.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Build cross-functional pods&amp;nbsp;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Teams work better when they sit together and solve problems side by side. Form &lt;strong&gt;pods&lt;/strong&gt;—stable groups of developers, ops, QA and product team members. It’s hard to stay siloed when you share a stand-up. Proximity builds trust. And trust moves code.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Foster psychological safety&amp;nbsp;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;People make mistakes. That’s how systems improve. But if people are afraid to speak up, problems stay buried. When teams feel safe raising concerns or admitting failure, they recover faster and learn more. Real incident reports don’t hide blame. They show the truth, so the next time is better.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Standardize environments&amp;nbsp;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“It worked on my machine” means nothing if it breaks down in production. Use &lt;strong&gt;infrastructure-as-code&lt;/strong&gt; and cloud tooling to keep dev, test and prod consistent. When the environment is the same everywhere, surprises are fewer. &lt;strong&gt;Kubernetes and Helm (Graduated) simplify this.&lt;/strong&gt;&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Tune CI/CD and testing for performance&amp;nbsp;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;A slow pipeline drags everyone down. Speed it up with tools that test on &lt;strong&gt;real devices&lt;/strong&gt;, measure &lt;strong&gt;browser performance&lt;/strong&gt; and automate the most critical paths. This isn’t about testing more – it’s about testing smart. &lt;strong&gt;Argo CD and Flux improve performance.&lt;/strong&gt;&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Ensure continuous monitoring &amp;amp; security&amp;nbsp;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;You can’t fix what you don’t see. Use tools like &lt;strong&gt;Nagios&lt;/strong&gt; or &lt;strong&gt;Prometheus&lt;/strong&gt; to monitor the system. Bake security into every step – use scanners, audits and static code analysis. Security is not the last step – it’s every step. &lt;strong&gt;Falco and cert-manager ensure security at runtime and in transport.&lt;/strong&gt;&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Improve report readability&amp;nbsp;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Long logs and cluttered dashboards don’t help. Use &lt;strong&gt;clear charts&lt;/strong&gt;, &lt;strong&gt;visual dashboards&lt;/strong&gt; and tools like &lt;strong&gt;BrowserStack Test Insights&lt;/strong&gt; to make results obvious – even to non-tech teams. When everyone can read the data, everyone can act. &lt;strong&gt;Jaeger and Grafana dashboards help here too.&lt;/strong&gt;&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;What a successful DevOps culture looks like&amp;nbsp;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Want to see DevOps done right? Look at Netflix. They had a simple problem: scale fast, don’t break. So, they changed how their teams worked. No more silos. They built cross-functional squads – developers, ops, QA all in one crew. They didn’t just work near each other. They worked together.&amp;nbsp;&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;They talked every day. They ran retrospectives. When something broke, they didn’t hide it – they wrote it down, studied it and ensured it didn’t happen again. They used tools like Slack to talk, Jira to track and GitHub to ship. These tools matter. But the fundamental shift came from trust, feedback and shared purpose.&amp;nbsp;&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Netflix didn’t win by building the perfect pipeline. They won by creating a culture where communication was constant and feedback wasn’t feared. The result? Fewer failures, faster deployments, better uptime – and a team that knew what winning looked like.&amp;nbsp;&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;DevOps doesn’t succeed because of tools. It succeeds because people talk, listen and own the work.&amp;nbsp;&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;That’s what an authentic DevOps culture looks like.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;The bottom line: talk is DevOps’ greatest strength&amp;nbsp;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;DevOps isn’t just built-in code. It’s a built-in routine. The best teams don’t wait for problems – they meet daily to talk. They look back after every sprint. They write down what broke, why and how to ensure it won’t break again.&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;DevOps lives and dies by how well teams talk to each other – not just when something breaks. The best teams don’t just move fast – they move together. They share the same goal, speak the same language and fix things before they fall apart. Pipelines help. Tools help. But when DevOps fails, it fails at the level of &lt;strong&gt;alignment&lt;/strong&gt;, not automation.&amp;nbsp;&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;So, ask yourself:&amp;nbsp;&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Are we talking enough?&lt;/strong&gt;&amp;nbsp;&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Are we listening well?&lt;/strong&gt;&amp;nbsp;&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Do we share the exact definition of success?&lt;/strong&gt;&amp;nbsp;&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you’re not sure, that’s where the work begins. Communication isn’t just nice-to-have – it’s essential. Building an effective DevOps culture takes continuous alignment between people, processes, and platforms. By focusing on communication, collaboration, and shared accountability, teams can ensure their DevOps practices not only function, but thrive.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;DevOps 是一种减少浪费的工作方式。它使用智能工具和实践来更快地构建、测试和交付软件。如果做得正确，它可以使团队更快、系统更强大、问题更小。这不仅仅是一件事——而是让整个机器运行得更好。但这意味着 DevOps 不仅仅是一个工具集或流程。这是一种思维方式和文化，源于修复损坏的东西的需要：开发人员和运营人员之间的墙。   &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;公司了解 DevOps 为项目带来的价值 - 这解释了为什么其市场价值增长如此之快。 2020 年，其价值约为&lt;strong&gt;43 亿美元&lt;/strong&gt;。一年后，其价值升至&lt;strong&gt;51 亿美元&lt;/strong&gt;。&lt;a href=&#34;https://www.strongdm.com/blog/devops-statistics#:~:text=DevOps%20Growth%20Statistics,USD%2012%2C215.54%20million%20by%202026.%22%20HY PERLINK%20%22https://www.strongdm.com/blog/devops-statistics#:~:text=DevOps%20Growth%20Statistics,USD%2012%2C215.54%20million%20by%202026。&#34;&gt; 如果保持这一速度，到 2026 年，这一数字将达到 122 亿美元&lt;/strong&gt;&lt;/a&gt;。六年内几乎增加了两倍。团队了解 DevOps 给项目带来了什么。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;但是 DevOps 的生死存亡取决于沟通。没有它，即使是最好的工具也会失败。有了它，团队可以更快地发现问题、更快地解决问题并交付有效的软件。继续阅读，了解沟通如何推动 DevOps 并帮助团队克服挑战。   &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;DevOps 无限循环&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;DevOps 不是一条直线。它循环移动——持续不断、相互连接、永无止境。这些阶段很简单：&lt;strong&gt;计划。发展。测试。发布。部署。操作。监视器。反馈。&lt;/strong&gt;然后又开始。每个阶段都为下一个阶段提供支持，每个阶段都依赖于最后一个阶段。就像手表中的齿轮一样，如果有一个滑倒，整个装置就会卡顿。  &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这个循环不仅仅与速度有关。这关乎节奏，关乎团队团结一致。如果他们停止说话——如果规划与构建不匹配，如果运营部门没有收到开发人员的消息——事情就会崩溃。虫子隐藏起来。发布失败。顾客离开。只有当人们畅所欲言、倾听并解决需要解决的问题时，这种循环才会牢固。工具有帮助，但沟通可以推动事情的发展。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;有许多 CNCF 工具可用于增强循环：&lt;/strong&gt; 用于编排的 &lt;strong&gt;Kubernetes（已毕业）&lt;/strong&gt;、用于 GitOps 驱动的 CI/CD 的 &lt;strong&gt;Argo 和 Flux（孵化/已毕业）&lt;/strong&gt;、用于监控的 &lt;strong&gt;Prometheus（已毕业）&lt;/strong&gt; 和 &lt;strong&gt;OpenTelemetry（孵化）&lt;/strong&gt; 和可观察性，&lt;strong&gt;Jaeger（已毕业）&lt;/strong&gt; 用于跟踪，&lt;strong&gt;Linkerd（已毕业）&lt;/strong&gt; 用于安全服务网格通信。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;DevOps 中的主要挑战&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;即使是最好的工具也无法修复破碎的文化。 DevOps 是建立在人的基础上的，而不仅仅是管道。它需要团队一起行动。但太频繁了，事情崩溃了。以下是工作陷入困境的最常见原因：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;环境不一致&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;当开发、测试和生产环境不匹配时，一切都不会按预期运行。虫子出现在一个地方，但没有出现在另一个地方，而时间都浪费在追鬼上了。问题并不总是出在代码上——而是出在代码运行的地方。 &lt;strong&gt;使用 Kubernetes 和 Helm（已毕业）等 CNCF 工具来标准化环境。&lt;/strong&gt; &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;团队孤岛和技能差距&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;开发人员和运营人员经常使用不同的语言。一个动作快；一个动作快。另一个使事情保持稳定。如果没有共享知识或交叉培训，他们就会朝相反的方向发展，从而减缓进展并加剧紧张。 &lt;strong&gt;将 GitOps 与 Argo 或 Flux 结合使用可以使两个团队保持共享工作流程。&lt;/strong&gt; &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;过时的做法&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;一些团队仍然使用旧方法——手动流程、发布周期长且审批缓慢。这就像试图驾驶一辆生锈的汽车赢得比赛一样。它阻碍了创新并阻碍团队以 DevOps 的速度前进。 &lt;strong&gt;Argo Workflows 等 CNCF CI/CD 工具可以帮助实现版本现代化。&lt;/strong&gt; &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;监控盲点&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您看不到问题，则无法解决它。没有适当监控的团队反应太晚——或者根本不反应。停机时间很长，客户比团队更早感受到。 &lt;strong&gt;Prometheus、Grafana、OpenTelemetry 和 Jaeger 提供全栈可观察性。&lt;/strong&gt; &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;CI/CD 性能瓶颈&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;构建失败、测试拖延、部署因管道错误而停滞，以及调整不当的 CI/CD 设置将快速发布变成僵局。系统变慢了，团队也变慢了。 &lt;strong&gt;使用 Argo CD 或 Flux 实现可扩展的云原生管道。&lt;/strong&gt; &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;自动化兼容性问题&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;并非所有工具都能很好地发挥作用 - 一个版本与另一个版本冲突，更新使系统崩溃，自动化破坏了流程而不是节省时间。 &lt;strong&gt;Crossplane（孵化）通过 Kubernetes 原生基础设施管理实现一致的多云自动化。 &lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;安全漏洞&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;当安全问题被忽视时，就会出现裂缝。一次突破就可以毁掉一切。这不仅仅是技术风险，更是信任风险。 &lt;strong&gt;Falco（孵化）提供运行时威胁检测，cert-manager（已毕业）自动执行证书管理。&lt;/strong&gt; &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;测试基础架构可扩展性&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;随着用户的增长，测试也必须增长。但很多球队都遇到了天花板。测试设置无法跟上，错误会从裂缝中溜走。 &lt;strong&gt;在 Kubernetes 上运行测试并利用 KubeVirt（孵化）进行基于虚拟机的工作负载可扩展测试环境。&lt;/strong&gt; &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;不清楚的调试报告&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;长日志。隐秘的错误。没有人知道是什么原因造成的。当报告令人困惑的程度多于澄清的程度时，错误就会挥之不去，脾气就会上升。 &lt;strong&gt;Jaeger 和 OpenTelemetry 改进了调试和跟踪可见性。&lt;/strong&gt; &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;决策瓶颈&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;没有明确的所有者，没有快速、否或是，团队拖延等待许可。工作停止，发布滞后。最终，没有人真正负责。 &lt;strong&gt;Prometheus 和 Grafana 仪表板提供了清晰的指标，有助于更快地做出决策。&lt;/strong&gt; &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;如何克服 DevOps 挑战（以及为何沟通至关重要）&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;没有什么神奇的工具可以修复 DevOps。但有一种东西是有效的：人们互相交谈。明确的目标。更少的孤岛。共同工作。以下是一份清单，列出了哪些内容有帮助以及为何重要。  &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;创建共同语言和共同目标&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果团队不使用相同的语言，他们就无法构建相同的东西。使用通用指标 - &lt;strong&gt;MTTR&lt;/strong&gt;、&lt;strong&gt;交付周期&lt;/strong&gt;、&lt;strong&gt;错误率&lt;/strong&gt;来锚定工作。这些数字让每个人都保持诚实。当一个团队推出功能而其他团队发布补丁时，这些目标就会发生冲突。不要让团队孤立地进行优化。让他们共享终点线。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;构建跨职能 Pod&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;当团队坐在一起并肩解决问题时，团队会工作得更好。形成&lt;strong&gt;pods&lt;/strong&gt;——由开发人员、运维人员、QA 和产品团队成员组成的稳定群体。当你分享脱口秀时，很难保持沉默。近距离建立信任。信任会移动代码。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;促进心理安全&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;人都会犯错误。这就是系统改进的方式。但如果人们不敢说出来，问题就会被埋没。当团队感到安全地提出疑虑或承认失败时，他们会更快恢复并了解更多信息。真实的事件报告不会掩盖责任。他们展示了真相，所以下次会更好。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;标准化环境&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果在生产中出现故障，“它可以在我的机器上运行”就毫无意义。使用&lt;strong&gt;基础设施即代码&lt;/strong&gt;和云工具来保持开发、测试和生产的一致性。当各地的环境都一样时，惊喜就会减少。 &lt;strong&gt;Kubernetes 和 Helm（已毕业）简化了这一过程。&lt;/strong&gt; &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;调整 CI/CD 和测试以提高性能&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;缓慢的管道会拖累每个人。使用在&lt;strong&gt;真实设备&lt;/strong&gt;上进行测试、测量&lt;strong&gt;浏览器性能&lt;/strong&gt;以及自动化最关键路径的工具来加快速度。这不是要进行更多测试，而是要进行智能测试。 &lt;strong&gt;Argo CD 和 Flux 提高了性能。&lt;/strong&gt; &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;确保持续监控和安全&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;你无法修复你看不到的东西。使用&lt;strong&gt;Nagios&lt;/strong&gt;或&lt;strong&gt;Prometheus&lt;/strong&gt;等工具来监控系统。将安全融入每一步——使用扫描仪、审计和静态代码分析。安全不是最后一步，而是每一步。 &lt;strong&gt;Falco 和 cert-manager 确保运行时和传输过程中的安全性。&lt;/strong&gt; &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;提高报告可读性&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;长日志和混乱的仪表板没有帮助。使用&lt;strong&gt;清晰的图表&lt;/strong&gt;、&lt;strong&gt;可视化仪表板&lt;/strong&gt;和&lt;strong&gt;BrowserStack Test Insights&lt;/strong&gt;等工具使结果显而易见 - 即使对于非技术团队也是如此。当每个人都可以读取数据时，每个人都可以采取行动。 &lt;strong&gt;Jaeger 和 Grafana 仪表板在这方面也能提供帮助。&lt;/strong&gt; &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;成功的 DevOps 文化是什么样的&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;想要看到 DevOps 正确完成吗？看看Netflix。他们有一个简单的问题：快速扩展，不要崩溃。因此，他们改变了团队的工作方式。不再有孤岛。他们建立了跨职能团队——开发人员、运营人员、质量检查人员都在一个团队中。他们不仅仅是在附近工作。他们一起工作。  &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;他们每天都会说话。他们进行了回顾。当出现问题时，他们不会隐藏它 - 他们把它写下来，研究它并确保它不会再次发生。他们使用 Slack 等工具进行交谈，使用 Jira 进行跟踪，使用 GitHub 进行发布。这些工具很重要。但根本性的转变来自信任、反馈和共同目标。  &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Netflix 并不是通过建立完美的管道而获胜的。他们通过创造一种持续沟通且不畏惧反馈的文化而获胜。结果呢？更少的故障、更快的部署、更好的正常运行时间 - 以及一支知道胜利是什么样子的团队。  &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;DevOps 的成功并不是因为工具。它之所以成功，是因为人们谈论、倾听并拥有自己的作品。  &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这就是真正的 DevOps 文化。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;底线：讨论是 DevOps 的最大优势&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;DevOps 不仅仅是内置代码。这是一个内置的例程。最好的团队不会等到问题出现，他们每天都会开会讨论。他们在每次冲刺后都会回顾。他们写下损坏的原因、原因以及如何确保它不会再次损坏。   &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;DevOps 的生死取决于团队之间的沟通程度，而不仅仅是出现问题时。最好的团队不仅行动迅速，而且还一起行动。他们有着相同的目标，说着相同的语言，并在事情崩溃之前解决问题。管道有帮助。工具有帮助。但是，当 DevOps 失败时，它会在&lt;strong&gt;对齐&lt;/strong&gt;层面失败，而不是在自动化层面失败。  &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;所以，问问自己：  &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;我们说得够多了吗？&lt;/strong&gt;  &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;斯特罗ng&gt;我们听得好吗？&lt;/strong&gt;  &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;我们对成功的确切定义认同吗？&lt;/strong&gt;  &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您不确定，那就从这里开始工作。沟通不仅是可有可无的，而且是必不可少的。构建有效的 DevOps 文化需要人员、流程和平台之间的持续协调。通过关注沟通、协作和共同责任，团队可以确保他们的 DevOps 实践不仅发挥作用，而且蓬勃发展。&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Mon, 13 Oct 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【KubeCon + CloudNativeCon North America 2025 Co-Located Event Deep Dive: Cloud Native + Kubernetes AI Day】KubeCon + CloudNativeCon 北美 2025 同期活动深度探讨：云原生 + Kubernetes AI Day</title>
      <link>https://www.cncf.io/blog/2025/10/13/kubecon-cloudnativecon-north-america-2025-co-located-event-deep-dive-cloud-native-kubernetes-ai-day/</link>
      <description>【&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1600&#34; height=&#34;356&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/image-2-1.jpg&#34; alt=&#34;Graphic for K8s + AI Day at KubeCon NA 2025&#34; class=&#34;wp-image-149003&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2025/10/image-2-1.jpg 1600w, https://www.cncf.io/wp-content/uploads/2025/10/image-2-1-300x67.jpg 300w, https://www.cncf.io/wp-content/uploads/2025/10/image-2-1-1024x228.jpg 1024w, https://www.cncf.io/wp-content/uploads/2025/10/image-2-1-768x171.jpg 768w, https://www.cncf.io/wp-content/uploads/2025/10/image-2-1-900x200.jpg 900w, https://www.cncf.io/wp-content/uploads/2025/10/image-2-1-600x134.jpg 600w, https://www.cncf.io/wp-content/uploads/2025/10/image-2-1-1200x267.jpg 1200w&#34; sizes=&#34;auto, (max-width: 1600px) 100vw, 1600px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Cloud Native &amp;amp; Kubernetes AI Day is welcoming the AI/ML and High Performance Computing (HPC) communities. Since 2022 there have been multiple dedicated events (Batch / HPC and Cloud Native AI days) but given the overlap in requirements, projects and end user interests it became clear we all fit better together.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Cloud Native &amp;amp; Kubernetes AI Day brings together a diverse range of technical enthusiasts, open source contributors, practitioners, researchers and end users. All united in a common goal: enhancing Kubernetes as the ultimate infrastructure management tool for research and AI/ML workloads.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Who will get the most out of attending this event?&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The Cloud Native &amp;amp; Kubernetes AI Day is aimed at seasoned practitioners as well as those new to the batch computing and MLOps worlds. Anyone looking for solutions and best practices to provide cost effective and efficient infrastructure to scale out batch computing, training and inference workloads, make the best use of scarce and expensive hardware accelerators and efficiently manage LLMs and agentic infrastructure. This event will also help practitioners of MLOps interact with maintainers of Cloud Native AI projects and foster collaboration between the two worlds.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;What is new and different this year?&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The theme this year is ‘agent,’ with multiple references and reports on Agentic AI and the cloud native infrastructure supporting it. This event will be a unique opportunity to connect and network with people driving this new generation infrastructure.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;What will the day look like?&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We will have a full day with 10 full sessions and 4 lightning talks and enough time for questions during the sessions and discussion in the break outs. We will be hearing from researchers, project maintainers and many end users reporting on successes and challenges of running AI/ML workloads on top of cloud native infrastructure. While the sessions will be engaging, there will be ample time during coffee breaks and lunch for hallway tracks and networking sessions, helping attendees engage with speakers, maintainers of projects and end users.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Should I do any homework first?&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;No formal prep is required, but consider going through the schedule in advance so you can prepare to ask or raise particular topics of interest to you or your organization. This is a unique opportunity to meet and learn from some of the industry’s best practitioners and a good chance to also raise your particular requirements and help set the path for our community.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;A special note from the program chairs&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;New tools supporting Agentic AI infrastructure:&lt;/strong&gt; The last few months have been unique in the number and quality of tools supporting LLMs and Agentic AI infrastructure. This will be a great opportunity to hear more details about the current status and where the community is heading.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Real-world use cases and success stories:&lt;/strong&gt; In the fast-moving area of AI/ML, listening to end user stories (both challenges and successes) is extremely important to understand what works and for which use cases.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;figure class =“wp-block-image size-full”&gt; &lt;img loading =“lazy”decoding =“async”width =“1600”height =“356”src =“https://www.cncf.io/wp-content/uploads/2025/10/image-2-1.jpg”alt =“K8s + AI日图形” KubeCon NA 2025&#34; class=&#34;wp-image-149003&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2025/10/image-2-1.jpg 1600w, https://www.cncf.io/wp-content/uploads/2025/10/image-2-1-300x67.jpg 300w，https://www.cncf.io/wp-content/uploads/2025/10/image-2-1-1024x228.jpg 1024w， https://www.cncf.io/wp-content/uploads/2025/10/image-2-1-768x171.jpg 768w，https://www.cncf.io/wp-content/uploads/2025/10/image-2-1-900x200.jpg 900w， https://www.cncf.io/wp-content/uploads/2025/10/image-2-1-600x134.jpg 600w，https://www.cncf.io/wp-content/uploads/2025/10/image-2-1-1200x267.jpg 1200w“尺寸=”自动， （最大宽度：1600px）100vw，1600px“referrerpolicy =“no-referrer”&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;云原生和 Kubernetes AI Day 欢迎 AI/ML 和高性能计算 (HPC) 社区。自 2022 年以来，已经举办了多个专门活动（批处理/HPC 和云原生 AI 日），但考虑到需求、项目和最终用户兴趣的重叠，很明显我们都更适合在一起。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;云原生和 Kubernetes AI Day 汇聚了各类技术爱好者、开源贡献者、从业者、研究人员和最终用户。大家团结在一个共同的目标：增强 Kubernetes 作为研究和 AI/ML 工作负载的终极基础设施管理工具。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;谁将从参加本次活动中获益最多？&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;云原生和 Kubernetes AI 日面向经验丰富的从业者以及批处理计算和 MLOps 领域的新手。任何寻求解决方案和最佳实践来提供具有成本效益和高效基础设施的人，以扩展批量计算、训练和推理工作负载，充分利用稀缺且昂贵的硬件加速器，并有效管理法学硕士和代理基础设施。此次活动还将帮助 MLOps 的从业者与云原生 AI 项目的维护者进行互动，并促进两个世界之间的合作。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;今年有什么新的和不同的？&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;今年的主题是“代理”，有关于 Agentic AI 和支持它的云原生基础设施的多个参考和报告。此次活动将是与推动新一代基础设施的人们建立联系和建立联系的独特机会。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;这一天会是什么样子？&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们将有一整天的时间，包括 10 场完整会议和 4 场闪电演讲，并有足够的时间在会议期间提问和在分组讨论中进行讨论。我们将听到研究人员、项目维护人员和许多最终用户报告在云原生基础设施上运行 AI/ML 工作负载的成功和挑战。虽然会议会很吸引人，但茶歇和学习期间会有充足的时间unch 用于走廊轨道和网络会议，帮助与会者与演讲者、项目维护者和最终用户互动。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;我应该先做作业吗？&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;不需要正式准备，但请考虑提前查看时间表，以便您可以准备询问或提出您或您的组织感兴趣的特定主题。这是一个与业界最优秀的从业者见面并向他们学习的独特机会，也是提出您的特殊要求并帮助为我们的社区设定道路的好机会。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;程序主席的特别说明&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;支持 Agentic AI 基础设施的新工具：&lt;/strong&gt;过去几个月，支持 LLM 和 Agentic AI 基础设施的工具的数量和质量都是独一无二的。这将是了解有关当前状态和社区发展方向的更多详细信息的绝佳机会。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;现实世界的用例和成功案例：&lt;/strong&gt;在快速发展的 AI/ML 领域，聆听最终用户的故事（挑战和成功）对于了解哪些方法有效以及哪些用例适用非常重要。&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Sun, 12 Oct 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【KubeCon + CloudNativeCon North America 2025 Co-Located Event Deep Dive: Data on Kubernetes Day】KubeCon + CloudNativeCon 北美 2025 同期活动深度探究：Kubernetes Day 数据</title>
      <link>https://www.cncf.io/blog/2025/10/10/kubecon-cloudnativecon-north-america-2025-co-located-event-deep-dive-data-on-kubernetes-day/</link>
      <description>【&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1734&#34; height=&#34;322&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/image-1.jpg&#34; alt=&#34;DoKC co-located event graphic for KC+CNC NA 2025&#34; class=&#34;wp-image-148687&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2025/10/image-1.jpg 1734w, https://www.cncf.io/wp-content/uploads/2025/10/image-1-300x56.jpg 300w, https://www.cncf.io/wp-content/uploads/2025/10/image-1-1024x190.jpg 1024w, https://www.cncf.io/wp-content/uploads/2025/10/image-1-768x143.jpg 768w, https://www.cncf.io/wp-content/uploads/2025/10/image-1-900x167.jpg 900w, https://www.cncf.io/wp-content/uploads/2025/10/image-1-600x111.jpg 600w, https://www.cncf.io/wp-content/uploads/2025/10/image-1-1200x223.jpg 1200w&#34; sizes=&#34;auto, (max-width: 1734px) 100vw, 1734px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Data on Kubernetes Day (DoK Day) began as a virtual event in 2021 and became an official co-located event for KubeCon + Cloud Native Con in 2023. Since then, it has been a staple at both the European and North American events, so we’re excited to bring it back for our community in Atlanta.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Running stateful workloads like databases, streaming, AI/ML, and analytics on Kubernetes is no longer a fringe practice—it’s becoming the standard for modern infrastructure. Organizations like Etsy, Grab, and Chick-fil-A have demonstrated what’s possible. Our goal for DoK Day is to provide you with the real-world resources, best practices, and use cases you need to confidently run data workloads on Kubernetes and accelerate your journey.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;What is new and different this year?&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This year, we have seen a significant increase in content submissions focusing on AI and LLMs, reflecting the industry trend of Kubernetes becoming the foundation for AI infrastructure. Our schedule will feature several new talks on this topic, from leveraging GPUs to managing AI data pipelines on Kubernetes. We are also proud to have our most diverse group of speakers and submissions to date, representing a wide range of backgrounds and experiences from the community.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;What will the day look like?&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;DoK Day is for practitioners and decision-makers who are pushing Kubernetes beyond stateless applications. Platform engineers, SREs, data engineers, architects, and CTOs who want to understand how to run stateful workloads at scale will find immense value. Whether you’re just starting to explore running DoK or are already operating mission-critical workloads in production, you’ll walk away with practical knowledge and a stronger network of peers facing similar challenges.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Should I do any homework first?&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;No formal prep is required, but we recommend attendees familiarize themselves with the Data on Kubernetes Community (DoKC) resources—such as our white papers, recorded talks, and Slack discussions. If you already run workloads on Kubernetes, bring your questions and challenges; if you’re new, come ready to absorb and connect. The more you engage with the community beforehand, the more you’ll get out of the event.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Find your community!&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The Data on Kubernetes Community is an open and inclusive community. Whether you’re a seasoned expert or just starting, we welcome you to join our Slack channel, attend our monthly virtual meetups, and contribute to our projects. This event is a celebration of the community’s hard work and a chance to connect face-to-face.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;A note from the program chairs&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We’re most excited about the energy of bringing thousands of cloud native practitioners together under one roof. For us, the highlight is seeing how data has become central to Kubernetes conversations—whether through AI/ML use cases, next-gen databases, or streaming workloads. Beyond the talks, we’re looking forward to the serendipitous hallway chats, reconnecting with old friends in the community, and welcoming new faces into the DoK ecosystem.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; Decoding=&#34;async&#34; width=&#34;1734&#34; height=&#34;322&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/image-1.jpg&#34; alt=&#34;DoKC 共置事件图形 KC+CNC NA 2025&#34; class=&#34;wp-image-148687&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2025/10/image-1.jpg 1734w, https://www.cncf.io/wp-content/uploads/2025/10/image-1-300x56.jpg 300w，https://www.cncf.io/wp-content/uploads/2025/10/image-1-1024x190.jpg 1024w， https://www.cncf.io/wp-content/uploads/2025/10/image-1-768x143.jpg 768w，https://www.cncf.io/wp-content/uploads/2025/10/image-1-900x167.jpg 900w， https://www.cncf.io/wp-content/uploads/2025/10/image-1-600x111.jpg 600w，https://www.cncf.io/wp-content/uploads/2025/10/image-1-1200x223.jpg 1200w“尺寸=”自动， （最大宽度：1734px）100vw，1734px“referrerpolicy =“no-referrer”&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes Day (DoK Day) 数据于 2021 年开始作为虚拟活动，并于 2023 年成为 KubeCon + Cloud Native Con 的官方同地活动。从那时起，它一直是欧洲和北美活动的主要活动，因此我们很高兴能将其带回亚特兰大社区。&lt;/​​p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在 Kubernetes 上运行数据库、流媒体、AI/ML 和分析等有状态工作负载不再是一种边缘实践，它正在成为现代基础设施的标准。 Etsy、Grab 和 Chick-fil-A 等组织已经证明了一切皆有可能。我们 DoK Day 的目标是为您提供所需的实际资源、最佳实践和用例，以便您自信地在 Kubernetes 上运行数据工作负载并加速您的旅程。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;今年有什么新的和不同的？&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;今年，我们看到关注 AI 和 LLM 的内容提交大幅增加，反映了 Kubernetes 成为 AI 基础设施基础的行业趋势。我们的日程安排将包括有关该主题的几场新演讲，从利用 GPU 到管理 Kubernetes 上的 AI 数据管道。我们还很自豪拥有迄今为止最多元化的演讲者和意见书，代表了社区的广泛背景和经验。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;这一天会是什么样子？&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;DoK Day 是为推动 Kubernetes 超越无状态应用程序的从业者和决策者举办的。想要了解如何大规模运行有状态工作负载的平台工程师、SRE、数据工程师、架构师和 CTO 将会发现巨大的价值。无论您是刚刚开始探索运行 DoK 还是已经在生产中运行任务关键型工作负载，您都将获得实用知识和面临类似挑战的更强大的同行网络。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;我应该先做作业吗？&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;不需要正式准备，但我们建议与会者熟悉 Kubernetes Comm 上的数据unity (DoKC) 资源——例如我们的白皮书、演讲录音和 Slack 讨论。如果您已经在 Kubernetes 上运行工作负载，请提出您的问题和挑战；如果您是新人，请准备好吸收和联系。您事先与社区互动越多，您从活动中获得的收获就越多。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;找到您的社区！&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes 数据社区是一个开放、包容的社区。无论您是经验丰富的专家还是新手，我们都欢迎您加入我们的 Slack 频道，参加我们每月的虚拟聚会，并为我们的项目做出贡献。这次活动是对社区辛勤工作的庆祝，也是一次面对面交流的机会。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;程序主席的说明&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们对将数千名云原生从业者聚集在一个屋檐下所产生的能量感到非常兴奋。对我们来说，重点是了解数据如何成为 Kubernetes 对话的核心——无论是通过 AI/ML 用例、下一代数据库还是流工作负载。除了会谈之外，我们还期待着偶然的走廊聊天、与社区中的老朋友重新联系，并欢迎新面孔加入 DoK 生态系统。&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Thu, 09 Oct 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【A blueprint for zero-trust AI on Kubernetes】Kubernetes 上的零信任人工智能蓝图</title>
      <link>https://www.cncf.io/blog/2025/10/10/a-blueprint-for-zero-trust-ai-on-kubernetes/</link>
      <description>【&lt;p&gt;LLMs and AI are everywhere these days. Everyone wants to build the next big thing, ship it fast, and maybe even cash out and chill for the rest of their lives. The problem? Most open source AI projects are shared &lt;em&gt;as is&lt;/em&gt;. They’re created with the best intentions, but their developers aren’t losing sleep over things like security guardrails or production hardening, that part is left for you to figure out.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If that sounds like the boat you’re in, you’re in the right place. In this blog, we’ll look at how running AI on Kubernetes introduces some very real networking and security challenges, and what you can do about them before your experiment turns into a liability.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Because here’s the thing: AI systems are complicated, sometimes even the people building them admit they don’t fully know why a model makes the decision it does. But at the end of the day, it’s still just bits moving around computers and network cables, and securing those bits, whether they’re API keys, training data, or model endpoints, is easier than you might think if you know the right patterns.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Are these AI security challenges unique?&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Yes and no. On the one hand, the issues AI workloads face, unrestricted network traffic, exposed endpoints, leaked credentials, are the same classic security problems we’ve been wrestling with in IT for decades. On the other hand, they don’t just move data around, they handle sensitive training datasets, expensive inference workloads, and powerful APIs that can be abused in seconds. A stolen API key doesn’t just mean a small breach; it could mean thousands of dollars in cloud bills or a model that starts spilling the beans for the wrong confidant. A compromised pod doesn’t just leak logs; it could expose proprietary datasets you spent months fine-tuning, erasing your competitive edge overnight.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;So while the problems aren’t entirely new, the stakes are a lot higher. It’s like the difference between leaving your bike unlocked outside a café versus leaving a sports car running with the keys in the ignition. Both are risky, but one is going to attract trouble a lot faster. “Reverse the order if you are living in Amsterdam, or Vancouver its the bike right ;)”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Securing an AI system can feel like taming a “complex beast.” While developers focus on model training and application logic, critical security considerations are often overlooked. This is partly because open source AI projects are typically presented “as is,” or because the pace of change in these frameworks are faster than the speed of light, and that is why we get frameworks with no or limited built-in security guardrails for production environments.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;When deployed in a default Kubernetes cluster, these AI workloads face significant risks:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Uncontrolled Network Traffic: By default, all pods in a Kubernetes cluster can communicate freely with each other. This creates an open environment where a single compromised component can lead to lateral movement and wider system breaches.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Sensitive Data Leakage: AI applications frequently handle sensitive API keys to connect with external services. Without proper handling, these keys can be “transferred between your users and platform” over unencrypted channels, vulnerable to eavesdropping.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Unsecured Network Exposure: Exposing AI endpoints to users or other services without robust ingress security leaves them open to unauthorized access and potential attacks.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;A blueprint for securing AI on Kubernetes&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Securing AI on Kubernetes does not require reinventing the wheel. Instead, it involves applying “well known security best practices” from the cloud-native ecosystem using a purpose-built toolset. Examples in this blog reference common CNI implementations (such as Calico or Cilium) that provide frameworks to address the unique security challenges of AI workloads.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Securing ingress to your endpoints (secure the front door)&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The first step in preventing API key eavesdropping is to lock down the entrypoint to your AI workloads. Many frameworks like Ollama, vLLM, or LiteLLM ship with a plain HTTP server out of the box, which means anyone in the path can snoop on your traffic if you’re not careful. When these frameworks run inside Kubernetes, securing their API endpoints with certificates is your first line of defense.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;br&gt;The good news? Kubernetes makes this easy. Using the `Gateway API` standard, you can create a gateway, attach certificates, and ensure your traffic is encrypted end-to-end. That way, sensitive keys and requests don’t travel in the clear text format.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you’d like to dive deeper into secure gateways, &lt;a href=&#34;https://github.com/frozenprocess/calico-gateway-api-examples&#34;&gt;click here&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Control the traffic (Sorry this cluster is RSVP only)&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Next, think about what happens inside the cluster. By default, all pods can talk to each other, like an open office. One compromised pod, and attackers can roam freely. To fix this you need to use Kubernetes network policies, a standard way to secure namespaced resources within your cluster. But there is a catch, Kubernetes on its own doesn’t enforce these policies it relies on your CNI (policy engine) to enforce them. Keep in mind that each CNI will also come with some “unique sauce” that allows you to go beyond what standard network policy providers.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For example, some CNIs support Global Network Policies that secure both namespaced and non-namespaced resources. By implementing such policies suddenly, your cluster has a VIP list, and lateral movement is blocked.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you’d like to learn more about securing your entire cluster, &lt;a href=&#34;https://github.com/frozenprocess/Tigera-Presentations/tree/master/2023-03-30.container-and-Kubernetes-security-policy-design/04.best-practices-for-securing-a-Kubernetes-environment&#34;&gt;click here&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;&lt;em&gt;Cloud AI providers (watch the other doors)&lt;/em&gt;&lt;/strong&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In some cases it might be “cheaper” to use Cloud providers instead of building your own AI apparatus, in such cases you should make sure that your API keys from these providers are not loosely configured and are actually tied to an identity that is only accessible to you. The easiest form of Identity that you can manage without having your developers to touch the code is IP address restrictions.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1262&#34; height=&#34;568&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-3.21.11-PM.jpg&#34; alt=&#34;Cloud AI providers (watch the other doors)&#34; class=&#34;wp-image-149207&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-3.21.11-PM.jpg 1262w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-3.21.11-PM-300x135.jpg 300w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-3.21.11-PM-1024x461.jpg 1024w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-3.21.11-PM-768x346.jpg 768w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-3.21.11-PM-900x405.jpg 900w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-3.21.11-PM-444x200.jpg 444w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-3.21.11-PM-889x400.jpg 889w&#34; sizes=&#34;auto, (max-width: 1262px) 100vw, 1262px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;&lt;em&gt;Managing outgoing traffic ( Network Address Translation )&lt;/em&gt;&lt;/strong&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;At this point, you might be wondering, with Kubernetes pods having ephemeral IPs, how can you ensure your workloads present a consistent IP to cloud providers?&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The answer comes down to your CNI of choice.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Depending on your CNI, you can configure Network Address Translation (NAT) to ensure workloads maintain stable, predictable IPs. You can even get granular with inclusions and exclusions, specifying exactly which interfaces or pods should use certain IPs. This gives you a reliable identity for external communications, critical for enforcing API key restrictions or ensuring cloud services recognize your workloads correctly.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;&lt;em&gt;Managing outgoing traffic ( Egress Gateways )&lt;/em&gt;&lt;/strong&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Egress gateways are another way to make sure which Identities should be used when communicating to an endpoint. An egress gateway is a configurable Pod, or node workload (depending on the CNCF based solution you have chosen) that gives you a more granular way to control your NATs.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;br&gt;For example, Calico Egress Gateway allows you to run pods that become an immediate gateway for your workloads and can be managed via independent policies and routes. This allows you to achieve&amp;nbsp; routing isolation for pods that need to talk to AI providers and deny or redirect other pods to other gateways.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you’d like to learn more about egress access within kubernetes, click &lt;a href=&#34;https://docs.tigera.io/calico/latest/about/kubernetes-training/about-kubernetes-egress&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Observability (What is actually happening inside the house)&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In the cloud, observability is everything. Traditional logging and perimeter security just don’t cut it anymore, they can’t explain why Kubernetes does what it does. Workloads in a distributed system can be running on different nodes, across clusters, or even in different regions. Without context, you’re basically flying blind, and that’s where traditional logging falls short and that is why the hottest topic in cloud native &lt;a href=&#34;https://www.cncf.io/blog/2025/07/18/a-mid-year-2025-look-at-cncf-linux-foundation-and-the-top-30-open-source-projects/&#34;&gt;right now is OpenTelemetry&lt;/a&gt;, a free, open-source framework/standard that helps capture, logs traces, metrics from distributed systems&amp;nbsp; and present it in a human readable way.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Modern CNI tools include observability features such as flow logs, service graphs, and context-aware visibility that show exactly how traffic flows between workloads, which policies are applied, and why. When combined with Grafana and Prometheus, these insights create a clear view into your Kubernetes cluster—turning “mystery connections” into actionable data and enabling a true zero-trust approach for AI workloads.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you’d like to learn more about observability, click &lt;a href=&#34;https://www.tigera.io/learn/guides/observability/&#34;&gt;here&lt;/a&gt;.&amp;nbsp;&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;The bottom line&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;While at the moment, AI can seem a new frontier, running into it without proper security is both dangerous and expensive. In this blog post we’ve gone through some simple security adjustments that can help you to secure your next bright idea in Kubernetes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;如今，法学硕士和人工智能无处不在。每个人都想打造下一个大产品，快速交付，甚至可能兑现并度过余生。问题？大多数开源人工智能项目都是按原样共享的。它们的创建是出于最好的意图，但它们的开发人员不会因为安全护栏或生产强化等问题而失眠，这部分留给您来解决。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果这听起来像您所在的船，那么您来对地方了。在本博客中，我们将了解在 Kubernetes 上运行 AI 如何引入一些非常现实的网络和安全挑战，以及在您的实验变成负担之前您可以采取哪些措施。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;因为事情是这样的：人工智能系统很复杂，有时甚至构建它们的人也承认他们并不完全知道模型为何做出这样的决定。但归根结底，它仍然只是在计算机和网络电缆周围移动的数据，并且如果您知道正确的模式，那么保护这些数据（无论是 API 密钥、训练数据还是模型端点）比您想象的要容易。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;这些人工智能安全挑战是否独特？&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;是和否。一方面，人工智能工作负载面临的问题、不受限制的网络流量、暴露的端点、泄露的凭证，都是我们几十年来一直在 IT 领域努力解决的经典安全问题。另一方面，它们不仅仅移动数据，还处理敏感的训练数据集、昂贵的推理工作负载以及可能在几秒钟内被滥用的强大 API。 API 密钥被盗并不仅仅意味着轻微的违规行为；这可能意味着数千美元的云账单，或者一个开始向错误的知己泄露秘密的模型。受损的 Pod 不仅会泄露日志，还会泄露日志。它可能会暴露您花费数月时间微调的专有数据集，一夜之间消除您的竞争优势。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;因此，虽然问题并不是全新的，但风险却要高得多。这就像将自行车锁在咖啡馆外与将跑车钥匙插在点火开关上运行之间的区别一样。两者都有风险，但其中一个会更快地招来麻烦。 “如果您住在阿姆斯特丹或温哥华，则相反的顺序是正确的自行车；）”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;保护人工智能系统的安全就像驯服一头“复杂的野兽”。虽然开发人员专注于模型训练和应用程序逻辑，但关键的安全考虑因素往往被忽视。部分原因是开源人工智能项目通常“按原样”呈现，或者因为这些框架的变化速度比光速更快，这就是为什么我们为生产环境提供的框架没有或有限的内置安全护栏。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;当部署在默认 Kubernetes 集群中时，这些 AI 工作负载面临重大风险：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;不受控制的网络流量：默认情况下，Kubernetes 集群中的所有 Pod他们可以自由地相互交流。这创建了一个开放的环境，其中单个受损组件可能导致横向移动和更广泛的系统漏洞。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;敏感数据泄露：AI 应用程序经常处理敏感 API 密钥以与外部服务连接。如果没有适当的处理，这些密钥可以通过未加密的渠道“在您的用户和平台之间传输”，很容易被窃听。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;不安全的网络暴露：在没有强大的入口安全性的情况下，将 AI 端点暴露给用户或其他服务会使它们容易遭受未经授权的访问和潜在的攻击。&lt;​​/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;在 Kubernetes 上保护 AI 的蓝图&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在 Kubernetes 上保护 AI 的安全不需要重新发明轮子。相反，它涉及使用专用工具集应用云原生生态系统中的“众所周知的安全最佳实践”。本博客中的示例引用了常见的 CNI 实现（例如 Calico 或 Cilium），这些实现提供了解决 AI 工作负载的独特安全挑战的框架。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;保护端点的入口安全（保护前门）&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;防止 API 密钥窃听的第一步是锁定 AI 工作负载的入口点。 Ollama、vLLM 或 LiteLLM 等许多框架都附带一个开箱即用的普通 HTTP 服务器，这意味着如果您不小心，路径中的任何人都可以窥探您的流量。当这些框架在 Kubernetes 内运行时，使用证书保护其 API 端点是您的第一道防线。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;br&gt;好消息？ Kubernetes 让这一切变得简单。使用“网关 API”标准，您可以创建网关、附加证书并确保您的流量进行端到端加密。这样，敏感密钥和请求就不会以明文格式传输。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您想深入了解安全网关，&lt;a href=&#34;https://github.com/frozenprocess/calico-gateway-api-examples&#34;&gt;点击此处&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;控制流量（抱歉，此集群仅支持 RSVP）&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;接下来，考虑一下集群内部会发生什么。默认情况下，所有 Pod 都可以相互通信，就像开放式办公室一样。一个被入侵的 Pod，攻击者就可以自由漫游。要解决此问题，您需要使用 Kubernetes 网络策略，这是保护集群内命名空间资源的标准方法。但有一个问题，Kubernetes 本身并不强制执行这些策略，它依赖于 CNI（策略引擎）来强制执行它们。请记住，每个 CNI 还将附带一些“独特的酱汁”，使您能够超越标准网络策略提供商。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;例如，某些 CNI 支持保护命名空间和非命名空间资源的全局网络策略。通过突然实施此类策略，您的集群将拥有 VIP 列表，横向移动将被阻止。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您想了解有关保护整个集群的更多信息，&lt;a href=&#34;https://github.com/frozenprocess/Tigera-Presentations/tree/master/2023-03-30.container-and-Kubernetes-security-policy-design/04.best-practices-for-secure-a-Kubernetes-environment&#34;&gt;点击此处&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;&lt;em&gt;云人工智能提供商（留意其他门）&lt;/em&gt;&lt;/strong&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在某些情况下，使用云提供商而不是构建自己的人工智能设备可能会“更便宜”，在这种情况下，您应该确保来自这些提供商的 API 密钥配置不松散，并且实际上与只有您可以访问的身份绑定。 IP 地址限制是您无需开发人员接触代码即可管理的最简单的身份验证形式。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“1262”高度=“568” src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-3.21.11-PM.jpg&#34; alt=&#34;云人工智能提供商（注意其他门）&#34; class=&#34;wp-image-149207&#34; srcset =“https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-3.21.11-PM.jpg 1262w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-3.21.11-PM-300x135.jpg 300w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-3.21.11-PM-1024x461.jpg 1024w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-3.21.11-PM-768x346.jpg 768w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-3.21.11-PM-900x405.jpg 900w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-3.21.11-PM-444x200.jpg 444w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-3.21.11-PM-889x400.jpg 889w“尺寸=”自动，（最大宽度：1262px）100vw，1262px“ referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;&lt;em&gt;管理传出流量（网络地址转换）&lt;/em&gt;&lt;/strong&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;此时，您可能想知道，由于 Kubernetes Pod 具有临时 IP，如何确保您的工作负载向云提供商提供一致的 IP？&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;答案取决于您选择的 CNI。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;根据您的 CNI，您可以配置网络地址转换 (NAT) 以确保工作负载保持稳定、可预测的 IP。您甚至可以细化包含和排除项，准确指定哪些接口或 Pod 应使用某些 IP。这为您提供了外部通信的可靠身份，对于执行 API 密钥限制或确保云服务正确识别您的工作负载至关重要。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;&lt;em&gt;管理传出流量（出口网关）&lt;/em&gt;&lt;/strong&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;出口网关是确保与端点通信时应使用哪些身份的另一种方法。出口网关是一个可配置的 Pod 或节点工作负载（取决于您选择的基于 CNCF 的解决方案），它为您提供更精细的方式来控制 NAT。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;br&gt;例如，印花布Egress Gateway 允许您运行 Pod，这些 Pod 成为工作负载的直接网关，并且可以通过独立的策略和路由进行管理。这使您可以为需要与 AI 提供商通信的 Pod 实现路由隔离，并拒绝或将其他 Pod 重定向到其他网关。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您想了解有关 kubernetes 中出口访问的更多信息，请点击&lt;a href=&#34;https://docs.tigera.io/calico/latest/about/kubernetes-training/about-kubernetes-egress&#34;&gt;此处&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;可观察性（房子内实际发生的情况）&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在云中，可观察性就是一切。传统的日志记录和外围安全已经不再有效，它们无法解释 Kubernetes 为何这么做。分布式系统中的工作负载可以运行在不同节点、跨集群、甚至不同区域。如果没有上下文，你基本上是盲目的，这就是传统日志记录的不足之处，这就是为什么云原生&lt;a href=&#34;https://www.cncf.io/blog/2025/07/18/a-mid-year-2025-look-at-cncf-linux-foundation-and-the-top-30-open-source-projects/&#34;&gt;现在最热门的话题是 OpenTelemetry&lt;/a&gt;，一个免费的开源框架/标准，有助于捕获、记录来自分布式系统的跟踪和指标，并以人类可读的方式呈现。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;现代 CNI 工具包括可观察性功能，例如流日志、服务图和上下文感知可见性，这些功能可以准确显示流量在工作负载之间的流动方式、应用了哪些策略以及原因。与 Grafana 和 Prometheus 结合使用时，这些见解可以为您的 Kubernetes 集群提供清晰的视图，将“神秘连接”转化为可操作的数据，并为 AI 工作负载提供真正的零信任方法。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您想了解有关可观察性的更多信息，请点击&lt;a href=&#34;https://www.tigera.io/learn/guides/observability/&#34;&gt;此处&lt;/a&gt;。  &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;底线&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;目前，人工智能似乎是一个新领域，但在没有适当安全措施的情况下进入它既危险又昂贵。在这篇博文中，我们完成了一些简单的安全调整，可以帮助您确保 Kubernetes 中的下一个好主意。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Thu, 09 Oct 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Testing asynchronous workflows using OpenTelemetry and Istio】使用 OpenTelemetry 和 Istio 测试异步工作流程</title>
      <link>https://www.cncf.io/blog/2025/10/09/testing-asynchronous-workflows-using-opentelemetry-and-istio/</link>
      <description>【&lt;p&gt;&lt;em&gt;Learn how to test complex asynchronous workflows in cloud native applications using OpenTelemetry for context propagation and Istio for traffic routing. Explore cost-effective approaches to isolate test environments without duplicating infrastructure.&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Introduction&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Asynchronous architectures have become a cornerstone of modern cloud native applications, enabling services to operate independently while maintaining system resilience and scalability. These architectures typically rely on message queues and event-driven communication patterns to decouple services, allowing them to handle varying loads and failures gracefully.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Popular message systems in the cloud native ecosystem include Apache Kafka, RabbitMQ, Redis Streams, Google Cloud Pub/Sub, AWS SQS, and Azure Service Bus. Each offers unique capabilities for different use cases, from high-throughput streaming to reliable message delivery. Regardless of which system you choose, testing end-to-end workflows that span multiple services and asynchronous boundaries presents unique challenges that traditional testing approaches struggle to address effectively.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This article explores how two CNCF projects—OpenTelemetry for distributed tracing and context propagation, and Istio for traffic management—can work together to create cost-effective, scalable testing environments for asynchronous workflows without the overhead of duplicating entire infrastructure stacks.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Challenges in testing asynchronous systems&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Testing asynchronous systems introduces several complex challenges not found in synchronous, request-response architectures:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Environment setup complexity&lt;/strong&gt;: Asynchronous systems require multiple coordinated components—brokers, producers, consumers, and often additional infrastructure like schema registries or monitoring tools. Setting up these components correctly with proper security, replication, and partitioning requires significant expertise and time.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Test isolation&lt;/strong&gt;: Unlike synchronous calls where requests can be easily isolated, asynchronous messages in shared systems can interfere with each other. Ensuring that test data from one scenario doesn’t impact another requires careful coordination.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Resource costs&lt;/strong&gt;: Traditional approaches often require duplicating entire message infrastructure for each test environment, leading to exponential cost growth as teams scale their testing practices.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Timing and ordering&lt;/strong&gt;: Asynchronous systems introduce timing dependencies and message ordering considerations that make tests more complex to design and more prone to flaky behavior.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Environment drift&lt;/strong&gt;: Maintaining multiple isolated environments often leads to configuration drift, where test environments diverge from production, reducing test confidence.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In this context, we define a &lt;em&gt;test tenant&lt;/em&gt; as an isolated testing context that needs to run test scenarios without interfering with other concurrent tests or production traffic.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Three approaches to test environment isolation&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;There are three primary approaches to achieving test isolation in asynchronous systems, each with different trade-offs in terms of cost, complexity, and isolation guarantees:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;1. Infrastructure-level isolation&lt;/strong&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The most straightforward approach is to create completely separate infrastructure for each test tenant. This means deploying independent instances of message brokers, databases, and all supporting services for every test scenario.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;640&#34; height=&#34;220&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/isol1.png&#34; alt=&#34;Infrastructure-level isolation&#34; class=&#34;wp-image-149193&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2025/10/isol1.png 640w, https://www.cncf.io/wp-content/uploads/2025/10/isol1-300x103.png 300w, https://www.cncf.io/wp-content/uploads/2025/10/isol1-582x200.png 582w&#34; sizes=&#34;auto, (max-width: 640px) 100vw, 640px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Advantages:&lt;/strong&gt; Complete isolation between test environments with no risk of cross-tenant interference. Tests can modify any infrastructure configuration without affecting others.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Considerations:&lt;/strong&gt; This approach becomes prohibitively expensive as the number of concurrent tests grows. Managing numerous independent environments creates significant operational overhead. Without automation, environments quickly become stale and drift from production configurations, reducing test reliability.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;2. Resource-level isolation&lt;/strong&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This approach shares core infrastructure (like message brokers) between tenants but creates isolated resources within that infrastructure. For example, using dedicated topics in Kafka, separate queues in RabbitMQ, or isolated namespaces in Redis for each test tenant.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;640&#34; height=&#34;302&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/isol2.png&#34; alt=&#34;Resource-level isolation&#34; class=&#34;wp-image-149194&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2025/10/isol2.png 640w, https://www.cncf.io/wp-content/uploads/2025/10/isol2-300x142.png 300w, https://www.cncf.io/wp-content/uploads/2025/10/isol2-424x200.png 424w&#34; sizes=&#34;auto, (max-width: 640px) 100vw, 640px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Advantages:&lt;/strong&gt; Significant cost savings compared to full duplication while maintaining good isolation. Shared infrastructure components reduce operational complexity.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Considerations:&lt;/strong&gt; Still requires duplicating and reconfiguring all producer and consumer services for each tenant. Complex automation is needed to create and tear down resources dynamically. Configuration management becomes challenging as the number of tenants grows.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;3. Request-level isolation&lt;/strong&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The most cost-effective approach establishes a shared baseline environment with all infrastructure and services running in production-like configurations. Test isolation is achieved through dynamic routing of requests and messages based on tenant context, rather than physical resource separation.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In this model, each test tenant has a unique identifier that gets propagated through all synchronous and asynchronous communication. Services use this identifier to determine whether they should process a given request or message. When testing specific service versions, only those services under test are deployed as separate instances—everything else uses the shared baseline.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;517&#34; height=&#34;421&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/isol3.png&#34; alt=&#34;Request-level isolation&#34; class=&#34;wp-image-149195&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2025/10/isol3.png 517w, https://www.cncf.io/wp-content/uploads/2025/10/isol3-300x244.png 300w, https://www.cncf.io/wp-content/uploads/2025/10/isol3-246x200.png 246w, https://www.cncf.io/wp-content/uploads/2025/10/isol3-491x400.png 491w&#34; sizes=&#34;auto, (max-width: 517px) 100vw, 517px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Advantages:&lt;/strong&gt; Minimal infrastructure duplication leads to dramatic cost savings (often 85%+ reduction). No environment drift since the baseline is continuously updated through existing CI/CD pipelines. Fastest environment creation (seconds vs. minutes/hours). Lowest operational overhead.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Considerations:&lt;/strong&gt; Requires instrumenting services for context propagation and implementing selective message processing. May not be suitable for scenarios requiring infrastructure-level isolation or testing infrastructure changes themselves.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The remainder of this article focuses on implementing this request-level isolation approach using OpenTelemetry and Istio.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Implementing request-level isolation&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Implementing request-level isolation requires two key capabilities: propagating tenant context across service boundaries, and routing traffic based on that context. OpenTelemetry and Istio provide complementary solutions to these challenges.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The architecture works by assigning each test tenant a unique identifier with mappings to specific service versions being tested. This tenant ID gets propagated through both synchronous (HTTP/gRPC) and asynchronous (message queue) communication paths, enabling dynamic routing decisions at every hop.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Central RouteService for tenant mapping&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;A critical component in this architecture is a central RouteService that maintains the authoritative mapping of tenant IDs to specific service versions under test. This service acts as the source of truth that all consumers consult to determine whether they should process a given message.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;When multiple versions of a consumer service are running (baseline and under-test versions), each instance receives all messages from the shared message queue. However, only one consumer should process each message based on the tenant context. The RouteService solves this consumer contention problem by providing a centralized decision point:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Centralized configuration:&lt;/strong&gt; All tenant-to-service mappings are stored in one place, making it easy to create, modify, and delete test scenarios without coordinating across multiple services.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Consumer coordination:&lt;/strong&gt; Multiple consumer instances can safely coexist, with each consulting the RouteService to determine if they should process a message based on the tenant ID and their own service version.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Dynamic updates:&lt;/strong&gt; Test scenarios can be created and destroyed without restarting consumers—they simply get updated routing information from the RouteService.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1288&#34; height=&#34;724&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.01.05-PM.jpg&#34; alt=&#34;Code&#34; class=&#34;wp-image-149196&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.01.05-PM.jpg 1288w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.01.05-PM-300x169.jpg 300w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.01.05-PM-1024x576.jpg 1024w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.01.05-PM-768x432.jpg 768w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.01.05-PM-900x506.jpg 900w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.01.05-PM-356x200.jpg 356w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.01.05-PM-712x400.jpg 712w&#34; sizes=&#34;auto, (max-width: 1288px) 100vw, 1288px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Using OpenTelemetry for context propagation&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://opentelemetry.io/&#34;&gt;OpenTelemetry&lt;/a&gt; provides the foundation for propagating tenant context across service boundaries through its powerful context propagation capabilities. The key mechanisms are:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Baggage for custom context:&lt;/strong&gt; OpenTelemetry’s&lt;a href=&#34;https://opentelemetry.io/docs/concepts/signals/baggage/&#34;&gt; Baggage&lt;/a&gt; feature allows you to attach custom key-value pairs (like tenant IDs) to traces that automatically propagate across service calls. This works for both HTTP/gRPC requests and can be extended to asynchronous messaging systems.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Automatic header propagation:&lt;/strong&gt; OpenTelemetry’s auto-instrumentation libraries for languages like Java, Node.js, Python, and Go automatically handle header propagation for popular frameworks, reducing the implementation burden on development teams.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Message queue integration:&lt;/strong&gt; OpenTelemetry provides specific guidance and libraries for propagating context through message queues. For example, when publishing messages to Kafka, producers automatically inject trace context (including baggage) into message headers. Consumers can then extract this context to make routing decisions.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1292&#34; height=&#34;576&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.03.00-PM.jpg&#34; alt=&#34;Code - adding tenant ID to OTel baggage&#34; class=&#34;wp-image-149197&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.03.00-PM.jpg 1292w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.03.00-PM-300x134.jpg 300w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.03.00-PM-1024x457.jpg 1024w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.03.00-PM-768x342.jpg 768w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.03.00-PM-900x401.jpg 900w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.03.00-PM-449x200.jpg 449w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.03.00-PM-897x400.jpg 897w&#34; sizes=&#34;auto, (max-width: 1292px) 100vw, 1292px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;On the consumer side, services can extract the tenant ID from the propagated context and decide whether to process the message based on their tenant mappings:&lt;br&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1274&#34; height=&#34;502&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.09.36-PM.jpg&#34; alt=&#34;Code - Consumer side&#34; class=&#34;wp-image-149202&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.09.36-PM.jpg 1274w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.09.36-PM-300x118.jpg 300w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.09.36-PM-1024x403.jpg 1024w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.09.36-PM-768x303.jpg 768w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.09.36-PM-900x355.jpg 900w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.09.36-PM-508x200.jpg 508w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.09.36-PM-1015x400.jpg 1015w&#34; sizes=&#34;auto, (max-width: 1274px) 100vw, 1274px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Leveraging Istio for traffic routing&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;While OpenTelemetry handles context propagation,&lt;a href=&#34;https://istio.io/&#34;&gt; Istio&lt;/a&gt; provides sophisticated traffic routing capabilities that complement this by enabling dynamic routing of HTTP/gRPC requests based on headers, including the tenant context propagated by OpenTelemetry.&lt;strong&gt;Virtual services for header-based routing:&lt;/strong&gt; Istio Virtual Services can route requests to different service versions based on header values. This allows you to direct traffic from specific tenants to the service versions under test while sending all other traffic to the baseline services.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1270&#34; height=&#34;1066&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.09.08-PM.jpg&#34; alt=&#34;Code - Istio VirtualService&#34; class=&#34;wp-image-149201&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.09.08-PM.jpg 1270w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.09.08-PM-300x252.jpg 300w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.09.08-PM-1024x860.jpg 1024w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.09.08-PM-768x645.jpg 768w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.09.08-PM-900x755.jpg 900w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.09.08-PM-238x200.jpg 238w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.09.08-PM-477x400.jpg 477w&#34; sizes=&#34;auto, (max-width: 1270px) 100vw, 1270px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Destination rules for service subsets:&lt;/strong&gt; Istio Destination Rules define the different versions of services (baseline vs. under-test) and their load balancing policies:&lt;br&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1270&#34; height=&#34;764&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.11.08-PM.jpg&#34; alt=&#34;Code - Destination Rule&#34; class=&#34;wp-image-149203&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.11.08-PM.jpg 1270w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.11.08-PM-300x180.jpg 300w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.11.08-PM-1024x616.jpg 1024w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.11.08-PM-768x462.jpg 768w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.11.08-PM-900x541.jpg 900w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.11.08-PM-332x200.jpg 332w, https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.11.08-PM-665x400.jpg 665w&#34; sizes=&#34;auto, (max-width: 1270px) 100vw, 1270px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Key benefits of Istio integration:&lt;/strong&gt; Transparent routing without application code changes, sophisticated traffic shaping capabilities (weighted routing, fault injection, timeouts), and comprehensive observability of routing decisions through built-in metrics and tracing integration.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Implementation considerations&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;While this approach offers significant benefits, there are several important considerations for successful implementation:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Non-request-scoped workflows:&lt;/strong&gt; Some asynchronous workflows aren’t triggered by external requests—batch jobs, scheduled tasks, or event-driven processes that start from database changes or time-based triggers. These scenarios require alternative approaches, such as embedding tenant context in data sources or using separate scheduling mechanisms for test scenarios.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Distributed cache management:&lt;/strong&gt; When services cache tenant mappings for performance, cache invalidation becomes critical. Implementing proper cache coherence mechanisms (like Redis pub/sub notifications or short TTL values) ensures that services quickly recognize new tenants or mapping changes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Consumer group lifecycle:&lt;/strong&gt; Message queue consumer groups require careful lifecycle management. Create unique consumer group names for test services, ensure proper offset handling (often starting from the baseline consumer’s current offset), and clean up consumer groups when tests complete to avoid resource leaks.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Data isolation strategies:&lt;/strong&gt; Different levels of data isolation may be needed depending on your use case. Options include tenant-prefixed keys in databases, separate database schemas, or carefully designed test data that doesn’t conflict with baseline data.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Observability and debugging:&lt;/strong&gt; Implement comprehensive logging and metrics around tenant routing decisions. OpenTelemetry’s distributed tracing helps track how tenant context flows through the system and identify where routing decisions are made.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Security considerations:&lt;/strong&gt; Ensure tenant IDs can’t be spoofed or manipulated by unauthorized actors. Consider using signed tokens or validating tenant context against authorized test scenarios to prevent accidental or malicious cross-tenant access.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Conclusion&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Testing asynchronous workflows in cloud native applications presents unique challenges that traditional testing approaches struggle to address cost-effectively. The combination of OpenTelemetry for context propagation and Istio for traffic routing provides a powerful foundation for implementing request-level isolation that dramatically reduces infrastructure costs while maintaining high-quality testing practices.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The vendor-neutral nature of both OpenTelemetry and Istio makes this solution broadly applicable across different cloud providers, message systems, and application architectures. Success with this approach requires careful planning for edge cases, such as batch workflows, and proper lifecycle management of shared resources, but the benefits—reduced costs, faster feedback loops, and elimination of environment drift—make it a compelling choice for teams serious about scaling their testing practices in cloud native environments.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;了解如何使用 OpenTelemetry 进行上下文传播，使用 Istio 进行流量路由，在云原生应用程序中测试复杂的异步工作流程。探索经济高效的方法来隔离测试环境，而无需重复基础设施。&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;简介&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;异步架构已成为现代云原生应用程序的基石，使服务能够独立运行，同时保持系统弹性和可扩展性。这些架构通常依赖消息队列和事件驱动的通信模式来解耦服务，从而使它们能够优雅地处理变化的负载和故障。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;云原生生态系统中流行的消息系统包括 Apache Kafka、RabbitMQ、Redis Streams、Google Cloud Pub/Sub、AWS SQS 和 Azure Service Bus。每个都为不同的用例提供了独特的功能，从高吞吐量流到可靠的消息传递。无论您选择哪种系统，测试跨越多个服务和异步边界的端到端工作流程都会带来传统测试方法难以有效解决的独特挑战。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;本文探讨了两个 CNCF 项目（用于分布式跟踪和上下文传播的 OpenTelemetry 以及用于流量管理的 Istio）如何协同工作，为异步工作流程创建经济高效、可扩展的测试环境，而无需复制整个基础设施堆栈的开销。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;测试异步系统的挑战&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;测试异步系统引入了同步请求响应架构中未发现的几个复杂挑战：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;环境设置复杂性&lt;/strong&gt;：异步系统需要多个协调组件——代理、生产者、消费者，通常还需要额外的基础设施，例如模式注册表或监控工具。通过适当的安全性、复制和分区来正确设置这些组件需要大量的专业知识和时间。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;测试隔离&lt;/strong&gt;：与可以轻松隔离请求的同步调用不同，共享系统中的异步消息可能会相互干扰。确保一种场景的测试数据不会影响另一种场景需要仔细协调。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;资源成本&lt;/strong&gt;：传统方法通常需要为每个测试环境复制整个消息基础架构，导致随着团队扩展测试实践，成本呈指数级增长。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;计时和排序&lt;/strong&gt;：异步系统引入了计时依赖性和消息排序注意事项，使测试设计更加复杂，并且更容易出现不稳定的行为。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;环境漂移&lt;/strong&gt;：维护多个隔离环境通常会导致配置漂移，即测试环境与产品环境不同行动，降低测试信心。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在这种情况下，我们将&lt;em&gt;测试租户&lt;/em&gt;定义为一个独立的测试上下文，需要运行测试场景而不干扰其他并发测试或生产流量。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;测试环境隔离的三种方法&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在异步系统中实现测试隔离有三种主要方法，每种方法在成本、复杂性和隔离保证方面都有不同的权衡：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;1.基础设施级隔离&lt;/strong&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;最直接的方法是为每个测试租户创建完全独立的基础架构。这意味着为每个测试场景部署消息代理、数据库和所有支持服务的独立实例。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34;解码=&#34;async&#34; width=&#34;640&#34; height=&#34;220&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/isol1.png&#34; alt=&#34;基础设施级隔离&#34; class =“wp-image-149193”srcset =“https://www.cncf.io/wp-content/uploads/2025/10/isol1.png 640w，https://www.cncf.io/wp-content/uploads/2025/10/isol1-300x103.png 300w，https://www.cncf.io/wp-content/uploads/2025/10/isol1-582x200.png 582w“尺寸=”自动，（最大宽度：640px）100vw，640px“referrerpolicy=“no-referrer”&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;优点：&lt;/strong&gt;测试环境之间完全隔离，没有跨租户干扰的风险。测试可以修改任何基础设施配置而不影响其他配置。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;注意事项：&lt;/strong&gt;随着并发测试数量的增加，这种方法的成本变得异常昂贵。管理众多独立环境会产生巨大的运营开销。如果没有自动化，环境很快就会变得陈旧并偏离生产配置，从而降低测试可靠性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;2.资源级隔离&lt;/strong&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;此方法在租户之间共享核心基础设施（如消息代理），但在该基础设施内创建隔离的资源。例如，为每个测试租户使用 Kafka 中的专用主题、RabbitMQ 中的单独队列或 Redis 中的隔离命名空间。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34;解码=&#34;async&#34; width=&#34;640&#34; height=&#34;302&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/isol2.png&#34; alt=&#34;资源级隔离&#34; 类=“wp-image-149194”srcset=“https://www.cncf.io/wp-content/uploads/2025/10/isol2.png 640w，https://www.cncf.io/wp-content/uploads/2025/10/isol2-300x142.png 300w，https://www.cncf.io/wp-content/uploads/2025/10/isol2-424x200.png 424w“尺寸=”自动，（最大宽度：640px）100vw，640px“referrerpolicy=“no-referrer”&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;优点：&lt;/strong&gt;与完全复制相比，可显着节省成本，同时保持良好的隔离性。共享基础架构组件降低了运营复杂性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;考虑口粮：仍然需要为每个租户复制和重新配置所有生产者和消费者服务。动态创建和拆除资源需要复杂的自动化。随着租户数量的增长，配置管理变得具有挑战性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;3.请求级隔离&lt;/strong&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;最具成本效益的方法是建立一个共享基线环境，所有基础设施和服务都在类似生产的配置中运行。测试隔离是通过基于租户上下文动态路由请求和消息来实现的，而不是物理资源分离。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在此模型中，每个测试租户都有一个唯一的标识符，该标识符通过所有同步和异步通信进行传播。服务使用此标识符来确定它们是否应该处理给定的请求或消息。测试特定服务版本时，只有那些被测试的服务才会部署为单独的实例，其他所有服务都使用共享基线。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;imgloading=&#34;lazy&#34;decoding=&#34;async&#34;width=&#34;517&#34;height=&#34;421&#34;src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/isol3.png&#34;alt=&#34;请求级隔离&#34; class =“wp-image-149195”srcset =“https://www.cncf.io/wp-content/uploads/2025/10/isol3.png 517w，https://www.cncf.io/wp-content/uploads/2025/10/isol3-300x244.png 300w，https://www.cncf.io/wp-content/uploads/2025/10/isol3-246x200.png 246w，https://www.cncf.io/wp-content/uploads/2025/10/isol3-491x400.png 491w&#34; 尺寸=“自动，（最大宽度：517px）100vw，517px”referrerpolicy=“no-referrer”&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;优点：&lt;/strong&gt;最少的基础设施重复可以显着节省成本（通常减少 85% 以上）。由于基线通过现有 CI/CD 管道不断更新，因此没有环境漂移。最快的环境创建（秒与分钟/小时）。最低的运营开销。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;注意事项：&lt;/strong&gt;需要用于上下文传播和实现选择性消息处理的检测服务。可能不适合需要基础设施级隔离或测试基础设施变更本身的场景。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;本文的其余部分重点介绍使用 OpenTelemetry 和 Istio 实现这种请求级隔离方法。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;实现请求级隔离&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;实现请求级隔离需要两个关键功能：跨服务边界传播租户上下文，以及基于该上下文路由流量。 OpenTelemetry 和 Istio 为这些挑战提供了补充解决方案。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;该架构的工作原理是为每个测试租户分配一个唯一标识符，并映射到正在测试的特定服务版本。此租户 ID 通过同步 (HTTP/gRPC) 和异步（消息队列）通信路径传播，从而在每一跳实现动态路由决策。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;用于租户映射的中央 RouteService&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;此架构中的一个关键组件是中央 RouteService，它维护租户 ID 到正在测试的特定服务版本的权威映射。该服务充当所有消费者参考以确定是否应该处理给定消息的事实来源。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;当消费者服务的多个版本运行时（基准版本和测试版本），每个实例都会接收来自共享消息队列的所有消息。但是，只有一个消费者应该根据租户上下文处理每条消息。 RouteService 通过提供集中决策点解决了消费者争用问题：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;集中配置&lt;/strong&gt;：所有租户到服务的映射都存储在一个位置，从而可以轻松创建、修改和删除测试场景，而无需跨多个服务进行协调。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;消费者协调：&lt;/strong&gt;多个消费者实例可以安全地共存，每个实例都会咨询 RouteService 以确定它们是否应该根据租户 ID 和自己的服务版本处理消息。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;动态更新：&lt;/strong&gt;无需重新启动消费者即可创建和销毁测试场景 - 它们只需从 RouteService 获取更新的路由信息​​即可。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“1288”高度=“724” src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.01.05-PM.jpg&#34; alt=&#34;代码&#34; class=&#34;wp-image-149196&#34; srcset =“https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.01.05-PM.jpg 1288w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.01.05-PM-300x169.jpg 300w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.01.05-PM-1024x576.jpg 1024w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.01.05-PM-768x432.jpg 768w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.01.05-PM-900x506.jpg 900w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.01.05-PM-356x200.jpg 356w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.01.05-PM-712x400.jpg 712w“尺寸=”自动，（最大宽度：1288px）100vw，1288px“ referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;使用 OpenTelemetry 进行上下文传播&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://opentelemetry.io/&#34;&gt;OpenTelemetry&lt;/a&gt; 通过其强大的上下文传播功能，为跨服务边界传播租户上下文提供了基础。关键机制是：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;自定义上下文的 Baggage：&lt;/strong&gt;OpenTelemetry 的&lt;a href=&#34;https://opentelemetry.io/docs/concepts/signals/baggage/&#34;&gt; Baggage&lt;/a&gt; 功能允许您将自定义键值对（例如租户 ID）附加到自动传播 acros 的跟踪的服务电话。这适用于 HTTP/gRPC 请求，并且可以扩展到异步消息系统。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;自动标头传播：&lt;/strong&gt;OpenTelemetry 针对 Java、Node.js、Python 和 Go 等语言的自动检测库可自动处理流行框架的标头传播，从而减轻开发团队的实施负担。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;消息队列集成：&lt;/strong&gt;OpenTelemetry 提供了通过消息队列传播上下文的具体指南和库。例如，当向 Kafka 发布消息时，生产者会自动将跟踪上下文（包括行李）注入到消息标头中。然后，消费者可以提取此上下文来做出路由决策。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“1292”高度=“576” src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.03.00-PM.jpg&#34; alt=&#34;代码 - 将租户 ID 添加到 OTel 行李&#34; class=&#34;wp-image-149197&#34; srcset =“https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.03.00-PM.jpg 1292w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.03.00-PM-300x134.jpg 300w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.03.00-PM-1024x457.jpg 1024w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.03.00-PM-768x342.jpg 768w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.03.00-PM-900x401.jpg 900w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.03.00-PM-449x200.jpg 449w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.03.00-PM-897x400.jpg 897w“尺寸=”自动，（最大宽度：1292px）100vw，1292px“ referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在消费者方面，服务可以从传播的上下文中提取租户 ID，并根据其租户映射决定是否处理消息：&lt;br&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“1274”高度=“502” src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.09.36-PM.jpg&#34; alt=&#34;代码-消费者端&#34; class=&#34;wp-image-149202&#34; srcset =“https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.09.36-PM.jpg 1274w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.09.36-PM-300x118.jpg 300w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.09.36-PM-1024x403.jpg 1024w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.09.36-PM-768x303.jpg 768w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.09.36-PM-900x355.jpg 900w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.09.36-PM-508x200.jpg 508w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.09.36-PM-1015x400.jpg 1015w“尺寸=”自动，（最大宽度：1274px）100vw，1274px“referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;利用 Istio 进行流量路由&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;虽然 OpenTelemetry 处理上下文传播，&lt;a href=&#34;https://istio.io/&#34;&gt;Istio&lt;/a&gt; 提供了复杂的流量路由功能，通过基于标头（包括 OpenTelemetry 传播的租户上下文）启用 HTTP/gRPC 请求的动态路由来补充这一功能。&lt;strong&gt;基于标头路由的虚拟服务：&lt;/strong&gt; Istio 虚拟服务可以根据标头值将请求路由到不同的服务版本。这使您可以将特定租户的流量引导至正在测试的服务版本，同时将所有其他流量发送至基准服务。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“1270”高度=“1066” src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.09.08-PM.jpg&#34; alt=&#34;代码 - Istio VirtualService&#34; class=&#34;wp-image-149201&#34; srcset =“https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.09.08-PM.jpg 1270w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.09.08-PM-300x252.jpg 300w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.09.08-PM-1024x860.jpg 1024w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.09.08-PM-768x645.jpg 768w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.09.08-PM-900x755.jpg 900w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.09.08-PM-238x200.jpg 238w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.09.08-PM-477x400.jpg 477w“尺寸=”自动，（最大宽度：1270px）100vw，1270px“ referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;服务子集的目标规则：&lt;/strong&gt; Istio 目标规则定义不同版本的服务（基准与测试中）及其负载平衡策略：&lt;br&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“1270”高度=“764” src=&#34;https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.11.08-PM.jpg&#34; alt=&#34;代码 - 目标规则&#34; class=&#34;wp-image-149203&#34; srcset =“https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.11.08-PM.jpg 1270w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.11.08-PM-300x180.jpg 300w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.11.08-PM-1024x616.jpg 1024w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.11.08-PM-768x462.jpg 768w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.11.08-PM-900x541.jpg 900w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.11.08-PM-332x200.jpg 332w， https://www.cncf.io/wp-content/uploads/2025/10/Screenshot-2025-10-08-at-1.11.08-PM-665x400.jpg 665w“尺寸=”自动，（最大宽度：1270px）100vw，1270px“referrerpolicy=”无-re费雷尔&#34;&gt;&lt;/图&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Istio 集成的主要优势：&lt;/strong&gt;无需更改应用程序代码即可实现透明路由、复杂的流量整形功能（加权路由、故障注入、超时）以及通过内置指标和跟踪集成实现路由决策的全面可观察性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;实施注意事项&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;虽然这种方法具有显着的优势，但成功实施有几个重要的考虑因素：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;非请求范围的工作流：&lt;/strong&gt;某些异步工作流不是由外部请求触发的 - 批处理作业、计划任务或从数据库更改或基于时间的触发器开始的事件驱动流程。这些场景需要替代方法，例如在数据源中嵌入租户上下文或针对测试场景使用单独的调度机制。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;分布式缓存管理：&lt;/strong&gt;当服务缓存租户映射以提高性能时，缓存失效变得至关重要。实施适当的缓存一致性机制（例如 Redis 发布/订阅通知或短 TTL 值）可确保服务快速识别新租户或映射更改。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;消费者组生命周期：&lt;/strong&gt;消息队列消费者组需要仔细的生命周期管理。为测试服务创建唯一的消费者组名称，确保正确的偏移量处理（通常从基线消费者的当前偏移量开始），并在测试完成时清理消费者组以避免资源泄漏。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;数据隔离策略：&lt;/strong&gt;根据您的使用案例，可能需要不同级别的数据隔离。选项包括数据库中的租户前缀密钥、单独的数据库架构或精心设计的不与基线数据冲突的测试数据。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;可观察性和调试&lt;/strong&gt;：围绕租户路由决策实施全面的日志记录和指标。 OpenTelemetry 的分布式跟踪有助于跟踪租户上下文如何流经系统并确定路由决策的位置。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;安全注意事项&lt;/strong&gt;：确保租户 ID 不会被未经授权的行为者欺骗或操纵。考虑使用签名令牌或根据授权测试场景验证租户上下文，以防止意外或恶意的跨租户访问。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;结论&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在云原生应用程序中测试异步工作流程带来了传统测试方法难以经济有效地解决的独特挑战。用于上下文传播的 OpenTelemetry 和用于流量路由的 Istio 相结合，为实现请求级隔离提供了强大的基础，从而显着降低基础设施成本，同时保持高质量的测试实践。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;OpenTelemetry 和 Istio 的供应商中立性质使得该解决方案具有广泛的适用性跨不同的云提供商、消息系统和应用程序架构。这种方法的成功需要对边缘情况进行仔细规划，例如批处理工作流程和共享资源的适当生命周期管理，但它的好处——降低成本、更快的反馈循环和消除环境漂移——使其成为认真考虑在云原生环境中扩展测试实践的团队的一个令人信服的选择。&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Wed, 08 Oct 2025 16:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>