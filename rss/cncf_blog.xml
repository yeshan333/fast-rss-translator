<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>CNCF - Blog</title>
    <link>http://rsshub.rssforever.com/cncf</link>
    <description>CNCF - Blog - Powered by RSSHub</description>
    <managingEditor>contact@rsshub.app (RSSHub)</managingEditor>
    <item>
      <title>【LitmusChaos audit complete!】LitmusChaos 审核完成！</title>
      <link>https://www.cncf.io/blog/2024/08/28/litmuschaos-audit-complete/</link>
      <description>【&lt;p&gt;&lt;em&gt;Cross-posted from the &lt;a href=&#34;https://ostif.org/litmuschaos-audit-complete/&#34;&gt;OSTIF blog&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;OSTIF&lt;/strong&gt;&amp;nbsp;is proud to share the results of our security audit of&amp;nbsp;&lt;a href=&#34;https://litmuschaos.io/&#34;&gt;&lt;strong&gt;LitmusChaos&lt;/strong&gt;&lt;/a&gt;. LitmusChaos is an open source chaos engineering platform for a multitude of cloud platforms. With the help of&amp;nbsp;&lt;a href=&#34;https://7asecurity.com/&#34;&gt;&lt;strong&gt;7ASecurity&lt;/strong&gt;&lt;/a&gt;&amp;nbsp;and the&lt;a href=&#34;https://www.cncf.io/&#34;&gt;&amp;nbsp;&lt;strong&gt;Cloud Native Computing Foundation&lt;/strong&gt;&lt;/a&gt;, this project can continue to provide secure chaos testing environments for developers.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Audit Process&lt;/strong&gt;:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This engagement was a whitebox security review paired with pentesting performed by the team at 7ASecurity. The scope of the audit was the source code of the project, which was targeted by testing to determine the best future security efforts as well as identify any vulnerabilities or hardening recommendations. Due to the function of LitmusChaos as a testing ground for software development lifecycles (specifically chaos engineering), it is important that the project is consistently being reviewed and tested for potential security threats. The project’s function creates a large attack surface, which makes it difficult to defend. Focus for the threat model was on general system flow, supply chain attacks, and deployment environments to determine the security of LitmusChaos function across multiple cloud platforms.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Audit Results&lt;/strong&gt;:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;16 Findings with a Security Impact&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;6 Vulnerabilities- 1 Critical, 3 High, 2 Medium&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;10 Hardening Recommendations- 2 Medium, 5 Low, 3 Informational&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Custom Threat Model of the data flow in LitmusChaos&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;8 Threats to the project defined, with detailed attack scenarios and fix recommendations&amp;nbsp;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Recommendations for future security hardening in LitmusChaos&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The audit report emphasizes that despite the number and severity of the findings of this audit, LitmusChaos has well-implemented security efforts that reflect well on the function, build, and maintenance of the project. LitmusChaos’s maintainers have provided proof of fixes for all issues related to this audit, which have been verified by 7ASecurity and are available in the audit report.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Third-party security audits don’t just create quantitative results but also result in documentation, insights, and recommendations that help project maintainers plan future security as well as releases and life cycles. OSTIF wishes LitmusChaos the best on its path towards Graduation through the CNCF Incubating Projects Program.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Thank you&lt;/strong&gt;&amp;nbsp;to the individuals and groups that made this engagement possible:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;LitmusChaos maintainers and community- specifically Umasankar Mukkara, Amit Das, Karthik Satchitanand, Prithvi Raj, Saranya Jena, Sarthak Jain, Shovan Maity, Vedant Shrotria, Namkyu Park, Sayan Mondal, Hrishav Kumar, Sahil Kumar, and Udit Gaurav&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;7ASecurity-Abraham Aranguren, Daniel Ortiz, Dariusz Jastrzębski, Miroslav Štampar, and Szymon Grzybowski&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;The Cloud Native Computing Foundation&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;You can read the Audit Report&amp;nbsp;&lt;a href=&#34;https://ostif.org/wp-content/uploads/2024/08/LIT-01-LitmusChaos-Audit-Report-Public-RC1.1-1.pdf&#34;&gt;&lt;strong&gt;HERE&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;You can read 7ASecurity’s Blog&amp;nbsp;&lt;a href=&#34;https://7asecurity.com/blog/2024/08/7asecurity-completes-litmuschaos-audit/&#34;&gt;&lt;strong&gt;HERE&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Everyone around the world depends on open source software. If you’re interested in financially supporting this critical work, contact&amp;nbsp;amir@ostif.org.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;从 &lt;a href=&#34;https://ostif.org/litmuschaos-audit-complete/&#34;&gt;OSTIF 博客&lt;/a&gt;&lt;/em&gt;交叉发布&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;OSTIF&lt;/strong&gt; 很自豪地分享我们对 &lt;a href=&#34;https://litmuschaos.io/&#34;&gt;&lt;strong&gt;LitmusChaos&lt;/strong&gt;&lt;/a&gt; 的安全审核结果。 LitmusChaos 是一个适用于多种云平台的开源混沌工程平台。在&lt;a href=&#34;https://7asecurity.com/&#34;&gt;&lt;strong&gt;7ASecurity&lt;/strong&gt;&lt;/a&gt;和&lt;a href=&#34;https://www.cncf.io/&#34;&gt;的帮助下&lt;strong&gt;云原生计算基金会&lt;/strong&gt;&lt;/a&gt;，该项目可以持续为开发者提供安全的混沌测试环境。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;审核流程&lt;/strong&gt;：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;此次合作是一项白盒安全审查，并由 7ASecurity 团队执行渗透测试。审计的范围是项目的源代码，通过测试确定未来最佳的安全工作以及识别任何漏洞或强化建议。由于 LitmusChaos 作为软件开发生命周期（特别是混沌工程）的测试场，因此持续对项目进行潜在安全威胁的审查和测试非常重要。该项目的功能造成了巨大的攻击面，使其难以防御。威胁模型的重点是一般系统流程、供应链攻击和部署环境，以确定跨多个云平台的 LitmusChaos 功能的安全性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;审核结果&lt;/strong&gt;：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;16 项具有安全影响的调查结果&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;6 个漏洞 - 1 个严重、3 个高、2 个中&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;10 条强化建议 - 2 条中、5 条低、3 条信息&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;LitmusChaos 中数据流的自定义威胁模型&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;定义了项目的 8 个威胁，并提供了详细的攻击场景和修复建议&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;针对 LitmusChaos 未来安全强化的建议&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;审计报告强调，尽管本次审计发现的问题数量众多且严重，但 LitmusChaos 仍实施了良好的安全措施，很好地反映了项目的功能、构建和维护。 LitmusChaos 的维护人员已提供与本次审计相关的所有问题的修复证明，这些证据已经过 7ASecurity 的验证，并可在审计报告中找到。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;第三方安全审核不仅会产生定量结果，还会产生文档、见解和建议，帮助项目维护人员规划未来的安全以及版本和生命周期。 OSTIF 祝愿 LitmusChaos 在通过 CNCF 孵化项目计划毕业的道路上一切顺利。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;感谢&lt;/strong&gt;促成此次参与的个人和团体：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Litmus混沌维护读者和社区 - 特别是 Umasankar Mukkara、Amit Das、Karthik Satchitanand、Prithvi Raj、Saranya Jena、Sarthak Jain、Shovan Maity、Vedant Shrotria、Namkyu Park、Sayan Mondal、Hrishav Kumar、Sahil Kumar 和 Udit Gaurav&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;7ASecurity-Abraham Aranguren、Daniel Ortiz、Dariusz Jastrzębski、Miroslav Štampar 和 Szymon Grzybowski&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;云原生计算基金会&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;您可以阅读审核报告&lt;a href=&#34;https://ostif.org/wp-content/uploads/2024/08/LIT-01-LitmusChaos-Audit-Report-Public-RC1.1-1。 pdf&#34;&gt;&lt;strong&gt;此处&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;您可以阅读 7ASecurity 的博客&lt;a href=&#34;https://7asecurity.com/blog/2024/08/7asecurity-completes-litmuschaos-audit/&#34;&gt;&lt;strong&gt;此处&lt;/strong&gt;&lt;/a&gt;&lt; /p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;世界各地的每个人都依赖开源软件。如果您有兴趣为这项重要工作提供经济支持，请联系 amir@ostif.org。&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Tue, 27 Aug 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Announcing 500 Kubestronauts】宣布 500 名 Kubetronauts</title>
      <link>https://www.cncf.io/blog/2024/08/27/announcing-500-kubestronauts/</link>
      <description>【&lt;p&gt;CNCF is pleased to announce that since launching the Kubestronauts program at KubeCon 2024 in Paris, over 500 &lt;a href=&#34;https://www.cncf.io/training/kubestronaut/&#34;&gt;Kubestronauts&lt;/a&gt; have joined the program. Each of these 500+ have active certifications in&amp;nbsp; all of CNCF’s Kubernetes certifications:&amp;nbsp; &lt;a href=&#34;https://www.cncf.io/training/certification/kcna/&#34;&gt;&lt;strong&gt;KCNA&lt;/strong&gt;&lt;/a&gt;, &lt;a href=&#34;https://www.cncf.io/training/certification/kcsa/&#34;&gt;&lt;strong&gt;KCSA&lt;/strong&gt;&lt;/a&gt;, &lt;a href=&#34;https://www.cncf.io/training/certification/cka/&#34;&gt;&lt;strong&gt;CKA&lt;/strong&gt;&lt;/a&gt;, &lt;a href=&#34;https://www.cncf.io/training/certification/ckad/&#34;&gt;&lt;strong&gt;CKAD&lt;/strong&gt;&lt;/a&gt;, &lt;a href=&#34;https://www.cncf.io/training/certification/cks/&#34;&gt;&lt;strong&gt;CKS&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Why become a Kubestronaut?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Becoming a Kubestronaut is more than a title. Here is what you can expect:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Kubestronaut jacket&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;A Credly badge&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Access to the dedicated / private Kubestronaut Slack channel and mailing list&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Coupons for 50% off five certifications each year – for yourself or to share&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;20% off three CNCF events (KubeCon or KubeDays) a year&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Open Source maintainers understand the value of deep, technical knowledge. While certifications validate your Kubernetes expertise, becoming a Kubestronaut adds another layer of recognition for your hard work. This program not only enhances your professional credibility but also paves the way for career growth A survey of our membership shows that 20% of Kubestronauts reported getting these certifications helped them get a raise and 37% say it helped them get a job.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“Becoming a Kubestronaut ensures that your hard work and expertise is acknowledged and valued, reinforcing the importance of recognition in driving innovation and collaboration in the open source community. In my personal opinion, Kubestronauts are some of the most valuable people you can hire in the industry to help you with your cloud native journey.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;–Chris Aniszczyk, CTO, CNCF&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;What Kubestronauts say about the program:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As most certifications are hands-on, there is no way to pass the exam unless you know what you are doing. It is proof to your employees and the customers you interact with that you know what exactly you are talking about.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.cncf.io/blog/2024/07/16/kubestronaut-in-orbit-eleni-grosdouli/&#34;&gt;Eleni Grosdouli&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;These certifications have opened up new opportunities for my work and enhanced my resume. Being recognized for your expertise through these certifications can be a powerful catalyst for career advancement.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;–&lt;a href=&#34;https://www.cncf.io/blog/2024/07/30/kubestronaut-in-orbit-kolawole-olowoporoku/&#34;&gt;Kolawole Olowoporoku&amp;nbsp;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Learn more about how to become a &lt;a href=&#34;https://www.cncf.io/training/kubestronaut/kubestronaut-faq/&#34;&gt;Kubestronaut&lt;/a&gt;&amp;nbsp; and read about the highlighted &lt;a href=&#34;https://www.cncf.io/lf-author-category/kubestronaut/&#34;&gt;Kubestronauts in Orbit&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Discover more about our Kubestronauts&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubestronauts come from around the world with members in 76 countries and every continent except Antarctica. Seventeen Kubestronauts are the only ones in their entire country! Our top five countries by number of Kubestronauts are:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;India&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;United States&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Germany&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;The Netherlands&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;France&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Here is the percentage of Kubestronauts from all countries:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXdslPc3JyYxqqTt2NBkq_nvEDURUZRwag5QJ-1DlxKqAKy07ypN5R_WorPswFnqKC31c_Xl-5U5c4k8cQBW84vIphEDQMJOAaPU8_Y8sehT5eYG7GAzXLX_5-APvtPNNmCfbi45CQuwgq60dg6WvUaBd_LH?key=1caxdgkLNSBgavAo9_twQA&#34; alt=&#34;Percentage of kubestronauts per country&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubestronauts represent companies of all sizes, from large cloud providers like Google and AWS to service companies like CapGemini, SopraSteria, and Accenture, as well as smaller companies like Fullstaq.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We’d like to thank all the Kubestronauts for being committed members of the CNCF Open Source community.&amp;nbsp; Learn more about becoming a &lt;a href=&#34;https://www.cncf.io/training/kubestronaut/kubestronaut-faq/&#34;&gt;Kubestronaut&lt;/a&gt; and explore stories in our &lt;a href=&#34;https://www.cncf.io/lf-author-category/kubestronaut/&#34;&gt;Kubestronauts in Orbit&lt;/a&gt; series.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;CNCF 很高兴地宣布，自从在巴黎 KubeCon 2024 上启动 Kubestronauts 计划以来，已有超过 500 名 &lt;a href=&#34;https://www.cncf.io/training/kubestronaut/&#34;&gt;Kubestronauts&lt;/a&gt; 加入程序。这 500 多个人均拥有 CNCF 的所有 Kubernetes 认证中的有效认证：&lt;a href=&#34;https://www.cncf.io/training/certification/kcna/&#34;&gt;&lt;strong&gt;KCNA&lt;/strong&gt;&lt;/a&gt; 、&lt;a href=&#34;https://www.cncf.io/training/certification/kcsa/&#34;&gt;&lt;strong&gt;KCSA&lt;/strong&gt;&lt;/a&gt;、&lt;a href=&#34;https://www.cncf. io/training/certification/cka/&#34;&gt;&lt;strong&gt;CKA&lt;/strong&gt;&lt;/a&gt;、&lt;a href=&#34;https://www.cncf.io/training/certification/ckad/&#34;&gt;&lt;strong&gt;CKAD &lt;/strong&gt;&lt;/a&gt;，&lt;a href=&#34;https://www.cncf.io/training/certification/cks/&#34;&gt;&lt;strong&gt;CKS&lt;/strong&gt;&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;为什么要成为 Kubetronaut？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;成为 Kubetronaut 不仅仅是一个头衔。以下是您可以期待的：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Kubestronaut 夹克&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Credly 徽章&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;访问专用/私人 Kubetronaut Slack 频道和邮件列表&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;每年获得五项认证可享受 50% 折扣的优惠券 - 供自己使用或与他人分享&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;每年三场 CNCF 活动（KubeCon 或 KubeDays）可享受 20% 折扣&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;开源维护者了解深厚的技术知识的价值。虽然认证可以验证您的 Kubernetes 专业知识，但成为 Kubetronaut 可以为您的辛勤工作增添另一层认可。该计划不仅可以提高您的职业信誉，还可以为职业发展铺平道路。对我们会员的调查显示，20% 的 Kubestronaut 表示获得这些认证帮助他们获得加薪，37% 的人表示这帮助他们找到工作。&lt;/p &gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“成为 Kubetronaut 可确保您的辛勤工作和专业知识得到认可和重视，从而强化认可在推动开源社区创新和协作方面的重要性。在我个人看来，Kubestronauts 是业内最有价值的人才，可以帮助您完成云原生之旅。”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;-Chris Aniszczyk，CNCF 首席技术官&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Kubestronauts 对该计划的评价：&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;由于大多数认证都是实践性的，因此除非您知道自己在做什么，否则无法通过考试。这向您的员工和与您互动的客户证明您确切地知道自己在说什么。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.cncf.io/blog/2024/07/16/kubestronaut-in-orbit-eleni-grosdouli/&#34;&gt;埃莱妮·格罗斯杜利&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这些认证为我的工作开辟了新的机会并丰富了我的简历。通过这些认证您的专业知识得到认可可以成为职业发展的强大催化剂。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;–&lt;a href=&#34;https://www.cncf.io/blog/2024/07/30/kubetronaut-in-orbit-kolawole-olowoporoku/&#34;&gt;Kolawole Olowoporoku &lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;详细了解如何成为 &lt;a href=&#34;https://www.cncf.io/training/kubestronaut/kubestronaut-faq/&#34;&gt;Kubestronaut&lt;/a&gt; 并了解突出显示的&lt;a href=&#34;https://www.cncf.io/lf-author-category/kubestronaut/&#34;&gt;轨道上的 Kubestronauts&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;了解有关我们 Kubestronauts 的更多信息&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubestronauts 来自世界各地，成员遍布 76 个国家和除南极洲以外的各大洲。整个国家仅有十七名 Kubesteronauts！我们的 Kubetronaut 数量排名前五的国家是：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;印度&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;美国&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;德国&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;荷兰&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;法国&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;以下是来自所有国家/地区的 Kubetronaut 的百分比：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXdslPc3JyYxqqTt2NBkq_nvEDURUZRwag5QJ-1DlxKqAKy07ypN5R_WorPswFnqKC31c_Xl-5U5c4k8cQBW84 vIphEDQMJOAaPU8_Y8sehT5eYG7GAzXLX_5-APvtPNNmCfbi45CQuwgq60dg6WvUaBd_LH?key=1caxdgkLNSBgavAo9_twQA&#34; alt= “每个国家/地区 kubestronaut 的百分比”referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubestronauts 代表各种规模的公司，从 Google 和 AWS 等大型云提供商到 CapGemini、SopraSteria 和 Accenture 等服务公司，以及 Fullstaq 等小型公司。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们要感谢所有 Kubetronauts 成为 CNCF 开源社区的忠实成员。  了解有关成为 &lt;a href=&#34;https://www.cncf.io/training/kubestronaut/kubestronaut-faq/&#34;&gt;Kubestronaut&lt;/a&gt; 的更多信息，并在我们的 &lt;a href=&#34;https://www 中探索故事.cncf.io/lf-author-category/kubetronaut/&#34;&gt;Kubestronauts in Orbit&lt;/a&gt; 系列。&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Mon, 26 Aug 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Announcing Envoy Proxy 1.31.0 and Envoy Gateway 1.1】宣布推出 Envoy 代理 1.31.0 和 Envoy 网关 1.1</title>
      <link>https://www.cncf.io/blog/2024/08/27/announcing-envoy-proxy-1-31-0-and-envoy-gateway-1-1/</link>
      <description>【&lt;p&gt;&lt;em&gt;Project post by Jimmy Song, Erica Hughberg, Alyssa Wilk, Guy Daich&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Introduction&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We are thrilled to announce the new releases of the Envoy project, Envoy Proxy 1.31.0 and the Envoy Gateway 1.1.0, now supporting version 1.1 of the Kubernetes Gateway API.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The Envoy Gateway 1.1 control plane enables you to leverage even more of the power of Envoy Proxy 1.31 as a Kubernetes Gateway. This first release of Envoy Gateway post GA continues to make it easier for you to configure, run, and use Envoy Proxy at scale.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The diverse and engaged Envoy community keeps solving shared traffic management challenges with common solutions, enabling us all to do even more in our cloud native environments. Showcasing the real industry power and impact of multi-company open source solutions.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Envoy Proxy&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;These updates bring a host of new features, improvements, and optimizations to enhance your cloud native infrastructure.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Dozens of new features, from improved health checks, to enhanced mirroring and retries, to extended access logs&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Improved error reporting for HTTP/3 and DNS resolution errors.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;New HTTP/3 “happy eyeballs” feature for improved connectivity upstream.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Proxy Protocol now supports typed metadata by default&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Extended support for Redis commands in Bloom 1.0.0&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Significant improvements to HTTP/2 security&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For more information, please visit the&lt;a href=&#34;https://github.com/envoyproxy/envoy/releases/tag/v1.31.0&#34;&gt; Envoy Proxy 1.31.0 release summary&lt;/a&gt; and full &lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/v1.31.0/version_history/v1.31/v1.31.0&#34;&gt;release notes&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Envoy Gateway&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Envoy Gateway 1.1 simplifies the management and deployment of Envoy, making it more accessible and easier to use as a Kubernetes ingress gateway.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Here are the highlights:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Leverage Gateway API 1.1: &lt;/strong&gt;The Envoy Gateway community strives to align with the evolution of the Gateway API, making sure fast turnaround on implementing change&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Get more control over traffic handling with new configuration flexibility:&lt;/strong&gt; Define and order filters, apply backend and client traffic handling policies, and reuse backend traffic handling policies across gateway routes.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Enhance Security with Gradual mTLS Rollout:&lt;/strong&gt; Gradually roll out mTLS for client-to-gateway TLS, ensuring a smooth transition without outages.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Reduce Time to Resolution with Improved Observability:&lt;/strong&gt; Grafana dashboard integration, Zipkin Support, and Route Metadata for traffic reports provide enhanced observability for better monitoring and quicker issue resolution.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Customize Traffic Handling with Your Own Code:&lt;/strong&gt; Extend Envoy programmability with external processes using EnvoyExtensionPolicy, allowing you to use WebAssembly (Wasm) extensions, and ExtProc support for calling an external process.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Integrate with your Service Mesh more easily: &lt;/strong&gt;Enhanced service mesh integration by enabling routing to Service Cluster IP targets.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For more details, check out the&lt;a href=&#34;https://gateway.envoyproxy.io/&#34;&gt; Envoy Gateway documentation&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Conclusion&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Stay tuned as we dive into the exciting new capabilities and how they can benefit your projects. Whether you are optimizing performance, enhancing security, gaining deeper insights, or pushing the boundaries of programmability, EG 1.1 provides the tools and features you need. Adopt or upgrade to EG 1.1 today and experience the future of Kubernetes ingress management.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;Jimmy Song、Erica Hughberg、Alyssa Wilk、Guy Daich 的项目帖子&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;简介&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们很高兴地宣布 Envoy 项目的新版本 Envoy Proxy 1.31.0 和 Envoy Gateway 1.1.0，现在支持 Kubernetes Gateway API 1.1 版。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Envoy Gateway 1.1 控制平面使您能够充分利用 Envoy Proxy 1.31 作为 Kubernetes 网关的强大功能。 Envoy Gateway GA 后的第一个版本继续让您更轻松地大规模配置、运行和使用 Envoy 代理。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;多元化且积极参与的 Envoy 社区不断通过通用解决方案解决共享流量管理挑战，使我们所有人能够在云原生环境中做更多事情。展示多公司开源解决方案的真正行业力量和影响。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;特使代理&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这些更新带来了大量新功能、改进和优化，以增强您的云原生基础架构。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;数十项新功能，从改进的运行状况检查到增强的镜像和重试，再到扩展的访问日志&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;改进了 HTTP/3 和 DNS 解析错误的错误报告。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;新的 HTTP/3“快乐眼球”功能可改善上游连接。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;代理协议现在默认支持类型化元数据&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;在 Bloom 1.0.0 中扩展了对 Redis 命令的支持&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;HTTP/2 安全性显着改进&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;有关更多信息，请访问&lt;a href=&#34;https://github.com/envoyproxy/envoy/releases/tag/v1.31.0&#34;&gt;Envoy Proxy 1.31.0 发布摘要&lt;/a&gt;和完整&lt; a href=&#34;https://www.envoyproxy.io/docs/envoy/v1.31.0/version_history/v1.31/v1.31.0&#34;&gt;发行说明&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;特使网关&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Envoy Gateway 1.1 简化了 Envoy 的管理和部署，使其更易于访问且更易于用作 Kubernetes 入口网关。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;以下是要点：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;&lt;strong&gt;利用 Gateway API 1.1：&lt;/strong&gt;Envoy Gateway 社区致力于与 Gateway API 的发展保持一致，确保快速周转实施变更&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;通过新的配置灵活性获得对流量处理的更多控制：&lt;/strong&gt;定义和排序过滤器、应用后端和客户端流量处理策略，以及跨网关路由重复使用后端流量处理策略。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;通过逐步推出 mTLS 增强安全性&lt;/strong&gt;：逐步推出客户端到网关 TLS 的 mTLS，确保平稳过渡而不会出现中断。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;通过改进的可观察性缩短解决问题的时间&lt;/strong&gt;：Grafana 仪表板集成、Zipkin 支持和流量报告的路线元数据提供了增强的可观察性，以便更好地监控和更快地解决问题。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;根据您的需求自定义流量处理自己的代码：&lt;/strong&gt;使用 EnvoyExtensionPolicy 通过外部进程扩展 Envoy 可编程性，允许您使用 WebAssembly (Wasm) 扩展，并支持 ExtProc 来调用外部进程。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;更轻松地与服务网格集成：&lt;/strong&gt;通过启用到服务集群 IP 目标的路由来增强服务网格集成。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;有关更多详细信息，请查看&lt;a href=&#34;https://gateway.envoyproxy.io/&#34;&gt;Envoy 网关文档&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;结论&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;请继续关注我们深入探讨令人兴奋的新功能以及它们如何使您的项目受益。无论您是要优化性能、增强安全性、获得更深入的见解，还是突破可编程性的界限，EG 1.1 都能提供您所需的工具和功能。立即采用或升级到 EG 1.1，体验 Kubernetes 入口管理的未来。&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Mon, 26 Aug 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Kubestronaut in Orbit: Fangel Colón】轨道上的立方体宇航员：科隆监狱</title>
      <link>https://www.cncf.io/blog/2024/08/27/kubestronaut-in-orbit-fangel-colon/</link>
      <description>【&lt;h2 class=&#34;wp-block-heading&#34;&gt;Get to know Fangel&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1800&#34; height=&#34;945&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/08/Kubestronaut-in-Orbit-8.jpg&#34; alt=&#34;fangel colon image&#34; class=&#34;wp-image-116566&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/08/Kubestronaut-in-Orbit-8.jpg 1800w, https://www.cncf.io/wp-content/uploads/2024/08/Kubestronaut-in-Orbit-8-300x158.jpg 300w, https://www.cncf.io/wp-content/uploads/2024/08/Kubestronaut-in-Orbit-8-1024x538.jpg 1024w, https://www.cncf.io/wp-content/uploads/2024/08/Kubestronaut-in-Orbit-8-768x403.jpg 768w, https://www.cncf.io/wp-content/uploads/2024/08/Kubestronaut-in-Orbit-8-194x102.jpg 194w, https://www.cncf.io/wp-content/uploads/2024/08/Kubestronaut-in-Orbit-8-388x204.jpg 388w, https://www.cncf.io/wp-content/uploads/2024/08/Kubestronaut-in-Orbit-8-776x408.jpg 776w, https://www.cncf.io/wp-content/uploads/2024/08/Kubestronaut-in-Orbit-8-1552x816.jpg 1552w, https://www.cncf.io/wp-content/uploads/2024/08/Kubestronaut-in-Orbit-8-900x473.jpg 900w, https://www.cncf.io/wp-content/uploads/2024/08/Kubestronaut-in-Orbit-8-381x200.jpg 381w, https://www.cncf.io/wp-content/uploads/2024/08/Kubestronaut-in-Orbit-8-762x400.jpg 762w, https://www.cncf.io/wp-content/uploads/2024/08/Kubestronaut-in-Orbit-8-590x310.jpg 590w, https://www.cncf.io/wp-content/uploads/2024/08/Kubestronaut-in-Orbit-8-1180x620.jpg 1180w&#34; sizes=&#34;(max-width: 1800px) 100vw, 1800px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This week’s Kubestronaut in Orbit, Fangel Emilio Colón Navarro, lives in the Dominican Republic and is an SRE at Banco BHD. He’s been working with CNCF technologies since 2020.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you’d like to be a Kubestronaut like Fangel,&amp;nbsp; get more details on the&lt;a href=&#34;https://www.cncf.io/training/kubestronaut/&#34;&gt; CNCF Kubestronaut &lt;/a&gt;page.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;When did you get started with Kubernetes–what was your first project?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;I started working with Kubernetes in 2020 on a project that required deploying ArgoCD. To be honest, I didn’t understand much of what I was doing, but this gave me enough encouragement to start a career studying Kubernetes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;What are the primary CNCF projects you work on or use today? What projects have you enjoyed the most in your career?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The CNCF projects I am currently working on are &lt;a href=&#34;https://github.com/Kubernetes&#34;&gt;Kubernetes&lt;/a&gt;,&amp;nbsp; &lt;a href=&#34;https://github.com/istio&#34;&gt;Istio&lt;/a&gt;,&amp;nbsp; &lt;a href=&#34;https://github.com/kedacore/keda&#34;&gt;Keda&lt;/a&gt;, &lt;a href=&#34;https://github.com/prometheus&#34;&gt;Prometheus&lt;/a&gt;, and &lt;a href=&#34;https://github.com/argoproj/argo-cd&#34;&gt;ArgoCD&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes is the main one since that’s where we run our applications, and we use Istio as a service mesh to manage clusters with a larger volume of workloads. I love Keda for the variety of available metrics available to allow it to adjust to our environments and ArgoCD at the moment as Continuous Deployments between the different clusters that I have.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;How have the certs helped you in your career?&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;These certifications have significantly propelled my career to the next level. It is the first time I feel I have the opportunity to specialize in something specific. Leveling up my professional skills helps me face any challenge at work effectively.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In my current role, I have gotten real value from the &lt;a href=&#34;https://www.cncf.io/training/certification/cks/&#34;&gt;CKS certification&lt;/a&gt; for supporting and making proposals for the management of vulnerabilities in Kubernetes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;&amp;nbsp;How has CNCF helped you or influenced your career?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;I would say that CNCF has been a significant influence on my career. Before, I was unaware of the professional work behind all the CNCF projects and the dedicated individuals who contribute to them. The learning opportunities they provide have been invaluable. I’m truly happy to have discovered CNCF.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;What are some other books/sites/courses you recommend for people who want to work with k8s?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Books:&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;“Kubernetes Security and Observability”&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;“Kubernetes Best Practices”&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Websites:&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Kubernetes official documentation&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Courses:&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Kubernetes-related courses on KodeKloud&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Linux Foundation courses&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Kubernetes Mastery on Udemy&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;What do you do in your free time?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;I usually exercise, and spend time with my family.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;What would you tell someone who is just starting their K8s certification journey? Any tips or tricks?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The key is to practice those concepts that you read or see in educational materials. It is very important to practice what you have learned, since it is the best way to retain it and easily put it into action.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;I was not lucky enough to have someone guide me on my path, but based on my experience I would say to educate yourself on Linux, Networking, and Containers. This is a solid foundation to start with and I am sure that the rest should be easier.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Today the Cloud native ecosystem is way more than Kubernetes. Do you plan to get other cloud native certifications from the CNCF?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Yes, next up for me is:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cncf.io/training/certification/#ica&#34;&gt;Istio Certified Associate (ICA)&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cncf.io/training/certification/cca/&#34;&gt;Cilium Certified Associate (CCA)&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cncf.io/training/certification/#capa&#34;&gt;Certified Argo Project Associate (CAPA)&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cncf.io/training/certification/#CGOA&#34;&gt;GitOps Certified Associate (CGOA)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;How did you get involved with cloud native and Kubernetes in general?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;I became involved through developing plans and ideas that use cloud native technologies. Additionally, I share my knowledge with colleagues who are interested in getting started with these technologies.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;h2 class=&#34;wp-block-heading&#34;&gt;了解 Fangel&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“1800”高度=“945”src=“https://www.cncf.io/ wp-content/uploads/2024/08/Kubestronaut-in-Orbit-8.jpg&#34; alt=&#34;fangel 冒号图像&#34; class=&#34;wp-image-116566&#34; srcset=&#34;https://www.cncf.io/wp -content/uploads/2024/08/Kubestronaut-in-Orbit-8.jpg 1800w，https://www.cncf.io/wp-content/uploads/2024/08/Kubestronaut-in-Orbit-8-300x158。 jpg 300w，https://www.cncf.io/wp-content/uploads/2024/08/Kubestronaut-in-Orbit-8-1024x538.jpg 1024w，https://www.cncf.io/wp-content/ uploads/2024/08/Kubestronaut-in-Orbit-8-768x403.jpg 768w，https://www.cncf.io/wp-content/uploads/2024/08/Kubestronaut-in-Orbit-8-194x102.jpg 194w，https://www.cncf.io/wp-content/uploads/2024/08/Kubestronaut-in-Orbit-8-388x204.jpg 388w，https://www.cncf.io/wp-content/uploads /2024/08/Kubestronaut-in-Orbit-8-776x408.jpg 776w，https://www.cncf.io/wp-content/uploads/2024/08/Kubestronaut-in-Orbit-8-1552x816.jpg 1552w ，https://www.cncf.io/wp-content/uploads/2024/08/Kubestronaut-in-Orbit-8-900x473.jpg 900w，https://www.cncf.io/wp-content/uploads/ 2024/08/Kubestronaut-in-Orbit-8-381x200.jpg 381w，https://www.cncf.io/wp-content/uploads/2024/08/Kubestronaut-in-Orbit-8-762x400.jpg 762w， https://www.cncf.io/wp-content/uploads/2024/08/Kubestronaut-in-Orbit-8-590x310.jpg 590w，https://www.cncf.io/wp-content/uploads/2024 /08/Kubestronaut-in-Orbit-8-1180x620.jpg 1180w&#34; 尺寸=&#34;(最大宽度: 1800px) 100vw, 1800px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;本周的 Orbit Kubetronaut 是 Fangel Emilio Colón Navarro，他住在多米尼加共和国，是 Banco BHD 的 SRE。自 2020 年以来，他一直致力于 CNCF 技术工作。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您想成为像 Fangel 这样的 Kubestronaut，请在&lt;a href=&#34;https://www.cncf.io/training/kubestronaut/&#34;&gt;CNCF Kubestronaut&lt;/a&gt;页面获取更多详细信息。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;您什么时候开始使用 Kubernetes - 您的第一个项目是什么？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我于 2020 年开始在一个需要部署 ArgoCD 的项目上使用 Kubernetes。说实话，我对自己所做的事情不太了解，但这给了我足够的鼓励，让我开始学习 Kubernetes 的职业生涯。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;您现在从事或使用的主要 CNCF 项目是什么？在您的职业生涯中，您最喜欢哪些项目？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我目前正在从事的 CNCF 项目是 &lt;a href=&#34;https://github.com/Kubernetes&#34;&gt;Kubernetes&lt;/a&gt;、&lt;a href=&#34;https://github.com/istio&#34;&gt; Istio&lt;/a&gt;、&lt;a href=&#34;https://github.com/kedacore/keda&#34;&gt;Keda&lt;/a&gt;、&lt;a href=&#34;https://github.com/prometheus&#34;&gt;普罗米修斯&lt;/a &gt; 和 &lt;a href=&#34;https://github.com/argoproj/argo-cd&#34;&gt;ArgoCD&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes 是主要的，因为我们在其中运行应用程序，并且我们使用 Istio 作为服务网格来管理具有大量工作负载的集群。我喜欢 Keda，因为它有多种可用指标，可以使其适应我们的环境，并且rgoCD 目前作为我拥有的不同集群之间的持续部署。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;这些证书对您的职业生涯有何帮助？ &lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这些认证极大地将我的职业生涯推向了一个新的水平。这是我第一次觉得自己有机会专注于某件事。提升我的专业技能有助于我有效应对工作中的任何挑战。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在我目前的职位上，我从&lt;a href=&#34;https://www.cncf.io/training/certification/cks/&#34;&gt;CKS 认证&lt;/a&gt;中获得了真正的价值，可以支持并提出建议Kubernetes 中的漏洞管理。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;CNCF 如何帮助您或影响您的职业生涯？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我想说 CNCF 对我的职业生涯产生了重大影响。之前，我并不知道所有 CNCF 项目背后的专业工作以及为这些项目做出贡献的敬业个人。他们提供的学习机会是无价的。我真的很高兴发现 CNCF。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;您为想要使用 k8s 的人推荐了哪些其他书籍/网站/课程？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;书籍：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;“Kubernetes 安全性和可观察性”&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;“Kubernetes 最佳实践”&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;网站：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Kubernetes 官方文档&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;课程：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;KodeKloud 上的 Kubernetes 相关课程&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Linux 基础课程&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;掌握 Udemy 上的 Kubernetes&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;你空闲时间做什么？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我通常锻炼身体，并与家人共度时光。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;您会对刚刚开始 K8s 认证之旅的人说些什么？有什么提示或技巧吗？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;关键是练习您在教育材料中读到或看到的那些概念。练习所学内容非常重要，因为这是保留所学内容并轻松付诸实践的最佳方式。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我没有足够幸运有人在我的道路上指导我，但根据我的经验，我会说要在 Linux、网络和容器方​​面进行自我教育。这是一个坚实的基础，我相信其余的应该会更容易。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;如今，云原生生态系统的意义远不止 Kubernetes。您是否计划获得 CNCF 的其他云原生认证？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;是的，我的下一步是：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cncf.io/training/certification/#ica&#34;&gt;Istio 认证工程师 (ICA)&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cncf.io/training/certification/cca/&#34;&gt;Cilium 认证助理 (CCA)&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cncf.io/training/certification/#capa&#34;&gt;Argo 项目认证助理 (CAPA)&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cncf.io/training/certification/#CGOA&#34;&gt;GitOps 认证助理e（CGOA）&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;您是如何涉足云原生和 Kubernetes 的？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我是通过开发使用云原生技术的计划和想法而参与其中的。此外，我还与有兴趣开始使用这些技术的同事分享我的知识。&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Mon, 26 Aug 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【My journey as a Kubernetes release team shadow: insights and experiences】我作为 Kubernetes 发布团队影子的旅程：见解和经验</title>
      <link>https://www.cncf.io/blog/2024/08/27/my-journey-as-a-kubernetes-release-team-shadow-insights-and-experiences/</link>
      <description>【&lt;p&gt;&lt;em&gt;Community post originally published on &lt;a href=&#34;https://medium.com/@maryam.tavakoli.3/630be70effb0&#34;&gt;Medium&lt;/a&gt; by Maryam Tavakkoli&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://miro.medium.com/v2/resize:fit:1400/1*gRWCRUVqRIuATJHeaiVhqA.png&#34; alt=&#34;Release chart&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Kubernetes Release Team Structure&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;b05f&#34;&gt;Kubernetes has become the de facto standard for container orchestration in the cloud-native ecosystem, powering some of the most critical infrastructures worldwide. The Kubernetes release process, which ensures the stability and improvement of the platform, is central to its continued success and evolution. This process is managed by a dedicated and diverse team of contributors from various organizations across the globe. I had the unique opportunity to serve as a shadow on the Kubernetes Release Team, contributing to the release of Kubernetes versions v1.29, v1.30, and v1.31. In this article, I’ll share my experiences across these release cycles, detailing the responsibilities I took on, the challenges I faced, and the invaluable lessons I learned as part of the broader Kubernetes community.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;151d&#34;&gt;The Release Team and SIG Release&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;c09c&#34;&gt;The Kubernetes Release Team operates as part of the Special Interest Group (SIG) Release.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;4009&#34;&gt;&lt;strong&gt;But what exactly is a SIG?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;d3d6&#34;&gt;A Special Interest Group (SIG) in the Kubernetes community is a group of contributors who collaborate on specific aspects of the project, ranging from networking to storage to releases. Each SIG is responsible for the ongoing development and maintenance of its focus area, ensuring that Kubernetes continues to evolve and improve.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;a449&#34;&gt;According to the&amp;nbsp;&lt;a href=&#34;https://github.com/kubernetes/sig-release/tree/master/release-team&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;SIG Release GitHub&lt;/a&gt;:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p id=&#34;ce93&#34;&gt;The Kubernetes Release Team is embedded within SIG Release and is responsible for the day-to-day work required to successfully deliver each release. Meanwhile, the broader SIG focuses on the continuous improvement of the release process itself.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;f1b6&#34;&gt;Release Team Structure&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;4487&#34;&gt;The Kubernetes Release Team is organized into five sub-teams:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Enhancements&lt;/strong&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;CI Signal &amp;amp; Bug Triage&lt;/strong&gt;&amp;nbsp;(These two sub-teams were merged starting with v1.30)&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Docs&lt;/strong&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Release Notes&lt;/strong&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Communications&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;28c7&#34;&gt;Each sub-team has a specific focus area, which is crucial to the overall release process. Handbooks detailing the responsibilities of both the leads and shadows are available for each sub-team. You can find these handbooks&amp;nbsp;&lt;a href=&#34;https://www.notion.so/LINK&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;7ec0&#34;&gt;&lt;strong&gt;But who is a shadow?!&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;1600&#34;&gt;The Role of Shadows in the Release Process&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;8974&#34;&gt;The shadow program is designed to mentor new contributors, providing them with hands-on experience while ensuring the continuity of the release process. Shadows work closely with their respective leads, gradually taking on more responsibilities as they gain confidence and expertise. This program is vital for cultivating future leaders within the Kubernetes community, ensuring that the release process remains sustainable and inclusive.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;f722&#34;&gt;My Experience as a Kubernetes Release Team Shadow&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;7afa&#34;&gt;I first learned about the Kubernetes release team through a kind friend in the community who shared their positive experience with the program. This is one of the best aspects of being part of such a supportive community — people are always willing to introduce you to new opportunities and help you take your first steps.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;4e6c&#34;&gt;Encouraged by this, I applied to join the v1.29 release team and was accepted as a Bug Triage Shadow.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;2b18&#34;&gt;Bug Triage Shadow for v1.29&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;af7b&#34;&gt;According to the&amp;nbsp;&lt;a href=&#34;https://github.com/kubernetes/sig-release/tree/master/release-team&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;SIG Release GitHub&lt;/a&gt;:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p id=&#34;6971&#34;&gt;The bug triage team is responsible to make sure that Issues and Pull Requests (PRs) which are targeted for the ongoing release cycle are dealt with in a timely fashion.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;c7ba&#34;&gt;Serving as a Bug Triage Shadow for v1.29 was my first experience on the release team, and it highlighted the significance of the community’s role. It was eye-opening to see how the release of the world’s second-largest open-source project is driven by the voluntary collaboration of many dedicated individuals.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;19dd&#34;&gt;Given the relatively light workload for this sub-team, it was decided to merge the Bug Triage team with the CI Signal team since the v1.30 release.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;3c8e&#34;&gt;CI Signal Shadow for v1.30&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;734e&#34;&gt;Being one of the CI Signal Shadows for v1.30 was my most challenging role. CI Signal is one of the most time-intensive roles on the release team, and I gained valuable experience during that cycle.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;7b0d&#34;&gt;According to the&amp;nbsp;&lt;a href=&#34;https://github.com/kubernetes/sig-release/blob/master/release-team/role-handbooks/ci-signal/README.md&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;handbook&lt;/a&gt;, the CI Signal team’s responsibilities include:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p id=&#34;a18b&#34;&gt;Continuously monitoring various e2e tests in SIG-release dashboards throughout the release cycle.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;05e2&#34;&gt;Providing early and ongoing signals on release and test health to both the Release Team and various SIGs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;3509&#34;&gt;Ensuring that all release-blocking tests deliver a clear Go/No-Go signal for the release.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;bb1f&#34;&gt;Following the merge of the Bug Triage sub-team into CI Signal, the responsibilities of Bug Triage were also included in this role.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;df83&#34;&gt;Docs Shadow for v1.31&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;32c4&#34;&gt;My experience as a Docs Shadow for v1.31 was generally smooth. The main challenge was ensuring timely communication with developers, and encouraging them to update the documentation alongside their features. This coordination is crucial so that both the feature and its corresponding documentation are ready for release.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;5ac3&#34;&gt;According to the&amp;nbsp;&lt;a href=&#34;https://github.com/kubernetes/sig-release/blob/master/release-team/role-handbooks/docs/README.md&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;handbook&lt;/a&gt;, the responsibilities of a Docs Shadow include:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p id=&#34;2747&#34;&gt;Identifying new Kubernetes features and enhancements (&lt;a href=&#34;https://www.kubernetes.dev/resources/keps/&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;Kubernetes Enhancement Proposals, also referred to as KEPs&lt;/a&gt;) that require new documentation and tracking them using the Enhancements Tracking sheet created for the release.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;f225&#34;&gt;Creating a dev branch used by contributors to target documentation updates for the upcoming release&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 class=&#34;wp-block-heading&#34; id=&#34;74fd&#34;&gt;Key Takeaways and Lessons Learned&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;07b6&#34;&gt;Being part of the Kubernetes Release Team has been a rewarding experience, providing both technical and personal growth. I gained hands-on experience across various areas of Kubernetes and deepened my appreciation for community involvement and collaboration in driving open-source projects forward.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;a78c&#34;&gt;For anyone interested in contributing to the CNCF community, I highly recommend participating as a shadow in the release team. It’s a challenging yet incredibly fulfilling way to give back to the community and advance your professional development.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p id=&#34;9a7f&#34;&gt;&lt;strong&gt;&lt;em&gt;If you’re ready to get involved, now is your chance to join the release team for the upcoming v1.32 release. Fill out the application form&amp;nbsp;&lt;/em&gt;&lt;/strong&gt;&lt;a href=&#34;https://docs.google.com/forms/d/e/1FAIpQLSdb60FW9aYIepSdXIWexQIKNJ8m3JSqHZ6kkH3Q_I7XP9OVYA/viewform&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;&lt;strong&gt;&lt;em&gt;here&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;&lt;em&gt;.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;04d6&#34;&gt;You can download the PDF version of the release team structure with clickable links&amp;nbsp;&lt;a href=&#34;https://drive.google.com/file/d/1JtZQ14CUZtkYOshx8oCcz4KtSycD_icc/view?usp=sharing&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;HERE&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://miro.medium.com/v2/resize:fit:1400/0*wN6cPkyBhJPpPMMh.png&#34; alt=&#34;image&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Find all my links&amp;nbsp;&lt;a href=&#34;https://linktr.ee/maryamtavakkoli&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;&lt;strong&gt;here&lt;/strong&gt;&lt;/a&gt;.&lt;a href=&#34;https://medium.com/@maryam.tavakoli.3?source=post_page-----630be70effb0--------------------------------&#34;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;ff7c&#34;&gt;&lt;em&gt;I would love to hear your thoughts and feedback on this article.&lt;br&gt;&lt;/em&gt;&lt;strong&gt;&lt;em&gt;Let’s continue learning, sharing, and evolving together!&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;&lt;br&gt;Until next time!&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;社区帖子最初由 Maryam Tavakkoli 在 &lt;a href=&#34;https://medium.com/@maryam.tavakoli.3/630be70effb0&#34;&gt;Medium&lt;/a&gt; 上发布&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://miro.medium.com/v2/resize:fit:1400/1*gRWCRUVqRIuATJHeaiVhqA.png&#34; alt=&#34;发布图表&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Kubernetes 发布团队结构&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;b05f&#34;&gt;Kubernetes 已成为云原生生态系统中容器编排的事实上的标准，为全球一些最关键的基础设施提供支持。 Kubernetes 发布流程确保了平台的稳定性和改进，是其持续成功和发展的核心。该流程由来自全球各个组织的敬业且多元化的贡献者团队管理。我有一个独特的机会作为 Kubernetes 发布团队的影子，为 Kubernetes 版本 v1.29、v1.30 和 v1.31 的发布做出了贡献。在本文中，我将分享我在这些发布周期中的经验，详细介绍我所承担的责任、所面临的挑战以及我作为更广泛的 Kubernetes 社区的一部分所学到的宝贵经验教训。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;151d&#34;&gt;发布团队和 SIG 发布&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;c09c&#34;&gt;Kubernetes 发布团队作为特别兴趣组 (SIG) 发布的一部分运作。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;4009&#34;&gt;&lt;strong&gt;但是 SIG 到底是什么？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;d3d6&#34;&gt;Kubernetes 社区中的特殊兴趣小组 (SIG) 是一群在项目特定方面（从网络到存储再到发布）进行协作的贡献者。每个 SIG 负责其重点领域的持续开发和维护，确保 Kubernetes 不断发展和改进。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;a449&#34;&gt;根据 &lt;a href=&#34;https://github.com/kubernetes/sig-release/tree/master/release-team&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt; SIG 发布 GitHub&lt;/a&gt;：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p id=&#34;ce93&#34;&gt;Kubernetes 发布团队嵌入在 SIG Release 中，负责成功交付每个版本所需的日常工作。同时，更广泛的 SIG 专注于发布流程本身的持续改进。&lt;/p&gt;&#xA;&lt;/块引用&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;f1b6&#34;&gt;发布团队结构&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;4487&#34;&gt;Kubernetes 发布团队分为五个子团队：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;增强&lt;/strong&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;CI 信号和错误分类&lt;/strong&gt;（这两个子团队从 v1.30 开始合并）&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;文档&lt;/strong&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;发行说明&lt;/strong&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;通讯&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;28c7&#34;&gt;每个子团队都有一个特定的重点领域，这对于整个发布流程至关重要。手册ks 详细说明了每个子团队的领导和影子的职责。您可以&lt;a href=&#34;https://www.notion.so/LINK&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;此处&lt;/a&gt;找到这些手册。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;7ec0&#34;&gt;&lt;strong&gt;但是谁是影子？！&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;1600&#34;&gt;影子在发布过程中的作用&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;8974&#34;&gt;影子计划旨在指导新贡献者，为他们提供实践经验，同时确保发布过程的连续性。影子与各自的领导密切合作，随着他们获得信心和专业知识，逐渐承担更多责任。该计划对于培养 Kubernetes 社区未来的领导者、确保发布过程保持可持续和包容性至关重要。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;f722&#34;&gt;我作为 Kubernetes 发布团队影子的经历&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;7afa&#34;&gt;我第一次了解 Kubernetes 发布团队是通过社区中的一位好朋友，他分享了他们对该项目的积极体验。这是成为这样一个支持性社区的一部分的最好的方面之一 - 人们总是愿意向您介绍新的机会并帮助您迈出第一步。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;4e6c&#34;&gt;受此鼓舞，我申请加入 v1.29 发布团队，并被接受为 Bug Triage Shadow。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;2b18&#34;&gt;v1.29 的错误分类阴影&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;af7b&#34;&gt;根据 &lt;a href=&#34;https://github.com/kubernetes/sig-release/tree/master/release-team&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt; SIG 发布 GitHub&lt;/a&gt;：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p id=&#34;6971&#34;&gt;错误分类团队负责确保及时处理针对当前发布周期的问题和拉取请求 (PR)。&lt;/p&gt;&#xA;&lt;/块引用&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;c7ba&#34;&gt;担任 v1.29 的 Bug Triage Shadow 是我在发布团队的第一次经历，它凸显了社区角色的重要性。看到世界第二大开源项目的发布是如何由许多奉献者的自愿合作推动的，真是令人大开眼界。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;19dd&#34;&gt;考虑到该子团队的工作量相对较轻，自 v1.30 版本起，决定将 Bug Triage 团队与 CI Signal 团队合并。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;3c8e&#34;&gt;CI 信号影子 v1.30&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;734e&#34;&gt;成为 v1.30 的 CI Signal Shadows 之一是我最具挑战性的角色。 CI Signal 是发布团队中最耗时的角色之一，我在这个周期中获得了宝贵的经验。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;7b0d&#34;&gt;根据 &lt;a href=&#34;https://github.com/kubernetes/sig-release/blob/master/release-team/role-handbooks/ci-signal/README.md&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;手册&lt;/a&gt;，CI Signal 团队的职责其中包括：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p id=&#34;a18b&#34;&gt;在整个发布周期中持续监控 SIG 发布仪表板中的各种 e2e 测试。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;05e2&#34;&gt;向发布团队和各个 SIG 提供有关发布和测试运行状况的早期和持续信号。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;3509&#34;&gt;确保所有发布阻止测试为发布提供明确的“通过/不通过”信号。&lt;/p&gt;&#xA;&lt;/块引用&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;bb1f&#34;&gt;随着 Bug Triage 子团队合并到 CI Signal 中，Bug Triage 的职责也纳入了该角色。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;df83&#34;&gt;Docs Shadow v1.31&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;32c4&#34;&gt;我作为 v1.31 Docs Shadow 的体验总体来说很顺利。主要挑战是确保与开发人员及时沟通，并鼓励他们更新文档及其功能。这种协调至关重要，这样该功能及其相应的文档才能准备好发布。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;5ac3&#34;&gt;根据 &lt;a href=&#34;https://github.com/kubernetes/sig-release/blob/master/release-team/role-handbooks/docs/README.md&#34; rel= &#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;手册&lt;/a&gt;，Docs Shadow的职责包括：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p id=&#34;2747&#34;&gt;确定新的 Kubernetes 功能和增强功能 (&lt;a href=&#34;https://www.kubernetes.dev/resources/keps/&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;Kubernetes 增强提案，也称为 KEP&lt;/a&gt;），需要新文档并使用为该版本创建的增强跟踪表来跟踪它们。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;f225&#34;&gt;创建供贡献者使用的开发分支，以针对即将发布的版本进行文档更新&lt;/p&gt;&#xA;&lt;/块引用&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 class=&#34;wp-block-heading&#34; id=&#34;74fd&#34;&gt;主要要点和经验教训&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;07b6&#34;&gt;成为 Kubernetes 发布团队的一员是一次有益的经历，可以实现技术和个人的成长。我在 Kubernetes 的各个领域获得了实践经验，并加深了对推动开源项目向前发展的社区参与和协作的赞赏。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;a78c&#34;&gt;对于任何有兴趣为 CNCF 社区做出贡献的人，我强烈建议您以影子身份参与发布团队。这是回馈社区和促进职业发展的一种具有挑战性但令人难以置信的充实方式。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p id=&#34;9a7f&#34;&gt;&lt;strong&gt;&lt;em&gt;如果您准备好参与，现在就有机会加入即将发布的 v1.32 版本的发布团队。填写申请表&lt;a href=&#34;https://docs.google.com/forms/d/e/1FAIpQLSdb60FW9aYIepSdXIWexQIKNJ8m3JSqHZ6kkH3Q_I7XP9OVYA/viewform&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;&lt;strong&gt;&lt;em&gt;这里&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;&lt;em&gt;。&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;/块引用&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;04d6&#34;&gt;您可以通过可点击的链接下载 PDF 版本的发布团队结构&lt;a href=&#34;https://drive.google.com/file/d/1JtZQ14CUZtkYOshx8oCcz4KtSycD_icc/view?usp=sharing&#34; rel =&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;此处&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://miro.medium.com/v2/resize:fit:1400/0*wN6cPkyBhJPpPMMh.png&#34; alt=&#34;image “referrerpolicy =“no-referrer”&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在&lt;a href=&#34;https://linktr.ee/maryamtavakkoli&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;&lt;strong&gt;此处&lt;/strong&gt;&lt;/a&gt;查找我的所有链接。&lt;a href =&#34;https://medium.com/@maryam.tavakoli.3?source=post_page-----630be70effb0------------------------ --------&#34;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;ff7c&#34;&gt;&lt;em&gt;我很想听听您对本文的想法和反馈。&lt;br&gt;&lt;/em&gt;&lt;strong&gt;&lt;em&gt;让我们继续学习、分享和共同发展！&lt;/em &gt;&lt;/strong&gt;&lt;em&gt;&lt;br&gt;下次再见！&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Mon, 26 Aug 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【How to create a Kubernetes cluster in a Local Zone through Managed Rancher Service】如何通过 Managed Rancher Service 在本地区域创建 Kubernetes 集群</title>
      <link>https://www.cncf.io/blog/2024/08/27/how-to-create-a-kubernetes-cluster-in-a-local-zone-through-managed-rancher-service/</link>
      <description>【&lt;p&gt;&lt;em&gt;Member post originally published on &lt;a href=&#34;https://blog.ovhcloud.com/how-to-create-a-kubernetes-cluster-in-a-local-zone-through-managed-rancher-service/&#34;&gt;OVH Cloud’s blog&lt;/a&gt; by Aurélie Vache &lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Container orchestration has become a cornerstone of modern application deployment, offering scalability, flexibility, and resource efficiency. It has become common to have to manage several Kubernetes clusters, but to do so efficiently it is useful to be well equipped.&lt;br&gt;&lt;br&gt;In this blog post we will see how to create a Kubernetes cluster in an OVHcloud Local Zone through Managed Rancher Service.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Managed Rancher Services (MRS)&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://blog.ovhcloud.com/wp-content/uploads/2024/07/image-18.png&#34; alt=&#34;Image&#34; class=&#34;wp-image-27146&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Managed Rancher Services (MRS), in Beta for now, is based on Rancher, an open-source container management platform, that simplifies the deployment and management of Kubernetes clusters. Managed Rancher Service by OVHcloud provides a powerful platform for orchestrating Kubernetes clusters seamlessly.&lt;br&gt;&lt;br&gt;Find more information on our&amp;nbsp;dedicated&lt;a href=&#34;https://www.ovhcloud.com/fr/public-cloud/managed-rancher-service/&#34;&gt;&amp;nbsp;Managed Rancher Services page&lt;/a&gt;.&lt;br&gt;&lt;br&gt;&lt;strong&gt;Note: The product is in Beta so you can&lt;a href=&#34;https://www.ovh.com/auth/?onsuccess=https%3A%2F%2Fwww.ovh.com%2Fmanager%2F%23%2Fpublic-cloud%3Fcontext%3Dwebsite&amp;amp;ovhSubsidiary=GB&amp;amp;_gl=1*rqcgpi*_gcl_au*ODk0Njk3ODc2LjE3MjA3NzExMTE.&#34;&gt;&amp;nbsp;try Managed Rancher Services for free&lt;/a&gt;!&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Local Zones (LZ)&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image aligncenter is-resized&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://blog.ovhcloud.com/wp-content/uploads/2024/07/image-19-1024x683.png&#34; alt=&#34;Image&#34; class=&#34;wp-image-27147&#34; style=&#34;width:486px;height:auto&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This year we also launched Local Zones. Local Zones are an extension of&amp;nbsp;&lt;a href=&#34;https://www.ovhcloud.com/en-gb/public-cloud/regions-availability/&#34;&gt;regions&lt;/a&gt;&amp;nbsp;that bring OVHcloud services closer to specific locations, offering reduced latency and improved performances for applications.&lt;br&gt;Local Zones are strategically placed in proximity to areas with high user demand. Their main goal is to minimize the time it takes to transfer data between the user and the cloud, in order to make services faster and more responsive, and meet data residency requirements.&lt;br&gt;&lt;br&gt;Find more information on our&amp;nbsp;dedicated&lt;a href=&#34;https://www.ovhcloud.com/en-gb/public-cloud/local-zone-compute/&#34;&gt;&amp;nbsp;Local Zone page&lt;/a&gt;.&lt;br&gt;&lt;br&gt;&lt;strong&gt;&lt;em&gt;Note: Until 31 August 2024 you can&lt;a href=&#34;https://www.ovh.com/auth/?onsuccess=https%3A%2F%2Fwww.ovh.com%2Fmanager%2F%23%2Fpublic-cloud%3Fcontext%3Dwebsite&amp;amp;ovhSubsidiary=GB&amp;amp;_gl=1*rqcgpi*_gcl_au*ODk0Njk3ODc2LjE3MjA3NzExMTE.&#34;&gt;&amp;nbsp;try Local Zones for free&lt;/a&gt;!&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Kubernetes on Compute instances&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://blog.ovhcloud.com/wp-content/uploads/2024/07/image-20.png&#34; alt=&#34;Image&#34; class=&#34;wp-image-27148&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;At OVHcloud we have a Managed Kubernetes Services solution but you can also deploy Kubernetes clusters on Compute Instances if you want to managed in your own your clusters.&lt;br&gt;&lt;br&gt;Find more information on our dedicated&amp;nbsp;&lt;a href=&#34;https://www.ovhcloud.com/en-gb/public-cloud/compute/&#34;&gt;Compute instances page&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Demo&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In this demo we will:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Create 5 compute instances (3 for the Kubernetes’s etcd + controlplane &amp;amp; 2 for workers) on a Local Zone&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Create a managed Rancher&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;In Rancher, configure the instances to deploy into them a Kubernetes cluster (with k3s or RKE2, depending on your needs ans use cases)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Creating Compute instances&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;First, you have to log in to the&amp;nbsp;&lt;a href=&#34;https://help.ovhcloud.com/csm/en-gb-public-cloud-kubernetes-create-cluster?id=kb_article_view&amp;amp;sysparm_article=KB0049683&#34;&gt;OVHcloud Control Panel&amp;nbsp;&lt;/a&gt;and open the&amp;nbsp;&lt;strong&gt;Public Cloud&lt;/strong&gt;&amp;nbsp;section. Then access the&amp;nbsp;&lt;strong&gt;Instances&lt;/strong&gt;&amp;nbsp;under the&amp;nbsp;&lt;strong&gt;Compute&lt;/strong&gt;&amp;nbsp;section.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Click on the&amp;nbsp;&lt;strong&gt;Create an instance&lt;/strong&gt;&amp;nbsp;button.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Choose a model (the type of an instance / the flavor,&amp;nbsp;&lt;code&gt;B3-8&lt;/code&gt;&amp;nbsp;for example, but you can choose another one, depending on your needs).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Choose a local zone (&lt;code&gt;Marseille&lt;/code&gt;&amp;nbsp;for example):&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://blog.ovhcloud.com/wp-content/uploads/2024/07/lz-1024x615.png&#34; alt=&#34;Images&#34; class=&#34;wp-image-27131&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Choose a distribution (&lt;code&gt;Ubuntu&lt;/code&gt;&amp;nbsp;for example).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Select your SSH key (we have to log in our instances later).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Choose&amp;nbsp;&lt;code&gt;5&lt;/code&gt;&amp;nbsp;as the number of instances to be created and change the name of the instance name (&lt;code&gt;lz-kube&lt;/code&gt;&amp;nbsp;for example).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Check the checkbox&amp;nbsp;&lt;code&gt;Public network&lt;/code&gt;&amp;nbsp;(to have a pubic IP).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The instances will take several minutes to spawn.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Deploying a Managed Rancher&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Still in the OVHcloud Control Panel, click on the&amp;nbsp;&lt;strong&gt;Create a Managed Rancher Service&lt;/strong&gt;&amp;nbsp;button.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Fill a name (&lt;code&gt;my_lz_rancher&lt;/code&gt;&amp;nbsp;for example), choose the&amp;nbsp;&lt;strong&gt;Standard&lt;/strong&gt;&amp;nbsp;plan, the recommended version then click on the&amp;nbsp;&lt;strong&gt;Create a Managed Rancher Service&lt;/strong&gt;&amp;nbsp;button.&lt;br&gt;Rancher instances are pre-provisioned, so your instance will be created immediately.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In the list of existing Managed Rancher Service, click on your instance, then click on&amp;nbsp;&lt;strong&gt;Generate access code&lt;/strong&gt;&amp;nbsp;button to generate the login and password to access to Rancher. Save the login and password and click on&amp;nbsp;&lt;strong&gt;Go to Rancher&lt;/strong&gt;&amp;nbsp;button.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Copy/paste the password in&amp;nbsp;&lt;strong&gt;password&lt;/strong&gt;&amp;nbsp;field and click on&amp;nbsp;&lt;strong&gt;Log in with Local User&lt;/strong&gt;&amp;nbsp;button.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;A new password will be generated, save it! Save the server URL too, check the&amp;nbsp;&lt;strong&gt;End User License Agreement&lt;/strong&gt;&amp;nbsp;checkbox and click on the&amp;nbsp;&lt;strong&gt;Continue&lt;/strong&gt;&amp;nbsp;button.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Configuring Rancher to deploy a Kubernetes cluster&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Creating a cluster&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In Rancher UI, click on the&amp;nbsp;&lt;strong&gt;Create&lt;/strong&gt;&amp;nbsp;button and then on the&amp;nbsp;&lt;strong&gt;Custom&lt;/strong&gt;&amp;nbsp;driver:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://blog.ovhcloud.com/wp-content/uploads/2024/07/custom.png&#34; alt=&#34;Images&#34; class=&#34;wp-image-27133&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Fill a cluster name (&lt;code&gt;lz-k3s&lt;/code&gt;&amp;nbsp;for example).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In the Kubernetes version list, choose the latest version of the wanted OS. For this blog post we will choose the latest version of K3s, but for production needs we recommend RKE2 instead.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://blog.ovhcloud.com/wp-content/uploads/2024/07/k3s-1024x423.png&#34; alt=&#34;Image&#34; class=&#34;wp-image-27134&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Then click on&amp;nbsp;&lt;code&gt;Create&lt;/code&gt;&amp;nbsp;button.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Configuring the cluster&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;:&lt;br&gt;In Rancher when you configure a node, there are three roles that can be assigned to nodes:&amp;nbsp;&lt;code&gt;&lt;em&gt;etcd&lt;/em&gt;&lt;/code&gt;,&amp;nbsp;&lt;code&gt;&lt;em&gt;controlplane&lt;/em&gt;&lt;/code&gt;&amp;nbsp;and&amp;nbsp;&lt;code&gt;&lt;em&gt;worker&lt;/em&gt;&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;There are some good practices:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;At least 3 nodes with the role&amp;nbsp;&lt;code&gt;etcd&lt;/code&gt;&amp;nbsp;are needed to survive a loss of 1 node and have a minimum high availability configuration for&amp;nbsp;&lt;code&gt;etcd&lt;/code&gt;. 3&amp;nbsp;&lt;code&gt;etcd&lt;/code&gt;&amp;nbsp;nodes are generally sufficient for smaller and medium clusters, and 5&amp;nbsp;&lt;code&gt;etcd&lt;/code&gt;&amp;nbsp;nodes for large clusters.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;At least 2 nodes with the role&amp;nbsp;&lt;code&gt;controlplane&lt;/code&gt;&amp;nbsp;for master component high availability.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;You can set both the&amp;nbsp;&lt;code&gt;etcd&lt;/code&gt;&amp;nbsp;and&amp;nbsp;&lt;code&gt;controlplane&lt;/code&gt;&amp;nbsp;roles for one instance.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;The worker role should not be used or added to nodes with the&amp;nbsp;&lt;code&gt;etcd&lt;/code&gt;&amp;nbsp;or&amp;nbsp;&lt;code&gt;controlplane&lt;/code&gt;&amp;nbsp;role.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;At least 2 nodes with the role&amp;nbsp;&lt;code&gt;worker&lt;/code&gt;&amp;nbsp;for workload rescheduling upon node failure.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For the configuration of our&amp;nbsp;&lt;code&gt;etcd + control planes&lt;/code&gt;&amp;nbsp;nodes, check only the&amp;nbsp;&lt;code&gt;&lt;em&gt;etcd&lt;/em&gt;&lt;/code&gt;&amp;nbsp;and&amp;nbsp;&lt;code&gt;&lt;em&gt;control&lt;/em&gt;&amp;nbsp;&lt;em&gt;plane&lt;/em&gt;&lt;/code&gt;&amp;nbsp;Nodes Roles:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://blog.ovhcloud.com/wp-content/uploads/2024/07/etcdnode-1024x501.png&#34; alt=&#34;Image&#34; class=&#34;wp-image-27139&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;And copy/paste the registration command in a file.&lt;br&gt;For the configuration of our&amp;nbsp;&lt;code&gt;worker&lt;/code&gt;&amp;nbsp;nodes, uncheck the checkboxes and check only the&amp;nbsp;&lt;code&gt;Worker&lt;/code&gt;&amp;nbsp;checkbox:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://blog.ovhcloud.com/wp-content/uploads/2024/07/workernode-1024x435.png&#34; alt=&#34;Image&#34; class=&#34;wp-image-27141&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;And copy/paste the registration command in a file.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In the OVHcloud Control Panel, click on the&amp;nbsp;&lt;strong&gt;Instances&lt;/strong&gt;&amp;nbsp;button.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Fill the search box with the beginning of the name of our instances:&amp;nbsp;&lt;code&gt;lz-kube&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://blog.ovhcloud.com/wp-content/uploads/2024/07/search-1024x529.png&#34; alt=&#34;Image&#34; class=&#34;wp-image-27142&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For the first three instances, pick the Public IP addresses and then in your local terminal connect you in ssh and copy/paste the first registration command (for etcd and control plane nodes):&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;$ ssh root@xxx.xxx.xxx.xxx&#xA;The authenticity of host &#39;xxx.xxx.xxx.xxx (xxx.xxx.xxx.xxx)&#39; can&#39;t be established.&#xA;ED25519 key fingerprint is SHA256:dqsdqsdqsdqsd/dqsdqsdqsdqsdqsdqsdq.&#xA;This key is not known by any other names&#xA;Are you sure you want to continue connecting (yes/no/[fingerprint])? yes&#xA;...&#xA;root@lz-kube-1:~# curl -fL https://dsqdsqdqsd.p7mg.rancher.ovh.net/system-agent-install.sh | sudo  sh -s - --server https://dsqdsqdqsd.p7mg.rancher.ovh.net --label &#39;cattle.io/os=linux&#39; --token kbv5k48vc8thhgqqhmtd8tn55qtlpgw7jp4llm4m4tvnp9sznscmpf --etcd --controlplane&#xA;  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current&#xA;                                 Dload  Upload   Total   Spent    Left  Speed&#xA;100 30794    0 30794    0     0   156k      0 --:--:-- --:--:-- --:--:--  157k&#xA;[INFO]  Label: cattle.io/os=linux&#xA;...&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;And for the last two instances, pick the Public IP addresses and then in your local terminal connect you in ssh and copy/paste the second registration command (for worker nodes):&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;$ ssh root@xxx.xxx.xxx.xxx&#xA;The authenticity of host &#39;xxx.xxx.xxx.xxx (xxx.xxx.xxx.xxx)&#39; can&#39;t be established.&#xA;ED25519 key fingerprint is SHA256:dqsdqsdqsdqsd/dqsdqsdqsdqsdqsdqsdq.&#xA;This key is not known by any other names&#xA;Are you sure you want to continue connecting (yes/no/[fingerprint])? yes&#xA;...&#xA;&#xA;root@lz-kube-4:~# curl -fL https://dsqdsqdqsd.p7mg.rancher.ovh.net/system-agent-install.sh | sudo  sh -s - --server https://dsqdsqdqsd.p7mg.rancher.ovh.net --label &#39;cattle.io/os=linux&#39; --token kbv5k48vc8thhgqqhmtd8tn55qtlpgw7jp4llm4m4tvnp9sznscmpf --worker&#xA;&#xA;  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current&#xA;                                 Dload  Upload   Total   Spent    Left  Speed&#xA;100 30794    0 30794    0     0   156k      0 --:--:-- --:--:-- --:--:--  157k&#xA;[INFO]  Label: cattle.io/os=linux&#xA;...&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Wait until the cluster is in&amp;nbsp;&lt;code&gt;Active&lt;/code&gt;&amp;nbsp;state.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Connecting to the cluster with kubectl CLI&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In Rancher UI, click on the&amp;nbsp;&lt;code&gt;lz-k3s&lt;/code&gt;&amp;nbsp;cluster.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Then click on the&amp;nbsp;&lt;strong&gt;Download KubeConfig&lt;/strong&gt;&amp;nbsp;icon to download the kubeconfig file and save the path of kubeconfig in an environment variable:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;$ export KUBE_CLUSTER=$(pwd)/lz_k3s.yml&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Test the connexion to the Kubernetes:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;$ kubectl --kubeconfig=$KUBE_CLUSTER cluster-info&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;List the nodes:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;$ kubectl --kubeconfig=$KUBE_CLUSTER get no&#xA;&#xA;NAME        STATUS   ROLES                       AGE     VERSION&#xA;lz-kube-1   Ready    control-plane,etcd,master   9m9s    v1.27.14+k3s1&#xA;lz-kube-2   Ready    control-plane,etcd,master   9m28s   v1.27.14+k3s1&#xA;lz-kube-3   Ready    control-plane,etcd,master   10m     v1.27.14+k3s1&#xA;lz-kube-4   Ready    worker                      8m59s   v1.27.14+k3s1&#xA;lz-kube-5   Ready    worker                      9m      v1.27.14+k3s1&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Conclusion&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We deployed and configured a Kubernetes cluster in Compute Instances on Local Zones with the new Managed Rancher Services and we discovered how to connect to it.&lt;br&gt;During the Beta phase, MRS is free so don’t hesitate to test it.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Want to go further?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Visit our technical&amp;nbsp;&lt;a href=&#34;https://help.ovhcloud.com/csm/en-gb-documentation-public-cloud-containers-orchestration-managed-rancher-service?id=kb_browse_cat&amp;amp;kb_id=574a8325551974502d4c6e78b7421938&amp;amp;kb_category=ba1cdc8ff1a082502d4cea09e7c8beb9&amp;amp;spa=1&#34;&gt;guides and how to about OVHcloud Managed Rancher Service&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;成员帖子最初发布于&lt;a href=&#34;https://blog.ovhcloud.com/how-to-create-a-kubernetes-cluster-in-a-local-zone-through-management- rancher-service/&#34;&gt;OVH Cloud 的博客&lt;/a&gt; 作者：Aurélie Vache &lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;容器编排已成为现代应用程序部署的基石，提供可扩展性、灵活性和资源效率。管理多个 Kubernetes 集群已变得很常见，但要高效地管理多个 Kubernetes 集群，配备精良的设备非常有用。&lt;br&gt;&lt;br&gt;在这篇博文中，我们将了解如何通过以下方式在 OVHcloud 本地区域中创建 Kubernetes 集群：托管 Rancher 服务。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;托管 Rancher 服务 (MRS)&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://blog.ovhcloud.com/wp-content/uploads/2024/07/image-18.png&#34; alt= “图像”class =“wp-image-27146”referrerpolicy =“no-referrer”&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;托管 Rancher Services (MRS) 目前处于测试阶段，基于开源容器管理平台 Rancher，可简化 Kubernetes 集群的部署和管理。 OVHcloud 的托管 Rancher 服务提供了一个强大的平台，用于无缝编排 Kubernetes 集群。&lt;br&gt;&lt;br&gt;有关我们的专用&lt;a href=&#34;https://www.ovhcloud.com/fr/public-cloud/management- rancher-service/&#34;&gt; 托管 Rancher 服务页面&lt;/a&gt;。&lt;br&gt;&lt;br&gt;&lt;strong&gt;注意：该产品处于 Beta 阶段，因此您可以&lt;a href=&#34;https://www.ovh.com/auth /?onsuccess=https%3A%2F%2Fwww.ovh.com%2Fmanager%2F%23%2Fpublic-cloud%3Fcontext%3Dwebsite&amp;ovhSubsidiary=GB&amp;_gl=1*rqcgpi*_gcl_au*ODk0Njk3ODc2LjE3MjA3NzExMTE。&#34;&gt; 免费试用 Managed Rancher 服务&lt;/一个&gt;!&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;本地区域 (LZ)&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-imagealigncenter is-resized&#34;&gt;&lt;imgdecoding=&#34;async&#34;src=&#34;https://blog.ovhcloud.com/wp-content/uploads/2024/07/image-19- 1024x683.png&#34; alt=&#34;图像&#34; class=&#34;wp-image-27147&#34; style=&#34;width:486px;height:auto&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;今年我们还推出了本地区域。本地区域是&lt;a href=&#34;https://www.ovhcloud.com/en-gb/public-cloud/regions-availability/&#34;&gt;区域&lt;/a&gt;的扩展，使 OVHcloud 服务更接近特定位置，提供减少延迟并提高应用程序性能。&lt;br&gt;本地区域战略性地放置在靠近用户需求较高的区域。他们的主要目标是最大限度地减少用户和云之间传输数据所需的时间，以使服务更快、响应更灵敏，并满足数据驻留要求。&lt;br&gt;&lt;br&gt;在我们的专用&lt;a href=&#34;https://www.ovhcloud.com/en-gb/public-cloud/local-zone-compute/&#34;&gt; 本地区域页面&lt;/a&gt;。&lt;br&gt;&lt;br&gt;&lt;strong&gt;&lt;em&gt;注意：在 2024 年 8 月 31 日之前，您可以&lt;a href=&#34;https://www.ovh.com/auth/?onsuccess=https%3A%2F%2Fwww.ovh.com%2Fmanager%2F%23%2Fpublic-cloud%3Fcontext %3Dwebsite&amp;ovhSubsidiary=GB&amp;_gl=1*rqcgpi*_gcl_au*ODk0Njk3ODc2LjE3MjA3NzExMTE。&#34;&gt; 尝试本地免费区域&lt;/a&gt;！&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;计算实例上的 Kubernetes&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://blog.ovhcloud.com/wp-content/uploads/2024/07/image-20.png&#34; alt= “图像”类=“wp-image-27148”referrerpolicy=“no-referrer”&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在 OVHcloud，我们有托管 Kubernetes 服务解决方案，但如果您想在自己的集群中进行管理，您也可以在计算实例上部署 Kubernetes 集群。&lt;br&gt;&lt;br&gt;在我们的专用 &lt;a href=&#34; 上查找更多信息https://www.ovhcloud.com/en-gb/public-cloud/compute/&#34;&gt;计算实例页面&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;演示&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在此演示中，我们将：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;在本地区域上创建 5 个计算实例（3 个用于 Kubernetes 的 etcd + 控制平面，2 个用于工作线程）&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;创建托管 Rancher&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;在 Rancher 中，配置实例以将 Kubernetes 集群部署到其中（使用 k3s 或 RKE2，具体取决于您的需求和用例）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;创建计算实例&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;首先，您必须登录&lt;a href=&#34;https://help.ovhcloud.com/csm/en-gb-public-cloud-kubernetes-create-cluster?id=kb_article_view&amp;sysparm_article=KB0049683&#34;&gt; OVHcloud 控制面板&lt;/a&gt;并打开&lt;strong&gt;公有云&lt;/strong&gt;部分。然后访问&lt;strong&gt;计算&lt;/strong&gt;部分下的&lt;strong&gt;实例&lt;/strong&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;点击&lt;strong&gt;创建实例&lt;/strong&gt;按钮。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;选择模型（实例类型/风格，例如 &lt;code&gt;B3-8&lt;/code&gt;，但您可以根据需要选择其他模型）。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;选择本地区域（例如&lt;code&gt;马赛&lt;/code&gt;）：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://blog.ovhcloud.com/wp-content/uploads/2024/07/lz-1024x615.png&#34; alt= “图像”class =“wp-image-27131”referrerpolicy =“no-referrer”&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;选择一个发行版（例如 &lt;code&gt;Ubuntu&lt;/code&gt;）。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;选择您的 SSH 密钥（我们必须稍后登录我们的实例）。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;选择&lt;code&gt;5&lt;/code&gt;作为要创建的实例数量，并更改实例名称（例如&lt;code&gt;lz-kube&lt;/code&gt;）。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;选中复选框&lt;code&gt;公共网络&lt;/code&gt;（拥有公共 IP）。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;实例需要几分钟才能生成。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;部署托管 Rancher&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;仍然在 OVHcloud 控制面板中，点击&lt;strong&gt;创建托管 Rancher 服务&lt;/strong&gt;按钮。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;填写名称（例如 &lt;code&gt;my_lz_rancher&lt;/code&gt;），选择&lt;strong&gt;标准&lt;/strong&gt;计划、推荐版本，然后点击&lt;strong&gt;创建托管 Rancher 服务&lt;/strong&gt;按钮。&lt;br&gt;Rancher 实例是预先配置的，因此您的实例将立即创建。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在列表中现有 Managed Rancher Service 的实例，点击您的实例，然后点击&lt;strong&gt;生成访问代码&lt;/strong&gt;按钮生成用于访问 Rancher 的登录名和密码。保存登录名和密码，然后点击&lt;strong&gt;转到 Rancher&lt;/strong&gt; 按钮。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;将密码复制/粘贴到&lt;strong&gt;密码&lt;/strong&gt;字段中，然后点击&lt;strong&gt;使用本地用户登录&lt;/strong&gt;按钮。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;将会生成一个新密码，保存它！也保存服务器 URL，选中&lt;strong&gt;最终用户许可协议&lt;/strong&gt;复选框，然后单击&lt;strong&gt;继续&lt;/strong&gt;按钮。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;配置 Rancher 部署 Kubernetes 集群&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;创建集群&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在 Rancher UI 中，点击&lt;strong&gt;创建&lt;/strong&gt;按钮，然后点击&lt;strong&gt;自定义&lt;/strong&gt;驱动程序：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://blog.ovhcloud.com/wp-content/uploads/2024/07/custom.png&#34; alt=&#34;图像“class =“wp-image-27133”referrerpolicy =“no-referrer”&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;填写集群名称（例如&lt;code&gt;lz-k3s&lt;/code&gt;）。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在 Kubernetes 版本列表中，选择所需操作系统的最新版本。在本博文中，我们将选择最新版本的 K3s，但出于生产需求，我们建议使用 RKE2。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://blog.ovhcloud.com/wp-content/uploads/2024/07/k3s-1024x423.png&#34; alt= “图像”class =“wp-image-27134”referrerpolicy =“no-referrer”&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;然后点击&lt;code&gt;创建&lt;/code&gt;按钮。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;配置集群&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;：&lt;br&gt;在 Rancher 中配置节点时，可以为节点分配三个角色：&lt;code&gt;&lt;em&gt;etcd&lt;/em&gt;&lt;/code&gt;、 &lt;code&gt;&lt;em&gt;控制平面&lt;/em&gt;&lt;/code&gt;和&lt;code&gt;&lt;em&gt;工作线程&lt;/em&gt;&lt;/code&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;有一些好的做法：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;至少需要 3 个具有 &lt;code&gt;etcd&lt;/code&gt; 角色的节点，才能在丢失 1 个节点的情况下幸存下来，并具有 &lt;code&gt;etcd&lt;/code&gt; 的最低高可用性配置。对于中小型集群，3 个 &lt;code&gt;etcd&lt;/code&gt; 节点通常就足够了，对于大型集群，5 个 &lt;code&gt;etcd&lt;/code&gt; 节点就足够了。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;至少 2 个具有&lt;code&gt;控制平面&lt;/code&gt;角色的节点，以实现主组件的高可用性。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;您可以为一个实例同时设置 &lt;code&gt;etcd&lt;/code&gt; 和 &lt;code&gt;controlplane&lt;/code&gt; 角色。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;不应使用辅助角色或将辅助角色添加到具有 &lt;code&gt;etcd&lt;/code&gt; 或 &lt;code&gt;controlplane&lt;/code&gt; 角色的节点。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;至少 2 个具有&lt;code&gt;worker&lt;/code&gt; 角色的节点，用于在节点故障时重新安排工作负载。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;对于&lt;code&gt;etcd + 控制平面&lt;/code&gt;节点的配置，仅检查&amp;nbsp;&lt;code&gt;&lt;em&gt;etcd&lt;/em&gt;&lt;/code&gt; 和&lt;code&gt;&lt;em&gt;control&lt;/em&gt; &lt;em&gt;plane&lt;/em&gt;&lt;/code&gt; 节点角色：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://blog.ovhcloud.com/wp-content/uploads/2024/07/etcdnode-1024x501.png&#34; alt= “图像”类=“wp-image-27139”referrerpolicy=“no-referrer”&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;然后将注册命令复制/粘贴到文件中。&lt;br&gt;对于&lt;code&gt;worker&lt;/code&gt;节点的配置，取消选中复选框并仅选中&lt;code&gt;Worker&lt;/code&gt;复选框：&lt; /p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://blog.ovhcloud.com/wp-content/uploads/2024/07/workernode-1024x435.png&#34; alt= “图像”类=“wp-image-27141”referrerpolicy=“no-referrer”&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;并将注册命令复制/粘贴到文件中。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在 OVHcloud 控制面板中，点击&lt;strong&gt;实例&lt;/strong&gt;按钮。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在搜索框中填写实例名称的开头：&lt;code&gt;lz-kube&lt;/code&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://blog.ovhcloud.com/wp-content/uploads/2024/07/search-1024x529.png&#34; alt= “图像”类=“wp-image-27142”referrerpolicy=“no-referrer”&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;对于前三个实例，选择公共 IP 地址，然后在本地终端中通过 ssh 连接您并复制/粘贴第一个注册命令（对于 etcd 和控制平面节点）：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;$ ssh root@xxx.xxx.xxx.xxx&#xA;无法确定主机“xxx.xxx.xxx.xxx (xxx.xxx.xxx.xxx)”的真实性。&#xA;ED25519 密钥指纹为 SHA256:dqsdqsdqsdqsd/dqsdqsdqsdqsdqsdqsdq。&#xA;该密钥没有任何其他名称&#xA;您确定要继续连接吗（是/否/[指纹]）？是的&#xA;...&#xA;root@lz-kube-1:~#curl -fL https://dsqdsqdqsd.p7mg.rancher.ovh.net/system-agent-install.sh | sudo sh -s - --server https://dsqdsqdqsd.p7mg.rancher.ovh.net --label &#39;cattle.io/os=linux&#39; --token kbv5k48vc8thhgqqhmtd8tn55qtlpgw7jp4llm4m4tvnp9sznscmpf --etcd --controlplane&#xA;  % 总计 % 已接收 % Xferd 平均速度 时间 时间 时间 当前&#xA;                                 Dload 上传总花费左速度&#xA;100 30794 0 30794 0 0 156k 0 --:--:-- --:--:-- --:--:-- 157k&#xA;[信息] 标签：cattle.io/os=linux&#xA;...&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;对于最后两个实例，选择公共 IP 地址，然后在本地终端中通过 ssh 连接您并复制/粘贴第二个注册命令（对于工作节点）：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;$ ssh root@xxx.xxx.xxx.xxx&#xA;无法确定主机“xxx.xxx.xxx.xxx (xxx.xxx.xxx.xxx)”的真实性。&#xA;ED25519 密钥指纹为 SHA256:dqsdqsdqsdqsd/dqsdqsdqsdqsdqsdqsdq。&#xA;该密钥没有任何其他名称&#xA;您确定要继续连接吗（是/否/[指纹]）？是的&#xA;...&#xA;&#xA;root@lz-kube-4:~#curl -fL https://dsqdsqdqsd.p7mg.rancher.ovh.net/system-agent-install.sh | sudo sh -s - --server https://dsqdsqdqsd.p7mg.rancher.ovh.net --label &#39;cattle.io/os=linux&#39; --token kbv5k48vc8thhgqqhmtd8tn55qtlpgw7jp4llm4m4tvnp9sznscmpf --worker&#xA;&#xA;  % 总计 % 已接收 % Xferd 平均速度 时间 时间 时间 当前&#xA;                                 Dload 上传总花费左速度&#xA;100 30794 0 30794 0 0 156k 0 --:--:-- --:--:-- --:--:-- 157k&#xA;[信息] 标签：cattle.io/os=linux&#xA;...&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;等待集群处于&lt;code&gt;Active&lt;/code&gt;状态。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;使用 kubectl CLI 连接到集群&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在 Rancher UI 中，点击 &lt;code&gt;lz-k3s&lt;/code&gt; 集群。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;然后点击&lt;strong&gt;下载 KubeConfig&lt;/strong&gt; 图标下载 kubeconfig 文件并将 kubeconfig 的路径保存在环境变量中：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;$ export KUBE_CLUSTER=$(pwd)/lz_k3s.yml&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;测试与 Kubernetes 的连接：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;$ kubectl --kubeconfig=$KUBE_CLUSTER 集群信息&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;列出节点：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;$ kubectl --kubeconfig=$KUBE_CLUSTER 没有得到&#xA;&#xA;姓名 状态 角色 年龄 版本&#xA;lz-kube-1 就绪控制平面、etcd、master 9m9s v1.27.14+k3s1&#xA;lz-kube-2 就绪控制平面、etcd、master 9m28s v1.27.14+k3s1&#xA;lz-kube-3 就绪控制平面、etcd、master 10m v1.27.14+k3s1&#xA;lz-kube-4 Ready Worker 8m59s v1.27.14+k3s1&#xA;lz-kube-5 Ready Worker 9m v1.27.14+k3s1&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;结论&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们使用新的托管 Rancher 服务在本地区域的计算实例中部署和配置了 Kubernetes 集群，并了解了如何连接到它。&lt;br&gt;在 Beta 阶段，MRS 是免费的，因此请毫不犹豫地测试它.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;想走得更远吗？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;访问我们的技术&lt;a href=&#34;https://help.ovhcloud.com/csm/en-gb-documentation-public-cloud-containers-orchestration-management-rancher-service?id=kb_browse_cat&amp;kb_id=574a8325551974502d4c6e78b7421938&amp;kb_category=ba1cdc8ff1a0 82502d4cea09e7c8beb9&amp;spa =1&#34;&gt;OVHcloud Managed Rancher Service 的指南和操作方法&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Mon, 26 Aug 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【wasmCloud on the factory floor: efficient and secure processing of high velocity machine data】工厂车间的 wasmCloud：高效、安全地处理高速机器数据</title>
      <link>https://www.cncf.io/blog/2024/08/23/wasmcloud-on-the-factory-floor-efficient-and-secure-processing-of-high-velocity-machine-data/</link>
      <description>【&lt;p&gt;&lt;em&gt;End user blog by Jochen Rau and Tyler Schoppe, Platform Engineering team at MachineMetrics&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p class=&#34;has-black-color has-gray-300-background-color has-text-color has-background has-link-color wp-elements-af86228d1572f0ae063b571f002771af&#34;&gt;&lt;em&gt;“WebAssembly, wasmCloud, and NATS will not only reshape the MachineMetrics business but are already transforming industrial IoT. A big thanks to the WebAssembly and wasmCloud community for supporting us all the way here and providing such awesome tools.”&lt;/em&gt; – &lt;strong&gt;Jochen Rau, Data Platform Lead, MachineMetrics.&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Improving Manufacturing Performance, Efficiency and Longevity&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Operating in the manufacturing sector has never been more costly. Exacerbated by high inflation, the cost of materials, fuel, shipping and labor have risen exponentially post-pandemic. In response, manufacturers are looking for ways to reduce maintenance costs, and improve production capacity. They’re doing this by putting advanced data analytics into production lines to better understand and optimize machine performance.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.machinemetrics.com/&#34;&gt;&lt;strong&gt;MachineMetrics LLC&lt;/strong&gt;&lt;/a&gt;, is a catalyst for this next phase of digital transformation. The company’s customers operate factories and plants containing advanced manufacturing machinery, producing swathes of unutilized data. Reporting is usually carried out manually, sometimes on thousands of machines. Manual errors often arise which result in missed anomalies, risking eventual machine failure.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;MachineMetrics’ edge monitoring devices connect to each machine to capture timely and accurate data from machine controls and sensors. By being able to closely analyze the performance of machinery, operators more accurately predict wear and tear. This reduces costly incidents, lowers maintenance costs and extends the longevity of equipment.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Data capture alone, however, consumes the majority of resources on each device which leaves less space to do much else. The inherent abundance of high-frequency data, coupled with network constraints, make visualizing that data difficult in tools like Grafana. MachineMetrics’ Data Platform Team Engineers Jochen Rau and Tyler Schoppe, suspected that the efficiency of the WebAssembly (Wasm) bytecode format could help solve this issue and unlock greater architectural freedom.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;WebAssembly is often described as a tiny virtual machine designed to execute portable bytecode in any location, at near native speed. When built with standardized, interchangeable &lt;strong&gt;WebAssembly components&lt;/strong&gt;, applications can run on any server, device or cloud that supports the standard APIs of WASI (WebAssembly System Interfaces) 0.2, regardless of the underlying hardware or operating system.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To test the theory, Rau and Schoppe designed an early PoC with the CNCF Sandbox Project &lt;strong&gt;wasmCloud&lt;/strong&gt;, which enables users to run WebAssembly workloads in distributed environments.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Edge Extensibility with WebAssembly&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Streaming high frequency data poses considerable challenges, exponentially increasing ingest costs. Many factories do not have the network bandwidth to support volume data being streamed across a fleet of machines. Adding to the challenge, a single edge device can collect data from dozens of systems machines and push it to the cloud, but this leaves few resources available for compute.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The PoC was created to discover whether wasmCloud could provide a more efficient and lightweight compute methodology, with business logic that could be more easily transported over the network. This would make better use of existing available resources at the edge, and put portable processing where needed most.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Engineered around the standard APIs of WASI 0.2, wasmCloud allowed the team to deploy and manage workloads as &lt;a href=&#34;https://component-model.bytecodealliance.org/design/why-component-model.html&#34;&gt;&lt;strong&gt;components&lt;/strong&gt;&lt;/a&gt;: portable, interoperable WebAssembly binaries that could run anywhere from the cloud to the edge. By including only the code they needed in components and fulfilling non-functional requirements with wasmCloud providers linked at runtime, applications could be tiny and portable. Because the non-functional requirements are externalized, updating dependencies for large fleets of devices is easy in case of a bug or needed feature&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Most importantly, the team could manage and run wasmCloud on existing Kubernetes clusters in a way that felt familiar to them, bringing the kind of extensibility to Kubernetes that was previously impossible.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXeQ03a-VU58Bo3qCnvFCXmGQJgXuZsMMZnnnpXgAVC2s7e3wuxiyTsESk7aWU8mzclP-DrGIh8uBEeRieTUrTv39jlMhG09DKQCYV6ZCgLHBEWdEhXPneY45JjlFbi_whAVah8ebch8mViL_Y-fpUfSMZo?key=7akIfN2LsupSp5m-Be-HvA&#34; alt=&#34;Figure 1: What platform engineering feels like in the wasmCloud ecosystem.&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 1: What platform engineering feels like in the wasmCloud ecosystem.&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Proof of Concept: Downsampling High-Frequency Data&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The team developed a custom algorithm allowing high-frequency data to be downsampled from any deployment target. This would allow processing power to be moved between edges and clouds, according to need and without losing data fidelity. Whether analyzing 5000 data points or just 50, the data would be consistent. Built on Sveinn Steinarsson’s (University of Iceland) &lt;a href=&#34;https://skemman.is/bitstream/1946/15343/3/SS_MSthesis.pdf&#34;&gt;Largest-Triangle-Three-Buckets (LTTB)&lt;/a&gt; algorithm, it was adjusted to operate on unbounded streams and provided stateful processing to enable storage.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Implemented in Rust and deployed in wasmCloud as a Wasm component, the completed downsampling algorithm reports proactive maintenance telemetry across edge and cloud platforms. Crucially, the algorithm is deployed to wasmCloud with Wadm, a Wasm components native orchestrator that integrates seamlessly with Kubernetes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Jochen Rau: &lt;em&gt;“Wadm simplifies creating and linking components. It’s easy to define your providers, as well as your components, in this common model and produce the providers you need for key-value mass messaging, as well as the downsampling component, hooked up together with some links. That’s great for reconciliation. And as we release new versions, it helps make sure everything goes smoothly.”&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The algorithm proves it’s possible to run high-frequency data workloads as components, on edge devices running in wasmCloud. wasmCloud is also shown to be an effective compute lattice on which to move workloads seamlessly between deployment targets. In the next development phase, Schoppe and Rau will deploy wasmCloud on machines, and begin to observe the potential efficiencies.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXfiGTZTIIDfEganWVi9J0xfYQF_7S2GPe59lkUa3j0EVNVq8JjMYZnmSoyRYee09KASHX95SVN2K8B0rq_GdrWRSl84ukEE9SXjEF_k7_0S5jjL41CsR5RDx5a9YgpujBLDZoIJXu5MCH2Ra-FVzXroURbl?key=7akIfN2LsupSp5m-Be-HvA&#34; alt=&#34;Figure 2: Downsampling algorithm maintains fidelity of the graph even at low sampling rates&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 2: Downsampling algorithm maintains fidelity of the graph even at low sampling rates&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXdDrMnXScGVx-kcAdKM9EfkDeH0KhIsmsjoJImwnuuJroOEkIxzEBsmT7tdkJKhMW1BPH5br8ASIlynU7aDXRcIeeu7ckEI1N07dSh2_lUZyNMPZ0sSAgGhVFBrUJHyrnSC5inTKhgtBaOrcr_OT-zDcNI?key=7akIfN2LsupSp5m-Be-HvA&#34; alt=&#34;Figure 3: Architecture of the PoC showing wasmCloud host running on an edge device. NATS serves as backbone for machine, configuration, and control data.&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 3: Architecture of the PoC showing wasmCloud host running on an edge device. NATS serves as backbone for machine, configuration, and control data.&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;What are the challenges wasmCloud overcomes?&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Portable Processing Made Real&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Rather than handing off data to be processed in the cloud, applications running as components in wasmCloud are radically smaller, freeing resources to process and stream performance data directly from machines. For MachineMetrics’ customers, that means lower latency, faster time-to-value, and fewer hardware problems.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This is only half the story. The real advantage for the team is in making these workloads portable to &lt;em&gt;any&lt;/em&gt; location—easily shifted back-and-forth between multiple edges and clouds. This gives the team freedom to make better and quicker architectural decisions.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Tyler Schoppe: &lt;em&gt;“What’s powerful is we don’t have to think about where the compute lives. wasmCloud takes that off the minds of developers, the importance of which cannot be overstated. If we need to make changes it’s a lot easier to pivot and move workloads from the edge to the cloud; if we need to scale, for instance. That would be very challenging for us to do in our current architecture.”&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;wasmCloud also breaks down language barriers. Usually, edge application teams work in a different preferred languages to their cloud engineering counterparts. Whether written in Python, Go, C++ or any other language, WASI 0.2 components mean edge and cloud teams can interoperate using standard WebAssembly Interface Type (WIT) definitions for interfaces. This unties them from specific libraries so they can focus on business logic.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Architectural Freedom = Resource Efficiency&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In traditional IoT models, processing is linear and unidirectional. Data is collected from separate sensors: captured by an edge, then ingested into a cloud—where the majority of compute takes place—before being handed off to the consumer. By pushing processing to the cloud, higher costs are incurred and latency increases. More importantly, valuable, more efficient processing capacity at the edge is underutilized.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;MachineMetrics does the majority of its data processing in Kubernetes in the cloud. By moving compute to devices, existing edge resources are used more effectively and cloud resources preserved. Porting logic between resources means the team can balance their resources against their needs. They use the cloud to scale the processing of larger data sets, whilst allowing edge devices to process and stream real-time data directly to operators.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Jochen Rau: &lt;em&gt;“The focus is to find ways to more efficiently use resources that we already have at the edge, and manage our cloud resources more effectively. wasmCloud helps us do that. It’s also a balance—edge devices are relatively small so we can scale much more easily in the cloud. Having the flexibility to move workloads around means greater resource efficiency.”&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Extending the Value of Existing Architecture&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;MachineMetrics uses Kubernetes extensively, but the team can’t run it at the edge. This is partly due to the company’s OS configuration, but primarily due to the limitations of Kubernetes. Kubernetes is great at managing infrastructure, but not so good at running applications on resource-constrained devices.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To solve this problem,&lt;a href=&#34;https://www.youtube.com/watch?v=fQdkNGZqYZA&#34;&gt; MachineMetrics&lt;/a&gt; uses wasmCloud alongside Kubernetes and ArgoCD, making use of the &lt;a href=&#34;https://github.com/wasmcloud/wasmcloud-operator&#34;&gt;wasmcloud-operator&lt;/a&gt; to deploy software to all of its edge locations. The wasmcloud-operator allows platform engineers to manage and run Wasm on Kubernetes using the standard, familiar controller pattern and custom resource definitions (CRDs), all while remaining decoupled from Kubernetes and free to leverage the unique benefits of components. Bringing the kind of extensibility to Kubernetes that was previously impossible.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Rau says: &lt;em&gt;“We shifted up a level: taking the wasmCloud host and deploying it on Kubernetes. The wasmcloud-operator makes this really simple to manage with our existing tools. We deploy our compute workloads on the lattice on wasmCloud. We’re crossing the boundaries between edge and cloud.”&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Using this “decoupled” model means it’s easy for MachineMetrics to tie wasmCloud directly into existing pipelines and tools like ArgoCD.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXc1BHaog5GC0UGS5GKpmHHycGimOj8goujL-piBc8wGgHvKwzWAY-ZXD5bEKBY41ZebFql-y0i-amlE-UBNBqB3HGs9ihWsQRwNB4w2wdtJad-fy1UJ6rhtCr_EIhKW6Q0RAUulz5KD7OPGPC_denwcew?key=7akIfN2LsupSp5m-Be-HvA&#34; alt=&#34;Figure 4: wasmCloud integrates with Kubernetes but as a separate service. This means engineers can capitalize on the benefits of the component model.&amp;nbsp;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 4: wasmCloud integrates with Kubernetes but as a separate service. This means engineers can capitalize on the benefits of the component model.&amp;nbsp;&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Deny-By-Default Security&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Security is also a major consideration for MachineMetrics. Each customer has completely distinct approaches to security. Some have large, dedicated security teams whereas others may adopt a leaner approach. In every case, data is highly sensitive–MachineMetrics has to bring the same cast-iron security to every use case, and must be able to scale the same level of security to devices and sensors.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The power of WebAssembly allows wasmCloud applications to run securely from edge to edge. All code runs in a deny-by-default, secure, stateless, and reactive sandbox. The sandbox satisfies larger customers’ enterprise Service Level Agreements and more complex security, compliance, and policy requirements.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Tyler Schoppe: &lt;em&gt;“We work with mom and pop shops making screws, all the way to hardware planned for outer space. Regardless of how much or little security they have, we treat their security with the same level of care. wasmCloud’s sandbox model gives us a lot of guarantees. In terms of developer peace of mind, it provides a lot for us out of the box.&lt;/em&gt;”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;wasmCloud’s hosts enforce a certain level of default security that cannot be loosened. For example, hosts will always validate runtime links. Additionally, the wasmCloud policy service API can be used to extend and customize policy evaluation, such as by restricting untrusted application components and providers on particular hosts.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Benefits to Manufacturers&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The team believes the benefits of being able to process and stream high velocity data directly from machines will excite their customers, from small shops to large plants. Carbide tools are very expensive—each machine costs thousands—so properly managing the utilization of them is essential. Damaged tools are not just expensive to replace, they can take out entire production lines. Extending the life of their tools through closer monitoring will save customers thousands in maintenance and replacements.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For Rau, the exciting part is being able to deliver a feature that customers have been waiting for.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Rau: &lt;em&gt;“Downsampled high frequency data is as expressive as raw data; we’re moving beyond aggregated monitoring data to being able to see real-time, high velocity data on dashboards. This is something our customers are asking for.”&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Rau and Schoppe are now taking what they’ve learned from the PoC, developing the solution further and investigating ways to integrate with third-party machinery.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Schoppe concludes:&lt;em&gt; “There’s nothing like this on the market right now and so it’s a great opportunity for us to put this kind of compute power in many more customers’ hands. As well as helping us differentiate, it will provide tremendous operational value for customers—something they can rely on to help them save money in a different way.”&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;MachineMetrics 平台工程团队 Jochen Rau 和 Tyler Schoppe 撰写的最终用户博客&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p class=&#34;has-black-color has-gray-300-background-color has-text-color has-background has-link-color wp-elements-af86228d1572f0ae063b571f002771af&#34;&gt;&lt;em&gt;“WebAssembly、wasmCloud 和 NATS 将不仅重塑了 MachineMetrics 业务，而且已经在改变工业物联网。非常感谢 WebAssembly 和 wasmCloud 社区一直以来对我们的支持，并提供了如此出色的工具。”&lt;/em&gt; – &lt;strong&gt;MachineMetrics 数据平台主管 Jochen Rau。&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;/块引用&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;提高制造性能、效率和寿命&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;制造业的运营成本从未如此之高。由于高通胀，材料、燃料、运输和劳动力的成本在大流行后呈指数级上升。对此，制造商正在寻找降低维护成本并提高生产能力的方法。为此，他们将先进的数据分析融入生产线，以更好地了解和优化机器性能。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.machinemetrics.com/&#34;&gt;&lt;strong&gt;MachineMetrics LLC&lt;/strong&gt;&lt;/a&gt; 是数字化转型下一阶段的催化剂。该公司的客户运营着拥有先进制造机械的工厂和工厂，产生了大量未利用的数据。报告通常是手动进行的，有时在数千台机器上进行。手动错误经常出现，导致遗漏异常，从而导致最终机器故障的风险。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;MachineMetrics 的边缘监控设备连接到每台机器，从机器控制和传感器捕获及时、准确的数据。通过密切分析机械性能，操作员可以更准确地预测磨损。这可以减少代价高昂的事故、降低维护成本并延长设备的使用寿命。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;然而，仅数据捕获就消耗了每个设备上的大部分资源，从而留下更少的空间来做其他事情。高频数据固有的丰富性，再加上网络限制，使得在 Grafana 等工具中可视化这些数据变得困难。 MachineMetrics 的数据平台团队工程师 Jochen Rau 和 Tyler Schoppe 怀疑 WebAssembly (Wasm) 字节码格式的效率可以帮助解决这个问题并释放更大的架构自由度。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;WebAssembly 通常被描述为一个微型虚拟机，旨在以接近本机的速度在任何位置执行可移植字节码。当使用标准化、可互换的 WebAssembly 组件构建时，应用程序可以在任何支持 WASI（WebAssembly 系统接口）0.2 标准 API 的服务器、设备或云上运行，无论底层硬件或操作系统如何。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;为了测试该理论，Rau 和 Schoppe 使用 CNCF 沙盒项目 &lt;strong&gt;wasmCloud&lt;/strong&gt; 设计了一个早期的 PoC，它使用户能够在分布式环境中运行 WebAssembly 工作负载。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;使用 WebAssembly 进行边缘扩展&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;流式传输高频数据带来了相当大的挑战，采集成本呈指数级增加。许多工厂没有网络带宽来支持在一组机器上传输大量数据。雪上加霜的是，单个边缘设备可以从数十台系统机器收集数据并将其推送到云端，但这使得可用于计算的资源很少。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;创建 PoC 的目的是为了发现 wasmCloud 是否可以提供更高效、更轻量的计算方法，以及可以更轻松地通过网络传输的业务逻辑。这将更好地利用边缘现有的可用资源，并将便携式处理放在最需要的地方。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;wasmCloud 围绕 WASI 0.2 的标准 API 进行设计，允许团队以 &lt;a href=&#34;https://component-model.bytecodealliance.org/design/why-component-model.html&#34;&gt; 的方式部署和管理工作负载&lt;strong&gt;组件&lt;/strong&gt;&lt;/a&gt;：可移植、可互操作的 WebAssembly 二进制文件，可以在从云端到边缘的任何地方运行。通过仅在组件中包含所需的代码并通过运行时链接的 wasmCloud 提供商来满足非功能性需求，应用程序可以变得很小且可移植。由于非功能性需求是外部化的，因此在出现错误或所需功能时可以轻松更新大量设备的依赖关系&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;最重要的是，团队可以以他们熟悉的方式在现有 Kubernetes 集群上管理和运行 wasmCloud，为 Kubernetes 带来以前不可能的可扩展性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXeQ03a-VU58Bo3qCnvFCXmGQJgXuZsMMZnnnpXgAVC2s7e3wuxiyTsESk7aWU8mzclP-DrGIh8uBEeRieTUrTv39jlMh G09DKQCYV6ZCgLHBEWdEhXPneY45JjlFbi_whAVah8ebch8mViL_Y-fpUfSMZo?key=7akIfN2LsupSp5m-Be- HvA&#34; alt=&#34;图 1：wasmCloud 生态系统中的平台工程感觉如何。&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;图 1：wasmCloud 生态系统中的平台工程感觉如何。&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;概念验证：高频数据下采样&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;该团队开发了一种自定义算法，允许从任何部署目标对高频数据进行下采样。这将允许根据需要在边缘和云端之间转移处理能力，并且不会损失数据保真度。无论是分析 5000 个数据点还是仅分析 50 个数据点，数据都是一致的。基于 Sveinn Steinarsson（冰岛大学）的 &lt;a href=&#34;https://skemman.is/bitstream/1946/15343/3/SS_MSthesis.pdf&#34;&gt;Largest-Triangle-Three-Buckets (LTTB)&lt;/a&gt; 算法，它被调整为在无界流上运行，并提供有状态处理以支持存储。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;完整的下采样算法在 Rust 中实现并作为 Wasm 组件部署在 wasmCloud 中，可报告跨边缘和云平台的主动维护遥测。至关重要的是，该算法通过 Wadm 部署到 wasmCloud，Wadm 是一个与 Kubernetes 无缝集成的 Wasm 组件原生编排器。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Jochen Rau：&lt;em&gt;“Wadm 简化了组件的创建和链接。在这个通用模型中，可以轻松定义您的提供程序以及组件，并生成键值群发消息传递所需的提供程序以及下采样组件，并通过一些链接连接在一起。这对和解很有好处。当我们发布新版本时，它有助于确保一切顺利。”&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;该算法证明可以在 wasmCloud 中运行的边缘设备上将高频数据工作负载作为组件运行。 wasmCloud 还被证明是一种有效的计算网格，可以在部署目标之间无缝移动工作负载。在下一个开发阶段，Schoppe 和 Rau 将在机器上部署 wasmCloud，并开始观察潜在的效率。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXfiGTZTIIDfEganWVi9J0xfYQF_7S2GPe59lkUa3j0EVNVq8JjMYZnmSoyRYee09KASHX95SVN2K8B0rq_GdrWRSl84ukEE9SXjEF _k7_0S5jjL41CsR5RDx5a9YgpujBLDZoIJXu5MCH2Ra-FVzXroURbl?key=7akIfN2LsupSp5m-Be-HvA&#34; alt= “图 2：即使在低采样率下，下采样算法也能保持图形的保真度”referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;图 2：下采样算法即使在低采样率下也能保持图形的保真度采样率&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXdDrMnXScGVx-kcAdKM9EfkDeH0KhIsmsjoJImwnuuJroOEkIxzEBsmT7tdkJKhMW1BPH5br8ASIlynU7aDXRcIeeu7ckEI1N0 7dSh2_lUZyNMPZ0sSAgGhVFBrUJHyrnSC5inTKhgtBaOrcr_OT-zDcNI?key=7akIfN2LsupSp5m-Be-HvA&#34; alt=&#34;图 3：PoC 架构显示 wasmCloud 主机在边缘设备上运行。NATS 作为机器、配置和控制数据的骨干网。&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;图 3：PoC 架构，显示在边缘设备上运行的 wasmCloud 主机。 NATS 充当机器、配置和控制数据的骨干网。&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;wasmCloud 克服了哪些挑战？&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;便携式处理成为现实&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在 wasmCloud 中作为组件运行的应用程序不是将数据移交到云中进行处理，而是要小得多，从而释放资源来直接从机器处理和流式传输性能数据。对于 MachineMetrics 的客户来说，这意味着更低的延迟、更快的价值实现和更少的硬件问题。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这只是故事的一半。该团队的真正优势在于使这些工作负载可移植到&lt;em&gt;任何&lt;/em&gt;位置 - 在多个边缘和云之间轻松来回转移。这使团队可以自由地做出更好、更快的架构决策。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Tyler Schoppe：&lt;em&gt;“强大之处在于我们不必考虑计算所在的位置。 wasmCloud 让开发人员不再考虑这一点，这一点的重要性怎么强调都不为过。如果我们需要做出改变，那么将工作负载从边缘转移到云端会容易得多；例如，如果我们需要扩展。在我们当前的架构中，这对我们来说是非常具有挑战性的。”&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;wasmCloud 还打破了语言障碍。通常，边缘应用程序团队使用与云工程团队不同的首选语言进行工作。无论是用 Python、Go、C++ 还是任何其他语言编写，WASI 0.2 组件都意味着边缘和云团队可以使用标准的 WebAssembly 接口类型 (WIT) 接口定义进行互操作。这将他们从特定的库中解放出来，以便他们可以专注于业务逻辑。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;架构自由 = 资源效率&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在传统的物联网模型中，处理是线性且单向的。数据是从单独的传感器收集的：由边缘捕获，然后摄取到云中（大部分计算发生在云中），然后交给消费者。通过将处理推至云端，会产生更高的成本并增加延迟。更重要的是，有价值、更高效的边缘处理能力没有得到充分利用。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;MachineMetrics 在云中的 Kubernetes 中完成大部分数据处理。通过将计算转移到设备，可以更有效地使用现有边缘资源并保留云资源。在资源之间移植逻辑意味着团队可以根据需求平衡资源。他们使用云来扩展更大数据集的处理，同时允许边缘设备处理实时数据并将其直接传输给运营商。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Jochen Rau：&lt;em&gt;“重点是找到更有效地使用我们已有的边缘资源的方法，并更有效地管理我们的云资源。 wasmCloud 帮助我们做到了这一点。这也是一种平衡——边缘设备相对较小，因此我们可以在云中更轻松地进行扩展。灵活地移动工作负载意味着更高的资源效率。”&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;扩展现有架构的价值&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;MachineMetrics 广泛使用 Kubernetes，但团队无法在边缘运行它。这部分是由于该公司的操作系统配置，但主要是由于 Kubernetes 的限制。 Kubernetes 擅长管理基础设施，但不擅长在资源上运行应用程序资源受限的设备。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;为了解决这个问题，&lt;a href=&#34;https://www.youtube.com/watch?v=fQdkNGZqYZA&#34;&gt;MachineMetrics&lt;/a&gt; 将 wasmCloud 与 Kubernetes 和 ArgoCD 一起使用，利用 &lt;a href= “https://github.com/wasmcloud/wasmcloud-operator&#34;&gt;wasmcloud-operator&lt;/a&gt; 将软件部署到其所有边缘站点。 wasmcloud-operator 允许平台工程师使用标准的、熟悉的控制器模式和自定义资源定义 (CRD) 在 Kubernetes 上管理和运行 Wasm，同时保持与 Kubernetes 的解耦，并自由地利用组件的独特优势。为 Kubernetes 带来以前不可能实现的可扩展性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Rau 说：&lt;em&gt;“我们提升了一个级别：采用 wasmCloud 主机并将其部署在 Kubernetes 上。 wasmcloud-operator 使得使用我们现有的工具来管理变得非常简单。我们将计算工作负载部署在 wasmCloud 上的网格上。我们正在跨越边缘和云之间的界限。”&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;使用这种“解耦”模型意味着 MachineMetrics 可以轻松地将 wasmCloud 直接绑定到现有管道和 ArgoCD 等工具中。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXc1BHaog5GC0UGS5GKpmHHycGimOj8goujL-piBc8wGgHvKwzWAY-ZXD5bEKBY41ZebFql-y0i-amlE-UBNBqB3HGs9i hWsQRwNB4w2wdtJad-fy1UJ6rhtCr_EIhKW6Q0RAUulz5KD7OPGPC_denwcew？ key=7akIfN2LsupSp5m-Be-HvA&#34; alt=&#34;图 4：wasmCloud 与 Kubernetes 集成，但作为一项单独的服务。这意味着工程师可以利用组件模型的优势。  &#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class= &#34;wp-element-caption&#34;&gt;图 4：wasmCloud 与 Kubernetes 集成，但作为单独的服务。这意味着工程师可以利用组件模型的优势。 &lt;/图标题&gt;&lt;/图&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;默认拒绝安全&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;安全性也是 MachineMetrics 的一个主要考虑因素。每个客户都有完全不同的安全方法。有些拥有大型、专门的安全团队，而另一些则可能采用更精简的方法。在每种情况下，数据都高度敏感 - MachineMetrics 必须为每个用例带来相同的铸铁安全性，并且必须能够将相同级别的安全性扩展到设备和传感器。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;WebAssembly 的强大功能允许 wasmCloud 应用程序从边缘到边缘安全地运行。所有代码都在默认拒绝、安全、无状态和反应式沙箱中运行。该沙箱可以满足较大客户的企业服务级别协议以及更复杂的安全性、合规性和策略要求。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Tyler Schoppe：&lt;em&gt;“我们与夫妻店合作生产螺丝，一直到计划用于外太空的硬件。无论他们的安全程度如何，我们都会同等程度地对待他们的安全。 wasmCloud的沙盒模型给了我们很多保证。就开发人员的安心而言，它提供了对我们来说有很多开箱即用的东西。&lt;/em&gt;”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;wasmCloud 的主机强制执行一定程度的默认安全性，且不能放松。例如，主机将始终验证运行时链接。此外，wasmCloud 策略服务 API 可用于扩展和自定义策略评估，例如通过限制特定主机上不受信任的应用程序组件和提供程序。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;给制造商带来的好处&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;该团队相信，能够直接从机器处理和传输高速数据的好处将使从小商店到大型工厂的客户兴奋不已。硬质合金刀具非常昂贵——每台机器花费数千美元——因此正确管理它们的利用率至关重要。损坏的工具不仅更换成本昂贵，而且还可能毁掉整条生产线。通过更密切的监控来延长工具的使用寿命将为客户节省数千美元的维护和更换费用。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;对于 Rau 来说，令人兴奋的部分是能够提供客户一直在等待的功能。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Rau：&lt;em&gt;“下采样的高频数据与原始数据一样具有表现力；我们正在超越聚合监控数据，转而能够在仪表板上查看实时、高速的数据。这是我们的客户所要求的。”&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Rau 和 Schoppe 现在正在利用从 PoC 中学到的知识，进一步开发解决方案并研究与第三方机器集成的方法。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Schoppe 总结道：&lt;em&gt;“目前市场上还没有这样的产品，因此这是我们将这种计算能力交到更多客户手中的绝佳机会。除了帮助我们脱颖而出之外，它还将为客户提供巨大的运营价值——他们可以依靠它以不同的方式节省资金。”&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Thu, 22 Aug 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【A guide to modern Kubernetes network policies】现代 Kubernetes 网络策略指南</title>
      <link>https://www.cncf.io/blog/2024/08/28/__trashed-5/</link>
      <description>【&lt;p&gt;&lt;em&gt;Member post originally published on &lt;a href=&#34;https://buoyant.io/blog/a-guide-to-modern-kubernetes-network-policies&#34;&gt;Bouyant’s blog&lt;/a&gt; by Scott Rigby&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In the world of Kubernetes, network policies are essential for controlling traffic within your cluster. But what are they really? And why, when and how should you implement them?&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Whether you’re an existing Kubernetes user and want to better understand networking, or a traditional network engineer trying to map your knowledge to Kubernetes, you’ve come to the right place.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This guide is for anyone interested in learning more about policy-based controls for your Kubernetes network traffic. You will learn about the different types of policies and why they matter, the pros and cons of each, how to define them, and when to combine them.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;What are network policies?&amp;nbsp;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Network policies help define which traffic is allowed to enter (ingress), exit (egress), and move between pods in a Kubernetes cluster.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Just like other resources in Kubernetes, network policies are declarative configurations that components within the cluster will use to enforce which traffic is allowed or denied and under what circumstances.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;But once you decide what policies you want to enforce, and it comes time to define them in a Kubernetes resource manifest, you’re met with several options. There is the Kubernetes native NetworkPolicy resource, but there are also other custom resources defined by other tools in the ecosystem, such as Cilium, Calico, Istio, and – our focus in this article – Linkerd. Rather than comparing and contrasting the individual tools and options, we’re going to take a step back and explain the two main categories that each of these different policy definitions fall into.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Broadly, network policies can be categorized into Layer 4 (L4) and Layer 7 (L7) policies. What does this mean? I know what you’re thinking, the 7-layer burrito! Close, but no. These refer to the seven layers of The Open Systems Interconnection (OSI) model.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;(Fun fact: the 7-layer burrito’s inspiration was the 7-layer dip, which was widely popular in the 1980s, but made its debut less than a year after the OSI model was published in 1980. Coincidence? I’ll leave the reader with evidence from internet history, including&amp;nbsp;&lt;a href=&#34;https://web.archive.org/web/19990826193318/http://www.europa.com/~dogman/osi/&#34;&gt;the original OCI is a sham rant&lt;/a&gt;, an&amp;nbsp;&lt;a href=&#34;https://datatracker.ietf.org/doc/html/draft-lohsen-ip-burrito-00&#34;&gt;IEFT networking RFC proposal&lt;/a&gt;, and this&amp;nbsp;&lt;a href=&#34;https://xkcd.com/1417/&#34;&gt;small nod hidden in xkcd&lt;/a&gt;).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://cdn.prod.website-files.com/627a84f19cfe42b2c96f2416/66c6067cfae5f2701da451dc_66c6061da6bbbba3d8044f1b_OSI%2520Model.png&#34; alt=&#34;screenshot of the OSI model layer architecture table on Wikipedia&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;The OSI model of networking depicted as a 7-layer burrito (&lt;a href=&#34;https://images.app.goo.gl/dJLKcVTALii589f28&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;source&lt;/a&gt;)&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The OSI model breaks down networking communication into 7 layers. While the OSI model might be somewhat dated – it has been stated many times that the internet doesn’t really work this way – layers 4 and 7 remain a useful reference for our purposes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The term “L4” refers to the fourth layer of the OSI model – the transport layer, encompassing protocols like TCP. “L7” corresponds to the (you guessed it!) seventh OSI layer – application-level communication, which includes HTTP, gRPC, and other application-specific protocols. In the context of Kubernetes network policies, L4 policies operate at the cluster level, while L7 policies application level. Much like the OSI layers themselves, L4 and L7 network policies are intended to work in tandem.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This guide will explore both types, covering how they are defined, their advantages and limitations, and their role in achieving a zero-trust security model.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;L4 network policies&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Layer 7 network policies operate at the application layer, understanding protocols such as HTTP and gRPC. Unlike L4 policies, L7 policies allow for more granular control, such as permitting “Service A to call the /foo/bar endpoint of Service B,” or “Service B will only talk to mTLS’d Services.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;How L4 network policies work&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;L4 policies are implemented by CNI plugins to configure the kernel’s packet filter – for example using Netfilter/iptables or eBPF – targeting IP addresses and port numbers corresponding to the pods in different services. For example, if you want to implement a policy where “Service A cannot call Service B on port 8080,” the system manages these rules dynamically as services and their corresponding pods change. This is done by targeting namespaces or pods by their label, using podSelector.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Here is a simple L4 network policy example, defining that only TCP traffic from service-a is allowed to port 8080 on pods in service-b. As soon as a NetworkPolicy with “Ingress” in its policyTypes is created that selects pods in service-b, those pods are considered “isolated for Ingress”. This means that only inbound traffic matching the combination of all ingress lists will be allowed. Reply traffic to those allowed connections is implicitly allowed. There are more options including explicit egress rules outlined in the&amp;nbsp;&lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/network-policies/&#34;&gt;Network Policies&lt;/a&gt;&amp;nbsp;concept page in Kubernetes docs, but we only need this simple example to explain the overall function of L4 policies in Kubernetes:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;apiVersion: networking.k8s.io/v1&#xA;kind: NetworkPolicy&#xA;metadata:&#xA;  name: service-a-to-b&#xA;  namespace: default&#xA;spec:&#xA;  podSelector:&#xA;    matchLabels:&#xA;      app: service-b&#xA;  policyTypes:&#xA;  - Ingress&#xA;  ingress:&#xA;  - from:&#xA;    - podSelector:&#xA;        matchLabels:&#xA;          app: service-a&#xA;    ports:&#xA;    - protocol: TCP&#xA;      port: 8080&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Pros and cons of L4 network policies&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Pros:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Built into most CNI plugins, making them readily available.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Cons:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Limited to expressing policies in terms of pod labels and ports, lacking granularity for specific routes or service names.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Limitated in the types of rules they can express—for example, cannot require all traffic go through a common gateway.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;No logging of security events is possible.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Vulnerable to “split brain” scenarios, where the mapping between pods and IP addresses can diverge, potentially allowing unauthorized access.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;IP addresses and ports can be spoofed, leading to potential security breaches. Modern security paradigms have moved beyond these simple constructs.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;When should I use L4 network policies?&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;L4 network policies have the advantage of being simple to understand and widely available in Kubernetes. However, given the (minor, but not insignificant) security weaknesses, lack of expressivity, and inability to log security events, L4 policies fall into the category of “necessary but not sufficient” controls, and should ultimately be combined with other controls (e.g. L7 network policies) as your security posture matures.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;L7 network policies&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Layer 7 network policies operate at the application layer, understanding protocols such as HTTP and gRPC. Unlike L4 policies, L7 policies can make use of the service name directly, and allow for policies such as “Service A is allowed to talk to Service B”, or “Service B will only talk to mTLS’d Services”. These policies also allow for more granular control, such as permitting “Service A to call the /foo/bar endpoint of Service B.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Implementing L7 policies with Linkerd&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In Kubernetes, L7 policies are typically implemented via a service mesh like Linkerd, and represented as&amp;nbsp;&lt;a href=&#34;https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/&#34;&gt;Custom Resources&lt;/a&gt;&amp;nbsp;such as&amp;nbsp;&lt;strong&gt;&lt;em&gt;Server.policy.linkerd.io&lt;/em&gt;&lt;/strong&gt;. Linkerd proxies HTTP and gRPC calls, understanding these protocols, and enforces policies accordingly. For more details, refer to&lt;a href=&#34;https://linkerd.io/2.15/features/server-policy/&#34;&gt;&amp;nbsp;Linkerd’s server policy documentation&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;How L7 policies work&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Linkerd enforces policies on the server side, meaning the proxies for Service A protect access to it, regardless of the caller. These policies are based on the service identities established during mutual TLS (mTLS), ensuring that IP addresses are ignored in favor of cryptographic properties of the connection. This method is designed to work seamlessly in distributed systems, similar to the open internet where coordination between systems is unreliable.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;It’s important to note that Linkerd has two types of policies: Default and Dynamic.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Default policies are set when installing or upgrading Linkerd. These policies let you allow or disallow traffic depending on whether the clients are within your service mesh, or within the same cluster (this last check is useful if, for example, you have a mesh that spans multiple clusters). There is also a policy to deny all traffic. Unless one of these policies are specified, all traffic is allowed (so the world doesn’t break when you install Linkerd!). You may also override this policy per namespace, and workload if desired. You can read more about&amp;nbsp;&lt;a href=&#34;https://linkerd.io/2.15/reference/authorization-policy/#default-policies&#34;&gt;default policies here&lt;/a&gt;, but for this article it’s enough to know these exist and work in tandem with Dynamic policies.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Dynamic policies, unlike Default policies, allow you to change policy behavior on the fly by updating the Custom Resources that control these policies. Dynamic policies are also called “fine-grained” policies, because they can control traffic for specific services, ports, routes, and more. In contrast to the single L4&amp;nbsp;&lt;strong&gt;&lt;em&gt;NetworkPolicy.networking.k8s.io&amp;nbsp;&lt;/em&gt;&lt;/strong&gt;resource, Linkerd Dynamic policies are represented by multiple CRDs in order to allow finer grained rules, and less repetition through reuse for multiple, related policies.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;One set of CRDs allow you to specify the destination for traffic you want to target (either a&amp;nbsp;&lt;strong&gt;&lt;em&gt;Server&lt;/em&gt;&lt;/strong&gt;, or a subset of it’s traffic called&amp;nbsp;&lt;strong&gt;&lt;em&gt;HTTPRoute&lt;/em&gt;&lt;/strong&gt;). Another set of CRDs represent authentication rules (either mesh identities with&amp;nbsp;&lt;strong&gt;&lt;em&gt;MeshTLSAuthentication&lt;/em&gt;&lt;/strong&gt;, or a set of IP subnets that clients must be part of called&amp;nbsp;&lt;strong&gt;&lt;em&gt;NetworkAuthentication&lt;/em&gt;&lt;/strong&gt;), which must be satisfied as part of a policy. And finally there is a CRD representing the&amp;nbsp;&lt;strong&gt;&lt;em&gt;AuthorizationPolicy&lt;/em&gt;&lt;/strong&gt;&amp;nbsp;itself, which maps a Custom resource from the first set of CRDs (a traffic target to be protected), to one of the second type of CRDs (the authentication required before access to the target is allowed).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Here are the example Custom Resources for a Linkerd L7 equivalent to the single L4 example resource above – a&amp;nbsp;&lt;strong&gt;&lt;em&gt;Server&lt;/em&gt;&lt;/strong&gt;, a&amp;nbsp;&lt;strong&gt;&lt;em&gt;MeshTLSAuthentication&lt;/em&gt;&lt;/strong&gt;, and the&amp;nbsp;&lt;strong&gt;&lt;em&gt;AuthorizationPolicy&lt;/em&gt;&lt;/strong&gt;&amp;nbsp;that references them:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The traffic destination:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;apiVersion: policy.linkerd.io/v1beta1&#xA;kind: Server&#xA;metadata:&#xA;  name: service-b&#xA;  namespace: default&#xA;spec:&#xA;  podSelector:&#xA;    matchLabels:&#xA;      app: service-a&#xA;  port: 8080&#xA;  proxyProtocol: &#34;HTTP/2&#34;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The authN rules:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;apiVersion: policy.linkerd.io/v1alpha1&#xA;kind: MeshTLSAuthentication&#xA;metadata:&#xA;  name: service-a&#xA;  namespace: default&#xA;spec:&#xA;  identityRefs:&#xA;    - kind: ServiceAccount&#xA;      name: service-a&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The authZ policy:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;apiVersion: policy.linkerd.io/v1alpha1&#xA;kind: AuthorizationPolicy&#xA;metadata:&#xA;  name: service-a-to-b&#xA;  namespace: default&#xA;spec:&#xA;  targetRef:&#xA;    group: policy.linkerd.io&#xA;    kind: Server&#xA;    name: service-b&#xA;  requiredAuthenticationRefs:&#xA;    - name: service-a&#xA;      kind: MeshTLSAuthentication&#xA;      group: policy.linkerd.io&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;There are many more options you can see in&amp;nbsp;&lt;a href=&#34;https://linkerd.io/2.15/reference/authorization-policy/&#34;&gt;Linkerd’s Authorization Policy&lt;/a&gt;&amp;nbsp;docs page, but this gives you a sense of the granularity, flexibility, and reusability of Linkerd’s L7 policy equivalent of the earlier L4 NetworkPolicy example.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Pros and cons of L7 network policies&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Pros:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Allows for fine-grained policies, such as “only allow encrypted connections with mTLS” and “only allow Foo to call /bar.”&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Not susceptible to split-brain scenarios.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Combines with mutual TLS to also provide authentication and encryption.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Can provide logging of security events such as (attempted) policy violations.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Cons:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Requires running a service mesh, as it is not built into Kubernetes natively.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Policies will not apply to traffic sent to unmeshed workloads (even if the source workloads are meshed).&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Policies will not apply to UDP or other non-TCP traffic.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Combining L7 and L4 policies&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Some use cases are best solved by L4 policies, while others are best solved by L7 policies. Luckily you don’t need to choose one or the other! You can implement both types of policies in your cluster at the same time. The pros and cons above will help you determine when to use each type of policy.&lt;br&gt;&lt;br&gt;As mentioned above – when you need to enforce policy about communication to any unmeshed resource, you would choose an L4 policy. Similarly, you would use L4 if you need to enforce cluster-wide policies regardless of individual workloads meshed status.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;You may also have requirements not supported by the current version of your installed service mesh. Linkerd introduced support for IPv6 in version 2.16 and earlier versions don’t support IPv6-specific policies.&amp;nbsp; Some requirements may not be supported by any version of your service mesh yet. For example, Linkerd policies do not support UDP or non-TCP traffic at all yet, because a clear use case for this&amp;nbsp;&lt;a href=&#34;https://github.com/linkerd/linkerd2/issues/4723#issuecomment-1984092126&#34;&gt;has not yet been established&lt;/a&gt;. Please let us know if you want to contribute to defining this use case. You may also want to follow that issue for updates. In the meantime, an L4 policy is a good option here.&lt;br&gt;&lt;br&gt;L7 policies on the other hand allow for more complex scenarios that require more granular control, opening up many more use cases. You can create allow or deny rules for specific clients, for access to individual workload endpoints, checks for whether or not there is an encrypted mTLS connection, for specific network authentication, for whether clients are meshed, or meshed within the same cluster, and many other options.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Finally, there is a use case for combining L7 and L4 policies with overlapping functionality, in order to create a more robust security framework. This belt-and-suspenders approach can leverage the strengths of both layers to enhance security. Using the examples above, you can explore combining L4 and L7 policies by defining BOTH the Linkerd&amp;nbsp;&lt;strong&gt;&lt;em&gt;Server&lt;/em&gt;&lt;/strong&gt;&amp;nbsp;Authorization policy AND the Kubernetes&amp;nbsp;&lt;strong&gt;&lt;em&gt;NetworkPolicy&lt;/em&gt;&lt;/strong&gt;&amp;nbsp;to restrict all network communication with the same service (&lt;strong&gt;&lt;em&gt;service-b&lt;/em&gt;&lt;/strong&gt;) to only your specified client service (&lt;strong&gt;&lt;em&gt;service-a&lt;/em&gt;&lt;/strong&gt;). Combining network policies across multiple layers like this is an example of the&amp;nbsp;&lt;a href=&#34;https://csrc.nist.gov/glossary/term/defense_in_depth&#34;&gt;defense in depth&lt;/a&gt;&amp;nbsp;security strategy, which recommends providing redundancy in the event of one security control failing.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Conclusion&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Network policies are a fundamental aspect of securing Kubernetes clusters. L4 policies provide basic control over traffic based on IP addresses and ports, while L7 policies offer granular control over application-layer traffic based on strong cryptographic identity. By combining both types of policies and leveraging a service mesh like Linkerd, you can implement a robust, zero-trust security model that addresses modern security challenges.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Want to give Linkerd a try? You can download and run the production-ready&amp;nbsp;&lt;a href=&#34;https://docs.buoyant.io/buoyant-enterprise-linkerd/latest/overview/&#34;&gt;Buoyant Enterprise for Linkerd&lt;/a&gt;&amp;nbsp;in minutes. Get started today!&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;成员帖子最初由 Scott Rigby 发布在 &lt;a href=&#34;https://buoyant.io/blog/a-guide-to-modern-kubernetes-network-policies&#34;&gt;Bouyant 博客&lt;/a&gt;上&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在 Kubernetes 领域，网络策略对于控制集群内的流量至关重要。但它们到底是什么？为什么、何时以及如何实施它们？&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;无论您是想要更好地了解网络的现有 Kubernetes 用户，还是试图将您的知识映射到 Kubernetes 的传统网络工程师，您都来对地方了。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;本指南适用于有兴趣了解有关 Kubernetes 网络流量基于策略的控制的更多信息的任何人。您将了解不同类型的政策及其重要性、每种政策的优缺点、如何定义它们以及何时组合它们。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;什么是网络政策？ &lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;网络策略帮助定义允许哪些流量进入​​（入口）、退出（出口）以及在 Kubernetes 集群中的 Pod 之间移动。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;就像 Kubernetes 中的其他资源一样，网络策略是声明性配置，集群内的组件将使用它来强制允许或拒绝哪些流量以及在什么情况下允许或拒绝哪些流量。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;但是，一旦您决定要执行哪些策略，并且需要在 Kubernetes 资源清单中定义它们，您就会遇到多种选择。有 Kubernetes 原生 NetworkPolicy 资源，但也有生态系统中其他工具定义的其他自定义资源，例如 Cilium、Calico、Istio 以及我们本文重点关注的 Linkerd。我们不会比较和对比各个工具和选项，而是退一步解释这些不同政策定义所属的两个主要类别。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;广义上，网络策略可分为第 4 层 (L4) 和第 7 层 (L7) 策略。这意味着什么？我知道你在想什么，七层墨西哥卷饼！接近，但没有。这些指的是开放系统互连 (OSI) 模型的七层。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;（有趣的事实：7 层墨西哥卷饼的灵感来自 7 层浸，它在 20 世纪 80 年代广泛流行，但在 1980 年 OSI 模型发布不到一年后首次亮相。巧合？我会为读者留下互联网历史的证据，包括&lt;a href=&#34;https://web.archive.org/web/199​​90826193318/http://www.europa.com/~dogman/osi/&#34;&gt;原始 OCI 是虚假的咆哮&lt;/a&gt;，&lt;a href=&#34;https://datatracker.ietf.org/doc/html/draft-lohsen-ip-burrito-00&#34;&gt;IEFT 网络 RFC 提案&lt;/a&gt;，以及这个&lt;a href=&#34;https://xkcd.com/1417/&#34;&gt;xkcd 中隐藏的小点头&lt;/a&gt;）。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://cdn.prod.website-files.com/627a84f19cfe42b2c96f2416/66c6067cfae5f2701da451dc_66c6061da6bbbba3d8044f1b_OSI%2520Model.png&#34; alt=&#34;屏幕截图的维基百科上的 OSI 模型层架构表”参考errerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;OSI 网络模型被描述为 7 层墨西哥卷饼 (&lt;a href=&#34;https://images.app.goo.gl/ dJLKcVTALii589f28&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;来源&lt;/a&gt;)&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;OSI 模型将网络通信分为 7 层。虽然 OSI 模型可能有些过时——人们已经多次说过，互联网实际上并不是这样工作的——第 4 层和第 7 层仍然是我们目的的有用参考。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;术语“L4”指的是 OSI 模型的第四层——传输层，包含 TCP 等协议。 “L7”对应于（您猜对了！）OSI 第七层——应用程序级通信，其中包括 HTTP、gRPC 和其他特定于应用程序的协议。在 Kubernetes 网络策略的上下文中，L4 策略在集群级别运行，而 L7 策略在应用程序级别运行。与 OSI 层本身非常相似，L4 和 L7 网络策略旨在协同工作。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;本指南将探讨这两种类型，包括它们的定义方式、它们的优点和局限性，以及它们在实现零信任安全模型中的作用。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;L4 网络策略&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;第 7 层网络策略在应用层运行，了解 HTTP 和 gRPC 等协议。与 L4 策略不同，L7 策略允许更精细的控制，例如允许“服务 A 调用服务 B 的 /foo/bar 端点”或“服务 B 只会与 mTLS 的服务通信。”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;L4 网络策略如何运作&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;L4 策略由 CNI 插件实现，用于配置内核的数据包过滤器（例如使用 Netfilter/iptables 或 eBPF），针对不同服务中 pod 对应的 IP 地址和端口号。例如，如果您想要实施“服务 A 无法在端口 8080 上调用服务 B”的策略，则系统会随着服务及其相应 pod 的变化动态管理这些规则。这是通过使用 podSelector 按名称空间或 pod 的标签定位来完成的。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这是一个简单的 L4 网络策略示例，定义仅允许来自 service-a 的 TCP 流量到达 service-b 中 pod 上的端口 8080。一旦创建了策略类型中包含“Ingress”的 NetworkPolicy，该策略选择了 service-b 中的 pod，这些 pod 就会被视为“针对 Ingress 隔离”。这意味着仅允许与所有入口列表的组合匹配的入站流量。对那些允许的连接的回复流量是隐式允许的。还有更多选项，包括 Kubernetes 文档中的&lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/network-policies/&#34;&gt;网络策略&lt;/a&gt;概念页面中概述的显式出口规则，但我们只需要这个简单的例子来解释 Kubernetes 中 L4 策略的整体功能：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;api版本：networking.k8s.io/v1&#xA;种类：网络策略&#xA;元数据：&#xA;  名称：服务 A 到 B&#xA;  命名空间：默认&#xA;规格：&#xA;  pod选择器：&#xA;    匹配标签：&#xA;      应用程序：服务-b&#xA;  政策类型：&#xA;  - 入口&#xA;  入口：&#xA;  - 从：&#xA;    - pod选择器：&#xA;        匹配标签：&#xA;          应用程序：服务-a&#xA;    端口：&#xA;    - 协议：TCP&#xA;      端口：8080&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;L4 网络策略的优缺点&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;优点：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;内置于大多数 CNI 插件中，使其易于使用。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;缺点：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;仅限于用 Pod 标签和端口来表达策略，缺乏特定路由或服务名称的粒度。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;它们可以表达的规则类型有限 - 例如，不能要求所有流量都通过公共网关。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;无法记录安全事件。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;容易受到“裂脑”场景的影响，其中 Pod 和 IP 地址之间的映射可能会出现分歧，从而可能导致未经授权的访问。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;IP 地址和端口可能被欺骗，从而导致潜在的安全漏洞。现代安全范例已经超越了这些简单的构造。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;什么时候应该使用 L4 网络策略？&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;L4 网络策略的优点是易于理解且在 Kubernetes 中广泛可用。然而，考虑到（次要但并非无关紧要的）安全弱点、缺乏表达性以及无法记录安全事件，L4 策略属于“必要但不充分”控制类别，最终应与其他控制措施（例如随着您的安全状况的成熟，L7 网络策略）。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;L7 网络策略&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;第 7 层网络策略在应用层运行，了解 HTTP 和 gRPC 等协议。与 L4 策略不同，L7 策略可以直接使用服务名称，并允许诸如“服务 A 允许与服务 B 对话”或“服务 B 只会与 mTLS 服务对话”等策略。这些策略还允许更精细的控制，例如允许“服务 A 调用服务 B 的 /foo/bar 端点。”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;使用 Linkerd 实施 L7 策略&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在 Kubernetes 中，L7 策略通常通过 Linkerd 等服务网格实现，并表示为 &lt;a href=&#34;https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/ &#34;&gt;自定义资源&lt;/a&gt;，例如&lt;strong&gt;&lt;em&gt;Server.policy.linkerd.io&lt;/em&gt;&lt;/strong&gt;。 Linkerd 代理 HTTP 和 gRPC 调用，了解这些协议并相应地执行策略。有关更多详细信息，请参阅&lt;a href=&#34;https://linkerd.io/2.15/features/server-policy/&#34;&gt;Linkerd 的服务器策略文档&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;L7 政策如何运作&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Linkerd 在服务器端强制执行策略，这意味着服务 A 的代理会保护对其的访问，无论调用者是谁。这些策略基于双向 TLS (mTLS) 期间建立的服务身份，确保忽略 IP 地址以支持连接的加密属性。这种方法旨在在分布式系统中无缝工作，类似于系统之间协调不可靠的开放互联网。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;需要注意的是，Linkerd 有两种类型的策略：默认策略和动态策略。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;默认策略是在安装或升级 Linkerd 时设置的。这些策略允许您根据客户端是否位于服务网格内或同一集群内来允许或禁止流量（例如，如果您有一个跨越多个集群的网格，则最后一项检查很有用）。还有一项拒绝所有流量的策略。除非指定这些策略之一，否则所有流量都是允许的（因此当您安装 Linkerd 时世界不会崩溃！）。如果需要，您还可以根据命名空间和工作负载覆盖此策略。您可以在此处详细了解&lt;a href=&#34;https://linkerd.io/2.15/reference/authorization-policy/#default-policies&#34;&gt;默认政策&lt;/a&gt;，但对于本文来说，了解这些政策的存在就足够了并与动态策略协同工作。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;与默认策略不同，动态策略允许您通过更新控制这些策略的自定义资源来动态更改策略行为。动态策略也称为“细粒度”策略，因为它们可以控制特定服务、端口、路由等的流量。与单个 L4 NetworkPolicy.networking.k8s.io 资源相比，Linkerd 动态策略由多个 CRD 表示，以便允许更细粒度的规则，并通过重用减少重复多个相关政策。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;通过一组 CRD，您可以指定要定位的流量的目的地（&lt;strong&gt;&lt;em&gt;服务器&lt;/em&gt;&lt;/strong&gt;，或其流量的子集&lt;strong&gt;&lt;em&gt; &gt;HTTPRoute&lt;/em&gt;&lt;/strong&gt;）。另一组 CRD 表示身份验证规则（具有 &lt;strong&gt;&lt;em&gt;MeshTLSAuthentication&lt;/em&gt;&lt;/strong&gt; 的网格身份，或者客户端必须属于的一组 IP 子网，称为&lt;strong&gt;&lt;em&gt;NetworkAuthentication&lt;/ em&gt;&lt;/strong&gt;），必须作为策略的一部分得到满足。最后有一个代表授权策略本身的 CRD，它将自定义资源从第一组 CRD（要保护的流量目标）映射到第二组 CRD 中的一个CRD 类型（允许访问目标之前所需的身份验证）。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;以下是 Linkerd L7 的示例自定义资源，相当于上面的单个 L4 示例资源 – 一个&lt;strong&gt;&lt;em&gt;服务器&lt;/em&gt;&lt;/strong&gt;、一个&lt;strong&gt;&lt;em&gt;MeshTLSAuthentication&lt;/em &gt;&lt;/strong&gt;，以及引用它们的&lt;strong&gt;&lt;em&gt;AuthorizationPolicy&lt;/em&gt;&lt;/strong&gt;：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;TRaffic目的地：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;api版本：policy.linkerd.io/v1beta1&#xA;种类：服务器&#xA;元数据：&#xA;  名称：服务-b&#xA;  命名空间：默认&#xA;规格：&#xA;  pod选择器：&#xA;    匹配标签：&#xA;      应用程序：服务-a&#xA;  端口：8080&#xA;  代理协议：“HTTP/2”&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;授权规则：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;api版本：policy.linkerd.io/v1alpha1&#xA;种类：MeshTLS身份验证&#xA;元数据：&#xA;  名称：服务-a&#xA;  命名空间：默认&#xA;规格：&#xA;  身份参考：&#xA;    - 种类：服务帐户&#xA;      名称：服务-a&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;authZ 策略：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;api版本：policy.linkerd.io/v1alpha1&#xA;种类：授权策略&#xA;元数据：&#xA;  名称：服务 A 到 B&#xA;  命名空间：默认&#xA;规格：&#xA;  目标参考：&#xA;    组：policy.linkerd.io&#xA;    种类：服务器&#xA;    名称：服务-b&#xA;  所需身份验证参考：&#xA;    - 名称：服务-a&#xA;      种类：MeshTLS身份验证&#xA;      组：policy.linkerd.io&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;您可以在 &lt;a href=&#34;https://linkerd.io/2.15/reference/authorization-policy/&#34;&gt;Linkerd 的授权政策&lt;/a&gt;文档页面中看到更多选项，但这为您提供了Linkerd 的 L7 策略的粒度、灵活性和可重用性相当于早期的 L4 NetworkPolicy 示例。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;L7 网络策略的优缺点&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;优点：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;允许细粒度的策略，例如“仅允许使用 mTLS 的加密连接”和“仅允许 Foo 调用 /bar”。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;不易受到裂脑情况的影响。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;与双向 TLS 结合还可以提供身份验证和加密。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;可以提供安全事件日志记录，例如（尝试的）政策违规行为。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;缺点：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;需要运行服务网格，因为它本身并未内置于 Kubernetes 中。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;政策不适用于发送到未网格化工作负载的流量（即使源工作负载已网格化）。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;政策不适用于 UDP 或其他非 TCP 流量。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;结合 L7 和 L4 策略&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;一些用例最好通过 L4 策略解决，而其他用例最好通过 L7 策略解决。幸运的是，您不需要选择其中之一！您可以在集群中同时实施这两种类型的策略。上述优点和缺点将帮助您确定何时使用每种类型的策略。&lt;br&gt;&lt;br&gt;如上所述 - 当您需要强制执行有关与任何非网格资源的通信的策略时，您将选择 L4 策略。同样，如果您需要强制执行集群范围内的策略，无论各个工作负载的网格状态如何，您都可以使用 L4。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;您可能还有当前安装的服务网格版本不支持的要求。 Linkerd 在 2.16 版本中引入了对 IPv6 的支持，早期版本不支持 IPv6 特定的策略。  有些要求可能不符合任何版本的服务网格都支持。例如，Linkerd 策略根本不支持 UDP 或非 TCP 流量，因为有一个明确的用例&lt;a href=&#34;https://github.com/linkerd/linkerd2/issues/4723#issuecomment-1984092126&#34; &gt;尚未确定&lt;/a&gt;。如果您想为定义此用例做出贡献，请告诉我们。您可能还想关注该问题以获取更新。与此同时，L4 策略是一个不错的选择。&lt;br&gt;&lt;br&gt;另一方面，L7 策略允许需要更精细控制的更复杂的场景，从而开辟更多用例。您可以为特定客户端创建允许或拒绝规则、访问各个工作负载端点、检查是否存在加密的 mTLS 连接、特定网络身份验证、客户端是否网格化或在同一集群内网格化等等。其他选项。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;最后，有一个将 L7 和 L4 策略与重叠功能相结合的用例，以创建更强大的安全框架。这种腰带和吊带方法可以利用两层的优势来增强安全性。使用上面的示例，您可以通过定义 Linkerd 服务器授权策略和 Kubernetes NetworkPolicy 来探索组合 L4 和 L7 策略&lt;strong&gt;&lt;em&gt;服务器&lt;/em&gt;&lt;/strong&gt;&lt; /strong&gt; 将与同一服务 (&lt;strong&gt;&lt;em&gt;service-b&lt;/em&gt;&lt;/strong&gt;) 的所有网络通信仅限于您指定的客户端服务 (&lt;strong&gt;&lt;em&gt;service-a&lt;/em&gt; &gt;&lt;/strong&gt;）。像这样组合跨多个层的网络策略是&lt;a href=&#34;https://csrc.nist.gov/glossary/term/defense_in_depth&#34;&gt;深度防御&lt;/a&gt;安全策略的一个示例，该策略建议在一个安全控制失败的事件。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;结论&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;网络策略是保护 Kubernetes 集群的一个基本方面。 L4 策略基于 IP 地址和端口提供对流量的基本控制，而 L7 策略基于强加密身份提供对应用层流量的精细控制。通过结合这两种类型的策略并利用 Linkerd 等服务网格，您可以实现强大的零信任安全模型来应对现代安全挑战。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;想尝试 Linkerd 吗？您可以在几分钟内下载并运行生产就绪的&lt;a href=&#34;https://docs.buoyant.io/buoyant-enterprise-linkerd/latest/overview/&#34;&gt;Buoyant Enterprise for Linkerd&lt;/a&gt;。今天就开始吧！&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Tue, 27 Aug 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Building a translation agent on LlamaEdge】在 LlamaEdge 上构建翻译代理</title>
      <link>https://www.cncf.io/blog/2024/08/26/building-a-translation-agent-on-llamaedge/</link>
      <description>【&lt;p&gt;&lt;em&gt;Member post originally published on &lt;a href=&#34;https://www.secondstate.io/articles/translation-agent/&#34;&gt;Second State’s blog&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Prof. Andrew Ng’s&amp;nbsp;&lt;a href=&#34;https://www.linkedin.com/posts/andrewyng_github-andrewyngtranslation-agent-activity-7206347897938866176-5tDJ/&#34;&gt;agentic translation&lt;/a&gt;&amp;nbsp;is a great demonstration on how to coordinate multiple LLM “agents” to work on a single task. It allows multiple smaller LLMs (like Llama-3 or Gemma-2) to work gether and produce better results than a single large LLM (like ChatGPT).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The&amp;nbsp;&lt;a href=&#34;https://github.com/andrewyng/translation-agent&#34;&gt;translation agent&lt;/a&gt;&amp;nbsp;is a great fit for&amp;nbsp;&lt;a href=&#34;https://github.com/LlamaEdge/LlamaEdge&#34;&gt;LlamaEdge&lt;/a&gt;, which provides a&amp;nbsp;&lt;a href=&#34;https://llamaedge.com/docs/llamaedge_vs_python&#34;&gt;lightweight&lt;/a&gt;,&amp;nbsp;&lt;a href=&#34;https://llamaedge.com/docs/llamaedge_vs_ollama&#34;&gt;embeddable&lt;/a&gt;,&amp;nbsp;&lt;a href=&#34;https://llamaedge.com/docs/llamaedge_vs_llamacpp&#34;&gt;portable&lt;/a&gt;, and&amp;nbsp;&lt;a href=&#34;https://github.com/LlamaEdge/LlamaEdge/blob/main/docker/README.md&#34;&gt;Docker-native&lt;/a&gt;&amp;nbsp;AI runtime for&amp;nbsp;&lt;a href=&#34;https://llamaedge.com/docs/llamaedge_vs_llamacpp&#34;&gt;many different&lt;/a&gt;&amp;nbsp;types of models and hardware accelerators. With LlamaEdge, you can build and distribute translation apps with embedded LLMs and prompts that can run on edge devices.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://www.secondstate.io/articles/translation-agent.png&#34; alt=&#34;Image&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;introduction-to-the-llm-translation-agent&#34;&gt;&lt;a href=&#34;https://www.secondstate.io/articles/translation-agent/#introduction-to-the-llm-translation-agent&#34;&gt;Introduction to the LLM Translation Agent&lt;/a&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This LLM Translation Agent is designed to facilitate accurate and efficient translation across multiple languages. It employs open source LLMs (Large Language Models) to provide high-quality translations. You can use your own fine-tuned models or any LLMs on Hugging Face like Meta’s Llama 3.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p&gt;For detailed commands on starting and running this agent, please visit&amp;nbsp;&lt;a href=&#34;https://github.com/second-state/translation-agent/blob/use_llamaedge/step-by-step-use-LocalAI.md&#34;&gt;GitHub – Second State/translation-agent&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To get started, clone the Translation Agent.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;git clone https://github.com/second-state/translation-agent.git&#xA;    &#xA;cd translation-agent&#xA;git checkout use_llamaedge&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Here, we run Llama-3-8B, Gemma-2-9B, and Phi-3-medium-128k locally and our Translation Agent on top of them respectively to showcase their translation quality. We test a simple translation task to see the results so as to compare their translation capabilities. You will need to install&amp;nbsp;&lt;a href=&#34;https://github.com/WasmEdge/WasmEdge&#34;&gt;WasmEdge&lt;/a&gt;&amp;nbsp;and the&amp;nbsp;&lt;a href=&#34;https://github.com/LlamaEdge/LlamaEdge&#34;&gt;LlamaEdge API server&lt;/a&gt;&amp;nbsp;to run those models across major GPU and CPU platforms.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;curl -sSf https://raw.githubusercontent.com/WasmEdge/WasmEdge/master/utils/install_v2.sh | bash -s -- -v 0.13.5&#xA;&#xA;curl -LO https://github.com/LlamaEdge/LlamaEdge/releases/latest/download/llama-api-server.wasm&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;You will also need the following configurations and prerequisites to run the agent app.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;export OPENAI_BASE_URL=&#34;http://localhost:8080/v1&#34;&#xA;export PYTHONPATH=${PWD}/src&#xA;export OPENAI_API_KEY=&#34;LLAMAEDGE&#34;&#xA;&#xA;pip install python-dotenv&#xA;pip install openai tiktoken icecream langchain_text_splitters&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;demo-1-running-translation-agents-with-llama-3-8b&#34;&gt;&lt;a href=&#34;https://www.secondstate.io/articles/translation-agent/#demo-1-running-translation-agents-with-llama-3-8b&#34;&gt;Demo 1: Running Translation Agents with Llama-3-8B&lt;/a&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;First, let’s run the translation agent with Meta AI’s popular Llama-3 model. We select the smallest Llama-3 model (the 8b model) for this demo. The translation task is from Chinese to English. Our&amp;nbsp;&lt;a href=&#34;https://hackmd.io/tdLiVR3TSc-8eVg_E-j9QA?view#Source-text&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;source text&lt;/a&gt;&amp;nbsp;is in Chinese, a brief intro to the ancient Chinese royal palace, the Forbidden City.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;step-11-run-llama-3-8b-on-your-own-device&#34;&gt;&lt;a href=&#34;https://www.secondstate.io/articles/translation-agent/#step-11-run-llama-3-8b-on-your-own-device&#34;&gt;Step 1.1: Run Llama-3-8B on your own device&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p&gt;See detailed instructions here:&amp;nbsp;&lt;a href=&#34;https://www.secondstate.io/articles/llama-3-8b/#run-llama-3-8b-on-your-own-device&#34;&gt;Run Llama-3-8B on your own device&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Download the Llama-3-8B model GGUF file. Since the size of the model is 5.73 GB. It can take a while to download.Copy&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;curl -LO https://huggingface.co/second-state/Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-Q5_K_M.gguf&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Next, use the following command to start an API server for the model.Copy&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;wasmedge --dir .:. --nn-preload default:GGML:AUTO:Meta-Llama-3-8B-Instruct-Q5_K_M.gguf \&#xA;  llama-api-server.wasm \&#xA;  --prompt-template llama-3-chat \&#xA;  --ctx-size 4096 \&#xA;  --model-name llama-3-8b&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;step-12-run-the-translation-agent-on-top-of-llama-3-8b&#34;&gt;&lt;a href=&#34;https://www.secondstate.io/articles/translation-agent/#step-12-run-the-translation-agent-on-top-of-llama-3-8b&#34;&gt;Step 1.2 Run the Translation Agent on top of Llama-3-8B&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Find the&amp;nbsp;&lt;code&gt;examples/example_script.py&lt;/code&gt;&amp;nbsp;file in your cloned agent repo and review its code. It tells the agent where to find your document and how to translate it. Change the model name to the one you are using, here we’re using&amp;nbsp;&lt;code&gt;llama-3-8b&lt;/code&gt;&amp;nbsp;model; also change the source and target languages you want (here we put&amp;nbsp;&lt;code&gt;Chinese&lt;/code&gt;&amp;nbsp;as the source language and&amp;nbsp;&lt;code&gt;English&lt;/code&gt;&amp;nbsp;as the target language).Copy&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;import os&#xA;import translation_agent as ta&#xA;        &#xA;if __name__ == &#34;__main__&#34;:&#xA;    source_lang, target_lang, country = &#34;Chinese&#34;, &#34;English&#34;, &#34;Britain&#34;&#xA;    &#xA;    relative_path = &#34;sample-texts/forbiddencity.txt&#34;&#xA;    script_dir = os.path.dirname(os.path.abspath(__file__))&#xA;    &#xA;    full_path = os.path.join(script_dir, relative_path)&#xA;    &#xA;    with open(full_path, encoding=&#34;utf-8&#34;) as file:&#xA;        source_text = file.read()&#xA;    &#xA;    print(f&#34;Source text:\n\n{source_text}\n------------\n&#34;)&#xA;    &#xA;    translation = ta.translate(&#xA;            source_lang=source_lang,&#xA;            target_lang=target_lang,&#xA;            source_text=source_text,&#xA;            country=country,&#xA;            model=&#34;llama-3-8b&#34;,&#xA;    )&#xA;    &#xA;    print(f&#34;Translation:\n\n{translation}&#34;)&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Then, you can find a&amp;nbsp;&lt;code&gt;examples/sample-texts&lt;/code&gt;&amp;nbsp;folder in your cloned repo. Put your file you want to translate in this folder and get its path. Here because we named our source text&amp;nbsp;&lt;code&gt;forbiddencity.txt&lt;/code&gt;, the relative path to the document would be&amp;nbsp;&lt;code&gt;sample-texts/forbiddencity.txt&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Run the below commands to have your text file translated into English.Copy&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;cd examples&#xA;python example_script.py&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Wait for several minutes and you will have&amp;nbsp;&lt;a href=&#34;https://hackmd.io/tdLiVR3TSc-8eVg_E-j9QA?view#English-Translation-by-Llama-3-8B&#34;&gt;a fully translated version&lt;/a&gt;&amp;nbsp;appear on your terminal screen.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;demo-2-running-translation-agents-with-gemma-2-9b&#34;&gt;&lt;a href=&#34;https://www.secondstate.io/articles/translation-agent/#demo-2-running-translation-agents-with-gemma-2-9b&#34;&gt;Demo 2: Running Translation Agents with Gemma-2-9B&lt;/a&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The benefit of running the Translation Agent with LlamaEdge is the ability for users to choose and embed different LLMs for different agentic tasks. To demonstrate this point, we will now change the translation agent LLM from Llama-3-8b to Google’s Gemma-2-9b, which is of similar size but scores higher on many language-related benchmarks.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The translation task is the same as before. Our&amp;nbsp;&lt;a href=&#34;https://hackmd.io/tdLiVR3TSc-8eVg_E-j9QA?view#Source-text&#34;&gt;source text&lt;/a&gt;&amp;nbsp;is in Chinese, a brief intro to the ancient Chinese royal palace, the Forbidden City. The translation target is English.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;step-21-run-gemma-2-9b-on-your-own-device&#34;&gt;&lt;a href=&#34;https://www.secondstate.io/articles/translation-agent/#step-21-run-gemma-2-9b-on-your-own-device&#34;&gt;Step 2.1 Run Gemma-2-9B on your own device&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p&gt;See detailed instructions here:&amp;nbsp;&lt;a href=&#34;https://www.secondstate.io/articles/gemma-2-9b/&#34;&gt;Run Gemma-2-9B on your own device&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Download the&amp;nbsp;&lt;a href=&#34;https://huggingface.co/second-state/gemma-2-9b-it-GGUF&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Gemma-2-9B-it model GGUF file&lt;/a&gt;. Since the size of the model is 6.40G, it could take a while to download.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;curl -LO https://huggingface.co/second-state/gemma-2-9b-it-GGUF/resolve/main/gemma-2-9b-it-Q5_K_M.gguf&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Start an API server for the model.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;wasmedge --dir .:. --nn-preload default:GGML:AUTO:gemma-2-9b-it-Q5_K_M.gguf \&#xA;  llama-api-server.wasm \&#xA;  --prompt-template gemma-instruct \&#xA;  --ctx-size 4096 \&#xA;  --model-name gemma-2-9b&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;step-22-run-the-translation-agent-to-run-on-top-of-gemma-2-9b&#34;&gt;&lt;a href=&#34;https://www.secondstate.io/articles/translation-agent/#step-22-run-the-translation-agent-to-run-on-top-of-gemma-2-9b&#34;&gt;Step 2.2 Run the Translation Agent to run on top of Gemma-2-9B&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Find the&amp;nbsp;&lt;code&gt;examples/example_script.py&lt;/code&gt;&amp;nbsp;file in your cloned agent repo and review its code. It tells the agent where to find your document and how to translate it. Change the model name to the one you are using, here we’re using&amp;nbsp;&lt;code&gt;gemma-2-9b&lt;/code&gt;&amp;nbsp;model; also change the source and target languages you want (here we put&amp;nbsp;&lt;code&gt;Chinese&lt;/code&gt;&amp;nbsp;as the source language and&amp;nbsp;&lt;code&gt;English&lt;/code&gt;&amp;nbsp;as the target language).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;import os  &#xA;import translation_agent as ta  &#xA;    &#xA;if __name__ == &#34;__main__&#34;:&#xA;    source_lang, target_lang, country = &#34;Chinese&#34;, &#34;English&#34;, &#34;Britain&#34;&#xA;    &#xA;    relative_path = &#34;sample-texts/forbiddencity.txt&#34;&#xA;    script_dir = os.path.dirname(os.path.abspath(__file__))&#xA;    &#xA;    full_path = os.path.join(script_dir, relative_path)&#xA;    &#xA;    with open(full_path, encoding=&#34;utf-8&#34;) as file:&#xA;        source_text = file.read()&#xA;    &#xA;    print(f&#34;Source text:\n\n{source_text}\n------------\n&#34;)&#xA;    &#xA;    translation = ta.translate(&#xA;            source_lang=source_lang,&#xA;            target_lang=target_lang,&#xA;            source_text=source_text,&#xA;            country=country,&#xA;            model=&#34;gemma-2-9b&#34;,&#xA;    )&#xA;    &#xA;    print(f&#34;Translation:\n\n{translation}&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Then, you can find a&amp;nbsp;&lt;code&gt;examples/sample-texts&lt;/code&gt;&amp;nbsp;folder in your cloned repo. Put your file you want to translate in this folder and get its path. Here because we named our source text&amp;nbsp;&lt;code&gt;forbiddencity.txt&lt;/code&gt;, the relative path to the document would be&amp;nbsp;&lt;code&gt;sample-texts/forbiddencity.txt&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Run the below commands to have your text file translated into English.Copy&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;cd examples    &#xA;python example_script.py&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;You can find the translated result in English&amp;nbsp;&lt;a href=&#34;https://hackmd.io/tdLiVR3TSc-8eVg_E-j9QA?view#English-Translation-by-Gemma-2-9B&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;demo-3-running-translation-agents-with-phi-3-medium-long-context-model&#34;&gt;&lt;a href=&#34;https://www.secondstate.io/articles/translation-agent/#demo-3-running-translation-agents-with-phi-3-medium-long-context-model&#34;&gt;Demo 3: Running Translation Agents with Phi-3-Medium long context model&lt;/a&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The Llama-3 and Gemma-2 models are great LLMs, but they have relatively small context windows. The agent requires all text to fit into the LLM context window, and that limits the size of articles they can translate. To fix this problem, we could select an open source LLM with a large context window. For this demo, we choose Microsoft’s Phi-3-medium-128k model, which has a massive 128k (over 100 thousand words or the length of several books) context window.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We run&amp;nbsp;&lt;a href=&#34;https://hackmd.io/vuFYZTVsQZyKmkeQ3ThZQw?view#Source-text&#34;&gt;a lengthy Chinese article on Forbidden City’s collaboration with the Varsaille Palace&lt;/a&gt;&amp;nbsp;through our Translation Agent powered by a Phi-3-medium-128k model we start locally.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;step-31-run-phi-3-medium-128k-on-your-own-device&#34;&gt;&lt;a href=&#34;https://www.secondstate.io/articles/translation-agent/#step-31-run-phi-3-medium-128k-on-your-own-device&#34;&gt;Step 3.1: Run Phi-3-medium-128k on your own device&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;blockquote class=&#34;wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p&gt;See detailed instructions here:&amp;nbsp;&lt;a href=&#34;https://www.secondstate.io/articles/phi-3-mini-128k/&#34;&gt;Getting Started with Phi-3-mini-128k&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Download the&amp;nbsp;&lt;a href=&#34;https://huggingface.co/second-state/Phi-3-medium-128k-instruct-GGUF&#34;&gt;Phi-3-Medium-128k model GGUF file&lt;/a&gt;.Copy&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;curl -LO https://huggingface.co/second-state/Phi-3-medium-128k-instruct-GGUF/resolve/main/Phi-3-medium-128k-instruct-Q5_K_M.gguf&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Run the following command to start an API server for the model with a 128k context window.Copy&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;wasmedge --dir .:. --nn-preload default:GGML:AUTO:Phi-3-medium-128k-instruct-Q5_K_M.gguf \&#xA;  llama-api-server.wasm \&#xA;  --prompt-template phi-3-chat \&#xA;  --ctx-size 128000 \&#xA;  --model-name phi-3-medium-128k&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;step-32-clone-and-run-the-translation-agent-on-top-of-phi-3-medium-128k&#34;&gt;&lt;a href=&#34;https://www.secondstate.io/articles/translation-agent/#step-32-clone-and-run-the-translation-agent-on-top-of-phi-3-medium-128k&#34;&gt;Step 3.2 Clone and run the Translation Agent on top of Phi-3-medium-128k&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Find the&amp;nbsp;&lt;code&gt;examples/example_script.py&lt;/code&gt;&amp;nbsp;file in your cloned agent repo and review its code. It tells the agent where to find your document and how to translate it. Change the model name to the one you are using, here we’re using&amp;nbsp;&lt;code&gt;phi-3-medium-128k&lt;/code&gt;&amp;nbsp;model; also change the source and target languages you want (here we put&amp;nbsp;&lt;code&gt;Chinese&lt;/code&gt;&amp;nbsp;as the source language and&amp;nbsp;&lt;code&gt;English&lt;/code&gt;&amp;nbsp;as the target language).Copy&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;import os  &#xA;import translation_agent as ta  &#xA;    &#xA;if __name__ == &#34;__main__&#34;:&#xA;    source_lang, target_lang, country = &#34;Chinese&#34;, &#34;English&#34;, &#34;Britain&#34;&#xA;    &#xA;    relative_path = &#34;sample-texts/long_article.txt&#34;&#xA;    script_dir = os.path.dirname(os.path.abspath(__file__))&#xA;    &#xA;    full_path = os.path.join(script_dir, relative_path)&#xA;    &#xA;    with open(full_path, encoding=&#34;utf-8&#34;) as file:&#xA;        source_text = file.read()&#xA;    &#xA;    print(f&#34;Source text:\n\n{source_text}\n------------\n&#34;)&#xA;    &#xA;    translation = ta.translate(&#xA;            source_lang=source_lang,&#xA;            target_lang=target_lang,&#xA;            source_text=source_text,&#xA;            country=country,&#xA;            model=&#34;phi-3-medium-128k&#34;,&#xA;    )&#xA;    &#xA;    print(f&#34;Translation:\n\n{translation}&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Then, you can find a&amp;nbsp;&lt;code&gt;examples/sample-texts&lt;/code&gt;&amp;nbsp;folder in your cloned repo. Put your file you want to translate in this folder and get its path. Here because we named our source text&amp;nbsp;&lt;code&gt;long_article.txt&lt;/code&gt;, the relative path to the document would be&amp;nbsp;&lt;code&gt;sample-texts/long_article.txt&lt;/code&gt;.Copy&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;cd examples&#xA;python example_script.py&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://hackmd.io/vuFYZTVsQZyKmkeQ3ThZQw?view#Source-text&#34;&gt;The translated results were impressive,&lt;/a&gt;&amp;nbsp;with the translation capturing the nuances and context of the original text with high fidelity.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;evaluation-of-translation-quality&#34;&gt;&lt;a href=&#34;https://www.secondstate.io/articles/translation-agent/#evaluation-of-translation-quality&#34;&gt;Evaluation of Translation Quality&lt;/a&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The three models, Llama-3-8B, Gemma-2-9B, and Phi-3-medium, have exhibited varying levels of performance in translating complex historical and cultural content from Chinese to English.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Llama-3-8B provides a translation that effectively captures the factual content but shows occasional stiffness in language, possibly indicating a direct translation approach that doesn’t fully adapt idiomatic expressions. It does not keep section title and the format of the original text and left certain part untranslated.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In contrast, The translation by Gemma-2-9B is quite accurate and retains the original meaning of the short intro article of Forbidden city. Gemma-2-9B’s translation exhibits a smooth and natural English flow, suggesting a sophisticated understanding of both the source language and the target language’s grammatical structures. The choice of words and sentence structures in Gemma-2-9B’s output demonstrates a high degree of linguistic finesse, suggesting it might be well-suited for translating formal and historically nuanced texts.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The Phi-3-medium-128k model can translate book-length text from Chinese to English. It demonstrates robust capabilities in handling large volumes of complex content, suggesting advanced memory handling and contextual awareness. The quality of translation remains consistent even with increased text length, indicating Phi’s utility in projects requiring extensive, detailed translations. But you can see it makes certain mistakes like mistaken “Wenhua Hall” as “also known as Forbidden City” in the first paragraph.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Overall, each model has its strengths, with Gemma-2-9B standing out for linguistic finesse and Phi-3-medium-128k for handling lengthy texts.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;conclusion&#34;&gt;&lt;a href=&#34;https://www.secondstate.io/articles/translation-agent/#conclusion&#34;&gt;Conclusion&lt;/a&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/LlamaEdge/LlamaEdge&#34;&gt;LlamaEdge&lt;/a&gt;&amp;nbsp;provides an easy way to embed different open-source LLMs into your agentic applications to fully take advantage of their finetuned capabilities for specific tasks. The result application can be properly packaged and distributed as a single app that runs across major CPU and GPU devices.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;会员帖子最初发布于&lt;a href=&#34;https://www.secondstate.io/articles/translation-agent/&#34;&gt;Second State 博客&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;教授。 Andrew Ng 的&lt;a href=&#34;https://www.linkedin.com/posts/andrewyng_github-andrewyngtranslation-agent-activity-7206347897938866176-5tDJ/&#34;&gt;代理翻译&lt;/a&gt;很好地演示了如何协调多个 LLM“代理”来完成单一任务。它允许多个较小的 LLM（如 Llama-3 或 Gemma-2）一起工作，并比单个大型 LLM（如 ChatGPT）产生更好的结果。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/andrewyng/translation-agent&#34;&gt;翻译代理&lt;/a&gt;非常适合&lt;a href=&#34;https://github.com/LlamaEdge/ LlamaEdge&#34;&gt;LlamaEdge&lt;/a&gt;，提供&lt;a href=&#34;https://llamaedge.com/docs/llamaedge_vs_python&#34;&gt;轻量级&lt;/a&gt;、&lt;a href=&#34;https://llamaedge.com/docs /llamaedge_vs_ollama&#34;&gt;嵌入式&lt;/a&gt;、&lt;a href=&#34;https://llamaedge.com/docs/llamaedge_vs_llamacpp&#34;&gt;便携式&lt;/a&gt;和&lt;a href=&#34;https://github.com/LlamaEdge/ LlamaEdge/blob/main/docker/README.md&#34;&gt;Docker 原生&lt;/a&gt; 适用于&lt;a href=&#34;https://llamaedge.com/docs/llamaedge_vs_llamacpp&#34;&gt;许多不同&lt;/a&gt;类型模型的 AI 运行时和硬件加速器。借助 LlamaEdge，您可以构建和分发带有嵌入式 LLM 和可在边缘设备上运行的提示的翻译应用程序。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://www.secondstate.io/articles/translation-agent.png&#34; alt=&#34;图像&#34;referrerpolicy=&#34;no-推荐人&#34;&gt;&lt;/图&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;introduction-to-the-llm-translation-agent&#34;&gt;&lt;a href=&#34;https://www.secondstate.io/articles/translation-agent/#introduction -to-the-llm-translation-agent&#34;&gt;LLM翻译代理简介&lt;/a&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;该法学硕士翻译代理旨在促进跨多种语言的准确高效翻译。它采用开源 LLM（大型语言模型）来提供高质量的翻译。您可以使用自己的微调模型或 Hugging Face 上的任何法学硕士（例如 Meta 的 Llama 3）。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p&gt;有关启动和运行此代理的详细命令，请访问 &lt;a href=&#34;https://github.com/second-state/translation-agent/blob/use_llamaedge/step-by-step-use-LocalAI。 md&#34;&gt;GitHub – 第二状态/翻译代理&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;/块引用&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;首先，克隆翻译代理。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;git 克隆 https://github.com/second-state/translation-agent.git&#xA;    &#xA;cd 翻译代理&#xA;git checkout use_llamaedge&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在这里，我们在本地运行 Llama-3-8B、Gemma-2-9B 和 Phi-3-medium-128k，并分别在它们之上运行我们的翻译代理来展示它们的翻译质量。我们测试一个简单的翻译任务来查看结果，从而比较他们的翻译能力。您需要安装&lt;a href=&#34;https:///github.com/WasmEdge/WasmEdge&#34;&gt;WasmEdge&lt;/a&gt; 和 &lt;a href=&#34;https://github.com/LlamaEdge/LlamaEdge&#34;&gt;LlamaEdge API 服务器&lt;/a&gt; 跨主要 GPU 运行这些模型CPU 平台。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;curl -sSf https://raw.githubusercontent.com/WasmEdge/WasmEdge/master/utils/install_v2.sh | bash -s ---v 0.13.5&#xA;&#xA;卷曲-LO https://github.com/LlamaEdge/LlamaEdge/releases/latest/download/llama-api-server.wasm&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;您还需要以下配置和先决条件才能运行代理应用程序。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;导出 OPENAI_BASE_URL=&#34;http://localhost:8080/v1&#34;&#xA;导出 PYTHONPATH=${PWD}/src&#xA;导出 OPENAI_API_KEY=&#34;LLAMAEDGE&#34;&#xA;&#xA;pip 安装 python-dotenv&#xA;pip install openai tiktoken Icecream langchain_text_splitters&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;demo-1-running-translation-agents-with-llama-3-8b&#34;&gt;&lt;a href=&#34;https://www.secondstate.io/articles/ Translation-agent/#demo-1-running-translation-agents-with-llama-3-8b&#34;&gt;演示 1：使用 Llama-3-8B 运行翻译代理&lt;/a&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;首先，让我们使用 Meta AI 流行的 Llama-3 模型运行翻译代理。我们为此演示选择最小的 Llama-3 模型（8b 模型）。翻译任务是从中文到英文。我们的&lt;a href=&#34;https://hackmd.io/tdLiVR3TSc-8eVg_E-j9QA?view#Source-text&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;源文本&lt;/a&gt;为中文，简短介绍中国古代皇家宫殿紫禁城。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;step-11-run-llama-3-8b-on-your-own-device&#34;&gt;&lt;a href=&#34;https://www.secondstate.io/ articles/translation-agent/#step-11-run-llama-3-8b-on-your-own-device&#34;&gt;步骤 1.1：在您自己的设备上运行 Llama-3-8B&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p&gt;请在此处查看详细说明：&lt;a href=&#34;https://www.secondstate.io/articles/llama-3-8b/#run-llama-3-8b-on-your-own-device&#34;&gt;运行您自己的设备上的 Llama-3-8B&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/块引用&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;下载 Llama-3-8B 模型 GGUF 文件。由于模型的大小为 5.73 GB。下载可能需要一段时间。复制&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;curl -LO https://huggingface.co/second-state/Llama-3-8B-Instruct-GGUF/resolve/main/Meta- Llama-3-8B-Instruct-Q5_K_M.gguf&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;接下来，使用以下命令为模型启动 API 服务器。复制&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;wasmedge --dir .:. --nn-预加载默认值：GGML：AUTO：Meta-Llama-3-8B-Instruct-Q5_K_M.gguf \&#xA;  llama-api-server.wasm \&#xA;  --prompt-template llama-3-chat \&#xA;  --ctx-大小 4096 \&#xA;  --模型名称 llama-3-8b&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;step-12-run-the-translation-agent-on-top-of-llama-3-8b&#34;&gt;&lt;a href=&#34;https://www. secondarystate.io/articles/translation-agent/#step-12-run-the-translation-agent-on-top-of-llama-3-8b&#34;&gt;步骤 1.2 在 Llama-3-8B 上运行翻译代理&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;找到&lt;代码&gt;examples/example_script.py&lt;/code&gt; 在克隆的代理存储库中创建文件并查看其代码。它告诉代理在哪里可以找到您的文件以及如何翻译它。将模型名称更改为您正在使用的模型名称，此处我们使用&lt;code&gt;llama-3-8b&lt;/code&gt;模型；还可以更改您想要的源语言和目标语言（这里我们将&lt;code&gt;中文&lt;/code&gt;作为源语言，&lt;code&gt;英语&lt;/code&gt;作为目标语言）。复制&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;导入操作系统&#xA;将 Translation_agent 导入为 ta&#xA;        &#xA;如果 __name__ == &#34;__main__&#34;:&#xA;    source_lang, target_lang, Country = &#34;中文&#34;, &#34;英语&#34;, &#34;英国&#34;&#xA;    &#xA;    relative_path =“样本文本/forbiddencity.txt”&#xA;    script_dir = os.path.dirname(os.path.abspath(__file__))&#xA;    &#xA;    full_path = os.path.join(script_dir, 相对路径)&#xA;    &#xA;    打开（full_path，encoding =“utf-8”）作为文件：&#xA;        源文本 = 文件.read()&#xA;    &#xA;    print(f&#34;源文本：\n\n{source_text}\n------------\n&#34;)&#xA;    &#xA;    翻译 = ta.translate(&#xA;            源语言=源语言,&#xA;            目标语言=目标语言,&#xA;            源文本=源文本，&#xA;            国家=国家，&#xA;            型号=“llama-3-8b”，&#xA;    ）&#xA;    &#xA;    print(f&#34;翻译：\n\n{translation}&#34;)&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;然后，您可以在克隆的存储库中找到 &lt;code&gt;examples/sample-texts&lt;/code&gt; 文件夹。将要翻译的文件放入此文件夹中并获取其路径。此处，由于我们将源文本命名为 &lt;code&gt;forbiddencity.txt&lt;/code&gt;，因此文档的相对路径将为 &lt;code&gt;sample-texts/forbiddencity.txt&lt;/code&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;运行以下命令将您的文本文件翻译成英语。复制&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;cd 示例&#xA;python example_script.py&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;等待几分钟，您将获得&lt;a href=&#34;https://hackmd.io/tdLiVR3TSc-8eVg_E-j9QA?view#English-Translation-by-Llama-3-8B&#34;&gt;完整翻译版本&lt; /a&gt; 出现在您的终端屏幕上。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;demo-2-running-translation-agents-with-gemma-2-9b&#34;&gt;&lt;a href=&#34;https://www.secondstate.io/articles/ Translation-agent/#demo-2-running-translation-agents-with-gemma-2-9b&#34;&gt;演示 2：使用 Gemma-2-9B 运行翻译代理&lt;/a&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;使用 LlamaEdge 运行翻译代理的好处是用户能够为不同的代理任务选择和嵌入不同的 LLM。为了证明这一点，我们现在将翻译代理 LLM 从 Llama-3-8b 更改为 Google 的 Gemma-2-9b，它大小相似，但在许多语言相关基准测试中得分更高。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;翻译任务与之前相同。我们的&lt;a href=&#34;https://hackmd.io/tdLiVR3TSc-8eVg_E-j9QA?view#Source-text&#34;&gt;源文本&lt;/a&gt;是中文的，是对中国古代皇宫紫禁城的简要介绍。翻译目标是英语。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;step-21-run-gemma-2-9b-on-your-own-device&#34;&gt;&lt;a href=&#34;https://www.secondstate.io/articles/translation-agent/#step-21-run-gemma-2-9b-on-your-own-device&#34;&gt;步骤 2.1 在您自己的设备上运行 Gemma-2-9B&lt;/a&gt;&lt;/ H3&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p&gt;请在此处查看详细说明：&lt;a href=&#34;https://www.secondstate.io/articles/gemma-2-9b/&#34;&gt;在您自己的设备上运行 Gemma-2-9B&lt;/a&gt;&lt;/p &gt;&#xA;&lt;/块引用&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;下载&lt;a href=&#34;https://huggingface.co/second-state/gemma-2-9b-it-GGUF&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Gemma-2-9B-它对 GGUF 文件进行建模&lt;/a&gt;。由于模型大小为6.40G，下载可能需要一段时间。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;curl -LO https://huggingface.co/second-state/gemma-2-9b-it-GGUF/resolve/main/gemma- 2-9b-it-Q5_K_M.gguf&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;为模型启动 API 服务器。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;wasmedge --dir .:. --nn-预加载默认值：GGML：AUTO：gemma-2-9b-it-Q5_K_M.gguf \&#xA;  llama-api-server.wasm \&#xA;  --prompt-template gemma-instruct \&#xA;  --ctx-大小 4096 \&#xA;  --型号名称 gemma-2-9b&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;step-22-run-the-translation-agent-to-run-on-top-of-gemma-2-9b&#34;&gt;&lt;a href=&#34;https: //www.secondstate.io/articles/translation-agent/#step-22-run-the-translation-agent-to-run-on-top-of-gemma-2-9b&#34;&gt;步骤 2.2 运行翻译代理在 Gemma-2-9B 上运行&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在克隆的代理存储库中找到 &lt;code&gt;examples/example_script.py&lt;/code&gt; 文件并查看其代码。它告诉代理在哪里可以找到您的文件以及如何翻译它。将模型名称更改为您正在使用的模型名称，这里我们使用的是&lt;code&gt;gemma-2-9b&lt;/code&gt;模型；还可以更改您想要的源语言和目标语言（此处我们将&lt;code&gt;中文&lt;/code&gt;作为源语言，将&lt;code&gt;英语&lt;/code&gt;作为目标语言）。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;导入操作系统  &#xA;将 Translation_agent 导入为 ta  &#xA;    &#xA;如果 __name__ == &#34;__main__&#34;:&#xA;    source_lang, target_lang, Country = &#34;中文&#34;, &#34;英语&#34;, &#34;英国&#34;&#xA;    &#xA;    relative_path =“样本文本/forbiddencity.txt”&#xA;    script_dir = os.path.dirname(os.path.abspath(__file__))&#xA;    &#xA;    full_path = os.path.join(script_dir, 相对路径)&#xA;    &#xA;    打开（full_path，encoding =“utf-8”）作为文件：&#xA;        源文本 = 文件.read()&#xA;    &#xA;    print(f&#34;源文本：\n\n{source_text}\n------------\n&#34;)&#xA;    &#xA;    翻译 = ta.translate(&#xA;            源语言=源语言,&#xA;            目标语言=目标语言,&#xA;            源文本=源文本，&#xA;            国家=国家，&#xA;            型号=“gemma-2-9b”，&#xA;    ）&#xA;    &#xA;    print(f&#34;翻译：\n\n{翻译}&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;然后，您可以在克隆的存储库中找到 &lt;code&gt;examples/sample-texts&lt;/code&gt; 文件夹。将要翻译的文件放入此文件夹中并获取其路径。由于我们将源文本命名为 &lt;code&gt;forbiddencity.txt&lt;/code&gt;，因此文档的相对路径为 &lt;code&gt;sample-texts/forbiddencity.txt&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;运行以下命令将您的文本文件翻译成英语。复制&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;cd 示例    &#xA;python example_script.py&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;您可以在&lt;a href=&#34;https://hackmd.io/tdLiVR3TSc-8eVg_E-j9QA?view#English-Translation-by-Gemma-2-9B&#34;&gt;此处找到英文翻译结果&lt;/a&gt; .&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;demo-3-running-translation-agents-with-phi-3-medium-long-context-model&#34;&gt;&lt;a href=&#34;https://www.wp-block-heading&#34; secondarystate.io/articles/translation-agent/#demo-3-running-translation-agents-with-phi-3-medium-long-context-model&#34;&gt;演示 3：使用 Phi-3-Medium 长上下文运行翻译代理模型&lt;/a&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Llama-3 和 Gemma-2 模型是很棒的 LLM，但它们的上下文窗口相对较小。代理要求所有文本都适合 LLM 上下文窗口，这限制了他们可以翻译的文章的大小。为了解决这个问题，我们可以选择一个具有大上下文窗口的开源法学硕士。在本演示中，我们选择 Microsoft 的 Phi-3-medium-128k 模型，该模型具有巨大的 128k（超过 10 万个单词或几本书的长度）上下文窗口。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们通过我们的翻译代理（由Phi-3-medium-128k 模型我们从本地开始。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;step-31-run-phi-3-medium-128k-on-your-own-device&#34;&gt;&lt;a href=&#34;https://www.secondstate. io/articles/translation-agent/#step-31-run-phi-3-medium-128k-on-your-own-device&#34;&gt;步骤 3.1：在您自己的设备上运行 Phi-3-medium-128k&lt;/a &gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;blockquote class=&#34;wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p&gt;请参阅此处的详细说明：&lt;a href=&#34;https://www.secondstate.io/articles/phi-3-mini-128k/&#34;&gt;Phi-3-mini-128k 入门&lt;/a&gt;。 &lt;/p&gt;&#xA;&lt;/块引用&gt;&#xA;&lt;/块引用&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;下载&lt;a href=&#34;https://huggingface.co/second-state/Phi-3-medium-128k-instruct-GGUF&#34;&gt;Phi-3-Medium-128k 模型 GGUF 文件&lt;/a&gt;。复制&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;curl -LO https://huggingface.co/second-state/Phi-3-medium-128k-instruct-GGUF/resolve/main/ Phi-3-medium-128k-instruct-Q5_K_M.gguf&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;运行以下命令，为具有 128k 上下文窗口的模型启动 API 服务器。复制&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;wasmedge --dir .:. --nn-预加载默认:GGML:AUTO:Phi-3-medium-128k-instruct-Q5_K_M.gguf \&#xA;  llama-api-server.wasm \&#xA;  --提示模板 phi-3-聊天 \&#xA;  --ctx-大小 128000 \&#xA;  --型号名称 phi-3-medium-128k&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;step-32-clone-and-run-the-translation-agent-on-top-of-phi-3-medium-128k&#34;&gt;&lt;a href=&#34; https://www.secondstate.io/articles/translation-agent/#step-32-clone-and-run-the-translation-agent-on-top-of-phi-3-medium-128k&#34;&gt;步骤 3.2 在 Phi-3-medium-128k 上克隆并运行翻译代理&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在克隆的代理存储库中找到 &lt;code&gt;examples/example_script.py&lt;/code&gt; 文件并查看其代码。它告诉代理在哪里可以找到您的文件以及如何翻译它。将模型名称更改为您正在使用的模型名称，这里我们使用的是&lt;code&gt;phi-3-medium-128k&lt;/code&gt;模型；还可以更改您想要的源语言和目标语言（这里我们将&lt;code&gt;中文&lt;/code&gt;作为源语言，&lt;code&gt;英语&lt;/code&gt;作为目标语言）。复制&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;导入操作系统  &#xA;将 Translation_agent 导入为 ta  &#xA;    &#xA;如果 __name__ == &#34;__main__&#34;:&#xA;    source_lang, target_lang, Country = &#34;中文&#34;, &#34;英语&#34;, &#34;英国&#34;&#xA;    &#xA;    relative_path =“样本文本/long_article.txt”&#xA;    script_dir = os.path.dirname(os.path.abspath(__file__))&#xA;    &#xA;    full_path = os.path.join(script_dir, 相对路径)&#xA;    &#xA;    打开（full_path，encoding =“utf-8”）作为文件：&#xA;        源文本 = 文件.read()&#xA;    &#xA;    print(f&#34;源文本：\n\n{source_text}\n------------\n&#34;)&#xA;    &#xA;    翻译 = ta.translate(&#xA;            源语言=源语言,&#xA;            目标语言=目标语言,&#xA;            源文本=源文本，&#xA;            国家=国家，&#xA;            型号=“phi-3-medium-128k”，&#xA;    ）&#xA;    &#xA;    print(f&#34;翻译：\n\n{翻译}&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;然后，您可以在克隆的存储库中找到 &lt;code&gt;examples/sample-texts&lt;/code&gt; 文件夹。将要翻译的文件放入此文件夹中并获取其路径。由于我们将源文本命名为 &lt;code&gt;long_article.txt&lt;/code&gt;，因此文档的相对路径为 &lt;code&gt;sample-texts/long_article.txt&lt;/code&gt;.Copy&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;cd 示例&#xA;python example_script.py&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://hackmd.io/vuFYZTVsQZyKmkeQ3ThZQw?view#Source-text&#34;&gt;翻译结果令人印象深刻&lt;/a&gt;，翻译以高保真度捕捉了原文的细微差别和上下文.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;evaluation-of-translation-quality&#34;&gt;&lt;a href=&#34;https://www.secondstate.io/articles/translation-agent/#evaluation-of-translation -quality&#34;&gt;翻译质量评估&lt;/a&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Llama-3-8B、Gemma-2-9B 和 Phi-3-medium 这三个模型在将复杂的历史和文化内容从中文翻译成英文方面表现出了不同程度的性能。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Llama-3-8B 提供的翻译可以有效地捕捉事实内容，但偶尔会出现语言僵化，这可能表明直接翻译方法并未完全适应惯用表达。它不保留章节标题和原文格式，并保留某些部分未翻译。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;相比之下，Gemma-2-9B 的翻译相当准确，保留了故宫简短介绍文章的原意。 Gemma-2-9B 的翻译展览英语流畅自然，表明对源语言和目标语言的语法结构有深入的理解。 Gemma-2-9B 输出中的单词和句子结构的选择展示了高度的语言技巧，表明它可能非常适合翻译正式的和历史上细致入微的文本。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Phi-3-medium-128k 模型可以将书本长度的文本从中文翻译成英文。它展示了处理大量复杂内容的强大功能，表明了先进的内存处理和上下文感知。即使文本长度增加，翻译质量也保持一致，这表明 Phi 在需要大量、详细翻译的项目中很有用。但你可以看到它有一些错误，比如第一段将“文华殿”误认为“又名紫禁城”。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;总体而言，每个模型都有其优点，Gemma-2-9B 在语言技巧方面表现出色，Phi-3-medium-128k 在处理冗长文本方面表现出色。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;conclusion&#34;&gt;&lt;a href=&#34;https://www.secondstate.io/articles/translation-agent/#conclusion&#34;&gt;结论&lt;/a&gt;&lt;/h2 &gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/LlamaEdge/LlamaEdge&#34;&gt;LlamaEdge&lt;/a&gt; 提供了一种简单的方法，将不同的开源 LLM 嵌入到您的代理应用程序中，以充分利用其微调功能具体任务。结果应用程序可以正确打包并分发为跨主要 CPU 和 GPU 设备运行的单个应用程序。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Sun, 25 Aug 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Ambient mesh: can sidecar-less Istio make your application faster?】环境网格：无 sidecar 的 Istio 能让您的应用程序更快吗？</title>
      <link>https://www.cncf.io/blog/2024/08/23/ambient-mesh-can-sidecar-less-istio-make-your-application-faster/</link>
      <description>【&lt;p&gt;&lt;em&gt;Community post originally published on &lt;a href=&#34;https://thenewstack.io/ambient-mesh-can-sidecar-less-istio-make-applications-faster/&#34;&gt;The New Stack &lt;/a&gt;by Lin Sun&lt;/em&gt;, &lt;em&gt;Head of Open Source at Solo.io&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Ambient mode is the new sidecar-less data plane introduced in Istio in 2022. When ambient mode reached &lt;a href=&#34;https://istio.io/latest/blog/2024/ambient-reaches-beta/&#34;&gt;Beta&lt;/a&gt; status in May this year, I started to see lots of users kicking the tires and running load tests to understand the performance implications after adding their applications to the mesh.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Inspired by &lt;a href=&#34;https://a-cup-of.coffee/blog/istio/#with-istio-ambient&#34;&gt;Quentin Joly’s blog&lt;/a&gt; about the incredible performance of Istio in ambient mode and similar feedback from other users in the community that sometimes applications are slightly faster in ambient mode, I decided to validate these results myself.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Test environment:&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;I used a 3 worker node Kubernetes cluster with 256GB RAM &amp;amp; 32 core CPU each node.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXfS50HjjsJiBqlv30JKgaaTJcmUq0hHcG3xNl42Yzd7E0FfKPAe0gI3tnNAx0gpud0LGfHkdI7cbTXJyzU5v46v-kucl-2_l7Lax0-kvCeG19mST3ToJdIu6r5u7BoYkAGVc14HnRyVlnX9TY_Ra9NilKQ?key=7Xu51UOF6Vd1czS7dgW7gA&#34; alt=&#34;Image&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Istio uses a few tools to make consistent benchmarking easy.&amp;nbsp; First, we use a load testing tool called &lt;a href=&#34;https://github.com/fortio/fortio&#34;&gt;fortio&lt;/a&gt;, which runs at a specified requests per second (RPS), records a histogram of execution time and calculates percentiles — e.g., P99, the response time where 99% of the requests took less than that number.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We also provide a sample app called &lt;a href=&#34;https://istio.io/latest/docs/examples/bookinfo/&#34;&gt;Bookinfo&lt;/a&gt;, which includes microservices written in Python, Java, Node.js and Ruby.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Each of the Bookinfo deployments has 2 replicas, which are evenly distributed to the 3 worker nodes. Using a &lt;a href=&#34;https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity&#34;&gt;pod anti-affinity rule&lt;/a&gt;, I made sure that fortio was placed on a different node than the &lt;a href=&#34;https://github.com/istio/istio/tree/master/samples/bookinfo/src/details&#34;&gt;details&lt;/a&gt; service.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Initial Test Result&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;I installed the Bookinfo application from the Istio v1.22.3 release. Using the fortio tool to drive load to individual Bookinfo services (for example, details) or the full Bookinfo app, I noticed &lt;strong&gt;near-zero latency impact &lt;/strong&gt;after adding everything to the ambient mesh. Most of the time they are within the range of 0-5% increase for the average or P90. I have noticed consistently that the details service in Istio ambient mode is slightly faster, just like Quentin reported in his blog.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Load testing the details service&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;I did the same test as Quentin, sending 100 RPS via 10 connections to the details service, and collected results for no mesh and ambient.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXfc1vCggIDlIXmGqt-ac1pUzDPHZd2feGf-TvJRpQu-nmCwXGVliCE8nB2CT_wkVMPibKKFOtjAQ1aj5zxQ-ivUQj74JFEtVZGwioAYbKLsLeuADG6dhTsvMqaYCvtZk3XlYHTFop6gc-z3zysDhyTrekuU?key=7Xu51UOF6Vd1czS7dgW7gA&#34; alt=&#34;No Mesh: 100 RPS to the details service&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;No Mesh: 100 RPS to the details service&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXdIB88W4APYre6YtZPZ90pRKvuoAFO05xhIaFXL50Y1PzD6LmZ0SoBTdgc6SMZSBar8LaNi5uWzDMA18_pEUZ9W_r1kiyiz9WwtcHMQQMkC6i4avrYLdsMlY8wGFc0FwEUR9VUvy-GSeaUJhAI8HK_fgJXB?key=7Xu51UOF6Vd1czS7dgW7gA&#34; alt=&#34;Image&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Ambient: 100 RPS to the details service&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Just like Quentin, I had to run multiple tests to validate that ambient mode is slightly more performant than no mesh — which is very hard to believe! In the case of the Bookinfo details service, adding ambient mode improved latencies by 6-11% on average – as well as adding mTLS and L4 observability!&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-fixed-layout&#34;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Fortio to &lt;/strong&gt;&lt;strong&gt;details&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Average&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P50&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P75&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P90&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P99&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Differences&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;No Mesh run 1&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;0.89ms&lt;/td&gt;&lt;td&gt;0.64ms&lt;/td&gt;&lt;td&gt;0.74ms&lt;/td&gt;&lt;td&gt;0.85ms&lt;/td&gt;&lt;td&gt;2.67ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;11% slower on average and 5% slower for P90&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Ambient run 1&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;0.80ms&lt;/td&gt;&lt;td&gt;0.6ms&lt;/td&gt;&lt;td&gt;0.71ms&lt;/td&gt;&lt;td&gt;0.81ms&lt;/td&gt;&lt;td&gt;1.4ms&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;No Mesh run 2&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;0.86ms&lt;/td&gt;&lt;td&gt;0.65ms&lt;/td&gt;&lt;td&gt;0.75ms&lt;/td&gt;&lt;td&gt;0.86ms&lt;/td&gt;&lt;td&gt;1.71ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;6% slower on average and 4% slower for P90&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Ambient run 2&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;0.81ms&lt;/td&gt;&lt;td&gt;0.61ms&lt;/td&gt;&lt;td&gt;0.72ms&lt;/td&gt;&lt;td&gt;0.83ms&lt;/td&gt;&lt;td&gt;1.56ms&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;No Mesh run 3&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;0.90ms&lt;/td&gt;&lt;td&gt;0.65ms&lt;/td&gt;&lt;td&gt;0.76ms&lt;/td&gt;&lt;td&gt;0.88ms&lt;/td&gt;&lt;td&gt;1.92ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;10% slower on average and 5% slower for P90&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Ambient run 3&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;0.82ms&lt;/td&gt;&lt;td&gt;0.63ms&lt;/td&gt;&lt;td&gt;0.72ms&lt;/td&gt;&lt;td&gt;0.84ms&lt;/td&gt;&lt;td&gt;1.5ms&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Table 1: Fortio to the details service 100 RPS 10 connections&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Why are apps sometimes faster in the ambient mesh?&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We’ve been taught that service meshes add latency. Quentin’s results, replicated here, show a case where a workload is &lt;em&gt;faster&lt;/em&gt; when running through a service mesh. What is happening?&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;First theory&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;When your applications are in the ambient mesh, the load requests travel first through a lightweight local node proxy called &lt;a href=&#34;https://istio.io/latest/docs/ambient/overview/#ztunnel&#34;&gt;ztunnel&lt;/a&gt;, then to the destination ztunnel, and onward to the service. The details service is using HTTP/1.1 with the Webrick library in Ruby and we have seen poor connection management and keep-alive behaviors in older or poorly configured HTTP libraries. My first hypothesis was that when the client and server are on different nodes, proxying through client and server ztunnels could actually be faster if the applications are not using efficient HTTP/2 connections. Ztunnel uses connection pooling and &lt;a href=&#34;https://en.wikipedia.org/wiki/HTTP_tunnel&#34;&gt;HTTP Connect&lt;/a&gt; to establish secure tunnels between nodes to leverage parallelism and HTTP/2 stream multiplexing under loads.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXdkVHCotSRWKoih2aQLCioo38lsv_PtQFILzTPQvVd3vZYFY5VKaIoVPH_VWLeLla9yZGZBhiTo5H1wH-O3EApb2RvUjM-A3Q5k8B9ffCIoN12sRL8UG_FMLIhxti0iZaYXWu7dttoiubPD0GyDyKDcGmE?key=7Xu51UOF6Vd1czS7dgW7gA&#34; alt=&#34;Image&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;However, this theory has some challenges. Why have I only observed this consistently with the details service but not any other Bookinfo services?&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Researching further, I discovered that our fortio load tool has &lt;a href=&#34;https://github.com/fortio/fortio/blob/8a7d9112667e637139c788b68cb063f456d20cb4/bincommon/commonflags.go#L55&#34;&gt;connection keep-alive enabled by default&lt;/a&gt;. With 10 connections from fortio to the details service and the details service (using the WEBrick Ruby library) respects the connection keep-alive settings, the connections can be reused effectively without ambient.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Load testing with connection close&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Next, I explored running the same load testing with setting the `Connection: close` header. This forcibly disables any HTTP connection pooling which is a good way to test this hypothesis.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;curl -v -d &#39;{&#34;metadata&#34;: {&#34;url&#34;:&#34;http://details:9080/details/0&#34;, &#34;c&#34;:&#34;10&#34;, &#34;qps&#34;: &#34;100&#34;, &#34;n&#34;: &#34;2000&#34;, &#34;async&#34;:&#34;on&#34;, &#34;save&#34;:&#34;on&#34;}}&#39; &#34;localhost:8081/fortio/rest/run?jsonPath=.metadata&#34; -H &#34;Connection: close&#34;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXfc-HDPourI5Dwlo3n-jkc5TMiqJdm0k0oSb1Z4HZkKIkVgCKKFyJbBv6fp40pS6XwTOrrUvYSYfmL7M6Dqu7ZdBSiJYvXo-O7f4weYTsuQHarX3uit-jQEL4HlWiwNc7PEFPS1DQgm6csv5FhdMhXxUUc?key=7Xu51UOF6Vd1czS7dgW7gA&#34; alt=&#34;Image&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;No Mesh: Fortio to the details service 100 RPS 10 connections with connection close&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXfBoHXMf2xaXMboBVCNYNmDBkoFIdefso_IbfLft83aStyTTcm4yOAv3zkEwUtddn1gnFZgT9tf_Z0S494iE6TliMgHFuv24TnEMEddXsFtk2JcS41jUZhTTvAljd9bDA25AGqyjKlt_ZUjZUDoawkBmwP4?key=7Xu51UOF6Vd1czS7dgW7gA&#34; alt=&#34;Image&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Ambient: Fortio to the details service 100 RPS 10 connections with connection close&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-fixed-layout&#34;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Fortio to &lt;/strong&gt;&lt;strong&gt;details&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Average&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P50&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P75&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P90&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P99&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Differences&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;No Mesh&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;1.90ms&lt;/td&gt;&lt;td&gt;1.72ms&lt;/td&gt;&lt;td&gt;2.28ms&lt;/td&gt;&lt;td&gt;2.77ms&lt;/td&gt;&lt;td&gt;3.98ms&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Ambient&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;2.06ms&lt;/td&gt;&lt;td&gt;2.15ms&lt;/td&gt;&lt;td&gt;2.65ms&lt;/td&gt;&lt;td&gt;2.94ms&lt;/td&gt;&lt;td&gt;4ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;8% slower for average &amp;amp; 6% slower for P90&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Table 2: Fortio to the details service 100 RPS 10 connections with connection close&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Compared with Table 1 results, Table 2 numbers have much higher response times, which is expected as each connection is closed immediately after each response from the details service. Given P50, P75, P90 and P99 are all slower from the ambient run with connection close, it seems safe to rule out connection pooling in ztunnel from the first theory could make requests faster.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Second theory&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;I noticed there is a &lt;a href=&#34;https://github.com/istio/istio/pull/51428/files&#34;&gt;performance-related PR&lt;/a&gt; from John Howard in the details and productpage services of the Bookinfo application in our new Istio v1.23 release. For the details service, the PR enabled the &lt;a href=&#34;https://brooker.co.za/blog/2024/05/09/nagle.html&#34;&gt;TCP_NODELAY&lt;/a&gt; flag for the details WEBrick server, which would reduce the unnecessary delay (up to &lt;a href=&#34;https://vorner.github.io/2020/11/06/40-ms-bug.html&#34;&gt;40ms&lt;/a&gt;) from the response time of the details service.&amp;nbsp; For the productpage service, the PR enabled keep-alive on incoming requests, which will reuse existing incoming connections and thus improve performance.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;With the newly updated details deployment that includes the fix, I repeated the same tests sending 100 RPS via 10 connections to the details service. The results for no mesh and ambient are really close so I ran each of the tests three times to ensure the results are consistent. Below are screenshots of the first run for each scenario:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXdjKAWCsxQBxdyihff3W_P4lB51q2BrhbDaqaF2zPooyH2LaoKVgZhFvhAVkBoUteAa0e3XNaBprLWLW6SweAsNw1YmFuk7FbDnnZKwVLC84URGBRt839qLPXKDOkI9F4dIfJU6UcVCaFbMfXEHpSmQlnph?key=7Xu51UOF6Vd1czS7dgW7gA&#34; alt=&#34;No Mesh: Fortio to the new details service 100 RPS 10 connections&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;No Mesh: Fortio to the new details service 100 RPS 10 connections&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXe2lvcrz94RNS_ewSFqOFRy01z3RRRs5kh7Fx8boQiGHGMHIzaRsO4Fmfo-3wOFAmnPez0SmDJsPiBRqq85L7_5xfOjdDhJbTefdG6QB-bZVmXhgwuNtZOHFpiLtvceT_OmEm7UMdkdXdlHe9OXGJ6tCTeX?key=7Xu51UOF6Vd1czS7dgW7gA&#34; alt=&#34;Ambient: Fortio to the new details service 100 RPS 10 connections&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;I built a table for the three runs for each scenario:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-fixed-layout&#34;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td colspan=&#34;2&#34;&gt;&lt;strong&gt;Fortio to &lt;/strong&gt;&lt;strong&gt;details&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Average&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P50&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P75&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P90&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P99&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Differences&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&#34;2&#34;&gt;&lt;strong&gt;1&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;No Mesh&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;0.76ms&lt;/td&gt;&lt;td&gt;0.58ms&lt;/td&gt;&lt;td&gt;0.69ms&lt;/td&gt;&lt;td&gt;0.81ms&lt;/td&gt;&lt;td&gt;1.56ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;5% slower on average and P90. 25% slower on P99&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Ambient&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;0.72ms&lt;/td&gt;&lt;td&gt;0.57ms&lt;/td&gt;&lt;td&gt;0.66ms&lt;/td&gt;&lt;td&gt;0.76ms&lt;/td&gt;&lt;td&gt;1.24ms&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&#34;2&#34;&gt;&lt;strong&gt;2&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;No Mesh&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;0.72ms&lt;/td&gt;&lt;td&gt;0.59ms&lt;/td&gt;&lt;td&gt;0.7ms&lt;/td&gt;&lt;td&gt;0.82ms&lt;/td&gt;&lt;td&gt;1.6ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;3% slower on P90&lt;/strong&gt; &lt;strong&gt;and&lt;/strong&gt; &lt;strong&gt;18% slower on P99&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Ambient&amp;nbsp;&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;0.76ms&lt;/td&gt;&lt;td&gt;0.59ms&lt;/td&gt;&lt;td&gt;0.69ms&lt;/td&gt;&lt;td&gt;0.8ms&lt;/td&gt;&lt;td&gt;1.37ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;5% slower on average&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&#34;2&#34;&gt;&lt;strong&gt;3&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;No Mesh&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;0.77ms&lt;/td&gt;&lt;td&gt;0.58ms&lt;/td&gt;&lt;td&gt;0.7ms&lt;/td&gt;&lt;td&gt;0.8ms&lt;/td&gt;&lt;td&gt;1.49ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;1% slower on average and 8% slower on P99&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Ambient&amp;nbsp;&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;0.76ms&lt;/td&gt;&lt;td&gt;0.59ms&lt;/td&gt;&lt;td&gt;0.69ms&lt;/td&gt;&lt;td&gt;0.81ms&lt;/td&gt;&lt;td&gt;1.38ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;1% slower on P90&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Table 3: Fortio to the new details service 100 RPS 10 connections&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Compared with the previous result from Table 1, the no mesh numbers from Table 3 have improved quite a bit (more substantially at higher percentage than the ambient numbers) and are now closer to the ambient numbers. Ztunnel has &lt;a href=&#34;https://github.com/istio/ztunnel/pulls?q=is%3Apr+is%3Aclosed+TCP_NODELAY&#34;&gt;TCP_NODELAY&lt;/a&gt; enabled by default, which contributed to the ambient performance improvement over no mesh in Table 1 when the old details service doesn’t have TCP_NODELAY enabled. When the new details service has TCP_NODELAY enabled, it has also improved the ambient response times slightly.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Table 3 also shows there is not much difference for average, P50, P75, P90 between no mesh and ambient runs for this type of load testing to the new details service with TCP_NODELAY enabled. The differences between these runs are likely noise with the exception of P99 where the no mesh is consistently 8% or more slower.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Third theory&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Continue reviewing the test results from Table 3, why would there be similar latency between no mesh and ambient when there are extra hops to ztunnel pods and significant benefits provided by ambient such as mTLS and L4 observability between the fortio and details service? For the P99 case, why would the details service in the ambient mode be faster consistently?&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Ztunnel provides great read/write buffer management with HTTP/2 multiplexing, which could effectively minimize or sometimes even eliminate the overhead added by the extra hops through the client and the server ztunnel pods. I decided to measure this with syscalls using &lt;a href=&#34;https://strace.io/&#34;&gt;strace&lt;/a&gt; from both the fortio and details service by getting into their Kubernetes worker nodes and attaching the pids using strace while filter out the irrelevant traces:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;strace -fp {pid} -e trace=write,writev,read,recvfrom,sendto,readv&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The strace output from the details service is similar for the no-mesh and ambient cases:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;…&#xA;read(9, &#34;GET /details/0 HTTP/1.1\r\nHost: d&#34;..., 8192) = 118&#xA;write(9, &#34;HTTP/1.1 200 OK\r\nContent-Type: a&#34;..., 180) = 180&#xA;write(9, &#34;{\&#34;id\&#34;:0,\&#34;author\&#34;:\&#34;William Shakes&#34;..., 178) = 178&#xA;write(2, &#34;192.168.239.19 - - [13/Aug/2024:&#34;..., 80) = 80&#xA;…&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Output 1: No mesh or ambient – attach strace to the details service’s PID&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The strace outputs from the fortio service for no-mesh vs ambient are different. In the no-mesh case we see fortio executed two reads, one for the HTTP headers and another for the body.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;…&#xA;read(13, &#34;HTTP/1.1 200 OK\r\nContent-Type: a&#34;..., 4096) = 180&#xA;read(13, &#34;{\&#34;id\&#34;:0,\&#34;author\&#34;:\&#34;William Shakes&#34;..., 4096) = 178&#xA;…&#xA;write(19, &#34;GET /details/0 HTTP/1.1\r\nHost: d&#34;..., 118) = 118&#xA;…&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Output 2: No mesh – attach strace to fortio’s PID&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In the ambient case we consistently see just one read for both the headers and the body.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;…&#xA;read(19, &#34;HTTP/1.1 200 OK\r\nContent-Type: a&#34;..., 4096) = 358&#xA;…&#xA;write(19, &#34;GET /details/0 HTTP/1.1\r\nHost: d&#34;..., 118) = 118&#xA;…&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Output 3: Ambient mesh – attach strace to fortio’s PID&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Why would this happen? It makes sense that the write calls are unchanged since they are entirely based on the application behavior which is not changed in this case. Ambient coalesces these multiple application writes and converts them into a single network write and by implication a single read in the peer.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In the test scenario above I observed a 60% reduction in total syscalls by the fortio service with ambient enabled. This is &lt;strong&gt;&lt;em&gt;very&lt;/em&gt;&lt;/strong&gt; substantial and explains the majority of the improvement in latency and ~25% CPU reduction of the fortio pod at peak time with ambient&lt;strong&gt;. &lt;/strong&gt;The reduction in syscalls is more than offsetting the cost of mTLS and the other features of ztunnel. I expect this pattern to be quite common in enterprise with some HTTP libraries and applications doing a better job of buffering and flushing and some not so much. Often this will correlate with the age of applications and the SDKs they were built on.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXckX5qK1dCRPqok1gI6sHxku5DJJxzFAmapskr64-aYLcqipl8umxksqvZ0Z8na1Bdp-ScO8a85gKB3WiO72BQLmDrVozVzfq6L69xdD9j-aagct2AOfPX8Aq5RE7_4ykgMwysUbb16gsiO7RL3w993LZF-?key=7Xu51UOF6Vd1czS7dgW7gA&#34; alt=&#34;Image&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;No mesh and ambient runs: Fortio to the details service 100 QPS 10 connections&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;What about the entire Bookinfo application?&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;With the newly updated details and productpage deployments, I started with sending 1000 RPS via 100 connections to the Bookinfo application, and observed great results for no mesh and ambient.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXeUhDIyse5YzHS0A73L7-g_kkXGijAzrF3dhDTs7aSlU6GcyI6vpo_GcyhR0gz-TtlMdUfvT-Tz62TXqK3pvskvgTPASkH16IYpseRgauXP0o7pgjLIHNEdp03CYWv99-kf9-iYlkpbaMwpmaaiENEL4bSC?key=7Xu51UOF6Vd1czS7dgW7gA&#34; alt=&#34;Image&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;No Mesh: Fortio to the new Bookinfo app 1000 RPS 100 connections.&lt;br&gt;&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full is-resized&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1600&#34; height=&#34;493&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/08/istio-1.png&#34; alt=&#34;Ambient: Fortio to the new Bookinfo app 1000 RPS 100 connections&#34; class=&#34;wp-image-116452&#34; style=&#34;width:900px;height:auto&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/08/istio-1.png 1600w, https://www.cncf.io/wp-content/uploads/2024/08/istio-1-300x92.png 300w, https://www.cncf.io/wp-content/uploads/2024/08/istio-1-1024x316.png 1024w, https://www.cncf.io/wp-content/uploads/2024/08/istio-1-768x237.png 768w, https://www.cncf.io/wp-content/uploads/2024/08/istio-1-900x277.png 900w, https://www.cncf.io/wp-content/uploads/2024/08/istio-1-600x185.png 600w, https://www.cncf.io/wp-content/uploads/2024/08/istio-1-1200x370.png 1200w&#34; sizes=&#34;(max-width: 1600px) 100vw, 1600px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Ambient: Fortio to the new Bookinfo app 1000 RPS 100 connections&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-fixed-layout&#34;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Fortio to Bookinfo&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Average&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P50&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P75&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P90&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P99&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Average Differences&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;No Mesh&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;1.39ms&lt;/td&gt;&lt;td&gt;1.32ms&lt;/td&gt;&lt;td&gt;1.42ms&lt;/td&gt;&lt;td&gt;1.67ms&lt;/td&gt;&lt;td&gt;2.19ms&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Ambient&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;1.40ms&lt;/td&gt;&lt;td&gt;1.34ms&lt;/td&gt;&lt;td&gt;1.48ms&lt;/td&gt;&lt;td&gt;1.68ms&lt;/td&gt;&lt;td&gt;2.94ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Less than 1% slower for average and P90&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;&lt;em&gt;Table 4: Fortio to the new Bookinfo app 1000 RPS 100 connections.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For comparison, I also ran the same test against the old Bookinfo sample shipped in v1.22.3, and you can see that the new Bookinfo made &lt;strong&gt;5-10X&lt;/strong&gt; improvements on response times, for either no mesh or ambient!&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-fixed-layout&#34;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Fortio to Bookinfo&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Average&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P50&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P75&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P90&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P99&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Average Differences&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;No Mesh&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;6.35ms&lt;/td&gt;&lt;td&gt;4.68ms&lt;/td&gt;&lt;td&gt;7.44ms&lt;/td&gt;&lt;td&gt;11.4ms&lt;/td&gt;&lt;td&gt;36.63ms&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Ambient&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;6.74ms&lt;/td&gt;&lt;td&gt;4.9ms&lt;/td&gt;&lt;td&gt;7.79ms&lt;/td&gt;&lt;td&gt;12.12ms&lt;/td&gt;&lt;td&gt;41.14ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;6% slower&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Table 5: Fortio to the old Bookinfo app 1000 RPS 100 connections&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Increased the load to 4000 RPS with 400 connections with the new Bookinfo deployments:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXcgUs18Og7Bcmeq5hw8UjiCDB3BJ7fG7h7f8NWeJGnPFmKShR189-K4humffSN-YEPtVnGssIJoRDWEHw9Ju6MmWW9hedRHdTDS29l6z9OEfh5Jp7CT5GR66RQ8tVeDW_muGy1Zl5hJSJrCGKLAVukvH3k?key=7Xu51UOF6Vd1czS7dgW7gA&#34; alt=&#34;Image&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;No Mesh: Fortio to the new Bookinfo app 4000 RPS 400 connections&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXfwlAWXixnPjf9bfZCBc61qZLIVGMnHcxiUl7e_yFc4ApV_PJsXTF6YyVCx1NNRhfSTaNNkcW1xKqw-igF716pNF9dCoPra8lEPwIRLu8Rm_1bnUj06Bh0Ca6gVsZmpxN_N2hYaMCHH89G27Xfy2aAeUC5n?key=7Xu51UOF6Vd1czS7dgW7gA&#34; alt=&#34;Image&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Ambient: Fortio to the new Bookinfo app 4000 RPS 400 connections&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The response times are still very good, way better than the old Bookinfo app with only 1000 RPS and 100 connections (Table 5):&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-fixed-layout&#34;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Fortio to Bookinfo&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Average&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P50&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P75&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P90&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P99&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Average Differences&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;No Mesh&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;1.54ms&lt;/td&gt;&lt;td&gt;1.33ms&lt;/td&gt;&lt;td&gt;1.54ms&lt;/td&gt;&lt;td&gt;2.25ms&lt;/td&gt;&lt;td&gt;3.98ms&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Ambient&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;1.58ms&lt;/td&gt;&lt;td&gt;1.37ms&lt;/td&gt;&lt;td&gt;1.57ms&lt;/td&gt;&lt;td&gt;2.33ms&lt;/td&gt;&lt;td&gt;4.9ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;3% slower on average and 4% slower on P90&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Table 6: Fortio to the new Bookinfo app 4000 RPS 400 connections&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;It is really nice to see that Bookinfo handles 4000 RPS without any errors and ambient mode is about 3-4% slower than no mesh with all the benefits of encryption in transit with mTLS and L4 observability. I recall I could only reach up to 1200 RPS with the old Bookinfo app, which already resulted in a small percentage of errors. Now I can increase loads to 4000 or higher RPS without errors.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Wrapping up:&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Ambient mode at L4 introduces only a very tiny impact — and occasionally even an automatic &lt;em&gt;improvement&lt;/em&gt;! — to users’ application latencies. Combined with the simple UX by labeling the namespace to enroll your application to ambient without restarting any workloads, it provides a delightful experience to users that we intended when we initially named it ambient.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;I would like to thank all of our Istio maintainers who built such a delightful project and CNCF for providing the Istio project access to the &lt;a href=&#34;https://www.cncf.io/community-infrastructure-lab/&#34;&gt;infrastructure lab&lt;/a&gt; where I performed the test. I would also like to thank Quentin Joly and many users who provided me with the “ambient is slighter faster than no mesh sometimes” feedback which triggered me to run the above benchmark tests to experience the improvement or tiny latency impact under load for myself.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;社区帖子最初发布于&lt;a href=&#34;https://thenewstack.io/ambient-mesh-can-sidecar-less-istio-make-applications-faster/&#34;&gt;新堆栈&lt;/a &gt; 作者：Lin Sun&lt;/em&gt;，&lt;em&gt;Solo.io 开源主管&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;环境模式是 2022 年 Istio 中引入的新的无 sidecar 数据平面。当环境模式达到&lt;a href=&#34;https://istio.io/latest/blog/2024/ambient-reaches-beta/&#34;&gt;今年 5 月处于 Beta&lt;/a&gt; 状态，我开始看到许多用户在将应用程序添加到网格后进行尝试并运行负载测试，以了解性能影响。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;受到 &lt;a href=&#34;https://a-cup-of.coffee/blog/istio/#with-istio-ambient&#34;&gt;Quentin Joly 的博客&lt;/a&gt;的启发，了解 Istio 在环境模式下令人难以置信的性能社区中其他用户的类似反馈表明，有时应用程序在环境模式下速度会稍快一些，因此我决定亲自验证这些结果。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;测试环境：&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我使用了 3 个工作节点 Kubernetes 集群，每个节点有 256GB RAM 和 32 核 CPU。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXfS50HjjsJiBqlv30JKgaaTJcmUq0hHcG3xNl42Yzd7E0FfKPAe0gI3tnNAx0gpud0LGfHkdI7cbTXJyzU5v46 v-kucl-2_l7Lax0-kvCeG19mST3ToJdIu6r5u7BoYkAGVc14HnRyVlnX9TY_Ra9NilKQ?key=7Xu51UOF6Vd1czS7dgW7gA&#34; alt= “图片”referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Istio 使用一些工具来轻松进行一致的基准测试。  首先，我们使用名为 &lt;a href=&#34;https://github.com/fortio/fortio&#34;&gt;fortio&lt;/a&gt; 的负载测试工具，它以指定的每秒请求数 (RPS) 运行，记录执行直方图时间并计算百分位数 - 例如，P99，即 99% 的请求花费的时间少于该数字的响应时间。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们还提供了一个名为 &lt;a href=&#34;https://istio.io/latest/docs/examples/bookinfo/&#34;&gt;Bookinfo&lt;/a&gt; 的示例应用程序，其中包括用 Python、Java、Node.js 编写的微服务。 Node.js 和 Ruby。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;每个 Bookinfo 部署都有 2 个副本，均匀分布到 3 个工作节点。使用 &lt;a href=&#34;https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity&#34;&gt;pod 反亲和性规则&lt;/a&gt;，我确保将 fortio 放置在与 &lt;a href=&#34;https://github.com/istio/istio/tree/master/samples/bookinfo/src/details&#34;&gt;details&lt;/a&gt; 服务不同的节点上。&lt; /p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;初始测试结果&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我从 Istio v1.22.3 版本安装了 Bookinfo 应用程序。使用 fortio 工具驱动单个 Bookinfo 服务（例如详细信息）或完整 Bookinfo 应用程序的负载，我注意到将所有内容添加到环境网格后&lt;strong&gt;接近零延迟影响&lt;/strong&gt;。大多数时候，平均值或 P90 的增幅在 0-5% 范围内。我一直注意到 Istio 环境模式下的详细信息服务稍微快一些，就像 Quentin 在他的博客中报告的那样。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3类=“wp-block-heading&#34;&gt;对详细信息服务进行负载测试&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我做了与 Quentin 相同的测试，通过 10 个连接发送 100 RPS 到详细信息服务，并收集了无网格和环境的结果。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXfc1vCggIDlIXmGqt-ac1pUzDPHZd2feGf-TvJRpQu-nmCwXGVliCE8nB2CT_wkVMPibKKFOtjAQ1aj5zxQ-ivUQj74JFEtVZ GwioAYbKLsLeuADG6dhTsvMqaYCvtZk3XlYHTFop6gc-z3zysDhyTrekuU?key= 7Xu51UOF6Vd1czS7dgW7gA&#34; alt=&#34;无网格：详细信息服务 100 RPS&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;无网格：详细信息服务 100 RPS&lt;/figcaption&gt;&lt;/图&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXdIB88W4APYre6YtZPZ90pRKvuoAFO05xhIaFXL50Y1PzD6LmZ0SoBTdgc6SMZSBar8LaNi5uWzDMA18_pEUZ9W_r1kiyiz9 WwtcHMQQMkC6i4avrYLdsMlY8wGFc0FwEUR9VUvy-GSeaUJhAI8HK_fgJXB?key=7Xu51UOF6Vd1czS7dgW7gA&#34; alt=&#34;图片&#34; 推荐政策=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;环境：详细信息服务 100 RPS&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;就像 Quentin 一样，我必须运行多个测试来验证环境模式比没有网格的性能稍好 - 这很难相信！就 Bookinfo 详细信息服务而言，添加环境模式可将延迟平均改善 6-11%，同时还添加 mTLS 和 L4 可观察性！&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-fixed-layout&#34;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Fortio &lt;/strong&gt;&lt;strong&gt;详细信息&lt;/strong&gt; &lt;/td&gt;&lt;td&gt;&lt;strong&gt;平均&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P50&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P75&lt;/strong&gt;&lt;/td&gt;&lt; td&gt;&lt;strong&gt;P90&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P99&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;差异&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr &gt;&lt;td&gt;&lt;strong&gt;无网格运行 1&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;0.89ms&lt;/td&gt;&lt;td&gt;0.64ms&lt;/td&gt;&lt;td&gt;0.74ms&lt;/td&gt;&lt;td&gt;0.85 ms&lt;/td&gt;&lt;td&gt;2.67ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;平均慢 11%，P90 慢 5%&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt; strong&gt;环境运行1&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;0.80ms&lt;/td&gt;&lt;td&gt;0.6ms&lt;/td&gt;&lt;td&gt;0.71ms&lt;/td&gt;&lt;td&gt;0.81ms&lt;/td&gt;&lt; td&gt;1.4ms&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;无网格运行 2&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;0.86ms&lt;/td&gt;&lt; td&gt;0.65ms&lt;/td&gt;&lt;td&gt;0.75ms&lt;/td&gt;&lt;td&gt;0.86ms&lt;/td&gt;&lt;td&gt;1.71ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;平均慢 6%，慢 4%对于 P90&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;环境运行 2&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;0.81ms&lt;/td&gt;&lt;td&gt;0.61ms&lt;/ td&gt;&lt;td&gt;0.72ms&lt;/td&gt;&lt;td&gt;0.83ms&lt;/td&gt;&lt;td&gt;1.56ms&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;否网格运行3&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;0.90ms&lt;/td&gt;&lt;td&gt;0.65ms&lt;/td&gt;&lt;td&gt;0.76ms&lt;/td&gt;&lt;td&gt;0.88ms&lt;/td&gt;&lt;td&gt; 1.92ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;平均慢 10%，P90 慢 5%&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;环境运行 3&lt;/strong &gt;&lt;/td&gt;&lt;td&gt;0.82ms&lt;/td&gt;&lt;td&gt;0.63ms&lt;/td&gt;&lt;td&gt;0.72ms&lt;/td&gt;&lt;td&gt;0.84ms&lt;/td&gt;&lt;td&gt;1.5ms&lt;/td&gt; &lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;表 1：Fortio 到详细信息服务 100 RPS 10 个连接&lt;/figcaption&gt;&lt;/figure &gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;为什么应用程序有时在环境网格中速度更快？&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们被告知服务网格可以添加延迟。此处复制的 Quentin 的结果显示了通过服务网格运行时工作负载&lt;em&gt;更快&lt;/em&gt;的情况。发生了什么事？&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;第一个理论&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;当您的应用程序位于环境网格中时，负载请求首先通过名为 &lt;a href=&#34;https://istio.io/latest/docs/ambient/overview/#ztunnel&#34;&gt;ztunnel 的轻量级本地节点代理传输&lt;/a&gt;，然后到目的地 ztunnel，然后继续到服务。详细信息服务使用 HTTP/1.1 和 Ruby 中的 Webrick 库，我们发现旧的或配置不当的 HTTP 库中的连接管理和保持活动行为很差。我的第一个假设是，当客户端和服务器位于不同节点上时，如果应用程序未使用高效的 HTTP/2 连接，则通过客户端和服务器 ztunnel 进行代理实际上可能会更快。 Ztunnel 使用连接池和 &lt;a href=&#34;https://en.wikipedia.org/wiki/HTTP_tunnel&#34;&gt;HTTP Connect&lt;/a&gt; 在节点之间建立安全隧道，以在负载下利用并行性和 HTTP/2 流复用。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXdkVHCotSRWKoih2aQLCioo38lsv_PtQFILzTPQvVd3vZYFY5VKaIoVPH_VWLeLla9yZGZBhiTo5H1wH-O3EApb2RvUjM- A3Q5k8B9ffCIoN12sRL8UG_FMLIhxti0iZaYXWu7dttoiubPD0GyDyKDcGmE?key=7Xu51UOF6Vd1czS7dgW7gA&#34; alt=&#34;图像“referrerpolicy =“no-referrer”&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;然而，这一理论存在一些挑战。为什么我只在详细信息服务中观察到这一点，而在任何其他 Bookinfo 服务中却没有观察到这一点？&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;进一步研究，我发现我们的 fortio 加载工具具有 &lt;a href=&#34;https://github.com/fortio/fortio/blob/8a7d9112667e637139c788b68cb063f456d20cb4/bincommon/commonflags.go#L55&#34;&gt;通过以下方式启用连接保持活动状态默认&lt;/a&gt;。从 fortio 到详细信息服务有 10 个连接，并且详细信息服务（使用 WEBrick Ruby 库）遵循连接保持活动设置，因此可以在没有环境的情况下有效地重用连接。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;连接关闭时进行负载测试&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;接下来，我尝试通过设置“Connection: close”标头来运行相同的负载测试。这会强制禁用任何 HTTP 连接池，这是测试这一假设的好方法。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;curl -v -d &#39;{&#34;metadata&#34;: {&#34;url&#34;:&#34;http://details:9080/details/0&#34;, &#34; c”：“10”，“qps”：“100”，“n”：“2000”，“异步”：“on”，“保存”：“on”}}&#39;“localhost：8081/fortio/rest/ run?jsonPath=.metadata&#34; -H &#34;连接：关闭&#34;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXfc-HDPourI5Dwlo3n-jkc5TMiqJdm0k0oSb1Z4HZkKIkVgCKKFyJbBv6fp40pS6XwTORrUvYSYfmL7M6Dqu7ZdBSiJYv Xo-O7f4weYTsuQHarX3uit-jQEL4HlWiwNc7PEFPS1DQgm6csv5FhdMhXxUUc?key=7Xu51UOF6Vd1czS7dgW7gA&#34; alt=&#34;图片&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;无网格：Fortio 到详细服务 100 RPS 10 个连接h 连接关闭&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXfBoHXMf2xaXMboBVCNYNmDBkoFIdefso_IbfLft83aStyTTcm4yOAv3zkEwUtddn1gnFZgT9tf_Z0S494iE6TliMgHFuv24T nEMEDdXsFtk2JcS41jUZhTTvAljd9bDA25AGqyjKlt_ZUjZUDoawkBmwP4?key=7Xu51UOF6Vd1czS7dgW7gA&#34; alt=&#34;图片&#34;referrerpolicy=&#34; no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;环境：Fortio 到详细信息服务 100 RPS 10 连接，连接关闭&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-fixed-layout&#34;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Fortio &lt;/strong&gt;&lt;strong&gt;详细信息&lt;/strong&gt; &lt;/td&gt;&lt;td&gt;&lt;strong&gt;平均&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P50&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P75&lt;/strong&gt;&lt;/td&gt;&lt; td&gt;&lt;strong&gt;P90&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P99&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;差异&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr &gt;&lt;td&gt;&lt;strong&gt;无网格&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;1.90ms&lt;/td&gt;&lt;td&gt;1.72ms&lt;/td&gt;&lt;td&gt;2.28ms&lt;/td&gt;&lt;td&gt;2.77ms&lt; /td&gt;&lt;td&gt;3.98ms&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;环境&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;2.06ms&lt;/td&gt; &lt;td&gt;2.15ms&lt;/td&gt;&lt;td&gt;2.65ms&lt;/td&gt;&lt;td&gt;2.94ms&lt;/td&gt;&lt;td&gt;4ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;平均慢 8%，慢 6%对于 P90&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;表 2：Fortio 到详细信息服务 100 RPS 10 个连接（连接关闭）&lt; /图标题&gt;&lt;/图&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;与表 1 结果相比，表 2 数字的响应时间要长得多，这是预期的，因为每个连接在详细信息服务的每次响应后立即关闭。鉴于 P50、P75、P90 和 P99 在连接关闭的环境运行中都较慢，因此可以安全地从第一个理论中排除 ztunnel 中的连接池可以使请求更快。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;第二种理论&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我注意到 John Howard 在详细信息和产品页面服务中有一个 &lt;a href=&#34;https://github.com/istio/istio/pull/51428/files&#34;&gt;与性能相关的 PR&lt;/a&gt;我们新的 Istio v1.23 版本中的 Bookinfo 应用程序。对于详细信息服务，PR 为详细信息 WEBrick 服务器启用了 &lt;a href=&#34;https://brooker.co.za/blog/2024/05/09/nagle.html&#34;&gt;TCP_NODELAY&lt;/a&gt; 标志，这将减少响应时间中不必要的延迟（最多 &lt;a href=&#34;https://vorner.github.io/2020/11/06/40-ms-bug.html&#34;&gt;40ms&lt;/a&gt;）细节服务。  对于productpage 服务，PR 启用了传入请求的保持活动状态，这将重用现有的传入连接，从而提高性能。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;通过包含修复程序的最新更新的详细信息部署，我重复了相同的测试，通过 10 个连接向详细信息服务发送 100 RPS。无网格和环境的结果非常接近，因此我将每个测试运行了三次以确保结果一致。以下是每个场景第一次运行的屏幕截图：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXdjKAWCsxQBxdyihff3W_P4lB51q2BrhbDaqaF2zPooyH2LaoKVgZhFvhAVkBoUteAa0e3XNaBprLWLW6SweAsNw1YmFuk7FbDnnZKwVLC84URGBRt839qLPXKDOkI9F4dIfJU6UcVCaFbMfXEHpSmQlnph?key=7Xu51UOF6Vd1czS7dgW7gA&#34; alt=&#34;无网格：Fortio 到新的详细信息服务 100 RPS 10 个连接&#34; Caption class=&#34;wp-element-caption&#34;&gt;无网格：Fortio 到新的详情服务 100 RPS 10 个连接&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXe2lvcrz94RNS_ewSFqOFRy01z3RRRs5kh7Fx8boQiGHGMHIzaRsO4Fmfo-3wOFAmnPez0SmDJsPiBRqq85L7_5xfOjdDhJbTef dG6QB-bZVmXhgwuNtZOHFpiLtvceT_OmEm7UMdkdXdlHe9OXGJ6tCTeX?key=7Xu51UOF6Vd1czS7dgW7gA&#34; alt=&#34;环境：Fortio 到新的详细信息服务 100 RPS 10 个连接”referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我为每个场景的三次运行构建了一个表：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-fixed-layout&#34;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td colspan=&#34;2&#34;&gt;&lt;strong&gt;Fortio 至 &lt;/strong&gt;&lt;strong&gt;详细信息&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;平均&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P50&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P75&lt;/strong&gt; &lt;/td&gt;&lt;td&gt;&lt;strong&gt;P90&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P99&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;差异&lt;/strong&gt;&lt;/td&gt;&lt; /tr&gt;&lt;tr&gt;&lt;td rowspan=&#34;2&#34;&gt;&lt;strong&gt;1&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;无网格&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;0.76ms&lt;/td &gt;&lt;td&gt;0.58ms&lt;/td&gt;&lt;td&gt;0.69ms&lt;/td&gt;&lt;td&gt;0.81ms&lt;/td&gt;&lt;td&gt;1.56ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;平均慢 5%，P90 。 P99 上慢 25%&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;环境&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;0.72ms&lt;/td&gt;&lt;td&gt;0.57ms&lt; /td&gt;&lt;td&gt;0.66ms&lt;/td&gt;&lt;td&gt;0.76ms&lt;/td&gt;&lt;td&gt;1.24ms&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&#34;2 &#34;&gt;&lt;strong&gt;2&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;无网格&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;0.72ms&lt;/td&gt;&lt;td&gt;0.59ms&lt;/td&gt;&lt;td &gt;0.7ms&lt;/td&gt;&lt;td&gt;0.82ms&lt;/td&gt;&lt;td&gt;1.6ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P90 上慢 3%&lt;/strong&gt; &lt;strong&gt;和&lt;/strong&gt; &lt;strong P99 上速度慢 &gt;18%&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;环境光&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;0.76ms&lt;/td&gt;&lt;td&gt;0.59ms &lt;/td&gt;&lt;td&gt;0.69ms&lt;/td&gt;&lt;td&gt;0.8ms&lt;/td&gt;&lt;td&gt;1.37ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;平均慢 5%&lt;/strong&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&#34;2&#34;&gt;&lt;strong&gt;3&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;无网格&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;0.77ms&lt;/ td&gt;&lt;td&gt;0.58ms&lt;/td&gt;&lt;td&gt;0.7ms&lt;/td&gt;&lt;td&gt;0.8ms&lt;/td&gt;&lt;td&gt;1.49ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;平均慢 1% P99 上慢 8%&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;环境&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;0.76ms&lt;/td&gt;&lt;td&gt;0.59ms&lt; /td&gt;&lt;td&gt;0.69ms&lt;/td&gt;&lt;td&gt;0.81ms&lt;/td&gt;&lt;td&gt;1.38ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P90 上慢 1%&lt;/strong&gt;&lt;/td&gt;&lt; /tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;表 3：Fortio 到新的详细信息服务 100 RPS 10 个连接&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;与表 1 中的先前结果相比，表 3 中的无网格数已改善相当多（比环境数更高的百分比），现在更接近环境数。 Ztunnel 默认启用 &lt;a href=&#34;https://github.com/istio/ztunnel/pulls?q=is%3Apr+is%3Aclose+TCP_NODELAY&#34;&gt;TCP_NODELAY&lt;/a&gt;，这有助于改善环境性能当旧的详细信息服务未启用 TCP_NODELAY 时，表 1 中没有网格。当新的详细信息服务启用 TCP_NODELAY 时，它具有所有因此稍微改善了环境响应时间。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;表 3 还显示，对于启用 TCP_NODELAY 的新详细信息服务进行此类负载测试，无网格运行和环境运行之间的平均值、P50、P75、P90 没有太大差异。这些运行之间的差异可能是噪音，但 P99 除外，其中无网格始终慢 8% 或更多。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;第三种理论&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;继续查看表 3 中的测试结果，当到 ztunnel pod 的额外跳数以及环境提供的显着优势（例如 fortio 和细节服务之间的 mTLS 和 L4 可观察性）时，为什么无网格和环境之间会存在类似的延迟？对于P99的情况，为什么环境模式下的细节服务会始终更快？ &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Ztunnel 通过 HTTP/2 多路复用提供出色的读/写缓冲区管理，这可以有效地最小化甚至有时甚至消除通过客户端和服务器 ztunnel pod 的额外跃点所增加的开销。我决定通过使用来自 fortio 和细节服务的 &lt;a href=&#34;https://strace.io/&#34;&gt;strace&lt;/a&gt; 的系统调用来测量这一点，方法是进入 Kubernetes 工作节点并使用 strace while filter 附加 pid去掉不相关的痕迹：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;strace -fp {pid} -e trace=write,writev,read,recvfrom,sendto,readv&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;对于无网格和环境情况，详细信息服务的 strace 输出类似：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;...&#xA;读取（9，“GET /details/0 HTTP/1.1\r\n主机：d”...，8192）= 118&#xA;写（9，“HTTP/1.1 200 OK\r\n内容类型：a”...，180）= 180&#xA;写(9, &#34;{\&#34;id\&#34;:0,\&#34;作者\&#34;:\&#34;William Shakes&#34;..., 178) = 178&#xA;写（2，“192.168.239.19 - - [2024年8月13日：”...，80）= 80&#xA;...&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;输出 1：无网格或环境 - 将 strace 附加到详细信息服务的 PID&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;fortio 服务对于无网格和环境的 strace 输出是不同的。在无网格的情况下，我们看到 fortio 执行了两次读取，一次针对 HTTP 标头，另一次针对正文。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;...&#xA;读取（13，“HTTP/1.1 200 OK\r\n内容类型：a”...，4096）= 180&#xA;读(13, &#34;{\&#34;id\&#34;:0,\&#34;作者\&#34;:\&#34;William Shakes&#34;..., 4096) = 178&#xA;……&#xA;写（19，“获取/详细信息/0 HTTP/1.1\r\n主机：d”...，118）= 118&#xA;...&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;输出 2：无网格 - 将 strace 附加到 fortio 的 PID&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在环境情况下，我们始终看到标题和正文都只读取一次。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;...&#xA;读取（19，“HTTP/1.1 200 OK\r\n内容类型：a”...，4096）= 358&#xA;……&#xA;写（19，“获取/详细信息/0 HTTP/1.1\r\n主机：d”...，118）= 118&#xA;...&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;输出 3：环境网格 - 将 strace 附加到 fortio 的 PID&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;为什么会发生这种情况？写调用保持不变是有道理的，因为它们完全基于应用程序行为，在这种情况下不会改变。环境将这些多因素结合在一起多个应用程序写入并将它们转换为单个网络写入，并暗示对等体中的单个读取。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在上面的测试场景中，我观察到启用环境的 fortio 服务的系统调用总数减少了 60%。这是&lt;strong&gt;&lt;em&gt;非常&lt;/em&gt;&lt;/strong&gt;的重要原因，并且解释了使用环境&lt;strong&gt;在高峰时间 fortio pod 的延迟改善和约 25% CPU 减少的大部分原因。系统调用的减少足以抵消 mTLS 和 ztunnel 其他功能的成本。我预计这种模式在企业中非常常见，一些 HTTP 库和应用程序在缓冲和刷新方面做得更好，而另一些则不然。通常，这与应用程序的年龄及其构建的 SDK 相关。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXckX5qK1dCRPqok1gI6sHxku5DJJxzFAmapskr64-aYLcqipl8umxksqvZ0Z8na1Bdp-ScO8a85gKB3WiO72BQLmDrVozVzf q6L69xdD9j-aagct2AOfPX8Aq5RE7_4ykgMwysUbb16gsiO7RL3w993LZF-?key=7Xu51UOF6Vd1czS7dgW7gA&#34; 替代=&#34;Image&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;无网格和环境运行：Fortio 到详细信息服务 100 QPS 10 个连接&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;整个 Bookinfo 应用程序怎么样？&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;通过新更新的详细信息和产品页面部署，我开始通过 100 个连接向 Bookinfo 应用程序发送 1000 RPS，并观察到没有网格和环境的良好结果。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXeUhDIyse5YzHS0A73L7-g_kkXGijAzrF3dhDTs7aSlU6GcyI6vpo_GcyhR0gz-TtlMdUfvT-Tz62TXqK3pvskvgTPAS kH16IYpseRgauXP0o7pgjLIHNEdp03CYWv99-kf9-iYlkpbaMwpmaaiENEL4bSC?key= 7Xu51UOF6Vd1czS7dgW7gA&#34; alt=&#34;Image&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;无网格：Fortio 到新的 Bookinfo 应用程序 1000 RPS 100 个连接。&lt;br&gt;&lt;/figcaption&gt;&lt;/图&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full is-resized&#34;&gt;&lt;imgloading=&#34;lazy&#34;decoding=&#34;async&#34;width=&#34;1600&#34;height=&#34;493&#34;src=&#34;https://www.cncf .io/wp-content/uploads/2024/08/istio-1.png&#34; alt=&#34;Ambient：Fortio 到新 Bookinfo 应用程序 1000 RPS 100 个连接&#34; class=&#34;wp-image-116452&#34; style=&#34;width:900px ;高度：自动” srcset =“https://www.cncf.io/wp-content/uploads/2024/08/istio-1.png 1600w，https://www.cncf.io/wp-content/uploads /2024/08/istio-1-300x92.png 300w，https://www.cncf.io/wp-content/uploads/2024/08/istio-1-1024x316.png 1024w，https://www.cncf .io/wp-content/uploads/2024/08/istio-1-768x237.png 768w，https://www.cncf.io/wp-content/uploads/2024/08/istio-1-900x277.png 900w ，https://www.cncf.io/wp-content/uploads/2024/08/istio-1-600x185.png 600w，https://www.cncf.io/wp-content/uploads/2024/08/ istio-1-1200x370.png 1200w&#34;sizes=&#34;(max-width: 1600px) 100vw, 1600px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;环境：Fortio 到新书信息应用程序 1000 RPS 100 个连接&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-fixed-layout&#34;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Fortio 到 Bookinfo&lt;/strong&gt;&lt;/td&gt;&lt;td&gt; &lt;strong&gt;平均&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P50&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P75&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P90&lt; /strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P99&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;平均差异&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong &gt;无网格&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;1.39ms&lt;/td&gt;&lt;td&gt;1.32ms&lt;/td&gt;&lt;td&gt;1.42ms&lt;/td&gt;&lt;td&gt;1.67ms&lt;/td&gt;&lt;td&gt; 2.19ms&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;环境&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;1.40ms&lt;/td&gt;&lt;td&gt;1.34ms&lt; /td&gt;&lt;td&gt;1.48ms&lt;/td&gt;&lt;td&gt;1.68ms&lt;/td&gt;&lt;td&gt;2.94ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;平均和 P90 慢不到 1%&lt;/strong&gt;&lt; /td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;&lt;em&gt;表 4：Fortio 到新 Bookinfo 应用程序 1000 RPS 100 个连接。&lt;/em&gt;&lt;/图标题&gt;&lt;/图&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;为了进行比较，我还对 v1.22.3 中提供的旧 Bookinfo 示例进行了相同的测试，您可以看到新的 Bookinfo 在响应时间上取得了 &lt;strong&gt;5-10X&lt;/strong&gt; 改进，无论是没有网格或环境！&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-fixed-layout&#34;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Fortio 到 Bookinfo&lt;/strong&gt;&lt;/td&gt;&lt;td&gt; &lt;strong&gt;平均&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P50&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P75&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P90&lt; /strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P99&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;平均差异&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong &gt;无网格&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;6.35ms&lt;/td&gt;&lt;td&gt;4.68ms&lt;/td&gt;&lt;td&gt;7.44ms&lt;/td&gt;&lt;td&gt;11.4ms&lt;/td&gt;&lt;td&gt; 36.63ms&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;环境&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;6.74ms&lt;/td&gt;&lt;td&gt;4.9ms&lt; /td&gt;&lt;td&gt;7.79ms&lt;/td&gt;&lt;td&gt;12.12ms&lt;/td&gt;&lt;td&gt;41.14ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;慢 6%&lt;/strong&gt;&lt;/td&gt;&lt;/tr &gt;&lt;/tbody&gt;&lt;/table&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;表 5：Fortio 到旧 Bookinfo 应用程序 1000 RPS 100 个连接&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;通过新的 Bookinfo 部署将负载增加到 4000 RPS，具有 400 个连接：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXcgUs18Og7Bcmeq5hw8UjiCDB3BJ7fG7h7f8NWeJGnPFmKShR189-K4humffSN-YEPtVnGssIJoRDWEHw9Ju6MmWW9hedRHd TDS29l6z9OEfh5Jp7CT5GR66RQ8tVeDW_muGy1Zl5hJSJrCGKLAVukvH3k?key=7Xu51UOF6Vd1czS7dgW7gA&#34; alt=&#34;图像&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;无网格：Fortio 到新的 Bookinfo 应用程序 4000 RPS 400 个连接&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXfwlAWXixnPjf9bfZCBc61qZLIVGMnHcxiUl7e_yFc4ApV_PJsXTF6YyVCx1NNRhfSTaNNkcW1xKqw-igF716pNF9dCoP ra8lEPwIRLu8Rm_1bnUj06Bh0Ca6gVsZmpxN_N2hYaMCHH89G27Xfy2aAeUC5n?key=7Xu51UOF6Vd1czS7dgW7gA&#34; alt=&#34;图片&#34; 推荐政策=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;环境：Fortio 到新的 Bookinfo 应用程序 4000 RPS 400 连接&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;响应时间仍然非常好，比只有 1000 RPS 和 100 个连接的旧 Bookinfo 应用程序要好得多（表 5）：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-fixed-layout&#34;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Fortio 到 Bookinfo&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;平均&lt;/strong&gt;&lt;/td&gt;&lt; td&gt;&lt;strong&gt;P50&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P75&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P90&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt; P99&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;平均差异&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;无网格&lt;/strong&gt;&lt;/td&gt;&lt;td &gt;1.54ms&lt;/td&gt;&lt;td&gt;1.33ms&lt;/td&gt;&lt;td&gt;1.54ms&lt;/td&gt;&lt;td&gt;2.25ms&lt;/td&gt;&lt;td&gt;3.98ms&lt;/td&gt;&lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;环境&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;1.58ms&lt;/td&gt;&lt;td&gt;1.37ms&lt;/td&gt;&lt;td&gt;1.57ms&lt;/td&gt;&lt; td&gt;2.33ms&lt;/td&gt;&lt;td&gt;4.9ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;平均慢 3%，P90 慢 4%&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt; &lt;/table&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;表 6：Fortio 到新 Bookinfo 应用程序 4000 RPS 400 个连接&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;很高兴看到 Bookinfo 可以毫无错误地处理 4000 RPS，环境模式比无网格慢约 3-4%，并且具有 mTLS 和 L4 可观测性传输加密的所有优势。我记得使用旧的 Bookinfo 应用程序只能达到 1200 RPS，这已经导致了一小部分错误。现在我可以将负载增加到 4000 或更高 RPS，而不会出现错误。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;总结：&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;L4 的环境模式只会产生非常微小的影响 - 有时甚至会自动&lt;em&gt;改进&lt;/em&gt;！ — 用户的应用程序延迟。通过标记命名空间来将应用程序注册到环境中而无需重新启动任何工作负载，与简单的用户体验相结合，它为用户提供了令人愉快的体验，这正是我们最初将其命名为环境时所希望的。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我要感谢所有 Istio 维护者，他们构建了如此令人愉快的项目，并感谢 CNCF 为 Istio 项目提供了对 &lt;a href=&#34;https://www.cncf.io/community-infrastruct-lab/ 的访问权限我进行测试的“基础设施实验室”。我还要感谢 Quentin Joly 和许多用户，他们向我提供了“环境有时比没有网格要快一些”的反馈，这促使我运行上述基准测试，以亲自体验负载下的改进或微小的延迟影响。&lt; /p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Thu, 22 Aug 2024 16:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>