<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>CNCF - Blog</title>
    <link>http://cloudys-rsshub-ab061133bcab.herokuapp.com/cncf</link>
    <description>CNCF - Blog - Powered by RSSHub</description>
    <managingEditor>contact@rsshub.app (RSSHub)</managingEditor>
    <item>
      <title>【Combining GenAI &amp; Agentic AI to build scalable, autonomous systems】Combining GenAI &amp; Agentic AI to build scalable, autonomous systems</title>
      <link>https://www.cncf.io/blog/2025/08/18/combining-genai-agentic-ai-to-build-scalable-autonomous-systems/</link>
      <description>【&lt;p&gt;A common pattern in today’s AI adoption is that businesses are investing heavily in GenAI capabilities, yet many are leaving significant value on the table by failing to pair it with Agentic AI.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This matters because while GenAI can generate content, ideas, or responses, it can’t act on them. However, when combined with Agentic AI, your systems shift from being reactive and prompt-driven to autonomous and outcome-oriented.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This article aims to help senior technology leaders better understand the value Agentic AI can add to existing AI infrastructure, while outlining key considerations to determine whether its implementation aligns with your business needs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Understanding Agentic AI&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXdK_MTJsDbf-762dNxU9eeSNBT3MNJaoPxFvS8z3GqUeDcUbpuSI1dfo3sw6NSIvLJ_LaMarkzvCDtMVvSnrrWrwvSHj9OvfxWcUeAE5rkbzcQ1HzjX4hetnrrqbX35C5r1Gx_CXQ?key=xgu2lQTqMaowWCibuTxnzqRW&#34; alt=&#34;Image caption: Core components of an Agentic AI Architecture from Markovate.&amp;nbsp;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;&lt;strong&gt;Image caption: Core components of an Agentic AI Architecture from &lt;/strong&gt;&lt;/em&gt;&lt;a href=&#34;https://markovate.com/blog/agentic-ai-architecture/?utm_source=chatgpt.com&#34;&gt;&lt;strong&gt;&lt;em&gt;Markovate.&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt;&lt;em&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Agentic AI systems are designed to operate autonomously, perceiving their environment, making decisions, and executing actions without continuous human oversight.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This autonomy enables businesses to streamline operations, reduce costs, and enhance scalability.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The image above illustrates how the following systems function:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Perception layer:&lt;/strong&gt; This layer involves collecting data from various sources i.e. sensors, cameras, microphones, and digital inputs, to understand the current state of the environment. For businesses, this means real-time monitoring of operations, customer interactions, and market trends, facilitating proactive decision-making and rapid response to changing conditions.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Cognition layer:&lt;/strong&gt; Once data is collected, the cognition layer processes this information to interpret context, recognise patterns, and determine the best course of action. This analysis automates complex decision-making processes and reduces reliance on manual interventions, minimising the risk of human error.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Action layer: &lt;/strong&gt;After determining the appropriate response, the action layer executes the decision i.e. adjusting system parameters, initiating workflows, or communicating with stakeholders. This capability ensures quick implementation of decisions to enhance operational efficiency.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Ultimately, Agentic AI systems are equipped with learning mechanisms that improve over time.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Through techniques like reinforcement learning, where the system learns from the outcomes of its actions, and supervised or unsupervised learning, where it identifies patterns in data, the AI adapts to new situations and refines its decision-making processes.&amp;nbsp;&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;GenAI is great at creation, while Agentic AI brings decision-making and execution&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The most disruptive AI solutions over the next few years will combine GenAI with Agentic AI, and the key to achieving better business outcomes is knowing when to use one, the other, or both.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Not every use case requires a full agentic system, but many businesses will be surprised at how many should.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;GenAI alone:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;GenAI excels at generating new content from existing data patterns, significantly boosting creativity and productivity across various domains. In software engineering, tools like GitHub Copilot are increasingly used to automate routine tasks such as generating boilerplate code. This enables engineers to avoid repetitive work and focus on more complex, high-impact challenges. While a human-in-the-loop remains essential to ensure code quality and alignment, GenAI is already improving engineering efficiency and accelerating delivery.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In data science and engineering, GenAI supports teams facing surging data demands by improving accessibility and streamlining processing. Large language models (LLMs) help optimise how data is queried and managed, enabling faster and more accurate insights.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;GenAI tools also enhance data analysis and application development by allowing users to interact with data through natural language processing (NLP), unlocking insights without requiring SQL expertise.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In the case of Retrieval-Augmented Generation (RAG), GenAI can efficiently access relevant data sources to assist customer service agents, or any customer-facing teams in responding to user queries with greater speed and accuracy.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Agentic AI Alone for autonomous decision-making and actions:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Agentic AI is best suited for automating complex, multi-step processes like supply chain management or customer service workflows.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Tasks that require real-time decision-making and adaptation to changing environments benefit from Agentic AI.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For example, a logistics company can implement Agentic AI to autonomously manage inventory levels, reorder supplies, and optimise delivery routes based on real-time data. This leads to improved operational efficiency, reduced errors, and faster response times.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Merging GenAI and Agentic AI:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The combined approach is best used when your business requires systems that generate content and autonomously act upon it.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The goal is to create end-to-end automated solutions that handle creation and execution, enhancing customer experiences through personalised interactions and proactive services.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;An example is when an e-commerce platform uses GenAI to create personalised product recommendations. Agentic AI automatically adjusts pricing and inventory based on customer behaviour and purchasing trends.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This combined approach delivers better customer engagement through personalised and timely interactions, helping the business achieve greater agility in responding to market demands.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Why human oversight matters in enterprise-scale AI systems:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In high-risk decision-making environments like finance or healthcare, AI systems aren’t always the right decision, but when they do make sense to implement, it’s essential to maintain a human-in-the-loop approach. This is especially important for models prone to errors or “hallucinations,” as inaccuracies can have significant consequences in these sectors.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Industries governed by strict regulations often face challenges when implementing AI systems that lack transparency. The opaque nature of some AI models can hinder compliance efforts and erode stakeholder trust.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Moreover, deploying and maintaining advanced AI systems, such as GenAI and Agentic AI can be resource-intensive, requiring substantial computational power and specialised expertise. This complexity reinforces the need for human oversight to ensure smooth implementation and to mitigate potential risks that could strain organisational resources.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For organisations with limited resources, adopting simpler AI solutions that address specific needs without the complexity of full integration may be more practical. Certain tasks inherently require human intuition, empathy, and ethical judgment, which are qualities that AI currently cannot replicate.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Strategic considerations for tech leaders&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As technology leaders, it’s essential to move beyond static GenAI chatbots and assess whether integrating GenAI and Agentic AI aligns with your organisation’s objectives. Evaluate the specific operational tasks within your organisation to determine if a combined AI approach is necessary or if a more straightforward solution would be more appropriate.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Ensure your organisation possesses the appropriate infrastructure and expertise to support complex AI systems. This includes robust data architectures, scalable computing resources, and a skilled workforce adept in AI technologies. Equally important is the prioritisation of AI solutions that offer transparency and explainability. In regulated industries, understanding the decision-making processes of AI systems is crucial to maintaining compliance and building trust with stakeholders.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;A common pattern in today’s AI adoption is that businesses are investing heavily in GenAI capabilities, yet many are leaving significant value on the table by failing to pair it with Agentic AI.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This matters because while GenAI can generate content, ideas, or responses, it can’t act on them. However, when combined with Agentic AI, your systems shift from being reactive and prompt-driven to autonomous and outcome-oriented.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This article aims to help senior technology leaders better understand the value Agentic AI can add to existing AI infrastructure, while outlining key considerations to determine whether its implementation aligns with your business needs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Understanding Agentic AI&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXdK_MTJsDbf-762dNxU9eeSNBT3MNJaoPxFvS8z3GqUeDcUbpuSI1dfo3sw6NSIvLJ_LaMarkzvCDtMVvSnrrWrwvSHj9OvfxWcUeAE5rkbzcQ1HzjX4hetnrrqbX35C5r1Gx_CXQ?key=xgu2lQTqMaowWCibuTxnzqRW&#34; alt=&#34;Image caption: Core components of an Agentic AI Architecture from Markovate.&amp;nbsp;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;&lt;strong&gt;Image caption: Core components of an Agentic AI Architecture from &lt;/strong&gt;&lt;/em&gt;&lt;a href=&#34;https://markovate.com/blog/agentic-ai-architecture/?utm_source=chatgpt.com&#34;&gt;&lt;strong&gt;&lt;em&gt;Markovate.&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt;&lt;em&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Agentic AI systems are designed to operate autonomously, perceiving their environment, making decisions, and executing actions without continuous human oversight.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This autonomy enables businesses to streamline operations, reduce costs, and enhance scalability.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The image above illustrates how the following systems function:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Perception layer:&lt;/strong&gt; This layer involves collecting data from various sources i.e. sensors, cameras, microphones, and digital inputs, to understand the current state of the environment. For businesses, this means real-time monitoring of operations, customer interactions, and market trends, facilitating proactive decision-making and rapid response to changing conditions.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Cognition layer:&lt;/strong&gt; Once data is collected, the cognition layer processes this information to interpret context, recognise patterns, and determine the best course of action. This analysis automates complex decision-making processes and reduces reliance on manual interventions, minimising the risk of human error.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Action layer: &lt;/strong&gt;After determining the appropriate response, the action layer executes the decision i.e. adjusting system parameters, initiating workflows, or communicating with stakeholders. This capability ensures quick implementation of decisions to enhance operational efficiency.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Ultimately, Agentic AI systems are equipped with learning mechanisms that improve over time.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Through techniques like reinforcement learning, where the system learns from the outcomes of its actions, and supervised or unsupervised learning, where it identifies patterns in data, the AI adapts to new situations and refines its decision-making processes.&amp;nbsp;&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;GenAI is great at creation, while Agentic AI brings decision-making and execution&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The most disruptive AI solutions over the next few years will combine GenAI with Agentic AI, and the key to achieving better business outcomes is knowing when to use one, the other, or both.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Not every use case requires a full agentic system, but many businesses will be surprised at how many should.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;GenAI alone:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;GenAI excels at generating new content from existing data patterns, significantly boosting creativity and productivity across various domains. In software engineering, tools like GitHub Copilot are increasingly used to automate routine tasks such as generating boilerplate code. This enables engineers to avoid repetitive work and focus on more complex, high-impact challenges. While a human-in-the-loop remains essential to ensure code quality and alignment, GenAI is already improving engineering efficiency and accelerating delivery.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In data science and engineering, GenAI supports teams facing surging data demands by improving accessibility and streamlining processing. Large language models (LLMs) help optimise how data is queried and managed, enabling faster and more accurate insights.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;GenAI tools also enhance data analysis and application development by allowing users to interact with data through natural language processing (NLP), unlocking insights without requiring SQL expertise.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In the case of Retrieval-Augmented Generation (RAG), GenAI can efficiently access relevant data sources to assist customer service agents, or any customer-facing teams in responding to user queries with greater speed and accuracy.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Agentic AI Alone for autonomous decision-making and actions:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Agentic AI is best suited for automating complex, multi-step processes like supply chain management or customer service workflows.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Tasks that require real-time decision-making and adaptation to changing environments benefit from Agentic AI.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For example, a logistics company can implement Agentic AI to autonomously manage inventory levels, reorder supplies, and optimise delivery routes based on real-time data. This leads to improved operational efficiency, reduced errors, and faster response times.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Merging GenAI and Agentic AI:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The combined approach is best used when your business requires systems that generate content and autonomously act upon it.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The goal is to create end-to-end automated solutions that handle creation and execution, enhancing customer experiences through personalised interactions and proactive services.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;An example is when an e-commerce platform uses GenAI to create personalised product recommendations. Agentic AI automatically adjusts pricing and inventory based on customer behaviour and purchasing trends.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This combined approach delivers better customer engagement through personalised and timely interactions, helping the business achieve greater agility in responding to market demands.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Why human oversight matters in enterprise-scale AI systems:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In high-risk decision-making environments like finance or healthcare, AI systems aren’t always the right decision, but when they do make sense to implement, it’s essential to maintain a human-in-the-loop approach. This is especially important for models prone to errors or “hallucinations,” as inaccuracies can have significant consequences in these sectors.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Industries governed by strict regulations often face challenges when implementing AI systems that lack transparency. The opaque nature of some AI models can hinder compliance efforts and erode stakeholder trust.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Moreover, deploying and maintaining advanced AI systems, such as GenAI and Agentic AI can be resource-intensive, requiring substantial computational power and specialised expertise. This complexity reinforces the need for human oversight to ensure smooth implementation and to mitigate potential risks that could strain organisational resources.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For organisations with limited resources, adopting simpler AI solutions that address specific needs without the complexity of full integration may be more practical. Certain tasks inherently require human intuition, empathy, and ethical judgment, which are qualities that AI currently cannot replicate.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Strategic considerations for tech leaders&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As technology leaders, it’s essential to move beyond static GenAI chatbots and assess whether integrating GenAI and Agentic AI aligns with your organisation’s objectives. Evaluate the specific operational tasks within your organisation to determine if a combined AI approach is necessary or if a more straightforward solution would be more appropriate.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Ensure your organisation possesses the appropriate infrastructure and expertise to support complex AI systems. This includes robust data architectures, scalable computing resources, and a skilled workforce adept in AI technologies. Equally important is the prioritisation of AI solutions that offer transparency and explainability. In regulated industries, understanding the decision-making processes of AI systems is crucial to maintaining compliance and building trust with stakeholders.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Sun, 17 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【How Imagine Learning Reduced Operational Overhead by 20% With Linkerd】How Imagine Learning Reduced Operational Overhead by 20% With Linkerd</title>
      <link>https://www.cncf.io/blog/2025/08/15/innovating-with-a-rock-solid-foundation-while-saving-40-on-networking-costs-imagine-learnings-journey-with-linkerd/</link>
      <description>【&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;At &lt;a href=&#34;https://www.imaginelearning.com/&#34;&gt;Imagine Learning&lt;/a&gt;, we strive to empower educators and inspire breakthrough moments for over 18 million students across the United States. As a digital-first education solutions provider, our mission is to deliver robust, reliable, and secure experiences to support the boundless potential of K-12 learners. Achieving this at scale—spanning hundreds of thousands of daily users—requires a technical foundation as innovative as our products.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;br&gt;To meet these demands, our engineering team has embraced modern cloud-native technologies. The cornerstone of our infrastructure is &lt;a href=&#34;https://linkerd.io/&#34;&gt;Linkerd&lt;/a&gt;, supported by Buoyant, running on Amazon’s Elastic Kubernetes Service (EKS). Linkerd gives us the critical capabilities that we need to scale effortlessly while maintaining the performance and reliability that our users depend on.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Delivering Reliability and Security at Scale&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Our users—students and educators—depend on fast, reliable, and secure access to our digital tools. Dropped traffic, slow load times, or security issues in the face of ever-evolving threats would disturb the user experience, potentially leading to customer churn. For that reason, reliability and security are a top priority for Imagine Learning. As our platform grew to include hundreds of microservices deployed across several Kubernetes clusters on AWS EKS, managing communications at scale to avoid these problems became extremely challenging. We needed a solution that would:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Encrypt traffic seamlessly.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Simplify service-to-service communication.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Provide deep observability into application-layer (L7) networking.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In short, we needed a service mesh.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Linkerd: Opting for Simplicity, Performance, and Security&amp;nbsp;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;After evaluating multiple service mesh options, Linkerd stood out due to its simplicity, performance, and security. Unlike other solutions, Linkerd uses a tiny &lt;a href=&#34;https://linkerd.io/2020/07/23/under-the-hood-of-linkerds-state-of-the-art-rust-proxy-linkerd2-proxy/&#34;&gt;Rust-based sidecar microproxy&lt;/a&gt;, offering a small compute footprint, significantly reduced CVEs, and enhanced overall security. Linkerd’s ease of configuration allowed us to deploy it reliably and scale it within hours, enabling our team to focus on delivering value to our customers.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Building a Scalable and Observable Platform&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Our engineering team integrated Linkerd with several other CNCF tools to create a robust platform:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Argo CD: Enables GitOps workflows, ensuring consistent deployment of Linkerd across all clusters.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Argo Rollouts: Enable us to roll out to customers progressively using Linkerd’s Gateway API Integration informed by metrics.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXcbBSsu283QNrhenBD5EaTzmlNXwUrNnMlJV5mY1WjOFgz3BC9HXvjv9MK14bcI2TcGBhceZWvgflsxvvilNJLs9OGX7ghSMK5qCOmNKqCLCCR8ZrMc8f4VICiz_BJ8fqdKuYovoQ?key=_fhJw1ohr7wmtuIs99B5_25z&#34; alt=&#34;Spoke Clusters graphic&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We started the implementation by adopting the &lt;a href=&#34;https://glossary.cncf.io/gitops/&#34;&gt;GitOps&lt;/a&gt; mindset: our Kubernetes manifests are stored in Git, and we use &lt;a href=&#34;https://argoproj.github.io/&#34;&gt;Argo&lt;/a&gt; CD to deploy resources into our Kubernetes clusters. Argo CD manages Linkerd, Argo Rollouts, the microservices our application teams build, and the other components needed for our platform.&amp;nbsp; Once deployed, all meshed pods were automatically mTLSed!&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Next, we started leveraging the &lt;a href=&#34;https://gateway-api.sigs.k8s.io/&#34;&gt;Gateway API &lt;/a&gt;in our environment to use Argo Rollouts with their Gateway API plugin. We now use Argo Rollouts for canary deployments, enabling controlled rollout of new application versions to our customers. Linkerd seamlessly changes the amount of traffic going to the new version based on Argo Rollouts’ instructions, and Argo Rollouts uses Linkerd’s HTTP metrics to understand whether a rollout is going successfully. This allows us to minimize the impact customers could experience due to a release deficiency.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Together, these tools in this architecture allow us to maintain a highly observable and manageable Kubernetes environment.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Transformational Gains&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The adoption of Linkerd has yielded significant technological and business benefits:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Reduced Operational Overhead by 20%: By streamlining service mesh management, we’ve cut the time spent on operational tasks by a substantial margin.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Enhanced Efficiency: Linkerd’s lightweight design reduced the compute requirements of our service mesh by over 80% compared to our previous service mesh implementation.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Improved Reliability: Real-time observability ensures rapid issue resolution, translating to better user experiences and fewer disruptions.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Improved Security: Linkerd has reduced the amount of service mesh-related CVEs we have been exposed to by 97% in 2024.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;On a personal level, these improvements mean fewer fire drills for our engineers, allowing them to focus on innovation.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Looking Ahead&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As we continue to scale, Imagine Learning remains committed to leveraging cloud-native technologies like Linkerd to deliver exceptional educational experiences. With a solid foundation powered by cloud-native software, including Linkerd, we are poised to inspire breakthrough moments for millions of students every day. to leveraging cloud-native technologies like Linkerd to deliver exceptional educational experiences. We are poised to inspire breakthrough moments for millions of students every day.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;At &lt;a href=&#34;https://www.imaginelearning.com/&#34;&gt;Imagine Learning&lt;/a&gt;, we strive to empower educators and inspire breakthrough moments for over 18 million students across the United States. As a digital-first education solutions provider, our mission is to deliver robust, reliable, and secure experiences to support the boundless potential of K-12 learners. Achieving this at scale—spanning hundreds of thousands of daily users—requires a technical foundation as innovative as our products.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;br&gt;To meet these demands, our engineering team has embraced modern cloud-native technologies. The cornerstone of our infrastructure is &lt;a href=&#34;https://linkerd.io/&#34;&gt;Linkerd&lt;/a&gt;, supported by Buoyant, running on Amazon’s Elastic Kubernetes Service (EKS). Linkerd gives us the critical capabilities that we need to scale effortlessly while maintaining the performance and reliability that our users depend on.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Delivering Reliability and Security at Scale&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Our users—students and educators—depend on fast, reliable, and secure access to our digital tools. Dropped traffic, slow load times, or security issues in the face of ever-evolving threats would disturb the user experience, potentially leading to customer churn. For that reason, reliability and security are a top priority for Imagine Learning. As our platform grew to include hundreds of microservices deployed across several Kubernetes clusters on AWS EKS, managing communications at scale to avoid these problems became extremely challenging. We needed a solution that would:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Encrypt traffic seamlessly.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Simplify service-to-service communication.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Provide deep observability into application-layer (L7) networking.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In short, we needed a service mesh.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Linkerd: Opting for Simplicity, Performance, and Security&amp;nbsp;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;After evaluating multiple service mesh options, Linkerd stood out due to its simplicity, performance, and security. Unlike other solutions, Linkerd uses a tiny &lt;a href=&#34;https://linkerd.io/2020/07/23/under-the-hood-of-linkerds-state-of-the-art-rust-proxy-linkerd2-proxy/&#34;&gt;Rust-based sidecar microproxy&lt;/a&gt;, offering a small compute footprint, significantly reduced CVEs, and enhanced overall security. Linkerd’s ease of configuration allowed us to deploy it reliably and scale it within hours, enabling our team to focus on delivering value to our customers.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Building a Scalable and Observable Platform&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Our engineering team integrated Linkerd with several other CNCF tools to create a robust platform:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Argo CD: Enables GitOps workflows, ensuring consistent deployment of Linkerd across all clusters.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Argo Rollouts: Enable us to roll out to customers progressively using Linkerd’s Gateway API Integration informed by metrics.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXcbBSsu283QNrhenBD5EaTzmlNXwUrNnMlJV5mY1WjOFgz3BC9HXvjv9MK14bcI2TcGBhceZWvgflsxvvilNJLs9OGX7ghSMK5qCOmNKqCLCCR8ZrMc8f4VICiz_BJ8fqdKuYovoQ?key=_fhJw1ohr7wmtuIs99B5_25z&#34; alt=&#34;Spoke Clusters graphic&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We started the implementation by adopting the &lt;a href=&#34;https://glossary.cncf.io/gitops/&#34;&gt;GitOps&lt;/a&gt; mindset: our Kubernetes manifests are stored in Git, and we use &lt;a href=&#34;https://argoproj.github.io/&#34;&gt;Argo&lt;/a&gt; CD to deploy resources into our Kubernetes clusters. Argo CD manages Linkerd, Argo Rollouts, the microservices our application teams build, and the other components needed for our platform.&amp;nbsp; Once deployed, all meshed pods were automatically mTLSed!&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Next, we started leveraging the &lt;a href=&#34;https://gateway-api.sigs.k8s.io/&#34;&gt;Gateway API &lt;/a&gt;in our environment to use Argo Rollouts with their Gateway API plugin. We now use Argo Rollouts for canary deployments, enabling controlled rollout of new application versions to our customers. Linkerd seamlessly changes the amount of traffic going to the new version based on Argo Rollouts’ instructions, and Argo Rollouts uses Linkerd’s HTTP metrics to understand whether a rollout is going successfully. This allows us to minimize the impact customers could experience due to a release deficiency.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Together, these tools in this architecture allow us to maintain a highly observable and manageable Kubernetes environment.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Transformational Gains&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The adoption of Linkerd has yielded significant technological and business benefits:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Reduced Operational Overhead by 20%: By streamlining service mesh management, we’ve cut the time spent on operational tasks by a substantial margin.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Enhanced Efficiency: Linkerd’s lightweight design reduced the compute requirements of our service mesh by over 80% compared to our previous service mesh implementation.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Improved Reliability: Real-time observability ensures rapid issue resolution, translating to better user experiences and fewer disruptions.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Improved Security: Linkerd has reduced the amount of service mesh-related CVEs we have been exposed to by 97% in 2024.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;On a personal level, these improvements mean fewer fire drills for our engineers, allowing them to focus on innovation.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Looking Ahead&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As we continue to scale, Imagine Learning remains committed to leveraging cloud-native technologies like Linkerd to deliver exceptional educational experiences. With a solid foundation powered by cloud-native software, including Linkerd, we are poised to inspire breakthrough moments for millions of students every day. to leveraging cloud-native technologies like Linkerd to deliver exceptional educational experiences. We are poised to inspire breakthrough moments for millions of students every day.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Thu, 14 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Celebrating 100 Days of Kagent】Celebrating 100 Days of Kagent</title>
      <link>https://www.cncf.io/blog/2025/08/19/celebrating-100-days-of-kagent/</link>
      <description>【&lt;p&gt;When we first &lt;a href=&#34;https://techstrong.ai/agentic-ai/solo-ios-kagent-brings-agentic-ai-to-cloud-native-operations/&#34;&gt;introduced kagent&lt;/a&gt; on March 17th, 2025, we had a bold vision: to bring agentic AI to cloud native—empowering platforms and DevOps engineers to harness AI agents for solving real operational challenges.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Fast forward 100 days, and today we’re celebrating a major milestone: &lt;strong&gt;100 days of the kagent project&lt;/strong&gt;! 🎉Thank you everyone for being part of this journey! 🚀&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Accepted into CNCF as a sandbox project&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;What began as a tool to address our own customer challenges has grown into a thriving open-source project. Kagent is now a &lt;strong&gt;CNCF Sandbox project&lt;/strong&gt;, and it’s evolving into a powerful &lt;strong&gt;declarative agentic AI framework&lt;/strong&gt;—enabling like-minded engineers to run AI agents in Kubernetes, automating complex operations and streamlining troubleshooting workflows.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXfncOUQ6yZnCUWu5AwPIyNR8r4qz0kHAwAnpau4PGO4utPJHAUEzG4b-TtanfIATjlbCCMLAMFVIew3_ETbh1Au5z22CoIMTd6QiWt7Rwku4V02QAHxjYx1gu740ZQV4BbJBCa-JA?key=qRZXOzXKu-A8HOMrTLESOw&#34; alt=&#34;Graphic of Peter Jausovec tweet&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Source: &lt;a href=&#34;https://www.linkedin.com/posts/pjausovec_kagent-has-been-accepted-as-a-cncf-sandbox-activity-7331347027777216512-9VC_&#34;&gt;LinkedIn post&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;🌟 100 Contributors &amp;amp; 1000+ GitHub Stars!&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In just 100 days, kagent has hit two incredible milestones:&lt;br&gt;🚀 &lt;a href=&#34;https://kagent.devstats.cncf.io/d/66/developer-activity-counts-by-companies?orgId=1&#34;&gt;&lt;strong&gt;100 contributors&lt;/strong&gt;&lt;/a&gt;, with over &lt;strong&gt;85% from outside Solo.io&lt;/strong&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt; ⭐ &lt;strong&gt;1000+ GitHub stars&lt;/strong&gt; from our amazing community!&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We’ve been actively connecting with contributors through &lt;strong&gt;GitHub, Discord, weekly community calls, livestreams,&lt;/strong&gt; and &lt;strong&gt;Contributor Spotlights&lt;/strong&gt;. We’re incredibly grateful for everyone who’s explored, supported, and contributed to kagent.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;A &lt;strong&gt;huge shoutout&lt;/strong&gt; to our &lt;strong&gt;top 20 contributors&lt;/strong&gt;, and a special thanks to our &lt;strong&gt;top 3&lt;/strong&gt;:&lt;br&gt;&lt;strong&gt;@eitanya, @peterj, and @sbx03&lt;/strong&gt; — we deeply appreciate your dedication and impact!! 🙌&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXfeXmVqqDJJHKz1EBqlt-iWF2xFG6HfDDfG9_3dPNTA18oEXY5iMwGFsVZn81XaD8gSfF3JpUtnMusQybNkpCVITY58mcEDiZpgNsQ-5R0Jm2jxnfGgjONhzoDHa4nYYgthzkuM?key=qRZXOzXKu-A8HOMrTLESOw&#34; alt=&#34;Top 20 contributors of kagent&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Source: https://kagent.devstats.cncf.io/d/66/developer-activity-counts-by-companies?orgId=1&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Users advocating for kagent&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Over the past 100 days, we’ve been blown away by how our early adopters are using kagent in creative and powerful ways—including in &lt;strong&gt;production environments&lt;/strong&gt;! Across &lt;strong&gt;social media, community meetings&lt;/strong&gt;, and beyond, users are not just experimenting—they’re innovating. 💡&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Here are just a few examples of how the community is putting kagent to work:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Talk to Infrastructure using kagent, A2A, kgateway and others!&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXfjfJqLAs-Mw5b2ljQMAcarEQVbc0uvFOM3U8aGcqKO0HQEcKNvEwtyuTP37WndR_XR3IM6QrYYfPhMklAKcIssdDqkPcbFnho8u8JPmMeKQkpxnXMa8m_0u0zW_r99wdHw_Qsp_A?key=qRZXOzXKu-A8HOMrTLESOw&#34; alt=&#34;Denys Vasyliev Tweet graphic&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Source: &lt;a href=&#34;https://www.linkedin.com/feed/update/urn:li:activity:7331020451076308993&#34;&gt;Linkedin post&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Integrate kagent with Argo MCP server&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXfC-VBRsVFxlTM5a23NGmiaGhN_1PgSs2VU_ZZh5xRg32Nnno_FA3T4KO7ltJ0mi6rWo9lcy7aAvAokbB2Nr4FuP4gtJ6SmVFyl7UcNHmkM8msXPqSCnOoLdyOEtWcHohWqjoM9og?key=qRZXOzXKu-A8HOMrTLESOw&#34; alt=&#34;Chris Matcham tweet graphic&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Source: &lt;a href=&#34;https://www.linkedin.com/posts/christophermatcham_exploring-argocds-new-mcp-server-with-kagent-activity-7326612299459321856-ucyq?utm_source=share&amp;amp;utm_medium=member_desktop&amp;amp;rcm=ACoAAABLihcBuozqLyftNtauegAdN2-QszsmqQQ&#34;&gt;Linkedin post&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Integrate kagent with home labs and MCP servers&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXfQBDyo9I7QK_Ue0JosClS_EV_b2YrquGUbb1Jgoz0VQuTbqnD-neB17LKzRCvoelBMGSnSqxjDL8leDp_5NeJ6mY5VgK7tanBOhKqgeEgv7_vGT7i82PbyJRzFizJRmjxFBlD32A?key=qRZXOzXKu-A8HOMrTLESOw&#34; style=&#34;&#34; alt=&#34;Dmytrp Rashko tweet graphic&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Source: &lt;a href=&#34;https://www.linkedin.com/feed/update/urn:li:activity:7327684658475712515&#34;&gt;LinkedIn post&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Use kagent for AI reliability engineering&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXdo3DIrgL-pEH8WxHWgD6NUH2C6sOnGdy0QK0zUPgi5cUV3DijD405nPmSRdQXgN4-rBSErYexpzEsBtOMoHH9BdrNnV6_uDDDjNg1wbmUyDY8Lxi3HJgovNIAq8Le9G5_GFbsRXg?key=qRZXOzXKu-A8HOMrTLESOw&#34; alt=&#34;Christian Posta tweet graphic&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Source: &lt;a href=&#34;https://www.linkedin.com/feed/update/urn:li:activity:7328046281916841985&#34;&gt;LinkedIn post&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Fast delivery with kagent: A2A agent with discord:&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXfc-yI2vYcz88Qt5pcyjWTbnDFmdjvragaGNWpQ-Rczs9DBDdpNkarfEiIae6b4xEVKeKc4MqoPy0RMobChXVh7SXtiCMMHdN2MlivTAe0AC-J2c-197wXQqqbEjBCqvOGUf_AoaQ?key=qRZXOzXKu-A8HOMrTLESOw&#34; alt=&#34;Marcin Kubica tweet graphic&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Source: &lt;a href=&#34;https://www.linkedin.com/feed/update/urn:li:activity:7340382418895368193&#34;&gt;LinkedIn post&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;GCP terraform agent on kagent:&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXeewrdKAA9o8kAVEu8TV9AHsnB6NwN3wAYdmgyJYaxBuk-G1zzzGSLeyadIDSnhyCGhC-r-xhVkWrfW7JeZWmKndnS1ke4dWDUeIagvQyyOo5HAOimxAXBdlE_By9LQHx58BA15?key=qRZXOzXKu-A8HOMrTLESOw&#34; alt=&#34;Huzefa Hamdard tweet graphic&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Source: &lt;a href=&#34;https://www.linkedin.com/posts/huzefa-hamdard_terraform-gcp-kubernetes-activity-7331957646113067010-7F7I?utm_source=share&amp;amp;utm_medium=member_desktop&amp;amp;rcm=ACoAAABLihcBuozqLyftNtauegAdN2-QszsmqQQ&#34;&gt;LinkedIn post&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;🌍 Kagent travels around the world&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In just 100 days, kagent has made its mark on the global stage. We’ve taken our vision of Agentic AI to some of the most prestigious conferences worldwide—sharing our belief that kagent is a key building block for the future of agentic AI.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;📢KubeCon + CloudNativeCon EU 2025&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This was where it all began—the first public announcement of kagent and our intention to donate it to the CNCF. The announcement was made during the Day 2 keynote by Idit Levine and Keith Babo. Later, Christian Posta delivered a live demo at the KubeCon + CloudNativeCon EU demo theater, showcasing kagent in action. 🚀&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;🇫🇷 GOSIM AI Paris 2025&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Eitan Yarmush took the stage in Paris to challenge attendees to rethink the open-source agent stack with kagent. Check out the &lt;a href=&#34;https://www.youtube.com/watch?v=4uus0zf6OUQ&#34;&gt;recording&lt;/a&gt;—it’s a must-watch!&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;🤠 KCD Texas 2025&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kagent was featured in KCD Texas keynote along with Headlamp, AI model pack and Dapr agent by Chris Aniszczyk. Later, I also did a live demo of kagent to help me with Istio ambient operations.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXeZ4iOD2uLVvR7xL_-DytvSgzZ2oOfsemdPwK5-P5lBO4KxJJhi0gD2YnPz3-qipho505kG0J1GgmBW4H74uQXI-uCqntGp-ODZs7HtMGiBmdHiVNXWf5Ahzg3X8eXP20RaWW7owQ?key=qRZXOzXKu-A8HOMrTLESOw&#34; alt=&#34;Lin Sun tweet graphic&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Source: &lt;a href=&#34;https://www.linkedin.com/feed/update/urn:li:activity:7328804002693820419&#34;&gt;LinkedIn post&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;🇬🇧London DevOps Meetup May 2025&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Denys Vasyliev presented using kagent for his custom controllers of Kubernetes and MCP servers.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXdgoW2ig_7yUy0BdZp9f4PWB-8Rz0Cd4bZRzFUqhe6PFZs_56yGNorngqGIwukyINvi9Zttj7pnWu4lBJlP2tuki_BA2SkCDeCRFHhoJAY7GcQrNcjIZKD3IrhlI2KovhM_luYuUw?key=qRZXOzXKu-A8HOMrTLESOw&#34; alt=&#34;Tor H. tweet graphic&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Source: &lt;a href=&#34;https://www.linkedin.com/posts/activity-7331419530239315968-fJ7j?utm_source=share&amp;amp;utm_medium=member_desktop&amp;amp;rcm=ACoAAABLihcBuozqLyftNtauegAdN2-QszsmqQQ&#34;&gt;Linkedin post&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;🇨🇳KubeCon + CloudNativeCon China 2025&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The excitement for kagent crossed continents as we shared it with the cloud native community in China.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXfY_J2siBaFNg68xPqZPfz_kj0-f5ire5Ucqa6B6ei4V-ksZg_qj4Tp2BwOmFXnbBJeZ8LYwJXY43QI_q_v8XeoWzr1OO9vA3Qlv1xac_fJH_HBbLUryn2pFaDxrkrjwBgh3aZU4Q?key=qRZXOzXKu-A8HOMrTLESOw&#34; alt=&#34;Brent Leung tweet graphic&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Source: &lt;a href=&#34;https://www.linkedin.com/feed/update/urn:li:activity:7339255065632731136&#34;&gt;LinkedIn post&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;🇯🇵 OpenSSF Community – Japan&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;I connected with the open source security community in Japan to explore how agentic AI can help shape the future of cloud-native users, OpenSSF, and the broader open source ecosystem. I also showcased a live demo of kagent, highlighting the future impact of agentic AI.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;🇺🇸Open Source Summit NA&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In a totally unplanned moment, I did a live demo of kagent alongside my generative AI application with Kubernetes, Argo and Istio—right in the middle of troubleshooting a Git mistake I had just made! 😅&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;It was amazing to have kagent acting like my buddy on stage, offering hints and helping me recover in real time. A great example of how powerful and practical agentic AI can be!&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Beyond cloud native operations&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;While kagent was originally designed to tackle challenges in cloud-native operations, we’ve been excited to see users applying it far beyond that scope.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Thanks to its knowledge-based agent, kagent can be used to interact with and reason over any type of documentation—not just Kubernetes manifests or infrastructure logs. From internal wikis and runbooks to software manuals and onboarding guides, kagent is proving to be a powerful tool for making structured and unstructured knowledge accessible via simple conversations.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;🎉&lt;/strong&gt;Wrapping up&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To everyone who has starred the kagent repo, contributed code, filed issues, joined discussions, or simply helped spread the word—&lt;strong&gt;thank you&lt;/strong&gt; for being an essential part of this community! We’re super excited to keep growing and building together.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;We’re proud to collaborate within the CNCF community to shape the future of agentic AI with kagent—together.&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Want to join the kagent community? Check out the project at&lt;/em&gt;&lt;a href=&#34;https://kagent.dev/&#34;&gt;&lt;em&gt; &lt;/em&gt;&lt;em&gt;kagent.dev&lt;/em&gt;&lt;/a&gt;&lt;em&gt;, star us on&lt;/em&gt;&lt;a href=&#34;https://github.com/kagent-dev/kagent&#34;&gt;&lt;em&gt; &lt;/em&gt;&lt;em&gt;GitHub&lt;/em&gt;&lt;/a&gt;&lt;em&gt;, and join our &lt;/em&gt;&lt;a href=&#34;https://discord.gg/Fu3k65f2k3&#34;&gt;&lt;em&gt;Discord&lt;/em&gt;&lt;/a&gt;&lt;em&gt; or weekly community meeting. Whether you’re looking to build your first AI agent or contribute to the framework itself, we’d love to have you onboard.&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;When we first &lt;a href=&#34;https://techstrong.ai/agentic-ai/solo-ios-kagent-brings-agentic-ai-to-cloud-native-operations/&#34;&gt;introduced kagent&lt;/a&gt; on March 17th, 2025, we had a bold vision: to bring agentic AI to cloud native—empowering platforms and DevOps engineers to harness AI agents for solving real operational challenges.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Fast forward 100 days, and today we’re celebrating a major milestone: &lt;strong&gt;100 days of the kagent project&lt;/strong&gt;! 🎉Thank you everyone for being part of this journey! 🚀&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Accepted into CNCF as a sandbox project&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;What began as a tool to address our own customer challenges has grown into a thriving open-source project. Kagent is now a &lt;strong&gt;CNCF Sandbox project&lt;/strong&gt;, and it’s evolving into a powerful &lt;strong&gt;declarative agentic AI framework&lt;/strong&gt;—enabling like-minded engineers to run AI agents in Kubernetes, automating complex operations and streamlining troubleshooting workflows.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXfncOUQ6yZnCUWu5AwPIyNR8r4qz0kHAwAnpau4PGO4utPJHAUEzG4b-TtanfIATjlbCCMLAMFVIew3_ETbh1Au5z22CoIMTd6QiWt7Rwku4V02QAHxjYx1gu740ZQV4BbJBCa-JA?key=qRZXOzXKu-A8HOMrTLESOw&#34; alt=&#34;Graphic of Peter Jausovec tweet&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Source: &lt;a href=&#34;https://www.linkedin.com/posts/pjausovec_kagent-has-been-accepted-as-a-cncf-sandbox-activity-7331347027777216512-9VC_&#34;&gt;LinkedIn post&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;🌟 100 Contributors &amp;amp; 1000+ GitHub Stars!&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In just 100 days, kagent has hit two incredible milestones:&lt;br&gt;🚀 &lt;a href=&#34;https://kagent.devstats.cncf.io/d/66/developer-activity-counts-by-companies?orgId=1&#34;&gt;&lt;strong&gt;100 contributors&lt;/strong&gt;&lt;/a&gt;, with over &lt;strong&gt;85% from outside Solo.io&lt;/strong&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt; ⭐ &lt;strong&gt;1000+ GitHub stars&lt;/strong&gt; from our amazing community!&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We’ve been actively connecting with contributors through &lt;strong&gt;GitHub, Discord, weekly community calls, livestreams,&lt;/strong&gt; and &lt;strong&gt;Contributor Spotlights&lt;/strong&gt;. We’re incredibly grateful for everyone who’s explored, supported, and contributed to kagent.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;A &lt;strong&gt;huge shoutout&lt;/strong&gt; to our &lt;strong&gt;top 20 contributors&lt;/strong&gt;, and a special thanks to our &lt;strong&gt;top 3&lt;/strong&gt;:&lt;br&gt;&lt;strong&gt;@eitanya, @peterj, and @sbx03&lt;/strong&gt; — we deeply appreciate your dedication and impact!! 🙌&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXfeXmVqqDJJHKz1EBqlt-iWF2xFG6HfDDfG9_3dPNTA18oEXY5iMwGFsVZn81XaD8gSfF3JpUtnMusQybNkpCVITY58mcEDiZpgNsQ-5R0Jm2jxnfGgjONhzoDHa4nYYgthzkuM?key=qRZXOzXKu-A8HOMrTLESOw&#34; alt=&#34;Top 20 contributors of kagent&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Source: https://kagent.devstats.cncf.io/d/66/developer-activity-counts-by-companies?orgId=1&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Users advocating for kagent&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Over the past 100 days, we’ve been blown away by how our early adopters are using kagent in creative and powerful ways—including in &lt;strong&gt;production environments&lt;/strong&gt;! Across &lt;strong&gt;social media, community meetings&lt;/strong&gt;, and beyond, users are not just experimenting—they’re innovating. 💡&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Here are just a few examples of how the community is putting kagent to work:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Talk to Infrastructure using kagent, A2A, kgateway and others!&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXfjfJqLAs-Mw5b2ljQMAcarEQVbc0uvFOM3U8aGcqKO0HQEcKNvEwtyuTP37WndR_XR3IM6QrYYfPhMklAKcIssdDqkPcbFnho8u8JPmMeKQkpxnXMa8m_0u0zW_r99wdHw_Qsp_A?key=qRZXOzXKu-A8HOMrTLESOw&#34; alt=&#34;Denys Vasyliev Tweet graphic&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Source: &lt;a href=&#34;https://www.linkedin.com/feed/update/urn:li:activity:7331020451076308993&#34;&gt;Linkedin post&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Integrate kagent with Argo MCP server&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXfC-VBRsVFxlTM5a23NGmiaGhN_1PgSs2VU_ZZh5xRg32Nnno_FA3T4KO7ltJ0mi6rWo9lcy7aAvAokbB2Nr4FuP4gtJ6SmVFyl7UcNHmkM8msXPqSCnOoLdyOEtWcHohWqjoM9og?key=qRZXOzXKu-A8HOMrTLESOw&#34; alt=&#34;Chris Matcham tweet graphic&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Source: &lt;a href=&#34;https://www.linkedin.com/posts/christophermatcham_exploring-argocds-new-mcp-server-with-kagent-activity-7326612299459321856-ucyq?utm_source=share&amp;amp;utm_medium=member_desktop&amp;amp;rcm=ACoAAABLihcBuozqLyftNtauegAdN2-QszsmqQQ&#34;&gt;Linkedin post&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Integrate kagent with home labs and MCP servers&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXfQBDyo9I7QK_Ue0JosClS_EV_b2YrquGUbb1Jgoz0VQuTbqnD-neB17LKzRCvoelBMGSnSqxjDL8leDp_5NeJ6mY5VgK7tanBOhKqgeEgv7_vGT7i82PbyJRzFizJRmjxFBlD32A?key=qRZXOzXKu-A8HOMrTLESOw&#34; style=&#34;&#34; alt=&#34;Dmytrp Rashko tweet graphic&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Source: &lt;a href=&#34;https://www.linkedin.com/feed/update/urn:li:activity:7327684658475712515&#34;&gt;LinkedIn post&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Use kagent for AI reliability engineering&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXdo3DIrgL-pEH8WxHWgD6NUH2C6sOnGdy0QK0zUPgi5cUV3DijD405nPmSRdQXgN4-rBSErYexpzEsBtOMoHH9BdrNnV6_uDDDjNg1wbmUyDY8Lxi3HJgovNIAq8Le9G5_GFbsRXg?key=qRZXOzXKu-A8HOMrTLESOw&#34; alt=&#34;Christian Posta tweet graphic&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Source: &lt;a href=&#34;https://www.linkedin.com/feed/update/urn:li:activity:7328046281916841985&#34;&gt;LinkedIn post&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Fast delivery with kagent: A2A agent with discord:&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXfc-yI2vYcz88Qt5pcyjWTbnDFmdjvragaGNWpQ-Rczs9DBDdpNkarfEiIae6b4xEVKeKc4MqoPy0RMobChXVh7SXtiCMMHdN2MlivTAe0AC-J2c-197wXQqqbEjBCqvOGUf_AoaQ?key=qRZXOzXKu-A8HOMrTLESOw&#34; alt=&#34;Marcin Kubica tweet graphic&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Source: &lt;a href=&#34;https://www.linkedin.com/feed/update/urn:li:activity:7340382418895368193&#34;&gt;LinkedIn post&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;GCP terraform agent on kagent:&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXeewrdKAA9o8kAVEu8TV9AHsnB6NwN3wAYdmgyJYaxBuk-G1zzzGSLeyadIDSnhyCGhC-r-xhVkWrfW7JeZWmKndnS1ke4dWDUeIagvQyyOo5HAOimxAXBdlE_By9LQHx58BA15?key=qRZXOzXKu-A8HOMrTLESOw&#34; alt=&#34;Huzefa Hamdard tweet graphic&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Source: &lt;a href=&#34;https://www.linkedin.com/posts/huzefa-hamdard_terraform-gcp-kubernetes-activity-7331957646113067010-7F7I?utm_source=share&amp;amp;utm_medium=member_desktop&amp;amp;rcm=ACoAAABLihcBuozqLyftNtauegAdN2-QszsmqQQ&#34;&gt;LinkedIn post&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;🌍 Kagent travels around the world&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In just 100 days, kagent has made its mark on the global stage. We’ve taken our vision of Agentic AI to some of the most prestigious conferences worldwide—sharing our belief that kagent is a key building block for the future of agentic AI.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;📢KubeCon + CloudNativeCon EU 2025&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This was where it all began—the first public announcement of kagent and our intention to donate it to the CNCF. The announcement was made during the Day 2 keynote by Idit Levine and Keith Babo. Later, Christian Posta delivered a live demo at the KubeCon + CloudNativeCon EU demo theater, showcasing kagent in action. 🚀&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;🇫🇷 GOSIM AI Paris 2025&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Eitan Yarmush took the stage in Paris to challenge attendees to rethink the open-source agent stack with kagent. Check out the &lt;a href=&#34;https://www.youtube.com/watch?v=4uus0zf6OUQ&#34;&gt;recording&lt;/a&gt;—it’s a must-watch!&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;🤠 KCD Texas 2025&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kagent was featured in KCD Texas keynote along with Headlamp, AI model pack and Dapr agent by Chris Aniszczyk. Later, I also did a live demo of kagent to help me with Istio ambient operations.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXeZ4iOD2uLVvR7xL_-DytvSgzZ2oOfsemdPwK5-P5lBO4KxJJhi0gD2YnPz3-qipho505kG0J1GgmBW4H74uQXI-uCqntGp-ODZs7HtMGiBmdHiVNXWf5Ahzg3X8eXP20RaWW7owQ?key=qRZXOzXKu-A8HOMrTLESOw&#34; alt=&#34;Lin Sun tweet graphic&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Source: &lt;a href=&#34;https://www.linkedin.com/feed/update/urn:li:activity:7328804002693820419&#34;&gt;LinkedIn post&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;🇬🇧London DevOps Meetup May 2025&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Denys Vasyliev presented using kagent for his custom controllers of Kubernetes and MCP servers.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXdgoW2ig_7yUy0BdZp9f4PWB-8Rz0Cd4bZRzFUqhe6PFZs_56yGNorngqGIwukyINvi9Zttj7pnWu4lBJlP2tuki_BA2SkCDeCRFHhoJAY7GcQrNcjIZKD3IrhlI2KovhM_luYuUw?key=qRZXOzXKu-A8HOMrTLESOw&#34; alt=&#34;Tor H. tweet graphic&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Source: &lt;a href=&#34;https://www.linkedin.com/posts/activity-7331419530239315968-fJ7j?utm_source=share&amp;amp;utm_medium=member_desktop&amp;amp;rcm=ACoAAABLihcBuozqLyftNtauegAdN2-QszsmqQQ&#34;&gt;Linkedin post&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;🇨🇳KubeCon + CloudNativeCon China 2025&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The excitement for kagent crossed continents as we shared it with the cloud native community in China.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXfY_J2siBaFNg68xPqZPfz_kj0-f5ire5Ucqa6B6ei4V-ksZg_qj4Tp2BwOmFXnbBJeZ8LYwJXY43QI_q_v8XeoWzr1OO9vA3Qlv1xac_fJH_HBbLUryn2pFaDxrkrjwBgh3aZU4Q?key=qRZXOzXKu-A8HOMrTLESOw&#34; alt=&#34;Brent Leung tweet graphic&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Source: &lt;a href=&#34;https://www.linkedin.com/feed/update/urn:li:activity:7339255065632731136&#34;&gt;LinkedIn post&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;🇯🇵 OpenSSF Community – Japan&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;I connected with the open source security community in Japan to explore how agentic AI can help shape the future of cloud-native users, OpenSSF, and the broader open source ecosystem. I also showcased a live demo of kagent, highlighting the future impact of agentic AI.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;🇺🇸Open Source Summit NA&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In a totally unplanned moment, I did a live demo of kagent alongside my generative AI application with Kubernetes, Argo and Istio—right in the middle of troubleshooting a Git mistake I had just made! 😅&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;It was amazing to have kagent acting like my buddy on stage, offering hints and helping me recover in real time. A great example of how powerful and practical agentic AI can be!&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Beyond cloud native operations&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;While kagent was originally designed to tackle challenges in cloud-native operations, we’ve been excited to see users applying it far beyond that scope.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Thanks to its knowledge-based agent, kagent can be used to interact with and reason over any type of documentation—not just Kubernetes manifests or infrastructure logs. From internal wikis and runbooks to software manuals and onboarding guides, kagent is proving to be a powerful tool for making structured and unstructured knowledge accessible via simple conversations.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;🎉&lt;/strong&gt;Wrapping up&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To everyone who has starred the kagent repo, contributed code, filed issues, joined discussions, or simply helped spread the word—&lt;strong&gt;thank you&lt;/strong&gt; for being an essential part of this community! We’re super excited to keep growing and building together.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;We’re proud to collaborate within the CNCF community to shape the future of agentic AI with kagent—together.&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Want to join the kagent community? Check out the project at&lt;/em&gt;&lt;a href=&#34;https://kagent.dev/&#34;&gt;&lt;em&gt; &lt;/em&gt;&lt;em&gt;kagent.dev&lt;/em&gt;&lt;/a&gt;&lt;em&gt;, star us on&lt;/em&gt;&lt;a href=&#34;https://github.com/kagent-dev/kagent&#34;&gt;&lt;em&gt; &lt;/em&gt;&lt;em&gt;GitHub&lt;/em&gt;&lt;/a&gt;&lt;em&gt;, and join our &lt;/em&gt;&lt;a href=&#34;https://discord.gg/Fu3k65f2k3&#34;&gt;&lt;em&gt;Discord&lt;/em&gt;&lt;/a&gt;&lt;em&gt; or weekly community meeting. Whether you’re looking to build your first AI agent or contribute to the framework itself, we’d love to have you onboard.&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Mon, 18 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Gear Up for the 5th Annual KCD Washington DC!】Gear Up for the 5th Annual KCD Washington DC!</title>
      <link>https://www.cncf.io/blog/2025/08/16/gear-up-for-the-5th-annual-kcd-washington-dc/</link>
      <description>【&lt;p&gt;We’re so thrilled to be organizing another year of cloud native community in the Nation’s Capital.&amp;nbsp; Past years have witnessed amazing presentations ranging from core Kubernetes topics to emerging trends in ML/AI, sustainability, virtual clusters and more.&amp;nbsp; This year promises to be even more amazing.&amp;nbsp; Our program is set, and includes two new innovations for our KCD:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;For the first time, we’re offering a &lt;strong&gt;hands-on workshop&lt;/strong&gt; covering basic and intermediate topics on using &lt;strong&gt;Prometheus&lt;/strong&gt; in your observability practice. The curriculum covers 20-25% of the Linux Foundation’s Prometheus Certified Associate (PCA) course.&amp;nbsp; While this workshop does not lead to certification, and is not a substitute for the PCA course, it will give you a solid working knowledge for getting started and perhaps help you decide if you’d like to pursue certification separately – if you do, you’ll be ahead of the game with this solid foundation.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;We’re adding a &lt;strong&gt;government-focused cybersecurity keynote&lt;/strong&gt; by our special guest, Ashley Jones, Cybersecurity Advisor for Region III of the Department of Homeland Security, Cybersecurity and Infrastructure Security Agency (CISA.)&amp;nbsp;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Special Government &amp;amp; Cybersecurity Focus – and free admission for our government employee community members!&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;You won’t want to miss Ashley Jones’ keynote if you’re a cybersecurity professional or involved in government technology in any way. A limited number of free tickets will be available soon for our community members working for federal, state or local government agencies. You can request a free government ticket here: &lt;a href=&#34;https://forms.gle/aLNfRwpvFn3vQ5Vo8&#34;&gt;https://forms.gle/aLNfRwpvFn3vQ5Vo8&lt;/a&gt;&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Plus our regular program is amazing!&lt;/strong&gt;&lt;br&gt;All of that rests on top of our regular program that includes presentations like:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Industry perspective: &lt;/strong&gt;&lt;em&gt;Scaling Cloud Native: Reaching the Next 10 Million Users&lt;/em&gt; by Lin Sun at Solo.io&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;K8s in the Enterprise: &lt;/strong&gt;&lt;em&gt;From Silos to SIGs: Building Kubernetes Community in the Enterprise&lt;/em&gt; by Jason Stryker&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Inclusivity: &lt;/strong&gt;&lt;em&gt;Unleash Your Inner Ally: Let’s Make Open Source Radically Welcoming!&lt;/em&gt; by Catherine Paganini and Christopher Khanoyan advocate for inclusivity in open source. (This talk willwith be interpreted for the hearing-impaired)&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Artificial Intelligence (AI):&lt;/strong&gt; &lt;em&gt;AI on Lockdown: Deploying ML Pipelines in Controlled Government Spaces&lt;/em&gt; by Kumuda Sreenivasa&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;….and a whole lot more, which you can see in the &lt;a href=&#34;https://kcd-washington-dc-2025.sessionize.com/&#34;&gt;Full Schedule&lt;/a&gt; [https://kcd-washington-dc-2025.sessionize.com/]&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;And there’s plenty of food, drinks and networking&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Once again, we plan on hosting an evening &lt;strong&gt;Social Hour&lt;/strong&gt; free for all attendees where you can meet fellow attendees, speakers, and sponsors, in a relaxed, community environment while enjoying drinks and appetizers.&amp;nbsp; And, of course, you can enjoy all-day snacks, beverages (tea, coffee, soft drinks) and a nutritious lunch, all included with your one-day ticket.&amp;nbsp; That’s a pretty good value for $75, and to make it even more inviting, we’re offering 25% for all CNCF readers using code FRIENDS25 when you &lt;a href=&#34;https://bit.ly/KCDDC2025&#34;&gt;Get Tickets&lt;/a&gt; [https://bit.ly/KCDDC2025] today.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;True community&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Last but not least, we know the current job market and economic times are difficult for many of our most vulnerable community members.&amp;nbsp; We also want to encourage participation from under-represented minority (URM) groups.&amp;nbsp; Therefore, we’re proud to offer a number of free tickets to community members in need or who are in URM groups. You can request a free community ticket here: &lt;a href=&#34;https://forms.gle/aLNfRwpvFn3vQ5Vo8&#34;&gt;https://forms.gle/aLNfRwpvFn3vQ5Vo8&lt;/a&gt;&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Additionally, we have been collaborating with the CNCF Deaf and Hard of Hearing Working Group to ensure this year’s event has live captioning throughout the day and interpretation services for our special presentation on inclusivity.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;In conclusion&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;br&gt;This year’s KCD Washington DC promises to be our biggest and best yet, packed with insightful sessions, hands-on workshops, inclusive community and invaluable networking opportunities.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We’re also once again co-locating with DevOpsDays DC for their auspicious 10&lt;sup&gt;th&lt;/sup&gt; editioniteration in the DMV, and third annual event joining forces with us.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We look forward to seeing you on September 16&lt;sup&gt;th&lt;/sup&gt; at the historic American Red Cross headquarters!&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;We’re so thrilled to be organizing another year of cloud native community in the Nation’s Capital.&amp;nbsp; Past years have witnessed amazing presentations ranging from core Kubernetes topics to emerging trends in ML/AI, sustainability, virtual clusters and more.&amp;nbsp; This year promises to be even more amazing.&amp;nbsp; Our program is set, and includes two new innovations for our KCD:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;For the first time, we’re offering a &lt;strong&gt;hands-on workshop&lt;/strong&gt; covering basic and intermediate topics on using &lt;strong&gt;Prometheus&lt;/strong&gt; in your observability practice. The curriculum covers 20-25% of the Linux Foundation’s Prometheus Certified Associate (PCA) course.&amp;nbsp; While this workshop does not lead to certification, and is not a substitute for the PCA course, it will give you a solid working knowledge for getting started and perhaps help you decide if you’d like to pursue certification separately – if you do, you’ll be ahead of the game with this solid foundation.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;We’re adding a &lt;strong&gt;government-focused cybersecurity keynote&lt;/strong&gt; by our special guest, Ashley Jones, Cybersecurity Advisor for Region III of the Department of Homeland Security, Cybersecurity and Infrastructure Security Agency (CISA.)&amp;nbsp;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Special Government &amp;amp; Cybersecurity Focus – and free admission for our government employee community members!&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;You won’t want to miss Ashley Jones’ keynote if you’re a cybersecurity professional or involved in government technology in any way. A limited number of free tickets will be available soon for our community members working for federal, state or local government agencies. You can request a free government ticket here: &lt;a href=&#34;https://forms.gle/aLNfRwpvFn3vQ5Vo8&#34;&gt;https://forms.gle/aLNfRwpvFn3vQ5Vo8&lt;/a&gt;&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Plus our regular program is amazing!&lt;/strong&gt;&lt;br&gt;All of that rests on top of our regular program that includes presentations like:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Industry perspective: &lt;/strong&gt;&lt;em&gt;Scaling Cloud Native: Reaching the Next 10 Million Users&lt;/em&gt; by Lin Sun at Solo.io&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;K8s in the Enterprise: &lt;/strong&gt;&lt;em&gt;From Silos to SIGs: Building Kubernetes Community in the Enterprise&lt;/em&gt; by Jason Stryker&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Inclusivity: &lt;/strong&gt;&lt;em&gt;Unleash Your Inner Ally: Let’s Make Open Source Radically Welcoming!&lt;/em&gt; by Catherine Paganini and Christopher Khanoyan advocate for inclusivity in open source. (This talk willwith be interpreted for the hearing-impaired)&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Artificial Intelligence (AI):&lt;/strong&gt; &lt;em&gt;AI on Lockdown: Deploying ML Pipelines in Controlled Government Spaces&lt;/em&gt; by Kumuda Sreenivasa&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;….and a whole lot more, which you can see in the &lt;a href=&#34;https://kcd-washington-dc-2025.sessionize.com/&#34;&gt;Full Schedule&lt;/a&gt; [https://kcd-washington-dc-2025.sessionize.com/]&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;And there’s plenty of food, drinks and networking&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Once again, we plan on hosting an evening &lt;strong&gt;Social Hour&lt;/strong&gt; free for all attendees where you can meet fellow attendees, speakers, and sponsors, in a relaxed, community environment while enjoying drinks and appetizers.&amp;nbsp; And, of course, you can enjoy all-day snacks, beverages (tea, coffee, soft drinks) and a nutritious lunch, all included with your one-day ticket.&amp;nbsp; That’s a pretty good value for $75, and to make it even more inviting, we’re offering 25% for all CNCF readers using code FRIENDS25 when you &lt;a href=&#34;https://bit.ly/KCDDC2025&#34;&gt;Get Tickets&lt;/a&gt; [https://bit.ly/KCDDC2025] today.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;True community&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Last but not least, we know the current job market and economic times are difficult for many of our most vulnerable community members.&amp;nbsp; We also want to encourage participation from under-represented minority (URM) groups.&amp;nbsp; Therefore, we’re proud to offer a number of free tickets to community members in need or who are in URM groups. You can request a free community ticket here: &lt;a href=&#34;https://forms.gle/aLNfRwpvFn3vQ5Vo8&#34;&gt;https://forms.gle/aLNfRwpvFn3vQ5Vo8&lt;/a&gt;&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Additionally, we have been collaborating with the CNCF Deaf and Hard of Hearing Working Group to ensure this year’s event has live captioning throughout the day and interpretation services for our special presentation on inclusivity.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;In conclusion&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;br&gt;This year’s KCD Washington DC promises to be our biggest and best yet, packed with insightful sessions, hands-on workshops, inclusive community and invaluable networking opportunities.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We’re also once again co-locating with DevOpsDays DC for their auspicious 10&lt;sup&gt;th&lt;/sup&gt; editioniteration in the DMV, and third annual event joining forces with us.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We look forward to seeing you on September 16&lt;sup&gt;th&lt;/sup&gt; at the historic American Red Cross headquarters!&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Fri, 15 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【How OTel Community Day Enriched my Open Source Career: A Tale of Community and Connection】How OTel Community Day Enriched my Open Source Career: A Tale of Community and Connection</title>
      <link>https://www.cncf.io/blog/2025/08/13/how-otel-community-day-enriched-my-open-source-career-a-tale-of-community-and-connection/</link>
      <description>【&lt;p&gt;My name is Diana Todea. I’m originally from Romania and have been living in Spain for the past nine years. I have worked as a Senior Site Reliability Engineer specializing in Observability for the last three years and my OpenTelemetry (OTel) journey began in 2024 with my first community contributions. What started as a simple curiosity quickly turned into a passion for open source. In 2025, my talk about my journey with OpenTelemetry was selected for &lt;strong&gt;OTel Community Day&lt;/strong&gt;, part of the &lt;strong&gt;Open Observability Summit&lt;/strong&gt; in Denver, Colorado. I was thrilled to participate as a speaker, this moment felt like a meaningful recognition of my contributions to the OpenTelemetry project and the broader Cloud Native community.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Key Takeaways from OTel Community Day&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;OTel Community Day was an enriching experience. From the supporting members of the open source community who organized and ran the event to meeting so many active contributors to the OTel project, the energy and collaboration were palpable.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;I attended several insightful talks that highlighted how much the project has grown in just one year. Speakers discussed the current pain points, the project’s direction, and how the community is continuing to drive improvements through new integrations and features. I also had the chance to speak directly with OTel maintainers and offer feedback on areas I believe need improvement. As a member of the &lt;strong&gt;#otel-localization-es&lt;/strong&gt; SIG, I shared updates on our efforts to translate the official OTel documentation into Spanish. It was a great opportunity to invite new contributors to join our localization initiative and help make the project more accessible to a global audience.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Many presentations focused on exciting, upcoming contributions that are just beginning to emerge and will soon become public. Connecting with peers at the event was invaluable, it gave me insight into where I can contribute next and which SIGs could use more support.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;My Continued Journey in Open Source&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;OTel Community Day wasn’t just an event, it became a turning point in my career and life. Inspired by the experience and the community, I decided to apply for the &lt;strong&gt;CNCF Ambassador&lt;/strong&gt; program. I believe this role plays a key part in motivating others to begin their own journeys into open source. Thanks to the support and spirit of the Cloud Native community, I have embraced a mindset of collaboration, mentorship and continuous learning. My career has evolved significantly this year and I’m now focusing more on &lt;strong&gt;open source Developer Advocacy&lt;/strong&gt; and finding new ways to support and uplift the community.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The event reignited my motivation to invest my technical skills in open source, give more talks on OpenTelemetry and other open source projects and share my experience with wider audiences. It’s given me the confidence to continue advocating for open standards and community-driven Development.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Final Thoughts&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;OTel Community Day truly strengthened my connection to the cloud native and open source ecosystems. It reminded me how impactful individual contributions can be and how important it is to nurture and support the local communities that make it all possible.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;My name is Diana Todea. I’m originally from Romania and have been living in Spain for the past nine years. I have worked as a Senior Site Reliability Engineer specializing in Observability for the last three years and my OpenTelemetry (OTel) journey began in 2024 with my first community contributions. What started as a simple curiosity quickly turned into a passion for open source. In 2025, my talk about my journey with OpenTelemetry was selected for &lt;strong&gt;OTel Community Day&lt;/strong&gt;, part of the &lt;strong&gt;Open Observability Summit&lt;/strong&gt; in Denver, Colorado. I was thrilled to participate as a speaker, this moment felt like a meaningful recognition of my contributions to the OpenTelemetry project and the broader Cloud Native community.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Key Takeaways from OTel Community Day&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;OTel Community Day was an enriching experience. From the supporting members of the open source community who organized and ran the event to meeting so many active contributors to the OTel project, the energy and collaboration were palpable.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;I attended several insightful talks that highlighted how much the project has grown in just one year. Speakers discussed the current pain points, the project’s direction, and how the community is continuing to drive improvements through new integrations and features. I also had the chance to speak directly with OTel maintainers and offer feedback on areas I believe need improvement. As a member of the &lt;strong&gt;#otel-localization-es&lt;/strong&gt; SIG, I shared updates on our efforts to translate the official OTel documentation into Spanish. It was a great opportunity to invite new contributors to join our localization initiative and help make the project more accessible to a global audience.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Many presentations focused on exciting, upcoming contributions that are just beginning to emerge and will soon become public. Connecting with peers at the event was invaluable, it gave me insight into where I can contribute next and which SIGs could use more support.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;My Continued Journey in Open Source&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;OTel Community Day wasn’t just an event, it became a turning point in my career and life. Inspired by the experience and the community, I decided to apply for the &lt;strong&gt;CNCF Ambassador&lt;/strong&gt; program. I believe this role plays a key part in motivating others to begin their own journeys into open source. Thanks to the support and spirit of the Cloud Native community, I have embraced a mindset of collaboration, mentorship and continuous learning. My career has evolved significantly this year and I’m now focusing more on &lt;strong&gt;open source Developer Advocacy&lt;/strong&gt; and finding new ways to support and uplift the community.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The event reignited my motivation to invest my technical skills in open source, give more talks on OpenTelemetry and other open source projects and share my experience with wider audiences. It’s given me the confidence to continue advocating for open standards and community-driven Development.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Final Thoughts&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;OTel Community Day truly strengthened my connection to the cloud native and open source ecosystems. It reminded me how impactful individual contributions can be and how important it is to nurture and support the local communities that make it all possible.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Tue, 12 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Beyond Code: Open Source, Mentorship and Microcks】Beyond Code: Open Source, Mentorship and Microcks</title>
      <link>https://www.cncf.io/blog/2025/08/14/beyond-code-open-source-mentorship-and-microcks/</link>
      <description>【&lt;h1 class=&#34;wp-block-heading&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXdmD9uMfsXK5PGrWMp3iKML56KdSqvMzeFtXL--zETrPIKYAwizNfmxM8xWaJpR_1rIY-oZ2O50EQncuL49ZdL0VfS5QLWjqp6jufitC1GTWW7JTCzt-DNhoGWA5gedNfONXMkgig?key=Wt8RVK4vQ6IWAEi65VQhyQ&#34; style=&#34;&#34; alt=&#34;Graphic of large puzzle pieces&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;https://www.pexels.com/photo/close-up-photo-of-people-holding-puzzle-pieces-6147381/&#34;&gt;Photo by Diva Plavalaguna from Pexels&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Open source software proves that collective contribution creates collective value. However, as a contributor to Microcks, I have observed a concerning pattern that threatens the sustainability of the project and countless others in the open source ecosystem.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;The Reality Behind the Code&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For years, the Microcks team of contributors and maintainers has dedicated countless hours to creating, enhancing, and maintaining Microcks. They have handled complex bugs, responded to support requests, and continuously improved the platform to satisfy the expanding demands of API mocking and testing. This work has been done without financial compensation, driven purely by our passion for creating valuable tools for the developer community.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The numbers tell a story: thousands of downloads, hundreds of GitHub stars, and a growing user base that spans startups to enterprise organizations. Microcks has become integral to many development workflows, saving teams countless hours and enabling better API development practices.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;The Silent Users&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Yet, despite this widespread adoption, we’ve noticed something troubling. Many users remain silent beneficiaries, downloading, deploying, and benefiting from Microcks, but their engagement ends there. When we reach out for community input, request feedback on new features, or seek help with documentation, the response is often silence.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This silence creates a challenging paradox for open source maintainers. While seeing download metrics and usage statistics climb feels validating, the lack of community engagement makes it difficult to prioritize development efforts, understand real-world pain points, and build the collaborative ecosystem that makes open source projects truly sustainable. We find ourselves making decisions in a vacuum, uncertain whether we’re solving the right problems or building features that actually matter to our users.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This isn’t about demanding gratitude or expecting every user to become a contributor. We understand that not everyone has the time, skills, or resources to contribute code. But there’s a vast middle ground between passive consumption and active development that many of our users could occupy.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;The Cost of Silence&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This one-sided relationship creates several challenges:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Sustainability concerns&lt;/em&gt;: When maintainers burn out or move on to other projects, there’s often no one ready to step up. The knowledge and passion that built the project can disappear overnight.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Innovation stagnation:&lt;/em&gt; Without diverse input from real users, we’re essentially developing in an echo chamber. We miss crucial use cases, overlook pain points, and may focus on features that sound good in theory but don’t address real-world needs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Community fragmentation&lt;/em&gt;&lt;em&gt;:&lt;/em&gt; A healthy open source project builds a community, not just a user base. Without engaged users, we risk losing the collaborative spirit that makes open source powerful.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Recognition deficit:&lt;/em&gt; While we don’t seek fame, visibility helps attract new contributors, secures funding opportunities, and validates the time we invest in the project.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Simple Ways to Give Back&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Contributing to Microcks (and any open source project) doesn’t require being a coding wizard. Here are meaningful ways to support the community:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Spread the word:&lt;/em&gt; Share your success stories, write blog posts about how Microcks solved your problems, or mention it in relevant discussions. Word-of-mouth is incredibly powerful.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Engage authentically:&lt;/em&gt; Star the repository, participate in discussions, attend community calls, or join our Slack/Discord. Your presence and voice matter.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Documentation contributions: &lt;/em&gt;Did you find something confusing? Noticed a gap in our docs? Even minor improvements to documentation help countless future users.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Report issues thoughtfully:&lt;/em&gt; When you encounter bugs, report them with details. Good bug reports are contributions that help everyone.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Answer questions:&lt;/em&gt; Share your knowledge if you see someone struggling with something you’ve figured out. Peer support strengthens the entire community.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Join the adopter community:&lt;/em&gt; If Microcks helps your organization, join the public adopter list: &amp;nbsp;&lt;a href=&#34;https://github.com/microcks/.github/blob/main/ADOPTERS.md&#34;&gt;https://github.com/microcks/.github/blob/main/ADOPTERS.md&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;A Sustainable Future&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We’re not asking for charity, we’re asking for partnership. Open source works best when it’s truly collaborative, when users become stakeholders in the project’s success. The most successful open source projects aren’t just tools; they’re communities of people who care about solving problems together.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Microcks has reached a critical juncture. We can continue growing as a community-driven project or remain a tool maintained by a few for the benefit of many. The choice isn’t ours alone—it belongs to everyone who has ever&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;benefited from our work.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Your Turn – Join Me in Building These Resources&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If Microcks has helped you ship better software, meet deadlines, or solve API testing challenges, I have specific ways you can help make it even better for everyone. As part of my LFX mentorship project, I’m working on critical resources our community desperately needs, but I can’t complete them without your real-world insights.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Here’s how you can contribute right now:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;em&gt;&amp;nbsp;&lt;/em&gt;&lt;em&gt;Share Your Deployment Details&lt;/em&gt; – Help us build the&lt;a href=&#34;https://github.com/microcks/community/issues/85&#34;&gt; Compatibility Matrix (#85)&lt;/a&gt; by sharing which versions of Kubernetes, MongoDB, and Keycloak work with your Microcks setup. Your configuration details help others avoid compatibility headaches.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&amp;nbsp;&lt;em&gt;Contribute Performance Data&lt;/em&gt; – Join our&lt;a href=&#34;https://github.com/microcks/community/issues/86&#34;&gt; Sizing Guide initiative (#86)&lt;/a&gt; by running our k6 benchmarks and sharing your results. Whether you’re running Microcks on a laptop or enterprise Kubernetes, your performance data helps teams right-size their deployments.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;em&gt;Share Security Solutions&lt;/em&gt; – If you’ve figured out how to secure Microcks mock endpoints with API gateways, please contribute to our&lt;a href=&#34;https://github.com/microcks/community/issues/51&#34;&gt; Security Documentation (#51)&lt;/a&gt;. Your Kong/ AWS API Gateway/ Traefik or NGINX configurations could save someone days of troubleshooting.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;These aren’t just documentation requests – they’re opportunities to ensure that the challenges you’ve already solved don’t need to be solved again by the next user.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;The next time you see these issues or similar calls for help, don’t scroll past.&lt;/strong&gt; Your experience is precisely what we need to build resources that genuinely serve the community.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Our GitHub repository is at&lt;a href=&#34;https://github.com/microcks/community&#34;&gt; microcks/community&lt;/a&gt;. The community is waiting for your insights to help ensure these initiatives succeed.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The future of Microcks depends not just on code commits, but on community commits. Are you ready to make yours?&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Blog by Krishi Agrawal (LFX’25 mentee @Microcks)&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Quote:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Yacine Kheddache – Microcks’ maintainer&lt;br&gt;&lt;em&gt;“As a maintainer of the Microcks project and mentor to Krishi during the 3 month LFX mentorship program, I was both glad and impressed to see how clearly she articulated one of the core challenges many open source projects face: the gap between being a good open source citizen and users who remain passive or silent. The project she worked on was a perfect example of something maintainers often can’t take on themselves, as our focus must remain on the project’s core objectives. After all, Microcks is an open source initiative, not a commercial product. This means adopters and the community must take responsibility for their deployment environments and requirements. That’s exactly why Krishi initiated the community repository and installation documentation, which we hope the community will continue to maintain and grow. Sharing is caring.”&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;h1 class=&#34;wp-block-heading&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXdmD9uMfsXK5PGrWMp3iKML56KdSqvMzeFtXL--zETrPIKYAwizNfmxM8xWaJpR_1rIY-oZ2O50EQncuL49ZdL0VfS5QLWjqp6jufitC1GTWW7JTCzt-DNhoGWA5gedNfONXMkgig?key=Wt8RVK4vQ6IWAEi65VQhyQ&#34; style=&#34;&#34; alt=&#34;Graphic of large puzzle pieces&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;https://www.pexels.com/photo/close-up-photo-of-people-holding-puzzle-pieces-6147381/&#34;&gt;Photo by Diva Plavalaguna from Pexels&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Open source software proves that collective contribution creates collective value. However, as a contributor to Microcks, I have observed a concerning pattern that threatens the sustainability of the project and countless others in the open source ecosystem.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;The Reality Behind the Code&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For years, the Microcks team of contributors and maintainers has dedicated countless hours to creating, enhancing, and maintaining Microcks. They have handled complex bugs, responded to support requests, and continuously improved the platform to satisfy the expanding demands of API mocking and testing. This work has been done without financial compensation, driven purely by our passion for creating valuable tools for the developer community.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The numbers tell a story: thousands of downloads, hundreds of GitHub stars, and a growing user base that spans startups to enterprise organizations. Microcks has become integral to many development workflows, saving teams countless hours and enabling better API development practices.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;The Silent Users&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Yet, despite this widespread adoption, we’ve noticed something troubling. Many users remain silent beneficiaries, downloading, deploying, and benefiting from Microcks, but their engagement ends there. When we reach out for community input, request feedback on new features, or seek help with documentation, the response is often silence.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This silence creates a challenging paradox for open source maintainers. While seeing download metrics and usage statistics climb feels validating, the lack of community engagement makes it difficult to prioritize development efforts, understand real-world pain points, and build the collaborative ecosystem that makes open source projects truly sustainable. We find ourselves making decisions in a vacuum, uncertain whether we’re solving the right problems or building features that actually matter to our users.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This isn’t about demanding gratitude or expecting every user to become a contributor. We understand that not everyone has the time, skills, or resources to contribute code. But there’s a vast middle ground between passive consumption and active development that many of our users could occupy.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;The Cost of Silence&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This one-sided relationship creates several challenges:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Sustainability concerns&lt;/em&gt;: When maintainers burn out or move on to other projects, there’s often no one ready to step up. The knowledge and passion that built the project can disappear overnight.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Innovation stagnation:&lt;/em&gt; Without diverse input from real users, we’re essentially developing in an echo chamber. We miss crucial use cases, overlook pain points, and may focus on features that sound good in theory but don’t address real-world needs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Community fragmentation&lt;/em&gt;&lt;em&gt;:&lt;/em&gt; A healthy open source project builds a community, not just a user base. Without engaged users, we risk losing the collaborative spirit that makes open source powerful.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Recognition deficit:&lt;/em&gt; While we don’t seek fame, visibility helps attract new contributors, secures funding opportunities, and validates the time we invest in the project.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Simple Ways to Give Back&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Contributing to Microcks (and any open source project) doesn’t require being a coding wizard. Here are meaningful ways to support the community:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Spread the word:&lt;/em&gt; Share your success stories, write blog posts about how Microcks solved your problems, or mention it in relevant discussions. Word-of-mouth is incredibly powerful.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Engage authentically:&lt;/em&gt; Star the repository, participate in discussions, attend community calls, or join our Slack/Discord. Your presence and voice matter.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Documentation contributions: &lt;/em&gt;Did you find something confusing? Noticed a gap in our docs? Even minor improvements to documentation help countless future users.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Report issues thoughtfully:&lt;/em&gt; When you encounter bugs, report them with details. Good bug reports are contributions that help everyone.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Answer questions:&lt;/em&gt; Share your knowledge if you see someone struggling with something you’ve figured out. Peer support strengthens the entire community.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Join the adopter community:&lt;/em&gt; If Microcks helps your organization, join the public adopter list: &amp;nbsp;&lt;a href=&#34;https://github.com/microcks/.github/blob/main/ADOPTERS.md&#34;&gt;https://github.com/microcks/.github/blob/main/ADOPTERS.md&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;A Sustainable Future&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We’re not asking for charity, we’re asking for partnership. Open source works best when it’s truly collaborative, when users become stakeholders in the project’s success. The most successful open source projects aren’t just tools; they’re communities of people who care about solving problems together.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Microcks has reached a critical juncture. We can continue growing as a community-driven project or remain a tool maintained by a few for the benefit of many. The choice isn’t ours alone—it belongs to everyone who has ever&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;benefited from our work.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Your Turn – Join Me in Building These Resources&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If Microcks has helped you ship better software, meet deadlines, or solve API testing challenges, I have specific ways you can help make it even better for everyone. As part of my LFX mentorship project, I’m working on critical resources our community desperately needs, but I can’t complete them without your real-world insights.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Here’s how you can contribute right now:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;em&gt;&amp;nbsp;&lt;/em&gt;&lt;em&gt;Share Your Deployment Details&lt;/em&gt; – Help us build the&lt;a href=&#34;https://github.com/microcks/community/issues/85&#34;&gt; Compatibility Matrix (#85)&lt;/a&gt; by sharing which versions of Kubernetes, MongoDB, and Keycloak work with your Microcks setup. Your configuration details help others avoid compatibility headaches.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&amp;nbsp;&lt;em&gt;Contribute Performance Data&lt;/em&gt; – Join our&lt;a href=&#34;https://github.com/microcks/community/issues/86&#34;&gt; Sizing Guide initiative (#86)&lt;/a&gt; by running our k6 benchmarks and sharing your results. Whether you’re running Microcks on a laptop or enterprise Kubernetes, your performance data helps teams right-size their deployments.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;em&gt;Share Security Solutions&lt;/em&gt; – If you’ve figured out how to secure Microcks mock endpoints with API gateways, please contribute to our&lt;a href=&#34;https://github.com/microcks/community/issues/51&#34;&gt; Security Documentation (#51)&lt;/a&gt;. Your Kong/ AWS API Gateway/ Traefik or NGINX configurations could save someone days of troubleshooting.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;These aren’t just documentation requests – they’re opportunities to ensure that the challenges you’ve already solved don’t need to be solved again by the next user.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;The next time you see these issues or similar calls for help, don’t scroll past.&lt;/strong&gt; Your experience is precisely what we need to build resources that genuinely serve the community.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Our GitHub repository is at&lt;a href=&#34;https://github.com/microcks/community&#34;&gt; microcks/community&lt;/a&gt;. The community is waiting for your insights to help ensure these initiatives succeed.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The future of Microcks depends not just on code commits, but on community commits. Are you ready to make yours?&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Blog by Krishi Agrawal (LFX’25 mentee @Microcks)&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Quote:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Yacine Kheddache – Microcks’ maintainer&lt;br&gt;&lt;em&gt;“As a maintainer of the Microcks project and mentor to Krishi during the 3 month LFX mentorship program, I was both glad and impressed to see how clearly she articulated one of the core challenges many open source projects face: the gap between being a good open source citizen and users who remain passive or silent. The project she worked on was a perfect example of something maintainers often can’t take on themselves, as our focus must remain on the project’s core objectives. After all, Microcks is an open source initiative, not a commercial product. This means adopters and the community must take responsibility for their deployment environments and requirements. That’s exactly why Krishi initiated the community repository and installation documentation, which we hope the community will continue to maintain and grow. Sharing is caring.”&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Wed, 13 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Uniting the Cloud Native Community at the Inaugural KCD SF Bay Area】Uniting the Cloud Native Community at the Inaugural KCD SF Bay Area</title>
      <link>https://www.cncf.io/blog/2025/08/20/uniting-the-cloud-native-community-at-the-inaugural-kcd-sf-bay-area/</link>
      <description>【&lt;p&gt;The cloud native landscape is constantly evolving, and staying ahead of the curve means more than just reading documentation—it means connecting with the people who are shaping the future. That’s exactly what the &lt;strong&gt;inaugural Kubernetes Community Day (KCD) SF Bay Area&lt;/strong&gt; event is all about. This full-day gathering, proudly sponsored by the Cloud Native Computing Foundation (CNCF), is the ultimate opportunity for enthusiasts, developers, and industry leaders to come together for a day of insightful talks and unparalleled networking.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;br&gt;On &lt;strong&gt;September 9th&lt;/strong&gt;, the historic Computer History Museum in Mountain View will open its doors to the Bay Area’s thriving cloud native community. This isn’t just a conference; it’s a celebration of collaboration and knowledge sharing. As an added bonus, your event registration grants you access to the museum’s fascinating exhibits, allowing you to explore the history of technology during your breaks.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;&lt;em&gt;&amp;nbsp;&lt;/em&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;&lt;em&gt;A Day Packed with Industry Visionaries&lt;/em&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The KCD SF Bay Area event boasts an incredible lineup of speakers and visionaries. You’ll have the chance to hear directly from some of the most influential minds in the cloud native space. Confirmed speakers include:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Solomon Hykes&lt;/strong&gt;, the founder of Docker and Dagger.io, whose work has fundamentally changed the way we build and deploy applications.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Jim Bugwadia&lt;/strong&gt;, founder of Nirmata and a key maintainer of the popular policy engine Kyverno.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Ramiro Berrelleza&lt;/strong&gt;, founder of Okteto, who is dedicated to simplifying cloud native development workflows.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Marina Moore&lt;/strong&gt;, the head of Edera Research, and a security expert data scientist.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Dan Garfield&lt;/strong&gt;, co-founder of Codefresh and a maintainer of the Argo Project.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Ron Petty&lt;/strong&gt; and &lt;strong&gt;Ricardo Aravena&lt;/strong&gt;, leads of the CNCF AI WG &amp;amp; TOC, who are at the forefront of integrating artificial intelligence with cloud native technologies.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Jonathan Bryce, &lt;/strong&gt;Executive Director of the CNCF, LF, and OIF.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;br&gt;These are just a few of the thought leaders you can expect to learn from. The full schedule, which you can view at &lt;a href=&#34;https://schedule.kcdsfbayarea.com/&#34;&gt;https://schedule.kcdsfbayarea.com&lt;/a&gt;, is packed with sessions designed to expand your knowledge and inspire new ideas.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;&lt;em&gt;A Special Moment: Celebrating 10 Years of the CNCF&lt;/em&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This year marks a special milestone for the cloud native community. We will take a moment during the event to celebrate the &lt;strong&gt;10th anniversary of the Cloud Native Computing Foundation (CNCF)&lt;/strong&gt;. The Computer History Museum holds a unique significance for us, as it was the very location where the CNCF was born. We are thrilled to be back at this historic venue to honor a decade of innovation, collaboration, and growth that has shaped the modern technological landscape. Join us as we recognize the achievements of the past ten years and look forward to the future of cloud native technology.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;&lt;em&gt;Hands-On Workshops and Demos&lt;/em&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In addition to the main talks, the event will feature hands-on workshops from some of the leading companies in the cloud native ecosystem. These sessions will give you a chance to dive deep into new tools and technologies with guidance from the experts who created them.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Heroku:&lt;/strong&gt; Explore approaches to deploying and managing applications, with a focus on developer-friendly workflows, scalability, and best practices..&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Appscode:&lt;/strong&gt; Gain practical experience with running production-grade databases on Kubernetes through hands-on sessions covering popular open source projects.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Nirmata:&lt;/strong&gt; Dive into Kubernetes governance and policy-as-code with the maintainers of Kyverno. These workshops are perfect for anyone looking to automate security and compliance in their clusters.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Mirantis:&lt;/strong&gt; Whether you’re a developer or an administrator, Mirantis will offer sessions on cloud native solutions, including Docker and Kubernetes, designed to help you prepare for certifications or simply sharpen your skills.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Octopus Deploy:&lt;/strong&gt; Simplify your CI/CD pipeline with deployment automation. This workshop will show you how to build robust, repeatable processes for getting your software from commit to production.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;&lt;em&gt;Hosted by Your Cloud Native Bay Area User Groups&lt;/em&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This event is brought to you by the passionate leaders of the Cloud Native Bay Area user groups: &lt;strong&gt;Lisa-Marie Namphy&lt;/strong&gt; (Intuit), &lt;strong&gt;Rey Lejano&lt;/strong&gt; (Red Hat), &lt;strong&gt;Jason Smith&lt;/strong&gt; (Google), and &lt;strong&gt;Natalie Lunbeck&lt;/strong&gt; (Shipyard). Their vision is to create a space that fosters collaboration and strengthens the local tech community.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;br&gt;The day will culminate in a vibrant &lt;strong&gt;evening social hour&lt;/strong&gt;, the perfect setting to relax, network, and connect with fellow attendees. It’s a great opportunity to continue conversations from the day and forge new friendships and professional connections.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;&lt;em&gt;Take Action Today!&lt;/em&gt;&lt;/strong&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;View the Schedule:&lt;/strong&gt;&amp;nbsp;&lt;a href=&#34;https://schedule.kcdsfbayarea.com/&#34;&gt;https://schedule.kcdsfbayarea.com&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol start=&#34;2&#34; class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Get Tickets:&lt;/strong&gt; Use code &lt;strong&gt;FRIENDS25&lt;/strong&gt; for a 25% discount on either platform.&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://community.cncf.io/events/details/cncf-kcd-sf-bay-area-presents-kcd-san-francisco-bay-area/&#34;&gt;CNCF Community&lt;/a&gt;&amp;nbsp;(requires a Linux Foundation account)&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://lu.ma/y3s2jegu&#34;&gt;Lu.ma&lt;/a&gt;&amp;nbsp;(requires a Lu.ma account)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Don’t miss this chance to learn from the best, network with peers, and celebrate the dynamic spirit of the cloud native community. We look forward to seeing you on September 9th in Mountain View!&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;The cloud native landscape is constantly evolving, and staying ahead of the curve means more than just reading documentation—it means connecting with the people who are shaping the future. That’s exactly what the &lt;strong&gt;inaugural Kubernetes Community Day (KCD) SF Bay Area&lt;/strong&gt; event is all about. This full-day gathering, proudly sponsored by the Cloud Native Computing Foundation (CNCF), is the ultimate opportunity for enthusiasts, developers, and industry leaders to come together for a day of insightful talks and unparalleled networking.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;br&gt;On &lt;strong&gt;September 9th&lt;/strong&gt;, the historic Computer History Museum in Mountain View will open its doors to the Bay Area’s thriving cloud native community. This isn’t just a conference; it’s a celebration of collaboration and knowledge sharing. As an added bonus, your event registration grants you access to the museum’s fascinating exhibits, allowing you to explore the history of technology during your breaks.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;&lt;em&gt;&amp;nbsp;&lt;/em&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;&lt;em&gt;A Day Packed with Industry Visionaries&lt;/em&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The KCD SF Bay Area event boasts an incredible lineup of speakers and visionaries. You’ll have the chance to hear directly from some of the most influential minds in the cloud native space. Confirmed speakers include:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Solomon Hykes&lt;/strong&gt;, the founder of Docker and Dagger.io, whose work has fundamentally changed the way we build and deploy applications.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Jim Bugwadia&lt;/strong&gt;, founder of Nirmata and a key maintainer of the popular policy engine Kyverno.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Ramiro Berrelleza&lt;/strong&gt;, founder of Okteto, who is dedicated to simplifying cloud native development workflows.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Marina Moore&lt;/strong&gt;, the head of Edera Research, and a security expert data scientist.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Dan Garfield&lt;/strong&gt;, co-founder of Codefresh and a maintainer of the Argo Project.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Ron Petty&lt;/strong&gt; and &lt;strong&gt;Ricardo Aravena&lt;/strong&gt;, leads of the CNCF AI WG &amp;amp; TOC, who are at the forefront of integrating artificial intelligence with cloud native technologies.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Jonathan Bryce, &lt;/strong&gt;Executive Director of the CNCF, LF, and OIF.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;br&gt;These are just a few of the thought leaders you can expect to learn from. The full schedule, which you can view at &lt;a href=&#34;https://schedule.kcdsfbayarea.com/&#34;&gt;https://schedule.kcdsfbayarea.com&lt;/a&gt;, is packed with sessions designed to expand your knowledge and inspire new ideas.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;&lt;em&gt;A Special Moment: Celebrating 10 Years of the CNCF&lt;/em&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This year marks a special milestone for the cloud native community. We will take a moment during the event to celebrate the &lt;strong&gt;10th anniversary of the Cloud Native Computing Foundation (CNCF)&lt;/strong&gt;. The Computer History Museum holds a unique significance for us, as it was the very location where the CNCF was born. We are thrilled to be back at this historic venue to honor a decade of innovation, collaboration, and growth that has shaped the modern technological landscape. Join us as we recognize the achievements of the past ten years and look forward to the future of cloud native technology.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;&lt;em&gt;Hands-On Workshops and Demos&lt;/em&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In addition to the main talks, the event will feature hands-on workshops from some of the leading companies in the cloud native ecosystem. These sessions will give you a chance to dive deep into new tools and technologies with guidance from the experts who created them.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Heroku:&lt;/strong&gt; Explore approaches to deploying and managing applications, with a focus on developer-friendly workflows, scalability, and best practices..&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Appscode:&lt;/strong&gt; Gain practical experience with running production-grade databases on Kubernetes through hands-on sessions covering popular open source projects.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Nirmata:&lt;/strong&gt; Dive into Kubernetes governance and policy-as-code with the maintainers of Kyverno. These workshops are perfect for anyone looking to automate security and compliance in their clusters.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Mirantis:&lt;/strong&gt; Whether you’re a developer or an administrator, Mirantis will offer sessions on cloud native solutions, including Docker and Kubernetes, designed to help you prepare for certifications or simply sharpen your skills.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Octopus Deploy:&lt;/strong&gt; Simplify your CI/CD pipeline with deployment automation. This workshop will show you how to build robust, repeatable processes for getting your software from commit to production.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;&lt;em&gt;Hosted by Your Cloud Native Bay Area User Groups&lt;/em&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This event is brought to you by the passionate leaders of the Cloud Native Bay Area user groups: &lt;strong&gt;Lisa-Marie Namphy&lt;/strong&gt; (Intuit), &lt;strong&gt;Rey Lejano&lt;/strong&gt; (Red Hat), &lt;strong&gt;Jason Smith&lt;/strong&gt; (Google), and &lt;strong&gt;Natalie Lunbeck&lt;/strong&gt; (Shipyard). Their vision is to create a space that fosters collaboration and strengthens the local tech community.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;br&gt;The day will culminate in a vibrant &lt;strong&gt;evening social hour&lt;/strong&gt;, the perfect setting to relax, network, and connect with fellow attendees. It’s a great opportunity to continue conversations from the day and forge new friendships and professional connections.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;&lt;em&gt;Take Action Today!&lt;/em&gt;&lt;/strong&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;View the Schedule:&lt;/strong&gt;&amp;nbsp;&lt;a href=&#34;https://schedule.kcdsfbayarea.com/&#34;&gt;https://schedule.kcdsfbayarea.com&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol start=&#34;2&#34; class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Get Tickets:&lt;/strong&gt; Use code &lt;strong&gt;FRIENDS25&lt;/strong&gt; for a 25% discount on either platform.&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://community.cncf.io/events/details/cncf-kcd-sf-bay-area-presents-kcd-san-francisco-bay-area/&#34;&gt;CNCF Community&lt;/a&gt;&amp;nbsp;(requires a Linux Foundation account)&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://lu.ma/y3s2jegu&#34;&gt;Lu.ma&lt;/a&gt;&amp;nbsp;(requires a Lu.ma account)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Don’t miss this chance to learn from the best, network with peers, and celebrate the dynamic spirit of the cloud native community. We look forward to seeing you on September 9th in Mountain View!&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Tue, 19 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【OpenKruise v1.8 Unlocking Infinite Possibilities in Cloud-Native Application Management】OpenKruise v1.8 Unlocking Infinite Possibilities in Cloud-Native Application Management</title>
      <link>https://www.cncf.io/blog/2025/08/13/openkruise-v1-8-unlocking-infinite-possibilities-in-cloud-native-application-management/</link>
      <description>【&lt;p&gt;&lt;a href=&#34;https://github.com/openkruise/kruise&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;OpenKruise&lt;/a&gt;&amp;nbsp;is an open-source cloud-native application automation management suite. It is also a current incubating project hosted by the Cloud Native Computing Foundation (CNCF). It is a standard extension component based on Kubernetes that is widely used in production of internet scale company. It also closely follows upstream community standards and adapts to the technical improvement and best practices for internet-scale scenarios.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In February 2025, OpenKruise released its latest version 1.8[2]. This version brings many important updates and enhancements, aimed at further improving the efficiency, elasticity, and reliability of cloud-native application management. This article provides a comprehensive overview of the new version.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;1. Embrace In-Place VPA: Unlock New Potential in Resource Management&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Authors:&amp;nbsp;&lt;a href=&#34;https://github.com/LavenderQAQ&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;@LavenderQAQ,&lt;/a&gt;&amp;nbsp;&lt;a href=&#34;https://github.com/ABNER-1&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;@ABNER-1&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In Kubernetes 1.27, the significant enhancement of&amp;nbsp;&lt;code&gt;InPlacePodVerticalScaling&lt;/code&gt;&amp;nbsp;(In-Place VPA) was introduced to boost the flexibility and efficiency of resource management. This feature has recently advanced to Beta in Kubernetes 1.33, reflecting its improved stability and suitability for production environments.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kruise is dedicated to boosting users’ workload management capabilities. In Kruise 1.8, we first integrated InPlacePodVerticalScaling with our advanced workload types like CloneSet, Advanced StatefulSet, and Advanced DaemonSet. Users can directly modify the resource settings in the workload to perform in-place resizing of resources for all pods under the workload without restarts, or simultaneously resources resize and upgrade images during in-place pod upgrades without recreating pods. This integration delivers a unique and optimized resource management experience that has not yet been incorporated into native Kubernetes workloads, offering users a distinct advantage in leveraging this innovative feature.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;1.1 Core Highlights&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;●&amp;nbsp;&lt;strong&gt;Easier and More Stable Implementation of Specification Changes&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Historically, both manual user-initiated and VPA-recommended resource adjustments triggered instance recreation, potentially introducing operational disruptions or system instability. This approach poses critical risks in high-load scenarios — upgrading database resources during peak demand becomes a high-stakes endeavor with potential cascading effects. Furthermore, the current VPA implementation relies on webhook modifications for newly scaled instances, creating specification drift between runtime configurations and pod templates. This architectural limitation impedes visibility and often prevents intended resource optimizations from materializing effectively.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;●&amp;nbsp;&lt;strong&gt;Future Integration with VPA for More Stable Vertical Scaling&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;By leveraging workload controllers’ inherent capability to orchestrate pod lifecycle operations, we can implement coordinated change management with built-in availability safeguards. Our strategic roadmap includes enabling VPA to initiate resource adjustments through standardized workload interfaces, ensuring consistent configuration updates across both existing and newly provisioned instances. This controller-centric approach eliminates direct pod manipulation, mitigating availability degradation risks caused by conflicting modifications from concurrent controllers while maintaining strict service level objectives.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;1.2 Enabling the Feature&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;1. Ensure Kubernetes Cluster Support&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Verify that your Kubernetes cluster has the&amp;nbsp;&lt;strong&gt;InPlacePodVerticalScaling&lt;/strong&gt;&amp;nbsp;feature enabled.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;2. Enable During Kruise Installation/Upgrade&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;When installing or upgrading Kruise, enable&amp;nbsp;&lt;strong&gt;InPlaceWorkloadVerticalScaling.&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;3. Configure Update Strategy&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Set the update strategy to either&amp;nbsp;&lt;strong&gt;InPlaceIfPossible&lt;/strong&gt;&amp;nbsp;or&amp;nbsp;&lt;strong&gt;InPlaceOnly&lt;/strong&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;1.3 Current Capabilities and Limitations&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;●&amp;nbsp;&lt;strong&gt;Supported Resource Types&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Only CPU and memory resources can be adjusted.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;●&amp;nbsp;&lt;strong&gt;Environment Constraints&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Certain limitations exist when operating in a&amp;nbsp;&lt;strong&gt;Cgroupv1&lt;/strong&gt;&amp;nbsp;environment.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;●&amp;nbsp;&lt;strong&gt;Adjustment Restrictions&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If resource adjustments result in changes to a Pod’s Quality of Service (QoS), Kruise-manager will automatically revert to recreating the Pod.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;1.4 Example Configuration&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;apiVersion: apps.kruise.io/v1alpha1&#xA;kind: CloneSet&#xA;spec:&#xA;  template:&#xA;    spec:&#xA;      containers:&#xA;        - name: example-container&#xA;          resources:&#xA;            requests:&#xA;              memory: &#34;512Mi&#34;&#xA;              cpu: &#34;500m&#34; # Adjusted from 1 -&amp;gt; 500m / 2&#xA;  updateStrategy:&#xA;    type: InPlaceIfPossible&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;Key Considerations:&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;● The&amp;nbsp;&lt;strong&gt;InPlacePodVerticalScaling&lt;/strong&gt;&amp;nbsp;feature in Kubernetes is still evolving. Carefully assess its suitability before deploying it in production environments.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;● Keep up-to-date with the latest developments.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;2. Redefining Storage Management for Stateful Workloads&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Authors:&amp;nbsp;&lt;a href=&#34;https://github.com/ABNER-1&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;@ABNER-1&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Throughout the evolution of Kubernetes, the Volume Expansion feature[6] was introduced in version 1.8 and became a General Availability (GA) feature in version 1.24. However, Persistent Volume Claims (PVCs) managed by the built-in StatefulSet have not fully leveraged this feature. Users have had to manually batch update PVCs for capacity maintenance, while newly added PVCs retain the original configuration, making the storage management for stateful workloads complex and inefficient.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Starting from its early versions, Kruise allowed users to manage the capacity of new PVCs by directly modifying the volume template of StatefulSet. In the latest Kruise 1.8, we have introducing&amp;nbsp;&lt;code&gt;in-place volume expansion support&lt;/code&gt;&amp;nbsp;for StatefulSet, aiming to revolutionize the storage management of stateful applications.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;2.1 Core Highlights: Seamless Expansion, Simplified Operations&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;1. In-place Expansion:&lt;/strong&gt;&amp;nbsp;No Pod Restart or Data Migration Required&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For stateful applications, storage capacity expansion often entails high maintenance costs and potential application downtime risks. Kruise 1.8’s in-place expansion feature allows users to directly increase the PVC capacity managed by Advanced StatefulSet without restarting pods or migrating data. This not only significantly reduces application downtime but also greatly simplifies the storage management process.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;2. Gradual Changes:&lt;/strong&gt;&amp;nbsp;Combined with Rolling Update Strategy&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kruise 1.8 also introduces a gradual change mechanism combined with the pod rolling sequence. Through this method, users can gradually and safely apply storage capacity expansion to existing PVCs, ensuring a smooth and reliable change process that minimizes the impact on business operations.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;3. Automated Management:&lt;/strong&gt;&amp;nbsp;No Manual Operations&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In the past, users needed to manually batch update PVC configurations, which was cumbersome and prone to errors. Now, with Kruise’s automated management capabilities, you can easily achieve unified management for both new and existing PVCs, significantly enhancing operational efficiency.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;2.2 Feature Limitations&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;The Kubernetes cluster in use must enable Volume Expansion or be above version 1.24.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;The storage class of the PVC to be expanded must be managed by CSI and support volume expansion. You can check the allowVolumeExpansion field of the storage class object to determine this.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;To use this feature, you need to enable the StatefulSetAutoResizePVCGate Feature Gate when installing or upgrading Kruise.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;2.3 Usage Example&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Control the volume update strategy through the volumeClaimUpdateStrategy field, including two modes: OnPodRollingUpdate and OnDelete.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The OnPodRollingUpdate mode allows automatic adjustment of PVC size during pod rolling updates, whereas the OnDelete mode requires manual deletion of old PVC before using the new volume template to recreate the PVC. This feature greatly enhances the flexibility and efficiency of managing stateful application storage, allowing easier adjustments when storage requirements change. Example configuration is as follows:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;apiVersion: apps.kruise.io/v1beta1&#xA;kind: StatefulSet&#xA;spec:&#xA;  # ...&#xA;  volumeClaimUpdateStrategy:&#xA;    # Options are OnPodRollingUpdate and OnDelete&#xA;    #   OnPodRollingUpdate: controller will automatically expand PVC during pod upgrade&#xA;    #   OnDelete: controller will only use the new volume claim template to reconstruct PVC after PVC deletion&#xA;    #             i.e., the default PVC update strategy before Kruise version 1.7.&#xA;    type: OnPodRollingUpdate &#xA;  volumeClaimTemplates:&#xA;    # ...&#xA;    spec:&#xA;      resources:&#xA;        requests:&#xA;          storage: 2Gi # 1Gi -&amp;gt; 2Gi&#xA;      storageClassName: allow-volume-expansion&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;After modifying the advanced statefulset spec, you can observe the changes in the status to monitor the PVC change situation:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;status:&#xA;  #...&#xA;  volumeClaimTemplates:&#xA;    - compatibleReadyReplicas: 0 # Number of PVCs with completed changes&#xA;      compatibleReplicas: 1 # Number of PVCs with updated spec sizes&#xA;      volumeClaimName: data0&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;3. Empowering AI Workloads with WorkloadSpread’s Capabilities&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Authors:&amp;nbsp;&lt;a href=&#34;https://github.com/AiRanthem&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;@AiRanthem&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In the Kubernetes ecosystem, multi-region management and flexible scheduling have always been core needs for complex workloads. Since the introduction of WorkloadSpread in Kruise 0.10.0, this feature has provided users with a non-intrusive way to enable detailed management of workloads across regions and nodes. Whether it’s spreading workloads horizontally by host or availability zone, or partition management by proportion and priority, WorkloadSpread demonstrates its powerful flexibility and adaptability.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;However, in practical applications, we found that not all workloads could fully meet the assumptions of WorkloadSpread. For example, AI workloads (such as TFJob in KubeFlow), due to their multi-role design, do not implement the Kubernetes Scale subinterface, making them unable to directly utilize the capabilities provided by WorkloadSpread. These workloads often need to span dedicated hardware or different availability zones to achieve better performance and flexibility, making the demand for multi-region management particularly urgent.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In Kruise 1.8, we have made significant upgrades targeting this pain point—supporting workloads that have not implemented the Scale subinterface. With the newly added&amp;nbsp;&lt;code&gt;targetFilter&lt;/code&gt;&amp;nbsp;configuration, users can now easily apply WorkloadSpread’s capabilities to complex AI workloads like TFJob, enabling more efficient resource allocation and management.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Below is a sample configuration for WorkloadSpread’s&amp;nbsp;&lt;code&gt;targetFilter&lt;/code&gt;. For more detailed documentation, please refer to the WorkloadSpread documentation.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;apiVersion: apps.kruise.io/v1alpha1&#xA;kind: WorkloadSpread&#xA;spec:&#xA;  # ...&#xA;  targetRef:&#xA;    apiVersion: kubeflow.org/v1alpha1&#xA;    kind: TFJob&#xA;    name: tfjob-demo&#xA;  # Use targetFilter to provide support for workloads without the Scale subinterface&#xA;  targetFilter: &#xA;    selector:&#xA;      # Use selector to filter instances managed by targetRef&#xA;      matchLabels:&#xA;        role: worker&#xA;    replicasPathList:&#xA;      # Use replicasPathList to specify the total number of replicas needed by targetRef&#xA;    - spec.tfReplicaSpecs.Worker.replicas&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;4. Custom Probing: Injecting New Vitality into Serverless Scenarios&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Authors:&amp;nbsp;&lt;a href=&#34;https://github.com/zmberg&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;@zmberg&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Since the introduction of the PodProbeMarker custom probing feature in Kruise 1.3, it has rapidly become a trusted tool among developers due to its flexible extension capabilities and wide range of applications. Specifically, in game solutions&amp;nbsp;&lt;code&gt;OpenKruise Game&lt;/code&gt;&amp;nbsp;(OKG), the service quality probing capabilities based on PodProbeMarker have helped numerous game developers achieve efficient and stable service management, making it the preferred tool in the industry.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;However, in&amp;nbsp;&lt;strong&gt;serverless scenarios&lt;/strong&gt;, PodProbeMarker’s custom probing capabilities once faced challenges. Before Kruise version 1.8, the implementation of PodProbeMarker relied on the node component&amp;nbsp;&lt;strong&gt;Kruise-Daemon,&lt;/strong&gt;&amp;nbsp;which could not be deployed in a serverless environment, thereby limiting its probing abilities.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Now, with the release of Kruise 1.8, this issue has finally been resolved! The Kruise team has optimized for serverless scenarios, extending the PodProbeMarker protocol to serverless pods, providing new possibilities for custom probing. You can now fully utilize resources in serverless scenarios while enjoying high-quality custom service probing capabilities, safeguarding your service operations.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The extension of the PodProbeMarker protocol in serverless scenarios is as follows:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;The Kruise-manager adds the required probe via the annotation&amp;nbsp;&lt;code&gt;kruise.io/podprobe&lt;/code&gt;&amp;nbsp;on serverless pods.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;The serverless PodProbeMarker implementation reads the probe information from the annotation&amp;nbsp;&lt;code&gt;kruise.io/podprobe&lt;/code&gt;, executes the probe, and writes the results to&amp;nbsp;&lt;code&gt;.status.conditions[x]&lt;/code&gt;&amp;nbsp;of the pod.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;The Kruise-manager recognizes the probe execution results from&amp;nbsp;&lt;code&gt;.status.conditions[x]&lt;/code&gt;&amp;nbsp;in serverless pods and performs the marking actions defined in&amp;nbsp;&lt;code&gt;markerPolicy&lt;/code&gt;.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For more detailed protocols and a list of supported container service providers, please refer to the PodProbeMarker documentation.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;5. SidecarSet Gradual Injection: More Granular Version Control&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Authors:&amp;nbsp;&lt;a href=&#34;https://github.com/AiRanthem&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;@AiRanthem&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In the cloud-native ecosystem of Kubernetes,&amp;nbsp;&lt;strong&gt;SidecarSet&lt;/strong&gt;&amp;nbsp;has become one of the most popular features of Kruise, serving as a powerful tool for simplifying the management and operations of sidecar containers. Whether it’s for log collection, monitoring agents, or service mesh components, SidecarSet’s elegant design helps users easily handle complex production environment requirements. However, in previous versions, support for gradual injection scenarios was somewhat lacking, causing some inconvenience for users requiring fine-grained version control.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Now, Kruise 1.8 introduces new enhancements by adding&amp;nbsp;&lt;strong&gt;gradual injection capabilities&lt;/strong&gt;, providing SidecarSet with unprecedented flexibility and control. Whether you wish to gradually verify the stability of a new version or need to implement complex release strategies, Kruise 1.8 offers robust support. Here is an example configuration:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;apiVersion: apps.kruise.io/v1alpha1&#xA;kind: SidecarSet&#xA;metadata:&#xA;  name: sidecarset&#xA;spec:&#xA;  # ...&#xA;  injectionStrategy:&#xA;    revision:&#xA;      # Specify the version to inject&#xA;      revisionName: revision-a&#xA;      # Options: Always and Partial&#xA;      #  Always: Always inject the specified version, in this case, revision-a&#xA;      #  Partial: Combine injection with the partition percentage to control the percentage of the specified version injected&#xA;      policy: Partial&#xA;  updateStrategy:&#xA;    partition: 70%&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This configuration allows you to control the injection of sidecar containers with precision, supporting advanced deployment strategies tailored to your specific needs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;6. Helm Pre-delete Hook: Kruise Accidental Deletion Protection&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Authors:&amp;nbsp;&lt;a href=&#34;https://github.com/AiRanthem&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;@AiRanthem&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In versions prior to Kruise 1.7.3, there was a significant risk involved in using Helm to uninstall Kruise, as this operation would remove Kruise itself, its custom resource definitions (CRDs), and the associated custom resources (CRs).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Starting from Kruise 1.7.3, a pre-delete hook has been introduced in the Helm uninstall process. This hook checks for the presence of custom resources managed by Kruise within the cluster uninstallation. If such resources are found, the uninstall process is stopped, preventing data loss and service interruptions due to accidental uninstallation. This improvement significantly enhances the security of managing Kruise with Helm.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Future Outlook&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For comprehensive upgrade and usage guidelines, please refer to the official&amp;nbsp;&lt;a href=&#34;https://openkruise.io/docs/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Kruise documentation&lt;/a&gt;&amp;nbsp;[4]. We believe that Kruise 1.8 will empower you to manage your cloud-native applications more effectively and elevate your application management experience.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Continuous Technological Evolution&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kruise is committed to providing users with exceptional cloud-native solutions. To achieve this vision, we have outlined three exciting upcoming releases:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;1. Release 1.9:&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Integrate LWS with Advanced StatefulSet for in-place upgrade capabilities&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Develop solutions for in-place upgrade restart limitations&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Implement gradual change strategies for ConfigmapSet&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;2. Release 2.0:&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Upgrade Kruise API to v1beta1&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;3. Release 2.1:&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Develop minimalist Kruise component deployment solutions&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Introduce new Liveness Probe features&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Get Involved&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Welcome to get involved with OpenKruise by joining us in Github/Slack/DingTalk/WeChat. Have something you’d like to broadcast to our community? Share your voice at our Bi-weekly community meeting (Chinese) [3], or through the channels below:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;● Join the community on Slack (English) [5].&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;● Join the community on DingTalk: Search GroupID&amp;nbsp;&lt;strong&gt;23330762&lt;/strong&gt;&amp;nbsp;(Chinese).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;● Join the community on WeChat (new): Search User&amp;nbsp;&lt;code&gt;openkruise&lt;/code&gt;&amp;nbsp;and let the robot invite you (Chinese).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;● [1]&amp;nbsp;&lt;a href=&#34;https://github.com/openkruise/kruise&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;OpenKruise github repo&lt;/a&gt;&lt;br&gt;● [2]&amp;nbsp;&lt;a href=&#34;https://github.com/openkruise/kruise/blob/master/CHANGELOG.md&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;ChangeLog&lt;/a&gt;&lt;br&gt;● [3]&amp;nbsp;&lt;a href=&#34;https://alidocs.dingtalk.com/i/nodes/14dA3GK8gjnMXbzEIoej1BL5J9ekBD76&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Bi-weekly community meeting (Chinese)&lt;/a&gt;&lt;br&gt;● [4]&amp;nbsp;&lt;a href=&#34;https://openkruise.io/docs/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Kruise docs&lt;/a&gt;&lt;br&gt;● [5]&amp;nbsp;&lt;a href=&#34;https://kubernetes.slack.com/channels/openkruise&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Slack channel&lt;/a&gt;&lt;br&gt;● [6]&amp;nbsp;&lt;a href=&#34;https://kubernetes.io/blog/2022/05/05/volume-expansion-ga/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;kubernetes volume-expansion ga&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;a href=&#34;https://github.com/openkruise/kruise&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;OpenKruise&lt;/a&gt;&amp;nbsp;is an open-source cloud-native application automation management suite. It is also a current incubating project hosted by the Cloud Native Computing Foundation (CNCF). It is a standard extension component based on Kubernetes that is widely used in production of internet scale company. It also closely follows upstream community standards and adapts to the technical improvement and best practices for internet-scale scenarios.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In February 2025, OpenKruise released its latest version 1.8[2]. This version brings many important updates and enhancements, aimed at further improving the efficiency, elasticity, and reliability of cloud-native application management. This article provides a comprehensive overview of the new version.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;1. Embrace In-Place VPA: Unlock New Potential in Resource Management&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Authors:&amp;nbsp;&lt;a href=&#34;https://github.com/LavenderQAQ&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;@LavenderQAQ,&lt;/a&gt;&amp;nbsp;&lt;a href=&#34;https://github.com/ABNER-1&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;@ABNER-1&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In Kubernetes 1.27, the significant enhancement of&amp;nbsp;&lt;code&gt;InPlacePodVerticalScaling&lt;/code&gt;&amp;nbsp;(In-Place VPA) was introduced to boost the flexibility and efficiency of resource management. This feature has recently advanced to Beta in Kubernetes 1.33, reflecting its improved stability and suitability for production environments.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kruise is dedicated to boosting users’ workload management capabilities. In Kruise 1.8, we first integrated InPlacePodVerticalScaling with our advanced workload types like CloneSet, Advanced StatefulSet, and Advanced DaemonSet. Users can directly modify the resource settings in the workload to perform in-place resizing of resources for all pods under the workload without restarts, or simultaneously resources resize and upgrade images during in-place pod upgrades without recreating pods. This integration delivers a unique and optimized resource management experience that has not yet been incorporated into native Kubernetes workloads, offering users a distinct advantage in leveraging this innovative feature.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;1.1 Core Highlights&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;●&amp;nbsp;&lt;strong&gt;Easier and More Stable Implementation of Specification Changes&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Historically, both manual user-initiated and VPA-recommended resource adjustments triggered instance recreation, potentially introducing operational disruptions or system instability. This approach poses critical risks in high-load scenarios — upgrading database resources during peak demand becomes a high-stakes endeavor with potential cascading effects. Furthermore, the current VPA implementation relies on webhook modifications for newly scaled instances, creating specification drift between runtime configurations and pod templates. This architectural limitation impedes visibility and often prevents intended resource optimizations from materializing effectively.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;●&amp;nbsp;&lt;strong&gt;Future Integration with VPA for More Stable Vertical Scaling&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;By leveraging workload controllers’ inherent capability to orchestrate pod lifecycle operations, we can implement coordinated change management with built-in availability safeguards. Our strategic roadmap includes enabling VPA to initiate resource adjustments through standardized workload interfaces, ensuring consistent configuration updates across both existing and newly provisioned instances. This controller-centric approach eliminates direct pod manipulation, mitigating availability degradation risks caused by conflicting modifications from concurrent controllers while maintaining strict service level objectives.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;1.2 Enabling the Feature&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;1. Ensure Kubernetes Cluster Support&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Verify that your Kubernetes cluster has the&amp;nbsp;&lt;strong&gt;InPlacePodVerticalScaling&lt;/strong&gt;&amp;nbsp;feature enabled.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;2. Enable During Kruise Installation/Upgrade&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;When installing or upgrading Kruise, enable&amp;nbsp;&lt;strong&gt;InPlaceWorkloadVerticalScaling.&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;3. Configure Update Strategy&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Set the update strategy to either&amp;nbsp;&lt;strong&gt;InPlaceIfPossible&lt;/strong&gt;&amp;nbsp;or&amp;nbsp;&lt;strong&gt;InPlaceOnly&lt;/strong&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;1.3 Current Capabilities and Limitations&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;●&amp;nbsp;&lt;strong&gt;Supported Resource Types&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Only CPU and memory resources can be adjusted.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;●&amp;nbsp;&lt;strong&gt;Environment Constraints&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Certain limitations exist when operating in a&amp;nbsp;&lt;strong&gt;Cgroupv1&lt;/strong&gt;&amp;nbsp;environment.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;●&amp;nbsp;&lt;strong&gt;Adjustment Restrictions&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If resource adjustments result in changes to a Pod’s Quality of Service (QoS), Kruise-manager will automatically revert to recreating the Pod.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;1.4 Example Configuration&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;apiVersion: apps.kruise.io/v1alpha1&#xA;kind: CloneSet&#xA;spec:&#xA;  template:&#xA;    spec:&#xA;      containers:&#xA;        - name: example-container&#xA;          resources:&#xA;            requests:&#xA;              memory: &#34;512Mi&#34;&#xA;              cpu: &#34;500m&#34; # Adjusted from 1 -&amp;gt; 500m / 2&#xA;  updateStrategy:&#xA;    type: InPlaceIfPossible&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;Key Considerations:&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;● The&amp;nbsp;&lt;strong&gt;InPlacePodVerticalScaling&lt;/strong&gt;&amp;nbsp;feature in Kubernetes is still evolving. Carefully assess its suitability before deploying it in production environments.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;● Keep up-to-date with the latest developments.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;2. Redefining Storage Management for Stateful Workloads&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Authors:&amp;nbsp;&lt;a href=&#34;https://github.com/ABNER-1&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;@ABNER-1&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Throughout the evolution of Kubernetes, the Volume Expansion feature[6] was introduced in version 1.8 and became a General Availability (GA) feature in version 1.24. However, Persistent Volume Claims (PVCs) managed by the built-in StatefulSet have not fully leveraged this feature. Users have had to manually batch update PVCs for capacity maintenance, while newly added PVCs retain the original configuration, making the storage management for stateful workloads complex and inefficient.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Starting from its early versions, Kruise allowed users to manage the capacity of new PVCs by directly modifying the volume template of StatefulSet. In the latest Kruise 1.8, we have introducing&amp;nbsp;&lt;code&gt;in-place volume expansion support&lt;/code&gt;&amp;nbsp;for StatefulSet, aiming to revolutionize the storage management of stateful applications.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;2.1 Core Highlights: Seamless Expansion, Simplified Operations&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;1. In-place Expansion:&lt;/strong&gt;&amp;nbsp;No Pod Restart or Data Migration Required&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For stateful applications, storage capacity expansion often entails high maintenance costs and potential application downtime risks. Kruise 1.8’s in-place expansion feature allows users to directly increase the PVC capacity managed by Advanced StatefulSet without restarting pods or migrating data. This not only significantly reduces application downtime but also greatly simplifies the storage management process.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;2. Gradual Changes:&lt;/strong&gt;&amp;nbsp;Combined with Rolling Update Strategy&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kruise 1.8 also introduces a gradual change mechanism combined with the pod rolling sequence. Through this method, users can gradually and safely apply storage capacity expansion to existing PVCs, ensuring a smooth and reliable change process that minimizes the impact on business operations.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;3. Automated Management:&lt;/strong&gt;&amp;nbsp;No Manual Operations&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In the past, users needed to manually batch update PVC configurations, which was cumbersome and prone to errors. Now, with Kruise’s automated management capabilities, you can easily achieve unified management for both new and existing PVCs, significantly enhancing operational efficiency.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;2.2 Feature Limitations&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;The Kubernetes cluster in use must enable Volume Expansion or be above version 1.24.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;The storage class of the PVC to be expanded must be managed by CSI and support volume expansion. You can check the allowVolumeExpansion field of the storage class object to determine this.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;To use this feature, you need to enable the StatefulSetAutoResizePVCGate Feature Gate when installing or upgrading Kruise.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;2.3 Usage Example&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Control the volume update strategy through the volumeClaimUpdateStrategy field, including two modes: OnPodRollingUpdate and OnDelete.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The OnPodRollingUpdate mode allows automatic adjustment of PVC size during pod rolling updates, whereas the OnDelete mode requires manual deletion of old PVC before using the new volume template to recreate the PVC. This feature greatly enhances the flexibility and efficiency of managing stateful application storage, allowing easier adjustments when storage requirements change. Example configuration is as follows:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;apiVersion: apps.kruise.io/v1beta1&#xA;kind: StatefulSet&#xA;spec:&#xA;  # ...&#xA;  volumeClaimUpdateStrategy:&#xA;    # Options are OnPodRollingUpdate and OnDelete&#xA;    #   OnPodRollingUpdate: controller will automatically expand PVC during pod upgrade&#xA;    #   OnDelete: controller will only use the new volume claim template to reconstruct PVC after PVC deletion&#xA;    #             i.e., the default PVC update strategy before Kruise version 1.7.&#xA;    type: OnPodRollingUpdate &#xA;  volumeClaimTemplates:&#xA;    # ...&#xA;    spec:&#xA;      resources:&#xA;        requests:&#xA;          storage: 2Gi # 1Gi -&amp;gt; 2Gi&#xA;      storageClassName: allow-volume-expansion&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;After modifying the advanced statefulset spec, you can observe the changes in the status to monitor the PVC change situation:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;status:&#xA;  #...&#xA;  volumeClaimTemplates:&#xA;    - compatibleReadyReplicas: 0 # Number of PVCs with completed changes&#xA;      compatibleReplicas: 1 # Number of PVCs with updated spec sizes&#xA;      volumeClaimName: data0&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;3. Empowering AI Workloads with WorkloadSpread’s Capabilities&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Authors:&amp;nbsp;&lt;a href=&#34;https://github.com/AiRanthem&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;@AiRanthem&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In the Kubernetes ecosystem, multi-region management and flexible scheduling have always been core needs for complex workloads. Since the introduction of WorkloadSpread in Kruise 0.10.0, this feature has provided users with a non-intrusive way to enable detailed management of workloads across regions and nodes. Whether it’s spreading workloads horizontally by host or availability zone, or partition management by proportion and priority, WorkloadSpread demonstrates its powerful flexibility and adaptability.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;However, in practical applications, we found that not all workloads could fully meet the assumptions of WorkloadSpread. For example, AI workloads (such as TFJob in KubeFlow), due to their multi-role design, do not implement the Kubernetes Scale subinterface, making them unable to directly utilize the capabilities provided by WorkloadSpread. These workloads often need to span dedicated hardware or different availability zones to achieve better performance and flexibility, making the demand for multi-region management particularly urgent.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In Kruise 1.8, we have made significant upgrades targeting this pain point—supporting workloads that have not implemented the Scale subinterface. With the newly added&amp;nbsp;&lt;code&gt;targetFilter&lt;/code&gt;&amp;nbsp;configuration, users can now easily apply WorkloadSpread’s capabilities to complex AI workloads like TFJob, enabling more efficient resource allocation and management.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Below is a sample configuration for WorkloadSpread’s&amp;nbsp;&lt;code&gt;targetFilter&lt;/code&gt;. For more detailed documentation, please refer to the WorkloadSpread documentation.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;apiVersion: apps.kruise.io/v1alpha1&#xA;kind: WorkloadSpread&#xA;spec:&#xA;  # ...&#xA;  targetRef:&#xA;    apiVersion: kubeflow.org/v1alpha1&#xA;    kind: TFJob&#xA;    name: tfjob-demo&#xA;  # Use targetFilter to provide support for workloads without the Scale subinterface&#xA;  targetFilter: &#xA;    selector:&#xA;      # Use selector to filter instances managed by targetRef&#xA;      matchLabels:&#xA;        role: worker&#xA;    replicasPathList:&#xA;      # Use replicasPathList to specify the total number of replicas needed by targetRef&#xA;    - spec.tfReplicaSpecs.Worker.replicas&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;4. Custom Probing: Injecting New Vitality into Serverless Scenarios&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Authors:&amp;nbsp;&lt;a href=&#34;https://github.com/zmberg&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;@zmberg&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Since the introduction of the PodProbeMarker custom probing feature in Kruise 1.3, it has rapidly become a trusted tool among developers due to its flexible extension capabilities and wide range of applications. Specifically, in game solutions&amp;nbsp;&lt;code&gt;OpenKruise Game&lt;/code&gt;&amp;nbsp;(OKG), the service quality probing capabilities based on PodProbeMarker have helped numerous game developers achieve efficient and stable service management, making it the preferred tool in the industry.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;However, in&amp;nbsp;&lt;strong&gt;serverless scenarios&lt;/strong&gt;, PodProbeMarker’s custom probing capabilities once faced challenges. Before Kruise version 1.8, the implementation of PodProbeMarker relied on the node component&amp;nbsp;&lt;strong&gt;Kruise-Daemon,&lt;/strong&gt;&amp;nbsp;which could not be deployed in a serverless environment, thereby limiting its probing abilities.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Now, with the release of Kruise 1.8, this issue has finally been resolved! The Kruise team has optimized for serverless scenarios, extending the PodProbeMarker protocol to serverless pods, providing new possibilities for custom probing. You can now fully utilize resources in serverless scenarios while enjoying high-quality custom service probing capabilities, safeguarding your service operations.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The extension of the PodProbeMarker protocol in serverless scenarios is as follows:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;The Kruise-manager adds the required probe via the annotation&amp;nbsp;&lt;code&gt;kruise.io/podprobe&lt;/code&gt;&amp;nbsp;on serverless pods.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;The serverless PodProbeMarker implementation reads the probe information from the annotation&amp;nbsp;&lt;code&gt;kruise.io/podprobe&lt;/code&gt;, executes the probe, and writes the results to&amp;nbsp;&lt;code&gt;.status.conditions[x]&lt;/code&gt;&amp;nbsp;of the pod.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;The Kruise-manager recognizes the probe execution results from&amp;nbsp;&lt;code&gt;.status.conditions[x]&lt;/code&gt;&amp;nbsp;in serverless pods and performs the marking actions defined in&amp;nbsp;&lt;code&gt;markerPolicy&lt;/code&gt;.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For more detailed protocols and a list of supported container service providers, please refer to the PodProbeMarker documentation.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;5. SidecarSet Gradual Injection: More Granular Version Control&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Authors:&amp;nbsp;&lt;a href=&#34;https://github.com/AiRanthem&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;@AiRanthem&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In the cloud-native ecosystem of Kubernetes,&amp;nbsp;&lt;strong&gt;SidecarSet&lt;/strong&gt;&amp;nbsp;has become one of the most popular features of Kruise, serving as a powerful tool for simplifying the management and operations of sidecar containers. Whether it’s for log collection, monitoring agents, or service mesh components, SidecarSet’s elegant design helps users easily handle complex production environment requirements. However, in previous versions, support for gradual injection scenarios was somewhat lacking, causing some inconvenience for users requiring fine-grained version control.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Now, Kruise 1.8 introduces new enhancements by adding&amp;nbsp;&lt;strong&gt;gradual injection capabilities&lt;/strong&gt;, providing SidecarSet with unprecedented flexibility and control. Whether you wish to gradually verify the stability of a new version or need to implement complex release strategies, Kruise 1.8 offers robust support. Here is an example configuration:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;apiVersion: apps.kruise.io/v1alpha1&#xA;kind: SidecarSet&#xA;metadata:&#xA;  name: sidecarset&#xA;spec:&#xA;  # ...&#xA;  injectionStrategy:&#xA;    revision:&#xA;      # Specify the version to inject&#xA;      revisionName: revision-a&#xA;      # Options: Always and Partial&#xA;      #  Always: Always inject the specified version, in this case, revision-a&#xA;      #  Partial: Combine injection with the partition percentage to control the percentage of the specified version injected&#xA;      policy: Partial&#xA;  updateStrategy:&#xA;    partition: 70%&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This configuration allows you to control the injection of sidecar containers with precision, supporting advanced deployment strategies tailored to your specific needs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;6. Helm Pre-delete Hook: Kruise Accidental Deletion Protection&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Authors:&amp;nbsp;&lt;a href=&#34;https://github.com/AiRanthem&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;@AiRanthem&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In versions prior to Kruise 1.7.3, there was a significant risk involved in using Helm to uninstall Kruise, as this operation would remove Kruise itself, its custom resource definitions (CRDs), and the associated custom resources (CRs).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Starting from Kruise 1.7.3, a pre-delete hook has been introduced in the Helm uninstall process. This hook checks for the presence of custom resources managed by Kruise within the cluster uninstallation. If such resources are found, the uninstall process is stopped, preventing data loss and service interruptions due to accidental uninstallation. This improvement significantly enhances the security of managing Kruise with Helm.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Future Outlook&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For comprehensive upgrade and usage guidelines, please refer to the official&amp;nbsp;&lt;a href=&#34;https://openkruise.io/docs/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Kruise documentation&lt;/a&gt;&amp;nbsp;[4]. We believe that Kruise 1.8 will empower you to manage your cloud-native applications more effectively and elevate your application management experience.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Continuous Technological Evolution&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kruise is committed to providing users with exceptional cloud-native solutions. To achieve this vision, we have outlined three exciting upcoming releases:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;1. Release 1.9:&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Integrate LWS with Advanced StatefulSet for in-place upgrade capabilities&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Develop solutions for in-place upgrade restart limitations&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Implement gradual change strategies for ConfigmapSet&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;2. Release 2.0:&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Upgrade Kruise API to v1beta1&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34;&gt;3. Release 2.1:&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Develop minimalist Kruise component deployment solutions&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Introduce new Liveness Probe features&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Get Involved&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Welcome to get involved with OpenKruise by joining us in Github/Slack/DingTalk/WeChat. Have something you’d like to broadcast to our community? Share your voice at our Bi-weekly community meeting (Chinese) [3], or through the channels below:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;● Join the community on Slack (English) [5].&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;● Join the community on DingTalk: Search GroupID&amp;nbsp;&lt;strong&gt;23330762&lt;/strong&gt;&amp;nbsp;(Chinese).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;● Join the community on WeChat (new): Search User&amp;nbsp;&lt;code&gt;openkruise&lt;/code&gt;&amp;nbsp;and let the robot invite you (Chinese).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;● [1]&amp;nbsp;&lt;a href=&#34;https://github.com/openkruise/kruise&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;OpenKruise github repo&lt;/a&gt;&lt;br&gt;● [2]&amp;nbsp;&lt;a href=&#34;https://github.com/openkruise/kruise/blob/master/CHANGELOG.md&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;ChangeLog&lt;/a&gt;&lt;br&gt;● [3]&amp;nbsp;&lt;a href=&#34;https://alidocs.dingtalk.com/i/nodes/14dA3GK8gjnMXbzEIoej1BL5J9ekBD76&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Bi-weekly community meeting (Chinese)&lt;/a&gt;&lt;br&gt;● [4]&amp;nbsp;&lt;a href=&#34;https://openkruise.io/docs/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Kruise docs&lt;/a&gt;&lt;br&gt;● [5]&amp;nbsp;&lt;a href=&#34;https://kubernetes.slack.com/channels/openkruise&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Slack channel&lt;/a&gt;&lt;br&gt;● [6]&amp;nbsp;&lt;a href=&#34;https://kubernetes.io/blog/2022/05/05/volume-expansion-ga/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;kubernetes volume-expansion ga&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Tue, 12 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Dragonfly v2.3.0 has been released】Dragonfly v2.3.0 has been released</title>
      <link>https://www.cncf.io/blog/2025/08/15/dragonfly-v2-3-0-has-been-released/</link>
      <description>【&lt;p&gt;Dragonfly v2.3.0 is released! 🎉🎉🎉 Thanks to the&amp;nbsp;&lt;a href=&#34;https://github.com/dragonflyoss/dragonfly/graphs/contributors&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;contributors&lt;/a&gt;&amp;nbsp;who made this release happen. We welcome you to visit&amp;nbsp;&lt;a href=&#34;https://d7y.io/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;d7y.io&lt;/a&gt;&amp;nbsp;website to learn more.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;features&#34;&gt;Features&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;persistent-cache-task&#34;&gt;Persistent Cache Task&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;It designs to provide persistent caching for tasks. This tool can import file and export file in P2P network. The solution is specifically engineered for high-speed read and write operations. This makes it particularly advantageous for scenarios involving large files, such as machine learning model checkpoints, where rapid, reliable access and distribution across the network are critical for training and inference workflows. By leveraging P2P distribution and persistent caching, dfcache significantly reduces I/O bottlenecks and accelerates the lifecycle of large data assets.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://d7y.io/assets/images/p1-1335923b71b6d0b8ab79985b83eed63f.webp&#34; alt=&#34;p1&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For documentation on how to use the dfcache command-line tool, please refer to the following link:&amp;nbsp;&lt;a href=&#34;https://d7y.io/docs/next/reference/commands/client/dfcache/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;dfcache&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;$ dfcache import /tmp/file.txt&lt;br&gt;⣷ Done: 2229733261&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;dfcache export 2229733261 -O /tmp/file.txt&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://d7y.io/assets/images/p2-3402280ce745b9211bef72483d4fc62b.webp&#34; alt=&#34;p2&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;resource-search-tasks-and-persistent-cache-tasks&#34;&gt;Resource Search (Tasks and Persistent Cache Tasks)&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The Resource Search feature enables seamless querying of tasks, including files, images, and persistent cache tasks. It optimizes resource access, improving task management and retrieval efficiency.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://d7y.io/assets/images/p3-77f7c55ff5b0787bf3eb301576c498b2.webp&#34; alt=&#34;p3&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;vortex-a-p2p-file-transfer-protocol-based-on-tlv&#34;&gt;Vortex: A P2P File Transfer Protocol Based on TLV&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Vortex protocol is a high-performance peer-to-peer (P2P) file transfer protocol implementation in Rust, designed as part of the Dragonfly project. It utilizes the TLV (Tag-Length-Value) format for efficient and flexible data transmission, making it ideal for large-scale file distribution scenarios.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Packet Format:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Packet Identifier (8 bits): Uniquely identifies each packet&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Tag (8 bits): Specifies data type in value field&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Length (32 bits): Indicates Value field length, up to 4 GiB&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Value (variable): Actual data content, maximum 1 GiB Protocol Format:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;-------------------------------------------------------------------------------------------------&lt;br&gt;|                            |                   |                    |                         |&lt;br&gt;| Packet Identifier (8 bits) |    Tag (8 bits)   |  Length (32 bits)  |   Value (up to 4 GiB)   |&lt;br&gt;|                            |                   |                    |                         |&lt;br&gt;-------------------------------------------------------------------------------------------------&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For more information, please refer to the&amp;nbsp;&lt;a href=&#34;https://github.com/dragonflyoss/vortex/blob/main/docs/README.md&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Vortex Protocol&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;enhanced-large-file-distribution&#34;&gt;Enhanced Large File Distribution&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This release significantly enhances Dragonfly’s large file distribution capabilities, delivering improved efficiency and performance. We’ve revamped our scheduling algorithms for large file scenarios to ensure smarter resource and task allocation. Additionally, new mechanisms now more effectively balance the load across peers during large file transfers. Optimizations to the peer-to-peer (P2P) protocol and network transport layers further boost transmission efficiency.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;These improvements include performance optimizations for both&amp;nbsp;&lt;a href=&#34;https://github.com/dragonflyoss/client&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Client&lt;/a&gt;&amp;nbsp;and&amp;nbsp;&lt;a href=&#34;https://github.com/dragonflyoss/dragonfly&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Scheduler&lt;/a&gt;. You can find more details in the project’s pull request.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;support-scopes-for-personal-access-tokens-pats&#34;&gt;Support scopes for Personal Access Tokens (PATs)&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;By enabling users to define specific access rights (scopes) for each PAT, we significantly enhance the security of Open API interactions. Instead of granting broad permissions, PATs can now be limited to only the necessary privileges required for a particular integration or task.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://d7y.io/assets/images/p4-50172b3cd7db0a786cfbf4506b4e7116.webp&#34; alt=&#34;p4&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;enhanced-preheating&#34;&gt;Enhanced Preheating&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34; id=&#34;implement-distributed-rate-limiting-for-preheating-tasks&#34;&gt;Implement Distributed Rate Limiting for Preheating Tasks&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;By limiting the rate at which preheating requests are initiated across the distributed system, it prevents excessive preheating activities from stressing the origin. This enhancement ensures a more stable preheating.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://d7y.io/assets/images/p5-12503b56433f8c57d422b5ca2db2e145.webp&#34; alt=&#34;p5&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34; id=&#34;support-to-set-piece-length-for-preheating&#34;&gt;Support to set piece length for preheating&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;By allowing adjustment of the piece size, users can optimize data transfer efficiency, particularly in scenarios involving large files.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://d7y.io/assets/images/p6-6397a374653fe6ea336bf72b5dbe53ed.webp&#34; alt=&#34;p6&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34; id=&#34;flexible-preheating-set-peer-scope-by-percentage-or-count&#34;&gt;Flexible Preheating: Set Peer scope by Percentage or Count&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This feature enhances preheating capabilities by allowing users to specify the preheating scope more precisely.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://d7y.io/assets/images/p7-4dc878da5c69ce9ff8dc35580d147b1d.webp&#34; alt=&#34;p7&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;implement-audit-logging-for-user-operations&#34;&gt;Implement Audit Logging for User Operations&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This feature introduces comprehensive audit logging capabilities to track user operations within the system. Audit logs will record critical actions performed by users, such as initiating preheating tasks, deleting task caches, and other significant system interactions.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://d7y.io/assets/images/p8-8a4d2b4938e85eb0a0370132120ada6c.webp&#34; alt=&#34;p8&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;garbage-collection&#34;&gt;Garbage Collection&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Dragonfly supports Garbage Collection (GC) Audit Logs and GC Job Records to track and manage garbage collection activities. The Manager enables automated GC retention, allowing records to be preserved for a configurable time period. Additionally, it provides the capability to manually trigger forced GC operations as needed.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This feature ensures efficient monitoring and management of GC processes, offering flexibility through automated retention policies and manual intervention for immediate GC execution.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://d7y.io/assets/images/p9-67adc683dc9a948cb38c167bb3df3f17.webp&#34; alt=&#34;p9&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;optimized-file-download-with-hard-link&#34;&gt;Optimized File Download with Hard Link&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;File download needs to be done in a way that is efficient and secure. If users are downloading a large file, it is not efficient to download the file and copy to the output path. Instead, we can create a hard link to the file and send the link to the user. This way, we can avoid copying the file and save time and resources. If hard link fails (e.g. due to different file systems), dfdaemon will fallback to copying the file.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For more information, please refer to the&amp;nbsp;&lt;a href=&#34;https://github.com/dragonflyoss/design/blob/main/systems-analysis/file-download-workflow-with-hard-link/README.md&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;file download workflow&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;hardware-acceleration-for-piece-hash-computation&#34;&gt;Hardware Acceleration for Piece Hash Computation&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This feature enables hardware-accelerated Piece hash computation, significantly boosting performance and efficiency. By utilizing specialized hardware, the hash computation process is accelerated, allowing faster processing of large file.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;advanced-storage-management&#34;&gt;Advanced Storage Management&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34; id=&#34;disk-space-validation-for-operations&#34;&gt;Disk Space Validation for Operations&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This feature enhances the client’s storage functionality by implementing disk space validation. When insufficient disk space is detected, the client will return a failure response, preventing potential data corruption or incomplete operations.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34; id=&#34;disk-garbage-collection-management&#34;&gt;Disk Garbage Collection Management&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This feature enhances Peer’s disk management by introducing configurable garbage collection (GC) thresholds based on disk usage. The distThreshold parameter allows users to define a specific disk capacity (e.g., 10TiB) as the base for calculating GC trigger points. If set, the distHighThresholdPercent (e.g., 80%) and distLowThresholdPercent (e.g., 60%) are applied relative to this capacity. If distThreshold is not provided or set to 0, these percentages are calculated based on the total actual disk space. When disk usage exceeds the high threshold, Dragonfly triggers GC(LRU) to reclaim space. GC stops when usage falls below the low threshold. This enables efficient management of a logical disk portion for caching, improving resource utilization and system performance.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://d7y.io/assets/images/p10-e2bde82dadf23237d62d46e83089bed3.webp&#34; alt=&#34;p10&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;support-for-opentelemetry-tracing&#34;&gt;Support for OpenTelemetry Tracing&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Dragonfly supports for tracing based on OpenTelemetry, covering the Manager, Scheduler, and Peers. This enables end-to-end visibility into the download process, allowing users to query detailed information, such as overall download latency, using a specific task ID. The integration ensures efficient monitoring and performance analysis across the entire system.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Add tracing configuration as follows (in Manager, Scheduler and Peer):&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://d7y.io/assets/images/p11-04e5650a0acfbc8de252d1a5ad21ff63.webp&#34; alt=&#34;p11&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;You can access the Jaeger UI to visualize the traces.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://d7y.io/assets/images/p12-0f1e72863018cdbe7b81c43fc57c4ab8.webp&#34; alt=&#34;p12&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For more information, please refer to the&amp;nbsp;&lt;a href=&#34;https://d7y.io/docs/next/operations/best-practices/observability/tracing/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Tracing&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;security-enhancements&#34;&gt;Security Enhancements&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We extend our sincere gratitude to the&amp;nbsp;&lt;a href=&#34;https://tag-security.cncf.io/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;CNCF TAG Security&lt;/a&gt;&amp;nbsp;for their collaboration on a joint security audit. Their expertise and thorough review were invaluable in helping us identify areas for security improvement within Dragonfly. For detailed information on the specific security issues addressed and the corresponding fixes, please refer to the following issue:&amp;nbsp;&lt;a href=&#34;https://github.com/dragonflyoss/dragonfly/issues/3811&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;#3811&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;nydus&#34;&gt;Nydus&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;significant-bug-fixes&#34;&gt;Significant bug fixes&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Fixed memory leaks and file descriptor leaks caused by&amp;nbsp;&lt;code&gt;sysinfo&lt;/code&gt;&amp;nbsp;library.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Cleans up the Unix domain socket (UDS) to prevent dfdaemon startup crashes.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Prevent client from repeatedly downloading the same piece from multiple parents.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;others&#34;&gt;Others&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;You can see&amp;nbsp;&lt;a href=&#34;https://github.com/dragonflyoss/dragonfly/blob/main/CHANGELOG.md&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;CHANGELOG&lt;/a&gt;&amp;nbsp;for more details.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;links&#34;&gt;Links&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Dragonfly Website:&amp;nbsp;&lt;a href=&#34;https://d7y.io/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;https://d7y.io/&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Dragonfly Repository:&amp;nbsp;&lt;a href=&#34;https://github.com/dragonflyoss/dragonfly&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;https://github.com/dragonflyoss/dragonfly&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Dragonfly Client Repository:&amp;nbsp;&lt;a href=&#34;https://github.com/dragonflyoss/client&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;https://github.com/dragonflyoss/client&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Dragonfly Console Repository:&amp;nbsp;&lt;a href=&#34;https://github.com/dragonflyoss/console&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;https://github.com/dragonflyoss/console&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Dragonfly Charts Repository:&amp;nbsp;&lt;a href=&#34;https://github.com/dragonflyoss/helm-charts&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;https://github.com/dragonflyoss/helm-charts&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Dragonfly Monitor Repository:&amp;nbsp;&lt;a href=&#34;https://github.com/dragonflyoss/monitoring&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;https://github.com/dragonflyoss/monitoring&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;Dragonfly v2.3.0 is released! 🎉🎉🎉 Thanks to the&amp;nbsp;&lt;a href=&#34;https://github.com/dragonflyoss/dragonfly/graphs/contributors&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;contributors&lt;/a&gt;&amp;nbsp;who made this release happen. We welcome you to visit&amp;nbsp;&lt;a href=&#34;https://d7y.io/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;d7y.io&lt;/a&gt;&amp;nbsp;website to learn more.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;features&#34;&gt;Features&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;persistent-cache-task&#34;&gt;Persistent Cache Task&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;It designs to provide persistent caching for tasks. This tool can import file and export file in P2P network. The solution is specifically engineered for high-speed read and write operations. This makes it particularly advantageous for scenarios involving large files, such as machine learning model checkpoints, where rapid, reliable access and distribution across the network are critical for training and inference workflows. By leveraging P2P distribution and persistent caching, dfcache significantly reduces I/O bottlenecks and accelerates the lifecycle of large data assets.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://d7y.io/assets/images/p1-1335923b71b6d0b8ab79985b83eed63f.webp&#34; alt=&#34;p1&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For documentation on how to use the dfcache command-line tool, please refer to the following link:&amp;nbsp;&lt;a href=&#34;https://d7y.io/docs/next/reference/commands/client/dfcache/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;dfcache&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;$ dfcache import /tmp/file.txt&lt;br&gt;⣷ Done: 2229733261&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;dfcache export 2229733261 -O /tmp/file.txt&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://d7y.io/assets/images/p2-3402280ce745b9211bef72483d4fc62b.webp&#34; alt=&#34;p2&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;resource-search-tasks-and-persistent-cache-tasks&#34;&gt;Resource Search (Tasks and Persistent Cache Tasks)&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The Resource Search feature enables seamless querying of tasks, including files, images, and persistent cache tasks. It optimizes resource access, improving task management and retrieval efficiency.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://d7y.io/assets/images/p3-77f7c55ff5b0787bf3eb301576c498b2.webp&#34; alt=&#34;p3&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;vortex-a-p2p-file-transfer-protocol-based-on-tlv&#34;&gt;Vortex: A P2P File Transfer Protocol Based on TLV&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Vortex protocol is a high-performance peer-to-peer (P2P) file transfer protocol implementation in Rust, designed as part of the Dragonfly project. It utilizes the TLV (Tag-Length-Value) format for efficient and flexible data transmission, making it ideal for large-scale file distribution scenarios.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Packet Format:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Packet Identifier (8 bits): Uniquely identifies each packet&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Tag (8 bits): Specifies data type in value field&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Length (32 bits): Indicates Value field length, up to 4 GiB&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Value (variable): Actual data content, maximum 1 GiB Protocol Format:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;-------------------------------------------------------------------------------------------------&lt;br&gt;|                            |                   |                    |                         |&lt;br&gt;| Packet Identifier (8 bits) |    Tag (8 bits)   |  Length (32 bits)  |   Value (up to 4 GiB)   |&lt;br&gt;|                            |                   |                    |                         |&lt;br&gt;-------------------------------------------------------------------------------------------------&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For more information, please refer to the&amp;nbsp;&lt;a href=&#34;https://github.com/dragonflyoss/vortex/blob/main/docs/README.md&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Vortex Protocol&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;enhanced-large-file-distribution&#34;&gt;Enhanced Large File Distribution&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This release significantly enhances Dragonfly’s large file distribution capabilities, delivering improved efficiency and performance. We’ve revamped our scheduling algorithms for large file scenarios to ensure smarter resource and task allocation. Additionally, new mechanisms now more effectively balance the load across peers during large file transfers. Optimizations to the peer-to-peer (P2P) protocol and network transport layers further boost transmission efficiency.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;These improvements include performance optimizations for both&amp;nbsp;&lt;a href=&#34;https://github.com/dragonflyoss/client&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Client&lt;/a&gt;&amp;nbsp;and&amp;nbsp;&lt;a href=&#34;https://github.com/dragonflyoss/dragonfly&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Scheduler&lt;/a&gt;. You can find more details in the project’s pull request.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;support-scopes-for-personal-access-tokens-pats&#34;&gt;Support scopes for Personal Access Tokens (PATs)&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;By enabling users to define specific access rights (scopes) for each PAT, we significantly enhance the security of Open API interactions. Instead of granting broad permissions, PATs can now be limited to only the necessary privileges required for a particular integration or task.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://d7y.io/assets/images/p4-50172b3cd7db0a786cfbf4506b4e7116.webp&#34; alt=&#34;p4&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;enhanced-preheating&#34;&gt;Enhanced Preheating&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34; id=&#34;implement-distributed-rate-limiting-for-preheating-tasks&#34;&gt;Implement Distributed Rate Limiting for Preheating Tasks&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;By limiting the rate at which preheating requests are initiated across the distributed system, it prevents excessive preheating activities from stressing the origin. This enhancement ensures a more stable preheating.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://d7y.io/assets/images/p5-12503b56433f8c57d422b5ca2db2e145.webp&#34; alt=&#34;p5&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34; id=&#34;support-to-set-piece-length-for-preheating&#34;&gt;Support to set piece length for preheating&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;By allowing adjustment of the piece size, users can optimize data transfer efficiency, particularly in scenarios involving large files.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://d7y.io/assets/images/p6-6397a374653fe6ea336bf72b5dbe53ed.webp&#34; alt=&#34;p6&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34; id=&#34;flexible-preheating-set-peer-scope-by-percentage-or-count&#34;&gt;Flexible Preheating: Set Peer scope by Percentage or Count&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This feature enhances preheating capabilities by allowing users to specify the preheating scope more precisely.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://d7y.io/assets/images/p7-4dc878da5c69ce9ff8dc35580d147b1d.webp&#34; alt=&#34;p7&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;implement-audit-logging-for-user-operations&#34;&gt;Implement Audit Logging for User Operations&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This feature introduces comprehensive audit logging capabilities to track user operations within the system. Audit logs will record critical actions performed by users, such as initiating preheating tasks, deleting task caches, and other significant system interactions.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://d7y.io/assets/images/p8-8a4d2b4938e85eb0a0370132120ada6c.webp&#34; alt=&#34;p8&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;garbage-collection&#34;&gt;Garbage Collection&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Dragonfly supports Garbage Collection (GC) Audit Logs and GC Job Records to track and manage garbage collection activities. The Manager enables automated GC retention, allowing records to be preserved for a configurable time period. Additionally, it provides the capability to manually trigger forced GC operations as needed.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This feature ensures efficient monitoring and management of GC processes, offering flexibility through automated retention policies and manual intervention for immediate GC execution.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://d7y.io/assets/images/p9-67adc683dc9a948cb38c167bb3df3f17.webp&#34; alt=&#34;p9&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;optimized-file-download-with-hard-link&#34;&gt;Optimized File Download with Hard Link&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;File download needs to be done in a way that is efficient and secure. If users are downloading a large file, it is not efficient to download the file and copy to the output path. Instead, we can create a hard link to the file and send the link to the user. This way, we can avoid copying the file and save time and resources. If hard link fails (e.g. due to different file systems), dfdaemon will fallback to copying the file.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For more information, please refer to the&amp;nbsp;&lt;a href=&#34;https://github.com/dragonflyoss/design/blob/main/systems-analysis/file-download-workflow-with-hard-link/README.md&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;file download workflow&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;hardware-acceleration-for-piece-hash-computation&#34;&gt;Hardware Acceleration for Piece Hash Computation&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This feature enables hardware-accelerated Piece hash computation, significantly boosting performance and efficiency. By utilizing specialized hardware, the hash computation process is accelerated, allowing faster processing of large file.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;advanced-storage-management&#34;&gt;Advanced Storage Management&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34; id=&#34;disk-space-validation-for-operations&#34;&gt;Disk Space Validation for Operations&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This feature enhances the client’s storage functionality by implementing disk space validation. When insufficient disk space is detected, the client will return a failure response, preventing potential data corruption or incomplete operations.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 class=&#34;wp-block-heading&#34; id=&#34;disk-garbage-collection-management&#34;&gt;Disk Garbage Collection Management&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This feature enhances Peer’s disk management by introducing configurable garbage collection (GC) thresholds based on disk usage. The distThreshold parameter allows users to define a specific disk capacity (e.g., 10TiB) as the base for calculating GC trigger points. If set, the distHighThresholdPercent (e.g., 80%) and distLowThresholdPercent (e.g., 60%) are applied relative to this capacity. If distThreshold is not provided or set to 0, these percentages are calculated based on the total actual disk space. When disk usage exceeds the high threshold, Dragonfly triggers GC(LRU) to reclaim space. GC stops when usage falls below the low threshold. This enables efficient management of a logical disk portion for caching, improving resource utilization and system performance.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://d7y.io/assets/images/p10-e2bde82dadf23237d62d46e83089bed3.webp&#34; alt=&#34;p10&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;support-for-opentelemetry-tracing&#34;&gt;Support for OpenTelemetry Tracing&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Dragonfly supports for tracing based on OpenTelemetry, covering the Manager, Scheduler, and Peers. This enables end-to-end visibility into the download process, allowing users to query detailed information, such as overall download latency, using a specific task ID. The integration ensures efficient monitoring and performance analysis across the entire system.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Add tracing configuration as follows (in Manager, Scheduler and Peer):&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://d7y.io/assets/images/p11-04e5650a0acfbc8de252d1a5ad21ff63.webp&#34; alt=&#34;p11&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;You can access the Jaeger UI to visualize the traces.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://d7y.io/assets/images/p12-0f1e72863018cdbe7b81c43fc57c4ab8.webp&#34; alt=&#34;p12&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For more information, please refer to the&amp;nbsp;&lt;a href=&#34;https://d7y.io/docs/next/operations/best-practices/observability/tracing/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Tracing&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;security-enhancements&#34;&gt;Security Enhancements&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We extend our sincere gratitude to the&amp;nbsp;&lt;a href=&#34;https://tag-security.cncf.io/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;CNCF TAG Security&lt;/a&gt;&amp;nbsp;for their collaboration on a joint security audit. Their expertise and thorough review were invaluable in helping us identify areas for security improvement within Dragonfly. For detailed information on the specific security issues addressed and the corresponding fixes, please refer to the following issue:&amp;nbsp;&lt;a href=&#34;https://github.com/dragonflyoss/dragonfly/issues/3811&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;#3811&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;nydus&#34;&gt;Nydus&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;significant-bug-fixes&#34;&gt;Significant bug fixes&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Fixed memory leaks and file descriptor leaks caused by&amp;nbsp;&lt;code&gt;sysinfo&lt;/code&gt;&amp;nbsp;library.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Cleans up the Unix domain socket (UDS) to prevent dfdaemon startup crashes.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Prevent client from repeatedly downloading the same piece from multiple parents.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;others&#34;&gt;Others&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;You can see&amp;nbsp;&lt;a href=&#34;https://github.com/dragonflyoss/dragonfly/blob/main/CHANGELOG.md&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;CHANGELOG&lt;/a&gt;&amp;nbsp;for more details.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;links&#34;&gt;Links&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Dragonfly Website:&amp;nbsp;&lt;a href=&#34;https://d7y.io/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;https://d7y.io/&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Dragonfly Repository:&amp;nbsp;&lt;a href=&#34;https://github.com/dragonflyoss/dragonfly&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;https://github.com/dragonflyoss/dragonfly&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Dragonfly Client Repository:&amp;nbsp;&lt;a href=&#34;https://github.com/dragonflyoss/client&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;https://github.com/dragonflyoss/client&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Dragonfly Console Repository:&amp;nbsp;&lt;a href=&#34;https://github.com/dragonflyoss/console&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;https://github.com/dragonflyoss/console&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Dragonfly Charts Repository:&amp;nbsp;&lt;a href=&#34;https://github.com/dragonflyoss/helm-charts&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;https://github.com/dragonflyoss/helm-charts&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Dragonfly Monitor Repository:&amp;nbsp;&lt;a href=&#34;https://github.com/dragonflyoss/monitoring&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;https://github.com/dragonflyoss/monitoring&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Thu, 14 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Cloud Native in the City of Kings】Cloud Native in the City of Kings</title>
      <link>https://www.cncf.io/blog/2025/08/14/cloud-native-in-the-city-of-kings/</link>
      <description>【&lt;p&gt;Lima, Peru — the “Ciudad de los Reyes” — hosted one of the most energized and well-attended Kubernetes Community Days (KCD) in the region this past weekend. From the start, it was clear that this was a gathering shaped by international collaboration and a shared passion for cloud native technologies across Latin America.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Speakers and attendees came from Brazil, Argentina, Chile, Colombia, Guatemala, Venezuela, the United States, and Peru. The diverse representation showed how deeply connected the region is around open source, with community members from different countries actively contributing to shared growth.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The event was at capacity, and every session was packed. What stood out to me was how the attendees approached it with the same enthusiasm and energy as a KubeCon + CloudNativeCon—only this time, it was happening right in Lima. The atmosphere was electric from the moment I walked into the venue. We estimated, over 600 people joined us throughout the day. Even after we ran out of swag and lanyards halfway through the event, the energy never dropped. In fact, by the time Pavel Puclla hosted the closing raffle with incredible enthusiasm, the room felt even more packed than it did in the morning.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;On Friday night, we gathered for the speaker reception. We shared a meal of delicious local food and attended a cultural performance that depicted the stories, struggles, and triumphs of the Peruvian people. It was a powerful way to connect with the local community and culture. That evening, we discussed how our cloud native communities operate in our respective countries, the challenges we face, and the strategies we’re exploring to grow participation and adoption. We also shared success stories on how we’ve used cloud native tools to drive meaningful outcomes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Getting to meet with representatives from PUCP, the event host, was another highlight. They expressed interest in expanding their work with cloud native technologies, and I was able to share some insight into the broader community and Peru’s leadership in the region. Peru has made impressive strides in cultivating new contributors—particularly within the growing group of Kubestronauts—and has become a central hub for Latin America’s momentum.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As the son of Honduran immigrants, this event held deep personal meaning for me. I have always hoped to see more cloud native leaders emerge from Latin America and take their place in the global open source ecosystem. KCD Lima was a clear step toward that goal. The event didn’t just highlight regional talent—it elevated it. It gave us a space to collaborate, learn, and lead together.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;I also had the privilege of moderating a panel on cloud native in the enterprise. The conversation focused on real-world challenges, success stories, and best practices. Panelists represented a wide range of industries including banking, consulting, mining, education, training, and government. While the list of sectors involved is far from exhaustive, it reflects how deeply cloud native practices are taking root across Latin America.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The level of coordination across countries and the collective investment in KCD Lima made it clear that this is a regional movement. The event highlighted the scale, talent, and dedication of the Latin American cloud native ecosystem.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Acknowledgments&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;A heartfelt thank you to the organizers:&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Carol Valencia (CNCF Ambassador)&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Pavel Puclla (CEO at Se.Colectiva)&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Jean Paul Lopez (Senior Consultant at Red Hat)&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Juan Manuel Chavez (Product Owner at BCP)&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Ronald Requena (Senior Engineer at Mibanco)&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Thank you to PUCP for hosting us and supporting community growth in Peru.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;And a sincere thank you to all the speakers who made this event possible:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Speakers&lt;/strong&gt;:&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Almendra Paz Rodriguez, Bianca Torres, Bruno Lopes, Caio Medeiros Pinto, Cami Martins, Carlos Martin Candela Espichan, Carolina Herrera Monteza, Daniel Román, Dante Medico Mejia, David Dali Susanibar Arce, Diana Alfaro, Eddú Meléndez Gonzales, Edmar Campos Cardoso, Edson Ferreira, Eduardo Munari, Eduardo Spotti, Emma Flores, Enzo Venturi, Ernesto Cardenas, Francisco Meneses, Gabriel Gómez de la Torre Parodi, Geoffroy Meder, Gina Alegre Milla, Glisse Lisbeth Jorge Malca, Gustavo Carvalho, Hugo Guerrero, Igor Eulálio, Ivan Contreras, Jack Torpoco, Jake Pineda, Jean Paul López, Jhon Inga, Jorge Luis Eduardo Avila Celada, Josef Calderon, Josua Castro, Juan Carlos Salvador, Juan Manuel Chávez, Jürgen Anders Guerra Ramos, Ken Esparta, Luis Falero Otiniano, Luis Rojas, Max Zeballos Torres, Nefi Arroyo, Nelson Luis Contreras Centeno, Paul Escarcena, Peter Lescano, Rafael Brito, Roberto Magallanes Martinez, Rodolfo Barzola Valdez, Rodrigo Alvarez, Sebastián Burgos, Sergio Méndez, Stanislav Yanallalli Emeliev, Stevenson Ramirez, Valeria Alexandra Villacorta Landeo, Willian Marchan Aranda, Yahaira Lisseth Perez Becerra.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Thank you for sharing your expertise and helping grow this community.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Cloud native in Latin America has a bright future, and events like KCD Lima continue to carry that momentum forward. If you are considering being part of the Latin American cloud native community, come for the food, but stay for the expertise. You’ll be glad you did!&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;Lima, Peru — the “Ciudad de los Reyes” — hosted one of the most energized and well-attended Kubernetes Community Days (KCD) in the region this past weekend. From the start, it was clear that this was a gathering shaped by international collaboration and a shared passion for cloud native technologies across Latin America.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Speakers and attendees came from Brazil, Argentina, Chile, Colombia, Guatemala, Venezuela, the United States, and Peru. The diverse representation showed how deeply connected the region is around open source, with community members from different countries actively contributing to shared growth.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The event was at capacity, and every session was packed. What stood out to me was how the attendees approached it with the same enthusiasm and energy as a KubeCon + CloudNativeCon—only this time, it was happening right in Lima. The atmosphere was electric from the moment I walked into the venue. We estimated, over 600 people joined us throughout the day. Even after we ran out of swag and lanyards halfway through the event, the energy never dropped. In fact, by the time Pavel Puclla hosted the closing raffle with incredible enthusiasm, the room felt even more packed than it did in the morning.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;On Friday night, we gathered for the speaker reception. We shared a meal of delicious local food and attended a cultural performance that depicted the stories, struggles, and triumphs of the Peruvian people. It was a powerful way to connect with the local community and culture. That evening, we discussed how our cloud native communities operate in our respective countries, the challenges we face, and the strategies we’re exploring to grow participation and adoption. We also shared success stories on how we’ve used cloud native tools to drive meaningful outcomes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Getting to meet with representatives from PUCP, the event host, was another highlight. They expressed interest in expanding their work with cloud native technologies, and I was able to share some insight into the broader community and Peru’s leadership in the region. Peru has made impressive strides in cultivating new contributors—particularly within the growing group of Kubestronauts—and has become a central hub for Latin America’s momentum.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As the son of Honduran immigrants, this event held deep personal meaning for me. I have always hoped to see more cloud native leaders emerge from Latin America and take their place in the global open source ecosystem. KCD Lima was a clear step toward that goal. The event didn’t just highlight regional talent—it elevated it. It gave us a space to collaborate, learn, and lead together.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;I also had the privilege of moderating a panel on cloud native in the enterprise. The conversation focused on real-world challenges, success stories, and best practices. Panelists represented a wide range of industries including banking, consulting, mining, education, training, and government. While the list of sectors involved is far from exhaustive, it reflects how deeply cloud native practices are taking root across Latin America.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The level of coordination across countries and the collective investment in KCD Lima made it clear that this is a regional movement. The event highlighted the scale, talent, and dedication of the Latin American cloud native ecosystem.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Acknowledgments&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;A heartfelt thank you to the organizers:&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Carol Valencia (CNCF Ambassador)&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Pavel Puclla (CEO at Se.Colectiva)&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Jean Paul Lopez (Senior Consultant at Red Hat)&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Juan Manuel Chavez (Product Owner at BCP)&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Ronald Requena (Senior Engineer at Mibanco)&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Thank you to PUCP for hosting us and supporting community growth in Peru.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;And a sincere thank you to all the speakers who made this event possible:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Speakers&lt;/strong&gt;:&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Almendra Paz Rodriguez, Bianca Torres, Bruno Lopes, Caio Medeiros Pinto, Cami Martins, Carlos Martin Candela Espichan, Carolina Herrera Monteza, Daniel Román, Dante Medico Mejia, David Dali Susanibar Arce, Diana Alfaro, Eddú Meléndez Gonzales, Edmar Campos Cardoso, Edson Ferreira, Eduardo Munari, Eduardo Spotti, Emma Flores, Enzo Venturi, Ernesto Cardenas, Francisco Meneses, Gabriel Gómez de la Torre Parodi, Geoffroy Meder, Gina Alegre Milla, Glisse Lisbeth Jorge Malca, Gustavo Carvalho, Hugo Guerrero, Igor Eulálio, Ivan Contreras, Jack Torpoco, Jake Pineda, Jean Paul López, Jhon Inga, Jorge Luis Eduardo Avila Celada, Josef Calderon, Josua Castro, Juan Carlos Salvador, Juan Manuel Chávez, Jürgen Anders Guerra Ramos, Ken Esparta, Luis Falero Otiniano, Luis Rojas, Max Zeballos Torres, Nefi Arroyo, Nelson Luis Contreras Centeno, Paul Escarcena, Peter Lescano, Rafael Brito, Roberto Magallanes Martinez, Rodolfo Barzola Valdez, Rodrigo Alvarez, Sebastián Burgos, Sergio Méndez, Stanislav Yanallalli Emeliev, Stevenson Ramirez, Valeria Alexandra Villacorta Landeo, Willian Marchan Aranda, Yahaira Lisseth Perez Becerra.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Thank you for sharing your expertise and helping grow this community.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Cloud native in Latin America has a bright future, and events like KCD Lima continue to carry that momentum forward. If you are considering being part of the Latin American cloud native community, come for the food, but stay for the expertise. You’ll be glad you did!&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Wed, 13 Aug 2025 16:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>