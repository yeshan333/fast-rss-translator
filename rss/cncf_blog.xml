<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>CNCF - Blog</title>
    <link>http://cloudys-rsshub-ab061133bcab.herokuapp.com/cncf</link>
    <description>CNCF - Blog - Powered by RSSHub</description>
    <managingEditor>contact@rsshub.app (RSSHub)</managingEditor>
    <item>
      <title>【Platform engineering maintenance pitfalls and smart strategies to stay ahead】平台工程维护陷阱和保持领先的明智策略</title>
      <link>https://www.cncf.io/blog/2026/01/21/platform-engineering-maintenance-pitfalls-and-smart-strategies-to-stay-ahead/</link>
      <description>【&lt;p&gt;Platform engineering is a discipline that aims to increase the productivity of software engineering teams by designing, building, and maintaining internal platforms that abstract underlying infrastructure complexity and provide self-service capabilities. Kubernetes-based platforms are often complex multi-Open Source Software (OSS) integrations; thus, platform engineering is not a “declare once and forget it” process. It requires continuous dependency maintenance and strategies for inevitable breaking changes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In this blog post, we’ll go over the integration of fourteen OSS projects to maintain the platform that is built on top of a Kubernetes cluster. We explore the following challenges:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Catching up with software upstream changes&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Controlling the supply chain&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Keeping up with Kubernetes upgrades&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Maintaining Helm chart upgrades&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Maintaining Applications with persistent data&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;The necessity of runtime validation&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Catching Up With Software Upstream Changes&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For this article, we have analyzed the last three years of releases for the following OSS projects: &lt;a href=&#34;https://github.com/argoproj/argo-cd&#34;&gt;argo-cd&lt;/a&gt;, &lt;a href=&#34;https://github.com/knative/serving&#34;&gt;knative-serving&lt;/a&gt;, &lt;a href=&#34;https://github.com/istio/istio&#34;&gt;istio&lt;/a&gt;, &lt;a href=&#34;https://github.com/goharbor/harbor&#34;&gt;harbor&lt;/a&gt;, &lt;a href=&#34;http://github.com/keycloak/keycloak&#34;&gt;keycloak&lt;/a&gt;, &lt;a href=&#34;https://github.com/cloudnative-pg/cloudnative-pg&#34;&gt;cloudnative-pg&lt;/a&gt;, &lt;a href=&#34;https://github.com/go-gitea/gitea&#34;&gt;gitea&lt;/a&gt;, &lt;a href=&#34;https://github.com/kubernetes/ingress-nginx&#34;&gt;ingress-nginx&lt;/a&gt;, &lt;a href=&#34;https://github.com/grafana/grafana&#34;&gt;grafana&lt;/a&gt;, &lt;a href=&#34;https://github.com/bitnami-labs/sealed-secrets&#34;&gt;sealed-secrets&lt;/a&gt;, &lt;a href=&#34;https://github.com/kyverno/kyverno&#34;&gt;kyverno&lt;/a&gt;, &lt;a href=&#34;https://github.com/prometheus/prometheus&#34;&gt;prometheus&lt;/a&gt;, &lt;a href=&#34;https://github.com/kubernetes-sigs/external-dns&#34;&gt;external-dns&lt;/a&gt;, and &lt;a href=&#34;https://github.com/cert-manager/cert-manager&#34;&gt;cert-manager&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Based on our experience and analysis, you can expect between &lt;strong&gt;2-5 major upgrades, 43-52 minor upgrades, and 276-327 software patches every year&lt;/strong&gt;. That’s nearly an update a day!&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1200&#34; height=&#34;742&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image1.png&#34; alt=&#34;Platform engineering build from OSS CNCF projects graph showing the aggregated number of changes per release type of major, minor, and patch.&#34; class=&#34;wp-image-155482&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image1.png 1200w, https://www.cncf.io/wp-content/uploads/2026/01/image1-300x186.png 300w, https://www.cncf.io/wp-content/uploads/2026/01/image1-1024x633.png 1024w, https://www.cncf.io/wp-content/uploads/2026/01/image1-768x475.png 768w, https://www.cncf.io/wp-content/uploads/2026/01/image1-900x557.png 900w, https://www.cncf.io/wp-content/uploads/2026/01/image1-323x200.png 323w, https://www.cncf.io/wp-content/uploads/2026/01/image1-647x400.png 647w&#34; sizes=&#34;auto, (max-width: 1200px) 100vw, 1200px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;A significant challenge arises from the responsibility of maintaining a robust security posture. Every day, a number of security vulnerabilities are discovered. They are addressed in upstream projects that your platform needs to apply as security patches. This significantly contributes to the number of patches from the diagram above. Such changes must be monitored and quickly adopted into your platform.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In line with this, a project or its chart maintainers may opt to stop maintaining previous versions and only provide an upgrade path towards the latest major release, which effectively marks an older major version as end-of-life. Even if you only intend to adopt a security upgrade, you are practically forced to follow the maintained version.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;A significant amount of maintenance effort can be automated, particularly when it comes to identifying new application versions. Helm chart releases are organized in repositories and registries, whereas binary software releases are found on GitHub using their API. This makes essential download and upgrading tasks a good candidate for being delegated to scripts that open a pull request accordingly. Automation addresses the short-term end-of-life problem.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Controlling the Supply Chain&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Recent years taught us that critical parts of the supply chain, such as container registries or Helm chart repositories, can be subject to rate limiting or disruptive changes like deprecation on short notice by either OSS communities or software vendors. Adopting those changes and ensuring platform instances are using the new platform version is often impossible in such a short time frame.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Maintaining a platform-dedicated container registry cache and a mono repository with Helm charts makes code-breaking changes transparent to users and buys platform engineers time to adapt. Similarly, this provides platform administrators the time to plan for an upgrade.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Keeping Up With Kubernetes Upgrades&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;While each Kubernetes minor version is maintained for 12 months, cloud platform providers often push for faster adoption, and expectations are set that users will keep up with the latest version. A new Kubernetes version may come with deprecated APIs that your Helm chart relies on, making upgrading your Helm chart an inevitability.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;A Kubernetes conformance smoke test enables you to discover potential breaking changes. Render all manifests that the platform would deploy and statically test the entire output against the Kubernetes OpenAPI schema, including all added custom resource definitions (CRDs).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Maintaining Helm Chart Upgrades&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;With a &lt;em&gt;platform as a product&lt;/em&gt; mindset, you own the full impact of what you deploy. Community Helm charts may reduce the number of manifests you need to define, but they do not remove the responsibility of understanding exactly what is being introduced into your Kubernetes cluster.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In practice, simply reviewing the Go template code is rarely sufficient to assess the effects of a new chart version on your platform, so other strategies need to be applied. Some of the Helm charts upgrades are delivered with modifications to immutable Kubernetes properties, such as Deployment’s label selector, complicating maintenance and upgrades further.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;By implementing a custom platform operator capable of managing changes to immutable Kubernetes properties, you can ensure a smooth upgrade. Detect potentially disruptive changes before they affect production environments by analyzing rendered Helm chart manifests: current version vs new version. The diff can also be performed against a running cluster, performing a dry run before applying changes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Maintaining Applications With Persistent Data&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Many Helm charts are delivered with dependencies that simplify deployment by bundling essential components such as SQL databases and key-value stores. These maintain the state on their dependent apps, and frequently require persistent volumes to do so.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For example, Helm dependencies declare manifests to deploy a PostgreSQL database service, but do not come with any operator that is aware of database lifecycle management (upgrades, migrations, replication). This “batteries-included” approach simplifies the initial deployment, but is a technical debt for platform operations.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To address these challenges, you must review the included dependency charts to check if they maintain application-critical data. Avoid using SQL databases provided as Helm chart dependencies. Instead, deploy database services via database operators, such as CloudnativePG, that are aware of both Kubernetes storage limitations (e.g., volume attachments) and database lifecycle requirements, such as migration workflows on major upgrades.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;The Necessity of Runtime Validation&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;A Helm chart upgrade that deploys without errors does not necessarily ensure the application still behaves as expected. This goes regardless of whether it relies on core manifests alone or additional custom resources. Code-breaking changes (whether in the chart or the application itself) often will not surface through simple manifest validation. Resources may appear healthy while silently diverging from their previous configuration, and even logs may fail to expose integration issues.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This makes robust quality assurance essential, particularly through automated integration tests where possible. Automated tests should operate on a running cluster to ensure that all services can contact their dependencies and that endpoints are exposed as expected.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Long-term cluster monitoring is essential as well. Issues like applications OOMKilled, CPU throttling, or running out of disk space often occur only after days or even weeks, depending on workload patterns. Detecting these problems early relies heavily on well-designed Prometheus rules. The Kube-Prometheus-Stack offers a solid foundation, but adding application-specific rules and alerting conditions can provide more insights.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Final Thoughts&amp;nbsp;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Once you commit to delivering a platform, you become responsible for the lifecycle of components. The open source community that develops essential applications usually responds quickly to compatibility and security issues; however, these changes still need to be integrated into your platform. You need to prepare for the operational cost, upgrading parts, and replacing components that are no longer maintained. The upside of coordinating this effort in your platform is that it provides relief to development teams from having to perform all the same work simultaneously. A high degree of automation and development of dedicated platform management components and tools ensures long-term maintainability.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Additionally, feedback and upstream contributions are an integral part of using open source software that ensures other users in similar scenarios can benefit from the experience and that upstream projects remain healthy.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;平台工程是一门学科，旨在通过设计、构建和维护内部平台来提高软件工程团队的生产力，这些平台抽象了底层基础设施的复杂性并提供自助服务功能。基于 Kubernetes 的平台通常是复杂的多开源软件 (OSS) 集成；因此，平台工程并不是一个“声明一次就可以忘记”的过程。它需要持续的依赖维护和针对不可避免的重大更改的策略。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在这篇博文中，我们将介绍 14 个 OSS 项目的集成，以维护构建在 Kubernetes 集群之上的平台。我们探讨以下挑战：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;跟上软件上游的变化&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;控制供应链&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;跟上 Kubernetes 升级&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;维护 Helm 图表升级&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;使用持久数据维护应用程序&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;运行时验证的必要性&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;赶上软件上游变化&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在本文中，我们分析了以下 OSS 项目过去三年的版本：&lt;a href=&#34;https://github.com/argoproj/argo-cd&#34;&gt;argo-cd&lt;/a&gt;、&lt;a href=&#34;https://github.com/knative/serving&#34;&gt;knative-serving&lt;/a&gt;、&lt;a href=&#34;https://github.com/istio/istio&#34;&gt;istio&lt;/a&gt;、&lt;a href=&#34;https://github.com/goharbor/harbor&#34;&gt;港口&lt;/a&gt;、&lt;a href=&#34;http://github.com/keycloak/keycloak&#34;&gt;keycloak&lt;/a&gt;、&lt;a href=&#34;https://github.com/cloudnative-pg/cloudnative-pg&#34;&gt;cloudnative-pg&lt;/a&gt;、&lt;a href=&#34;https://github.com/go-gitea/gitea&#34;&gt;gitea&lt;/a&gt;、&lt;a href=&#34;https://github.com/kubernetes/ingress-nginx&#34;&gt;ingress-nginx&lt;/a&gt;、&lt;a href=&#34;https://github.com/grafana/grafana&#34;&gt;grafana&lt;/a&gt;、&lt;a href=&#34;https://github.com/bitnami-labs/sealed-secrets&#34;&gt;密封秘密&lt;/a&gt;、&lt;a href=&#34;https://github.com/kyverno/kyverno&#34;&gt;kyverno&lt;/a&gt;、&lt;a href=&#34;https://github.com/prometheus/prometheus&#34;&gt;prometheus&lt;/a&gt;、&lt;a href=&#34;https://github.com/kubernetes-sigs/external-dns&#34;&gt;external-dns&lt;/a&gt; 和 &lt;a href=&#34;https://github.com/cert-manager/cert-manager&#34;&gt;cert-manager&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;根据我们的经验和分析，您每年预计会出现&lt;strong&gt;2-5 个主要升级、43-52 个次要升级和 276-327 个软件补丁&lt;/strong&gt;。这几乎是一天更新一次！&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt; &lt;img loading =“lazy”decoding =“async”width =“1200”height =“742”src =“https://www.cncf.io/wp-content/uploads/2026/01/image1.png”alt =“OSS CNCF项目图表中的平台工程构建，显示主要，次要和补丁的每个版本类型的更改汇总数量。” class =“wp-image-155482”srcset =“https://www.cncf.io/wp-content/uploads/2026/01/image1.png 1200w，https://www.cncf.io/wp-content/uploads/2026/01/image1-300x186.png 300w， https://www.cncf.io/wp-content/uploads/2026/01/image1-1024x633.png 1024w，https://www.cncf.io/wp-content/uploads/2026/01/image1-768x475.png 768w，https://www.cncf.io/wp-content/uploads/2026/01/image1-900x557.png 900w，https://www.cncf.io/wp-content/uploads/2026/01/image1-323x200.png 323w， https://www.cncf.io/wp-content/uploads/2026/01/image1-647x400.png 647w&#34;sizes=&#34;auto,(最大宽度:1200px)100vw,1200px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;维护稳健的安全态势的责任带来了重大挑战。每天都会发现许多安全漏洞。它们在您的平台需要作为安全补丁应用的上游项目中得到解决。这极大地增加了上图中的补丁数量。必须监控此类更改并快速将其应用到您的平台中。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;与此相一致，项目或其图表维护者可能会选择停止维护以前的版本，而只提供通往最新主要版本的升级路径，这实际上将旧主要版本标记为生命周期结束。即使您只想采用安全升级，您实际上也被迫遵循维护版本。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;大量的维护工作可以实现自动化，特别是在识别新的应用程序版本时。 Helm 图表版本在存储库和注册表中组织，而二进制软件版本则使用其 API 在 GitHub 上找到。这使得基本的下载和升级任务成为委托给相应打开拉取请求的脚本的良好候选者。自动化解决了短期报废问题。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;控制供应链&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;近年来，我们了解到供应链的关键部分（例如容器注册表或 Helm 图表存储库）可能会受到速率限制或破坏性更改的影响，例如 OSS 社区或软件供应商在短时间内通知弃用。在如此短的时间内采用这些更改并确保平台实例使用新的平台版本通常是不可能的。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;维护平台专用的容器注册表缓存和带有 Helm 图表的单一存储库，可以使代码破坏更改对用户透明，并为平台工程师赢得适应时间。同样，这为平台管理员提供了规划升级的时间。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;跟上 Kubernetes 升级&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;虽然每个 Kubernetes 小版本都会维护 12 个月，但云平台提供商通常会推动更快的采用，并且期望用户能够跟上最新版本。新的 Kubernetes 版本可能附带您的 Helm Chart 所依赖的已弃用的 API，这使得升级您的 Helm Chart 成为必然。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes 一致性冒烟测试使您能够发现潜在的重大变更。渲染平台将部署的所有清单，并根据 Kubernetes OpenAPI 架构静态测试整个输出，包括所有添加的自定义资源定义 (CRD)。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 类=“wp-bl”ock-heading&#34;&gt;维护 Helm Chart 升级&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;凭借&lt;em&gt;平台即产品&lt;/em&gt;的心态，您拥有所部署内容的全部影响。社区 Helm 图表可能会减少您需要定义的清单数量，但它们并不能免除准确理解 Kubernetes 集群中引入的内容的责任。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在实践中，仅仅检查 Go 模板代码很少足以评估新图表版本对您平台的影响，因此需要应用其他策略。一些 Helm 图表升级是通过对不可变的 Kubernetes 属性（例如 Deployment 的标签选择器）进行修改而提供的，这使维护和升级进一步复杂化。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;通过实现能够管理不可变 Kubernetes 属性更改的自定义平台操作员，您可以确保顺利升级。通过分析渲染的 Helm 图表清单：当前版本与新版本，在潜在的破坏性更改影响生产环境之前检测到它们。还可以针对正在运行的集群执行差异，在应用更改之前执行试运行。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;使用持久数据维护应用程序&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;许多 Helm 图表都附带依赖项，这些依赖项通过捆绑 SQL 数据库和键值存储等基本组件来简化部署。它们维护其依赖应用程序的状态，并且经常需要持久卷来执行此操作。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;例如，Helm 依赖项声明清单以部署 PostgreSQL 数据库服务，但不附带任何了解数据库生命周期管理（升级、迁移、复制）的操作员。这种“包含电池”的方法简化了初始部署，但对平台运营来说是一种技术债务。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;为了应对这些挑战，您必须查看包含的依赖关系图表，以检查它们是否维护应用程序关键数据。避免使用作为 Helm 图表依赖项提供的 SQL 数据库。相反，通过数据库操作员（例如 CloudnativePG）部署数据库服务，这些操作员了解 Kubernetes 存储限制（例如卷附件）和数据库生命周期要求（例如重大升级时的迁移工作流程）。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;运行时验证的必要性&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;部署无错误的 Helm 图表升级不一定能确保应用程序仍按预期运行。无论它是单独依赖核心清单还是依赖额外的自定义资源，这都是如此。代码破坏性更改（无论是在图表中还是应用程序本身）通常不会通过简单的清单验证而显现出来。资源可能看起来很健康，但悄悄地偏离了以前的配置，甚至日志也可能无法暴露集成问题。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这使得强大的质量保证变得至关重要，特别是在可能的情况下通过自动化集成测试。自动化测试应该在运行时运行集群以确保所有服务都可以联系其依赖项，并且端点按预期公开。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;长期集群监控也很重要。应用程序 OOMKilled、CPU 限制或磁盘空间不足等问题通常仅在几天甚至几周后发生，具体取决于工作负载模式。及早发现这些问题在很大程度上依赖于精心设计的 Prometheus 规则。 Kube-Prometheus-Stack 提供了坚实的基础，但添加特定于应用程序的规则和警报条件可以提供更多见解。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;最终想法&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;一旦您承诺交付一个平台，您就需要对组件的生命周期负责。开发重要应用程序的开源社区通常会对兼容性和安全问题做出快速响应；但是，这些更改仍然需要集成到您的平台中。您需要为运营成本、升级零件以及更换不再维护的组件做好准备。在平台中协调这项工作的好处是，它可以让开发团队不必同时执行所有相同的工作。高度自动化以及专用平台管理组件和工具的开发确保了长期的可维护性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;此外，反馈和上游贡献是使用开源软件不可或缺的一部分，可确保类似场景中的其他用户可以从体验中受益，并确保上游项目保持健康。&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Tue, 20 Jan 2026 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Kubernetes Fuels AI Growth; Organizational Culture Remains the Decisive Factor】Kubernetes 推动人工智能增长；组织文化仍然是决定性因素</title>
      <link>https://www.cncf.io/blog/2026/01/20/kubernetes-fuels-ai-growth-organizational-culture-remains-the-decisive-factor/</link>
      <description>【&lt;p&gt;The &lt;a href=&#34;https://www.cncf.io/reports/the-cncf-annual-cloud-native-survey/&#34;&gt;CNCF Annual Cloud Native Survey&lt;/a&gt; confirms a long-developing trend: Kubernetes has moved from container orchestration to becoming the backbone of modern infrastructure—including AI.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Production usage of Kubernetes now stands at 82% among container users, and 66% of AI adopters are using it to scale inference workloads. Kubernetes is no longer a niche tool; it’s a core infrastructure layer supporting scale, reliability, and increasingly AI systems.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This shift reflects both the technical evolution and growing operational maturity of the cloud native ecosystem. 98% of organizations surveyed have now adopted cloud native technologies, making it the near-universal standard for modern enterprise infrastructure.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image aligncenter size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;434&#34; height=&#34;230&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image-12-2.jpg&#34; alt=&#34;Cloud native adoption reaches 98% across surveyed organizations.&#34; class=&#34;wp-image-155422&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image-12-2.jpg 434w, https://www.cncf.io/wp-content/uploads/2026/01/image-12-2-300x159.jpg 300w, https://www.cncf.io/wp-content/uploads/2026/01/image-12-2-194x102.jpg 194w, https://www.cncf.io/wp-content/uploads/2026/01/image-12-2-377x200.jpg 377w&#34; sizes=&#34;auto, (max-width: 434px) 100vw, 434px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Kubernetes: From Infrastructure Choice to Infrastructure Standard&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Survey data shows that Kubernetes has matured into the enterprise default. Organizations have moved beyond experimentation and are now focused on standardizing their infrastructure strategies. With this maturity comes more consistent deployment models and a broader application of cloud native best practices across teams.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image aligncenter size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;886&#34; height=&#34;230&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image-12-3.jpg&#34; alt=&#34;66% of organizations use Kubernetes to host generative AI workloads and 82% of container users deploy Kubernetes in production, up from 66% in 2023.&#34; class=&#34;wp-image-155423&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image-12-3.jpg 886w, https://www.cncf.io/wp-content/uploads/2026/01/image-12-3-300x78.jpg 300w, https://www.cncf.io/wp-content/uploads/2026/01/image-12-3-768x199.jpg 768w, https://www.cncf.io/wp-content/uploads/2026/01/image-12-3-600x156.jpg 600w&#34; sizes=&#34;auto, (max-width: 886px) 100vw, 886px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes is now the default choice for building scalable, observable systems. It’s the platform teams rely on as they move from pilots to production-grade AI workloads.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;AI Adoption Is Infrastructure-First&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;There’s often a gap between AI ambition and what infrastructure can support. The 2025 data found that only 7% of organizations deploy AI models daily, and over half don’t train models at all. Instead, many prioritize the reliable and cost-effective operation of pre-trained models.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image aligncenter size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;430&#34; height=&#34;228&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image-12-4.jpg&#34; alt=&#34;47% of organizations deploy AI models occasionally, with only 7% deploying daily.&#34; class=&#34;wp-image-155429&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image-12-4.jpg 430w, https://www.cncf.io/wp-content/uploads/2026/01/image-12-4-300x159.jpg 300w, https://www.cncf.io/wp-content/uploads/2026/01/image-12-4-194x102.jpg 194w, https://www.cncf.io/wp-content/uploads/2026/01/image-12-4-377x200.jpg 377w&#34; sizes=&#34;auto, (max-width: 430px) 100vw, 430px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes is helping bridge that gap, enabling teams to unify how they scale, deploy and manage AI workloads. As the report notes, &lt;em&gt;“Success requires treating AI/ML as a first-class infrastructure challenge, not just an algorithmic one.”&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;What Mature Teams Are Doing: GitOps, Platforms, Observability&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The survey reinforces the growing trend toward platform engineering. Teams that have adopted GitOps workflows, internal developer portals, and automated pipelines are better positioned to scale AI and cloud native workloads.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;A clear signal of maturity: 0% of “explorers” report using GitOps, compared to 58% of “innovators.” These practices represent well-established methods that support consistency, scalability, and operational efficiency.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image aligncenter size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;430&#34; height=&#34;228&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image-12-5.jpg&#34; alt=&#34;GitOps adoption jumps from 0% among cloud native explorers to 58% among cloud native innovators&#34; class=&#34;wp-image-155430&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image-12-5.jpg 430w, https://www.cncf.io/wp-content/uploads/2026/01/image-12-5-300x159.jpg 300w, https://www.cncf.io/wp-content/uploads/2026/01/image-12-5-194x102.jpg 194w, https://www.cncf.io/wp-content/uploads/2026/01/image-12-5-377x200.jpg 377w&#34; sizes=&#34;auto, (max-width: 430px) 100vw, 430px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Observability also continues to be critical as workloads become more dynamic. OpenTelemetry’s position as the second-highest-velocity CNCF project reflects strong momentum for vendor-neutral, standardized instrumentation. Teams now depend on real-time visibility to keep systems reliable and performant in production.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Culture Is Now the Primary Barrier&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For the first time, culture—not complexity or security—is the top barrier to cloud native adoption. 47% of organizations cite cultural change with development teams as their biggest challenge.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image aligncenter size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;430&#34; height=&#34;228&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image-12.jpg&#34; alt=&#34;Cultural changes with the development team ranks as the #1 challenge for deploying containers (47%), surpassing technical concerns.&#34; class=&#34;wp-image-155417&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image-12.jpg 430w, https://www.cncf.io/wp-content/uploads/2026/01/image-12-300x159.jpg 300w, https://www.cncf.io/wp-content/uploads/2026/01/image-12-194x102.jpg 194w, https://www.cncf.io/wp-content/uploads/2026/01/image-12-377x200.jpg 377w&#34; sizes=&#34;auto, (max-width: 430px) 100vw, 430px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This highlights a recurring insight from the survey: the technical foundation is in place, but many organizations still need to adapt their internal structures and workflows to fully benefit from cloud native capabilities.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Looking Ahead: Infrastructure and Sustainability&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As Kubernetes cements its position as the infrastructure for AI and modern workloads, the community faces the new challenge of sustainability. AI workloads are increasing pressure on open source infrastructure through machine-driven usage.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The report warns that many systems operate on a “dangerously fragile premise.” Ensuring continued innovation will depend on organizations stepping up to contribute, support maintainers, and participate actively in sustaining the ecosystem.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Sustaining the future of cloud native will require intentional investment in infrastructure, governance, and community. CNCF will continue advancing this work through open collaboration, evolving standards, and support for maintainers and contributors across the ecosystem.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For those building at scale, now is the time to align your infrastructure strategy with what the data—and the community—clearly show.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Join our upcoming webinar, &lt;a href=&#34;https://community.cncf.io/events/details/cncf-cncf-online-programs-presents-cloud-native-live-the-cncf-annual-cloud-native-survey-infrastructure-of-ais-future/&#34;&gt;&lt;em&gt;Cloud Native Live: The CNCF Annual Cloud Native Survey — Infrastructure of AI’s Future&lt;/em&gt;&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;on February 3, 2026, to hear SVP of research Hilary Carter and a special guest analyst discuss the results of the survey and what that means for the future of the cloud native ecosystem.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;a href=&#34;https://www.cncf.io/reports/the-cncf-annual-cloud-native-survey/&#34;&gt;CNCF 年度云原生调查&lt;/a&gt;证实了一个长期发展趋势：Kubernetes 已从容器编排转变为包括人工智能在内的现代基础设施的支柱。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;目前容器用户中 Kubernetes 的生产使用率为 82%，66% 的 AI 采用者正在使用它来扩展推理工作负载。 Kubernetes 不再是一个小众工具；它是支持规模、可靠性和日益增长的人工智能系统的核心基础设施层。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这种转变反映了云原生生态系统的技术演变和运营成熟度的提高。 98% 的受访组织现已采用云原生技术，使其成为现代企业基础设施的近乎通用标准。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-imagealigncenter size-full&#34;&gt;&lt;imgloading=&#34;lazy&#34;decoding=&#34;async&#34;width=&#34;434&#34;height=&#34;230&#34;src=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image-12-2.jpg&#34; alt=&#34;在接受调查的组织中，云原生采用率达到 98%。&#34; class =“wp-image-155422”srcset =“https://www.cncf.io/wp-content/uploads/2026/01/image-12-2.jpg 434w，https://www.cncf.io/wp-content/uploads/2026/01/image-12-2-300x159.jpg 300w， https://www.cncf.io/wp-content/uploads/2026/01/image-12-2-194x102.jpg 194w，https://www.cncf.io/wp-content/uploads/2026/01/image-12-2-377x200.jpg 377w“尺寸=”自动，（最大宽度：434px）100vw， 434px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Kubernetes：从基础设施选择到基础设施标准&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;调查数据显示，Kubernetes 已成熟为企业默认。组织已经超越了实验，现在专注于标准化其基础设施战略。随着这种成熟度的到来，部署模型更加一致，云原生最佳实践在团队中得到更广泛的应用。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-imagealigncenter size-full&#34;&gt;&lt;imgloading=&#34;lazy&#34;decoding=&#34;async&#34;width=&#34;886&#34;height=&#34;230&#34;src=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image-12-3.jpg&#34;alt=&#34;66%的组织使用Kubernetes来托管生成式AI工作负载，82%的容器用户在生产中部署Kubernetes，这一比例从2023 年将达到 66%。” class =“wp-image-155423”srcset =“https://www.cncf.io/wp-content/uploads/2026/01/image-12-3.jpg 886w，https://www.cncf.io/wp-content/uploads/2026/01/image-12-3-300x78.jpg 300w， https://www.cncf.io/wp-content/uploads/2026/01/image-12-3-768x199.jpg 768w，https://www.cncf.io/wp-content/uploads/2026/01/image-12-3-600x156.jpg 600w“尺寸=”自动，（最大宽度：886px）100vw， 886px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes 现在是构建可扩展、可观察系统的默认选择。这是团队从试点转向生产级人工智能工作负载时所依赖的平台。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;人工智能采用是基础设施优先&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;经常有一个g人工智能的雄心与基础设施可以支持的内容之间存在一定的差距。 2025 年的数据发现，只有 7% 的组织每天部署人工智能模型，超过一半的组织根本不训练模型。相反，许多人优先考虑预训练模型的可靠且经济高效的运行。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-imagealigncenter size-full&#34;&gt;&lt;imgloading=&#34;lazy&#34;decoding=&#34;async&#34;width=&#34;430&#34;height=&#34;228&#34;src=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image-12-4.jpg&#34; alt=&#34;47% 的组织偶尔部署 AI 模型，只有 7% 每天部署。&#34; class =“wp-image-155429”srcset =“https://www.cncf.io/wp-content/uploads/2026/01/image-12-4.jpg 430w，https://www.cncf.io/wp-content/uploads/2026/01/image-12-4-300x159.jpg 300w， https://www.cncf.io/wp-content/uploads/2026/01/image-12-4-194x102.jpg 194w，https://www.cncf.io/wp-content/uploads/2026/01/image-12-4-377x200.jpg 377w“尺寸=”自动，（最大宽度：430px）100vw， 430px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes 正在帮助弥合这一差距，使团队能够统一扩展、部署和管理 AI 工作负载的方式。正如报告指出的那样，“成功需要将 AI/ML 视为一流的基础设施挑战，而不仅仅是算法挑战。”&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;成熟团队正在做什么：GitOps、平台、可观察性&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;该调查强化了平台工程日益增长的趋势。采用 GitOps 工作流程、内部开发人员门户和自动化管道的团队能够更好地扩展人工智能和云原生工作负载。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;成熟度的明确信号：0% 的“探索者”报告使用 GitOps，而“创新者”的比例为 58%。这些实践代表了支持一致性、可扩展性和运营效率的成熟方法。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-imagealigncenter size-full&#34;&gt;&lt;imgloading=&#34;lazy&#34;decoding=&#34;async&#34;width=&#34;430&#34;height=&#34;228&#34;src=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image-12-5.jpg&#34;alt=&#34;云原生探索者中的 GitOps 采用率从 0% 跃升至云原生创新者中的 58%&#34; class =“wp-image-155430”srcset =“https://www.cncf.io/wp-content/uploads/2026/01/image-12-5.jpg 430w，https://www.cncf.io/wp-content/uploads/2026/01/image-12-5-300x159.jpg 300w， https://www.cncf.io/wp-content/uploads/2026/01/image-12-5-194x102.jpg 194w，https://www.cncf.io/wp-content/uploads/2026/01/image-12-5-377x200.jpg 377w“尺寸=”自动，（最大宽度：430px）100vw， 430px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;随着工作负载变得更加动态，可观察性也仍然至关重要。 OpenTelemetry 作为第二高速度​​ CNCF 项目的地位反映了供应商中立的标准化仪器的强劲势头。团队现在依靠实时可见性来保持系统在生产中的可靠性和性能。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;文化现在是主要障碍&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;第一次，文化——而不是复杂性或安全性——成为了p 云原生采用的障碍。 47% 的组织将开发团队的文化变革视为最大的挑战。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-imagealigncenter size-full&#34;&gt;&lt;imgloading=&#34;lazy&#34;decoding=&#34;async&#34;width=&#34;430&#34;height=&#34;228&#34;src=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image-12.jpg&#34;alt=&#34;开发团队的文化变化被列为部署容器的第一大挑战 (47%)，超过了技术问题。&#34; class =“wp-image-155417”srcset =“https://www.cncf.io/wp-content/uploads/2026/01/image-12.jpg 430w，https://www.cncf.io/wp-content/uploads/2026/01/image-12-300x159.jpg 300w， https://www.cncf.io/wp-content/uploads/2026/01/image-12-194x102.jpg 194w，https://www.cncf.io/wp-content/uploads/2026/01/image-12-377x200.jpg 377w“尺寸=”自动，（最大宽度：430px）100vw， 430px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这凸显了调查中反复出现的一个见解：技术基础已经到位，但许多组织仍然需要调整其内部结构和工作流程，以充分受益于云原生功能。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;展望未来：基础设施和可持续发展&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;随着 Kubernetes 巩固其作为人工智能和现代工作负载基础设施的地位，社区面临着可持续性的新挑战。人工智能工作负载通过机器驱动的使用给开源基础设施带来越来越大的压力。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;该报告警告说，许多系统都在“危险脆弱的前提下”运行。确保持续创新将取决于组织加紧贡献、支持维护者并积极参与维持生态系统。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;维持云原生的未来需要对基础设施、治理和社区进行有意投资。 CNCF 将通过开放协作、不断发展的标准以及对整个生态系统的维护者和贡献者的支持来继续推进这项工作。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;对于那些大规模建设的人来说，现在是根据数据和社区明确显示的内容调整基础设施策略的时候了。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;参加我们即将举行的网络研讨会，&lt;a href=&#34;https://community.cncf.io/events/details/cncf-cncf-online-programs-presents-cloud-native-live-the-cncf-annual-cloud-native-survey-infrastruct-of-ais-future/&#34;&gt;&lt;em&gt;云原生直播：CNCF 年度云原生调查 — 人工智能未来的基础设施&lt;/em&gt;&lt;/a&gt;&lt;em&gt;， &lt;/em&gt;2026 年 2 月 3 日，聆听研究高级副总裁 Hilary Carter 和一位特邀客座分析师讨论调查结果以及这对云原生生态系统的未来意味着什么。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Mon, 19 Jan 2026 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Reclaiming underutilized GPUs in Kubernetes using scheduler plugins】使用调度程序插件回收 Kubernetes 中未充分利用的 GPU</title>
      <link>https://www.cncf.io/blog/2026/01/20/reclaiming-underutilized-gpus-in-kubernetes-using-scheduler-plugins/</link>
      <description>【&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;The problem nobody talks about&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;GPUs are expensive; and yours are probably sitting idle right now. High-end GPUs (for example, NVIDIA A100-class devices) can cost $10,000+, and in a Kubernetes cluster running AI workloads, you might have dozens of them. Here’s the uncomfortable truth: most of the time, they’re sitting idle. If you’re struggling with GPU scheduling in Kubernetes or looking for ways to reclaim idle GPUs, you’re not alone.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;A data scientist spins up a training job, requests 4 GPUs, runs for two hours, then leaves for lunch. The GPUs sit allocated but unused. Meanwhile, another team’s job is queued, waiting for resources that technically exist but aren’t available.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Standard Kubernetes scheduling doesn’t help here. It sees allocated resources as unavailable — period. The scheduler does not currently take real-time GPU utilization into account.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Kubernetes scheduling trade-offs for GPUs&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes was built for CPUs. Its scheduling model assumes resources are either allocated or free, with nothing in between. For CPUs, this mostly works — a pod using 10% of its requested CPU isn’t blocking others in the same way.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;GPUs are different. They’re discrete, expensive, and often requested in large quantities. A pod requesting 4 GPUs gets exactly 4 GPUs, even if it’s only actively using them 20% of the time. This is the core challenge of GPU resource management in Kubernetes — the scheduler has no concept of actual utilization.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The default Kubernetes preemption mechanism (DefaultPreemption) can evict lower-priority pods to make room for higher-priority ones. But it only considers priority — not actual utilization. Pods are treated equivalently from a preemption perspective when they share the same priority, regardless of their current utilization.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We evaluated several existing approaches. For example, device plugins focus on allocation, while autoscaling addresses capacity rather than reclaiming idle resources. Cluster autoscaler can add nodes but won’t reclaim idle resources on existing ones. Various GPU sharing approaches exist, but they don’t address the fundamental scheduling problem.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;The core idea: Utilization-aware preemption&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We needed utilization-aware preemption that considers what GPUs are actually doing, not just what they’ve been allocated. The solution: a custom Kubernetes scheduler plugin for idle GPU reclaim that replaces the default preemption logic with an alternative approach that incorporates utilization signals.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The plugin, which we called ReclaimIdleResource, operates in the PostFilter phase of the scheduling cycle. This is where Kubernetes looks for preemption candidates when a pod can’t be scheduled normally.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Here’s the key insight: instead of just comparing priorities, we query Prometheus for GPU utilization metrics (in our case, sourced from DCGM).&amp;nbsp; A pod is only eligible for preemption if:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;1. Its priority is below the preemptor’s threshold&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;2. It’s been running long enough to establish a usage pattern&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;3. Its actual GPU utilization is below a configured threshold&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This means an idle pod with priority 1000 can be preempted by a pod with priority 500, if the idle pod isn’t actually using its GPUs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Where ReclaimIdleResource fits in the scheduling cycle&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The plugin replaces DefaultPreemption in the PostFilter phase, activating only when normal scheduling fails.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1600&#34; height=&#34;789&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image-13.png&#34; alt=&#34;This image shows a flow chart view of the scheduling cycle. It shows the flow from PreFilter to Filter to Score. At score, if nodes are found, the chart moves straight on to bind. If nodes aren&#39;t found, the flow chart moves to PostFilter ReclaimIdleResource replaces DefaultPreemption. &#34; class=&#34;wp-image-155694&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image-13.png 1600w, https://www.cncf.io/wp-content/uploads/2026/01/image-13-300x148.png 300w, https://www.cncf.io/wp-content/uploads/2026/01/image-13-1024x505.png 1024w, https://www.cncf.io/wp-content/uploads/2026/01/image-13-768x379.png 768w, https://www.cncf.io/wp-content/uploads/2026/01/image-13-900x444.png 900w, https://www.cncf.io/wp-content/uploads/2026/01/image-13-406x200.png 406w, https://www.cncf.io/wp-content/uploads/2026/01/image-13-811x400.png 811w&#34; sizes=&#34;auto, (max-width: 1600px) 100vw, 1600px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;How it works&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The plugin hooks into the scheduler as a PostFilter extension:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;profiles:&#xA;- schedulerName: default-scheduler&#xA;  plugins:&#xA;    postFilter:&#xA;      enabled:&#xA;      - name: ReclaimIdleResource&#xA;      disabled:&#xA;      - name: DefaultPreemption&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;When a GPU-requesting pod can’t be scheduled, the plugin:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;1. Checks cooldown&lt;/strong&gt; — Has this pod recently triggered preemption? If so, wait. This prevents thrashing.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;2. Scans potential victims&lt;/strong&gt; — Finds all lower-priority pods on candidate nodes that have GPUs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;3. Evaluates each victim&lt;/strong&gt; — Parses its PriorityClass for reclaim policy annotations, checks if it’s still in its “toleration period” (grace period after scheduling), queries Prometheus for average GPU utilization over the monitoring window, and compares utilization against the idle threshold.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;4. Selects minimal victims&lt;/strong&gt; — Sorts eligible victims by GPU count (descending) and priority (ascending), then selects the minimum set needed to free enough GPUs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;5. Validates the decision&lt;/strong&gt; — Runs filter plugins to confirm the preemptor will actually fit after preemption.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The policy is defined per-PriorityClass through annotations:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;kind: PriorityClass&#xA;metadata:&#xA;  name: batch-workload&#xA;  annotations:&#xA;    reclaim-idle-resource.scheduling.x-k8s.io/minimum-preemptable-priority: &#34;10000&#34;&#xA;    reclaim-idle-resource.scheduling.x-k8s.io/toleration-seconds: &#34;3600&#34;&#xA;    reclaim-idle-resource.scheduling.x-k8s.io/resource-idle-seconds: &#34;3600&#34;&#xA;    reclaim-idle-resource.scheduling.x-k8s.io/resource-idle-usage-threshold: &#34;10.0&#34;&#xA;value: 8000&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This says: pods in this priority class can tolerate preemption for one hour after scheduling, and can be preempted if their GPU usage stays below 10% for an hour — but only by pods with priority 10000 or higher.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Key design decisions&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Why PriorityClass annotations?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We considered a custom CRD, but PriorityClass already exists in the scheduling mental model. Teams already think about priority when designing workloads. Adding reclaim policy as annotations keeps the configuration close to where people expect it.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Why a monitoring window instead of instant utilization?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;GPU workloads are bursty. A training job might spike to 100% utilization during forward/backward passes, then drop to near-zero during data loading. Instant measurements would give false positives. We use a configurable window (typically 30–60 minutes) to capture the true usage pattern.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Why query Prometheus instead of using in-memory metrics?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The scheduler runs as a single replica. We needed utilization data that survives scheduler restarts and can be queried historically. DCGM exports to Prometheus naturally, and most GPU clusters already have this pipeline.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Why a cooldown period?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Without it, a preemptor pod could trigger preemption, fail to schedule for unrelated reasons, and immediately trigger another preemption attempt. The 30-second cooldown prevents rapid-fire preemption storms.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;What we learned&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Tuning matters more than we expected. &lt;/strong&gt;The idle threshold and monitoring window need to match your workload patterns. Too aggressive and you’ll preempt jobs mid-training. Too conservative and you won’t reclaim much.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Observability is essential. &lt;/strong&gt;We added extensive logging and Kubernetes events so operators can understand why preemption decisions were made. When someone’s job gets preempted, they want to know why.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Multi-Instance GPU (MIG) adds additional scheduling considerations.. &lt;/strong&gt;NVIDIA’s Multi-Instance GPU feature means a single physical GPU can be partitioned. We had to add partition-size compatibility checks to avoid preempting pods on nodes where the preemptor couldn’t run.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Related Links&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;• Kubernetes Scheduler Plugins: https://github.com/kubernetes-sigs/scheduler-plugins&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;• NVIDIA DCGM Exporter: https://github.com/NVIDIA/dcgm-exporter&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Originally published on Medium. Permission granted for republishing on CNCF blog.&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;无人谈论的问题&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;GPU 价格昂贵；而你的可能现在闲置着。高端 GPU（例如 NVIDIA A100 级设备）的价格可能超过 10,000 美元，在运行 AI 工作负载的 Kubernetes 集群中，您可能拥有数十个 GPU。这是一个令人不安的事实：大多数时候，他们都闲着。如果您在 Kubernetes 中的 GPU 调度方面遇到困难，或者正在寻找回收空闲 GPU 的方法，那么您并不孤单。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;一位数据科学家启动一项训练作业，请求 4 个 GPU，运行两个小时，然后出去吃午饭。 GPU 已分配但未使用。与此同时，另一个团队的作业正在排队，等待技术上存在但不可用的资源。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;标准 Kubernetes 调度在这里没有帮助。它将分配的资源视为不可用——就这样。调度程序当前不考虑实时 GPU 利用率。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Kubernetes 调度与 GPU 的权衡&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes 是为 CPU 构建的。其调度模型假设资源要么已分配，要么已释放，没有中间状态。对于 CPU，这在很大程度上是有效的 - 使用其请求 CPU 的 10% 的 Pod 不会以同样的方式阻止其他 Pod。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;GPU 是不同的。它们是离散的、昂贵的，并且通常需要大量的。请求 4 个 GPU 的 Pod 正好获得 4 个 GPU，即使它只在 20% 的时间里主动使用它们。这是 Kubernetes 中 GPU 资源管理的核心挑战——调度器没有实际利用率的概念。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;默认的 Kubernetes 抢占机制（DefaultPreemption）可以驱逐低优先级的 pod，为高优先级的 pod 腾出空间。但它只考虑优先级，而不考虑实际利用率。当 Pod 共享相同的优先级时，从抢占的角度来看，它们被同等对待，无论它们当前的利用率如何。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们评估了几种现有的方法。例如，设备插件专注于分配，而自动缩放则解决容量问题，而不是回收闲置资源。集群自动缩放程序可以添加节点，但不会回收现有节点上的空闲资源。存在各种 GPU 共享方法，但它们并没有解决根本的调度问题。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;核心思想：利用率感知抢占&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们需要利用率感知的抢占，考虑 GPU 实际在做什么，而不仅仅是它们被分配的事情。解决方案：用于空闲 GPU 回收的自定义 Kubernetes 调度程序插件，用包含利用率信号的替代方法替换默认的抢占逻辑。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;该插件我们称为 ReclaimIdleResource，在调度周期的 PostFilter 阶段运行。当 Pod 无法正常调度时，Kubernetes 会在此处寻找抢占候选者。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这里是关键的见解：不仅仅是比较优先级，我们e 查询 Prometheus 以获取 GPU 利用率指标（在我们的示例中，来自 DCGM）。  pod 仅在以下情况下才有资格被抢占：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;1.它的优先级低于抢占者的阈值&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;2.它已经运行了足够长的时间来建立使用模式&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;3.其实际 GPU 利用率低于配置的阈值&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这意味着，如果空闲 Pod 实际上并未使用其 GPU，则优先级为 1000 的空闲 Pod 可以被优先级为 500 的 Pod 抢占。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;ReclaimIdleResource 在调度周期中的位置&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;该插件替换了PostFilter阶段的DefaultPreemption，仅在正常调度失败时激活。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;imgloading=&#34;lazy&#34;decoding=&#34;async&#34; width=&#34;1600&#34; height=&#34;789&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image-13.png&#34; alt=&#34;此图为调度周期的流程图视图，展示了从PreFilter到Filter到Score的流程。在score时，如果找到节点，则图表直线移动如果未找到节点，流程图将移至 PostFilter ReclaimIdleResource 替换 DefaultPreemption。 https://www.cncf.io/wp-content/uploads/2026/01/image-13-300x148.png 300w，https://www.cncf.io/wp-content/uploads/2026/01/image-13-1024x505.png 1024w， https://www.cncf.io/wp-content/uploads/2026/01/image-13-768x379.png 768w，https://www.cncf.io/wp-content/uploads/2026/01/image-13-900x444.png 900w， https://www.cncf.io/wp-content/uploads/2026/01/image-13-406x200.png 406w，https://www.cncf.io/wp-content/uploads/2026/01/image-13-811x400.png 811w“尺寸=”自动，（最大宽度：1600px）100vw， 1600px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;它是如何工作的&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;该插件作为 PostFilter 扩展挂钩到调度程序：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;配置文件：&#xA;- 调度程序名称：默认调度程序&#xA;  插件：&#xA;    后置过滤器：&#xA;      启用：&#xA;      - 名称：回收空闲资源&#xA;      禁用：&#xA;      - 名称：默认抢占&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;当无法调度 GPU 请求的 pod 时，插件：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;强&gt;1。检查冷却时间&lt;/strong&gt; - 此 Pod 最近是否触发了抢占？如果是这样，请等待。这可以防止抖动。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;强&gt;2。扫描潜在受害者&lt;/strong&gt; - 查找具有 GPU 的候选节点上所有优先级较低的 Pod。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;强&gt;3。评估每个受害者 - 解析其 PriorityClass 以获取回收策略注释，检查其是否仍处于“容忍期”（调度后的宽限期），查询 Prometheus 监控窗口内的平均 GPU 利用率，并将利用率与空闲阈值进行比较。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;强&gt;4。选择最少的受害者&lt;/strong&gt; - 按 GPU 数量（降序）和优先级（升序）对符合条件的受害者进行排序，然后选择释放足够 GP 所需的最小集合我们。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;强&gt;5。验证决策&lt;/strong&gt; - 运行过滤器插件以确认抢占器在抢占后确实适合。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;该策略是通过注释按 PriorityClass 定义的：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;种类：优先级&#xA;元数据：&#xA;  名称：批量工作负载&#xA;  注释：&#xA;    回收空闲资源.scheduling.x-k8s.io/最小可抢占优先级：“10000”&#xA;    回收空闲资源.scheduling.x-k8s.io/toleration-秒：“3600”&#xA;    回收空闲资源.scheduling.x-k8s.io/资源空闲秒：“3600”&#xA;    回收-空闲-资源.scheduling.x-k8s.io/resource-idle-usage-threshold：“10.0”&#xA;价值：8000&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这表示：此优先级的 pod 可以在调度后容忍抢占一小时，并且如果 GPU 使用率在一小时内保持在 10% 以下，则可以被抢占 - 但只能被优先级为 10000 或更高的 pod 抢占。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;关键设计决策&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;为什么要使用 PriorityClass 注释？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们考虑了自定义 CRD，但 PriorityClass 已经存在于调度心智模型中。团队在设计工作负载时已经考虑了优先级。添加回收策略作为注释可以使配置接近人们期望的位置。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;为什么采用监控窗口而不是即时利用率？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;GPU 工作负载是突发性的。训练作业在前向/后向传递过程中利用率可能会飙升至 100%，然后在数据加载过程中降至接近于零。即时测量会给出误报。我们使用可配置的窗口（通常为 30-60 分钟）来捕获真实的使用模式。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;为什么查询 Prometheus 而不是使用内存指标？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;调度程序作为单个副本运行。我们需要在调度程序重新启动后仍然存在并且可以历史查询的利用率数据。 DCGM 自然地导出到 Prometheus，并且大多数 GPU 集群已经拥有此管道。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;为什么要有冷却时间？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果没有它，抢占器 Pod 可能会触发抢占，由于不相关的原因而无法调度，并立即触发另一次抢占尝试。 30 秒的冷却时间可以防止速射先发制人的风暴。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;我们学到了什么&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;调整比我们预期的更重要。 &lt;/strong&gt;空闲阈值和监控窗口需要与您的工作负载模式相匹配。过于激进，你会在训练中抢占工作机会。太保守，你不会收回太多。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;可观察性至关重要。 &lt;/strong&gt;我们添加了广泛的日志记录和 Kubernetes 事件，以便操作员能够了解为何做出抢占决策。当某人的工作被抢占时，他们想知道原因。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;多实例 GPU (MIG) 增加了额外的调度考虑因素。&lt;/strong&gt;NVIDIA 的多实例 GPU 功能意味着可以对单个物理 GPU 进行分区。我们必须添加分区-大小兼容性检查，以避免抢占抢占器无法运行的节点上的 pod。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;相关链接&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;• Kubernetes 调度程序插件：https://github.com/kubernetes-sigs/scheduler-plugins&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;• NVIDIA DCGM 导出器：https://github.com/NVIDIA/dcgm-exporter&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;最初发布于 Medium。已获得在 CNCF 博客上重新发布的许可。&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Mon, 19 Jan 2026 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Top 28 Kubernetes resources for 2026: Learn and stay up-to-date】2026 年 28 个 Kubernetes 最佳资源：学习并保持最新状态</title>
      <link>https://www.cncf.io/blog/2026/01/19/top-28-kubernetes-resources-for-2026-learn-and-stay-up-to-date/</link>
      <description>【&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The cloud native community is thriving and Kubernetes has a lot to do with it. In this open source ecosystem, practitioners are continually sharing knowledge, tools, and lessons learned from first-hand experience to help others succeed.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Whether your goal is to learn the fundamentals, stay current on the latest releases and patterns, build an Internal Developer Platform (IDP), or run artificial intelligence (AI) / machine learning (ML) workloads on Kubernetes, there are more resources than any one person could possibly keep up with. This guide is designed for engineers who are new to Kubernetes or those who are already deploying and maintaining workloads in production environments. It’s a curated set of durable, high‑signal places to listen, watch, and discuss different aspects of the K8s and cloud native ecosystem, grouped from fundamentals through advanced operations and community resources.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Start with Fundamentals&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you’re brand-new, work through Fundamentals and Labs before worrying about exams or listening to podcasts. These build basic mental models and vocabulary before you touch a cluster.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/tutorials/&#34;&gt;Kubernetes Basics (Official Tutorials)&lt;/a&gt;: Interactive, in‑browser tutorials from the project maintainers that walk you through core concepts and simple labs.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.udemy.com/course/kubernetes-getting-started/&#34;&gt;Kubernetes Course (Udemy)&lt;/a&gt;: A short, structured video course that reinforces the basics if you prefer an instructor‑led format.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Get into hands-on Labs and Sandboxes&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Once core ideas make sense, practice real commands in safe, disposable environments.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://training.play-with-kubernetes.com/kubernetes-workshop/&#34;&gt;Play with Kubernetes&lt;/a&gt;: A free, browser‑based playground that lets you spin up temporary clusters and experiment without installing anything locally.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://killercoda.com/playgrounds/scenario/kubernetes&#34;&gt;Killercoda Kubernetes Scenarios&lt;/a&gt;: An interactive lab platform with browser terminals and guided Kubernetes scenarios covering pods, deployments, services, networking, and troubleshooting.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://kodekloud.com/studio/labs/kubernetes?ref=kodekloud.com&#34;&gt;KodeKloud Kubernetes Labs&lt;/a&gt;: Hands‑on labs and playgrounds, including&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://training.linuxfoundation.org/certification/certified-kubernetes-administrator-cka/&#34;&gt;Certified Kubernetes Administrator (CKA)&lt;/a&gt;, &lt;a href=&#34;https://training.linuxfoundation.org/certification/certified-kubernetes-application-developer-ckad/&#34;&gt;Certified Kubernetes Application Developer (CKAD)&lt;/a&gt;, &lt;a href=&#34;https://training.linuxfoundation.org/certification/certified-kubernetes-security-specialist/&#34;&gt;Certified Kubernetes Security Specialist (CKS)&lt;/a&gt;‑aligned environments so you can try real commands in a realistic cluster.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Explore learning roadmaps, guides, and exams&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;These help you choose what to learn next instead of bouncing randomly between topics.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://roadmap.sh/kubernetes&#34;&gt;Kubernetes Roadmap&lt;/a&gt;: A community‑maintained visual roadmap that lays out topics from fundamentals through advanced areas like security, observability, and networking.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://devopscube.com/learn-kubernetes-complete-roadmap/&#34;&gt;How to Learn Kubernetes in 2025&lt;/a&gt;: A step‑by‑step guide suggesting an order for core concepts, labs, and complementary tools so you can build a coherent self‑study plan.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;CKA/CKAD/CKS: CNCF exam curricula and handbooks that define the domains and competencies for each certification and double as skill checklists.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Stay current with podcasts&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Use these to reinforce concepts and hear real‑world stories while commuting or context‑switching.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://kubernetespodcast.com/&#34;&gt;Kubernetes Podcast from Google&lt;/a&gt;: A long‑running show with guest insights from the Kubernetes community plus news and commentary from recent releases and events.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://podcasts.apple.com/us/podcast/kubernetes-bytes/id1580068566&#34;&gt;Kubernetes Bytes&lt;/a&gt;: Focuses on Kubernetes and cloud‑native topics, often diving into platform engineering, operations, and ecosystem projects.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://packetpushers.net/podcast/day-two-devops/&#34;&gt;Day Two DevOps&lt;/a&gt;: Conversations with technical leaders on modern DevOps, covering automation, security, networking, and day‑2 concerns.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.softwaredefinedtalk.com/episodes&#34;&gt;Software Defined Talk&lt;/a&gt;: A broader enterprise software and cloud show where Kubernetes, DevOps, serverless, and security are common topics.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://podcasts.apple.com/us/podcast/open-source-data/id1530428904&#34;&gt;Open||Source||Data&lt;/a&gt;: Explores open‑source data, software, and AI through conversations with developers, regulators, and academics, useful for data‑heavy K8s workloads.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://podcast.bretfisher.com/&#34;&gt;DevOps and Docker Talk&lt;/a&gt;: Covers DevOps, cloud management, sysadmin topics, and container tools like Docker, Kubernetes, and Swarm.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.buzzsprout.com/1010419&#34;&gt;The Deep Edge Podcast&lt;/a&gt;: Discusses cloud‑native and networking technologies that underpin more advanced Kubernetes use cases at the edge.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://feeder.co/discover/184933d887/cncf-io&#34;&gt;Cloud Native Engineering&lt;/a&gt;: Aggregates news, events, and deep dives from across the cloud native ecosystem, with frequent coverage of Kubernetes and related CNCF projects.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Explore curated lists, videos, and advanced topics&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Once you’re comfortable, these resources will help you branch into production practices and specialized workloads.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/ramitsurana/awesome-kubernetes&#34;&gt;Awesome Kubernetes&lt;/a&gt;: A long‑standing curated “awesome list” collecting Kubernetes learning material, documentation, tutorials, tools, and blog posts.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/@cncf&#34;&gt;CNCF YouTube Channel&lt;/a&gt;: Publishes KubeCon sessions and highlight reels, Cloud Native Live sessions, and short explainers on Kubernetes, GitOps, and policy as code.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://kube.fm/&#34;&gt;KubeFM&lt;/a&gt;: Features expert opinions, success stories, and failure stories about running and scaling Kubernetes in production.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://dok.community/&#34;&gt;Data on Kubernetes Community&lt;/a&gt;: Focuses on running data‑intensive, stateful, and AI/ML workloads on Kubernetes, with content often tied to live sessions and talks.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Engage: Communities, chat, and events&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As you start building and operating clusters, learning from others is one of the fastest ways to increase your knowledge. Here are some great places to do just that.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Forums and Q&amp;amp;A&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Reddit: &lt;a href=&#34;https://www.reddit.com/r/kubernetes/&#34;&gt;/r/kubernetes/&lt;/a&gt; and &lt;a href=&#34;https://www.reddit.com/r/devops/&#34;&gt;/r/devops/&lt;/a&gt; are best for architecture debates and quick Q&amp;amp;A.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;X (formerly Twitter): &lt;a href=&#34;https://x.com/kubernetesio&#34;&gt;@kubernetesio&lt;/a&gt; and &lt;a href=&#34;https://x.com/learnk8s&#34;&gt;@learnk8s&lt;/a&gt; are great Kubernetes resources.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Bluesky: &lt;a href=&#34;https://bsky.app/profile/kelseyhightower.com&#34;&gt;@kelseyhightower.com&lt;/a&gt; and &lt;a href=&#34;https://bsky.app/profile/cncf.io&#34;&gt;@cncf.io&lt;/a&gt; are active and informative accounts.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Real‑time chat&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Discord: &lt;a href=&#34;https://k8s-at-home.com/&#34;&gt;Kubernetes @ Home&lt;/a&gt; and &lt;a href=&#34;https://discord.com/invite/3F5nvYK&#34;&gt;k8s/openshift&lt;/a&gt; host active discussions around best practices, home‑lab experimentation, cluster configuration, and troubleshooting.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Slack: &lt;a href=&#34;https://slack.cncf.io/&#34;&gt;CNCF Slack&lt;/a&gt; for project/SIG chatter, &lt;a href=&#34;https://www.devopschat.co/community/register&#34;&gt;DevOpsChat&lt;/a&gt; for broader DevOps/SRE, and &lt;a href=&#34;https://fairwindscommunity.slack.com/join/shared_invite/zt-3ki8tr7tv-rLECXXzthoD4L7bDVxVzpg#/shared-invite/email&#34;&gt;Fairwinds OSS Community&lt;/a&gt; for Kubernetes governance and cost topics.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Meetups and events&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.meetup.com/topics/kubernetes/&#34;&gt;Kubernetes Meetups&lt;/a&gt;: Local Cloud Native, DevOps, and Kubernetes meetups around the world that host talks, lightning sessions, and social gatherings. Find one near you!&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cncf.io/kcds/&#34;&gt;Kubernetes Community Days (KCDs)&lt;/a&gt;: Regional, community‑run conferences supported by the CNCF that often include dedicated sessions on AI/ML platforms, data on Kubernetes, platform engineering, MLOps, and more.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://events.linuxfoundation.org/about/calendar/?_sft_lfevent-category=kubecon-cloudnativecon-cncf-events&#34;&gt;KubeCon + CloudNativeCon&lt;/a&gt;: The flagship CNCF events, with hundreds of Kubernetes and Cloud Native sessions, most of which are also later available on YouTube.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Deepen your Kubernetes expertise&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you’re interested in hard‑won expertise on security, cost optimization, and guardrails, you can also explore our library of resources. These focus on practical, production‑grade Kubernetes operations and governance.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.fairwinds.com/kubernetes-security-add-on-management&#34;&gt;eBook: How to Build Better Cluster Security Through Smart Add-On Management&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.fairwinds.com/blog/ai-cloud-native-managing-kubernetes-platform&#34;&gt;Blog: AI Runs Best On Cloud Native—But Who’s Managing the Kubernetes Platform?&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.fairwinds.com/ebook-lessons-learned-from-a-decade-of-managing-k8s&#34;&gt;eBook: Lessons Learned from a Decade of Managing K8s&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.fairwinds.com/blog/benefits-open-source-idp-design-aws&#34;&gt;Blog: The Benefits of Using an Open Source IDP Design On AWS&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you’d rather focus on your building and refining your applications than on cluster upgrades, add‑ons, and security patching, &lt;a href=&#34;https://calendly.com/melissa-fairwinds/30min?__hstc=91154437.4224623da34aa179dfa3b327a9c02dfb.1763141925180.1764879758103.1764881854680.8&amp;amp;__hssc=91154437.1.1764959517974&amp;amp;__hsfp=3440324983&amp;amp;hsCtaTracking=a849dc40-48e5-423e-9ef4-d3a89514017c%7Cacea6f44-9875-48e7-a0e8-09347c53b443&amp;amp;month=2025-12&#34;&gt;talk with us&lt;/a&gt; about Managed Kubernetes‑as‑a‑Service for your mission‑critical workloads.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;云原生社区正在蓬勃发展，Kubernetes 与之有很大关系。在这个开源生态系统中，从业者不断分享知识、工具和从第一手经验中吸取的教训，以帮助他人取得成功。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;无论您的目标是学习基础知识、了解最新版本和模式、构建内部开发人员平台 (IDP)，还是在 Kubernetes 上运行人工智能 (AI)/机器学习 (ML) 工作负载，这里提供的资源比任何人都可能跟上的要多。本指南专为刚刚接触 Kubernetes 或已经在生产环境中部署和维护工作负载的工程师而设计。这是一组精心策划的持久、高信号场所，可供聆听、观看和讨论 K8 和云原生生态系统的不同方面，从基础知识到高级操作和社区资源。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;从基础知识开始&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您是新手，请先完成基础知识和实验，然后再担心考试或收听播客。在您接触集群之前，这些会构建基本的心理模型和词汇。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/tutorials/&#34;&gt;Kubernetes 基础知识（官方教程）&lt;/a&gt;：项目维护人员提供的交互式浏览器内教程，可引导您完成核心概念和简单的实验。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.udemy.com/course/kubernetes-getting-started/&#34;&gt;Kubernetes 课程 (Udemy)&lt;/a&gt;：这是一门简短的结构化视频课程，如果您喜欢讲师指导的形式，可以强化基础知识。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;进入实践实验室和沙盒&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;一旦核心想法有意义，就可以在安全、一次性的环境中练习真正的命令。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://training.play-with-kubernetes.com/kubernetes-workshop/&#34;&gt;玩转 Kubernetes&lt;/a&gt;：一个基于浏览器的免费游乐场，可让您启动临时集群并进行实验，而无需在本地安装任何内容。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://killercoda.com/playgrounds/scenario/kubernetes&#34;&gt;Killercoda Kubernetes 场景&lt;/a&gt;：一个交互式实验室平台，具有浏览器终端和指导性 Kubernetes 场景，涵盖 Pod、部署、服务、网络和故障排除。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://kodekloud.com/studio/labs/kubernetes?ref=kodekloud.com&#34;&gt;KodeKloud Kubernetes 实验室&lt;/a&gt;：实践实验室和游乐场，包括&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://training.linuxfoundation.org/certification/certified-kubernetes-administrator-cka/&#34;&gt;认证 Kubernetes 管理员 (CKA)&lt;/a&gt;、&lt;a href=&#34;https://training.linuxfoundation.org/certification/certified-kubernetes-application-developer-ckad/&#34;&gt;认证 Kubernetes 应用开发人员 (CKAD)&lt;/a&gt;、&lt;a href=&#34;https://training.linuxfoundation.org/certification/certified-kubernetes-security-specialist/&#34;&gt;认证 Kubernetes 安全专家 (CKS)&lt;/a&gt;‑一致的环境，以便您可以在真实的集群中尝试真实的命令。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;探索学习路线图、指南和考试&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这些可以帮助您选择接下来要学习的内容，而不是在主题之间随机切换。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://roadmap.sh/kubernetes&#34;&gt;Kubernetes 路线图&lt;/a&gt;：社区维护的可视化路线图，列出了从基础知识到安全性、可观察性和网络等高级领域的主题。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://devopscube.com/learn-kubernetes-complete-roadmap/&#34;&gt;2025 年如何学习 Kubernetes&lt;/a&gt;：分步指南，建议核心概念、实验和补充工具的顺序，以便您可以制定连贯的自学计划。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;CKA/CKAD/CKS：CNCF 考试课程和手册，定义了每个认证的领域和能力，并兼作技能清单。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;及时了解播客&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;使用它们来强化概念并在通勤或环境切换时听到现实世界的故事。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://kubernetespodcast.com/&#34;&gt;Google 的 Kubernetes 播客&lt;/a&gt;：一个长期播出的节目，包含来自 Kubernetes 社区的嘉宾见解以及来自最新版本和活动的新闻和评论。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://podcasts.apple.com/us/podcast/kubernetes-bytes/id1580068566&#34;&gt;Kubernetes Bytes&lt;/a&gt;：专注于 Kubernetes 和云原生主题，经常深入探讨平台工程、运营和生态系统项目。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://packetpushers.net/podcast/day-two-devops/&#34;&gt;第二天 DevOps&lt;/a&gt;：与技术领导者就现代 DevOps 进行对话，涵盖自动化、安全、网络和第二天关注的问题。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.softwaredefinetalk.com/episodes&#34;&gt;软件定义讲座&lt;/a&gt;：更广泛的企业软件和云展示，其中 Kubernetes、DevOps、无服务器和安全性是常见主题。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://podcasts.apple.com/us/podcast/open-source-data/id1530428904&#34;&gt;开放||源||数据&lt;/a&gt;：通过与开发者、监管机构和学者的对话探索开源数据、软件和人工智能，这对于数据量大的 K8s 工作负载非常有用。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://podcast.bretfisher.com/&#34;&gt;DevOps 和 Docker Talk&lt;/a&gt;：涵盖 DevOps、云管理、系统管理主题以及 Docker、Kubernetes 和 Swarm 等容器工具。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.buzzsprout.com/1010419&#34;&gt;Deep Edge 播客&lt;/a&gt;：讨论支持更高级的边缘 Kubernetes 使用案例的云原生和网络技术。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://feeder.co/discover/184933d887/cncf-io&#34;&gt;云原生工程&lt;/a&gt;：聚合整个云原生生态系统的新闻、事件和深入研究，频繁报道 Kubernetes 和相关 CNCF 项目。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;探索精选列表、视频和高级主题&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;一旦您感到舒适，这些资源将帮助您扩展到生产实践和专门的工作负载。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/ramitsurana/awesome-kubernetes&#34;&gt;Awesome Kubernetes&lt;/a&gt;：长期策划的“很棒列表”，收集 Kubernetes 学习材料、文档、教程、工具和博客文章。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/@cncf&#34;&gt;CNCF YouTube 频道&lt;/a&gt;：发布 KubeCon 会议和精彩片段、云原生直播会议以及有关 Kubernetes、GitOps 和政策即代码的简短说明。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://kube.fm/&#34;&gt;KubeFM&lt;/a&gt;：提供有关在生产中运行和扩展 Kubernetes 的专家意见、成功案例和失败案例。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://dok.community/&#34;&gt;Kubernetes 社区数据&lt;/a&gt;：专注于在 Kubernetes 上运行数据密集型、有状态的 AI/ML 工作负载，内容通常与实时会话和演讲相关。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;参与：社区、聊天和活动&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;当您开始构建和运营集群时，向他人学习是增加知识的最快方法之一。这里有一些很棒的地方可以做到这一点。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;论坛和问答&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;Reddit：&lt;a href=&#34;https://www.reddit.com/r/kubernetes/&#34;&gt;/r/kubernetes/&lt;/a&gt; 和 &lt;a href=&#34;https://www.reddit.com/r/devops/&#34;&gt;/r/devops/&lt;/a&gt; 最适合架构辩论和快速问答。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;X（以前称为 Twitter）：&lt;a href=&#34;https://x.com/kubernetesio&#34;&gt;@kubernetesio&lt;/a&gt; 和 &lt;a href=&#34;https://x.com/learnk8s&#34;&gt;@learnk8s&lt;/a&gt; 是很棒的 Kubernetes 资源。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Bluesky：&lt;a href=&#34;https://bsky.app/profile/kelseyhightower.com&#34;&gt;@kelseyhightower.com&lt;/a&gt; 和 &lt;a href=&#34;https://bsky.app/profile/cncf.io&#34;&gt;@cncf.io&lt;/a&gt; 是活跃且信息丰富的帐户。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;实时聊天&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;Discord：&lt;a href=&#34;https://k8s-at-home.com/&#34;&gt;Kubernetes @ Home&lt;/a&gt; 和 &lt;a href=&#34;https://discord.com/invite/3F5nvYK&#34;&gt;k8s/openshift&lt;/a&gt; 围绕最佳实践、家庭实验室实验、集群配置和故障排除进行积极讨论。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Slack：&lt;a href=&#34;https://slack.cncf.io/&#34;&gt;CNCF Slack&lt;/a&gt; 用于项目/SIG 聊天，&lt;a href=&#34;https://www.devopschat.co/community/register&#34;&gt;DevOpsChat&lt;/a&gt; 用于更广泛的 DevOps/SRE，&lt;a href=&#34;https://fairwindscommunity.slack.com/join/shared_invite/zt-3ki8tr7tv-rLECXXzthoD4L7bDVxVzpg#/shared-invite/email&#34;&gt;Fairwinds OSS 社区&lt;/a&gt;，了解 Kubernetes 治理和成本主题。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;聚会和活动&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.meetup.com/topics/kubernetes/&#34;&gt;Kubernetes 聚会&lt;/a&gt;：世界各地的本地云原生、DevOps 和 Kubernetes 聚会，举办演讲、闪电会议和社交聚会。寻找您附近的一个！&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cncf.io/kcds/&#34;&gt;库布ernetes 社区日 (KCD)&lt;/a&gt;：由 CNCF 支持的区域性社区会议，通常包括有关 AI/ML 平台、Kubernetes 数据、平台工程、MLOps 等的专门会议。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://events.linuxfoundation.org/about/calendar/?_sft_lfevent-category=kubecon-cloudnativecon-cncf-events&#34;&gt;KubeCon + CloudNativeCon&lt;/a&gt;：旗舰 CNCF 活动，举办数百场 Kubernetes 和云原生会议，其中大部分会议稍后还可在 YouTube 上观看。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;加深您的 Kubernetes 专业知识&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您对安全、成本优化和护栏方面来之不易的专业知识感兴趣，您还可以探索我们的资源库。这些重点关注实用的生产级 Kubernetes 操作和治理。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.fairwinds.com/kubernetes-security-add-on-management&#34;&gt;电子书：如何通过智能附加组件管理构建更好的集群安全性&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.fairwinds.com/blog/ai-cloud-native-managing-kubernetes-platform&#34;&gt;博客：人工智能在云原生上运行最佳 - 但谁在管理 Kubernetes 平台？&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.fairwinds.com/ebook-lessons-learned-from-a-decade-of-managing-k8s&#34;&gt;电子书：管理 K8 十年的经验教训&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.fairwinds.com/blog/benefits-open-source-idp-design-aws&#34;&gt;博客：在 AWS 上使用开源 IDP 设计的优势&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您更愿意专注于构建和完善应用程序而不是集群升级、附加组件和安全修补，&lt;a href=&#34;https://calendly.com/melissa-fairwinds/30min?__hstc=91154437.4224623da34aa179dfa3b327a9c02dfb.1763141925180.1764879758103.1764881854680.8&amp;__hssc= 91154437.1.1764959517974&amp;__hsfp=3440324983&amp;hsCtaTracking=a849dc40-48e5-423e- 9ef4-d3a89514017c%7Cacea6f44-9875-48e7-a0e8-09347c53b443&amp;month=2025-12&#34;&gt;谈话与我们联系&lt;/a&gt;了解适用于您的任务关键型工作负载的托管 Kubernetes 即服务。&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Sun, 18 Jan 2026 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【CRI-O completes second OSTIF audit】CRI-O 完成第二次 OSTIF 审核</title>
      <link>https://www.cncf.io/blog/2026/01/16/cri-o-completes-second-ostif-audit/</link>
      <description>【&lt;p&gt;The &lt;strong&gt;Open Source Technology Improvement Fund&lt;/strong&gt; is proud to share the results of our security audit of &lt;a href=&#34;https://cri-o.io/&#34;&gt;&lt;strong&gt;CRI-O&lt;/strong&gt;&lt;/a&gt;. CRI-O is an implementation of the &lt;a href=&#34;https://kubernetes.io/&#34;&gt;Kubernetes&lt;/a&gt; Container Runtime Interface (CRI) that is OCI-compliant (-O) that provides the backend between OCI-format container images and the Kubernetes control plane. With the help of &lt;a href=&#34;https://x41-dsec.de/&#34;&gt;&lt;strong&gt;X41 D-Sec&lt;/strong&gt;&lt;/a&gt; and the &lt;a href=&#34;https://www.cncf.io/&#34;&gt;&lt;strong&gt;Cloud Native Computing Foundation&lt;/strong&gt;&lt;/a&gt; (CNCF), CRI-O completed their &lt;a href=&#34;https://ostif.org/our-audit-of-cri-o-is-complete-high-severity-issues-found-and-fixed/&#34;&gt;second security audit with OSTIF&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Audit Process&lt;/strong&gt;:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This security engagement took place in late fall of 2025, performed by an audit team from X41. By manually reviewing the source code from the CRI-O public repository, with additional support from static analysis tooling, the auditors were able to evaluate the security health of the project. In paying particular attention to package dependencies, the sandbox implementation, fuzzing integration, DoS vectors, and image verification processes, the auditors inspected the project for multiple security concerns relevant to the functionality of the project .&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Audit Results&lt;/strong&gt;:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;2 Findings&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;2 Informational&amp;nbsp;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Further Security Work Recommendations&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The auditor’s report describes the CRI-O code as “well-designed and effectively executed, striking a sound balance between minimalism and practical robustness.” There were two findings with security impact identified by this engagement, and while they are ranked to be Informational findings, the report urges robust and automated security best practices to help runtime and reliability.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Thank you&lt;/strong&gt; to the individuals and groups that made this engagement possible:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;CRI-O maintainers and community, especially: Peter Hunt and Sascha Grunert&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;X41 D-Sec, especially: Markus Vervier, Eric Sesterhenn, Alexander Schloegl, Christian Mayr, Hannes Moesl-Canaval, and Antonela Conti&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;The CNCF&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;You can read the Audit Report &lt;a href=&#34;https://ostif.org/wp-content/uploads/2026/01/X41-OSTIF-CRI-O-Audit-Public-Report-2025-12-03.pdf&#34;&gt;&lt;strong&gt;HERE&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;You can read X41’s Blog &lt;a href=&#34;https://x41-dsec.de/security/research/job/news/2026/01/13/cri-o/&#34;&gt;&lt;strong&gt;HERE&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;strong&gt;开源技术改进基金&lt;/strong&gt;很自豪地分享我们对 &lt;a href=&#34;https://cri-o.io/&#34;&gt;&lt;strong&gt;CRI-O&lt;/strong&gt;&lt;/a&gt; 的安全审计结果。 CRI-O 是 &lt;a href=&#34;https://kubernetes.io/&#34;&gt;Kubernetes&lt;/a&gt; 容器运行时接口 (CRI) 的实现，它符合 OCI 标准 (-O)，提供 OCI 格式容器映像和 Kubernetes 控制平面之间的后端。在 &lt;a href=&#34;https://x41-dsec.de/&#34;&gt;&lt;strong&gt;X41 D-Sec&lt;/strong&gt;&lt;/a&gt; 和&lt;a href=&#34;https://www.cncf.io/&#34;&gt;&lt;strong&gt;云原生计算基金会&lt;/strong&gt;&lt;/a&gt; (CNCF) 的帮助下，CRI-O 完成了他们的&lt;a href=&#34;https://ostif.org/our-audit-of-cri-o-is-complete-high-severity-issues-found-and-fixed/&#34;&gt;OSTIF 进行第二次安全审核&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;审核流程&lt;/strong&gt;：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;此次安全活动于 2025 年秋末进行，由 X41 的审计团队执行。通过手动审查 CRI-O 公共存储库中的源代码，并借助静态分析工具的额外支持，审计人员能够评估项目的安全健康状况。审计人员特别关注包依赖性、沙箱实现、模糊集成、DoS 向量和图像验证过程，检查了项目是否存在与项目功能相关的多个安全问题。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;审核结果&lt;/strong&gt;：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;2 项调查结果&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;2 信息性&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;进一步的安全工作建议&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;审计报告将 CRI-O 代码描述为“精心设计且有效执行，在极简主义和实用稳健性之间取得了良好的平衡。”这次活动确定了两项具有安全影响的调查结果，虽然它们被列为信息性调查结果，但该报告敦促强大的自动化安全最佳实践来帮助运行时间和可靠性。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;感谢&lt;/strong&gt;促成此次参与的个人和团体：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;CRI-O 维护者和社区，尤其是：Peter Hunt 和 Sascha Grunert&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;X41 D-Sec，尤其是：Markus Vervier、Eric Sesterhenn、Alexander Schloegl、Christian Mayr、Hannes Moesl-Canaval 和 Antonela Conti&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;CNCF&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;您可以&lt;a href=&#34;https://ostif.org/wp-content/uploads/2026/01/X41-OSTIF-CRI-O-Audit-Public-Report-2025-12-03.pdf&#34;&gt;&lt;strong&gt;此处&lt;/strong&gt;&lt;/a&gt;阅读审核报告&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;您可以阅读 X41 的博客&lt;a href=&#34;https://x41-dsec.de/security/research/job/news/2026/01/13/cri-o/&#34;&gt;&lt;strong&gt;此处&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Thu, 15 Jan 2026 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【KubeCon + CloudNativeCon NA: Top sessions from the CNCF End User TAB】KubeCon + CloudNativeCon NA：CNCF 最终用户 TAB 的热门会议</title>
      <link>https://www.cncf.io/blog/2026/01/15/kubecon-cloudnativecon-na-top-sessions-from-the-cncf-end-user-tab/</link>
      <description>【&lt;p&gt;2025 brought significant developments in the cloud native landscape, with a strong focus on AI but new projects and end user reports in many other areas. As always, KubeCon is one of the key places we see the progress coming from project reports, end users showcasing their stacks and use cases or vendors in the sponsor hall.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In this blog post, we start 2026 with a look back at the latest KubeCon+ CloudNativeCon North America in Atlanta, highlighting selected sessions from members of the &lt;a href=&#34;https://www.cncf.io/people/end-user-technical-advisory-board/&#34;&gt;CNCF End User Technical Advisory Board (TAB).&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Alolita Sharma&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;So many interesting sessions make it hard to short-list my favorite talks 😀 Talks that made it to my list included:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Session Title: &lt;/strong&gt;Benchmarking GenAI Foundation Model Inference Optimizations on Kubernetes&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;“&lt;/strong&gt;Minimizing inference costs for LLM deployments is a critical component of cost observability, cost management and infra capacity management for all organizations operating inference pipelines. Speakers Sachin Mathew Varghese of Capital One and Brendan Slabe of Google focused this talk on optimization techniques to measure and benchmarked inference performance in a standardized way and walked through a Kubernetes SIG project to benchmark GenAI foundation model inference.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Session Title:&lt;/strong&gt; Discover Cortex: High Scalability Metrics in 2025&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“Cortex is a key technology in the CNCF observability project ecosystem which provides a highly scalable, multi-tenant storage solution for OpenTelemetry and Prometheus metrics observability. This maintainer talk by Friedrich Gonzalez, Charlie Le and Alolita Sharma from Apple and Anand Rajagopal from AWS zoomed in on key features in Release 1.19, what’s next on the project roadmap and community.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Session Title: &lt;/strong&gt;Project Lightning Talk: Perses: Update&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“Perses is an exciting sandbox project for observability visualization to watch out for in the cloud-native observability landscape. Core maintainer Augustin Husson provided a progress update about new features and community growth in this session.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Session Title: &lt;/strong&gt;Retrofitting OTEL Collectors &amp;amp; Prometheus – How To Overcome Scale/Design Limitations&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“Scaling observability data collection is key to handling trace span cardinality from Kubernetes clusters across multiple regions. Using multiple OpenTelemetry connectors and processors for each Collector and yet maintaining an efficient memory footprint is more art than science.This session, by Vijay Samuel and Sandeep Raveesh of EBay, explored some solutions to achieve this optimization leveraging long-term retention examples.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Chad Beaudin&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Session Title&lt;/strong&gt;: Maintainers Summit&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&amp;nbsp;“Yes, I know this is a bit of a cheat since it wasn’t a session.&amp;nbsp; However, this was my first time attending the Maintainers Summit and it was an exciting experience.&amp;nbsp; Hearing the conversations from the maintainer community on things they liked, and more importantly, the struggles they were dealing with was great.&amp;nbsp; Additionally, the famous Hallway Track was a lot of fun just getting to meet the various project maintainers.&amp;nbsp;Lots of passion all around.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Kenta Tada&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;KubeCon + CloudNativeCon North America 2025 presented a compelling lineup of sessions tackling the evolving challenges of networking, runtime customization, and long-term sustainability in large-scale cloud-native environments. As Kubernetes operations mature, themes such as IPv6 adoption, runtime extensibility, and Long-Term Support (LTS) are becoming pivotal for scalability, reliability, and operational resilience. The following three sessions stood out as particularly valuable for end‑user practitioners and platform engineers:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Session Title: &lt;/strong&gt;TikTok’s IPv6 Journey To Cilium: Pitfalls and Lessons Learned&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“Migrating to IPv6‑only environments is a milestone for hyperscale operators, and TikTok’s move to Cilium provides a rare, first-hand look at this transformation. This session detailed the technical journey of deploying Cilium on IPv6‑only Kubernetes clusters, highlighting pitfalls and engineering workarounds that enabled production readiness. Attendees gained insights into debugging Cilium network policies, handling IPv6‑specific DNS and NDP traffic behaviors, and overcoming kernel‑level challenges such as NodePort timeouts — essential knowledge for teams modernizing their networking stack.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Session Title: &lt;/strong&gt;Container Runtime Customization at Netflix: A Case Study With NRI and OCI Hooks&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“Runtime extensibility remains one of the most powerful yet underexplored aspects of Kubernetes operations. In this case study, Netflix engineers revealed how they evolved *Titus*, their global-scale container platform, by integrating ContainerD’s Node Resource Interface (NRI) and OCI hooks to support complex, specialized workloads—while preserving Kubernetes compatibility. The session offered an&amp;nbsp; inside view of custom lifecycle management, network and storage adaptations, and sidecar orchestration at scale. This was essential for platform teams building or maintaining custom runtime layers and seeking the balance between flexibility and standardization.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Session Title: &lt;/strong&gt;Shaping LTS Together: What We’ve Learned the Hard Way&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“As Kubernetes penetrates regulated and mission‑critical environments, LTS is emerging as a key concern for platform teams and vendors. This cross‑vendor panel gathered members to share operational lessons from maintaining Kubernetes over extended timelines. Discussions covered defining LTS scope (security vs. stability), managing upgrade paths, aligning dependencies, and fostering ecosystem coordination. For attendees tasked with maintaining clusters beyond the upstream support window—or interested in the future of Kubernetes lifecycle management—this was a strategic session.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Ricardo Rocha&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Session Title&lt;/strong&gt;: Benchmarking GenAI Foundation Model Inference Optimizations on Kubernetes&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“Model inference is slowly becoming a possible bottleneck in many environments. Consistent benchmarking is a key part to optimize all the different components and layers involved, this is an effort worth following. This was one of many sessions in this KubeCon + CloudNativeCon around inference optimization which helpedl end users struggling in this area.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Session Title: &lt;/strong&gt;Slurm Bridge: Slurm Scheduling Superpowers in Kubernetes&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“In the age of the GPU, interfacing cloud native environments (on-premises and public cloud) with existing supercomputers and other HPC environments is becoming essential. This effort comes from SchedMD, the company behind SLURM, making it worth following.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Session Title:&lt;/strong&gt; DRA is GA! Kubernetes WG Device Management – GPUs, TPUs, NICs and More With DRA&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;“&lt;/strong&gt;DRA will be key to interface new generation accelerators and other specialized environments with the cloud native infrastructures we all have become used to. Extremely happy to see this in GA and great to see all the updates and developments.”&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Session Title: &lt;/strong&gt;Managing a Million Infra Resources at Spotify: Designing the Platform To Manage Change at Scale&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“Spotify is a previous winner of the Top End User award and has always been one of the key end users in our community, also bringing forwards new tools such as Backstage. Listening to how changes are managed at their scale helped everyone, no matter the size of the deployment.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Joseph Sandoval&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Session Title:&lt;/strong&gt; Evolving Kubernetes Scheduling &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://kccncna2025.sched.com/event/27FeY/evolving-kubernetes-scheduling-eric-tune-wojciech-tyczynski-google&#34;&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;”&lt;/strong&gt;The scheduler is where the rubber meets the road for AI/ML on Kubernetes. Right now, teams are cobbling together third-party extensions to make GPU workloads actually work: managing gang scheduling, topology awareness, pre-emption policies. Tune and Tyczyński are core contributors who show the community’s roadmap for moving this functionality upstream. The key insight from the talk: “The Kubernetes scheduler is designed to schedule one pod on one node at a time, and we now need it to schedule groups of pods on groups of nodes at a time.” That fundamental architectural shift is what separates batch/ML workloads from the microservices patterns K8s was built for, and signals where the community is investing to make Kubernetes the invisible substrate for AI workloads.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;br&gt;&lt;strong&gt;Session Title:&lt;/strong&gt; Keynote: Supply Chain Reaction: A Cautionary Tale in K8s Security &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://kccncna2025.sched.com/event/27HSy/keynote-supply-chain-reaction-a-cautionary-tale-in-k8s-security-stacey-potter-manager-of-community-openssf-adolfo-garcia-veytia-founder-and-engineer-carabiner-systems&#34;&gt;&lt;br&gt;&lt;/a&gt;“Supply chain attacks are the nightmare scenario because your cluster passes every security scan while the build pipeline itself is compromised. Stacey and Adolfo ditched the standard slide deck for a live skit that dramatized exactly how this happens: an engineer watches helplessly as cryptomining malware spreads through their secure cluster. Firewalls worked. mTLS was configured correctly. Vulnerability scanners came back clean. None of it mattered because the compiler itself was tainted. The theatrical format worked because it made the abstract threat tangible and kept you engaged through what could have been another dry security talk. Their demonstration of the OSPS Baseline with Sigstore, SLSA attestation, and gittuf shows the defensive playbook: verify provenance at every step, not just the final artifact. If you’re building platforms that developers trust, this is why supply chain security has moved from a nice-to-have to a table-stakes requirement.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Henrik Blixt&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Session Title:&lt;/strong&gt; The Evolution of Platform APIs in the Age of LLMs &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“As a platform product manager at Intuit this session stood out because it tackled how platform APIs are changing in the era of large language models (LLMs),&amp;nbsp; shifting from rigid definitions toward more dynamic, conversational, and “wizard-style” interactions where devs and automation agents can &lt;em&gt;consume&lt;/em&gt; the platform in new ways, which&amp;nbsp; is highly relevant to me: it highlighted how platform engineering is evolving to offer model-driven interfaces rather than only static APIs, making service consumption, management, and troubleshooting far more intuitive.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Session Title:&amp;nbsp;&lt;/strong&gt; Progressive Configuration Delivery for Zero-Downtime Cloud Workloads &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“Being an Argo maintainer, this session hit a soft spot, because it addressed progressive delivery of configurations (not just code or images), with a CRD-based approach that decouples image versioning from configuration delivery and enables batch/traffic-based rollout of config changes. This kind of capability is directly aligned with our need to manage configuration drift, rollout risk, and seamless service updates . I was thrilled when&amp;nbsp;they detailed&amp;nbsp;how this can reduce the blast radius of config changes across multiple services and clusters, which resonated with many other audience members as well!”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Session Title: &lt;/strong&gt;Creating and Maintaining Ephemeral Runtime Environments for 18,000 Developers &lt;strong&gt;&lt;br&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“This session resonated strongly since it featured a real-world case of scaling ephemeral environments to 18,000 developers, which directly touches on the kind of demand and features we see at Intuit and it aligns with our focus on developer experience and velocity: providing on-demand, isolated, production-like runtime environments supports feature velocity, reduces risk, and improves confidence in deployments.”&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;2025 年云原生领域取得了重大发展，重点关注人工智能，但许多其他领域也出现了新项目和最终用户报告。与往常一样，KubeCon 是我们从项目报告、最终用户展示其堆栈和用例或赞助商大厅中的供应商中看到进展的关键场所之一。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在这篇博文中，我们从 2026 年开始回顾在亚特兰大举行的最新 KubeCon+ CloudNativeCon 北美会议，重点介绍 &lt;a href=&#34;https://www.cncf.io/people/end-user-technical-advisory-board/&#34;&gt;CNCF 最终用户技术咨询委员会 (TAB) 成员的精选会议。&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;阿洛丽塔·夏尔马&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如此多有趣的会议让我很难列出我最喜欢的演讲😀 进入我的列表的演讲包括：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;会议标题：&lt;/strong&gt;在 Kubernetes 上对 GenAI 基础模型推理优化进行基准测试&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;“&lt;/strong&gt;最大限度地降低 LLM 部署的推理成本是所有运行推理管道的组织的成本可观测性、成本管理和基础设施容量管理的关键组成部分。Capital One 的 Sachin Mathew Varghese 和 Google 的 Brendan Slabe 的演讲重点讨论了以标准化方式衡量推理性能和进行基准测试的优化技术，并介绍了一个 Kubernetes SIG 项目来对 GenAI 基础模型推理进行基准测试。”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;会议标题：&lt;/strong&gt;探索 Cortex：2025 年的高可扩展性指标&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“Cortex 是 CNCF 可观测性项目生态系统中的一项关键技术，它为 OpenTelemetry 和 Prometheus 指标可观测性提供了高度可扩展的多租户存储解决方案。来自 Apple 的 Friedrich Gonzalez、Charlie Le 和 Alolita Sharma 以及来自 AWS 的 Anand Rajagopal 的维护者演讲重点介绍了 1.19 版中的关键功能，以及项目路线图和社区的下一步发展。”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;会议标题：&lt;/strong&gt;闪电项目演讲：Perses：更新&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“Perses 是一个令人兴奋的可观测性可视化沙盒项目，在云原生可观测性领域值得关注。核心维护者 Augustin Husson 在本次会议中提供了有关新功能和社区发展的最新进展。”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;会议标题：&lt;/strong&gt;改造 OTEL 收集器和 Prometheus – 如何克服规模/设计限制&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“扩展可观测性数据收集是处理跨多个区域的 Kubernetes 集群的跟踪范围基数的关键。为每个收集器使用多个 OpenTelemetry 连接器和处理器，同时保持高效的内存占用更多的是艺术而不是科学。本次会议由 EBay 的 Vijay Samuel 和 Sandeep Raveesh 主持，探讨了一些解决方案，以利用长期保留示例来实现这种优化。”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;查德·博丁&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;会议标题&lt;/strong&gt;：维护者峰会&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt; “是的，我知道这有点作弊，因为这不是一次会议。  然而，这是我第一次参加维护者峰会，这是一次令人兴奋的经历。  听到维护者社区关于他们喜欢的事情的对话，更重要的是，他们正在处理的斗争是伟大的。  此外，著名的走廊轨道与各个项目维护人员见面也很有趣。 到处充满激情。”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;多田健太&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;KubeCon + CloudNativeCon North America 2025 举办了一系列引人注目的会议，旨在应对大规模云原生环境中不断变化的网络、运行时定制和长期可持续性挑战。随着 Kubernetes 运营的成熟，IPv6 采用、运行时可扩展性和长期支持 (LTS) 等主题正成为可扩展性、可靠性和运营弹性的关键。以下三场会议对于最终用户从业者和平台工程师特别有价值：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;会议标题：&lt;/strong&gt;TikTok 的 IPv6 Cilium 之旅：陷阱和经验教训&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“迁移到纯 IPv6 环境对于超大规模运营商来说是一个里程碑，TikTok 迁移到 Cilium 为我们提供了罕见的第一手资料来了解这一转变。本次会议详细介绍了在纯 IPv6 Kubernetes 集群上部署 Cilium 的技术历程，重点介绍了实现生产准备的陷阱和工程解决方法。与会者深入了解了调试 Cilium 网络策略、处理 IPv6 特定的 DNS 和 NDP 流量行为，以及克服 NodePort 超时等内核级挑战，这些都是团队实现网络堆栈现代化的基本知识。”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;会议标题：&lt;/strong&gt;Netflix 的容器运行时定制：NRI 和 OCI Hook 的案例研究&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“运行时可扩展性仍然是 Kubernetes 操作中最强大但尚未充分开发的方面之一。在本案例研究中，Netflix 工程师揭示了他们如何通过集成 ContainerD 的节点资源接口 (NRI) 和 OCI 挂钩来发展全球规模的容器平台 *Titus*，以支持复杂、专业的工作负载，同时保持 Kubernetes 兼容性。该会议提供了自定义生命周期管理、网络和存储适应以及大规模 sidecar 编排的内部视图。这对于平台团队构建或维护自定义运行时层以及寻求灵活性和标准化之间的平衡至关重要。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;会议标题：&lt;/strong&gt;共同塑造 LTS：我们历经艰辛才学到的东西&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“随着 Kubernetes 渗透到受监管和任务关键型环境中，LTS 正在成为平台团队和供应商的一个主要关注点。这个跨供应商小组聚集了成员，分享长期维护 Kubernetes 的操作经验教训。涵盖的讨论定义 LTS 范围（安全性与稳定性）、管理升级路径、调整依赖关系并促进生态系统协调。对于负责在上游支持窗口之外维护集群的与会者或对 Kubernetes 生命周期管理的未来感兴趣的与会者来说，这是一次战略会议。”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;里卡多·罗查&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;会议标题&lt;/strong&gt;：Kubernetes 上的 GenAI 基础模型推理优化基准测试&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“模型推理正在慢慢成为许多环境中可能的瓶颈。一致的基准测试是优化涉及的所有不同组件和层的关键部分，这是一项值得遵循的努力。这是 KubeCon + CloudNativeCon 中围绕推理优化的众多会议之一，帮助了在该领域苦苦挣扎的最终用户。”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;会议标题：&lt;/strong&gt;Slurm Bridge：Kubernetes 中的 Slurm 调度超级能力&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“在 GPU 时代，云原生环境（本地和公共云）与现有超级计算机和其他 HPC 环境的接口变得至关重要。这项工作来自 SLURM 背后的公司 SchedMD，值得关注。”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;会议标题：&lt;/strong&gt;DRA 正式发布！ Kubernetes WG 设备管理 – GPU、TPU、NIC 等使用 DRA&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;“&lt;/strong&gt;DRA 将成为新一代加速器和其他专业环境与我们都已经习惯的云原生基础设施接口的关键。非常高兴在正式版中看到这一点，也很高兴看到所有的更新和发展。” &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;会议标题：&lt;/strong&gt;管理 Spotify 的百万基础设施资源：设计大规模管理变革的平台&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“Spotify 是顶级最终用户奖的前任获得者，并且一直是我们社区的关键最终用户之一，还带来了 Backstage 等新工具。无论部署规模有多大，了解如何管理大规模的变更对每个人都有帮助。”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;约瑟夫·桑多瓦尔&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;会议标题：&lt;/strong&gt;不断发展的 Kubernetes 调度&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://kccncna2025.sched.com/event/27FeY/evolving-kubernetes-scheduling-eric-tune-wojciech-tyczynski-google&#34;&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;”&lt;/strong&gt;调度程序是 Kubernetes 上 AI/ML 的关键所在。目前，团队正在拼凑第三方扩展，以使 GPU 工作负载真正发挥作用：管理组调度、拓扑感知、抢占策略。 Tune 和 Tyczyński 是核心贡献者，他们展示了社区将该功能向上游推进的路线图。演讲的主要见解是：“Kubernetes 调度程序旨在一次在一个节点上调度一个 pod，而我们现在需要它一次在一组节点上调度一组 pod。”这种基本的架构转变是将批处理/机器学习工作负载与微型工作负载区分开来的。K8s 专为服务模式而构建，并表明社区正在投资哪些领域，以使 Kubernetes 成为人工智能工作负载的隐形基础。”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;br&gt;&lt;strong&gt;会议标题：&lt;/strong&gt;主题演讲：供应链反应：K8s 安全性的警示故事&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://kccncna2025.sched.com/event/27HSy/keynote-supply-chain-reaction-a-cautionary-tale-in-k8s-security-stacey-potter-manager-of-community-openssf-adolfo-garcia-veytia-Founder-and-engineer-carabiner-systems&#34;&gt;&lt;br&gt;&lt;/a&gt;“供应链攻击是一场噩梦，因为您的集群通过了每次安全扫描，而构建管道本身却受到了损害。史黛西和阿道夫放弃了标准的幻灯片，转而制作了一个现场短剧，戏剧化地描述了这种情况的发生：一名工程师无助地看着加密货币挖矿恶意软件在他们的安全集群中传播。防火墙起作用了。 mTLS 配置正确。漏洞扫描仪恢复正常。这些都不重要，因为编译器本身就被污染了。戏剧形式之所以有效，是因为它使抽象的威胁变得有形，并让你参与到可能是另一场枯燥的安全谈话中。他们使用 Sigstore、SLSA 证明和 gittuf 演示了 OSPS 基线，展示了防御策略：验证每一步的出处，而不仅仅是最终的工件。如果您正在构建开发人员信任的平台，这就是为什么供应链安全已从“可有可无”转变为“赌注”要求。”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;亨里克·布利克特&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;会议标题：&lt;/strong&gt;法学硕士时代平台 API 的演变&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“作为 Intuit 的平台产品经理，本次会议之所以脱颖而出，是因为它讨论了平台 API 在大型语言模型 (LLM) 时代的变化，从严格的定义转向更加动态、对话式和“向导式”的交互，开发人员和自动化代理可以以新的方式&lt;em&gt;使用&lt;/em&gt;平台，这与我高度相关：它强调了平台工程如何发展为提供模型驱动的接口而不仅仅是静态 API，从而使服务消费、管理和故障排除更加直观。”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;会议标题：&lt;/strong&gt;零停机云工作负载的渐进式配置交付&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“作为 Argo 维护者，本次会议触及了一个软肋，因为它解决了配置（不仅仅是代码或图像）的渐进式交付问题，采用基于 CRD 的方法将图像版本控制与配置交付分离，并支持基于批量/流量的配置更改推出。这种功能直接满足我们管理配置漂移、部署风险和无缝服务更新的需求。当他们详细介绍这如何减少跨多个服务和集群的配置更改的影响范围时，我感到很兴奋，这也引起了许多其他观众的共鸣！”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;会议标题：&lt;/strong&gt;为 18,000 名开发人员创建和维护临时运行时环境&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“本次会议引起了强烈反响，因为它介绍了将临时环境扩展到 18,000 名开发人员的真实案例，这直接触及了我们在 Intuit 看到的需求和功能，并且与我们对开发人员体验和速度的关注相一致：提供按需、隔离、类似生产的运行时环境支持功能速度、降低风险并提高部署信心。”&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Wed, 14 Jan 2026 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【The symbiotic revolution: AI and cloud native technologies transforming the digital landscape】共生革命：人工智能和云原生技术改变数字格局</title>
      <link>https://www.cncf.io/blog/2026/01/13/the-symbiotic-revolution-ai-and-cloud-native-technologies-transforming-the-digital-landscape/</link>
      <description>【&lt;p&gt;&lt;em&gt;This Ambassador Blog was originally published on the writer’s blog and is republished here with permission.&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1195&#34; height=&#34;675&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2026/01/AI-and-Kubernetes-1195x675-1.jpg&#34; alt=&#34;AI and Kubernetes handshake&#34; class=&#34;wp-image-154928&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2026/01/AI-and-Kubernetes-1195x675-1.jpg 1195w, https://www.cncf.io/wp-content/uploads/2026/01/AI-and-Kubernetes-1195x675-1-300x169.jpg 300w, https://www.cncf.io/wp-content/uploads/2026/01/AI-and-Kubernetes-1195x675-1-1024x578.jpg 1024w, https://www.cncf.io/wp-content/uploads/2026/01/AI-and-Kubernetes-1195x675-1-768x434.jpg 768w, https://www.cncf.io/wp-content/uploads/2026/01/AI-and-Kubernetes-1195x675-1-900x508.jpg 900w, https://www.cncf.io/wp-content/uploads/2026/01/AI-and-Kubernetes-1195x675-1-354x200.jpg 354w, https://www.cncf.io/wp-content/uploads/2026/01/AI-and-Kubernetes-1195x675-1-708x400.jpg 708w&#34; sizes=&#34;auto, (max-width: 1195px) 100vw, 1195px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In the ever-evolving world of technology, few pairings have sparked as much innovation as the intersection of artificial intelligence (AI) and cloud native architectures. Cloud native technologies, built around containers, microservices, and orchestration tools like Kubernetes, emphasize scalability, resilience, and agility. Meanwhile, AI—encompassing machine learning (ML), deep learning, and generative models—drives intelligent automation and data-driven insights. As we approach 2026, this synergy is reshaping how organizations deploy, manage, and optimize workloads. In this blog post, we’ll explore how AI is revolutionizing cloud native workloads, the benefits AI brings to cloud native environments, and how AI itself gains from powerhouse tools like Kubernetes. We’ll also dive into real-world use cases that illustrate this transformative relationship.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;How AI is Influencing and Changing Cloud Native Workloads&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Cloud native workloads traditionally involve containerized applications orchestrated across distributed systems, but AI is injecting intelligence into these processes, making them more adaptive and efficient. At its core, AI influences workloads by enabling predictive analytics, automated optimization, and dynamic resource allocation.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;One key change is the shift from static to AI-driven scaling. Traditional cloud native setups rely on rule-based autoscaling, but AI models can predict demand spikes using historical data, optimizing resource usage in real-time. For instance, AI workloads demand massive computational power, often involving GPUs, and cloud native designs ensure these resources scale seamlessly without overprovisioning. This evolution turns rigid infrastructures into flexible, self-healing systems.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;AI is also altering workload development cycles. Generative AI tools streamline DevOps by automating code generation, testing, and security checks in cloud native applications. In AI-native infrastructures, workloads become more resilient to failures, with AI detecting anomalies and rerouting tasks proactively. This not only reduces downtime but also lowers costs by minimizing idle resources.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Moreover, AI is pushing cloud native workloads toward edge computing and hybrid environments. By processing data closer to the source, AI-enhanced workloads handle real-time applications like IoT analytics more effectively, blurring the lines between cloud and on-premises setups. Overall, AI is transforming cloud native workloads from mere scalable containers into intelligent, proactive ecosystems that anticipate needs and adapt instantaneously.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;How Cloud Native Environments Benefit from AI&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The benefits flow both ways: cloud native environments, characterized by their modularity and portability, are supercharged by AI integration. This results in enhanced efficiency, security, and innovation across the board.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;AI optimizes resource management in cloud native setups. By analyzing usage patterns, AI algorithms enable predictive scaling, reducing waste and ensuring cost-efficiency. For example, in hybrid cloud environments, AI provides insights that improve application performance and resource allocation, leading to faster decision-making. This is particularly valuable for handling variable workloads, where AI can dynamically provision resources in response to changes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Security and resilience also see massive gains. AI-powered tools detect threats in real-time within containerized environments, automating responses to vulnerabilities. Collaboration across teams improves as AI fosters agility and cost savings, allowing developers to focus on innovation rather than maintenance. In AI-native applications, this translates to personalized user experiences and faster deployment cycles.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Additionally, cloud native environments benefit from AI’s ability to handle massive data volumes. Scalability becomes effortless, with AI enabling remote access and global collaboration in development. The cloud’s flexibility for AI training and deployment overcomes barriers like cost and scaling, making it an ideal platform for complex models. In essence, AI turns cloud native infrastructures into smarter, more resilient hubs that drive business value through automation and intelligence.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;How AI Benefits from Technologies Like Kubernetes&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes, the de facto standard for container orchestration, provides AI with the robust foundation needed to thrive at scale. AI workloads, often resource-intensive and distributed, see immense gains from Kubernetes’ capabilities in portability, scalability, and management.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes excels in handling AI’s demanding tasks, such as model training and inference, by efficiently managing GPUs and accelerators. It ensures reproducibility and portability, allowing AI models to run consistently across environments—from on-premises to multi-cloud. For large-scale AI operations, Kubernetes simplifies orchestration, isolating processes and automating CI/CD pipelines.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;AI benefits from Kubernetes’ automation features, like self-optimizing clusters and predictive resource management, which accelerate ML pipelines. GPU resource management is a standout advantage, enabling efficient allocation for training without manual intervention. Moreover, Kubernetes supports edge AI deployments and enhances security, making it ideal for production-grade AI.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Going forward, AI will continue to benefit from Kubernetes advancements, such as smarter MLOps and integration with frameworks like PyTorch. By providing a consistent API, Kubernetes allows seamless movement of AI research and production workloads, fostering innovation. Ultimately, Kubernetes empowers AI to scale globally while maintaining efficiency and reliability.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Real-World Use Cases: AI and Cloud Native in Action&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To ground these concepts, let’s examine some real-world examples where AI and cloud native technologies intersect. The following examples highlight how end users and platform teams are utilizing Kubernetes and cloud native technologies in AI environments in production:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/case-studies/openai/&#34;&gt;OpenAI leverages Kubernetes for massive-scale AI training&lt;/a&gt;, scaling to &lt;a href=&#34;https://www.fairwinds.com/blog/ai-cloud-native-managing-kubernetes-platform&#34;&gt;over 7,500 nodes&lt;/a&gt; for parallel processing in model development. This demonstrates Kubernetes’ capability in handling resource-intensive AI workloads while ensuring portability.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.zdnet.com/article/cloud-native-computing-is-poised-to-explode-thanks-to-ai-inference-work/&#34;&gt;Google Cloud uses Kubernetes for AI inference&lt;/a&gt;, processing quadrillions of tokens monthly. Their internal jobs highlight how cloud native orchestration supports explosive growth in AI demands, optimizing for bare-metal performance in neoclouds.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://blogs.oracle.com/developers/autoscaling-gpu-workloads-oci-kubernetes-engine-oke&#34;&gt;Oracle uses Kubernetes to orchestrate GPU-accelerated AI workloads&lt;/a&gt;, automatically scaling pods using GPU accelerators to minimize the number of idle GPUs, the costs associated with them, and ensuring fast response performance when GPU demand is high.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.uber.com/blog/ubers-journey-to-ray-on-kubernetes-ray-setup/&#34;&gt;Uber runs its Machine Learning platform on Kubernetes&lt;/a&gt;, observing 1.5- to 4-times improvement in ‌training speed and better GPU utilization for resources across zones and clusters.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://venturebeat.com/security/armo-shows-how-chatgpt-can-help-protect-kubernetes&#34;&gt;ARMO integrates ChatGPT with Kubernetes for security&lt;/a&gt;, allowing teams to generate custom controls in natural language to secure clusters and pipelines. This use case shows AI enhancing cloud native security without deep coding expertise.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://venturebeat.com/ai/scaleops-new-ai-infra-product-slashes-gpu-costs-for-self-hosted-enterprise?amp=&amp;amp;amp=&#34;&gt;ScaleOps’ AI Infra Product, running on Kubernetes, slashes GPU costs by 50-70% for enterprise LLMs&lt;/a&gt; by automating optimization across clouds and on-premises. Early adopters report seamless integration, proving the cost-saving potential of AI-driven cloud native management.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;These cases underscore the practical impact: from cost reductions and security enhancements to scalable innovation, AI, and cloud native technologies are driving tangible business outcomes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Conclusion: A Future of Mutual Empowerment&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The fusion of AI and cloud native technologies like Kubernetes is more than a trend—it’s a paradigm shift. AI infuses intelligence into workloads, making them adaptive and efficient, while cloud native environments gain from AI’s optimization and automation. In turn, AI thrives on Kubernetes’ orchestration, scaling to meet global demands. As seen in deployments by OpenAI, Google, Uber, and others, this symbiosis is already yielding breakthroughs. Looking ahead, expect even tighter integrations, with AI-native infrastructures becoming the norm. For organizations, embracing this revolution means unlocking unprecedented agility, cost savings, and innovation in an AI-driven world.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;此大使博客最初发布在作者的博客上，经许可在此处重新发布。&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt; &lt;img loading =“lazy”decoding =“async”width =“1195”height =“675”src =“https://www.cncf.io/wp-content/uploads/2026/01/AI-and-Kubernetes-1195x675-1.jpg”alt =“AI和Kubernetes握手”class =“wp-image-154928” srcset =“https://www.cncf.io/wp-content/uploads/2026/01/AI-and-Kubernetes-1195x675-1.jpg 1195w，https://www.cncf.io/wp-content/uploads/2026/01/AI-and-Kubernetes-1195x675-1-300x169.jpg 300w， https://www.cncf.io/wp-content/uploads/2026/01/AI-and-Kubernetes-1195x675-1-1024x578.jpg 1024w，https://www.cncf.io/wp-content/uploads/2026/01/AI-and-Kubernetes-1195x675-1-768x434.jpg 768w， https://www.cncf.io/wp-content/uploads/2026/01/AI-and-Kubernetes-1195x675-1-900x508.jpg 900w，https://www.cncf.io/wp-content/uploads/2026/01/AI-and-Kubernetes-1195x675-1-354x200.jpg 354w， https://www.cncf.io/wp-content/uploads/2026/01/AI-and-Kubernetes-1195x675-1-708x400.jpg 708w“尺寸=”自动，（最大宽度：1195px）100vw，1195px“referrerpolicy=”no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在不断发展的技术世界中，很少有配对能够像人工智能 (AI) 和云原生架构的交集那样激发如此多的创新。围绕容器、微服务和 Kubernetes 等编排工具构建的云原生技术强调可扩展性、弹性和敏捷性。与此同时，人工智能（包括机器学习 (ML)、深度学习和生成模型）推动智能自动化和数据驱动的见解。随着 2026 年的临近，这种协同作用正在重塑组织部署、管理和优化工作负载的方式。在这篇博文中，我们将探讨人工智能如何彻底改变云原生工作负载、人工智能给云原生环境带来的好处，以及人工智能本身如何从 Kubernetes 等强大工具中获益。我们还将深入研究说明这种变革关系的现实用例。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;人工智能如何影响和改变云原生工作负载&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;云原生工作负载传统上涉及跨分布式系统编排的容器化应用程序，但人工智能正在为这些流程注入智能，使它们更具适应性和效率。人工智能的核心是通过预测分析、自动优化和动态资源分配来影响工作负载。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;一个关键的变化是从静态扩展向人工智能驱动扩展的转变。传统的云原生设置依赖于基于规则的自动扩展，但人工智能模型可以使用历史数据预测需求峰值，从而实时优化资源使用。例如，人工智能工作负载需要大量的计算能力，通常涉及 GPU，而云原生设计可确保这些资源无缝扩展而不会过度配置。这种演变将刚性的基础设施转变为灵活的、自我修复的系统。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;人工智能也在改变工作负载开发周期。生成式 AI 工具通过在云原生应用程序中自动生成代码、测试和安全检查来简化 DevOps。在人工智能原生基础设施中，通过人工智能主动检测异常并重新路由任务，工作负载对故障的恢复能力变得更强。这不仅可以减少停机时间，还可以通过最大限度地减少闲置资源来降低成本。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;此外，人工智能正在将云原生工作负载推向边缘计算和混合环境。通过处理更接近源的数据，人工智能增强的工作负载可以更有效地处理物联网分析等实时应用程序，从而模糊了云和本地设置之间的界限。总体而言，人工智能正在将云原生工作负载从单纯的可扩展容器转变为能够预测需求并即时适应的智能、主动的生态系统。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;云原生环境如何从人工智能中受益&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;好处是双向的：以模块化和可移植性为特征的云原生环境通过人工智能集成得到了增强。这会全面提高效率、安全性和创新。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;人工智能优化了云原生设置中的资源管理。通过分析使用模式，人工智能算法可以实现预测性扩展，减少浪费并确保成本效益。例如，在混合云环境中，人工智能提供的见解可以提高应用程序性能和资源分配，从而加快决策速度。这对于处理可变工作负载特别有价值，其中人工智能可以动态配置资源以响应变化。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;安全性和弹性也取得了巨大的进步。人工智能驱动的工具可以实时检测容器化环境中的威胁，自动响应漏洞。随着人工智能促进敏捷性和成本节约，跨团队的协作得到改善，使开发人员能够专注于创新而不是维护。在人工智能原生应用程序中，这意味着个性化的用户体验和更快的部署周期。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;此外，云原生环境受益于人工智能处理海量数据的能力。通过人工智能实现远程访问和开发中的全球协作，可扩展性变得毫不费力。云在人工智能训练和部署方面的灵活性克服了成本和扩展等障碍，使其成为复杂模型的理想平台。从本质上讲，人工智能将云原生基础设施转变为更智能、更有弹性的中心，通过自动化和智能化推动业务价值。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;人工智能如何从 Kubernetes 等技术中受益&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes 是容器编排的事实上的标准，为 AI 提供了大规模发展所需的坚实基础。 AI 工作负载通常是资源密集型和分布式的，可以从 Kubernetes 在可移植性、可扩展性和管理方面的功能获得巨大收益。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes 擅长处理人工智能的高要求任务，例如模型训练通过有效管理 GPU 和加速器来进行推理。它确保了可重复性和可移植性，使人工智能模型能够跨环境（从本地到多云）一致运行。对于大规模人工智能操作，Kubernetes 简化了编排、隔离流程以及自动化 CI/CD 管道。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;人工智能受益于 Kubernetes 的自动化功能，例如自我优化集群和预测资源管理，可加速机器学习管道。 GPU 资源管理是一个突出的优势，无需人工干预即可高效分配训练。此外，Kubernetes 支持边缘 AI 部署并增强安全性，非常适合生产级 AI。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;展望未来，人工智能将继续受益于 Kubernetes 的进步，例如更智能的 MLOps 以及与 PyTorch 等框架的集成。通过提供一致的 API，Kubernetes 允许人工智能研究和生产工作负载的无缝移动，从而促进创新。最终，Kubernetes 使人工智能能够在全球范围内扩展，同时保持效率和可靠性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;实际用例：人工智能和云原生的实际应用&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;为了奠定这些概念的基础，让我们看一下人工智能和云原生技术交叉的一些现实示例。以下示例重点介绍了最终用户和平台团队如何在生产中的 AI 环境中利用 Kubernetes 和云原生技术：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/case-studies/openai/&#34;&gt;OpenAI 利用 Kubernetes 进行大规模 AI 训练&lt;/a&gt;，扩展到&lt;a href=&#34;https://www.fairwinds.com/blog/ai-cloud-native-managing-kubernetes-platform&#34;&gt;超过 7,500 个节点&lt;/a&gt;在模型开发中进行并行处理。这证明了 Kubernetes 在处理资源密集型人工智能工作负载的同时确保可移植性的能力。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.zdnet.com/article/cloud-native-computing-is-poished-to-explode-thanks-to-ai-inference-work/&#34;&gt;Google Cloud 使用 Kubernetes 进行 AI 推理&lt;/a&gt;，每月处理数千万个令牌。他们的内部工作强调了云原生编排如何支持人工智能需求的爆炸性增长，优化新云中的裸机性能。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://blogs.oracle.com/developers/autoscaling-gpu-workloads-oci-kubernetes-engine-oke&#34;&gt;Oracle 使用 Kubernetes 来编排 GPU 加速的 AI 工作负载&lt;/a&gt;，使用 GPU 加速器自动扩展 Pod，以最大程度地减少空闲 GPU 的数量及其相关成本，并确保在 GPU 需求较高时快速响应性能。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.uber.com/blog/ubers-journey-to-ray-on-kubernetes-ray-setup/&#34;&gt;Uber 在 Kubernetes 上运行其机器学习平台&lt;/a&gt;，观察到训练速度提高了 1.5 到 4 倍，跨区域和集群的资源 GPU 利用率提高了。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://venturebeat.com/security/armo-shows-how-chatgpt-can-help-protect-kubernetes&#34;&gt;ARMO 集成ChatGPT 与 Kubernetes 一起实现安全&lt;/a&gt;，允许团队以自然语言生成自定义控件，以保护集群和管道的安全。该用例展示了人工智能无需深厚的编码专业知识即可增强云原生安全性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://venturebeat.com/ai/scaleops-new-ai-infra-product-slashes-gpu-costs-for-self-hosted-enterprise?amp=&amp;amp=&#34;&gt;ScaleOps 的 AI 基础设施产品在 Kubernetes 上运行，通过跨云和本地的自动化优化，将企业 LLM 的 GPU 成本削减 50-70%&lt;/a&gt;。早期采用者表示无缝集成，证明了人工智能驱动的云原生管理的成本节约潜力。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这些案例强调了实际影响：从降低成本和增强安全性到可扩展的创新、人工智能和云原生技术正在推动切实的业务成果。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;结论：相互赋权的未来&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;人工智能与 Kubernetes 等云原生技术的融合不仅仅是一种趋势，更是一种范式转变。人工智能将智能注入工作负载中，使其具有适应性和高效性，而云原生环境则从人工智能的优化和自动化中获益。反过来，人工智能在 Kubernetes 的协调下蓬勃发展，并通过扩展来满足全球需求。从 OpenAI、谷歌、Uber 和其他公司的部署中可以看出，这种共生关系已经取得了突破。展望未来，预计集成会更加紧密，人工智能原生基础设施将成为常态。对于组织来说，拥抱这场革命意味着在人工智能驱动的世界中释放前所未有的敏捷性、成本节约和创新。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Mon, 12 Jan 2026 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【A decade of open source in CNCF with 300,000+ contributors and counting】CNCF 开源十年，拥有超过 300,000 名贡献者，而且还在不断增加</title>
      <link>https://www.cncf.io/blog/2026/01/12/a-decade-of-open-source-in-cncf-with-300000-contributors-and-counting/</link>
      <description>【&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We’re excited to announce that the Cloud Native Computing Foundation (CNCF) community has reached an important milestone: &lt;a href=&#34;https://www.cncf.io/project-metrics/&#34;&gt;&lt;strong&gt;more than 300,000 contributors&lt;/strong&gt;&lt;/a&gt; have participated in CNCF hosted projects across more than 11500 organizations from 190 countries.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This incredible metric reflects the collective efforts of those who contribute code, documentation, reviews, testing, issue triage, design, and community support across the CNCF project landscape. It also represents continued participation across projects at every stage,&amp;nbsp; from sandbox to graduated, and showcases the scale of collaboration that is the foundation of cloud native open source.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;A community-driven cloud native ecosystem&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.cncf.io/project-metrics/&#34;&gt;CNCF projects&lt;/a&gt; are built and maintained by a global community of contributors working in the open.&amp;nbsp; Reaching more than 300,000 contributors is the result of years of open collaboration across many communities who have given their time and effort to help build the cloud native ecosystem. Contributors participate in different ways and at different levels, but all contributions help projects evolve, improve reliability, and remain responsive to user needs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Contributions across the project lifecycle&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;CNCF hosts projects at different stages of maturity, each with its own contributor dynamics:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Sandbox &lt;/strong&gt;projects explore new ideas and early-stage innovation.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Incubating &lt;/strong&gt;projects&lt;strong&gt; &lt;/strong&gt;show growing adoption and contributor activity.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Graduated &lt;/strong&gt;projects demonstrate long-term sustainability and broad community involvement.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Across all stages, contributor participation is essential to project health, and the growth highlights ongoing engagement across this full lifecycle.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Thank you to the community&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This milestone belongs to the entire community; everyone who has opened a pull request, reviewed a change, filed an issue, improved documentation, or supported others along the way.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As CNCF projects continue to grow and evolve, community participation remains central to their success. Thank you to everyone who has contributed and continues to contribute on a daily basis.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To explore contributor activity and learn how to get involved, visit the &lt;a href=&#34;https://www.cncf.io/project-metrics/&#34;&gt;&lt;strong&gt;CNCF Project Metrics&lt;/strong&gt; page&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们很高兴地宣布，云原生计算基金会 (CNCF) 社区已达到一个重要里程碑：&lt;a href=&#34;https://www.cncf.io/project-metrics/&#34;&gt;&lt;strong&gt;超过 300,000 名贡献者&lt;/strong&gt;&lt;/a&gt;参与了来自 190 个国家/地区 11500 多个组织的 CNCF 托管项目。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这个令人难以置信的指标反映了整个 CNCF 项目环境中贡献代码、文档、审查、测试、问题分类、设计和社区支持的人们的集体努力。它还代表了从沙箱到分级的各个阶段的项目持续参与，并展示了作为云原生开源基础的协作规模。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;社区驱动的云原生生态系统&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.cncf.io/project-metrics/&#34;&gt;CNCF 项目&lt;/a&gt;由开放工作的全球贡献者社区构建和维护。  超过 300,000 名贡献者是许多社区多年来开放合作的结果，他们付出了时间和精力来帮助构建云原生生态系统。贡献者以不同的方式和不同的级别参与，但所有贡献都有助于项目发展、提高可靠性并保持对用户需求的响应。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;整个项目生命周期的贡献&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;CNCF 托管处于不同成熟阶段的项目，每个项目都有自己的贡献者动态：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;沙盒&lt;/strong&gt;项目探索新想法和早期创新。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;孵化&lt;/strong&gt;项目&lt;strong&gt; &lt;/strong&gt;显示采用率和贡献者活动不断增长。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;毕业&lt;/strong&gt;项目展示了长期可持续性和广泛的社区参与。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在所有阶段，贡献者的参与对于项目的健康发展至关重要，而这种增长凸显了整个生命周期中的持续参与。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;感谢社区&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这个里程碑属于整个社区；在此过程中提出拉取请求、审查更改、提出问题、改进文档或支持其他人的每个人。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;随着 CNCF 项目的不断发展和发展，社区参与仍然是其成功的核心。感谢所有每天做出贡献并继续做出贡献的人。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;要探索贡献者活动并了解如何参与，请访问&lt;a href=&#34;https://www.cncf.io/project-metrics/&#34;&gt;&lt;strong&gt;CNCF 项目指标&lt;/strong&gt;页面&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Sun, 11 Jan 2026 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【OpenCost: Reflecting on 2025 and looking ahead to 2026】OpenCost：反思2025年、展望2026年</title>
      <link>https://www.cncf.io/blog/2026/01/12/opencost-reflecting-on-2025-and-looking-ahead-to-2026/</link>
      <description>【&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The OpenCost project has had a fruitful year in terms of releases, our wonderful mentees and contributors, and fun gatherings at KubeCons.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1200&#34; height=&#34;630&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image-10-1.jpg&#34; alt=&#34;A header image featuring the OpenCost logo, and a text headline &amp;quot;A Strong Year, Stronger Community.&amp;quot; The image features a green background and three photo images: One of a group of technologists at the OpenCost desk in the Project Pavillion at KubeCon; the second, an image of a crowded auditorium; the third featuring three people talking, one of whom is wearing a green OpenCost sweater. &#34; class=&#34;wp-image-155251&#34; title=&#34;OpenCost 2025&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image-10-1.jpg 1200w, https://www.cncf.io/wp-content/uploads/2026/01/image-10-1-300x158.jpg 300w, https://www.cncf.io/wp-content/uploads/2026/01/image-10-1-1024x538.jpg 1024w, https://www.cncf.io/wp-content/uploads/2026/01/image-10-1-768x403.jpg 768w, https://www.cncf.io/wp-content/uploads/2026/01/image-10-1-194x102.jpg 194w, https://www.cncf.io/wp-content/uploads/2026/01/image-10-1-388x204.jpg 388w, https://www.cncf.io/wp-content/uploads/2026/01/image-10-1-776x408.jpg 776w, https://www.cncf.io/wp-content/uploads/2026/01/image-10-1-900x473.jpg 900w, https://www.cncf.io/wp-content/uploads/2026/01/image-10-1-381x200.jpg 381w, https://www.cncf.io/wp-content/uploads/2026/01/image-10-1-762x400.jpg 762w, https://www.cncf.io/wp-content/uploads/2026/01/image-10-1-590x310.jpg 590w, https://www.cncf.io/wp-content/uploads/2026/01/image-10-1-1180x620.jpg 1180w&#34; sizes=&#34;auto, (max-width: 1200px) 100vw, 1200px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you’re new to OpenCost, it is an open-source cost and resources management tool that is an Incubating project in the Cloud Native Computing Foundation (CNCF). It was created by IBM Kubecost and continues to be maintained and supported by IBM Kubecost, Randoli, and a wider community of partners, including the major cloud providers. &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;OpenCost releases&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The OpenCost project had &lt;a href=&#34;https://github.com/opencost/opencost/releases&#34;&gt;11 releases in 2025&lt;/a&gt;. These include new features and capabilities that improve the experience for both users and contributors. Here are a few highlights:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/opencost/opencost/pull/3166&#34;&gt;Promless:&lt;/a&gt; OpenCost can be configured to run without Prometheus, using environment variables which can be set using helm. Users will be able to run OpenCost using the Collector Datasource (beta) which can be run without Prometheus.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;OpenCost MCP server: AI agents can now query cost data in real-time using natural language. They can analyze spending patterns across namespaces, pods, and nodes, generate cost reports and recommendations automatically, and provide other insights from OpenCost data.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Export system: The project now has a generic export framework to make it possible to export cost data in a type-safe way.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Diagnostics system: OpenCost has a complete diagnostic framework with an interface, runners, and export capabilities.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Heartbeat system: You can do system health tracking with timestamped heartbeat events for export and more.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Cloud providers: There are continued improvements for users to track cloud and multi-cloud metrics. We appreciate contributions from Oracle (including providing hosting for our demo) and DigitalOcean (for recent cloud services provider work).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Thanks to our maintainers and contributors who make these releases possible and successful, including our mentees and community contributors as well.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Mentorship and community management&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Our project has been committed to mentorship through the Linux Foundation for a while, and we continue to have fantastic mentees who bring innovation and support to the community. Manas Sivakumar was a summer 2025 mentee and worked on writing Integration tests for OpenCost’s enterprise readiness. Manas’ work is now part of the OpenCost integration testing pipeline for all future contributions.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Adesh Pal, a mentee, made a big splash with the &lt;a href=&#34;https://opencost.io/blog/opencost-mcp-server&#34;&gt;OpenCost MCP server&lt;/a&gt;. The MCP server now comes by default and needs no configuration. It outputs readable markdown on metrics as well as step-by-step suggestions to make improvements.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Sparsh Raj has been in our community for a while and has become our most recent mentee. Sparsh has written a blog post on &lt;a href=&#34;https://opencost.io/blog/introducing-kubemodel&#34;&gt;KubeModel&lt;/a&gt;, the foundation of OpenCost’s Data Model 2.0. Sparsh’s work will meet the needs for a robust and scalable data model that can handle Kubernetes complexity and constantly shifting resources.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;On the community side, Tamao Nakahara was brought into the IBM Kubecost team for a few months of open source and developer experience expertise. Tamao helped organize the regular OpenCost community meetings, leading actions around events, the website, and docs. On the website, Tamao improved the UX for new and returning users, and brought in Ginger Walker to help clean up the docs.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Events and talks&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As a CNCF incubating project, OpenCost participated in the key KubeCon events. Most recently, the team was at KubeCon + CloudNativeCon Atlanta 2025, where maintainer Matt Bolt from IBM Kubecost kicked off the week with a Project Lightning talk. During a co-located event that day, Rajith Attapattu, CTO of contributing company Randoli, also gave a talk on OpenCost. Dee Zeis, Rajith, and Tamao also answered questions at the OpenCost kiosk in the Project Pavilion.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Earlier in the year, the team was also at both KubeCon + CloudNativeCon in London and Japan, giving talks and running the OpenCost kiosks.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;2026!&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;What’s in store for OpenCost in the coming year? Aside from meeting all of you at future KubeCon + CloudNativeCon’s, we’re also excited about a few roadmap highlights. As mentioned, our LFX mentee Sparsh is working on KubeModel, which will be important for improvements to OpenCost’s data model. As AI continues to increase in adoption, the team is also working on building out costing features to track AI usage. Finally, supply chain security improvements are a priority.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We’re looking forward to seeing more of you in the community in the next year!&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;OpenCost 项目在发布、出色的学员和贡献者以及 KubeCons 的有趣聚会方面度过了硕果累累的一年。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; Decoding=&#34;async&#34; width=&#34;1200&#34; height=&#34;630&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image-10-1.jpg&#34; alt=&#34;带有 OpenCost 徽标的标题图像和文本标题“强劲的一年，更强的社区。”该图像具有绿色背景和三张照片图片：KubeCon 项目馆 OpenCost 办公桌前的一组技术人员；第二张是拥挤的礼堂的图片；第三张是三个人在说话，其中一个穿着绿色的 OpenCost 毛衣” class=&#34;wp-image-155251&#34; title=&#34;OpenCost 2025&#34; srcset =“https://www.cncf.io/wp-content/uploads/2026/01/image-10-1.jpg 1200w，https://www.cncf.io/wp-content/uploads/2026/01/image-10-1-300x158.jpg 300w， https://www.cncf.io/wp-content/uploads/2026/01/image-10-1-1024x538.jpg 1024w，https://www.cncf.io/wp-content/uploads/2026/01/image-10-1-768x403.jpg 768w， https://www.cncf.io/wp-content/uploads/2026/01/image-10-1-194x102.jpg 194w，https://www.cncf.io/wp-content/uploads/2026/01/image-10-1-388x204.jpg 388w， https://www.cncf.io/wp-content/uploads/2026/01/image-10-1-776x408.jpg 776w，https://www.cncf.io/wp-content/uploads/2026/01/image-10-1-900x473.jpg 900w， https://www.cncf.io/wp-content/uploads/2026/01/image-10-1-381x200.jpg 381w，https://www.cncf.io/wp-content/uploads/2026/01/image-10-1-762x400.jpg 762w， https://www.cncf.io/wp-content/uploads/2026/01/image-10-1-590x310.jpg 590w，https://www.cncf.io/wp-content/uploads/2026/01/image-10-1-1180x620.jpg 1180w“尺寸=”自动，（最大宽度：1200px） 100vw，1200px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您不熟悉 OpenCost，它是一个开源成本和资源管理工具，是云原生计算基金会 (CNCF) 的孵化项目。它由 IBM Kubecost 创建，并继续由 IBM Kubecost、Randoli 以及更广泛的合作伙伴社区（包括主要云提供商）维护和支持。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;OpenCost 版本&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;OpenCost 项目&lt;a href=&#34;https://github.com/opencost/opencost/releases&#34;&gt;2025 年发布了 11 个版本&lt;/a&gt;。其中包括可改善用户和贡献者体验的新特性和功能。以下是一些亮点：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/opencost/opencost/pull/3166&#34;&gt;Promless：&lt;/a&gt; OpenCost 可以配置为在没有 Prometheus 的情况下运行，使用可以使用 helm 设置的环境变量。用户将能够使用收集器数据源（测试版）运行 OpenCost，该数据源可以在没有 Prometheus 的情况下运行。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;OpenCost MCP 服务器：AI 代理现在可以使用自然语言实时查询成本数据。他们可以分析跨命名空间、pod 和节点的支出模式，自动生成成本报告和建议，并提供来自 OpenCost 数据的其他见解。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;导出系统：该项目现在拥有一个通用导出框架，可以以类型安全的方式导出成本数据。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;诊断系统：OpenCost 拥有完整的诊断框架，包括界面、运行程序和导出功能。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;心跳系统：您可以使用带时间戳的心跳事件进行系统运行状况跟踪，以进行导出等操作。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;云提供商：用户跟踪云和多云指标的能力不断改进。我们感谢 Oracle（包括为我们的演示提供托管）和 DigitalOcean（最近的云服务提供商工作）的贡献。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;感谢我们的维护者和贡献者，包括我们的学员和社区贡献者，是他们使这些版本成为可能并取得成功。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;指导和社区管理&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们的项目一段时间以来一直致力于通过 Linux 基金会进行指导，并且我们继续拥有出色的受指导者，他们为社区带来创新和支持。 Manas Sivakumar 是 2025 年夏季学员，致力于为 OpenCost 的企业准备情况编写集成测试。 Manas 的工作现已成为 OpenCost 集成测试管道的一部分，以供未来的所有贡献。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;学员 Adesh Pal 凭借 &lt;a href=&#34;https://opencost.io/blog/opencost-mcp-server&#34;&gt;OpenCost MCP 服务器&lt;/a&gt;引起了巨大轰动。 MCP 服务器现在是默认设置，无需配置。它输出可读的指标标记以及改进的分步建议。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Sparsh Raj 已经加入我们的社区一段时间了，并成为我们最新的学员。 Sparsh 撰写了一篇关于 OpenCost 数据模型 2.0 基础 &lt;a href=&#34;https://opencost.io/blog/introducing-kubemodel&#34;&gt;KubeModel&lt;/a&gt; 的博客文章。 Sparsh 的工作将满足对强大且可扩展的数据模型的需求，该模型可以处理 Kubernetes 的复杂性和不断变化的资源。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;在社区方面，Tamao Nakahara 被引入 IBM Kubecost 团队，积累了几个月的开源和开发人员经验专业知识。 Tamao 帮助组织定期的 OpenCost 社区会议，领导围绕活动、网站和文档的行动。在网站上，Tamao 改进了新用户和回访用户的用户体验，并引入了 Ginger Walker 来帮助清理文档。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;活动和讲座&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;OpenCost作为CNCF孵化项目，参与了KubeCon的重要活动。最近，该团队参加了 2025 年亚特兰大 KubeCon + CloudNativeCon，来自 IBM Kubecost 的维护者 Matt Bolt 以 Project Lightning 演讲拉开了本周的序幕。在当天的同期活动中，贡献公司 Randoli 的 CTO Rajith Attapattu 也发表了有关 OpenCost 的演讲。 Dee Zeis、Rajith 和 Tamao 还在项目馆的 OpenCost 信息亭回答了问题。&lt;/p&gt;&lt;p&gt;今年早些时候，该团队还在伦敦和日本举行的 KubeCon + CloudNativeCon 上发表演讲并运行 OpenCost 信息亭。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;2026！&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;来年 OpenCost 将会发生什么？除了在未来的 KubeCon + CloudNativeCon 上与大家见面之外，我们还对一些路线图亮点感到兴奋。如前所述，我们的 LFX 学员 Sparsh 正在研究 KubeModel，这对于 OpenCost 数据模型的改进非常重要。随着人工智能的采用率不断提高，该团队还致力于构建成本计算功能来跟踪人工智能的使用情况。最后，供应链安全改进是当务之急。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们期待明年在社区中见到更多的人！&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Sun, 11 Jan 2026 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【HolmesGPT: Agentic troubleshooting built for the cloud native era】HolmesGPT：专为云原生时代构建的代理故障排除</title>
      <link>https://www.cncf.io/blog/2026/01/07/holmesgpt-agentic-troubleshooting-built-for-the-cloud-native-era/</link>
      <description>【&lt;p&gt;If you’ve ever debugged a production incident, you know that the hardest part often isn’t the fix, it’s &lt;strong&gt;finding where to begin&lt;/strong&gt;. Most on-call engineers end up spending hours piecing together clues, fighting time pressure, and trying to make sense of scattered data. You’ve probably run into one or more of these challenges:&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Unwritten knowledge and missing context:&lt;/strong&gt;&lt;br&gt;You’re pulled into an outage for a service you barely know. The original owners have changed teams, the documentation is half-written, and the “runbook” is either stale or missing altogether. You spend the first 30 minutes trying to find someone who’s seen this issue before — and if you’re unlucky, this incident is a &lt;em&gt;new&lt;/em&gt; one.&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Tool overload and context switching:&lt;/strong&gt;&lt;br&gt;Your screen looks like an air traffic control dashboard. You’re running monitoring queries, flipping between Grafana and Application Insights, checking container logs, and scrolling through traces — all while someone’s asking for an ETA in the incident channel. Correlating data across tools is manual, slow, and mentally exhausting.&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Overwhelming complexity and knowledge gaps:&lt;/strong&gt;&lt;br&gt;Modern cloud-native systems like Kubernetes are powerful, but they’ve made troubleshooting far more complex. Every layer — nodes, pods, controllers, APIs, networking, autoscalers – introduces its own failure modes. To diagnose effectively, you need deep expertise across multiple domains, something even seasoned engineers can’t always keep up with.&amp;nbsp;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The challenges require a solution that can look across signals, recall patterns from past incidents, and guide you toward the most likely cause.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This is where &lt;strong&gt;HolmesGPT, a CNCF Sandbox project,&lt;/strong&gt; could help.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&amp;nbsp;&lt;br&gt;HolmesGPT was accepted as a CNCF Sandbox project in October 2025. It’s built to simplify the chaos of production debugging – bringing together logs, metrics, and traces from different sources, reasoning over them, and surfacing clear, data-backed insights in plain language.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;What is HolmesGPT?&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/robusta-dev/holmesgpt/&#34;&gt;&lt;strong&gt;HolmesGPT&lt;/strong&gt;&lt;/a&gt; is an &lt;strong&gt;open-source AI troubleshooting agent&lt;/strong&gt; built for Kubernetes and cloud-native environments. It combines &lt;strong&gt;observability telemetry&lt;/strong&gt;, &lt;strong&gt;LLM reasoning&lt;/strong&gt;, and &lt;strong&gt;structured runbooks&lt;/strong&gt; to accelerate root cause analysis and suggest next actions.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Unlike static dashboards or chatbots, HolmesGPT is &lt;em&gt;agentic&lt;/em&gt;: it actively decides what data to fetch, runs targeted queries, and iteratively refines its hypotheses – all while staying within your environment.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Key benefits:&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;AI-native control loop:&lt;/strong&gt; HolmesGPT uses an agentic task list approach&amp;nbsp;&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Open architecture:&lt;/strong&gt; Every integration and toolset is open and extensible, works with existing runbooks and MCP servers&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Data privacy:&lt;/strong&gt; Models can run locally or inside your cluster or on the cloud&amp;nbsp;&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Community-driven:&lt;/strong&gt; Designed around CNCF principles of openness, interoperability, and transparency.&amp;nbsp;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;How it works&amp;nbsp;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;When you run:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;holmes ask “Why is my pod in crash loop back off state” &lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;HolmesGPT:&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Understands intent&lt;/strong&gt; → it recognizes you want to diagnose a pod restart issue&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Creates a task list &lt;/strong&gt;→ breaks down the problem into smaller chunks and executes each of them separately&amp;nbsp;&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Queries data sources&lt;/strong&gt; → runs Prometheus queries, collects Kubernetes events or logs, inspects pod specs including which pod&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Correlates context&lt;/strong&gt; → detects that a recent deployment updated the image&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Explains and suggests fixes&lt;/strong&gt; → returns a natural language diagnosis and remediation steps.&amp;nbsp;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Here’s a simplified overview of the architecture:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;936&#34; height=&#34;507&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image-3-1.jpg&#34; alt=&#34;HolmesGPT architecture &#34; class=&#34;wp-image-154746&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2026/01/image-3-1.jpg 936w, https://www.cncf.io/wp-content/uploads/2026/01/image-3-1-300x163.jpg 300w, https://www.cncf.io/wp-content/uploads/2026/01/image-3-1-768x416.jpg 768w, https://www.cncf.io/wp-content/uploads/2026/01/image-3-1-900x488.jpg 900w, https://www.cncf.io/wp-content/uploads/2026/01/image-3-1-369x200.jpg 369w, https://www.cncf.io/wp-content/uploads/2026/01/image-3-1-738x400.jpg 738w&#34; sizes=&#34;auto, (max-width: 936px) 100vw, 936px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Extensible by design&amp;nbsp;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;HolmesGPT’s architecture allows contributors to add new components:&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Toolsets:&lt;/strong&gt; Build custom commands for internal observability pipelines&amp;nbsp;or expose existing tools through a &lt;strong&gt;Model Context Protocol (MCP) &lt;/strong&gt;server.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Evals:&lt;/strong&gt; Add custom evals to benchmark performance, cost , latency of models&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Runbooks:&lt;/strong&gt; Codify best practices (e.g., “diagnose DNS failures” or “debug PVC provisioning”).&amp;nbsp;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Example of a simple custom tool:&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code lang=&#34;markdown&#34; class=&#34;language-markdown&#34;&gt;holmes:&#xA;  toolsets:&#xA;    kubernetes/pod_status:&#xA;      description: &#34;Check the status of a Kubernetes pod.&#34;&#xA;      tools:&#xA;        - name: &#34;get_pod&#34;&#xA;          description: &#34;Fetch pod details from a namespace.&#34;&#xA;          command: &#34;kubectl get pod {{ pod }} -n {{ namespace }}&#34;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Getting started&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Install Holmesgpt&lt;/strong&gt;&amp;nbsp;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;There are 4-5 ways to install Holmesgpt, one of the easiest ways to get started is through &lt;a href=&#34;https://holmesgpt.dev/installation/python-installation/&#34;&gt;pip&lt;/a&gt;.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;brew tap robusta-dev/homebrew-holmesgpt&#xA;brew install holmesgpt&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The &lt;a href=&#34;https://holmesgpt.dev/installation/cli-installation/&#34;&gt;detailed installation guide&lt;/a&gt; has instructions for helm, CLI and the UI.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol start=&#34;2&#34; class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Setup the LLM&lt;/strong&gt; (Any Open AI compatible LLM) by setting the API Key&amp;nbsp;&amp;nbsp;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In most cases, this means setting &lt;a href=&#34;https://holmesgpt.dev/ai-providers/&#34;&gt;the appropriate environment variabl&lt;/a&gt;e based on the LLM provider.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol start=&#34;3&#34; class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Run it locally&lt;/strong&gt;&amp;nbsp;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;holmes ask &#34;what is wrong with the user-profile-import pod?&#34; --model=&#34;anthropic/claude-sonnet-4-5&#34;&amp;nbsp;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol start=&#34;4&#34; class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Explore other features &lt;/strong&gt;&amp;nbsp;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;GitHub: &lt;a href=&#34;https://github.com/robusta-dev/holmesgpt&#34;&gt;https://github.com/robusta-dev/holmesgpt&lt;/a&gt;&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Docs: &lt;a href=&#34;https://holmesgpt.dev/&#34;&gt;holmesgpt.dev&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;How to get involved&amp;nbsp;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;HolmesGPT is entirely community-driven and welcomes all forms of contribution:&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-fixed-layout&#34;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Area&lt;/strong&gt;&amp;nbsp;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;How you can help&lt;/strong&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Integrations&lt;/strong&gt;&amp;nbsp;&lt;/td&gt;&lt;td&gt;Add new toolsets for your observability tools or CI/CD pipelines.&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Runbooks&lt;/strong&gt;&amp;nbsp;&lt;/td&gt;&lt;td&gt;Encode operational expertise for others to reuse.&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Evaluation&lt;/strong&gt;&amp;nbsp;&lt;/td&gt;&lt;td&gt;Help build benchmarks for AI reasoning accuracy and observability insights.&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Docs and tutorials&lt;/strong&gt;&amp;nbsp;&lt;/td&gt;&lt;td&gt;Improve onboarding, create demos, or contribute walkthroughs.&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Community&lt;/strong&gt;&amp;nbsp;&lt;/td&gt;&lt;td&gt;Join discussions around governance and CNCF Sandbox progression.&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;All contributions follow the &lt;a href=&#34;https://github.com/cncf/foundation/blob/main/code-of-conduct.md&#34;&gt;CNCF Code of Conduct&lt;/a&gt;.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Further Resources&lt;/strong&gt;&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/robusta-dev/holmesgpt&#34;&gt;GitHub Repository&lt;/a&gt;&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&amp;nbsp;Join CNCF Slack → #holmesgpt&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/robusta-dev/holmesgpt/blob/master/CONTRIBUTING.md&#34;&gt;Contributing Guide&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;如果您曾经调试过生产事件，您就会知道最困难的部分通常不是修复，而是&lt;strong&gt;找到从哪里开始&lt;/strong&gt;。大多数待命工程师最终会花费数小时拼凑线索，应对时间压力，并试图理解分散的数据。您可能遇到过以下一项或多项挑战：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;不成文的知识和缺失的上下文：&lt;/strong&gt;&lt;br&gt;您因一项您几乎不知道的服务而陷入中断。原来的所有者已经更换了团队，文档写了一半，“运行手册”要么已经过时，要么完全丢失。您会在前 30 分钟内尝试找到以前遇到过此问题的人 - 如果您运气不好，此事件将是一个&lt;em&gt;新&lt;/em&gt;事件。 &lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;工具过载和上下文切换：&lt;/strong&gt;&lt;br&gt;您的屏幕看起来像空中交通管制仪表板。您正在运行监视查询、在 Grafana 和 Application Insights 之间切换、检查容器日志并滚动跟踪 - 所有这些都同时有人在事件通道中请求 ETA。跨工具关联数据是手动的、缓慢的且耗费精力的过程。 &lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;巨大的复杂性和知识差距：&lt;/strong&gt;&lt;br&gt;像 Kubernetes 这样的现代云原生系统功能强大，但它们使故障排除变得更加复杂。每一层——节点、pod、控制器、API、网络、自动缩放器——都会引入自己的故障模式。为了有效地进行诊断，您需要跨多个领域的深厚专业知识，即使是经验丰富的工程师也无法始终跟上。 &lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这些挑战需要一个能够跨信号查看、回忆过去事件的模式并引导您找出最可能的原因的解决方案。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这就是 CNCF 沙箱项目 &lt;strong&gt;HolmesGPT&lt;/strong&gt; 可以提供帮助的地方。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt; &lt;br&gt;HolmesGPT 于 2025 年 10 月被接受为 CNCF 沙箱项目。它的构建是为了简化混乱的生产调试 - 将来自不同来源的日志、指标和跟踪汇集在一起，对其进行推理，并以简单的语言呈现清晰的、有数据支持的见解。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;HolmesGPT 是什么？&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/robusta-dev/holmesgpt/&#34;&gt;&lt;strong&gt;HolmesGPT&lt;/strong&gt;&lt;/a&gt; 是一款专为 Kubernetes 和云原生环境构建的&lt;strong&gt;开源 AI 故障排除代理&lt;/strong&gt;。它结合了&lt;strong&gt;可观测性遥测&lt;/strong&gt;、&lt;strong&gt;法学硕士推理&lt;/strong&gt;和&lt;strong&gt;结构化运行手册&lt;/strong&gt;来加速根本原因分析并建议下一步行动。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;与静态仪表板或聊天机器人不同，HolmesGPT 是&lt;em&gt;代理&lt;/em&gt;：它主动决定要获取哪些数据，运行有针对性的查询，并迭代地完善其假设 - 所有这些都在您的环境中进行。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;主要优点：&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class =“wp-block-l”是&gt;&#xA;&lt;li&gt;&lt;strong&gt;人工智能原生控制循环&lt;/strong&gt;：HolmesGPT 使用代理任务列表方法  &lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;开放架构&lt;/strong&gt;：每个集成和工具集都是开放且可扩展的，可与现有 Runbook 和 MCP 服务器配合使用&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;数据隐私&lt;/strong&gt;：模型可以在本地、集群内部或云端运行&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;社区驱动&lt;/strong&gt;：围绕 CNCF 的开放性、互操作性和透明度原则进行设计。 &lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;工作原理&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;当你跑步时：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;holmes 问“为什么我的 Pod 处于崩溃循环退出状态”&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;霍姆斯GPT：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;&lt;strong&gt;理解意图&lt;/strong&gt; → 它会识别您想要诊断 Pod 重启问题&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;创建任务列表&lt;/strong&gt;→ 将问题分解为更小的块并单独执行每个块  &lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;查询数据源&lt;/strong&gt; → 运行 Prometheus 查询、收集 Kubernetes 事件或日志、检查 Pod 规格（包括哪个 Pod）&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;关联上下文&lt;/strong&gt; → 检测到最近的部署更新了映像   &lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;解释并建议修复&lt;/strong&gt; → 返回自然语言诊断和修复步骤。 &lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;以下是该架构的简化概述：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt;&lt;img load =“lazy”decoding =“async”width =“936”height =“507”src =“https://www.cncf.io/wp-content/uploads/2026/01/image-3-1.jpg”alt =“HolmesGPT架构”class =“wp-image-154746” srcset =“https://www.cncf.io/wp-content/uploads/2026/01/image-3-1.jpg 936w，https://www.cncf.io/wp-content/uploads/2026/01/image-3-1-300x163.jpg 300w， https://www.cncf.io/wp-content/uploads/2026/01/image-3-1-768x416.jpg 768w，https://www.cncf.io/wp-content/uploads/2026/01/image-3-1-900x488.jpg 900w， https://www.cncf.io/wp-content/uploads/2026/01/image-3-1-369x200.jpg 369w，https://www.cncf.io/wp-content/uploads/2026/01/image-3-1-738x400.jpg 738w“尺寸=”自动，（最大宽度：936px）100vw， 936px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;可通过设计进行扩展&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;HolmesGPT 的架构允许贡献者添加新组件：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;工具集&lt;/strong&gt;：为内部可观测性管道构建自定义命令或通过&lt;strong&gt;模型上下文协议 (MCP)&lt;/strong&gt;服务器公开现有工具。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;评估&lt;/strong&gt;：添加自定义评估以对模型的性能、成本、延迟进行基准测试&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;操作手册&lt;/strong&gt;：整理最佳实践（例如“诊断 DNS 故障”或“调试 PVC 配置”）。 &lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;简单的自定义工具示例：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code lang=&#34;markdown&#34; 类福尔摩斯：&#xA;  工具集：&#xA;    kubernetes/pod_status：&#xA;      描述：“检查 Kubernetes Pod 的状态。”&#xA;      工具：&#xA;        - 名称：“get_pod”&#xA;          描述：“从命名空间获取 Pod 详细信息。”&#xA;          命令：“kubectl get pod {{ pod }} -n {{命名空间}}”&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;开始使用&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;&lt;strong&gt;安装 Holmesgpt&lt;/strong&gt; &lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;有 4-5 种安装 Holmesgpt 的方法，最简单的入门方法之一是通过 &lt;a href=&#34;https://holmesgpt.dev/installation/python-installation/&#34;&gt;pip&lt;/a&gt;。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;酿造龙头robusta-dev/homebrew-holmesgpt&#xA;酿造安装 holmesgpt&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://holmesgpt.dev/installation/cli-installation/&#34;&gt;详细安装指南&lt;/a&gt;包含有关 helm、CLI 和 UI 的说明。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol start=&#34;2&#34; class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;通过设置 API 密钥来设置 LLM&lt;/strong&gt;（任何开放 AI 兼容的 LLM）&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在大多数情况下，这意味着根据 LLM 提供商设置&lt;a href=&#34;https://holmesgpt.dev/ai-providers/&#34;&gt;适当的环境变量&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol start=&#34;3&#34; class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;本地运行&lt;/strong&gt; &lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;holmes 问“user-profile-import pod 出了什么问题？” --model=&#34;anthropic/claude-sonnet-4-5&#34; &lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;        &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol start=&#34;4&#34; class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;探索其他功能&lt;/strong&gt; &lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;GitHub：&lt;a href=&#34;https://github.com/robusta-dev/holmesgpt&#34;&gt;https://github.com/robusta-dev/holmesgpt&lt;/a&gt; &lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;文档：&lt;a href=&#34;https://holmesgpt.dev/&#34;&gt;holmesgpt.dev&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;如何参与&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;HolmesGPT 完全由社区驱动，欢迎各种形式的贡献：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-fixed-layout&#34;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;区域&lt;/strong&gt; &lt;/td&gt;&lt;td&gt;&lt;strong&gt;您如何提供帮助&lt;/strong&gt; &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;集成&lt;/strong&gt; &lt;/td&gt;&lt;td&gt;为您的可观察性工具或 CI/CD 管道添加新的工具集。 &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;运行手册&lt;/strong&gt; &lt;/td&gt;&lt;td&gt;对运营专业知识进行编码以供其他人重复使用。 &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;评估&lt;/strong&gt; &lt;/td&gt;&lt;td&gt;帮助建立人工智能推理准确性和可观察性见解的基准。 &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;文档和教程&lt;/strong&gt; &lt;/td&gt;&lt;td&gt;改进入门、创建演示或提供演练。 &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;社区&lt;/strong&gt; &lt;/td&gt;&lt;td&gt;加入有关治理和 CNCF 沙箱进展的讨论。 &lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;所有贡献均遵循&lt;a href=&#34;https://github.com/cncf/foundation/blob/main/code-of-conduct.md&#34;&gt;CNCF 行为准则&lt;/一个&gt;。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;更多资源&lt;/strong&gt; &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/robusta-dev/holmesgpt&#34;&gt;GitHub 存储库&lt;/a&gt; &lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt; 加入 CNCF Slack → #holmesgpt &lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/robusta-dev/holmesgpt/blob/master/CONTRIBUTING.md&#34;&gt;贡献指南&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Tue, 06 Jan 2026 16:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>