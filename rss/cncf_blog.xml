<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>CNCF - Blog</title>
    <link>http://rsshub.rssforever.com/cncf</link>
    <description>CNCF - Blog - Powered by RSSHub</description>
    <managingEditor>contact@rsshub.app (RSSHub)</managingEditor>
    <item>
      <title>【Bridging cultures: empowering Japanese contributions to the Kubernetes community】架起文化桥梁：增强日本人对 Kubernetes 社区的贡献</title>
      <link>https://www.cncf.io/blog/2024/08/21/bridging-cultures-empowering-japanese-contributions-to-the-kubernetes-community/</link>
      <description>【&lt;p&gt;&lt;em&gt;Community post by Xie Ziyi, Kubernetes Upstream Training Japan Organizer, Cloud Native Community Japan Organizer, and Software Engineer, NEC Solution Innovators, Ltd.&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;What is &lt;a href=&#34;https://kutj.connpass.com/&#34;&gt;Kubernetes Upstream Training Japan&lt;/a&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes Upstream Training Japan is a training course held in Japanese that introduces the tasks, procedures, and concepts required to make contributions to the Kubernetes community (also known as the upstream community), a project hosted by the Cloud Native Computing Foundation (CNCF), and provides hands-on experience with actual contribution process.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Since community members are required to communicate with foreigners in English, it takes a lot of courage for Japanese folks who do not speak English well and who face cultural barriers to joining our community. For those who would like to join the community but are unable to take the first step, we are organizing this event to first create a place in Japan where they can communicate with local experts in Japanese and gradually familiarize themselves with how the community functions.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Starting in 2019, the event has been held once or twice a year, even during COVID-19, and as of May 2024, it has been held a total of 10 times. We believe that this event is meaningful, as we have been able to communicate with folks from all over the country and some of them have started their contribution activities because of this event. From this year, this event will be a SIG of &lt;a href=&#34;https://community.cncf.io/cloud-native-community-japan/&#34;&gt;CNCJ (Cloud Native Community Japan)&lt;/a&gt;, and we believe it will further promote the culture of open source more powerfully.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;What is Cloud Native Community Japan (CNCJ)&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;CNCJ was established on November 7, 2023, as a vendor-neutral forum to connect CNCF upstream with the Japanese community, companies, and organizations, to promote CNCF and cloud-native technologies in Japan, and to encourage OSS contributions and innovation in cloud-native from Japan.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As of September 2023, there was only one CNCF Ambassador in Japan, and the number of Japanese speakers at KubeCon + CloudNativeCon was in the single digits. There was also no Japanese community working with CNCF. Therefore, volunteers from the CNCF and the Japanese community co-founded CNCJ.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Since its inception, each meetup and sub-chapter has brought together people interested in cloud native technologies, allowing us to listen to the voices of people from various industries.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Recap event on March 13, 2024&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The &lt;a href=&#34;https://kutj.connpass.com/event/310096/&#34;&gt;first event as CNCJ&lt;/a&gt; was held on Wednesday, March 13, 2024.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Active maintainers and contributors were running the lectures, almost all of them belonging to different repositories, and they were able to share their real experiences, which was well received by the participants.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We had a large number of Japanese company employees and students attend this year’s event. Of the 50 slots available, 47 folks signed up for the program, with a maximum of 35 participants. The majority of them submitted PRs and proceeded to the merge, and we had a lot of questions and a lot of excitement.　&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We plan to continue organizing this event once or twice a year, and each time we will also share some new trends as well.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you would like to be notified of these events, please contact &lt;a href=&#34;https://community.cncf.io/cloud-native-community-japan/&#34;&gt;CNCJ&lt;/a&gt; or &lt;a href=&#34;https://kutj. connpass.com/&#34;&gt;Kubernetes Upstream Training Japan&lt;/a&gt; and register as a member. You will receive an email notification as soon as the event is scheduled.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In addition, as a SIG of CNCJ, we have updated our materials and workshop recordings and and they are kept in the &lt;a href=&#34;https://github.com/kubernetes-sigs/%20contributor-playground/tree/master/japan/adhoc&#34;&gt;kubernetes-sigs/contributor-playground/japan/adhoc folder&lt;/a&gt;. The recordings as well as the advance preparation and slides are in the same folder, so those who cannot attend the event can study on their own, watching the recordings whenever they want.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Growing the Cloud-Native Community in Japan&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In doing so, we hope to be able to help more people join our community, promote the development of cloud-native technologies in Japan, and help the cloud native community grow.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Next Event on August 26, 2024&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The next Kubernetes Upstream Training Japan is scheduled for Monday, August 26, 2024, and we are currently looking for participants. By participating in this training, you will not only gain an understanding of the Kubernetes community but also learn specific contribution methods through hands-on experience!&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This event will be a great opportunity to take the first step in contributing and you will gain valuable tips, so if you are in Japan and interested, we look forward to your participation!&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;社区帖子，作者：日本 Kubernetes 上游培训组织者、日本云原生社区组织者、NEC Solution Innovators, Ltd. 软件工程师。&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;什么是&lt;a href=&#34;https://kutj.connpass.com/&#34;&gt;日本 Kubernetes 上游培训&lt;/a&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes Upstream Training Japan 是一门以日语举办的培训课程，介绍为 Kubernetes 社区（也称为上游社区）做出贡献所需的任务、程序和概念，该项目由云原生计算基金会 ( CNCF），并提供实际贡献过程的实践经验。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;由于社区成员需要用英语与外国人交流，对于英语不好且面临文化障碍的日本人来说加入我们的社区需要很大的勇气。对于那些想加入社区但无法迈出第一步的人来说，我们举办这个活动是为了首先在日本创造一个地方，让他们可以用日语与当地专家交流，逐渐熟悉社区的运作方式。&lt; /p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;从 2019 年开始，该活动每年举办一到两次，即使在 COVID-19 期间也是如此，截至 2024 年 5 月，已总共举办了 10 届。我们认为这个活动是有意义的，因为我们能够与来自全国各地的人们进行交流，并且有些人因为这个活动而开始了他们的贡献活动。从今年开始，该活动将成为 &lt;a href=&#34;https://community.cncf.io/cloud-native-community-japan/&#34;&gt;CNCJ（日本云原生社区）&lt;/a&gt; 的 SIG，我们相信它将进一步更有力地弘扬开源文化。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;什么是日本云原生社区 (CNCJ)&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;CNCJ 成立于 2023 年 11 月 7 日，作为供应商中立的论坛，将 CNCF 上游与日本社区、公司和组织联系起来，在日本推广 CNCF 和云原生技术，并鼓励 OSS 贡献和创新来自日本的云原生。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;截至 2023 年 9 月，日本只有一名 CNCF 大使，KubeCon + CloudNativeCon 上讲日语的人数仅为个位数。也没有日本社区与 CNCF 合作。因此，CNCF 和日本社区的志愿者共同创立了 CNCJ。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;自创办以来，每一次的聚会和分章节都汇聚了对云原生技术感兴趣的人们，让我们能够倾听来自各个行业人士的声音。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;2024 年 3 月 13 日活动回顾&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://kutj.connpass.com/event/310096/&#34;&gt;CNCJ 的首次活动&lt;/a&gt;于 2024 年 3 月 13 日星期三举行。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;活跃的维护者和贡献者正在主持讲座，几乎所有人都属于不同的存储库，他们能够分享他们的真实经验得到了与会人员的一致好评。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;今年的活动有很多日本公司的员工和学生参加。在 50 个可用名额中，有 47 人报名参加了该计划，参与者最多为 35 人。他们中的大多数人提交了 PR 并进行了合并，我们有很多问题，也很兴奋。　&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们计划继续每年举办一到两次这样的活动，每次我们也会分享一些新的趋势。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您想收到这些事件的通知，请联系 &lt;a href=&#34;https://community.cncf.io/cloud-native-community-japan/&#34;&gt;CNCJ&lt;/a&gt; 或 &lt;a href =&#34;https://kutj.connpass.com/&#34;&gt;Kubernetes Upstream Training Japan&lt;/a&gt; 并注册成为会员。活动安排完毕后，您将立即收到电子邮件通知。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;此外，作为 CNCJ 的 SIG，我们更新了我们的材料和研讨会录音，并将它们保存在 &lt;a href=&#34;https://github.com/kubernetes-sigs/%20contributor-playground/tree /master/japan/adhoc&#34;&gt;kubernetes-sigs/contributor-playground/japan/adhoc 文件夹&lt;/a&gt;。录音与事先准备和幻灯片都在同一个文件夹中，因此无法参加活动的人可以自行学习，随时观看录音。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;在日本发展云原生社区&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;通过这样做，我们希望能够帮助更多的人加入我们的社区，促进日本云原生技术的发展，帮助云原生社区成长。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;下一次活动将于 2024 年 8 月 26 日举行&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;下一次 Kubernetes 上游培训日本计划于 2024 年 8 月 26 日星期一举行，我们目前正在寻找参与者。通过参加本次培训，您不仅可以了解Kubernetes社区，还可以通过亲身体验了解具体的贡献方法！&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;此活动将是一个迈出贡献第一步的绝佳机会，您将获得宝贵的提示，因此，如果您在日本并且对此感兴趣，我们期待您的参与！&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Tue, 20 Aug 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Announcing Envoy Proxy 1.31.0 and Envoy Gateway 1.1】宣布推出 Envoy 代理 1.31.0 和 Envoy 网关 1.1</title>
      <link>https://www.cncf.io/blog/2024/08/27/announcing-envoy-proxy-1-31-0-and-envoy-gateway-1-1/</link>
      <description>【&lt;p&gt;&lt;em&gt;Project post by Jimmy Song, Erica Hughberg, Alyssa Wilk, Guy Daich&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Introduction&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We are thrilled to announce the new releases of the Envoy project, Envoy Proxy 1.31.0 and the Envoy Gateway 1.1.0, now supporting version 1.1 of the Kubernetes Gateway API.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The Envoy Gateway 1.1 control plane enables you to leverage even more of the power of Envoy Proxy 1.31 as a Kubernetes Gateway. This first release of Envoy Gateway post GA continues to make it easier for you to configure, run, and use Envoy Proxy at scale.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The diverse and engaged Envoy community keeps solving shared traffic management challenges with common solutions, enabling us all to do even more in our cloud native environments. Showcasing the real industry power and impact of multi-company open source solutions.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Envoy Proxy&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;These updates bring a host of new features, improvements, and optimizations to enhance your cloud native infrastructure.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Dozens of new features, from improved health checks, to enhanced mirroring and retries, to extended access logs&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Improved error reporting for HTTP/3 and DNS resolution errors.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;New HTTP/3 “happy eyeballs” feature for improved connectivity upstream.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Proxy Protocol now supports typed metadata by default&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Extended support for Redis commands in Bloom 1.0.0&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Significant improvements to HTTP/2 security&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For more information, please visit the&lt;a href=&#34;https://github.com/envoyproxy/envoy/releases/tag/v1.31.0&#34;&gt; Envoy Proxy 1.31.0 release summary&lt;/a&gt; and full &lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/v1.31.0/version_history/v1.31/v1.31.0&#34;&gt;release notes&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Envoy Gateway&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Envoy Gateway 1.1 simplifies the management and deployment of Envoy, making it more accessible and easier to use as a Kubernetes ingress gateway.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Here are the highlights:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Leverage Gateway API 1.1: &lt;/strong&gt;The Envoy Gateway community strives to align with the evolution of the Gateway API, making sure fast turnaround on implementing change&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Get more control over traffic handling with new configuration flexibility:&lt;/strong&gt; Define and order filters, apply backend and client traffic handling policies, and reuse backend traffic handling policies across gateway routes.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Enhance Security with Gradual mTLS Rollout:&lt;/strong&gt; Gradually roll out mTLS for client-to-gateway TLS, ensuring a smooth transition without outages.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Reduce Time to Resolution with Improved Observability:&lt;/strong&gt; Grafana dashboard integration, Zipkin Support, and Route Metadata for traffic reports provide enhanced observability for better monitoring and quicker issue resolution.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Customize Traffic Handling with Your Own Code:&lt;/strong&gt; Extend Envoy programmability with external processes using EnvoyExtensionPolicy, allowing you to use WebAssembly (Wasm) extensions, and ExtProc support for calling an external process.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Integrate with your Service Mesh more easily: &lt;/strong&gt;Enhanced service mesh integration by enabling routing to Service Cluster IP targets.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For more details, check out the&lt;a href=&#34;https://gateway.envoyproxy.io/&#34;&gt; Envoy Gateway documentation&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Conclusion&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Stay tuned as we dive into the exciting new capabilities and how they can benefit your projects. Whether you are optimizing performance, enhancing security, gaining deeper insights, or pushing the boundaries of programmability, EG 1.1 provides the tools and features you need. Adopt or upgrade to EG 1.1 today and experience the future of Kubernetes ingress management.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;Jimmy Song、Erica Hughberg、Alyssa Wilk、Guy Daich 的项目帖子&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;简介&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们很高兴地宣布 Envoy 项目的新版本 Envoy Proxy 1.31.0 和 Envoy Gateway 1.1.0，现在支持 Kubernetes Gateway API 1.1 版。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Envoy Gateway 1.1 控制平面使您能够充分利用 Envoy Proxy 1.31 作为 Kubernetes 网关的强大功能。 Envoy Gateway GA 后的第一个版本继续让您更轻松地大规模配置、运行和使用 Envoy 代理。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;多元化且积极参与的 Envoy 社区不断通过通用解决方案解决共享流量管理挑战，使我们所有人能够在云原生环境中做更多事情。展示多公司开源解决方案的真正行业力量和影响。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;特使代理&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这些更新带来了大量新功能、改进和优化，以增强您的云原生基础架构。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;数十项新功能，从改进的运行状况检查到增强的镜像和重试，再到扩展的访问日志&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;改进了 HTTP/3 和 DNS 解析错误的错误报告。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;新的 HTTP/3“快乐眼球”功能可改善上游连接。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;代理协议现在默认支持类型化元数据&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;在 Bloom 1.0.0 中扩展了对 Redis 命令的支持&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;HTTP/2 安全性显着改进&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;有关更多信息，请访问&lt;a href=&#34;https://github.com/envoyproxy/envoy/releases/tag/v1.31.0&#34;&gt;Envoy Proxy 1.31.0 发布摘要&lt;/a&gt;和完整&lt; a href=&#34;https://www.envoyproxy.io/docs/envoy/v1.31.0/version_history/v1.31/v1.31.0&#34;&gt;发行说明&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;特使网关&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Envoy Gateway 1.1 简化了 Envoy 的管理和部署，使其更易于访问且更易于用作 Kubernetes 入口网关。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;以下是要点：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;&lt;strong&gt;利用 Gateway API 1.1：&lt;/strong&gt;Envoy Gateway 社区致力于与 Gateway API 的发展保持一致，确保快速周转实施变更&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;通过新的配置灵活性获得对流量处理的更多控制：&lt;/strong&gt;定义和排序过滤器、应用后端和客户端流量处理策略，以及跨网关路由重复使用后端流量处理策略。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;通过逐步推出 mTLS 增强安全性&lt;/strong&gt;：逐步推出客户端到网关 TLS 的 mTLS，确保平稳过渡而不会出现中断。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;通过改进的可观察性缩短解决问题的时间&lt;/strong&gt;：Grafana 仪表板集成、Zipkin 支持和流量报告的路线元数据提供了增强的可观察性，以便更好地监控和更快地解决问题。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;根据您的需求自定义流量处理自己的代码：&lt;/strong&gt;使用 EnvoyExtensionPolicy 扩展 Envoy 的可编程性与外部进程，允许您使用 WebAssembly (Wasm) 扩展，并支持 ExtProc 来调用外部进程。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;更轻松地与服务网格集成：&lt;/strong&gt;通过启用到服务集群 IP 目标的路由来增强服务网格集成。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;有关更多详细信息，请查看&lt;a href=&#34;https://gateway.envoyproxy.io/&#34;&gt;Envoy 网关文档&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;结论&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;请继续关注我们深入探讨令人兴奋的新功能以及它们如何使您的项目受益。无论您是要优化性能、增强安全性、获得更深入的见解，还是突破可编程性的界限，EG 1.1 都能提供您所需的工具和功能。立即采用或升级到 EG 1.1，体验 Kubernetes 入口管理的未来。&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Mon, 26 Aug 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Announcing 500 Kubestronauts】宣布 500 名 Kubetronauts</title>
      <link>https://www.cncf.io/blog/2024/08/27/announcing-500-kubestronauts/</link>
      <description>【&lt;p&gt;CNCF is pleased to announce that since launching the Kubestronauts program at KubeCon 2024 in Paris, over 500 &lt;a href=&#34;https://www.cncf.io/training/kubestronaut/&#34;&gt;Kubestronauts&lt;/a&gt; have joined the program. Each of these 500+ have active certifications in&amp;nbsp; all of CNCF’s Kubernetes certifications:&amp;nbsp; &lt;a href=&#34;https://www.cncf.io/training/certification/kcna/&#34;&gt;&lt;strong&gt;KCNA&lt;/strong&gt;&lt;/a&gt;, &lt;a href=&#34;https://www.cncf.io/training/certification/kcsa/&#34;&gt;&lt;strong&gt;KCSA&lt;/strong&gt;&lt;/a&gt;, &lt;a href=&#34;https://www.cncf.io/training/certification/cka/&#34;&gt;&lt;strong&gt;CKA&lt;/strong&gt;&lt;/a&gt;, &lt;a href=&#34;https://www.cncf.io/training/certification/ckad/&#34;&gt;&lt;strong&gt;CKAD&lt;/strong&gt;&lt;/a&gt;, &lt;a href=&#34;https://www.cncf.io/training/certification/cks/&#34;&gt;&lt;strong&gt;CKS&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Why become a Kubestronaut?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Becoming a Kubestronaut is more than a title. Here is what you can expect:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Kubestronaut jacket&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;A Credly badge&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Access to the dedicated / private Kubestronaut Slack channel and mailing list&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Coupons for 50% off five certifications each year – for yourself or to share&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;20% off three CNCF events (KubeCon or KubeDays) a year&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Open Source maintainers understand the value of deep, technical knowledge. While certifications validate your Kubernetes expertise, becoming a Kubestronaut adds another layer of recognition for your hard work. This program not only enhances your professional credibility but also paves the way for career growth A survey of our membership shows that 20% of Kubestronauts reported getting these certifications helped them get a raise and 37% say it helped them get a job.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“Becoming a Kubestronaut ensures that your hard work and expertise is acknowledged and valued, reinforcing the importance of recognition in driving innovation and collaboration in the open source community. In my personal opinion, Kubestronauts are some of the most valuable people you can hire in the industry to help you with your cloud native journey.”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;–Chris Aniszczyk, CTO, CNCF&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;What Kubestronauts say about the program:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;As most certifications are hands-on, there is no way to pass the exam unless you know what you are doing. It is proof to your employees and the customers you interact with that you know what exactly you are talking about.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.cncf.io/blog/2024/07/16/kubestronaut-in-orbit-eleni-grosdouli/&#34;&gt;Eleni Grosdouli&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;These certifications have opened up new opportunities for my work and enhanced my resume. Being recognized for your expertise through these certifications can be a powerful catalyst for career advancement.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;–&lt;a href=&#34;https://www.cncf.io/blog/2024/07/30/kubestronaut-in-orbit-kolawole-olowoporoku/&#34;&gt;Kolawole Olowoporoku&amp;nbsp;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Learn more about how to become a &lt;a href=&#34;https://www.cncf.io/training/kubestronaut/kubestronaut-faq/&#34;&gt;Kubestronaut&lt;/a&gt;&amp;nbsp; and read about the highlighted &lt;a href=&#34;https://www.cncf.io/lf-author-category/kubestronaut/&#34;&gt;Kubestronauts in Orbit&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Discover more about our Kubestronauts&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubestronauts come from around the world with members in 76 countries and every continent except Antarctica. Seventeen Kubestronauts are the only ones in their entire country! Our top five countries by number of Kubestronauts are:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;India&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;United States&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Germany&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;The Netherlands&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;France&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Here is the percentage of Kubestronauts from all countries:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXdslPc3JyYxqqTt2NBkq_nvEDURUZRwag5QJ-1DlxKqAKy07ypN5R_WorPswFnqKC31c_Xl-5U5c4k8cQBW84vIphEDQMJOAaPU8_Y8sehT5eYG7GAzXLX_5-APvtPNNmCfbi45CQuwgq60dg6WvUaBd_LH?key=1caxdgkLNSBgavAo9_twQA&#34; alt=&#34;Percentage of kubestronauts per country&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubestronauts represent companies of all sizes, from large cloud providers like Google and AWS to service companies like CapGemini, SopraSteria, and Accenture, as well as smaller companies like Fullstaq.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We’d like to thank all the Kubestronauts for being committed members of the CNCF Open Source community.&amp;nbsp; Learn more about becoming a &lt;a href=&#34;https://www.cncf.io/training/kubestronaut/kubestronaut-faq/&#34;&gt;Kubestronaut&lt;/a&gt; and explore stories in our &lt;a href=&#34;https://www.cncf.io/lf-author-category/kubestronaut/&#34;&gt;Kubestronauts in Orbit&lt;/a&gt; series.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;CNCF 很高兴地宣布，自从在巴黎 KubeCon 2024 上启动 Kubestronauts 计划以来，已有超过 500 名 &lt;a href=&#34;https://www.cncf.io/training/kubestronaut/&#34;&gt;Kubestronauts&lt;/a&gt; 加入程序。这 500 多个人均拥有 CNCF 的所有 Kubernetes 认证中的有效认证：&lt;a href=&#34;https://www.cncf.io/training/certification/kcna/&#34;&gt;&lt;strong&gt;KCNA&lt;/strong&gt;&lt;/a&gt; 、&lt;a href=&#34;https://www.cncf.io/training/certification/kcsa/&#34;&gt;&lt;strong&gt;KCSA&lt;/strong&gt;&lt;/a&gt;、&lt;a href=&#34;https://www.cncf. io/training/certification/cka/&#34;&gt;&lt;strong&gt;CKA&lt;/strong&gt;&lt;/a&gt;、&lt;a href=&#34;https://www.cncf.io/training/certification/ckad/&#34;&gt;&lt;strong&gt;CKAD &lt;/strong&gt;&lt;/a&gt;，&lt;a href=&#34;https://www.cncf.io/training/certification/cks/&#34;&gt;&lt;strong&gt;CKS&lt;/strong&gt;&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;为什么要成为 Kubetronaut？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;成为 Kubetronaut 不仅仅是一个头衔。以下是您可以期待的：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Kubestronaut 夹克&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Credly 徽章&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;访问专用/私人 Kubetronaut Slack 频道和邮件列表&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;每年获得五项认证可享受 50% 折扣的优惠券 - 供自己使用或与他人分享&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;每年三场 CNCF 活动（KubeCon 或 KubeDays）可享受 20% 折扣&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;开源维护者了解深厚的技术知识的价值。虽然认证可以验证您的 Kubernetes 专业知识，但成为 Kubetronaut 可以为您的辛勤工作增添另一层认可。该计划不仅可以提高您的职业信誉，还可以为职业发展铺平道路。对我们会员的调查显示，20% 的 Kubestronaut 表示获得这些认证帮助他们获得加薪，37% 的人表示这帮助他们找到工作。&lt;/p &gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;“成为 Kubetronaut 可确保您的辛勤工作和专业知识得到认可和重视，从而强化认可在推动开源社区创新和协作方面的重要性。在我个人看来，Kubestronauts 是业内最有价值的人才，可以帮助您完成云原生之旅。”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;-Chris Aniszczyk，CNCF 首席技术官&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Kubestronauts 对该计划的评价：&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;由于大多数认证都是实践性的，因此除非您知道自己在做什么，否则无法通过考试。这向您的员工和与您互动的客户证明您确切地知道自己在说什么。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.cncf.io/blog/2024/07/16/kubestronaut-in-orbit-eleni-grosdouli/&#34;&gt;埃莱妮·格罗斯杜利&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这些认证为我的工作开辟了新的机会并丰富了我的简历。通过这些认证您的专业知识得到认可可以成为职业发展的强大催化剂。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;–&lt;a href=&#34;https://www.cncf.io/blog/2024/07/30/kubetronaut-in-orbit-kolawole-olowoporoku/&#34;&gt;Kolawole Olowoporoku &lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;详细了解如何成为 &lt;a href=&#34;https://www.cncf.io/training/kubestronaut/kubestronaut-faq/&#34;&gt;Kubestronaut&lt;/a&gt; 并了解突出显示的&lt;a href=&#34;https://www.cncf.io/lf-author-category/kubestronaut/&#34;&gt;轨道上的 Kubestronauts&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;了解有关我们 Kubestronauts 的更多信息&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubestronauts 来自世界各地，成员遍布 76 个国家和除南极洲以外的各大洲。整个国家仅有十七名 Kubesteronauts！我们的 Kubetronaut 数量排名前五的国家是：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol类=“wp-block-list”&gt;&#xA;&lt;li&gt;印度&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;美国&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;德国&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;荷兰&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;法国&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;以下是来自所有国家/地区的 Kubetronaut 的百分比：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXdslPc3JyYxqqTt2NBkq_nvEDURUZRwag5QJ-1DlxKqAKy07ypN5R_WorPswFnqKC31c_Xl-5U5c4k8cQBW84 vIphEDQMJOAaPU8_Y8sehT5eYG7GAzXLX_5-APvtPNNmCfbi45CQuwgq60dg6WvUaBd_LH?key=1caxdgkLNSBgavAo9_twQA&#34; alt= “每个国家/地区 kubestronaut 的百分比”referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubestronauts 代表各种规模的公司，从 Google 和 AWS 等大型云提供商到 CapGemini、SopraSteria 和 Accenture 等服务公司，以及 Fullstaq 等小型公司。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们要感谢所有 Kubetronauts 成为 CNCF 开源社区的忠实成员。  了解有关成为 &lt;a href=&#34;https://www.cncf.io/training/kubestronaut/kubestronaut-faq/&#34;&gt;Kubestronaut&lt;/a&gt; 的更多信息，并在我们的 &lt;a href=&#34;https://www 中探索故事.cncf.io/lf-author-category/kubetronaut/&#34;&gt;Kubestronauts in Orbit&lt;/a&gt; 系列。&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Mon, 26 Aug 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Kubestronaut in Orbit: Fangel Colón】轨道上的立方体宇航员：科隆监狱</title>
      <link>https://www.cncf.io/blog/2024/08/27/kubestronaut-in-orbit-fangel-colon/</link>
      <description>【&lt;h2 class=&#34;wp-block-heading&#34;&gt;Get to know Fangel&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1800&#34; height=&#34;945&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/08/Kubestronaut-in-Orbit-8.jpg&#34; alt=&#34;fangel colon image&#34; class=&#34;wp-image-116566&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/08/Kubestronaut-in-Orbit-8.jpg 1800w, https://www.cncf.io/wp-content/uploads/2024/08/Kubestronaut-in-Orbit-8-300x158.jpg 300w, https://www.cncf.io/wp-content/uploads/2024/08/Kubestronaut-in-Orbit-8-1024x538.jpg 1024w, https://www.cncf.io/wp-content/uploads/2024/08/Kubestronaut-in-Orbit-8-768x403.jpg 768w, https://www.cncf.io/wp-content/uploads/2024/08/Kubestronaut-in-Orbit-8-194x102.jpg 194w, https://www.cncf.io/wp-content/uploads/2024/08/Kubestronaut-in-Orbit-8-388x204.jpg 388w, https://www.cncf.io/wp-content/uploads/2024/08/Kubestronaut-in-Orbit-8-776x408.jpg 776w, https://www.cncf.io/wp-content/uploads/2024/08/Kubestronaut-in-Orbit-8-1552x816.jpg 1552w, https://www.cncf.io/wp-content/uploads/2024/08/Kubestronaut-in-Orbit-8-900x473.jpg 900w, https://www.cncf.io/wp-content/uploads/2024/08/Kubestronaut-in-Orbit-8-381x200.jpg 381w, https://www.cncf.io/wp-content/uploads/2024/08/Kubestronaut-in-Orbit-8-762x400.jpg 762w, https://www.cncf.io/wp-content/uploads/2024/08/Kubestronaut-in-Orbit-8-590x310.jpg 590w, https://www.cncf.io/wp-content/uploads/2024/08/Kubestronaut-in-Orbit-8-1180x620.jpg 1180w&#34; sizes=&#34;(max-width: 1800px) 100vw, 1800px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This week’s Kubestronaut in Orbit, Fangel Emilio Colón Navarro, lives in the Dominican Republic and is an SRE at Banco BHD. He’s been working with CNCF technologies since 2020.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If you’d like to be a Kubestronaut like Fangel,&amp;nbsp; get more details on the&lt;a href=&#34;https://www.cncf.io/training/kubestronaut/&#34;&gt; CNCF Kubestronaut &lt;/a&gt;page.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;When did you get started with Kubernetes–what was your first project?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;I started working with Kubernetes in 2020 on a project that required deploying ArgoCD. To be honest, I didn’t understand much of what I was doing, but this gave me enough encouragement to start a career studying Kubernetes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;What are the primary CNCF projects you work on or use today? What projects have you enjoyed the most in your career?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The CNCF projects I am currently working on are &lt;a href=&#34;https://github.com/Kubernetes&#34;&gt;Kubernetes&lt;/a&gt;,&amp;nbsp; &lt;a href=&#34;https://github.com/istio&#34;&gt;Istio&lt;/a&gt;,&amp;nbsp; &lt;a href=&#34;https://github.com/kedacore/keda&#34;&gt;Keda&lt;/a&gt;, &lt;a href=&#34;https://github.com/prometheus&#34;&gt;Prometheus&lt;/a&gt;, and &lt;a href=&#34;https://github.com/argoproj/argo-cd&#34;&gt;ArgoCD&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes is the main one since that’s where we run our applications, and we use Istio as a service mesh to manage clusters with a larger volume of workloads. I love Keda for the variety of available metrics available to allow it to adjust to our environments and ArgoCD at the moment as Continuous Deployments between the different clusters that I have.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;How have the certs helped you in your career?&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;These certifications have significantly propelled my career to the next level. It is the first time I feel I have the opportunity to specialize in something specific. Leveling up my professional skills helps me face any challenge at work effectively.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In my current role, I have gotten real value from the &lt;a href=&#34;https://www.cncf.io/training/certification/cks/&#34;&gt;CKS certification&lt;/a&gt; for supporting and making proposals for the management of vulnerabilities in Kubernetes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;&amp;nbsp;How has CNCF helped you or influenced your career?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;I would say that CNCF has been a significant influence on my career. Before, I was unaware of the professional work behind all the CNCF projects and the dedicated individuals who contribute to them. The learning opportunities they provide have been invaluable. I’m truly happy to have discovered CNCF.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;What are some other books/sites/courses you recommend for people who want to work with k8s?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Books:&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;“Kubernetes Security and Observability”&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;“Kubernetes Best Practices”&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Websites:&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Kubernetes official documentation&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Courses:&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Kubernetes-related courses on KodeKloud&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Linux Foundation courses&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Kubernetes Mastery on Udemy&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;What do you do in your free time?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;I usually exercise, and spend time with my family.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;What would you tell someone who is just starting their K8s certification journey? Any tips or tricks?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The key is to practice those concepts that you read or see in educational materials. It is very important to practice what you have learned, since it is the best way to retain it and easily put it into action.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;I was not lucky enough to have someone guide me on my path, but based on my experience I would say to educate yourself on Linux, Networking, and Containers. This is a solid foundation to start with and I am sure that the rest should be easier.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Today the Cloud native ecosystem is way more than Kubernetes. Do you plan to get other cloud native certifications from the CNCF?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Yes, next up for me is:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cncf.io/training/certification/#ica&#34;&gt;Istio Certified Associate (ICA)&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cncf.io/training/certification/cca/&#34;&gt;Cilium Certified Associate (CCA)&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cncf.io/training/certification/#capa&#34;&gt;Certified Argo Project Associate (CAPA)&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cncf.io/training/certification/#CGOA&#34;&gt;GitOps Certified Associate (CGOA)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;How did you get involved with cloud native and Kubernetes in general?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;I became involved through developing plans and ideas that use cloud native technologies. Additionally, I share my knowledge with colleagues who are interested in getting started with these technologies.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;h2 class=&#34;wp-block-heading&#34;&gt;了解 Fangel&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“1800”高度=“945”src=“https://www.cncf.io/ wp-content/uploads/2024/08/Kubestronaut-in-Orbit-8.jpg&#34; alt=&#34;fangel 冒号图像&#34; class=&#34;wp-image-116566&#34; srcset=&#34;https://www.cncf.io/wp -content/uploads/2024/08/Kubestronaut-in-Orbit-8.jpg 1800w，https://www.cncf.io/wp-content/uploads/2024/08/Kubestronaut-in-Orbit-8-300x158。 jpg 300w，https://www.cncf.io/wp-content/uploads/2024/08/Kubestronaut-in-Orbit-8-1024x538.jpg 1024w，https://www.cncf.io/wp-content/ uploads/2024/08/Kubestronaut-in-Orbit-8-768x403.jpg 768w，https://www.cncf.io/wp-content/uploads/2024/08/Kubestronaut-in-Orbit-8-194x102.jpg 194w，https://www.cncf.io/wp-content/uploads/2024/08/Kubestronaut-in-Orbit-8-388x204.jpg 388w，https://www.cncf.io/wp-content/uploads /2024/08/Kubestronaut-in-Orbit-8-776x408.jpg 776w，https://www.cncf.io/wp-content/uploads/2024/08/Kubestronaut-in-Orbit-8-1552x816.jpg 1552w ，https://www.cncf.io/wp-content/uploads/2024/08/Kubestronaut-in-Orbit-8-900x473.jpg 900w，https://www.cncf.io/wp-content/uploads/ 2024/08/Kubestronaut-in-Orbit-8-381x200.jpg 381w，https://www.cncf.io/wp-content/uploads/2024/08/Kubestronaut-in-Orbit-8-762x400.jpg 762w， https://www.cncf.io/wp-content/uploads/2024/08/Kubestronaut-in-Orbit-8-590x310.jpg 590w，https://www.cncf.io/wp-content/uploads/2024 /08/Kubestronaut-in-Orbit-8-1180x620.jpg 1180w&#34; 尺寸=&#34;(最大宽度: 1800px) 100vw, 1800px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;本周的 Orbit Kubetronaut 是 Fangel Emilio Colón Navarro，他住在多米尼加共和国，是 Banco BHD 的 SRE。自 2020 年以来，他一直致力于 CNCF 技术工作。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您想成为像 Fangel 这样的 Kubestronaut，请在&lt;a href=&#34;https://www.cncf.io/training/kubestronaut/&#34;&gt;CNCF Kubestronaut&lt;/a&gt;页面获取更多详细信息。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;您什么时候开始使用 Kubernetes - 您的第一个项目是什么？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我于 2020 年开始在一个需要部署 ArgoCD 的项目上使用 Kubernetes。说实话，我对自己所做的事情不太了解，但这给了我足够的鼓励，让我开始学习 Kubernetes 的职业生涯。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;您现在从事或使用的主要 CNCF 项目是什么？在您的职业生涯中，您最喜欢哪些项目？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我目前正在从事的 CNCF 项目是 &lt;a href=&#34;https://github.com/Kubernetes&#34;&gt;Kubernetes&lt;/a&gt;、&lt;a href=&#34;https://github.com/istio&#34;&gt; Istio&lt;/a&gt;、&lt;a href=&#34;https://github.com/kedacore/keda&#34;&gt;Keda&lt;/a&gt;、&lt;a href=&#34;https://github.com/prometheus&#34;&gt;普罗米修斯&lt;/a &gt; 和 &lt;a href=&#34;https://github.com/argoproj/argo-cd&#34;&gt;ArgoCD&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Kubernetes 是主要的，因为我们在其中运行应用程序，并且我们使用 Istio 作为服务网格来管理具有大量工作负载的集群。我喜欢 Keda，因为它有多种可用指标，可以使其适应我们的环境，并且rgoCD 目前作为我拥有的不同集群之间的持续部署。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;这些证书对您的职业生涯有何帮助？ &lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这些认证极大地将我的职业生涯推向了一个新的水平。这是我第一次觉得自己有机会专注于某件事。提升我的专业技能有助于我有效应对工作中的任何挑战。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在我目前的职位上，我从&lt;a href=&#34;https://www.cncf.io/training/certification/cks/&#34;&gt;CKS 认证&lt;/a&gt;中获得了真正的价值，可以支持并提出建议Kubernetes 中的漏洞管理。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;CNCF 如何帮助您或影响您的职业生涯？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我想说 CNCF 对我的职业生涯产生了重大影响。之前，我并不知道所有 CNCF 项目背后的专业工作以及为这些项目做出贡献的敬业个人。他们提供的学习机会是无价的。我真的很高兴发现 CNCF。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;您为想要使用 k8s 的人推荐了哪些其他书籍/网站/课程？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;书籍：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;“Kubernetes 安全性和可观察性”&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;“Kubernetes 最佳实践”&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;网站：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Kubernetes 官方文档&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;课程：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;KodeKloud 上的 Kubernetes 相关课程&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Linux 基础课程&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;掌握 Udemy 上的 Kubernetes&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;你空闲时间做什么？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我通常锻炼身体，并与家人共度时光。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;您会对刚刚开始 K8s 认证之旅的人说些什么？有什么提示或技巧吗？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;关键是练习您在教育材料中读到或看到的那些概念。练习所学内容非常重要，因为这是保留所学内容并轻松付诸实践的最佳方式。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我没有足够幸运有人在我的道路上指导我，但根据我的经验，我会说要在 Linux、网络和容器方​​面进行自我教育。这是一个坚实的基础，我相信其余的应该会更容易。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;如今，云原生生态系统的意义远不止 Kubernetes。您是否计划获得 CNCF 的其他云原生认证？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;是的，我的下一步是：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cncf.io/training/certification/#ica&#34;&gt;Istio 认证工程师 (ICA)&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cncf.io/training/certification/cca/&#34;&gt;Cilium 认证助理 (CCA)&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cncf.io/training/certification/#capa&#34;&gt;Argo 项目认证助理 (CAPA)&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cncf.io/training/certification/#CGOA&#34;&gt;GitOps 认证助理e（CGOA）&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;您是如何涉足云原生和 Kubernetes 的？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我是通过开发使用云原生技术的计划和想法而参与其中的。此外，我还与有兴趣开始使用这些技术的同事分享我的知识。&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Mon, 26 Aug 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【My journey as a Kubernetes release team shadow: insights and experiences】我作为 Kubernetes 发布团队影子的旅程：见解和经验</title>
      <link>https://www.cncf.io/blog/2024/08/27/my-journey-as-a-kubernetes-release-team-shadow-insights-and-experiences/</link>
      <description>【&lt;p&gt;&lt;em&gt;Community post originally published on &lt;a href=&#34;https://medium.com/@maryam.tavakoli.3/630be70effb0&#34;&gt;Medium&lt;/a&gt; by Maryam Tavakkoli&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://miro.medium.com/v2/resize:fit:1400/1*gRWCRUVqRIuATJHeaiVhqA.png&#34; alt=&#34;Release chart&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Kubernetes Release Team Structure&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;b05f&#34;&gt;Kubernetes has become the de facto standard for container orchestration in the cloud-native ecosystem, powering some of the most critical infrastructures worldwide. The Kubernetes release process, which ensures the stability and improvement of the platform, is central to its continued success and evolution. This process is managed by a dedicated and diverse team of contributors from various organizations across the globe. I had the unique opportunity to serve as a shadow on the Kubernetes Release Team, contributing to the release of Kubernetes versions v1.29, v1.30, and v1.31. In this article, I’ll share my experiences across these release cycles, detailing the responsibilities I took on, the challenges I faced, and the invaluable lessons I learned as part of the broader Kubernetes community.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;151d&#34;&gt;The Release Team and SIG Release&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;c09c&#34;&gt;The Kubernetes Release Team operates as part of the Special Interest Group (SIG) Release.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;4009&#34;&gt;&lt;strong&gt;But what exactly is a SIG?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;d3d6&#34;&gt;A Special Interest Group (SIG) in the Kubernetes community is a group of contributors who collaborate on specific aspects of the project, ranging from networking to storage to releases. Each SIG is responsible for the ongoing development and maintenance of its focus area, ensuring that Kubernetes continues to evolve and improve.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;a449&#34;&gt;According to the&amp;nbsp;&lt;a href=&#34;https://github.com/kubernetes/sig-release/tree/master/release-team&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;SIG Release GitHub&lt;/a&gt;:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p id=&#34;ce93&#34;&gt;The Kubernetes Release Team is embedded within SIG Release and is responsible for the day-to-day work required to successfully deliver each release. Meanwhile, the broader SIG focuses on the continuous improvement of the release process itself.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;f1b6&#34;&gt;Release Team Structure&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;4487&#34;&gt;The Kubernetes Release Team is organized into five sub-teams:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Enhancements&lt;/strong&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;CI Signal &amp;amp; Bug Triage&lt;/strong&gt;&amp;nbsp;(These two sub-teams were merged starting with v1.30)&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Docs&lt;/strong&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Release Notes&lt;/strong&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Communications&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;28c7&#34;&gt;Each sub-team has a specific focus area, which is crucial to the overall release process. Handbooks detailing the responsibilities of both the leads and shadows are available for each sub-team. You can find these handbooks&amp;nbsp;&lt;a href=&#34;https://www.notion.so/LINK&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;7ec0&#34;&gt;&lt;strong&gt;But who is a shadow?!&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;1600&#34;&gt;The Role of Shadows in the Release Process&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;8974&#34;&gt;The shadow program is designed to mentor new contributors, providing them with hands-on experience while ensuring the continuity of the release process. Shadows work closely with their respective leads, gradually taking on more responsibilities as they gain confidence and expertise. This program is vital for cultivating future leaders within the Kubernetes community, ensuring that the release process remains sustainable and inclusive.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;f722&#34;&gt;My Experience as a Kubernetes Release Team Shadow&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;7afa&#34;&gt;I first learned about the Kubernetes release team through a kind friend in the community who shared their positive experience with the program. This is one of the best aspects of being part of such a supportive community — people are always willing to introduce you to new opportunities and help you take your first steps.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;4e6c&#34;&gt;Encouraged by this, I applied to join the v1.29 release team and was accepted as a Bug Triage Shadow.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;2b18&#34;&gt;Bug Triage Shadow for v1.29&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;af7b&#34;&gt;According to the&amp;nbsp;&lt;a href=&#34;https://github.com/kubernetes/sig-release/tree/master/release-team&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;SIG Release GitHub&lt;/a&gt;:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p id=&#34;6971&#34;&gt;The bug triage team is responsible to make sure that Issues and Pull Requests (PRs) which are targeted for the ongoing release cycle are dealt with in a timely fashion.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;c7ba&#34;&gt;Serving as a Bug Triage Shadow for v1.29 was my first experience on the release team, and it highlighted the significance of the community’s role. It was eye-opening to see how the release of the world’s second-largest open-source project is driven by the voluntary collaboration of many dedicated individuals.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;19dd&#34;&gt;Given the relatively light workload for this sub-team, it was decided to merge the Bug Triage team with the CI Signal team since the v1.30 release.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;3c8e&#34;&gt;CI Signal Shadow for v1.30&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;734e&#34;&gt;Being one of the CI Signal Shadows for v1.30 was my most challenging role. CI Signal is one of the most time-intensive roles on the release team, and I gained valuable experience during that cycle.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;7b0d&#34;&gt;According to the&amp;nbsp;&lt;a href=&#34;https://github.com/kubernetes/sig-release/blob/master/release-team/role-handbooks/ci-signal/README.md&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;handbook&lt;/a&gt;, the CI Signal team’s responsibilities include:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p id=&#34;a18b&#34;&gt;Continuously monitoring various e2e tests in SIG-release dashboards throughout the release cycle.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;05e2&#34;&gt;Providing early and ongoing signals on release and test health to both the Release Team and various SIGs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;3509&#34;&gt;Ensuring that all release-blocking tests deliver a clear Go/No-Go signal for the release.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;bb1f&#34;&gt;Following the merge of the Bug Triage sub-team into CI Signal, the responsibilities of Bug Triage were also included in this role.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;df83&#34;&gt;Docs Shadow for v1.31&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;32c4&#34;&gt;My experience as a Docs Shadow for v1.31 was generally smooth. The main challenge was ensuring timely communication with developers, and encouraging them to update the documentation alongside their features. This coordination is crucial so that both the feature and its corresponding documentation are ready for release.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;5ac3&#34;&gt;According to the&amp;nbsp;&lt;a href=&#34;https://github.com/kubernetes/sig-release/blob/master/release-team/role-handbooks/docs/README.md&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;handbook&lt;/a&gt;, the responsibilities of a Docs Shadow include:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p id=&#34;2747&#34;&gt;Identifying new Kubernetes features and enhancements (&lt;a href=&#34;https://www.kubernetes.dev/resources/keps/&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;Kubernetes Enhancement Proposals, also referred to as KEPs&lt;/a&gt;) that require new documentation and tracking them using the Enhancements Tracking sheet created for the release.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;f225&#34;&gt;Creating a dev branch used by contributors to target documentation updates for the upcoming release&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 class=&#34;wp-block-heading&#34; id=&#34;74fd&#34;&gt;Key Takeaways and Lessons Learned&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;07b6&#34;&gt;Being part of the Kubernetes Release Team has been a rewarding experience, providing both technical and personal growth. I gained hands-on experience across various areas of Kubernetes and deepened my appreciation for community involvement and collaboration in driving open-source projects forward.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;a78c&#34;&gt;For anyone interested in contributing to the CNCF community, I highly recommend participating as a shadow in the release team. It’s a challenging yet incredibly fulfilling way to give back to the community and advance your professional development.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p id=&#34;9a7f&#34;&gt;&lt;strong&gt;&lt;em&gt;If you’re ready to get involved, now is your chance to join the release team for the upcoming v1.32 release. Fill out the application form&amp;nbsp;&lt;/em&gt;&lt;/strong&gt;&lt;a href=&#34;https://docs.google.com/forms/d/e/1FAIpQLSdb60FW9aYIepSdXIWexQIKNJ8m3JSqHZ6kkH3Q_I7XP9OVYA/viewform&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;&lt;strong&gt;&lt;em&gt;here&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;&lt;em&gt;.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;04d6&#34;&gt;You can download the PDF version of the release team structure with clickable links&amp;nbsp;&lt;a href=&#34;https://drive.google.com/file/d/1JtZQ14CUZtkYOshx8oCcz4KtSycD_icc/view?usp=sharing&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;HERE&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://miro.medium.com/v2/resize:fit:1400/0*wN6cPkyBhJPpPMMh.png&#34; alt=&#34;image&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Find all my links&amp;nbsp;&lt;a href=&#34;https://linktr.ee/maryamtavakkoli&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;&lt;strong&gt;here&lt;/strong&gt;&lt;/a&gt;.&lt;a href=&#34;https://medium.com/@maryam.tavakoli.3?source=post_page-----630be70effb0--------------------------------&#34;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;ff7c&#34;&gt;&lt;em&gt;I would love to hear your thoughts and feedback on this article.&lt;br&gt;&lt;/em&gt;&lt;strong&gt;&lt;em&gt;Let’s continue learning, sharing, and evolving together!&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;&lt;br&gt;Until next time!&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;社区帖子最初由 Maryam Tavakkoli 在 &lt;a href=&#34;https://medium.com/@maryam.tavakoli.3/630be70effb0&#34;&gt;Medium&lt;/a&gt; 上发布&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://miro.medium.com/v2/resize:fit:1400/1*gRWCRUVqRIuATJHeaiVhqA.png&#34; alt=&#34;发布图表&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Kubernetes 发布团队结构&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;b05f&#34;&gt;Kubernetes 已成为云原生生态系统中容器编排的事实上的标准，为全球一些最关键的基础设施提供支持。 Kubernetes 发布流程确保了平台的稳定性和改进，是其持续成功和发展的核心。该流程由来自全球各个组织的敬业且多元化的贡献者团队管理。我有一个独特的机会作为 Kubernetes 发布团队的影子，为 Kubernetes 版本 v1.29、v1.30 和 v1.31 的发布做出了贡献。在本文中，我将分享我在这些发布周期中的经验，详细介绍我所承担的责任、我面临的挑战以及我作为更广泛的 Kubernetes 社区的一部分学到的宝贵经验教训。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;151d&#34;&gt;发布团队和 SIG 发布&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;c09c&#34;&gt;Kubernetes 发布团队作为特别兴趣组 (SIG) 发布的一部分运作。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;4009&#34;&gt;&lt;strong&gt;但是 SIG 到底是什么？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;d3d6&#34;&gt;Kubernetes 社区中的特殊兴趣小组 (SIG) 是一群在项目特定方面（从网络、存储到发布）进行协作的贡献者。每个 SIG 负责其重点领域的持续开发和维护，确保 Kubernetes 不断发展和改进。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;a449&#34;&gt;根据 &lt;a href=&#34;https://github.com/kubernetes/sig-release/tree/master/release-team&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt; SIG 发布 GitHub&lt;/a&gt;：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p id=&#34;ce93&#34;&gt;Kubernetes 发布团队嵌入在 SIG Release 中，负责成功交付每个版本所需的日常工作。同时，更广泛的 SIG 专注于发布流程本身的持续改进。&lt;/p&gt;&#xA;&lt;/块引用&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;f1b6&#34;&gt;发布团队结构&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;4487&#34;&gt;Kubernetes 发布团队分为五个子团队：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;增强&lt;/strong&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;CI 信号和错误分类&lt;/strong&gt;（这两个子团队从 v1.30 开始合并）&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;文档&lt;/strong&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;发行说明&lt;/strong&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;通讯&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;28c7&#34;&gt;每个子团队都有一个特定的重点领域，这对于整个发布流程至关重要。手册ks 详细说明了每个子团队的领导和影子的职责。您可以&lt;a href=&#34;https://www.notion.so/LINK&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;此处&lt;/a&gt;找到这些手册。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;7ec0&#34;&gt;&lt;strong&gt;但是谁是影子？！&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;1600&#34;&gt;影子在发布过程中的作用&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;8974&#34;&gt;影子计划旨在指导新贡献者，为他们提供实践经验，同时确保发布过程的连续性。影子与各自的领导密切合作，随着他们获得信心和专业知识，逐渐承担更多责任。该计划对于培养 Kubernetes 社区未来的领导者、确保发布过程保持可持续和包容性至关重要。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;f722&#34;&gt;我作为 Kubernetes 发布团队影子的经历&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;7afa&#34;&gt;我第一次了解 Kubernetes 发布团队是通过社区中的一位好朋友，他分享了他们对该项目的积极体验。这是成为这样一个支持性社区的一部分的最好的方面之一 - 人们总是愿意向您介绍新的机会并帮助您迈出第一步。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;4e6c&#34;&gt;受此鼓舞，我申请加入 v1.29 发布团队，并被接受为 Bug Triage Shadow。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;2b18&#34;&gt;v1.29 的错误分类阴影&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;af7b&#34;&gt;根据 &lt;a href=&#34;https://github.com/kubernetes/sig-release/tree/master/release-team&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt; SIG 发布 GitHub&lt;/a&gt;：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p id=&#34;6971&#34;&gt;错误分类团队负责确保及时处理针对当前发布周期的问题和拉取请求 (PR)。&lt;/p&gt;&#xA;&lt;/块引用&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;c7ba&#34;&gt;担任 v1.29 的 Bug Triage Shadow 是我在发布团队的第一次经历，它凸显了社区角色的重要性。看到世界第二大开源项目的发布是如何由许多奉献者的自愿合作推动的，真是令人大开眼界。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;19dd&#34;&gt;考虑到该子团队的工作量相对较轻，自 v1.30 版本起，决定将 Bug Triage 团队与 CI Signal 团队合并。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;3c8e&#34;&gt;CI 信号影子 v1.30&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;734e&#34;&gt;成为 v1.30 的 CI Signal Shadows 之一是我最具挑战性的角色。 CI Signal 是发布团队中最耗时的角色之一，我在这个周期中获得了宝贵的经验。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;7b0d&#34;&gt;根据 &lt;a href=&#34;https://github.com/kubernetes/sig-release/blob/master/release-team/role-handbooks/ci-signal/README.md&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;手册&lt;/a&gt;，CI Signal 团队的职责其中包括：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p id=&#34;a18b&#34;&gt;在整个发布周期中持续监控 SIG 发布仪表板中的各种 e2e 测试。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;05e2&#34;&gt;向发布团队和各个 SIG 提供有关发布和测试运行状况的早期和持续信号。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;3509&#34;&gt;确保所有发布阻止测试为发布提供明确的“通过/不通过”信号。&lt;/p&gt;&#xA;&lt;/块引用&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;bb1f&#34;&gt;随着 Bug Triage 子团队合并到 CI Signal 中，Bug Triage 的职责也纳入了该角色。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;df83&#34;&gt;Docs Shadow v1.31&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;32c4&#34;&gt;我作为 v1.31 Docs Shadow 的体验总体来说很顺利。主要挑战是确保与开发人员及时沟通，并鼓励他们更新文档及其功能。这种协调至关重要，这样该功能及其相应的文档才能准备好发布。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;5ac3&#34;&gt;根据 &lt;a href=&#34;https://github.com/kubernetes/sig-release/blob/master/release-team/role-handbooks/docs/README.md&#34; rel= &#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;手册&lt;/a&gt;，Docs Shadow的职责包括：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p id=&#34;2747&#34;&gt;确定新的 Kubernetes 功能和增强功能 (&lt;a href=&#34;https://www.kubernetes.dev/resources/keps/&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;Kubernetes 增强提案，也称为 KEP&lt;/a&gt;），需要新文档并使用为该版本创建的增强跟踪表来跟踪它们。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;f225&#34;&gt;创建供贡献者使用的开发分支，以针对即将发布的版本进行文档更新&lt;/p&gt;&#xA;&lt;/块引用&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 class=&#34;wp-block-heading&#34; id=&#34;74fd&#34;&gt;主要要点和经验教训&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;07b6&#34;&gt;成为 Kubernetes 发布团队的一员是一次有益的经历，可以实现技术和个人的成长。我在 Kubernetes 的各个领域获得了实践经验，并加深了对推动开源项目向前发展的社区参与和协作的赞赏。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;a78c&#34;&gt;对于任何有兴趣为 CNCF 社区做出贡献的人，我强烈建议您作为发布团队的影子参与其中。这是回馈社区和促进职业发展的一种具有挑战性但令人难以置信的充实方式。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p id=&#34;9a7f&#34;&gt;&lt;strong&gt;&lt;em&gt;如果您准备好参与，现在就有机会加入即将发布的 v1.32 版本的发布团队。填写申请表&lt;a href=&#34;https://docs.google.com/forms/d/e/1FAIpQLSdb60FW9aYIepSdXIWexQIKNJ8m3JSqHZ6kkH3Q_I7XP9OVYA/viewform&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;&lt;strong&gt;&lt;em&gt;这里&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;&lt;em&gt;。&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;/块引用&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;04d6&#34;&gt;您可以通过可点击的链接下载 PDF 版本的发布团队结构&lt;a href=&#34;https://drive.google.com/file/d/1JtZQ14CUZtkYOshx8oCcz4KtSycD_icc/view?usp=sharing&#34; rel =&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;此处&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://miro.medium.com/v2/resize:fit:1400/0*wN6cPkyBhJPpPMMh.png&#34; alt=&#34;image “referrerpolicy =“no-referrer”&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在&lt;a href=&#34;https://linktr.ee/maryamtavakkoli&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;&lt;strong&gt;此处&lt;/strong&gt;&lt;/a&gt;查找我的所有链接。&lt;a href =&#34;https://medium.com/@maryam.tavakoli.3?source=post_page-----630be70effb0------------------------ --------&#34;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p id=&#34;ff7c&#34;&gt;&lt;em&gt;我很想听听您对本文的想法和反馈。&lt;br&gt;&lt;/em&gt;&lt;strong&gt;&lt;em&gt;让我们继续学习、分享和共同发展！&lt;/em &gt;&lt;/strong&gt;&lt;em&gt;&lt;br&gt;下次再见！&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Mon, 26 Aug 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【How to create a Kubernetes cluster in a Local Zone through Managed Rancher Service】如何通过 Managed Rancher Service 在本地区域创建 Kubernetes 集群</title>
      <link>https://www.cncf.io/blog/2024/08/27/how-to-create-a-kubernetes-cluster-in-a-local-zone-through-managed-rancher-service/</link>
      <description>【&lt;p&gt;&lt;em&gt;Member post originally published on &lt;a href=&#34;https://blog.ovhcloud.com/how-to-create-a-kubernetes-cluster-in-a-local-zone-through-managed-rancher-service/&#34;&gt;OVH Cloud’s blog&lt;/a&gt; by Aurélie Vache &lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Container orchestration has become a cornerstone of modern application deployment, offering scalability, flexibility, and resource efficiency. It has become common to have to manage several Kubernetes clusters, but to do so efficiently it is useful to be well equipped.&lt;br&gt;&lt;br&gt;In this blog post we will see how to create a Kubernetes cluster in an OVHcloud Local Zone through Managed Rancher Service.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Managed Rancher Services (MRS)&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://blog.ovhcloud.com/wp-content/uploads/2024/07/image-18.png&#34; alt=&#34;Image&#34; class=&#34;wp-image-27146&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Managed Rancher Services (MRS), in Beta for now, is based on Rancher, an open-source container management platform, that simplifies the deployment and management of Kubernetes clusters. Managed Rancher Service by OVHcloud provides a powerful platform for orchestrating Kubernetes clusters seamlessly.&lt;br&gt;&lt;br&gt;Find more information on our&amp;nbsp;dedicated&lt;a href=&#34;https://www.ovhcloud.com/fr/public-cloud/managed-rancher-service/&#34;&gt;&amp;nbsp;Managed Rancher Services page&lt;/a&gt;.&lt;br&gt;&lt;br&gt;&lt;strong&gt;Note: The product is in Beta so you can&lt;a href=&#34;https://www.ovh.com/auth/?onsuccess=https%3A%2F%2Fwww.ovh.com%2Fmanager%2F%23%2Fpublic-cloud%3Fcontext%3Dwebsite&amp;amp;ovhSubsidiary=GB&amp;amp;_gl=1*rqcgpi*_gcl_au*ODk0Njk3ODc2LjE3MjA3NzExMTE.&#34;&gt;&amp;nbsp;try Managed Rancher Services for free&lt;/a&gt;!&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Local Zones (LZ)&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image aligncenter is-resized&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://blog.ovhcloud.com/wp-content/uploads/2024/07/image-19-1024x683.png&#34; alt=&#34;Image&#34; class=&#34;wp-image-27147&#34; style=&#34;width:486px;height:auto&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This year we also launched Local Zones. Local Zones are an extension of&amp;nbsp;&lt;a href=&#34;https://www.ovhcloud.com/en-gb/public-cloud/regions-availability/&#34;&gt;regions&lt;/a&gt;&amp;nbsp;that bring OVHcloud services closer to specific locations, offering reduced latency and improved performances for applications.&lt;br&gt;Local Zones are strategically placed in proximity to areas with high user demand. Their main goal is to minimize the time it takes to transfer data between the user and the cloud, in order to make services faster and more responsive, and meet data residency requirements.&lt;br&gt;&lt;br&gt;Find more information on our&amp;nbsp;dedicated&lt;a href=&#34;https://www.ovhcloud.com/en-gb/public-cloud/local-zone-compute/&#34;&gt;&amp;nbsp;Local Zone page&lt;/a&gt;.&lt;br&gt;&lt;br&gt;&lt;strong&gt;&lt;em&gt;Note: Until 31 August 2024 you can&lt;a href=&#34;https://www.ovh.com/auth/?onsuccess=https%3A%2F%2Fwww.ovh.com%2Fmanager%2F%23%2Fpublic-cloud%3Fcontext%3Dwebsite&amp;amp;ovhSubsidiary=GB&amp;amp;_gl=1*rqcgpi*_gcl_au*ODk0Njk3ODc2LjE3MjA3NzExMTE.&#34;&gt;&amp;nbsp;try Local Zones for free&lt;/a&gt;!&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Kubernetes on Compute instances&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://blog.ovhcloud.com/wp-content/uploads/2024/07/image-20.png&#34; alt=&#34;Image&#34; class=&#34;wp-image-27148&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;At OVHcloud we have a Managed Kubernetes Services solution but you can also deploy Kubernetes clusters on Compute Instances if you want to managed in your own your clusters.&lt;br&gt;&lt;br&gt;Find more information on our dedicated&amp;nbsp;&lt;a href=&#34;https://www.ovhcloud.com/en-gb/public-cloud/compute/&#34;&gt;Compute instances page&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Demo&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In this demo we will:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;Create 5 compute instances (3 for the Kubernetes’s etcd + controlplane &amp;amp; 2 for workers) on a Local Zone&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Create a managed Rancher&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;In Rancher, configure the instances to deploy into them a Kubernetes cluster (with k3s or RKE2, depending on your needs ans use cases)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Creating Compute instances&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;First, you have to log in to the&amp;nbsp;&lt;a href=&#34;https://help.ovhcloud.com/csm/en-gb-public-cloud-kubernetes-create-cluster?id=kb_article_view&amp;amp;sysparm_article=KB0049683&#34;&gt;OVHcloud Control Panel&amp;nbsp;&lt;/a&gt;and open the&amp;nbsp;&lt;strong&gt;Public Cloud&lt;/strong&gt;&amp;nbsp;section. Then access the&amp;nbsp;&lt;strong&gt;Instances&lt;/strong&gt;&amp;nbsp;under the&amp;nbsp;&lt;strong&gt;Compute&lt;/strong&gt;&amp;nbsp;section.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Click on the&amp;nbsp;&lt;strong&gt;Create an instance&lt;/strong&gt;&amp;nbsp;button.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Choose a model (the type of an instance / the flavor,&amp;nbsp;&lt;code&gt;B3-8&lt;/code&gt;&amp;nbsp;for example, but you can choose another one, depending on your needs).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Choose a local zone (&lt;code&gt;Marseille&lt;/code&gt;&amp;nbsp;for example):&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://blog.ovhcloud.com/wp-content/uploads/2024/07/lz-1024x615.png&#34; alt=&#34;Images&#34; class=&#34;wp-image-27131&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Choose a distribution (&lt;code&gt;Ubuntu&lt;/code&gt;&amp;nbsp;for example).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Select your SSH key (we have to log in our instances later).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Choose&amp;nbsp;&lt;code&gt;5&lt;/code&gt;&amp;nbsp;as the number of instances to be created and change the name of the instance name (&lt;code&gt;lz-kube&lt;/code&gt;&amp;nbsp;for example).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Check the checkbox&amp;nbsp;&lt;code&gt;Public network&lt;/code&gt;&amp;nbsp;(to have a pubic IP).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The instances will take several minutes to spawn.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Deploying a Managed Rancher&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Still in the OVHcloud Control Panel, click on the&amp;nbsp;&lt;strong&gt;Create a Managed Rancher Service&lt;/strong&gt;&amp;nbsp;button.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Fill a name (&lt;code&gt;my_lz_rancher&lt;/code&gt;&amp;nbsp;for example), choose the&amp;nbsp;&lt;strong&gt;Standard&lt;/strong&gt;&amp;nbsp;plan, the recommended version then click on the&amp;nbsp;&lt;strong&gt;Create a Managed Rancher Service&lt;/strong&gt;&amp;nbsp;button.&lt;br&gt;Rancher instances are pre-provisioned, so your instance will be created immediately.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In the list of existing Managed Rancher Service, click on your instance, then click on&amp;nbsp;&lt;strong&gt;Generate access code&lt;/strong&gt;&amp;nbsp;button to generate the login and password to access to Rancher. Save the login and password and click on&amp;nbsp;&lt;strong&gt;Go to Rancher&lt;/strong&gt;&amp;nbsp;button.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Copy/paste the password in&amp;nbsp;&lt;strong&gt;password&lt;/strong&gt;&amp;nbsp;field and click on&amp;nbsp;&lt;strong&gt;Log in with Local User&lt;/strong&gt;&amp;nbsp;button.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;A new password will be generated, save it! Save the server URL too, check the&amp;nbsp;&lt;strong&gt;End User License Agreement&lt;/strong&gt;&amp;nbsp;checkbox and click on the&amp;nbsp;&lt;strong&gt;Continue&lt;/strong&gt;&amp;nbsp;button.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Configuring Rancher to deploy a Kubernetes cluster&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Creating a cluster&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In Rancher UI, click on the&amp;nbsp;&lt;strong&gt;Create&lt;/strong&gt;&amp;nbsp;button and then on the&amp;nbsp;&lt;strong&gt;Custom&lt;/strong&gt;&amp;nbsp;driver:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://blog.ovhcloud.com/wp-content/uploads/2024/07/custom.png&#34; alt=&#34;Images&#34; class=&#34;wp-image-27133&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Fill a cluster name (&lt;code&gt;lz-k3s&lt;/code&gt;&amp;nbsp;for example).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In the Kubernetes version list, choose the latest version of the wanted OS. For this blog post we will choose the latest version of K3s, but for production needs we recommend RKE2 instead.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://blog.ovhcloud.com/wp-content/uploads/2024/07/k3s-1024x423.png&#34; alt=&#34;Image&#34; class=&#34;wp-image-27134&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Then click on&amp;nbsp;&lt;code&gt;Create&lt;/code&gt;&amp;nbsp;button.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Configuring the cluster&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;:&lt;br&gt;In Rancher when you configure a node, there are three roles that can be assigned to nodes:&amp;nbsp;&lt;code&gt;&lt;em&gt;etcd&lt;/em&gt;&lt;/code&gt;,&amp;nbsp;&lt;code&gt;&lt;em&gt;controlplane&lt;/em&gt;&lt;/code&gt;&amp;nbsp;and&amp;nbsp;&lt;code&gt;&lt;em&gt;worker&lt;/em&gt;&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;There are some good practices:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;At least 3 nodes with the role&amp;nbsp;&lt;code&gt;etcd&lt;/code&gt;&amp;nbsp;are needed to survive a loss of 1 node and have a minimum high availability configuration for&amp;nbsp;&lt;code&gt;etcd&lt;/code&gt;. 3&amp;nbsp;&lt;code&gt;etcd&lt;/code&gt;&amp;nbsp;nodes are generally sufficient for smaller and medium clusters, and 5&amp;nbsp;&lt;code&gt;etcd&lt;/code&gt;&amp;nbsp;nodes for large clusters.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;At least 2 nodes with the role&amp;nbsp;&lt;code&gt;controlplane&lt;/code&gt;&amp;nbsp;for master component high availability.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;You can set both the&amp;nbsp;&lt;code&gt;etcd&lt;/code&gt;&amp;nbsp;and&amp;nbsp;&lt;code&gt;controlplane&lt;/code&gt;&amp;nbsp;roles for one instance.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;The worker role should not be used or added to nodes with the&amp;nbsp;&lt;code&gt;etcd&lt;/code&gt;&amp;nbsp;or&amp;nbsp;&lt;code&gt;controlplane&lt;/code&gt;&amp;nbsp;role.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;At least 2 nodes with the role&amp;nbsp;&lt;code&gt;worker&lt;/code&gt;&amp;nbsp;for workload rescheduling upon node failure.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For the configuration of our&amp;nbsp;&lt;code&gt;etcd + control planes&lt;/code&gt;&amp;nbsp;nodes, check only the&amp;nbsp;&lt;code&gt;&lt;em&gt;etcd&lt;/em&gt;&lt;/code&gt;&amp;nbsp;and&amp;nbsp;&lt;code&gt;&lt;em&gt;control&lt;/em&gt;&amp;nbsp;&lt;em&gt;plane&lt;/em&gt;&lt;/code&gt;&amp;nbsp;Nodes Roles:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://blog.ovhcloud.com/wp-content/uploads/2024/07/etcdnode-1024x501.png&#34; alt=&#34;Image&#34; class=&#34;wp-image-27139&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;And copy/paste the registration command in a file.&lt;br&gt;For the configuration of our&amp;nbsp;&lt;code&gt;worker&lt;/code&gt;&amp;nbsp;nodes, uncheck the checkboxes and check only the&amp;nbsp;&lt;code&gt;Worker&lt;/code&gt;&amp;nbsp;checkbox:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://blog.ovhcloud.com/wp-content/uploads/2024/07/workernode-1024x435.png&#34; alt=&#34;Image&#34; class=&#34;wp-image-27141&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;And copy/paste the registration command in a file.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In the OVHcloud Control Panel, click on the&amp;nbsp;&lt;strong&gt;Instances&lt;/strong&gt;&amp;nbsp;button.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Fill the search box with the beginning of the name of our instances:&amp;nbsp;&lt;code&gt;lz-kube&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://blog.ovhcloud.com/wp-content/uploads/2024/07/search-1024x529.png&#34; alt=&#34;Image&#34; class=&#34;wp-image-27142&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For the first three instances, pick the Public IP addresses and then in your local terminal connect you in ssh and copy/paste the first registration command (for etcd and control plane nodes):&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;$ ssh root@xxx.xxx.xxx.xxx&#xA;The authenticity of host &#39;xxx.xxx.xxx.xxx (xxx.xxx.xxx.xxx)&#39; can&#39;t be established.&#xA;ED25519 key fingerprint is SHA256:dqsdqsdqsdqsd/dqsdqsdqsdqsdqsdqsdq.&#xA;This key is not known by any other names&#xA;Are you sure you want to continue connecting (yes/no/[fingerprint])? yes&#xA;...&#xA;root@lz-kube-1:~# curl -fL https://dsqdsqdqsd.p7mg.rancher.ovh.net/system-agent-install.sh | sudo  sh -s - --server https://dsqdsqdqsd.p7mg.rancher.ovh.net --label &#39;cattle.io/os=linux&#39; --token kbv5k48vc8thhgqqhmtd8tn55qtlpgw7jp4llm4m4tvnp9sznscmpf --etcd --controlplane&#xA;  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current&#xA;                                 Dload  Upload   Total   Spent    Left  Speed&#xA;100 30794    0 30794    0     0   156k      0 --:--:-- --:--:-- --:--:--  157k&#xA;[INFO]  Label: cattle.io/os=linux&#xA;...&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;And for the last two instances, pick the Public IP addresses and then in your local terminal connect you in ssh and copy/paste the second registration command (for worker nodes):&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;$ ssh root@xxx.xxx.xxx.xxx&#xA;The authenticity of host &#39;xxx.xxx.xxx.xxx (xxx.xxx.xxx.xxx)&#39; can&#39;t be established.&#xA;ED25519 key fingerprint is SHA256:dqsdqsdqsdqsd/dqsdqsdqsdqsdqsdqsdq.&#xA;This key is not known by any other names&#xA;Are you sure you want to continue connecting (yes/no/[fingerprint])? yes&#xA;...&#xA;&#xA;root@lz-kube-4:~# curl -fL https://dsqdsqdqsd.p7mg.rancher.ovh.net/system-agent-install.sh | sudo  sh -s - --server https://dsqdsqdqsd.p7mg.rancher.ovh.net --label &#39;cattle.io/os=linux&#39; --token kbv5k48vc8thhgqqhmtd8tn55qtlpgw7jp4llm4m4tvnp9sznscmpf --worker&#xA;&#xA;  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current&#xA;                                 Dload  Upload   Total   Spent    Left  Speed&#xA;100 30794    0 30794    0     0   156k      0 --:--:-- --:--:-- --:--:--  157k&#xA;[INFO]  Label: cattle.io/os=linux&#xA;...&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Wait until the cluster is in&amp;nbsp;&lt;code&gt;Active&lt;/code&gt;&amp;nbsp;state.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Connecting to the cluster with kubectl CLI&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In Rancher UI, click on the&amp;nbsp;&lt;code&gt;lz-k3s&lt;/code&gt;&amp;nbsp;cluster.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Then click on the&amp;nbsp;&lt;strong&gt;Download KubeConfig&lt;/strong&gt;&amp;nbsp;icon to download the kubeconfig file and save the path of kubeconfig in an environment variable:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;$ export KUBE_CLUSTER=$(pwd)/lz_k3s.yml&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Test the connexion to the Kubernetes:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;$ kubectl --kubeconfig=$KUBE_CLUSTER cluster-info&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;List the nodes:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;$ kubectl --kubeconfig=$KUBE_CLUSTER get no&#xA;&#xA;NAME        STATUS   ROLES                       AGE     VERSION&#xA;lz-kube-1   Ready    control-plane,etcd,master   9m9s    v1.27.14+k3s1&#xA;lz-kube-2   Ready    control-plane,etcd,master   9m28s   v1.27.14+k3s1&#xA;lz-kube-3   Ready    control-plane,etcd,master   10m     v1.27.14+k3s1&#xA;lz-kube-4   Ready    worker                      8m59s   v1.27.14+k3s1&#xA;lz-kube-5   Ready    worker                      9m      v1.27.14+k3s1&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Conclusion&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We deployed and configured a Kubernetes cluster in Compute Instances on Local Zones with the new Managed Rancher Services and we discovered how to connect to it.&lt;br&gt;During the Beta phase, MRS is free so don’t hesitate to test it.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Want to go further?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Visit our technical&amp;nbsp;&lt;a href=&#34;https://help.ovhcloud.com/csm/en-gb-documentation-public-cloud-containers-orchestration-managed-rancher-service?id=kb_browse_cat&amp;amp;kb_id=574a8325551974502d4c6e78b7421938&amp;amp;kb_category=ba1cdc8ff1a082502d4cea09e7c8beb9&amp;amp;spa=1&#34;&gt;guides and how to about OVHcloud Managed Rancher Service&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;成员帖子最初发布于 &lt;a href=&#34;https://blog.ovhcloud.com/how-to-create-a-kubernetes-cluster-in-a-local-zone-through-management- rancher-service/&#34;&gt;OVH Cloud 的博客&lt;/a&gt; 作者：Aurélie Vache &lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;容器编排已成为现代应用程序部署的基石，提供可扩展性、灵活性和资源效率。管理多个 Kubernetes 集群已变得很常见，但要高效地管理多个 Kubernetes 集群，配备精良的设备非常有用。&lt;br&gt;&lt;br&gt;在这篇博文中，我们将了解如何通过以下方式在 OVHcloud 本地区域中创建 Kubernetes 集群：托管 Rancher 服务。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;托管 Rancher 服务 (MRS)&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://blog.ovhcloud.com/wp-content/uploads/2024/07/image-18.png&#34; alt= “图像”class =“wp-image-27146”referrerpolicy =“no-referrer”&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;托管 Rancher Services (MRS) 目前处于测试阶段，基于开源容器管理平台 Rancher，可简化 Kubernetes 集群的部署和管理。 OVHcloud 的托管 Rancher 服务提供了一个强大的平台，用于无缝编排 Kubernetes 集群。&lt;br&gt;&lt;br&gt;有关我们的专用&lt;a href=&#34;https://www.ovhcloud.com/fr/public-cloud/management- rancher-service/&#34;&gt; 托管 Rancher 服务页面&lt;/a&gt;。&lt;br&gt;&lt;br&gt;&lt;strong&gt;注意：该产品处于 Beta 阶段，因此您可以&lt;a href=&#34;https://www.ovh.com/auth /?onsuccess=https%3A%2F%2Fwww.ovh.com%2Fmanager%2F%23%2Fpublic-cloud%3Fcontext%3Dwebsite&amp;ovhSubsidiary=GB&amp;_gl=1*rqcgpi*_gcl_au*ODk0Njk3ODc2LjE3MjA3NzExMTE。&#34;&gt; 免费试用 Managed Rancher 服务&lt;/一个&gt;!&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;本地区域 (LZ)&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-imagealigncenter is-resized&#34;&gt;&lt;imgdecoding=&#34;async&#34;src=&#34;https://blog.ovhcloud.com/wp-content/uploads/2024/07/image-19- 1024x683.png&#34; alt=&#34;图像&#34; class=&#34;wp-image-27147&#34; style=&#34;width:486px;height:auto&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;今年我们还推出了本地区域。本地区域是&lt;a href=&#34;https://www.ovhcloud.com/en-gb/public-cloud/regions-availability/&#34;&gt;区域&lt;/a&gt;的扩展，使 OVHcloud 服务更接近特定位置，提供减少延迟并提高应用程序性能。&lt;br&gt;本地区域战略性地放置在靠近用户需求较高的区域。他们的主要目标是最大限度地减少用户和云之间传输数据所需的时间，以使服务更快、响应更灵敏，并满足数据驻留要求。&lt;br&gt;&lt;br&gt;在我们的专用&lt;a href=&#34;https://www.ovhcloud.com/en-gb/public-cloud/local-zone-compute/&#34;&gt; 本地区域页面&lt;/a&gt;。&lt;br&gt;&lt;br&gt;&lt;strong&gt;&lt;em&gt;注意：在 2024 年 8 月 31 日之前，您可以&lt;a href=&#34;https://www.ovh.com/auth/?onsuccess=https%3A%2F%2Fwww.ovh.com%2Fmanager%2F%23%2Fpublic-cloud%3Fcontext %3Dwebsite&amp;ovhSubsidiary=GB&amp;_gl=1*rqcgpi*_gcl_au*ODk0Njk3ODc2LjE3MjA3NzExMTE。&#34;&gt; 尝试本地免费区域&lt;/a&gt;！&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;计算实例上的 Kubernetes&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://blog.ovhcloud.com/wp-content/uploads/2024/07/image-20.png&#34; alt= “图像”类=“wp-image-27148”referrerpolicy=“no-referrer”&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在 OVHcloud，我们有托管 Kubernetes 服务解决方案，但如果您想在自己的集群中进行管理，您也可以在计算实例上部署 Kubernetes 集群。&lt;br&gt;&lt;br&gt;在我们的专用 &lt;a href=&#34; 上查找更多信息https://www.ovhcloud.com/en-gb/public-cloud/compute/&#34;&gt;计算实例页面&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;演示&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在此演示中，我们将：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;在本地区域上创建 5 个计算实例（3 个用于 Kubernetes 的 etcd + 控制平面，2 个用于工作线程）&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;创建托管 Rancher&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;在 Rancher 中，配置实例以将 Kubernetes 集群部署到其中（使用 k3s 或 RKE2，具体取决于您的需求和用例）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;创建计算实例&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;首先，您必须登录&lt;a href=&#34;https://help.ovhcloud.com/csm/en-gb-public-cloud-kubernetes-create-cluster?id=kb_article_view&amp;sysparm_article=KB0049683&#34;&gt; OVHcloud 控制面板&lt;/a&gt;并打开&lt;strong&gt;公有云&lt;/strong&gt;部分。然后访问&lt;strong&gt;计算&lt;/strong&gt;部分下的&lt;strong&gt;实例&lt;/strong&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;点击&lt;strong&gt;创建实例&lt;/strong&gt;按钮。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;选择模型（实例类型/风格，例如 &lt;code&gt;B3-8&lt;/code&gt;，但您可以根据需要选择其他模型）。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;选择本地区域（例如&lt;code&gt;马赛&lt;/code&gt;）：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://blog.ovhcloud.com/wp-content/uploads/2024/07/lz-1024x615.png&#34; alt= “图像”class =“wp-image-27131”referrerpolicy =“no-referrer”&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;选择一个发行版（例如 &lt;code&gt;Ubuntu&lt;/code&gt;）。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;选择您的 SSH 密钥（我们必须稍后登录我们的实例）。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;选择&lt;code&gt;5&lt;/code&gt;作为要创建的实例数量，并更改实例名称（例如&lt;code&gt;lz-kube&lt;/code&gt;）。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;选中复选框&lt;code&gt;公共网络&lt;/code&gt;（拥有公共 IP）。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;实例将需要几分钟才能生成。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;部署托管 Rancher&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;仍然在 OVHcloud 控制面板中，点击&lt;strong&gt;创建托管 Rancher 服务&lt;/strong&gt;按钮。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;填写名称（例如 &lt;code&gt;my_lz_rancher&lt;/code&gt;），选择&lt;strong&gt;标准&lt;/strong&gt;计划、推荐版本，然后点击&lt;strong&gt;创建托管 Rancher 服务&lt;/strong&gt;按钮。&lt;br&gt;Rancher 实例是预先配置的，因此您的实例将立即创建。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在列表中现有 Managed Rancher Service 的实例，点击您的实例，然后点击&lt;strong&gt;生成访问代码&lt;/strong&gt;按钮生成用于访问 Rancher 的登录名和密码。保存登录名和密码，然后点击&lt;strong&gt;转到 Rancher&lt;/strong&gt; 按钮。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;将密码复制/粘贴到&lt;strong&gt;密码&lt;/strong&gt;字段中，然后点击&lt;strong&gt;使用本地用户登录&lt;/strong&gt;按钮。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;将会生成一个新密码，保存！也保存服务器 URL，选中&lt;strong&gt;最终用户许可协议&lt;/strong&gt;复选框，然后单击&lt;strong&gt;继续&lt;/strong&gt;按钮。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;配置 Rancher 部署 Kubernetes 集群&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;创建集群&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在 Rancher UI 中，点击&lt;strong&gt;创建&lt;/strong&gt;按钮，然后点击&lt;strong&gt;自定义&lt;/strong&gt;驱动程序：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://blog.ovhcloud.com/wp-content/uploads/2024/07/custom.png&#34; alt=&#34;图像“class =“wp-image-27133”referrerpolicy =“no-referrer”&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;填写集群名称（例如&lt;code&gt;lz-k3s&lt;/code&gt;）。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在 Kubernetes 版本列表中，选择所需操作系统的最新版本。在本博文中，我们将选择最新版本的 K3s，但出于生产需求，我们建议使用 RKE2。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://blog.ovhcloud.com/wp-content/uploads/2024/07/k3s-1024x423.png&#34; alt= “图像”class =“wp-image-27134”referrerpolicy =“no-referrer”&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;然后点击&lt;code&gt;创建&lt;/code&gt;按钮。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;配置集群&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;：&lt;br&gt;在 Rancher 中配置节点时，可以为节点分配三个角色：&lt;code&gt;&lt;em&gt;etcd&lt;/em&gt;&lt;/code&gt;、 &lt;code&gt;&lt;em&gt;控制平面&lt;/em&gt;&lt;/code&gt;和&lt;code&gt;&lt;em&gt;工作线程&lt;/em&gt;&lt;/code&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;有一些好的做法：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;至少需要 3 个具有 &lt;code&gt;etcd&lt;/code&gt; 角色的节点，才能在丢失 1 个节点的情况下幸存下来，并具有 &lt;code&gt;etcd&lt;/code&gt; 的最低高可用性配置。对于中小型集群，3 个 &lt;code&gt;etcd&lt;/code&gt; 节点通常就足够了，对于大型集群，5 个 &lt;code&gt;etcd&lt;/code&gt; 节点就足够了。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;至少 2 个具有&lt;code&gt;控制平面&lt;/code&gt;角色的节点，以实现主组件的高可用性。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;您可以为一个实例同时设置 &lt;code&gt;etcd&lt;/code&gt; 和 &lt;code&gt;controlplane&lt;/code&gt; 角色。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;不应使用辅助角色或将辅助角色添加到具有 &lt;code&gt;etcd&lt;/code&gt; 或 &lt;code&gt;controlplane&lt;/code&gt; 角色的节点。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;至少 2 个具有&lt;code&gt;worker&lt;/code&gt; 角色的节点，用于在节点故障时重新安排工作负载。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;对于&lt;code&gt;etcd + 控制平面&lt;/code&gt;节点的配置，仅检查&amp;nbsp;&lt;code&gt;&lt;em&gt;etcd&lt;/em&gt;&lt;/code&gt; 和&lt;code&gt;&lt;em&gt;control&lt;/em&gt; &lt;em&gt;plane&lt;/em&gt;&lt;/code&gt; 节点角色：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://blog.ovhcloud.com/wp-content/uploads/2024/07/etcdnode-1024x501.png&#34; alt= “图像”class =“wp-image-27139”referrerpolicy =“no-referrer”&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;然后将注册命令复制/粘贴到文件中。&lt;br&gt;对于&lt;code&gt;worker&lt;/code&gt;节点的配置，取消选中复选框并仅选中&lt;code&gt;Worker&lt;/code&gt;复选框：&lt; /p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://blog.ovhcloud.com/wp-content/uploads/2024/07/workernode-1024x435.png&#34; alt= “图像”类=“wp-image-27141”referrerpolicy=“no-referrer”&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;并将注册命令复制/粘贴到文件中。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在 OVHcloud 控制面板中，点击&lt;strong&gt;实例&lt;/strong&gt;按钮。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在搜索框中填写实例名称的开头：&lt;code&gt;lz-kube&lt;/code&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://blog.ovhcloud.com/wp-content/uploads/2024/07/search-1024x529.png&#34; alt= “图像”类=“wp-image-27142”referrerpolicy=“no-referrer”&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;对于前三个实例，选择公共 IP 地址，然后在本地终端中通过 ssh 连接您并复制/粘贴第一个注册命令（对于 etcd 和控制平面节点）：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;$ ssh root@xxx.xxx.xxx.xxx&#xA;无法确定主机“xxx.xxx.xxx.xxx (xxx.xxx.xxx.xxx)”的真实性。&#xA;ED25519 密钥指纹为 SHA256:dqsdqsdqsdqsd/dqsdqsdqsdqsdqsdqsdq。&#xA;该密钥没有任何其他名称&#xA;您确定要继续连接吗（是/否/[指纹]）？是的&#xA;...&#xA;root@lz-kube-1:~#curl -fL https://dsqdsqdqsd.p7mg.rancher.ovh.net/system-agent-install.sh | sudo sh -s - --server https://dsqdsqdqsd.p7mg.rancher.ovh.net --label &#39;cattle.io/os=linux&#39; --token kbv5k48vc8thhgqqhmtd8tn55qtlpgw7jp4llm4m4tvnp9sznscmpf --etcd --controlplane&#xA;  % 总计 % 已接收 % Xferd 平均速度 时间 时间 时间 当前&#xA;                                 Dload 上传总花费左速度&#xA;100 30794 0 30794 0 0 156k 0 --:--:-- --:--:-- --:--:-- 157k&#xA;[信息] 标签：cattle.io/os=linux&#xA;...&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;对于最后两个实例，选择公共 IP 地址，然后在本地终端中通过 ssh 连接您并复制/粘贴第二个注册命令（对于工作节点）：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;$ ssh root@xxx.xxx.xxx.xxx&#xA;无法确定主机“xxx.xxx.xxx.xxx (xxx.xxx.xxx.xxx)”的真实性。&#xA;ED25519 密钥指纹为 SHA256:dqsdqsdqsdqsd/dqsdqsdqsdqsdqsdqsdq。&#xA;该密钥没有任何其他名称&#xA;您确定要继续连接吗（是/否/[指纹]）？是的&#xA;...&#xA;&#xA;root@lz-kube-4:~#curl -fL https://dsqdsqdqsd.p7mg.rancher.ovh.net/system-agent-install.sh | sudo sh -s - --server https://dsqdsqdqsd.p7mg.rancher.ovh.net --label &#39;cattle.io/os=linux&#39; --token kbv5k48vc8thhgqqhmtd8tn55qtlpgw7jp4llm4m4tvnp9sznscmpf --worker&#xA;&#xA;  % 总计 % 已接收 % Xferd 平均速度 时间 时间 时间 当前&#xA;                                 Dload 上传总花费左速度&#xA;100 30794 0 30794 0 0 156k 0 --:--:-- --:--:-- --:--:-- 157k&#xA;[信息] 标签：cattle.io/os=linux&#xA;...&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;等待集群处于&lt;code&gt;Active&lt;/code&gt;状态。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;使用 kubectl CLI 连接到集群&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在 Rancher UI 中，点击 &lt;code&gt;lz-k3s&lt;/code&gt; 集群。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;然后点击&lt;strong&gt;下载 KubeConfig&lt;/strong&gt; 图标下载 kubeconfig 文件并将 kubeconfig 的路径保存在环境变量中：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;$ export KUBE_CLUSTER=$(pwd)/lz_k3s.yml&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;测试与 Kubernetes 的连接：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;$ kubectl --kubeconfig=$KUBE_CLUSTER 集群信息&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;列出节点：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;$ kubectl --kubeconfig=$KUBE_CLUSTER 没有得到&#xA;&#xA;姓名 状态 角色 年龄 版本&#xA;lz-kube-1 就绪控制平面、etcd、master 9m9s v1.27.14+k3s1&#xA;lz-kube-2 就绪控制平面、etcd、master 9m28s v1.27.14+k3s1&#xA;lz-kube-3 就绪控制平面、etcd、master 10m v1.27.14+k3s1&#xA;lz-kube-4 Ready Worker 8m59s v1.27.14+k3s1&#xA;lz-kube-5 Ready Worker 9m v1.27.14+k3s1&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;结论&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们使用新的托管 Rancher 服务在本地区域的计算实例中部署和配置了 Kubernetes 集群，并了解了如何连接到它。&lt;br&gt;在 Beta 阶段，MRS 是免费的，因此请毫不犹豫地测试它.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;想走得更远吗？&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;访问我们的技术&lt;a href=&#34;https://help.ovhcloud.com/csm/en-gb-documentation-public-cloud-containers-orchestration-management-rancher-service?id=kb_browse_cat&amp;kb_id=574a8325551974502d4c6e78b7421938&amp;kb_category=ba1cdc8ff1a0 82502d4cea09e7c8beb9&amp;spa =1&#34;&gt;OVHcloud Managed Rancher Service 的指南和操作方法&lt;/a&gt;。&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Mon, 26 Aug 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【wasmCloud on the factory floor: efficient and secure processing of high velocity machine data】工厂车间的 wasmCloud：高效、安全地处理高速机器数据</title>
      <link>https://www.cncf.io/blog/2024/08/23/wasmcloud-on-the-factory-floor-efficient-and-secure-processing-of-high-velocity-machine-data/</link>
      <description>【&lt;p&gt;&lt;em&gt;End user blog by Jochen Rau and Tyler Schoppe, Platform Engineering team at MachineMetrics&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p class=&#34;has-black-color has-gray-300-background-color has-text-color has-background has-link-color wp-elements-af86228d1572f0ae063b571f002771af&#34;&gt;&lt;em&gt;“WebAssembly, wasmCloud, and NATS will not only reshape the MachineMetrics business but are already transforming industrial IoT. A big thanks to the WebAssembly and wasmCloud community for supporting us all the way here and providing such awesome tools.”&lt;/em&gt; – &lt;strong&gt;Jochen Rau, Data Platform Lead, MachineMetrics.&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Improving Manufacturing Performance, Efficiency and Longevity&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Operating in the manufacturing sector has never been more costly. Exacerbated by high inflation, the cost of materials, fuel, shipping and labor have risen exponentially post-pandemic. In response, manufacturers are looking for ways to reduce maintenance costs, and improve production capacity. They’re doing this by putting advanced data analytics into production lines to better understand and optimize machine performance.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.machinemetrics.com/&#34;&gt;&lt;strong&gt;MachineMetrics LLC&lt;/strong&gt;&lt;/a&gt;, is a catalyst for this next phase of digital transformation. The company’s customers operate factories and plants containing advanced manufacturing machinery, producing swathes of unutilized data. Reporting is usually carried out manually, sometimes on thousands of machines. Manual errors often arise which result in missed anomalies, risking eventual machine failure.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;MachineMetrics’ edge monitoring devices connect to each machine to capture timely and accurate data from machine controls and sensors. By being able to closely analyze the performance of machinery, operators more accurately predict wear and tear. This reduces costly incidents, lowers maintenance costs and extends the longevity of equipment.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Data capture alone, however, consumes the majority of resources on each device which leaves less space to do much else. The inherent abundance of high-frequency data, coupled with network constraints, make visualizing that data difficult in tools like Grafana. MachineMetrics’ Data Platform Team Engineers Jochen Rau and Tyler Schoppe, suspected that the efficiency of the WebAssembly (Wasm) bytecode format could help solve this issue and unlock greater architectural freedom.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;WebAssembly is often described as a tiny virtual machine designed to execute portable bytecode in any location, at near native speed. When built with standardized, interchangeable &lt;strong&gt;WebAssembly components&lt;/strong&gt;, applications can run on any server, device or cloud that supports the standard APIs of WASI (WebAssembly System Interfaces) 0.2, regardless of the underlying hardware or operating system.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To test the theory, Rau and Schoppe designed an early PoC with the CNCF Sandbox Project &lt;strong&gt;wasmCloud&lt;/strong&gt;, which enables users to run WebAssembly workloads in distributed environments.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Edge Extensibility with WebAssembly&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Streaming high frequency data poses considerable challenges, exponentially increasing ingest costs. Many factories do not have the network bandwidth to support volume data being streamed across a fleet of machines. Adding to the challenge, a single edge device can collect data from dozens of systems machines and push it to the cloud, but this leaves few resources available for compute.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The PoC was created to discover whether wasmCloud could provide a more efficient and lightweight compute methodology, with business logic that could be more easily transported over the network. This would make better use of existing available resources at the edge, and put portable processing where needed most.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Engineered around the standard APIs of WASI 0.2, wasmCloud allowed the team to deploy and manage workloads as &lt;a href=&#34;https://component-model.bytecodealliance.org/design/why-component-model.html&#34;&gt;&lt;strong&gt;components&lt;/strong&gt;&lt;/a&gt;: portable, interoperable WebAssembly binaries that could run anywhere from the cloud to the edge. By including only the code they needed in components and fulfilling non-functional requirements with wasmCloud providers linked at runtime, applications could be tiny and portable. Because the non-functional requirements are externalized, updating dependencies for large fleets of devices is easy in case of a bug or needed feature&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Most importantly, the team could manage and run wasmCloud on existing Kubernetes clusters in a way that felt familiar to them, bringing the kind of extensibility to Kubernetes that was previously impossible.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXeQ03a-VU58Bo3qCnvFCXmGQJgXuZsMMZnnnpXgAVC2s7e3wuxiyTsESk7aWU8mzclP-DrGIh8uBEeRieTUrTv39jlMhG09DKQCYV6ZCgLHBEWdEhXPneY45JjlFbi_whAVah8ebch8mViL_Y-fpUfSMZo?key=7akIfN2LsupSp5m-Be-HvA&#34; alt=&#34;Figure 1: What platform engineering feels like in the wasmCloud ecosystem.&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 1: What platform engineering feels like in the wasmCloud ecosystem.&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Proof of Concept: Downsampling High-Frequency Data&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The team developed a custom algorithm allowing high-frequency data to be downsampled from any deployment target. This would allow processing power to be moved between edges and clouds, according to need and without losing data fidelity. Whether analyzing 5000 data points or just 50, the data would be consistent. Built on Sveinn Steinarsson’s (University of Iceland) &lt;a href=&#34;https://skemman.is/bitstream/1946/15343/3/SS_MSthesis.pdf&#34;&gt;Largest-Triangle-Three-Buckets (LTTB)&lt;/a&gt; algorithm, it was adjusted to operate on unbounded streams and provided stateful processing to enable storage.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Implemented in Rust and deployed in wasmCloud as a Wasm component, the completed downsampling algorithm reports proactive maintenance telemetry across edge and cloud platforms. Crucially, the algorithm is deployed to wasmCloud with Wadm, a Wasm components native orchestrator that integrates seamlessly with Kubernetes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Jochen Rau: &lt;em&gt;“Wadm simplifies creating and linking components. It’s easy to define your providers, as well as your components, in this common model and produce the providers you need for key-value mass messaging, as well as the downsampling component, hooked up together with some links. That’s great for reconciliation. And as we release new versions, it helps make sure everything goes smoothly.”&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The algorithm proves it’s possible to run high-frequency data workloads as components, on edge devices running in wasmCloud. wasmCloud is also shown to be an effective compute lattice on which to move workloads seamlessly between deployment targets. In the next development phase, Schoppe and Rau will deploy wasmCloud on machines, and begin to observe the potential efficiencies.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXfiGTZTIIDfEganWVi9J0xfYQF_7S2GPe59lkUa3j0EVNVq8JjMYZnmSoyRYee09KASHX95SVN2K8B0rq_GdrWRSl84ukEE9SXjEF_k7_0S5jjL41CsR5RDx5a9YgpujBLDZoIJXu5MCH2Ra-FVzXroURbl?key=7akIfN2LsupSp5m-Be-HvA&#34; alt=&#34;Figure 2: Downsampling algorithm maintains fidelity of the graph even at low sampling rates&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 2: Downsampling algorithm maintains fidelity of the graph even at low sampling rates&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXdDrMnXScGVx-kcAdKM9EfkDeH0KhIsmsjoJImwnuuJroOEkIxzEBsmT7tdkJKhMW1BPH5br8ASIlynU7aDXRcIeeu7ckEI1N07dSh2_lUZyNMPZ0sSAgGhVFBrUJHyrnSC5inTKhgtBaOrcr_OT-zDcNI?key=7akIfN2LsupSp5m-Be-HvA&#34; alt=&#34;Figure 3: Architecture of the PoC showing wasmCloud host running on an edge device. NATS serves as backbone for machine, configuration, and control data.&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 3: Architecture of the PoC showing wasmCloud host running on an edge device. NATS serves as backbone for machine, configuration, and control data.&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;What are the challenges wasmCloud overcomes?&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Portable Processing Made Real&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Rather than handing off data to be processed in the cloud, applications running as components in wasmCloud are radically smaller, freeing resources to process and stream performance data directly from machines. For MachineMetrics’ customers, that means lower latency, faster time-to-value, and fewer hardware problems.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This is only half the story. The real advantage for the team is in making these workloads portable to &lt;em&gt;any&lt;/em&gt; location—easily shifted back-and-forth between multiple edges and clouds. This gives the team freedom to make better and quicker architectural decisions.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Tyler Schoppe: &lt;em&gt;“What’s powerful is we don’t have to think about where the compute lives. wasmCloud takes that off the minds of developers, the importance of which cannot be overstated. If we need to make changes it’s a lot easier to pivot and move workloads from the edge to the cloud; if we need to scale, for instance. That would be very challenging for us to do in our current architecture.”&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;wasmCloud also breaks down language barriers. Usually, edge application teams work in a different preferred languages to their cloud engineering counterparts. Whether written in Python, Go, C++ or any other language, WASI 0.2 components mean edge and cloud teams can interoperate using standard WebAssembly Interface Type (WIT) definitions for interfaces. This unties them from specific libraries so they can focus on business logic.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Architectural Freedom = Resource Efficiency&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In traditional IoT models, processing is linear and unidirectional. Data is collected from separate sensors: captured by an edge, then ingested into a cloud—where the majority of compute takes place—before being handed off to the consumer. By pushing processing to the cloud, higher costs are incurred and latency increases. More importantly, valuable, more efficient processing capacity at the edge is underutilized.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;MachineMetrics does the majority of its data processing in Kubernetes in the cloud. By moving compute to devices, existing edge resources are used more effectively and cloud resources preserved. Porting logic between resources means the team can balance their resources against their needs. They use the cloud to scale the processing of larger data sets, whilst allowing edge devices to process and stream real-time data directly to operators.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Jochen Rau: &lt;em&gt;“The focus is to find ways to more efficiently use resources that we already have at the edge, and manage our cloud resources more effectively. wasmCloud helps us do that. It’s also a balance—edge devices are relatively small so we can scale much more easily in the cloud. Having the flexibility to move workloads around means greater resource efficiency.”&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Extending the Value of Existing Architecture&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;MachineMetrics uses Kubernetes extensively, but the team can’t run it at the edge. This is partly due to the company’s OS configuration, but primarily due to the limitations of Kubernetes. Kubernetes is great at managing infrastructure, but not so good at running applications on resource-constrained devices.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To solve this problem,&lt;a href=&#34;https://www.youtube.com/watch?v=fQdkNGZqYZA&#34;&gt; MachineMetrics&lt;/a&gt; uses wasmCloud alongside Kubernetes and ArgoCD, making use of the &lt;a href=&#34;https://github.com/wasmcloud/wasmcloud-operator&#34;&gt;wasmcloud-operator&lt;/a&gt; to deploy software to all of its edge locations. The wasmcloud-operator allows platform engineers to manage and run Wasm on Kubernetes using the standard, familiar controller pattern and custom resource definitions (CRDs), all while remaining decoupled from Kubernetes and free to leverage the unique benefits of components. Bringing the kind of extensibility to Kubernetes that was previously impossible.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Rau says: &lt;em&gt;“We shifted up a level: taking the wasmCloud host and deploying it on Kubernetes. The wasmcloud-operator makes this really simple to manage with our existing tools. We deploy our compute workloads on the lattice on wasmCloud. We’re crossing the boundaries between edge and cloud.”&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Using this “decoupled” model means it’s easy for MachineMetrics to tie wasmCloud directly into existing pipelines and tools like ArgoCD.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXc1BHaog5GC0UGS5GKpmHHycGimOj8goujL-piBc8wGgHvKwzWAY-ZXD5bEKBY41ZebFql-y0i-amlE-UBNBqB3HGs9ihWsQRwNB4w2wdtJad-fy1UJ6rhtCr_EIhKW6Q0RAUulz5KD7OPGPC_denwcew?key=7akIfN2LsupSp5m-Be-HvA&#34; alt=&#34;Figure 4: wasmCloud integrates with Kubernetes but as a separate service. This means engineers can capitalize on the benefits of the component model.&amp;nbsp;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 4: wasmCloud integrates with Kubernetes but as a separate service. This means engineers can capitalize on the benefits of the component model.&amp;nbsp;&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Deny-By-Default Security&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Security is also a major consideration for MachineMetrics. Each customer has completely distinct approaches to security. Some have large, dedicated security teams whereas others may adopt a leaner approach. In every case, data is highly sensitive–MachineMetrics has to bring the same cast-iron security to every use case, and must be able to scale the same level of security to devices and sensors.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The power of WebAssembly allows wasmCloud applications to run securely from edge to edge. All code runs in a deny-by-default, secure, stateless, and reactive sandbox. The sandbox satisfies larger customers’ enterprise Service Level Agreements and more complex security, compliance, and policy requirements.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Tyler Schoppe: &lt;em&gt;“We work with mom and pop shops making screws, all the way to hardware planned for outer space. Regardless of how much or little security they have, we treat their security with the same level of care. wasmCloud’s sandbox model gives us a lot of guarantees. In terms of developer peace of mind, it provides a lot for us out of the box.&lt;/em&gt;”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;wasmCloud’s hosts enforce a certain level of default security that cannot be loosened. For example, hosts will always validate runtime links. Additionally, the wasmCloud policy service API can be used to extend and customize policy evaluation, such as by restricting untrusted application components and providers on particular hosts.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;Benefits to Manufacturers&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The team believes the benefits of being able to process and stream high velocity data directly from machines will excite their customers, from small shops to large plants. Carbide tools are very expensive—each machine costs thousands—so properly managing the utilization of them is essential. Damaged tools are not just expensive to replace, they can take out entire production lines. Extending the life of their tools through closer monitoring will save customers thousands in maintenance and replacements.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For Rau, the exciting part is being able to deliver a feature that customers have been waiting for.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Rau: &lt;em&gt;“Downsampled high frequency data is as expressive as raw data; we’re moving beyond aggregated monitoring data to being able to see real-time, high velocity data on dashboards. This is something our customers are asking for.”&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Rau and Schoppe are now taking what they’ve learned from the PoC, developing the solution further and investigating ways to integrate with third-party machinery.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Schoppe concludes:&lt;em&gt; “There’s nothing like this on the market right now and so it’s a great opportunity for us to put this kind of compute power in many more customers’ hands. As well as helping us differentiate, it will provide tremendous operational value for customers—something they can rely on to help them save money in a different way.”&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;MachineMetrics 平台工程团队 Jochen Rau 和 Tyler Schoppe 撰写的最终用户博客&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p class=&#34;has-black-color has-gray-300-background-color has-text-color has-background has-link-color wp-elements-af86228d1572f0ae063b571f002771af&#34;&gt;&lt;em&gt;“WebAssembly、wasmCloud 和 NATS 将不仅重塑了 MachineMetrics 业务，而且已经在改变工业物联网。非常感谢 WebAssembly 和 wasmCloud 社区一直以来对我们的支持，并提供了如此出色的工具。”&lt;/em&gt; – &lt;strong&gt;MachineMetrics 数据平台主管 Jochen Rau。&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;/块引用&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;提高制造性能、效率和寿命&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;制造业的运营成本从未如此之高。由于高通胀，材料、燃料、运输和劳动力的成本在大流行后呈指数级上升。对此，制造商正在寻找降低维护成本并提高生产能力的方法。为此，他们将先进的数据分析融入生产线，以更好地了解和优化机器性能。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.machinemetrics.com/&#34;&gt;&lt;strong&gt;MachineMetrics LLC&lt;/strong&gt;&lt;/a&gt; 是数字化转型下一阶段的催化剂。该公司的客户运营着拥有先进制造机械的工厂和工厂，产生了大量未利用的数据。报告通常是手动进行的，有时在数千台机器上进行。手动错误经常出现，导致遗漏异常，从而导致最终机器故障的风险。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;MachineMetrics 的边缘监控设备连接到每台机器，从机器控制和传感器捕获及时、准确的数据。通过密切分析机械性能，操作员可以更准确地预测磨损。这可以减少代价高昂的事故、降低维护成本并延长设备的使用寿命。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;然而，仅数据捕获就消耗了每个设备上的大部分资源，从而留下更少的空间来做其他事情。高频数据固有的丰富性，加上网络限制，使得在 Grafana 等工具中可视化这些数据变得困难。 MachineMetrics 的数据平台团队工程师 Jochen Rau 和 Tyler Schoppe 怀疑 WebAssembly (Wasm) 字节码格式的效率可以帮助解决这个问题并释放更大的架构自由度。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;WebAssembly 通常被描述为一个微型虚拟机，旨在以接近本机的速度在任何位置执行可移植字节码。当使用标准化、可互换的 WebAssembly 组件构建时，应用程序可以在任何支持 WASI（WebAssembly 系统接口）0.2 标准 API 的服务器、设备或云上运行，无论底层硬件或操作系统如何。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;为了测试该理论，Rau 和 Schoppe 使用 CNCF 沙盒项目 &lt;strong&gt;wasmCloud&lt;/strong&gt; 设计了一个早期的 PoC，它使用户能够在分布式环境中运行 WebAssembly 工作负载。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;使用 WebAssembly 进行边缘扩展&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;流式传输高频数据带来了相当大的挑战，采集成本呈指数级增加。许多工厂没有网络带宽来支持在一组机器上传输大量数据。雪上加霜的是，单个边缘设备可以从数十台系统机器收集数据并将其推送到云端，但这使得可用于计算的资源很少。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;创建 PoC 的目的是为了发现 wasmCloud 是否可以提供更高效、更轻量的计算方法，以及可以更轻松地通过网络传输的业务逻辑。这将更好地利用边缘现有的可用资源，并将便携式处理放在最需要的地方。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;wasmCloud 围绕 WASI 0.2 的标准 API 进行设计，允许团队以 &lt;a href=&#34;https://component-model.bytecodealliance.org/design/why-component-model.html&#34;&gt; 的方式部署和管理工作负载&lt;strong&gt;组件&lt;/strong&gt;&lt;/a&gt;：可移植、可互操作的 WebAssembly 二进制文件，可以在从云端到边缘的任何地方运行。通过仅在组件中包含所需的代码并通过运行时链接的 wasmCloud 提供商来满足非功能性需求，应用程序可以变得很小且可移植。由于非功能性需求是外部化的，因此在出现错误或所需功能时可以轻松更新大量设备的依赖关系&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;最重要的是，团队可以以他们熟悉的方式在现有 Kubernetes 集群上管理和运行 wasmCloud，为 Kubernetes 带来以前不可能的可扩展性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXeQ03a-VU58Bo3qCnvFCXmGQJgXuZsMMZnnnpXgAVC2s7e3wuxiyTsESk7aWU8mzclP-DrGIh8uBEeRieTUrTv39jlMh G09DKQCYV6ZCgLHBEWdEhXPneY45JjlFbi_whAVah8ebch8mViL_Y-fpUfSMZo?key=7akIfN2LsupSp5m-Be- HvA&#34; alt=&#34;图 1：wasmCloud 生态系统中的平台工程感觉如何。&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;图 1：wasmCloud 生态系统中的平台工程感觉如何。&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;概念验证：高频数据下采样&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;该团队开发了一种自定义算法，允许从任何部署目标对高频数据进行下采样。这将允许根据需要在边缘和云端之间转移处理能力，并且不会损失数据保真度。无论是分析 5000 个数据点还是仅分析 50 个数据点，数据都是一致的。基于 Sveinn Steinarsson（冰岛大学）的 &lt;a href=&#34;https://skemman.is/bitstream/1946/15343/3/SS_MSthesis.pdf&#34;&gt;Largest-Triangle-Three-Buckets (LTTB)&lt;/a&gt; 算法，它被调整为在无界流上运行，并提供有状态处理以支持存储。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;完整的下采样算法在 Rust 中实现并作为 Wasm 组件部署在 wasmCloud 中，可报告跨边缘和云平台的主动维护遥测。至关重要的是，该算法通过 Wadm 部署到 wasmCloud，Wadm 是一个与 Kubernetes 无缝集成的 Wasm 组件原生编排器。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Jochen Rau：&lt;em&gt;“Wadm 简化了组件的创建和链接。在这个通用模型中，可以轻松定义您的提供程序以及组件，并生成键值群发消息传递所需的提供程序以及下采样组件，并通过一些链接连接在一起。这对和解很有好处。当我们发布新版本时，它有助于确保一切顺利。”&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;该算法证明可以在 wasmCloud 中运行的边缘设备上将高频数据工作负载作为组件运行。 wasmCloud 还被证明是一种有效的计算网格，可以在部署目标之间无缝移动工作负载。在下一个开发阶段，Schoppe 和 Rau 将在机器上部署 wasmCloud，并开始观察潜在的效率。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXfiGTZTIIDfEganWVi9J0xfYQF_7S2GPe59lkUa3j0EVNVq8JjMYZnmSoyRYee09KASHX95SVN2K8B0rq_GdrWRSl84ukEE9SXjEF _k7_0S5jjL41CsR5RDx5a9YgpujBLDZoIJXu5MCH2Ra-FVzXroURbl?key=7akIfN2LsupSp5m-Be-HvA&#34; alt= “图 2：即使在低采样率下，下采样算法也能保持图形的保真度”referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;图 2：下采样算法即使在低采样率下也能保持图形的保真度采样率&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXdDrMnXScGVx-kcAdKM9EfkDeH0KhIsmsjoJImwnuuJroOEkIxzEBsmT7tdkJKhMW1BPH5br8ASIlynU7aDXRcIeeu7ckEI1N0 7dSh2_lUZyNMPZ0sSAgGhVFBrUJHyrnSC5inTKhgtBaOrcr_OT-zDcNI?key=7akIfN2LsupSp5m-Be-HvA&#34; alt=&#34;图 3：PoC 架构显示 wasmCloud 主机在边缘设备上运行。NATS 作为机器、配置和控制数据的骨干网。&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;图 3：PoC 架构，显示在边缘设备上运行的 wasmCloud 主机。 NATS 充当机器、配置和控制数据的骨干网。&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;wasmCloud 克服了哪些挑战？&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;便携式处理成为现实&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在 wasmCloud 中作为组件运行的应用程序不是将数据移交到云中进行处理，而是要小得多，从而释放资源来直接从机器处理和流式传输性能数据。对于 MachineMetrics 的客户来说，这意味着更低的延迟、更快的价值实现和更少的硬件问题。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;这只是故事的一半。该团队的真正优势在于使这些工作负载可移植到&lt;em&gt;任何&lt;/em&gt;位置 - 在多个边缘和云之间轻松来回转移。这使团队可以自由地做出更好、更快的架构决策。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Tyler Schoppe：&lt;em&gt;“强大之处在于我们不必考虑计算所在的位置。 wasmCloud 让开发人员不再考虑这一点，这一点的重要性怎么强调都不为过。如果我们需要做出改变，那么将工作负载从边缘转移到云端会容易得多；例如，如果我们需要扩展。在我们当前的架构中，这对我们来说是非常具有挑战性的。”&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;wasmCloud 还打破了语言障碍。通常，边缘应用程序团队使用与云工程团队不同的首选语言进行工作。无论是用 Python、Go、C++ 还是任何其他语言编写，WASI 0.2 组件都意味着边缘和云团队可以使用标准的 WebAssembly 接口类型 (WIT) 接口定义进行互操作。这将他们从特定的库中解放出来，以便他们可以专注于业务逻辑。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;架构自由 = 资源效率&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在传统的物联网模型中，处理是线性且单向的。数据是从单独的传感器收集的：由边缘捕获，然后摄取到云中（大部分计算发生在云中），然后交给消费者。通过将处理推至云端，会产生更高的成本并增加延迟。更重要的是，有价值、更高效的边缘处理能力没有得到充分利用。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;MachineMetrics 在云中的 Kubernetes 中完成大部分数据处理。通过将计算转移到设备，可以更有效地使用现有边缘资源并保留云资源。在资源之间移植逻辑意味着团队可以根据需求平衡资源。他们使用云来扩展更大数据集的处理，同时允许边缘设备处理实时数据并将其直接传输给运营商。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Jochen Rau：&lt;em&gt;“重点是找到更有效地使用我们已有的边缘资源的方法，并更有效地管理我们的云资源。 wasmCloud 帮助我们做到了这一点。这也是一种平衡——边缘设备相对较小，因此我们可以在云中更轻松地进行扩展。灵活地移动工作负载意味着更高的资源效率。”&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;扩展现有架构的价值&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;MachineMetrics 广泛使用 Kubernetes，但团队无法在边缘运行它。这部分是由于该公司的操作系统配置，但主要是由于 Kubernetes 的限制。 Kubernetes 擅长管理基础设施，但不擅长在资源上运行应用程序资源受限的设备。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;为了解决这个问题，&lt;a href=&#34;https://www.youtube.com/watch?v=fQdkNGZqYZA&#34;&gt;MachineMetrics&lt;/a&gt; 将 wasmCloud 与 Kubernetes 和 ArgoCD 一起使用，利用 &lt;a href= “https://github.com/wasmcloud/wasmcloud-operator&#34;&gt;wasmcloud-operator&lt;/a&gt; 将软件部署到其所有边缘站点。 wasmcloud-operator 允许平台工程师使用标准的、熟悉的控制器模式和自定义资源定义 (CRD) 在 Kubernetes 上管理和运行 Wasm，同时保持与 Kubernetes 的解耦，并自由地利用组件的独特优势。为 Kubernetes 带来以前不可能实现的可扩展性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Rau 说：&lt;em&gt;“我们提升了一个级别：采用 wasmCloud 主机并将其部署在 Kubernetes 上。 wasmcloud-operator 使得使用我们现有的工具来管理变得非常简单。我们将计算工作负载部署在 wasmCloud 上的网格上。我们正在跨越边缘和云之间的界限。”&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;使用这种“解耦”模型意味着 MachineMetrics 可以轻松地将 wasmCloud 直接绑定到现有管道和 ArgoCD 等工具中。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXc1BHaog5GC0UGS5GKpmHHycGimOj8goujL-piBc8wGgHvKwzWAY-ZXD5bEKBY41ZebFql-y0i-amlE-UBNBqB3HGs9i hWsQRwNB4w2wdtJad-fy1UJ6rhtCr_EIhKW6Q0RAUulz5KD7OPGPC_denwcew？ key=7akIfN2LsupSp5m-Be-HvA&#34; alt=&#34;图 4：wasmCloud 与 Kubernetes 集成，但作为一项单独的服务。这意味着工程师可以利用组件模型的优势。  &#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class= &#34;wp-element-caption&#34;&gt;图 4：wasmCloud 与 Kubernetes 集成，但作为单独的服务。这意味着工程师可以利用组件模型的优势。 &lt;/图标题&gt;&lt;/图&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;默认拒绝安全&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;安全性也是 MachineMetrics 的一个主要考虑因素。每个客户都有完全不同的安全方法。有些拥有大型、专门的安全团队，而另一些则可能采用更精简的方法。在每种情况下，数据都高度敏感 - MachineMetrics 必须为每个用例带来相同的铸铁安全性，并且必须能够将相同级别的安全性扩展到设备和传感器。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;WebAssembly 的强大功能允许 wasmCloud 应用程序从边缘到边缘安全地运行。所有代码都在默认拒绝、安全、无状态和反应式沙箱中运行。该沙箱可以满足较大客户的企业服务级别协议以及更复杂的安全性、合规性和策略要求。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Tyler Schoppe：&lt;em&gt;“我们与夫妻店合作生产螺丝，一直到计划用于外太空的硬件。无论他们的安全保障程度如何，我们都会同等程度地保障他们的安全。 wasmCloud的沙盒模型给了我们很多保证。就开发人员的安心而言，它提供了对我们来说有很多开箱即用的东西。&lt;/em&gt;”&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;wasmCloud 的主机强制执行一定程度的默认安全性，且不能放松。例如，主机将始终验证运行时链接。此外，wasmCloud 策略服务 API 可用于扩展和自定义策略评估，例如通过限制特定主机上不受信任的应用程序组件和提供程序。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;&lt;strong&gt;给制造商带来的好处&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;该团队相信，能够直接从机器处理和传输高速数据的好处将使从小商店到大型工厂的客户兴奋不已。硬质合金刀具非常昂贵——每台机器花费数千美元——因此正确管理它们的利用率至关重要。损坏的工具不仅更换成本昂贵，而且还可能毁掉整条生产线。通过更密切的监控来延长工具的使用寿命将为客户节省数千美元的维护和更换费用。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;对于 Rau 来说，令人兴奋的部分是能够提供客户一直在等待的功能。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Rau：&lt;em&gt;“下采样的高频数据与原始数据一样具有表现力；我们正在超越聚合监控数据，转而能够在仪表板上查看实时、高速的数据。这是我们的客户所要求的。”&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Rau 和 Schoppe 现在正在利用从 PoC 中学到的知识，进一步开发解决方案并研究与第三方机器集成的方法。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Schoppe 总结道：&lt;em&gt;“目前市场上还没有这样的产品，因此这是我们将这种计算能力交到更多客户手中的绝佳机会。除了帮助我们脱颖而出之外，它还将为客户提供巨大的运营价值——他们可以依靠它以不同的方式节省资金。”&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Thu, 22 Aug 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Building a translation agent on LlamaEdge】在 LlamaEdge 上构建翻译代理</title>
      <link>https://www.cncf.io/blog/2024/08/26/building-a-translation-agent-on-llamaedge/</link>
      <description>【&lt;p&gt;&lt;em&gt;Member post originally published on &lt;a href=&#34;https://www.secondstate.io/articles/translation-agent/&#34;&gt;Second State’s blog&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Prof. Andrew Ng’s&amp;nbsp;&lt;a href=&#34;https://www.linkedin.com/posts/andrewyng_github-andrewyngtranslation-agent-activity-7206347897938866176-5tDJ/&#34;&gt;agentic translation&lt;/a&gt;&amp;nbsp;is a great demonstration on how to coordinate multiple LLM “agents” to work on a single task. It allows multiple smaller LLMs (like Llama-3 or Gemma-2) to work gether and produce better results than a single large LLM (like ChatGPT).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The&amp;nbsp;&lt;a href=&#34;https://github.com/andrewyng/translation-agent&#34;&gt;translation agent&lt;/a&gt;&amp;nbsp;is a great fit for&amp;nbsp;&lt;a href=&#34;https://github.com/LlamaEdge/LlamaEdge&#34;&gt;LlamaEdge&lt;/a&gt;, which provides a&amp;nbsp;&lt;a href=&#34;https://llamaedge.com/docs/llamaedge_vs_python&#34;&gt;lightweight&lt;/a&gt;,&amp;nbsp;&lt;a href=&#34;https://llamaedge.com/docs/llamaedge_vs_ollama&#34;&gt;embeddable&lt;/a&gt;,&amp;nbsp;&lt;a href=&#34;https://llamaedge.com/docs/llamaedge_vs_llamacpp&#34;&gt;portable&lt;/a&gt;, and&amp;nbsp;&lt;a href=&#34;https://github.com/LlamaEdge/LlamaEdge/blob/main/docker/README.md&#34;&gt;Docker-native&lt;/a&gt;&amp;nbsp;AI runtime for&amp;nbsp;&lt;a href=&#34;https://llamaedge.com/docs/llamaedge_vs_llamacpp&#34;&gt;many different&lt;/a&gt;&amp;nbsp;types of models and hardware accelerators. With LlamaEdge, you can build and distribute translation apps with embedded LLMs and prompts that can run on edge devices.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://www.secondstate.io/articles/translation-agent.png&#34; alt=&#34;Image&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;introduction-to-the-llm-translation-agent&#34;&gt;&lt;a href=&#34;https://www.secondstate.io/articles/translation-agent/#introduction-to-the-llm-translation-agent&#34;&gt;Introduction to the LLM Translation Agent&lt;/a&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;This LLM Translation Agent is designed to facilitate accurate and efficient translation across multiple languages. It employs open source LLMs (Large Language Models) to provide high-quality translations. You can use your own fine-tuned models or any LLMs on Hugging Face like Meta’s Llama 3.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p&gt;For detailed commands on starting and running this agent, please visit&amp;nbsp;&lt;a href=&#34;https://github.com/second-state/translation-agent/blob/use_llamaedge/step-by-step-use-LocalAI.md&#34;&gt;GitHub – Second State/translation-agent&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;To get started, clone the Translation Agent.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;git clone https://github.com/second-state/translation-agent.git&#xA;    &#xA;cd translation-agent&#xA;git checkout use_llamaedge&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Here, we run Llama-3-8B, Gemma-2-9B, and Phi-3-medium-128k locally and our Translation Agent on top of them respectively to showcase their translation quality. We test a simple translation task to see the results so as to compare their translation capabilities. You will need to install&amp;nbsp;&lt;a href=&#34;https://github.com/WasmEdge/WasmEdge&#34;&gt;WasmEdge&lt;/a&gt;&amp;nbsp;and the&amp;nbsp;&lt;a href=&#34;https://github.com/LlamaEdge/LlamaEdge&#34;&gt;LlamaEdge API server&lt;/a&gt;&amp;nbsp;to run those models across major GPU and CPU platforms.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;curl -sSf https://raw.githubusercontent.com/WasmEdge/WasmEdge/master/utils/install_v2.sh | bash -s -- -v 0.13.5&#xA;&#xA;curl -LO https://github.com/LlamaEdge/LlamaEdge/releases/latest/download/llama-api-server.wasm&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;You will also need the following configurations and prerequisites to run the agent app.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;export OPENAI_BASE_URL=&#34;http://localhost:8080/v1&#34;&#xA;export PYTHONPATH=${PWD}/src&#xA;export OPENAI_API_KEY=&#34;LLAMAEDGE&#34;&#xA;&#xA;pip install python-dotenv&#xA;pip install openai tiktoken icecream langchain_text_splitters&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;demo-1-running-translation-agents-with-llama-3-8b&#34;&gt;&lt;a href=&#34;https://www.secondstate.io/articles/translation-agent/#demo-1-running-translation-agents-with-llama-3-8b&#34;&gt;Demo 1: Running Translation Agents with Llama-3-8B&lt;/a&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;First, let’s run the translation agent with Meta AI’s popular Llama-3 model. We select the smallest Llama-3 model (the 8b model) for this demo. The translation task is from Chinese to English. Our&amp;nbsp;&lt;a href=&#34;https://hackmd.io/tdLiVR3TSc-8eVg_E-j9QA?view#Source-text&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;source text&lt;/a&gt;&amp;nbsp;is in Chinese, a brief intro to the ancient Chinese royal palace, the Forbidden City.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;step-11-run-llama-3-8b-on-your-own-device&#34;&gt;&lt;a href=&#34;https://www.secondstate.io/articles/translation-agent/#step-11-run-llama-3-8b-on-your-own-device&#34;&gt;Step 1.1: Run Llama-3-8B on your own device&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p&gt;See detailed instructions here:&amp;nbsp;&lt;a href=&#34;https://www.secondstate.io/articles/llama-3-8b/#run-llama-3-8b-on-your-own-device&#34;&gt;Run Llama-3-8B on your own device&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Download the Llama-3-8B model GGUF file. Since the size of the model is 5.73 GB. It can take a while to download.Copy&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;curl -LO https://huggingface.co/second-state/Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-Q5_K_M.gguf&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Next, use the following command to start an API server for the model.Copy&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;wasmedge --dir .:. --nn-preload default:GGML:AUTO:Meta-Llama-3-8B-Instruct-Q5_K_M.gguf \&#xA;  llama-api-server.wasm \&#xA;  --prompt-template llama-3-chat \&#xA;  --ctx-size 4096 \&#xA;  --model-name llama-3-8b&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;step-12-run-the-translation-agent-on-top-of-llama-3-8b&#34;&gt;&lt;a href=&#34;https://www.secondstate.io/articles/translation-agent/#step-12-run-the-translation-agent-on-top-of-llama-3-8b&#34;&gt;Step 1.2 Run the Translation Agent on top of Llama-3-8B&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Find the&amp;nbsp;&lt;code&gt;examples/example_script.py&lt;/code&gt;&amp;nbsp;file in your cloned agent repo and review its code. It tells the agent where to find your document and how to translate it. Change the model name to the one you are using, here we’re using&amp;nbsp;&lt;code&gt;llama-3-8b&lt;/code&gt;&amp;nbsp;model; also change the source and target languages you want (here we put&amp;nbsp;&lt;code&gt;Chinese&lt;/code&gt;&amp;nbsp;as the source language and&amp;nbsp;&lt;code&gt;English&lt;/code&gt;&amp;nbsp;as the target language).Copy&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;import os&#xA;import translation_agent as ta&#xA;        &#xA;if __name__ == &#34;__main__&#34;:&#xA;    source_lang, target_lang, country = &#34;Chinese&#34;, &#34;English&#34;, &#34;Britain&#34;&#xA;    &#xA;    relative_path = &#34;sample-texts/forbiddencity.txt&#34;&#xA;    script_dir = os.path.dirname(os.path.abspath(__file__))&#xA;    &#xA;    full_path = os.path.join(script_dir, relative_path)&#xA;    &#xA;    with open(full_path, encoding=&#34;utf-8&#34;) as file:&#xA;        source_text = file.read()&#xA;    &#xA;    print(f&#34;Source text:\n\n{source_text}\n------------\n&#34;)&#xA;    &#xA;    translation = ta.translate(&#xA;            source_lang=source_lang,&#xA;            target_lang=target_lang,&#xA;            source_text=source_text,&#xA;            country=country,&#xA;            model=&#34;llama-3-8b&#34;,&#xA;    )&#xA;    &#xA;    print(f&#34;Translation:\n\n{translation}&#34;)&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Then, you can find a&amp;nbsp;&lt;code&gt;examples/sample-texts&lt;/code&gt;&amp;nbsp;folder in your cloned repo. Put your file you want to translate in this folder and get its path. Here because we named our source text&amp;nbsp;&lt;code&gt;forbiddencity.txt&lt;/code&gt;, the relative path to the document would be&amp;nbsp;&lt;code&gt;sample-texts/forbiddencity.txt&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Run the below commands to have your text file translated into English.Copy&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;cd examples&#xA;python example_script.py&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Wait for several minutes and you will have&amp;nbsp;&lt;a href=&#34;https://hackmd.io/tdLiVR3TSc-8eVg_E-j9QA?view#English-Translation-by-Llama-3-8B&#34;&gt;a fully translated version&lt;/a&gt;&amp;nbsp;appear on your terminal screen.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;demo-2-running-translation-agents-with-gemma-2-9b&#34;&gt;&lt;a href=&#34;https://www.secondstate.io/articles/translation-agent/#demo-2-running-translation-agents-with-gemma-2-9b&#34;&gt;Demo 2: Running Translation Agents with Gemma-2-9B&lt;/a&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The benefit of running the Translation Agent with LlamaEdge is the ability for users to choose and embed different LLMs for different agentic tasks. To demonstrate this point, we will now change the translation agent LLM from Llama-3-8b to Google’s Gemma-2-9b, which is of similar size but scores higher on many language-related benchmarks.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The translation task is the same as before. Our&amp;nbsp;&lt;a href=&#34;https://hackmd.io/tdLiVR3TSc-8eVg_E-j9QA?view#Source-text&#34;&gt;source text&lt;/a&gt;&amp;nbsp;is in Chinese, a brief intro to the ancient Chinese royal palace, the Forbidden City. The translation target is English.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;step-21-run-gemma-2-9b-on-your-own-device&#34;&gt;&lt;a href=&#34;https://www.secondstate.io/articles/translation-agent/#step-21-run-gemma-2-9b-on-your-own-device&#34;&gt;Step 2.1 Run Gemma-2-9B on your own device&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p&gt;See detailed instructions here:&amp;nbsp;&lt;a href=&#34;https://www.secondstate.io/articles/gemma-2-9b/&#34;&gt;Run Gemma-2-9B on your own device&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Download the&amp;nbsp;&lt;a href=&#34;https://huggingface.co/second-state/gemma-2-9b-it-GGUF&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Gemma-2-9B-it model GGUF file&lt;/a&gt;. Since the size of the model is 6.40G, it could take a while to download.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;curl -LO https://huggingface.co/second-state/gemma-2-9b-it-GGUF/resolve/main/gemma-2-9b-it-Q5_K_M.gguf&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Start an API server for the model.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;wasmedge --dir .:. --nn-preload default:GGML:AUTO:gemma-2-9b-it-Q5_K_M.gguf \&#xA;  llama-api-server.wasm \&#xA;  --prompt-template gemma-instruct \&#xA;  --ctx-size 4096 \&#xA;  --model-name gemma-2-9b&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;step-22-run-the-translation-agent-to-run-on-top-of-gemma-2-9b&#34;&gt;&lt;a href=&#34;https://www.secondstate.io/articles/translation-agent/#step-22-run-the-translation-agent-to-run-on-top-of-gemma-2-9b&#34;&gt;Step 2.2 Run the Translation Agent to run on top of Gemma-2-9B&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Find the&amp;nbsp;&lt;code&gt;examples/example_script.py&lt;/code&gt;&amp;nbsp;file in your cloned agent repo and review its code. It tells the agent where to find your document and how to translate it. Change the model name to the one you are using, here we’re using&amp;nbsp;&lt;code&gt;gemma-2-9b&lt;/code&gt;&amp;nbsp;model; also change the source and target languages you want (here we put&amp;nbsp;&lt;code&gt;Chinese&lt;/code&gt;&amp;nbsp;as the source language and&amp;nbsp;&lt;code&gt;English&lt;/code&gt;&amp;nbsp;as the target language).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;import os  &#xA;import translation_agent as ta  &#xA;    &#xA;if __name__ == &#34;__main__&#34;:&#xA;    source_lang, target_lang, country = &#34;Chinese&#34;, &#34;English&#34;, &#34;Britain&#34;&#xA;    &#xA;    relative_path = &#34;sample-texts/forbiddencity.txt&#34;&#xA;    script_dir = os.path.dirname(os.path.abspath(__file__))&#xA;    &#xA;    full_path = os.path.join(script_dir, relative_path)&#xA;    &#xA;    with open(full_path, encoding=&#34;utf-8&#34;) as file:&#xA;        source_text = file.read()&#xA;    &#xA;    print(f&#34;Source text:\n\n{source_text}\n------------\n&#34;)&#xA;    &#xA;    translation = ta.translate(&#xA;            source_lang=source_lang,&#xA;            target_lang=target_lang,&#xA;            source_text=source_text,&#xA;            country=country,&#xA;            model=&#34;gemma-2-9b&#34;,&#xA;    )&#xA;    &#xA;    print(f&#34;Translation:\n\n{translation}&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Then, you can find a&amp;nbsp;&lt;code&gt;examples/sample-texts&lt;/code&gt;&amp;nbsp;folder in your cloned repo. Put your file you want to translate in this folder and get its path. Here because we named our source text&amp;nbsp;&lt;code&gt;forbiddencity.txt&lt;/code&gt;, the relative path to the document would be&amp;nbsp;&lt;code&gt;sample-texts/forbiddencity.txt&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Run the below commands to have your text file translated into English.Copy&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;cd examples    &#xA;python example_script.py&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;You can find the translated result in English&amp;nbsp;&lt;a href=&#34;https://hackmd.io/tdLiVR3TSc-8eVg_E-j9QA?view#English-Translation-by-Gemma-2-9B&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;demo-3-running-translation-agents-with-phi-3-medium-long-context-model&#34;&gt;&lt;a href=&#34;https://www.secondstate.io/articles/translation-agent/#demo-3-running-translation-agents-with-phi-3-medium-long-context-model&#34;&gt;Demo 3: Running Translation Agents with Phi-3-Medium long context model&lt;/a&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The Llama-3 and Gemma-2 models are great LLMs, but they have relatively small context windows. The agent requires all text to fit into the LLM context window, and that limits the size of articles they can translate. To fix this problem, we could select an open source LLM with a large context window. For this demo, we choose Microsoft’s Phi-3-medium-128k model, which has a massive 128k (over 100 thousand words or the length of several books) context window.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We run&amp;nbsp;&lt;a href=&#34;https://hackmd.io/vuFYZTVsQZyKmkeQ3ThZQw?view#Source-text&#34;&gt;a lengthy Chinese article on Forbidden City’s collaboration with the Varsaille Palace&lt;/a&gt;&amp;nbsp;through our Translation Agent powered by a Phi-3-medium-128k model we start locally.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;step-31-run-phi-3-medium-128k-on-your-own-device&#34;&gt;&lt;a href=&#34;https://www.secondstate.io/articles/translation-agent/#step-31-run-phi-3-medium-128k-on-your-own-device&#34;&gt;Step 3.1: Run Phi-3-medium-128k on your own device&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;blockquote class=&#34;wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p&gt;See detailed instructions here:&amp;nbsp;&lt;a href=&#34;https://www.secondstate.io/articles/phi-3-mini-128k/&#34;&gt;Getting Started with Phi-3-mini-128k&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Download the&amp;nbsp;&lt;a href=&#34;https://huggingface.co/second-state/Phi-3-medium-128k-instruct-GGUF&#34;&gt;Phi-3-Medium-128k model GGUF file&lt;/a&gt;.Copy&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;curl -LO https://huggingface.co/second-state/Phi-3-medium-128k-instruct-GGUF/resolve/main/Phi-3-medium-128k-instruct-Q5_K_M.gguf&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Run the following command to start an API server for the model with a 128k context window.Copy&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;wasmedge --dir .:. --nn-preload default:GGML:AUTO:Phi-3-medium-128k-instruct-Q5_K_M.gguf \&#xA;  llama-api-server.wasm \&#xA;  --prompt-template phi-3-chat \&#xA;  --ctx-size 128000 \&#xA;  --model-name phi-3-medium-128k&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;step-32-clone-and-run-the-translation-agent-on-top-of-phi-3-medium-128k&#34;&gt;&lt;a href=&#34;https://www.secondstate.io/articles/translation-agent/#step-32-clone-and-run-the-translation-agent-on-top-of-phi-3-medium-128k&#34;&gt;Step 3.2 Clone and run the Translation Agent on top of Phi-3-medium-128k&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Find the&amp;nbsp;&lt;code&gt;examples/example_script.py&lt;/code&gt;&amp;nbsp;file in your cloned agent repo and review its code. It tells the agent where to find your document and how to translate it. Change the model name to the one you are using, here we’re using&amp;nbsp;&lt;code&gt;phi-3-medium-128k&lt;/code&gt;&amp;nbsp;model; also change the source and target languages you want (here we put&amp;nbsp;&lt;code&gt;Chinese&lt;/code&gt;&amp;nbsp;as the source language and&amp;nbsp;&lt;code&gt;English&lt;/code&gt;&amp;nbsp;as the target language).Copy&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;import os  &#xA;import translation_agent as ta  &#xA;    &#xA;if __name__ == &#34;__main__&#34;:&#xA;    source_lang, target_lang, country = &#34;Chinese&#34;, &#34;English&#34;, &#34;Britain&#34;&#xA;    &#xA;    relative_path = &#34;sample-texts/long_article.txt&#34;&#xA;    script_dir = os.path.dirname(os.path.abspath(__file__))&#xA;    &#xA;    full_path = os.path.join(script_dir, relative_path)&#xA;    &#xA;    with open(full_path, encoding=&#34;utf-8&#34;) as file:&#xA;        source_text = file.read()&#xA;    &#xA;    print(f&#34;Source text:\n\n{source_text}\n------------\n&#34;)&#xA;    &#xA;    translation = ta.translate(&#xA;            source_lang=source_lang,&#xA;            target_lang=target_lang,&#xA;            source_text=source_text,&#xA;            country=country,&#xA;            model=&#34;phi-3-medium-128k&#34;,&#xA;    )&#xA;    &#xA;    print(f&#34;Translation:\n\n{translation}&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Then, you can find a&amp;nbsp;&lt;code&gt;examples/sample-texts&lt;/code&gt;&amp;nbsp;folder in your cloned repo. Put your file you want to translate in this folder and get its path. Here because we named our source text&amp;nbsp;&lt;code&gt;long_article.txt&lt;/code&gt;, the relative path to the document would be&amp;nbsp;&lt;code&gt;sample-texts/long_article.txt&lt;/code&gt;.Copy&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;cd examples&#xA;python example_script.py&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://hackmd.io/vuFYZTVsQZyKmkeQ3ThZQw?view#Source-text&#34;&gt;The translated results were impressive,&lt;/a&gt;&amp;nbsp;with the translation capturing the nuances and context of the original text with high fidelity.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;evaluation-of-translation-quality&#34;&gt;&lt;a href=&#34;https://www.secondstate.io/articles/translation-agent/#evaluation-of-translation-quality&#34;&gt;Evaluation of Translation Quality&lt;/a&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The three models, Llama-3-8B, Gemma-2-9B, and Phi-3-medium, have exhibited varying levels of performance in translating complex historical and cultural content from Chinese to English.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Llama-3-8B provides a translation that effectively captures the factual content but shows occasional stiffness in language, possibly indicating a direct translation approach that doesn’t fully adapt idiomatic expressions. It does not keep section title and the format of the original text and left certain part untranslated.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In contrast, The translation by Gemma-2-9B is quite accurate and retains the original meaning of the short intro article of Forbidden city. Gemma-2-9B’s translation exhibits a smooth and natural English flow, suggesting a sophisticated understanding of both the source language and the target language’s grammatical structures. The choice of words and sentence structures in Gemma-2-9B’s output demonstrates a high degree of linguistic finesse, suggesting it might be well-suited for translating formal and historically nuanced texts.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The Phi-3-medium-128k model can translate book-length text from Chinese to English. It demonstrates robust capabilities in handling large volumes of complex content, suggesting advanced memory handling and contextual awareness. The quality of translation remains consistent even with increased text length, indicating Phi’s utility in projects requiring extensive, detailed translations. But you can see it makes certain mistakes like mistaken “Wenhua Hall” as “also known as Forbidden City” in the first paragraph.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Overall, each model has its strengths, with Gemma-2-9B standing out for linguistic finesse and Phi-3-medium-128k for handling lengthy texts.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;conclusion&#34;&gt;&lt;a href=&#34;https://www.secondstate.io/articles/translation-agent/#conclusion&#34;&gt;Conclusion&lt;/a&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/LlamaEdge/LlamaEdge&#34;&gt;LlamaEdge&lt;/a&gt;&amp;nbsp;provides an easy way to embed different open-source LLMs into your agentic applications to fully take advantage of their finetuned capabilities for specific tasks. The result application can be properly packaged and distributed as a single app that runs across major CPU and GPU devices.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;会员帖子最初发布于&lt;a href=&#34;https://www.secondstate.io/articles/translation-agent/&#34;&gt;Second State 博客&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;教授。 Andrew Ng 的&lt;a href=&#34;https://www.linkedin.com/posts/andrewyng_github-andrewyngtranslation-agent-activity-7206347897938866176-5tDJ/&#34;&gt;代理翻译&lt;/a&gt;很好地演示了如何协调多个 LLM“代理”来完成单一任务。它允许多个较小的 LLM（如 Llama-3 或 Gemma-2）一起工作，并比单个大型 LLM（如 ChatGPT）产生更好的结果。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/andrewyng/translation-agent&#34;&gt;翻译代理&lt;/a&gt;非常适合&lt;a href=&#34;https://github.com/LlamaEdge/ LlamaEdge&#34;&gt;LlamaEdge&lt;/a&gt;，提供&lt;a href=&#34;https://llamaedge.com/docs/llamaedge_vs_python&#34;&gt;轻量级&lt;/a&gt;、&lt;a href=&#34;https://llamaedge.com/docs /llamaedge_vs_ollama&#34;&gt;嵌入式&lt;/a&gt;、&lt;a href=&#34;https://llamaedge.com/docs/llamaedge_vs_llamacpp&#34;&gt;便携式&lt;/a&gt;和&lt;a href=&#34;https://github.com/LlamaEdge/ LlamaEdge/blob/main/docker/README.md&#34;&gt;Docker 原生&lt;/a&gt; 适用于&lt;a href=&#34;https://llamaedge.com/docs/llamaedge_vs_llamacpp&#34;&gt;许多不同&lt;/a&gt;类型模型的 AI 运行时和硬件加速器。借助 LlamaEdge，您可以构建和分发带有嵌入式 LLM 和可在边缘设备上运行的提示的翻译应用程序。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://www.secondstate.io/articles/translation-agent.png&#34; alt=&#34;图像&#34;referrerpolicy=&#34;no-推荐人&#34;&gt;&lt;/图&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;introduction-to-the-llm-translation-agent&#34;&gt;&lt;a href=&#34;https://www.secondstate.io/articles/translation-agent/#introduction -to-the-llm-translation-agent&#34;&gt;LLM翻译代理简介&lt;/a&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;该法学硕士翻译代理旨在促进跨多种语言的准确高效翻译。它采用开源 LLM（大型语言模型）来提供高质量的翻译。您可以使用自己的微调模型或 Hugging Face 上的任何法学硕士（例如 Meta 的 Llama 3）。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p&gt;有关启动和运行此代理的详细命令，请访问 &lt;a href=&#34;https://github.com/second-state/translation-agent/blob/use_llamaedge/step-by-step-use-LocalAI。 md&#34;&gt;GitHub – 第二状态/翻译代理&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;/块引用&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;首先，克隆翻译代理。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;git 克隆 https://github.com/second-state/translation-agent.git&#xA;    &#xA;cd 翻译代理&#xA;git checkout use_llamaedge&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在这里，我们在本地运行 Llama-3-8B、Gemma-2-9B 和 Phi-3-medium-128k，并分别在它们之上运行我们的翻译代理来展示它们的翻译质量。我们测试一个简单的翻译任务来查看结果，从而比较他们的翻译能力。您需要安装&lt;a href=&#34;https:///github.com/WasmEdge/WasmEdge&#34;&gt;WasmEdge&lt;/a&gt; 和 &lt;a href=&#34;https://github.com/LlamaEdge/LlamaEdge&#34;&gt;LlamaEdge API 服务器&lt;/a&gt; 跨主要 GPU 运行这些模型CPU 平台。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;curl -sSf https://raw.githubusercontent.com/WasmEdge/WasmEdge/master/utils/install_v2.sh | bash -s ---v 0.13.5&#xA;&#xA;卷曲-LO https://github.com/LlamaEdge/LlamaEdge/releases/latest/download/llama-api-server.wasm&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;您还需要以下配置和先决条件才能运行代理应用程序。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;导出 OPENAI_BASE_URL=&#34;http://localhost:8080/v1&#34;&#xA;导出 PYTHONPATH=${PWD}/src&#xA;导出 OPENAI_API_KEY=&#34;LLAMAEDGE&#34;&#xA;&#xA;pip 安装 python-dotenv&#xA;pip install openai tiktoken Icecream langchain_text_splitters&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;demo-1-running-translation-agents-with-llama-3-8b&#34;&gt;&lt;a href=&#34;https://www.secondstate.io/articles/ Translation-agent/#demo-1-running-translation-agents-with-llama-3-8b&#34;&gt;演示 1：使用 Llama-3-8B 运行翻译代理&lt;/a&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;首先，让我们使用 Meta AI 流行的 Llama-3 模型运行翻译代理。我们为此演示选择最小的 Llama-3 模型（8b 模型）。翻译任务是从中文到英文。我们的&lt;a href=&#34;https://hackmd.io/tdLiVR3TSc-8eVg_E-j9QA?view#Source-text&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;源文本&lt;/a&gt;为中文，简短介绍中国古代皇家宫殿紫禁城。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;step-11-run-llama-3-8b-on-your-own-device&#34;&gt;&lt;a href=&#34;https://www.secondstate.io/ articles/translation-agent/#step-11-run-llama-3-8b-on-your-own-device&#34;&gt;步骤 1.1：在您自己的设备上运行 Llama-3-8B&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p&gt;请在此处查看详细说明：&lt;a href=&#34;https://www.secondstate.io/articles/llama-3-8b/#run-llama-3-8b-on-your-own-device&#34;&gt;运行您自己的设备上的 Llama-3-8B&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/块引用&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;下载 Llama-3-8B 模型 GGUF 文件。由于模型的大小为 5.73 GB。下载可能需要一段时间。复制&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;curl -LO https://huggingface.co/second-state/Llama-3-8B-Instruct-GGUF/resolve/main/Meta- Llama-3-8B-Instruct-Q5_K_M.gguf&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;接下来，使用以下命令为模型启动 API 服务器。复制&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;wasmedge --dir .:. --nn-预加载默认值：GGML：AUTO：Meta-Llama-3-8B-Instruct-Q5_K_M.gguf \&#xA;  llama-api-server.wasm \&#xA;  --prompt-template llama-3-chat \&#xA;  --ctx-大小 4096 \&#xA;  --模型名称 llama-3-8b&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;step-12-run-the-translation-agent-on-top-of-llama-3-8b&#34;&gt;&lt;a href=&#34;https://www. secondarystate.io/articles/translation-agent/#step-12-run-the-translation-agent-on-top-of-llama-3-8b&#34;&gt;步骤 1.2 在 Llama-3-8B 上运行翻译代理&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;找到&lt;代码&gt;examples/example_script.py&lt;/code&gt; 在克隆的代理存储库中创建文件并查看其代码。它告诉代理在哪里可以找到您的文件以及如何翻译它。将模型名称更改为您正在使用的模型名称，此处我们使用&lt;code&gt;llama-3-8b&lt;/code&gt;模型；还可以更改您想要的源语言和目标语言（这里我们将&lt;code&gt;中文&lt;/code&gt;作为源语言，&lt;code&gt;英语&lt;/code&gt;作为目标语言）。复制&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;导入操作系统&#xA;将 Translation_agent 导入为 ta&#xA;        &#xA;如果 __name__ == &#34;__main__&#34;:&#xA;    source_lang, target_lang, Country = &#34;中文&#34;, &#34;英语&#34;, &#34;英国&#34;&#xA;    &#xA;    relative_path =“样本文本/forbiddencity.txt”&#xA;    script_dir = os.path.dirname(os.path.abspath(__file__))&#xA;    &#xA;    full_path = os.path.join(script_dir, 相对路径)&#xA;    &#xA;    打开（full_path，encoding =“utf-8”）作为文件：&#xA;        源文本 = 文件.read()&#xA;    &#xA;    print(f&#34;源文本：\n\n{source_text}\n------------\n&#34;)&#xA;    &#xA;    翻译 = ta.translate(&#xA;            源语言=源语言,&#xA;            目标语言=目标语言,&#xA;            源文本=源文本，&#xA;            国家=国家，&#xA;            型号=“llama-3-8b”，&#xA;    ）&#xA;    &#xA;    print(f&#34;翻译：\n\n{translation}&#34;)&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;然后，您可以在克隆的存储库中找到 &lt;code&gt;examples/sample-texts&lt;/code&gt; 文件夹。将要翻译的文件放入此文件夹中并获取其路径。此处，由于我们将源文本命名为 &lt;code&gt;forbiddencity.txt&lt;/code&gt;，因此文档的相对路径将为 &lt;code&gt;sample-texts/forbiddencity.txt&lt;/code&gt;。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;运行以下命令将您的文本文件翻译成英语。复制&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;cd 示例&#xA;python example_script.py&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;等待几分钟，您将获得&lt;a href=&#34;https://hackmd.io/tdLiVR3TSc-8eVg_E-j9QA?view#English-Translation-by-Llama-3-8B&#34;&gt;完整翻译版本&lt; /a&gt; 出现在您的终端屏幕上。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;demo-2-running-translation-agents-with-gemma-2-9b&#34;&gt;&lt;a href=&#34;https://www.secondstate.io/articles/ Translation-agent/#demo-2-running-translation-agents-with-gemma-2-9b&#34;&gt;演示 2：使用 Gemma-2-9B 运行翻译代理&lt;/a&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;使用 LlamaEdge 运行翻译代理的好处是用户能够为不同的代理任务选择和嵌入不同的 LLM。为了证明这一点，我们现在将翻译代理 LLM 从 Llama-3-8b 更改为 Google 的 Gemma-2-9b，它大小相似，但在许多语言相关基准测试中得分更高。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;翻译任务与之前相同。我们的&lt;a href=&#34;https://hackmd.io/tdLiVR3TSc-8eVg_E-j9QA?view#Source-text&#34;&gt;源文本&lt;/a&gt;是中文的，是对中国古代皇宫紫禁城的简要介绍。翻译目标是英语。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;step-21-run-gemma-2-9b-on-your-own-device&#34;&gt;&lt;a href=&#34;https://www.secondstate.io/articles/translation-agent/#step-21-run-gemma-2-9b-on-your-own-device&#34;&gt;步骤 2.1 在您自己的设备上运行 Gemma-2-9B&lt;/a&gt;&lt;/ H3&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p&gt;请在此处查看详细说明：&lt;a href=&#34;https://www.secondstate.io/articles/gemma-2-9b/&#34;&gt;在您自己的设备上运行 Gemma-2-9B&lt;/a&gt;&lt;/p &gt;&#xA;&lt;/块引用&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;下载&lt;a href=&#34;https://huggingface.co/second-state/gemma-2-9b-it-GGUF&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Gemma-2-9B-它对 GGUF 文件进行建模&lt;/a&gt;。由于模型大小为6.40G，下载可能需要一段时间。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;curl -LO https://huggingface.co/second-state/gemma-2-9b-it-GGUF/resolve/main/gemma- 2-9b-it-Q5_K_M.gguf&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;为模型启动 API 服务器。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;wasmedge --dir .:. --nn-预加载默认值：GGML：AUTO：gemma-2-9b-it-Q5_K_M.gguf \&#xA;  llama-api-server.wasm \&#xA;  --prompt-template gemma-instruct \&#xA;  --ctx-大小 4096 \&#xA;  --型号名称 gemma-2-9b&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;step-22-run-the-translation-agent-to-run-on-top-of-gemma-2-9b&#34;&gt;&lt;a href=&#34;https: //www.secondstate.io/articles/translation-agent/#step-22-run-the-translation-agent-to-run-on-top-of-gemma-2-9b&#34;&gt;步骤 2.2 运行翻译代理在 Gemma-2-9B 上运行&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在克隆的代理存储库中找到 &lt;code&gt;examples/example_script.py&lt;/code&gt; 文件并查看其代码。它告诉代理在哪里可以找到您的文件以及如何翻译它。将模型名称更改为您正在使用的模型名称，这里我们使用的是&lt;code&gt;gemma-2-9b&lt;/code&gt;模型；还可以更改您想要的源语言和目标语言（此处我们将&lt;code&gt;中文&lt;/code&gt;作为源语言，将&lt;code&gt;英语&lt;/code&gt;作为目标语言）。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;导入操作系统  &#xA;将 Translation_agent 导入为 ta  &#xA;    &#xA;如果 __name__ == &#34;__main__&#34;:&#xA;    source_lang, target_lang, Country = &#34;中文&#34;, &#34;英语&#34;, &#34;英国&#34;&#xA;    &#xA;    relative_path =“样本文本/forbiddencity.txt”&#xA;    script_dir = os.path.dirname(os.path.abspath(__file__))&#xA;    &#xA;    full_path = os.path.join(script_dir, 相对路径)&#xA;    &#xA;    打开（full_path，encoding =“utf-8”）作为文件：&#xA;        源文本 = 文件.read()&#xA;    &#xA;    print(f&#34;源文本：\n\n{source_text}\n------------\n&#34;)&#xA;    &#xA;    翻译 = ta.translate(&#xA;            源语言=源语言,&#xA;            目标语言=目标语言,&#xA;            源文本=源文本，&#xA;            国家=国家，&#xA;            型号=“gemma-2-9b”，&#xA;    ）&#xA;    &#xA;    print(f&#34;翻译：\n\n{翻译}&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;然后，您可以在克隆的存储库中找到 &lt;code&gt;examples/sample-texts&lt;/code&gt; 文件夹。将要翻译的文件放入此文件夹中并获取其路径。由于我们将源文本命名为 &lt;code&gt;forbiddencity.txt&lt;/code&gt;，因此文档的相对路径为 &lt;code&gt;sample-texts/forbiddencity.txt&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;运行以下命令将您的文本文件翻译成英语。复制&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;cd 示例    &#xA;python example_script.py&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;您可以在&lt;a href=&#34;https://hackmd.io/tdLiVR3TSc-8eVg_E-j9QA?view#English-Translation-by-Gemma-2-9B&#34;&gt;此处找到英文翻译结果&lt;/a&gt; .&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;demo-3-running-translation-agents-with-phi-3-medium-long-context-model&#34;&gt;&lt;a href=&#34;https://www.wp-block-heading&#34; secondarystate.io/articles/translation-agent/#demo-3-running-translation-agents-with-phi-3-medium-long-context-model&#34;&gt;演示 3：使用 Phi-3-Medium 长上下文运行翻译代理模型&lt;/a&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Llama-3 和 Gemma-2 模型是很棒的 LLM，但它们的上下文窗口相对较小。代理要求所有文本都适合 LLM 上下文窗口，这限制了他们可以翻译的文章的大小。为了解决这个问题，我们可以选择一个具有大上下文窗口的开源法学硕士。在本演示中，我们选择 Microsoft 的 Phi-3-medium-128k 模型，该模型具有巨大的 128k（超过 10 万个单词或几本书的长度）上下文窗口。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们通过我们的翻译代理（由Phi-3-medium-128k 模型我们从本地开始。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;step-31-run-phi-3-medium-128k-on-your-own-device&#34;&gt;&lt;a href=&#34;https://www.secondstate. io/articles/translation-agent/#step-31-run-phi-3-medium-128k-on-your-own-device&#34;&gt;步骤 3.1：在您自己的设备上运行 Phi-3-medium-128k&lt;/a &gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote class=&#34;wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;blockquote class=&#34;wp-block-quote is-style-smaller-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p&gt;请参阅此处的详细说明：&lt;a href=&#34;https://www.secondstate.io/articles/phi-3-mini-128k/&#34;&gt;Phi-3-mini-128k 入门&lt;/a&gt;。 &lt;/p&gt;&#xA;&lt;/块引用&gt;&#xA;&lt;/块引用&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;下载&lt;a href=&#34;https://huggingface.co/second-state/Phi-3-medium-128k-instruct-GGUF&#34;&gt;Phi-3-Medium-128k 模型 GGUF 文件&lt;/a&gt;。复制&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;curl -LO https://huggingface.co/second-state/Phi-3-medium-128k-instruct-GGUF/resolve/main/ Phi-3-medium-128k-instruct-Q5_K_M.gguf&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;运行以下命令，为具有 128k 上下文窗口的模型启动 API 服务器。复制&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;wasmedge --dir .:. --nn-预加载默认:GGML:AUTO:Phi-3-medium-128k-instruct-Q5_K_M.gguf \&#xA;  llama-api-server.wasm \&#xA;  --提示模板 phi-3-聊天 \&#xA;  --ctx-大小 128000 \&#xA;  --型号名称 phi-3-medium-128k&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;step-32-clone-and-run-the-translation-agent-on-top-of-phi-3-medium-128k&#34;&gt;&lt;a href=&#34; https://www.secondstate.io/articles/translation-agent/#step-32-clone-and-run-the-translation-agent-on-top-of-phi-3-medium-128k&#34;&gt;步骤 3.2 在 Phi-3-medium-128k 上克隆并运行翻译代理&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在克隆的代理存储库中找到 &lt;code&gt;examples/example_script.py&lt;/code&gt; 文件并查看其代码。它告诉代理在哪里可以找到您的文件以及如何翻译它。将模型名称更改为您正在使用的模型名称，这里我们使用的是&lt;code&gt;phi-3-medium-128k&lt;/code&gt;模型；还可以更改您想要的源语言和目标语言（这里我们将&lt;code&gt;中文&lt;/code&gt;作为源语言，&lt;code&gt;英语&lt;/code&gt;作为目标语言）。复制&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;导入操作系统  &#xA;将 Translation_agent 导入为 ta  &#xA;    &#xA;如果 __name__ == &#34;__main__&#34;:&#xA;    source_lang, target_lang, Country = &#34;中文&#34;, &#34;英语&#34;, &#34;英国&#34;&#xA;    &#xA;    relative_path =“样本文本/long_article.txt”&#xA;    script_dir = os.path.dirname(os.path.abspath(__file__))&#xA;    &#xA;    full_path = os.path.join(script_dir, 相对路径)&#xA;    &#xA;    打开（full_path，encoding =“utf-8”）作为文件：&#xA;        源文本 = 文件.read()&#xA;    &#xA;    print(f&#34;源文本：\n\n{source_text}\n------------\n&#34;)&#xA;    &#xA;    翻译 = ta.translate(&#xA;            源语言=源语言,&#xA;            目标语言=目标语言,&#xA;            源文本=源文本，&#xA;            国家=国家，&#xA;            型号=“phi-3-medium-128k”，&#xA;    ）&#xA;    &#xA;    print(f&#34;翻译：\n\n{翻译}&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;然后，您可以在克隆的存储库中找到 &lt;code&gt;examples/sample-texts&lt;/code&gt; 文件夹。将要翻译的文件放入此文件夹中并获取其路径。由于我们将源文本命名为 &lt;code&gt;long_article.txt&lt;/code&gt;，因此文档的相对路径为 &lt;code&gt;sample-texts/long_article.txt&lt;/code&gt;.Copy&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;cd 示例&#xA;python example_script.py&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://hackmd.io/vuFYZTVsQZyKmkeQ3ThZQw?view#Source-text&#34;&gt;翻译结果令人印象深刻&lt;/a&gt;，翻译以高保真度捕捉了原文的细微差别和上下文.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;evaluation-of-translation-quality&#34;&gt;&lt;a href=&#34;https://www.secondstate.io/articles/translation-agent/#evaluation-of-translation -quality&#34;&gt;翻译质量评估&lt;/a&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Llama-3-8B、Gemma-2-9B 和 Phi-3-medium 这三个模型在将复杂的历史和文化内容从中文翻译成英文方面表现出了不同程度的性能。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Llama-3-8B 提供的翻译可以有效地捕捉事实内容，但偶尔会出现语言僵化，这可能表明直接翻译方法并未完全适应惯用表达。它不保留章节标题和原文格式，并保留某些部分未翻译。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;相比之下，Gemma-2-9B 的翻译相当准确，保留了故宫简短介绍文章的原意。 Gemma-2-9B 的翻译展览英语流畅自然，表明对源语言和目标语言的语法结构有深入的理解。 Gemma-2-9B 输出中的单词和句子结构的选择展示了高度的语言技巧，表明它可能非常适合翻译正式的和历史上细致入微的文本。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Phi-3-medium-128k 模型可以将书本长度的文本从中文翻译成英文。它展示了处理大量复杂内容的强大功能，表明了先进的内存处理和上下文感知。即使文本长度增加，翻译质量也保持一致，这表明 Phi 在需要大量、详细翻译的项目中很有用。但你可以看到它有一些错误，比如第一段将“文华殿”误认为“又名紫禁城”。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;总体而言，每个模型都有其优点，Gemma-2-9B 在语言技巧方面表现突出，Phi-3-medium-128k 在处理冗长文本方面表现出色。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;conclusion&#34;&gt;&lt;a href=&#34;https://www.secondstate.io/articles/translation-agent/#conclusion&#34;&gt;结论&lt;/a&gt;&lt;/h2 &gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/LlamaEdge/LlamaEdge&#34;&gt;LlamaEdge&lt;/a&gt; 提供了一种简单的方法，将不同的开源 LLM 嵌入到您的代理应用程序中，以充分利用其微调功能具体任务。结果应用程序可以正确打包并分发为跨主要 CPU 和 GPU 设备运行的单个应用程序。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Sun, 25 Aug 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Developing an AI agent for smart contextual Q&amp;A】开发用于智能上下文问答的人工智能代理</title>
      <link>https://www.cncf.io/blog/2024/08/19/developing-an-ai-agent-for-smart-contextual-qa/</link>
      <description>【&lt;p&gt;&lt;em&gt;&amp;nbsp;Member post originally published on &lt;a href=&#34;https://www.infracloud.io/blogs/developing-ai-agent-for-smart-contextual-qna/&#34;&gt;InfraCloud’s blog&lt;/a&gt; by Shreyas Mocherla, Product Engineer Intern at InfraCloud Technologies&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Accelerated by the pandemic, online tech communities have grown rapidly. With new members joining every day, it’s tough to keep track of past conversations. Often, newcomers ask questions that have already been answered, causing repetition and redundancy. To tackle this, we built an intelligent assistant that tracks past conversations, searches Stack Overflow for technical help, and browses the web for relevant information.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;InSightful is a ReAct (Reasoning and Action) Agent with access to multiple tools, such as a web searcher and a context retriever, to achieve the given task. In our case, it is a question and answer application. We will delve deeper into the workings of the application as we progress. At the end of the day, you will be able to understand how agents work and how you can develop your own. These agents are highly customizable, giving you a lot of flexibility in picking a use-case.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;insightul-demo-lets-see-what-insightful-can-do&#34;&gt;InSightul demo: Let’s see what InSightful can do&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;InSightful is meant to be an AI Agent that can smartly retrieve conversations from a workspace, search results on Stack Overflow with a given context and as well as browse the web whenever the information asked for is not available in the other two places. This makes sure that InSightful has a safety net to fallback on in case the intermediary response (thought and observation) does not match the user’s question. Let us see how we can develop such an application.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;A GPU-enabled Kubernetes cluster OR a single GPU-enabled machine with Docker installed&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;A&amp;nbsp;&lt;a href=&#34;https://huggingface.co/settings/tokens&#34;&gt;HuggingFace account with a valid API key&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Three Services:&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;TGI –&amp;nbsp;&lt;a href=&#34;https://artifacthub.io/packages/helm/infracloud-charts/text-generation-inference&#34;&gt;Text Generation Inference&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;TEI –&amp;nbsp;&lt;a href=&#34;https://artifacthub.io/packages/helm/infracloud-charts/text-embeddings-inference&#34;&gt;Text Embeddings Inference&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Vector store –&amp;nbsp;&lt;a href=&#34;https://artifacthub.io/packages/helm/infracloud-charts/chromadb&#34;&gt;Chroma DB&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Note: This tutorial assumes the developer has experience with Docker and understands how to use it appropriately. If the developer is using Kubernetes, this tutorial assumes they have a multi-node GPU cluster.&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For the demo, we will be using a readily available HuggingFace dataset consisting of conversations from a workplace, simulating the real environment. The dataset mimics actual interactions amongst colleagues in tech communities like Slack workspaces, Reddit threads, or Discord servers. Downloading the dataset does not require any additional steps as it is included in the Python code.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;set-up&#34;&gt;Set up&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In our set up, we are using a Kubernetes cluster that is already provisioned and completely set up to run AI workloads on.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;If this is not your case, run the ai-stack separately on a GPU-enabled machine. If your machine is not equipped with a GPU, the inference will be extremely slow and is not recommended.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;&lt;code&gt;$ kubectl get svc -n ai-stack&#xA;&#xA;NAME       TYPE           CLUSTER-IP      EXTERNAL-IP     PORT(S)          AGE&#xA;tei        LoadBalancer   10.233.22.94    192.168.0.203   80:32215/TCP     21h&#xA;tgi        LoadBalancer   10.233.50.250   192.168.0.202   80:31963/TCP     21h&#xA;vectordb   LoadBalancer   10.233.27.106   192.168.0.201   8000:30992/TCP   21h&#xA;&lt;/code&gt;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://artifacthub.io/packages/helm/infracloud-charts/ai-stack&#34;&gt;(Kubernetes Services deployed using our AI stack chart)&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Once each service is deployed and running, we can access their respective IPs and ports to send and receive data. Go ahead and clone the repo and follow the steps in the&amp;nbsp;&lt;a href=&#34;https://github.com/infracloudio/insightful&#34;&gt;InSightful README&lt;/a&gt;&amp;nbsp;file.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;After successfully following the steps in the README, if all goes well, you should be greeted with this page on your browser:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://www.infracloud.io/assets/img/Blog/insightful-ai-agent/insightful-landing-page.webp&#34; alt=&#34;InSightful landing page&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;(InSightful landing page)&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;insightful-in-action&#34;&gt;InSightful in action&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Now, let’s see InSightful in action by asking it a question.You can ask different types of questions, according to the information you need.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Conversation analysis&lt;/strong&gt;: InSightful can analyze and provide insights on the topics being discussed in tech communities. For example, if people are frequently discussing a specific programming language, it can highlight that.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1600&#34; height=&#34;538&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/08/insightful-capturing-details-in-slack-conversations.webp&#34; alt=&#34;(InSightful capturing details in Slack conversations)&#34; class=&#34;wp-image-116296&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/08/insightful-capturing-details-in-slack-conversations.webp 1600w, https://www.cncf.io/wp-content/uploads/2024/08/insightful-capturing-details-in-slack-conversations-300x101.webp 300w, https://www.cncf.io/wp-content/uploads/2024/08/insightful-capturing-details-in-slack-conversations-1024x344.webp 1024w, https://www.cncf.io/wp-content/uploads/2024/08/insightful-capturing-details-in-slack-conversations-768x258.webp 768w, https://www.cncf.io/wp-content/uploads/2024/08/insightful-capturing-details-in-slack-conversations-900x303.webp 900w, https://www.cncf.io/wp-content/uploads/2024/08/insightful-capturing-details-in-slack-conversations-595x200.webp 595w, https://www.cncf.io/wp-content/uploads/2024/08/insightful-capturing-details-in-slack-conversations-1190x400.webp 1190w&#34; sizes=&#34;(max-width: 1600px) 100vw, 1600px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;(InSightful capturing details in Slack conversations)&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Community health analysis&lt;/strong&gt;: InSightful can evaluate engagement, sentiment, and overall health of a tech community. It can show if people are generally positive or negative about certain topics.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full is-resized&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1600&#34; height=&#34;538&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/08/2-insightful-analyzing-sentiments-and-overall-community-health.webp&#34; alt=&#34;(InSightful analyzing sentiments and overall community healths)&#34; class=&#34;wp-image-116297&#34; style=&#34;width:900px;height:auto&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/08/2-insightful-analyzing-sentiments-and-overall-community-health.webp 1600w, https://www.cncf.io/wp-content/uploads/2024/08/2-insightful-analyzing-sentiments-and-overall-community-health-300x101.webp 300w, https://www.cncf.io/wp-content/uploads/2024/08/2-insightful-analyzing-sentiments-and-overall-community-health-1024x344.webp 1024w, https://www.cncf.io/wp-content/uploads/2024/08/2-insightful-analyzing-sentiments-and-overall-community-health-768x258.webp 768w, https://www.cncf.io/wp-content/uploads/2024/08/2-insightful-analyzing-sentiments-and-overall-community-health-900x303.webp 900w, https://www.cncf.io/wp-content/uploads/2024/08/2-insightful-analyzing-sentiments-and-overall-community-health-595x200.webp 595w, https://www.cncf.io/wp-content/uploads/2024/08/2-insightful-analyzing-sentiments-and-overall-community-health-1190x400.webp 1190w&#34; sizes=&#34;(max-width: 1600px) 100vw, 1600px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;(InSightful analyzing sentiments and overall community healths)&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Search Stack Overflow&lt;/strong&gt;: InSightful can search Stack Overflow for relevant questions and answers, saving users time by providing instant solutions to common problems.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full is-resized&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1600&#34; height=&#34;538&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/08/3-insightful-responding-to-technical-question.webp&#34; alt=&#34;(InSightful responding to a technical question)&#34; class=&#34;wp-image-116298&#34; style=&#34;width:900px;height:auto&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/08/3-insightful-responding-to-technical-question.webp 1600w, https://www.cncf.io/wp-content/uploads/2024/08/3-insightful-responding-to-technical-question-300x101.webp 300w, https://www.cncf.io/wp-content/uploads/2024/08/3-insightful-responding-to-technical-question-1024x344.webp 1024w, https://www.cncf.io/wp-content/uploads/2024/08/3-insightful-responding-to-technical-question-768x258.webp 768w, https://www.cncf.io/wp-content/uploads/2024/08/3-insightful-responding-to-technical-question-900x303.webp 900w, https://www.cncf.io/wp-content/uploads/2024/08/3-insightful-responding-to-technical-question-595x200.webp 595w, https://www.cncf.io/wp-content/uploads/2024/08/3-insightful-responding-to-technical-question-1190x400.webp 1190w&#34; sizes=&#34;(max-width: 1600px) 100vw, 1600px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;(InSightful responding to a technical question)&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Browse the web&lt;/strong&gt;: InSightful can conduct web searches to gather relevant information on community topics, providing up-to-date knowledge.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1600&#34; height=&#34;584&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/08/4-insightful-providing-response-from-web-search-result.webp&#34; alt=&#34;(InSightful providing a response from web search results)&#34; class=&#34;wp-image-116299&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/08/4-insightful-providing-response-from-web-search-result.webp 1600w, https://www.cncf.io/wp-content/uploads/2024/08/4-insightful-providing-response-from-web-search-result-300x110.webp 300w, https://www.cncf.io/wp-content/uploads/2024/08/4-insightful-providing-response-from-web-search-result-1024x374.webp 1024w, https://www.cncf.io/wp-content/uploads/2024/08/4-insightful-providing-response-from-web-search-result-768x280.webp 768w, https://www.cncf.io/wp-content/uploads/2024/08/4-insightful-providing-response-from-web-search-result-900x329.webp 900w, https://www.cncf.io/wp-content/uploads/2024/08/4-insightful-providing-response-from-web-search-result-548x200.webp 548w, https://www.cncf.io/wp-content/uploads/2024/08/4-insightful-providing-response-from-web-search-result-1096x400.webp 1096w&#34; sizes=&#34;(max-width: 1600px) 100vw, 1600px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;(InSightful providing a response from web search results)&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Now that we know what InSightful can do, let’s understand what it is, and how it works. As mentioned earlier, InSightful is powered by an AI Agent, so let’s begin with Agents.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;agents-a-brief-introduction&#34;&gt;Agents: A brief introduction&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;When ChatGPT was released, it quickly became popular, surpassing&amp;nbsp;&lt;a href=&#34;https://www.reuters.com/technology/chatgpt-sets-record-fastest-growing-user-base-analyst-note-2023-02-01/&#34;&gt;1 millions users in just 5 days&lt;/a&gt;. Natural Language Processing (NLP) has been around for a while, but ChatGPT took it to the next level by turning a Language Model into a Large Language Model (LLM).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;However, LLMs, while powerful language models, are like parrots—they repeat what they hear without real understanding. To make them more applicable to specific tasks and problems, we have to fine-tune, provide detailed prompts, and set guard rails to align their responses closely to the demands of the user. Developing agents exploit some of these approaches that enable them to reason and act accordingly. With a set of tools, an agent can perform actions on an environment, something a regular base LLM cannot achieve. Agents integrate these additional tools and frameworks, allowing them to perform specific tasks, make decisions, and interact dynamically with their environment.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For the sake of simplicity and to limit the scope of the InSightful demo, we will only be talking about the techniques we have employed to adapt the LLM to our own use case. We integrated LLM with web search and context retrieval tools, as well as provided a well-defined prompt. The combination of the prompt and the accessibility of the tools is what brings our agent to life. Something to note is that we don’t necessarily have to create an agent to utilize tools, instead, we can directly provide a compatible LLM with tools. We mention “compatible LLM” because not all LLMs are tool-calling enabled. However, with the help of&amp;nbsp;&lt;a href=&#34;https://github.com/langchain-ai/langchain&#34;&gt;LangChain&lt;/a&gt;, any LLM can be used to develop an agent to achieve the same results of tool-calling enabled LLMs. Ultimately, the LLM is used solely for reasoning and accessing a set of provided tools in a LangChain agent.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We prompted the agent cautiously and refined the prompt in several iterations, making it almost foolproof. The prompt makes the agent much more reliable in solving tasks, consistently abiding to a structure while forming its final response.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For InSightful, we took the Reasoning and Action (ReAct) Agent approach, which is a type of agent that can reason through a task, form an action plan to guide its actions and finally responds after thorough self-reflection. The incorporation of tools into the agent enables it to form effective responses.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://www.infracloud.io/assets/img/Blog/insightful-ai-agent/bts-of-react-agent.webp&#34; alt=&#34;Behind The Scenes of a ReAct agent&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://betterprogramming.pub/make-langchain-agent-actually-works-with-local-llms-vicuna-wizardlm-etc-da42b6b1a97&#34;&gt;(Behind The Scenes of a ReAct agent)&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;From the diagram, we can understand that the task-in-hand is the question provided by the user and the environment is provided by the tool’s description. The tool’s description provides concise context to the agent to decide if a given tool is useful for the task or not. The cycle of “Thought-Action-Observation” is repeated a defined number of times until a satisfiable observation is made.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;There are other alternatives to ReAct that are linear rather than ReAct’s cyclic approach such as Chain-of-Thought (CoT) and Tree-of-Thought (ToT), however, these alternatives do not support actions and will not enable learning from the consequences of the actions on an environment. They are purely reasoning-backed approaches.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;creating-tools-as-functions&#34;&gt;Creating tools as functions&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Fundamentally, tools are exactly what they sound like they are. They supplement the agent to generate accurate and contextual responses according to the user’s question.&amp;nbsp;&lt;a href=&#34;https://python.langchain.com/v0.1/docs/integrations/tools/&#34;&gt;LangChain has an exhaustive list of such tools&lt;/a&gt;&amp;nbsp;that can be integrated with agents.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;InSightful applies several tools to enhance the agent:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Conversation Retriever tool&lt;/strong&gt;: We converted the traditional&amp;nbsp;&lt;a href=&#34;https://www.infracloud.io/blogs/retrieval-augmented-generation-using-data-with-llms/&#34;&gt;Retrieval-Augmented Generation (RAG)&lt;/a&gt;&amp;nbsp;approach into a tool, making it more efficient for the agent. We essentially created our own tool, since the tool we want is not directly available in the LangChain package. This tool uses a vectorstore as its retriever, enabling similarity searches and predictions.This integration streamlines the process, allowing the agent to retrieve information without executing separate functions.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Stack Overflow search tool&lt;/strong&gt;: We developed this tool using the&amp;nbsp;&lt;a href=&#34;https://api.stackexchange.com/&#34;&gt;Stack Exchange API&lt;/a&gt;, enabling the agent to search and query the extensive database of questions and answers on Stack Overflow.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Search engine tool&lt;/strong&gt;:&amp;nbsp;&lt;a href=&#34;https://tavily.com/&#34;&gt;Tavily Search&lt;/a&gt;&amp;nbsp;is a search engine tailored specifically for LLMs. We use the Tavily API integration with LangChain, which provides Tavily Search as a tool to use with LangChain agents.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;providing-tools-to-our-agent&#34;&gt;Providing tools to our Agent&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;After creating these tools as callable functions, we compile them into a simple Python list like so:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-preformatted&#34;&gt;&lt;code&gt;tools = [retriever_tool, stack_overflow_search_tool, web_search_tool]&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;(List of tools provided to the agent)&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;LangChain iterates over this list, using the name and description provided in each tool’s docstring to understand their purposes. Setting a name and description for each custom tool is mandatory as it provides LangChain with the context of what each function achieves.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Once we have our list of tools, we set it as a parameter when creating our agent. This setup indicates to the agent that it has access to these tools. When the agent determines which tool to use, it runs the corresponding function to trigger the tool. Ideally, the tool returns the desired results, and the agent uses that as additional context to augment its responses.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;By integrating these tools, InSightful can:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Retrieve and analyze conversations&lt;/strong&gt;: Identify recurring questions and provide answers from past discussions, saving time and reducing redundancy.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Engage in technical Q&amp;amp;A&lt;/strong&gt;: Answer technical questions using Stack Overflow, giving quick and accurate responses.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Conduct independent research&lt;/strong&gt;: Browse the web for additional information on community topics, ensuring up-to-date and comprehensive answers.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;connecting-the-dots&#34;&gt;Connecting the dots&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://www.infracloud.io/assets/img/Blog/insightful-ai-agent/insightful-workflow-diagram.webp&#34; alt=&#34;InSightful workflow diagram&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;(InSightful workflow diagram)&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Let’s break down each of the components and how they fit into the big picture:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Document Retrieval&lt;/strong&gt;: Retrieve conversation histories, technical questions, and other relevant data from a Data Source such as the vector store in our case.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Vector Storage&lt;/strong&gt;:&amp;nbsp;&lt;a href=&#34;https://www.infracloud.io/blogs/vector-databases-beginners-guide/&#34;&gt;Vector Stores&lt;/a&gt;&amp;nbsp;are where the embeddings are stored. The embeddings are generated by&amp;nbsp;&lt;a href=&#34;https://www.infracloud.io/blogs/developing-ai-agent-for-smart-contextual-qna/#prerequisites&#34;&gt;TEI&lt;/a&gt;.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;LLM&lt;/strong&gt;:&amp;nbsp;&lt;a href=&#34;https://www.infracloud.io/blogs/developing-ai-agent-for-smart-contextual-qna/#prerequisites&#34;&gt;TGI&lt;/a&gt;&amp;nbsp;is where the LLM is running to generate responses based on the retrieved data, providing meaningful answers to user queries.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Tool/External API Integration&lt;/strong&gt;: Integrate additional tools for searching Stack Overflow and browsing the web, expanding the assistant’s capabilities. The tools are powered by APIs offered by each of the services (Tavily and Stack Overflow).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Here’s an example of the process when a user query is entered.The query “Latest news on Kubernetes” yields this result, only visible to the developer:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://www.infracloud.io/assets/img/Blog/insightful-ai-agent/insightful-reasoning-and-action-stage.webp&#34; alt=&#34;InSightful’s Reasoning and Action stage&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;(InSightful’s Reasoning and Action stage)&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The user sees this on the front-end:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://www.infracloud.io/assets/img/Blog/insightful-ai-agent/results-of-the-reasoning-and-action-steps.webp&#34; alt=&#34;Results of the Reasoning and Action steps&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;(Results of the Reasoning and Action steps)&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;benefits-of-the-on-premise-approach-local-kubernetes-cluster&#34;&gt;Benefits of the on-premise approach (local Kubernetes cluster)&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;InSightful works well in various online tech communities, such as Slack workspaces, Reddit threads, and Discord servers. The on-premise approach offers several advantages:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Data security&lt;/strong&gt;: On-premise solutions provide enhanced security by keeping data within the organization’s own infrastructure, making it harder for remote hackers to access sensitive information. This level of control is especially crucial for industries with strict compliance requirements.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Customization&lt;/strong&gt;: Organizations can tailor their hardware and software configurations to meet specific needs and compliance requirements. This allows for more specialized and efficient setups that cloud solutions might not offer.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Performance and low latency&lt;/strong&gt;: Since the infrastructure is local, data processing and access times are faster. This is particularly beneficial for real-time applications or those handling large data volumes.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Control and ownership&lt;/strong&gt;: Complete control over the hardware, software, and data ensures that organizations can implement their own security measures and protocols without relying on external providers.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;InSightful uses state-of-the-art Generative AI to provide an intelligent assistant for tech communities and enterprises. By keeping track of past and present conversations, accessing Stack Overflow for technical questions, and browsing the web for additional research, InSightful reduces redundancy and improves the efficiency of information retrieval. This on-premise approach shows how integrating LLMs with specialized tools can create a practical and powerful AI assistant for enterprises. You can follow this article to build an AI Agent to power a conversation search and retrieval engine for your communication channels like Discord and Slack; however, having an efficient and scalable cloud infrastructure is crucial for building an AI application.&amp;nbsp;&lt;a href=&#34;https://www.infracloud.io/build-ai-cloud/&#34;&gt;AI &amp;amp; GPU Cloud experts&lt;/a&gt;&amp;nbsp;can help you achieve this.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Hopefully, this has been as informative as we sought out to make it. Stay connected with us by subscribing to our weekly newsletter. Please share your valuable feedback with us, and we would love to hear from you on&amp;nbsp;&lt;a href=&#34;https://linkedin.com/in/aiwithshrey&#34;&gt;LinkedIn&lt;/a&gt;!&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;references&#34;&gt;References&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;LLM App dev framework –&amp;nbsp;&lt;a href=&#34;https://python.langchain.com/v0.1/docs/get_started/introduction/&#34;&gt;LangChain docs&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;Tools used by InSightful –&amp;nbsp;&lt;a href=&#34;https://tavily.com/&#34;&gt;Tavily&lt;/a&gt;,&amp;nbsp;&lt;a href=&#34;https://tavily.com/&#34;&gt;Stack Exchange API&lt;/a&gt;,&amp;nbsp;&lt;a href=&#34;https://www.trychroma.com/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Chroma&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;HuggingFace components –&amp;nbsp;&lt;a href=&#34;https://huggingface.co/docs/text-generation-inference/en/index&#34;&gt;Text Generation Inference&lt;/a&gt;,&amp;nbsp;&lt;a href=&#34;https://huggingface.co/docs/text-embeddings-inference/en/index&#34;&gt;Text Embeddings Inference&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt; 会员帖子最初发布于 &lt;a href=&#34;https://www.infracloud.io/blogs/developing-ai-agent-for-smart-contextual-qna/&#34;&gt;InfraCloud 博客&lt;/a&gt;作者：Shreyas Mocherla，InfraCloud Technologies 实习生产品工程师&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;受疫情影响，在线技术社区迅速发展。随着每天都有新成员加入，很难跟踪过去的对话。通常，新来者会提出已经回答过的问题，从而导致重复和冗余。为了解决这个问题，我们构建了一个智能助手，可以跟踪过去的对话，在 Stack Overflow 上搜索技术帮助，并浏览网络以获取相关信息。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;InSightful 是一个 ReAct（推理和行动）代理，可以访问多种工具（例如网络搜索器和上下文检索器）来完成给定的任务。在我们的例子中，它是一个问答应用程序。随着我们的进展，我们将更深入地研究应用程序的工作原理。最终，您将能够了解代理如何工作以及如何开发自己的代理。这些代理是高度可定制的，让您在选择用例时具有很大的灵活性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;insightul-demo-lets-see-what-insightful-can-do&#34;&gt;InSightul 演示：让我们看看 InSightful 可以做什么&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;InSightful 是一个人工智能代理，可以智能地从工作区检索对话，在给定上下文的 Stack Overflow 上搜索结果，并在其他两个地方无法提供所需信息时浏览网页。这确保了 InSightful 有一个安全网可以依靠，以防中间响应（想法和观察）与用户的问题不匹配。让我们看看如何开发这样的应用程序。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;preventions&#34;&gt;先决条件&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;支持 GPU 的 Kubernetes 集群或安装了 Docker 的单个支持 GPU 的机器&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;a href=&#34;https://huggingface.co/settings/tokens&#34;&gt;具有有效 API 密钥的 HuggingFace 帐户&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;三项服务：&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;TGI – &lt;a href=&#34;https://artifacthub.io/packages/helm/infracloud-charts/text- Generation-inference&#34;&gt;文本生成推理&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;TEI – &lt;a href=&#34;https://artifacthub.io/packages/helm/infracloud-charts/text-embeddings-inference&#34;&gt;文本嵌入推断&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;矢量存储 - &lt;a href=&#34;https://artifacthub.io/packages/helm/infracloud-charts/chromadb&#34;&gt;Chroma DB&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;em&gt;注意：本教程假设开发人员具有 Docker 经验并了解如何正确使用它。如果开发人员使用 Kubernetes，本教程假设他们有一个多节点 GPU 集群。&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在演示中，我们将使用现成的 HuggingFace 数据集，其中包含工作场所的对话，模拟真实环境。该数据集模仿实际的交互在 Slack 工作区、Reddit 线程或 Discord 服务器等技术社区中的同事之间进行交流。下载数据集不需要任何额外的步骤，因为它包含在 Python 代码中。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;set-up&#34;&gt;设置&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在我们的设置中，我们使用的是 Kubernetes 集群，该集群已配置并完全设置为运行 AI 工作负载。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;如果您的情况并非如此，请在支持 GPU 的计算机上单独运行 ai-stack。如果您的机器没有配备GPU，推理速度会非常慢，不推荐。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;&lt;code&gt;$ kubectl get svc -n ai-stack&#xA;&#xA;名称 类型 集群 IP 外部 IP 端口 年龄&#xA;泰负载均衡器 10.233.22.94 192.168.0.203 80:32215/TCP 21h&#xA;tgi 负载均衡器 10.233.50.250 192.168.0.202 80:31963/TCP 21h&#xA;矢量数据库负载均衡器 10.233.27.106 192.168.0.201 8000:30992/TCP 21h&#xA;&lt;/code&gt;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://artifacthub.io/packages/helm/infracloud-charts/ai-stack&#34;&gt;（使用我们的 AI 堆栈图表部署的 Kubernetes 服务）&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;一旦每个服务部署并运行，我们就可以访问它们各自的IP和端口来发送和接收数据。继续克隆存储库并按照&lt;a href=&#34;https://github.com/infracloudio/insightful&#34;&gt;InSightful README&lt;/a&gt; 文件中的步骤操作。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;成功执行自述文件中的步骤后，如果一切顺利，您的浏览器上应该会看到以下页面：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://www.infracloud.io/assets/img/Blog/insightful-ai-agent/insightful-landing-page. webp&#34; alt=&#34;InSightful 登陆页面&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;（InSightful 登陆页面）&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34; id=&#34;insightful-in-action&#34;&gt;富有洞察力的行动&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;现在，让我们通过提问来了解 InSightful 的实际应用。您可以根据需要的信息提出不同类型的问题。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;对话分析&lt;/strong&gt;：InSightful 可以分析技术社区中正在讨论的主题并提供见解。例如，如果人们经常讨论某种特定的编程语言，它可以突出显示这一点。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“1600”高度=“538”src=“https://www.cncf.io/ wp-content/uploads/2024/08/insightful-capturing-details-in-slack-conversations.webp&#34; alt=&#34;（InSightful 捕获 Slack 对话中的详细信息）&#34; class=&#34;wp-image-116296&#34; srcset=&#34;https: //www.cncf.io/wp-content/uploads/2024/08/insightful-capturing-details-in-slack-conversations.webp 1600w，https://www.cncf.io/wp-content/uploads/2024 /08/insightful-capturing-details-in-slack-conversations-300x101.webp 300w，https://www.cncf.io/wp-content/uploads/2024/08/insightful-capturing-details-in-slack-conversations-1024x344.webp 1024w，https://www.cncf.io/wp-content/uploads/2024/08/insightful-capturing-details-in-slack-conversations-768x258.webp 768w，https:// www.cncf.io/wp-content/uploads/2024/08/insightful-capturing-details-in-slack-conversations-900x303.webp 900w，https://www.cncf.io/wp-content/uploads/2024 /08/insightful-capturing-details-in-slack-conversations-595x200.webp 595w，https://www.cncf.io/wp-content/uploads/2024/08/insightful-capturing-details-in-slack- conversations-1190x400.webp 1190w&#34;sizes=&#34;(max-width: 1600px) 100vw, 1600px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;（有洞察力地捕获 Slack 对话中的详细信息）&lt; /图标题&gt;&lt;/图&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;社区健康分析&lt;/strong&gt;：InSightful 可以评估科技社区的参与度、情绪和整体健康状况。它可以显示人们对某些主题的总体态度是积极还是消极。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full is-resized&#34;&gt;&lt;imgloading=&#34;lazy&#34;decoding=&#34;async&#34;width=&#34;1600&#34;height=&#34;538&#34;src=&#34;https://www.cncf .io/wp-content/uploads/2024/08/2-insightful-analyzing-sentiments-and-overall-community-health.webp&#34; alt=&#34;（有洞察力的分析情绪和整体社区健康）&#34; class=&#34;wp-image -116297&#34; style=&#34;width:900px;height:auto&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/08/2-insightful-analyzing-sentiments-and-overall-community -health.webp 1600w，https://www.cncf.io/wp-content/uploads/2024/08/2-insightful-analyzing-sentiments-and-overall-community-health-300x101.webp 300w，https:// /www.cncf.io/wp-content/uploads/2024/08/2-insightful-analyzing-sentiments-and-overall-community-health-1024x344.webp 1024w，https://www.cncf.io/wp-内容/uploads/2024/08/2-insightful-analyzing-sentiments-and-overall-community-health-768x258.webp 768w，https://www.cncf.io/wp-content/uploads/2024/08/2 -insightful-analyzing-sentiments-and-overall-community-health-900x303.webp 900w，https://www.cncf.io/wp-content/uploads/2024/08/2-insightful-analyzing-sentiments-and-整体社区健康-595x200.webp 595w，https://www.cncf.io/wp-content/uploads/2024/08/2-insightful-analyzing-sentiments-and-overall-community-health-1190x400.webp 1190w&#34;sizes=&#34;(max-width: 1600px) 100vw, 1600px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;（有洞察力的分析情绪和整体社区健康状况）&lt;/figcaption&gt;&lt; /图&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;搜索 Stack Overflow&lt;/strong&gt;：InSightful 可以在 Stack Overflow 中搜索相关问题和答案，通过提供常见问题的即时解决方案来节省用户时间。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full is-resized&#34;&gt;&lt;imgloading=&#34;lazy&#34;decoding=&#34;async&#34;width=&#34;1600&#34;height=&#34;538&#34;src=&#34;https://www.cncf .io/wp-content/uploads/2024/08/3-insightful-responding-to-technical-question.webp&#34; alt=&#34;(InSightful 回答技术问题)&#34; class=&#34;wp-image-116298&#34; style= “宽度：900px；高度：自动” srcset =“https：//www.cncf.io/wp-content/uploads/2024/08/3-insightful-responding-to-technical-question.webp 1600w，https://www.cncf.io/wp-content/uploads/2024/08 /3-insightful-responding-to-technical-question-300x101.webp 300w，https://www.cncf.io/wp-content/uploads/2024/08/3-insightful-responding-to-technical-question- 1024x344.webp 1024w，https://www.cncf.io/wp-content/uploads/2024/08/3-insightful-responding-to-technical-question-768x258.webp 768w，https://www.cncf。 io/wp-content/uploads/2024/08/3-insightful-responding-to-technical-question-900x303.webp 900w，https://www.cncf.io/wp-content/uploads/2024/08/3 -insightful-responding-to-technical-question-595x200.webp 595w，https://www.cncf.io/wp-content/uploads/2024/08/3-insightful-responding-to-technical-question-1190x400。 webp 1190w&#34;sizes=&#34;(max-width: 1600px) 100vw, 1600px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;（富有洞察力地回答技术问题）&lt;/figcaption&gt;&lt; /图&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;浏览网络&lt;/strong&gt;：InSightful 可以进行网络搜索，收集社区主题的相关信息，提供最新知识。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class =“wp-block-image size-full”&gt;&lt;img加载=“lazy”解码=“异步”宽度=“1600”高度=“584”src=“https://www.cncf.io/ wp-content/uploads/2024/08/4-insightful-providing-response-from-web-search-result.webp&#34; alt=&#34;（InSightful 提供来自网络搜索结果的响应）&#34; class=&#34;wp-image-116299 “ srcset =“https://www.cncf.io/wp-content/uploads/2024/08/4-insightful-providing-response-from-web-search-result.webp 1600w，https://www.cncf .io/wp-content/uploads/2024/08/4-insightful-providing-response-from-web-search-result-300x110.webp 300w，https://www.cncf.io/wp-content/uploads/ 2024/08/4-insightful-providing-response-from-web-search-result-1024x374.webp 1024w，https://www.cncf.io/wp-content/uploads/2024/08/4-insightful-providing -response-from-web-search-result-768x280.webp 768w，https://www.cncf.io/wp-content/uploads/2024/08/4-insightful-providing-response-from-web-search-结果-900x329.webp 900w，https://www.cncf.io/wp-content/uploads/2024/08/4-insightful-providing-response-from-web-search-result-548x200.webp 548w，https： //www.cncf.io/wp-content/uploads/2024/08/4-insightful-providing-response-from-web-search-result-1096x400.webp 1096w“尺寸=”（最大宽度：1600px）100vw , 1600px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;（InSightful 提供网络搜索结果的响应）&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;现在我们知道了 InSightful 可以做什么，让我们了解它是什么以及它是如何工作的。如前所述，InSightful 由 AI 代理提供支持，因此让我们从代理开始。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;agents-a-brief-introduction&#34;&gt;代理：简介&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;ChatGPT 发布后，迅速流行起来，超过了&lt;a href=&#34;https://www.reuters.com/technology/chatgpt-sets-record-fastest-forming-user-base-analyst-note-2023 -02-01/&#34;&gt;100万用户只需 5 天&lt;/a&gt;。自然语言处理 (NLP) 已经出现了一段时间，但 ChatGPT 通过将语言模型转变为大型语言模型 (LLM)，将其提升到了一个新的水平。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;然而，法学硕士虽然拥有强大的语言模型，但就像鹦鹉一样——他们会重复听到的内容，但没有真正理解。为了使它们更适用于特定的任务和问题，我们必须进行微调，提供详细的提示，并设置防护栏，使其响应与用户的需求紧密结合。开发代理利用其中一些方法使它们能够进行推理并采取相应的行动。通过一组工具，代理可以在环境中执行操作，这是常规基础法学硕士无法实现的。代理集成了这些附加工具和框架，使它们能够执行特定任务、做出决策并与环境动态交互。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;为了简单起见并限制 InSightful 演示的范围，我们将仅讨论我们用来使 LLM 适应我们自己的用例的技术。我们将法学硕士与网络搜索和上下文检索工具集成，并提供了明确定义的提示。工具的提示和可访问性的结合使我们的代理变得栩栩如生。需要注意的是，我们不一定要创建一个代理来使用工具，相反，我们可以直接提供一个与工具兼容的LLM。我们提到“兼容的 LLM”是因为并非所有的 LLM 都支持工具调用。然而，在&lt;a href=&#34;https://github.com/langchain-ai/langchain&#34;&gt;LangChain&lt;/a&gt;的帮助下，任何LLM都可以用来开发代理，以达到与工具调用相同的结果启用法学硕士。最终，LLM 仅用于推理和访问 LangChain 代理中提供的一组工具。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们谨慎地提示代理，并在多次迭代中完善了提示，使其几乎万无一失。提示使代理在解决任务时更加可靠，在形成最终响应时始终遵守结构。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;对于 InSightful，我们采用了推理与行动（ReAct）Agent 方法，这种 Agent 可以通过任务进行推理，形成行动计划来指导其行动，并在彻底的自我反思后最终做出响应。将工具整合到代理中使其能够形成有效的响应。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://www.infracloud.io/assets/img/Blog/insightful-ai-agent/bts-of-react- agent.webp&#34; alt=&#34;ReAct 代理的幕后花絮&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://betterprogramming.pub/make-langchain-agent-actually-works-with-local-llms-vicuna-wizardlm-etc-da42b6b1a97&#34;&gt;（ReAct 代理的幕后故事） &lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;从图中我们可以理解，手头的任务是用户提供的问题，环境是工具的描述提供的。该工具的描述为该工具提供了简洁的上下文决定给定工具是否对任务有用。 “思想-行动-观察”的循环重复一定次数，直到得到令人满意的观察结果。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;ReAct 还有其他线性替代方案，而不是 ReAct 的循环方法，例如思想链 (CoT) 和思想树 (ToT)，但是，这些替代方案不支持操作，也无法实现学习来自行为对环境的后果。它们是纯粹推理支持的方法。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;creating-tools-as-functions&#34;&gt;将工具创建为函数&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;从根本上来说，工具正如其听起来的样子。它们对代理进行补充，以根据用户的问题生成准确且符合上下文的响应。 &lt;a href=&#34;https://python.langchain.com/v0.1/docs/integrations/tools/&#34;&gt;LangChain 拥有此类工具的详尽列表&lt;/a&gt;，可以与代理集成。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;InSightful 应用了多种工具来增强代理：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;对话检索工具&lt;/strong&gt;：我们转换了传统的&lt;a href=&#34;https://www.infracloud.io/blogs/retrieval-augmented- Generation-using-data-with-llms/&#34; &gt;将检索增强生成 (RAG)&lt;/a&gt; 方法融入到工具中，从而提高代理的效率。我们本质上是创建了自己的工具，因为我们想要的工具不能直接在 LangChain 包中获得。该工具使用矢量存储作为检索器，支持相似性搜索和预测。这种集成简化了流程，允许代理检索信息而无需执行单独的功能。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;Stack Overflow 搜索工具&lt;/strong&gt;：我们使用 &lt;a href=&#34;https://api.stackexchange.com/&#34;&gt;Stack Exchange API&lt;/a&gt; 开发了此工具，使代理能够在 Stack Overflow 上搜索和查询广泛的问题和解答数据库。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;搜索引擎工具&lt;/strong&gt;：&lt;a href=&#34;https://tavily.com/&#34;&gt;Tavily Search&lt;/a&gt;是专为法学硕士量身定制的搜索引擎。我们使用 Tavily API 与 LangChain 集成，它提供 Tavily Search 作为与 LangChain 代理一起使用的工具。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;providing-tools-to-our-agent&#34;&gt;向我们的代理提供工具&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;将这些工具创建为可调用函数后，我们将它们编译成一个简单的 Python 列表，如下所示：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-preformatted&#34;&gt;&lt;code&gt;工具 = [retriever_tool、stack_overflow_search_tool、web_search_tool]&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;（提供给代理的工具列表）&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;LangChain 迭代此列表，使用每个工具的文档字符串中提供的名称和描述来了解其用途。必须为每个自定义工具设置名称和描述，因为它为 LangChain 提供了每个功能实现的背景。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;一旦我们有了工具列表，我们就可以在创建代理时将其设置为参数。这安装程序向代理表明它可以访问这些工具。当代理确定要使用哪个工具时，它会运行相应的函数来触发该工具。理想情况下，该工具返回所需的结果，并且代理将其用作附加上下文来增强其响应。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;通过集成这些工具，InSightful 可以：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;检索和分析对话&lt;/strong&gt;：识别重复出现的问题并根据过去的讨论提供答案，从而节省时间并减少冗余。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;参与技术问答&lt;/strong&gt;：使用 Stack Overflow 回答技术问题，并给出快速、准确的答复。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;进行独立研究&lt;/strong&gt;：浏览网络以获取有关社区主题的更多信息，确保获得最新且全面的答案。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;connecting-the-dots&#34;&gt;连接点&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://www.infracloud.io/assets/img/Blog/insightful-ai-agent/insightful-workflow-diagram。 webp&#34; alt=&#34;InSightful 工作流程图&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;（InSightful 工作流程图）&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;让我们分解每个组件以及它们如何融入大局：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;文档检索&lt;/strong&gt;：从数据源（例如我们案例中的矢量存储）检索对话历史记录、技术问题和其他相关数据。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;矢量存储&lt;/strong&gt;：&lt;a href=&#34;https://www.infracloud.io/blogs/vector-databases-beginners-guide/&#34;&gt;矢量存储&lt;/a&gt;是嵌入的位置被存储。嵌入由&lt;a href=&#34;https://www.infracloud.io/blogs/developing-ai-agent-for-smart-contextual-qna/#precessions&#34;&gt;TEI&lt;/a&gt;生成。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;法学硕士&lt;/strong&gt;：&lt;a href=&#34;https://www.infracloud.io/blogs/developing-ai-agent-for-smart-contextual-qna/#preventions&#34;&gt;TGI&lt;/ a&gt; 是 LLM 运行的地方，根据检索到的数据生成响应，为用户查询提供有意义的答案。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;工具/外部 API 集成&lt;/strong&gt;：集成用于搜索 Stack Overflow 和浏览网页的其他工具，扩展助手的功能。这些工具由每个服务（Tavily 和 Stack Overflow）提供的 API 提供支持。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;以下是输入用户查询时的流程示例。查询“Kubernetes 上的最新新闻”会产生此结果，仅对开发人员可见：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://www.infracloud.io/assets/img/Blog/insightful-ai-agent/insightful-reasoning-and- action-stage.webp&#34; alt=&#34;InSightful 的推理和行动阶段&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;（InSightful 的推理和行动阶段）&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;用户在前面看到这个-结束：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://www.infracloud.io/assets/img/Blog/insightful-ai-agent/results-of-the- Reasoning-and-action-steps.webp&#34; alt=&#34;推理和操作步骤的结果&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;（推理和操作步骤的结果） &lt;/图标题&gt;&lt;/图&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;benefits-of-the-on-premise-approach-local-kubernetes-cluster&#34;&gt;本地方法（本地 Kubernetes 集群）的优势&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;InSightful 在各种在线技术社区中运行良好，例如 Slack 工作区、Reddit 线程和 Discord 服务器。本地部署方法有几个优点：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;数据安全&lt;/strong&gt;：本地解决方案通过将数据保留在组织自己的基础设施内来提供增强的安全性，使远程黑客更难访问敏感信息。这种控制水平对于具有严格合规要求的行业尤其重要。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;定制&lt;/strong&gt;：组织可以定制其硬件和软件配置以满足特定需求和合规性要求。这样可以实现云解决方案可能无法提供的更专业、更高效的设置。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;性能和低延迟&lt;/strong&gt;：由于基础设施位于本地，因此数据处理和访问时间更快。这对于实时应用程序或处理大数据量的应用程序特别有利。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;&lt;strong&gt;控制和所有权&lt;/strong&gt;：对硬件、软件和数据的完全控制可确保组织能够实施自己的安全措施和协议，而无需依赖外部提供商。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;conclusion&#34;&gt;结论&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;InSightful 使用最先进的生成式人工智能为科技社区和企业提供智能助手。通过跟踪过去和现在的对话、访问 Stack Overflow 解决技术问题以及浏览网页进行其他研究，InSightful 减少了冗余并提高了信息检索的效率。这种本地方法展示了如何将法学硕士与专业工具集成，为企业创建实用且强大的人工智能助手。您可以按照本文构建一个 AI 代理，为您的沟通渠道（如 Discord 和 Slack）提供对话搜索和检索引擎；然而，拥有高效且可扩展的云基础设施对于构建人工智能应用程序至关重要。 &lt;a href=&#34;https://www.infracloud.io/build-ai-cloud/&#34;&gt;AI 和 GPU 云专家&lt;/a&gt;可以帮助您实现这一目标。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;希望这能提供我们想要的信息。订阅我们的每周时事通讯，与我们保持联系。请与我们分享您的宝贵反馈，我们很乐意在 &lt;a href=&#34;https://linkedin.com/in/aiwit 上收到您的来信hshrey&#34;&gt;领英&lt;/a&gt;！&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34; id=&#34;references&#34;&gt;参考&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul class=&#34;wp-block-list&#34;&gt;&#xA;&lt;li&gt;LLM 应用开发框架 – &lt;a href=&#34;https://python.langchain.com/v0.1/docs/get_started/introduction/&#34;&gt;LangChain 文档&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;InSightful 使用的工具 - &lt;a href=&#34;https://tavily.com/&#34;&gt;Tavily&lt;/a&gt;、&lt;a href=&#34;https://tavily.com/&#34;&gt;Stack Exchange API&lt;/a&gt; &gt;, &lt;a href=&#34;https://www.trychroma.com/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Chroma&lt;/a&gt;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li&gt;HuggingFace 组件 – &lt;a href=&#34;https://huggingface.co/docs/text- Generation-inference/en/index&#34;&gt;文本生成推理&lt;/a&gt;、&lt;a href=&#34;https://huggingface .co/docs/text-embeddings-inference/en/index&#34;&gt;文本嵌入推断&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Sun, 18 Aug 2024 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Ambient mesh: can sidecar-less Istio make your application faster?】环境网格：无 sidecar 的 Istio 能让您的应用程序更快吗？</title>
      <link>https://www.cncf.io/blog/2024/08/23/ambient-mesh-can-sidecar-less-istio-make-your-application-faster/</link>
      <description>【&lt;p&gt;&lt;em&gt;Community post originally published on &lt;a href=&#34;https://thenewstack.io/ambient-mesh-can-sidecar-less-istio-make-applications-faster/&#34;&gt;The New Stack &lt;/a&gt;by Lin Sun&lt;/em&gt;, &lt;em&gt;Head of Open Source at Solo.io&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Ambient mode is the new sidecar-less data plane introduced in Istio in 2022. When ambient mode reached &lt;a href=&#34;https://istio.io/latest/blog/2024/ambient-reaches-beta/&#34;&gt;Beta&lt;/a&gt; status in May this year, I started to see lots of users kicking the tires and running load tests to understand the performance implications after adding their applications to the mesh.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Inspired by &lt;a href=&#34;https://a-cup-of.coffee/blog/istio/#with-istio-ambient&#34;&gt;Quentin Joly’s blog&lt;/a&gt; about the incredible performance of Istio in ambient mode and similar feedback from other users in the community that sometimes applications are slightly faster in ambient mode, I decided to validate these results myself.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Test environment:&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;I used a 3 worker node Kubernetes cluster with 256GB RAM &amp;amp; 32 core CPU each node.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXfS50HjjsJiBqlv30JKgaaTJcmUq0hHcG3xNl42Yzd7E0FfKPAe0gI3tnNAx0gpud0LGfHkdI7cbTXJyzU5v46v-kucl-2_l7Lax0-kvCeG19mST3ToJdIu6r5u7BoYkAGVc14HnRyVlnX9TY_Ra9NilKQ?key=7Xu51UOF6Vd1czS7dgW7gA&#34; alt=&#34;Image&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Istio uses a few tools to make consistent benchmarking easy.&amp;nbsp; First, we use a load testing tool called &lt;a href=&#34;https://github.com/fortio/fortio&#34;&gt;fortio&lt;/a&gt;, which runs at a specified requests per second (RPS), records a histogram of execution time and calculates percentiles — e.g., P99, the response time where 99% of the requests took less than that number.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We also provide a sample app called &lt;a href=&#34;https://istio.io/latest/docs/examples/bookinfo/&#34;&gt;Bookinfo&lt;/a&gt;, which includes microservices written in Python, Java, Node.js and Ruby.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Each of the Bookinfo deployments has 2 replicas, which are evenly distributed to the 3 worker nodes. Using a &lt;a href=&#34;https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity&#34;&gt;pod anti-affinity rule&lt;/a&gt;, I made sure that fortio was placed on a different node than the &lt;a href=&#34;https://github.com/istio/istio/tree/master/samples/bookinfo/src/details&#34;&gt;details&lt;/a&gt; service.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Initial Test Result&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;I installed the Bookinfo application from the Istio v1.22.3 release. Using the fortio tool to drive load to individual Bookinfo services (for example, details) or the full Bookinfo app, I noticed &lt;strong&gt;near-zero latency impact &lt;/strong&gt;after adding everything to the ambient mesh. Most of the time they are within the range of 0-5% increase for the average or P90. I have noticed consistently that the details service in Istio ambient mode is slightly faster, just like Quentin reported in his blog.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Load testing the details service&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;I did the same test as Quentin, sending 100 RPS via 10 connections to the details service, and collected results for no mesh and ambient.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXfc1vCggIDlIXmGqt-ac1pUzDPHZd2feGf-TvJRpQu-nmCwXGVliCE8nB2CT_wkVMPibKKFOtjAQ1aj5zxQ-ivUQj74JFEtVZGwioAYbKLsLeuADG6dhTsvMqaYCvtZk3XlYHTFop6gc-z3zysDhyTrekuU?key=7Xu51UOF6Vd1czS7dgW7gA&#34; alt=&#34;No Mesh: 100 RPS to the details service&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;No Mesh: 100 RPS to the details service&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXdIB88W4APYre6YtZPZ90pRKvuoAFO05xhIaFXL50Y1PzD6LmZ0SoBTdgc6SMZSBar8LaNi5uWzDMA18_pEUZ9W_r1kiyiz9WwtcHMQQMkC6i4avrYLdsMlY8wGFc0FwEUR9VUvy-GSeaUJhAI8HK_fgJXB?key=7Xu51UOF6Vd1czS7dgW7gA&#34; alt=&#34;Image&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Ambient: 100 RPS to the details service&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Just like Quentin, I had to run multiple tests to validate that ambient mode is slightly more performant than no mesh — which is very hard to believe! In the case of the Bookinfo details service, adding ambient mode improved latencies by 6-11% on average – as well as adding mTLS and L4 observability!&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-fixed-layout&#34;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Fortio to &lt;/strong&gt;&lt;strong&gt;details&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Average&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P50&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P75&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P90&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P99&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Differences&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;No Mesh run 1&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;0.89ms&lt;/td&gt;&lt;td&gt;0.64ms&lt;/td&gt;&lt;td&gt;0.74ms&lt;/td&gt;&lt;td&gt;0.85ms&lt;/td&gt;&lt;td&gt;2.67ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;11% slower on average and 5% slower for P90&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Ambient run 1&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;0.80ms&lt;/td&gt;&lt;td&gt;0.6ms&lt;/td&gt;&lt;td&gt;0.71ms&lt;/td&gt;&lt;td&gt;0.81ms&lt;/td&gt;&lt;td&gt;1.4ms&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;No Mesh run 2&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;0.86ms&lt;/td&gt;&lt;td&gt;0.65ms&lt;/td&gt;&lt;td&gt;0.75ms&lt;/td&gt;&lt;td&gt;0.86ms&lt;/td&gt;&lt;td&gt;1.71ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;6% slower on average and 4% slower for P90&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Ambient run 2&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;0.81ms&lt;/td&gt;&lt;td&gt;0.61ms&lt;/td&gt;&lt;td&gt;0.72ms&lt;/td&gt;&lt;td&gt;0.83ms&lt;/td&gt;&lt;td&gt;1.56ms&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;No Mesh run 3&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;0.90ms&lt;/td&gt;&lt;td&gt;0.65ms&lt;/td&gt;&lt;td&gt;0.76ms&lt;/td&gt;&lt;td&gt;0.88ms&lt;/td&gt;&lt;td&gt;1.92ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;10% slower on average and 5% slower for P90&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Ambient run 3&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;0.82ms&lt;/td&gt;&lt;td&gt;0.63ms&lt;/td&gt;&lt;td&gt;0.72ms&lt;/td&gt;&lt;td&gt;0.84ms&lt;/td&gt;&lt;td&gt;1.5ms&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Table 1: Fortio to the details service 100 RPS 10 connections&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Why are apps sometimes faster in the ambient mesh?&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;We’ve been taught that service meshes add latency. Quentin’s results, replicated here, show a case where a workload is &lt;em&gt;faster&lt;/em&gt; when running through a service mesh. What is happening?&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;First theory&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;When your applications are in the ambient mesh, the load requests travel first through a lightweight local node proxy called &lt;a href=&#34;https://istio.io/latest/docs/ambient/overview/#ztunnel&#34;&gt;ztunnel&lt;/a&gt;, then to the destination ztunnel, and onward to the service. The details service is using HTTP/1.1 with the Webrick library in Ruby and we have seen poor connection management and keep-alive behaviors in older or poorly configured HTTP libraries. My first hypothesis was that when the client and server are on different nodes, proxying through client and server ztunnels could actually be faster if the applications are not using efficient HTTP/2 connections. Ztunnel uses connection pooling and &lt;a href=&#34;https://en.wikipedia.org/wiki/HTTP_tunnel&#34;&gt;HTTP Connect&lt;/a&gt; to establish secure tunnels between nodes to leverage parallelism and HTTP/2 stream multiplexing under loads.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXdkVHCotSRWKoih2aQLCioo38lsv_PtQFILzTPQvVd3vZYFY5VKaIoVPH_VWLeLla9yZGZBhiTo5H1wH-O3EApb2RvUjM-A3Q5k8B9ffCIoN12sRL8UG_FMLIhxti0iZaYXWu7dttoiubPD0GyDyKDcGmE?key=7Xu51UOF6Vd1czS7dgW7gA&#34; alt=&#34;Image&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;However, this theory has some challenges. Why have I only observed this consistently with the details service but not any other Bookinfo services?&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Researching further, I discovered that our fortio load tool has &lt;a href=&#34;https://github.com/fortio/fortio/blob/8a7d9112667e637139c788b68cb063f456d20cb4/bincommon/commonflags.go#L55&#34;&gt;connection keep-alive enabled by default&lt;/a&gt;. With 10 connections from fortio to the details service and the details service (using the WEBrick Ruby library) respects the connection keep-alive settings, the connections can be reused effectively without ambient.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Load testing with connection close&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Next, I explored running the same load testing with setting the `Connection: close` header. This forcibly disables any HTTP connection pooling which is a good way to test this hypothesis.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;curl -v -d &#39;{&#34;metadata&#34;: {&#34;url&#34;:&#34;http://details:9080/details/0&#34;, &#34;c&#34;:&#34;10&#34;, &#34;qps&#34;: &#34;100&#34;, &#34;n&#34;: &#34;2000&#34;, &#34;async&#34;:&#34;on&#34;, &#34;save&#34;:&#34;on&#34;}}&#39; &#34;localhost:8081/fortio/rest/run?jsonPath=.metadata&#34; -H &#34;Connection: close&#34;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXfc-HDPourI5Dwlo3n-jkc5TMiqJdm0k0oSb1Z4HZkKIkVgCKKFyJbBv6fp40pS6XwTOrrUvYSYfmL7M6Dqu7ZdBSiJYvXo-O7f4weYTsuQHarX3uit-jQEL4HlWiwNc7PEFPS1DQgm6csv5FhdMhXxUUc?key=7Xu51UOF6Vd1czS7dgW7gA&#34; alt=&#34;Image&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;No Mesh: Fortio to the details service 100 RPS 10 connections with connection close&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXfBoHXMf2xaXMboBVCNYNmDBkoFIdefso_IbfLft83aStyTTcm4yOAv3zkEwUtddn1gnFZgT9tf_Z0S494iE6TliMgHFuv24TnEMEddXsFtk2JcS41jUZhTTvAljd9bDA25AGqyjKlt_ZUjZUDoawkBmwP4?key=7Xu51UOF6Vd1czS7dgW7gA&#34; alt=&#34;Image&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Ambient: Fortio to the details service 100 RPS 10 connections with connection close&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-fixed-layout&#34;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Fortio to &lt;/strong&gt;&lt;strong&gt;details&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Average&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P50&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P75&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P90&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P99&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Differences&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;No Mesh&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;1.90ms&lt;/td&gt;&lt;td&gt;1.72ms&lt;/td&gt;&lt;td&gt;2.28ms&lt;/td&gt;&lt;td&gt;2.77ms&lt;/td&gt;&lt;td&gt;3.98ms&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Ambient&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;2.06ms&lt;/td&gt;&lt;td&gt;2.15ms&lt;/td&gt;&lt;td&gt;2.65ms&lt;/td&gt;&lt;td&gt;2.94ms&lt;/td&gt;&lt;td&gt;4ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;8% slower for average &amp;amp; 6% slower for P90&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Table 2: Fortio to the details service 100 RPS 10 connections with connection close&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Compared with Table 1 results, Table 2 numbers have much higher response times, which is expected as each connection is closed immediately after each response from the details service. Given P50, P75, P90 and P99 are all slower from the ambient run with connection close, it seems safe to rule out connection pooling in ztunnel from the first theory could make requests faster.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Second theory&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;I noticed there is a &lt;a href=&#34;https://github.com/istio/istio/pull/51428/files&#34;&gt;performance-related PR&lt;/a&gt; from John Howard in the details and productpage services of the Bookinfo application in our new Istio v1.23 release. For the details service, the PR enabled the &lt;a href=&#34;https://brooker.co.za/blog/2024/05/09/nagle.html&#34;&gt;TCP_NODELAY&lt;/a&gt; flag for the details WEBrick server, which would reduce the unnecessary delay (up to &lt;a href=&#34;https://vorner.github.io/2020/11/06/40-ms-bug.html&#34;&gt;40ms&lt;/a&gt;) from the response time of the details service.&amp;nbsp; For the productpage service, the PR enabled keep-alive on incoming requests, which will reuse existing incoming connections and thus improve performance.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;With the newly updated details deployment that includes the fix, I repeated the same tests sending 100 RPS via 10 connections to the details service. The results for no mesh and ambient are really close so I ran each of the tests three times to ensure the results are consistent. Below are screenshots of the first run for each scenario:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXdjKAWCsxQBxdyihff3W_P4lB51q2BrhbDaqaF2zPooyH2LaoKVgZhFvhAVkBoUteAa0e3XNaBprLWLW6SweAsNw1YmFuk7FbDnnZKwVLC84URGBRt839qLPXKDOkI9F4dIfJU6UcVCaFbMfXEHpSmQlnph?key=7Xu51UOF6Vd1czS7dgW7gA&#34; alt=&#34;No Mesh: Fortio to the new details service 100 RPS 10 connections&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;No Mesh: Fortio to the new details service 100 RPS 10 connections&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXe2lvcrz94RNS_ewSFqOFRy01z3RRRs5kh7Fx8boQiGHGMHIzaRsO4Fmfo-3wOFAmnPez0SmDJsPiBRqq85L7_5xfOjdDhJbTefdG6QB-bZVmXhgwuNtZOHFpiLtvceT_OmEm7UMdkdXdlHe9OXGJ6tCTeX?key=7Xu51UOF6Vd1czS7dgW7gA&#34; alt=&#34;Ambient: Fortio to the new details service 100 RPS 10 connections&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;I built a table for the three runs for each scenario:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-fixed-layout&#34;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td colspan=&#34;2&#34;&gt;&lt;strong&gt;Fortio to &lt;/strong&gt;&lt;strong&gt;details&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Average&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P50&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P75&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P90&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P99&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Differences&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&#34;2&#34;&gt;&lt;strong&gt;1&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;No Mesh&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;0.76ms&lt;/td&gt;&lt;td&gt;0.58ms&lt;/td&gt;&lt;td&gt;0.69ms&lt;/td&gt;&lt;td&gt;0.81ms&lt;/td&gt;&lt;td&gt;1.56ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;5% slower on average and P90. 25% slower on P99&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Ambient&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;0.72ms&lt;/td&gt;&lt;td&gt;0.57ms&lt;/td&gt;&lt;td&gt;0.66ms&lt;/td&gt;&lt;td&gt;0.76ms&lt;/td&gt;&lt;td&gt;1.24ms&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&#34;2&#34;&gt;&lt;strong&gt;2&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;No Mesh&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;0.72ms&lt;/td&gt;&lt;td&gt;0.59ms&lt;/td&gt;&lt;td&gt;0.7ms&lt;/td&gt;&lt;td&gt;0.82ms&lt;/td&gt;&lt;td&gt;1.6ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;3% slower on P90&lt;/strong&gt; &lt;strong&gt;and&lt;/strong&gt; &lt;strong&gt;18% slower on P99&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Ambient&amp;nbsp;&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;0.76ms&lt;/td&gt;&lt;td&gt;0.59ms&lt;/td&gt;&lt;td&gt;0.69ms&lt;/td&gt;&lt;td&gt;0.8ms&lt;/td&gt;&lt;td&gt;1.37ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;5% slower on average&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&#34;2&#34;&gt;&lt;strong&gt;3&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;No Mesh&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;0.77ms&lt;/td&gt;&lt;td&gt;0.58ms&lt;/td&gt;&lt;td&gt;0.7ms&lt;/td&gt;&lt;td&gt;0.8ms&lt;/td&gt;&lt;td&gt;1.49ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;1% slower on average and 8% slower on P99&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Ambient&amp;nbsp;&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;0.76ms&lt;/td&gt;&lt;td&gt;0.59ms&lt;/td&gt;&lt;td&gt;0.69ms&lt;/td&gt;&lt;td&gt;0.81ms&lt;/td&gt;&lt;td&gt;1.38ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;1% slower on P90&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Table 3: Fortio to the new details service 100 RPS 10 connections&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Compared with the previous result from Table 1, the no mesh numbers from Table 3 have improved quite a bit (more substantially at higher percentage than the ambient numbers) and are now closer to the ambient numbers. Ztunnel has &lt;a href=&#34;https://github.com/istio/ztunnel/pulls?q=is%3Apr+is%3Aclosed+TCP_NODELAY&#34;&gt;TCP_NODELAY&lt;/a&gt; enabled by default, which contributed to the ambient performance improvement over no mesh in Table 1 when the old details service doesn’t have TCP_NODELAY enabled. When the new details service has TCP_NODELAY enabled, it has also improved the ambient response times slightly.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Table 3 also shows there is not much difference for average, P50, P75, P90 between no mesh and ambient runs for this type of load testing to the new details service with TCP_NODELAY enabled. The differences between these runs are likely noise with the exception of P99 where the no mesh is consistently 8% or more slower.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;Third theory&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Continue reviewing the test results from Table 3, why would there be similar latency between no mesh and ambient when there are extra hops to ztunnel pods and significant benefits provided by ambient such as mTLS and L4 observability between the fortio and details service? For the P99 case, why would the details service in the ambient mode be faster consistently?&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Ztunnel provides great read/write buffer management with HTTP/2 multiplexing, which could effectively minimize or sometimes even eliminate the overhead added by the extra hops through the client and the server ztunnel pods. I decided to measure this with syscalls using &lt;a href=&#34;https://strace.io/&#34;&gt;strace&lt;/a&gt; from both the fortio and details service by getting into their Kubernetes worker nodes and attaching the pids using strace while filter out the irrelevant traces:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;strace -fp {pid} -e trace=write,writev,read,recvfrom,sendto,readv&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The strace output from the details service is similar for the no-mesh and ambient cases:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;…&#xA;read(9, &#34;GET /details/0 HTTP/1.1\r\nHost: d&#34;..., 8192) = 118&#xA;write(9, &#34;HTTP/1.1 200 OK\r\nContent-Type: a&#34;..., 180) = 180&#xA;write(9, &#34;{\&#34;id\&#34;:0,\&#34;author\&#34;:\&#34;William Shakes&#34;..., 178) = 178&#xA;write(2, &#34;192.168.239.19 - - [13/Aug/2024:&#34;..., 80) = 80&#xA;…&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Output 1: No mesh or ambient – attach strace to the details service’s PID&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The strace outputs from the fortio service for no-mesh vs ambient are different. In the no-mesh case we see fortio executed two reads, one for the HTTP headers and another for the body.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;…&#xA;read(13, &#34;HTTP/1.1 200 OK\r\nContent-Type: a&#34;..., 4096) = 180&#xA;read(13, &#34;{\&#34;id\&#34;:0,\&#34;author\&#34;:\&#34;William Shakes&#34;..., 4096) = 178&#xA;…&#xA;write(19, &#34;GET /details/0 HTTP/1.1\r\nHost: d&#34;..., 118) = 118&#xA;…&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Output 2: No mesh – attach strace to fortio’s PID&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In the ambient case we consistently see just one read for both the headers and the body.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;…&#xA;read(19, &#34;HTTP/1.1 200 OK\r\nContent-Type: a&#34;..., 4096) = 358&#xA;…&#xA;write(19, &#34;GET /details/0 HTTP/1.1\r\nHost: d&#34;..., 118) = 118&#xA;…&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Output 3: Ambient mesh – attach strace to fortio’s PID&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Why would this happen? It makes sense that the write calls are unchanged since they are entirely based on the application behavior which is not changed in this case. Ambient coalesces these multiple application writes and converts them into a single network write and by implication a single read in the peer.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;In the test scenario above I observed a 60% reduction in total syscalls by the fortio service with ambient enabled. This is &lt;strong&gt;&lt;em&gt;very&lt;/em&gt;&lt;/strong&gt; substantial and explains the majority of the improvement in latency and ~25% CPU reduction of the fortio pod at peak time with ambient&lt;strong&gt;. &lt;/strong&gt;The reduction in syscalls is more than offsetting the cost of mTLS and the other features of ztunnel. I expect this pattern to be quite common in enterprise with some HTTP libraries and applications doing a better job of buffering and flushing and some not so much. Often this will correlate with the age of applications and the SDKs they were built on.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXckX5qK1dCRPqok1gI6sHxku5DJJxzFAmapskr64-aYLcqipl8umxksqvZ0Z8na1Bdp-ScO8a85gKB3WiO72BQLmDrVozVzfq6L69xdD9j-aagct2AOfPX8Aq5RE7_4ykgMwysUbb16gsiO7RL3w993LZF-?key=7Xu51UOF6Vd1czS7dgW7gA&#34; alt=&#34;Image&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;No mesh and ambient runs: Fortio to the details service 100 QPS 10 connections&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;What about the entire Bookinfo application?&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;With the newly updated details and productpage deployments, I started with sending 1000 RPS via 100 connections to the Bookinfo application, and observed great results for no mesh and ambient.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXeUhDIyse5YzHS0A73L7-g_kkXGijAzrF3dhDTs7aSlU6GcyI6vpo_GcyhR0gz-TtlMdUfvT-Tz62TXqK3pvskvgTPASkH16IYpseRgauXP0o7pgjLIHNEdp03CYWv99-kf9-iYlkpbaMwpmaaiENEL4bSC?key=7Xu51UOF6Vd1czS7dgW7gA&#34; alt=&#34;Image&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;No Mesh: Fortio to the new Bookinfo app 1000 RPS 100 connections.&lt;br&gt;&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full is-resized&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1600&#34; height=&#34;493&#34; src=&#34;https://www.cncf.io/wp-content/uploads/2024/08/istio-1.png&#34; alt=&#34;Ambient: Fortio to the new Bookinfo app 1000 RPS 100 connections&#34; class=&#34;wp-image-116452&#34; style=&#34;width:900px;height:auto&#34; srcset=&#34;https://www.cncf.io/wp-content/uploads/2024/08/istio-1.png 1600w, https://www.cncf.io/wp-content/uploads/2024/08/istio-1-300x92.png 300w, https://www.cncf.io/wp-content/uploads/2024/08/istio-1-1024x316.png 1024w, https://www.cncf.io/wp-content/uploads/2024/08/istio-1-768x237.png 768w, https://www.cncf.io/wp-content/uploads/2024/08/istio-1-900x277.png 900w, https://www.cncf.io/wp-content/uploads/2024/08/istio-1-600x185.png 600w, https://www.cncf.io/wp-content/uploads/2024/08/istio-1-1200x370.png 1200w&#34; sizes=&#34;(max-width: 1600px) 100vw, 1600px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Ambient: Fortio to the new Bookinfo app 1000 RPS 100 connections&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-fixed-layout&#34;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Fortio to Bookinfo&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Average&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P50&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P75&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P90&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P99&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Average Differences&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;No Mesh&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;1.39ms&lt;/td&gt;&lt;td&gt;1.32ms&lt;/td&gt;&lt;td&gt;1.42ms&lt;/td&gt;&lt;td&gt;1.67ms&lt;/td&gt;&lt;td&gt;2.19ms&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Ambient&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;1.40ms&lt;/td&gt;&lt;td&gt;1.34ms&lt;/td&gt;&lt;td&gt;1.48ms&lt;/td&gt;&lt;td&gt;1.68ms&lt;/td&gt;&lt;td&gt;2.94ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Less than 1% slower for average and P90&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;&lt;em&gt;Table 4: Fortio to the new Bookinfo app 1000 RPS 100 connections.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;For comparison, I also ran the same test against the old Bookinfo sample shipped in v1.22.3, and you can see that the new Bookinfo made &lt;strong&gt;5-10X&lt;/strong&gt; improvements on response times, for either no mesh or ambient!&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-fixed-layout&#34;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Fortio to Bookinfo&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Average&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P50&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P75&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P90&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P99&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Average Differences&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;No Mesh&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;6.35ms&lt;/td&gt;&lt;td&gt;4.68ms&lt;/td&gt;&lt;td&gt;7.44ms&lt;/td&gt;&lt;td&gt;11.4ms&lt;/td&gt;&lt;td&gt;36.63ms&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Ambient&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;6.74ms&lt;/td&gt;&lt;td&gt;4.9ms&lt;/td&gt;&lt;td&gt;7.79ms&lt;/td&gt;&lt;td&gt;12.12ms&lt;/td&gt;&lt;td&gt;41.14ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;6% slower&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Table 5: Fortio to the old Bookinfo app 1000 RPS 100 connections&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Increased the load to 4000 RPS with 400 connections with the new Bookinfo deployments:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXcgUs18Og7Bcmeq5hw8UjiCDB3BJ7fG7h7f8NWeJGnPFmKShR189-K4humffSN-YEPtVnGssIJoRDWEHw9Ju6MmWW9hedRHdTDS29l6z9OEfh5Jp7CT5GR66RQ8tVeDW_muGy1Zl5hJSJrCGKLAVukvH3k?key=7Xu51UOF6Vd1czS7dgW7gA&#34; alt=&#34;Image&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;No Mesh: Fortio to the new Bookinfo app 4000 RPS 400 connections&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXfwlAWXixnPjf9bfZCBc61qZLIVGMnHcxiUl7e_yFc4ApV_PJsXTF6YyVCx1NNRhfSTaNNkcW1xKqw-igF716pNF9dCoPra8lEPwIRLu8Rm_1bnUj06Bh0Ca6gVsZmpxN_N2hYaMCHH89G27Xfy2aAeUC5n?key=7Xu51UOF6Vd1czS7dgW7gA&#34; alt=&#34;Image&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Ambient: Fortio to the new Bookinfo app 4000 RPS 400 connections&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;The response times are still very good, way better than the old Bookinfo app with only 1000 RPS and 100 connections (Table 5):&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-fixed-layout&#34;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Fortio to Bookinfo&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Average&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P50&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P75&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P90&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P99&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Average Differences&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;No Mesh&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;1.54ms&lt;/td&gt;&lt;td&gt;1.33ms&lt;/td&gt;&lt;td&gt;1.54ms&lt;/td&gt;&lt;td&gt;2.25ms&lt;/td&gt;&lt;td&gt;3.98ms&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Ambient&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;1.58ms&lt;/td&gt;&lt;td&gt;1.37ms&lt;/td&gt;&lt;td&gt;1.57ms&lt;/td&gt;&lt;td&gt;2.33ms&lt;/td&gt;&lt;td&gt;4.9ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;3% slower on average and 4% slower on P90&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Table 6: Fortio to the new Bookinfo app 4000 RPS 400 connections&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;It is really nice to see that Bookinfo handles 4000 RPS without any errors and ambient mode is about 3-4% slower than no mesh with all the benefits of encryption in transit with mTLS and L4 observability. I recall I could only reach up to 1200 RPS with the old Bookinfo app, which already resulted in a small percentage of errors. Now I can increase loads to 4000 or higher RPS without errors.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;Wrapping up:&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Ambient mode at L4 introduces only a very tiny impact — and occasionally even an automatic &lt;em&gt;improvement&lt;/em&gt;! — to users’ application latencies. Combined with the simple UX by labeling the namespace to enroll your application to ambient without restarting any workloads, it provides a delightful experience to users that we intended when we initially named it ambient.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;I would like to thank all of our Istio maintainers who built such a delightful project and CNCF for providing the Istio project access to the &lt;a href=&#34;https://www.cncf.io/community-infrastructure-lab/&#34;&gt;infrastructure lab&lt;/a&gt; where I performed the test. I would also like to thank Quentin Joly and many users who provided me with the “ambient is slighter faster than no mesh sometimes” feedback which triggered me to run the above benchmark tests to experience the improvement or tiny latency impact under load for myself.&lt;/p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;】&lt;p&gt;&lt;em&gt;社区帖子最初发布于&lt;a href=&#34;https://thenewstack.io/ambient-mesh-can-sidecar-less-istio-make-applications-faster/&#34;&gt;新堆栈&lt;/a &gt; 作者：Lin Sun&lt;/em&gt;，&lt;em&gt;Solo.io 开源主管&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;环境模式是 2022 年 Istio 中引入的新的无 sidecar 数据平面。当环境模式达到&lt;a href=&#34;https://istio.io/latest/blog/2024/ambient-reaches-beta/&#34;&gt;今年 5 月处于 Beta&lt;/a&gt; 状态，我开始看到许多用户在将应用程序添加到网格后进行尝试并运行负载测试，以了解性能影响。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;受到 &lt;a href=&#34;https://a-cup-of.coffee/blog/istio/#with-istio-ambient&#34;&gt;Quentin Joly 的博客&lt;/a&gt;的启发，了解 Istio 在环境模式下令人难以置信的性能社区中其他用户的类似反馈表明，有时应用程序在环境模式下速度会稍快一些，因此我决定亲自验证这些结果。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;测试环境：&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我使用了 3 个工作节点 Kubernetes 集群，每个节点有 256GB RAM 和 32 核 CPU。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXfS50HjjsJiBqlv30JKgaaTJcmUq0hHcG3xNl42Yzd7E0FfKPAe0gI3tnNAx0gpud0LGfHkdI7cbTXJyzU5v46 v-kucl-2_l7Lax0-kvCeG19mST3ToJdIu6r5u7BoYkAGVc14HnRyVlnX9TY_Ra9NilKQ?key=7Xu51UOF6Vd1czS7dgW7gA&#34; alt= “图片”referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Istio 使用一些工具来轻松进行一致的基准测试。  首先，我们使用名为 &lt;a href=&#34;https://github.com/fortio/fortio&#34;&gt;fortio&lt;/a&gt; 的负载测试工具，它以指定的每秒请求数 (RPS) 运行，记录执行直方图时间并计算百分位数 - 例如，P99，即 99% 的请求花费的时间少于该数字的响应时间。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们还提供了一个名为 &lt;a href=&#34;https://istio.io/latest/docs/examples/bookinfo/&#34;&gt;Bookinfo&lt;/a&gt; 的示例应用程序，其中包括用 Python、Java、Node.js 编写的微服务。 Node.js 和 Ruby。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;每个 Bookinfo 部署都有 2 个副本，均匀分布到 3 个工作节点。使用 &lt;a href=&#34;https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity&#34;&gt;pod 反亲和性规则&lt;/a&gt;，我确保将 fortio 放置在与 &lt;a href=&#34;https://github.com/istio/istio/tree/master/samples/bookinfo/src/details&#34;&gt;details&lt;/a&gt; 服务不同的节点上。&lt; /p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;初始测试结果&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我从 Istio v1.22.3 版本安装了 Bookinfo 应用程序。使用 fortio 工具驱动单个 Bookinfo 服务（例如详细信息）或完整 Bookinfo 应用程序的负载，我注意到将所有内容添加到环境网格后&lt;strong&gt;接近零延迟影响&lt;/strong&gt;。大多数时候，平均值或 P90 的增幅在 0-5% 范围内。我一直注意到 Istio 环境模式下的详细信息服务稍微快一些，就像 Quentin 在他的博客中报告的那样。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3类=“wp-block-heading&#34;&gt;对详细信息服务进行负载测试&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我做了与 Quentin 相同的测试，通过 10 个连接发送 100 RPS 到详细信息服务，并收集了无网格和环境的结果。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXfc1vCggIDlIXmGqt-ac1pUzDPHZd2feGf-TvJRpQu-nmCwXGVliCE8nB2CT_wkVMPibKKFOtjAQ1aj5zxQ-ivUQj74JFEtVZ GwioAYbKLsLeuADG6dhTsvMqaYCvtZk3XlYHTFop6gc-z3zysDhyTrekuU?key= 7Xu51UOF6Vd1czS7dgW7gA&#34; alt=&#34;无网格：详细信息服务 100 RPS&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;无网格：详细信息服务 100 RPS&lt;/figcaption&gt;&lt;/图&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXdIB88W4APYre6YtZPZ90pRKvuoAFO05xhIaFXL50Y1PzD6LmZ0SoBTdgc6SMZSBar8LaNi5uWzDMA18_pEUZ9W_r1kiyiz9 WwtcHMQQMkC6i4avrYLdsMlY8wGFc0FwEUR9VUvy-GSeaUJhAI8HK_fgJXB?key=7Xu51UOF6Vd1czS7dgW7gA&#34; alt=&#34;图片&#34; 推荐策略=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;环境：详细信息服务 100 RPS&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;就像 Quentin 一样，我必须运行多个测试来验证环境模式比没有网格的性能稍好 - 这很难相信！就 Bookinfo 详细信息服务而言，添加环境模式可将延迟平均改善 6-11%，同时还添加 mTLS 和 L4 可观察性！&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-fixed-layout&#34;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Fortio &lt;/strong&gt;&lt;strong&gt;详细信息&lt;/strong&gt; &lt;/td&gt;&lt;td&gt;&lt;strong&gt;平均&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P50&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P75&lt;/strong&gt;&lt;/td&gt;&lt; td&gt;&lt;strong&gt;P90&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P99&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;差异&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr &gt;&lt;td&gt;&lt;strong&gt;无网格运行 1&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;0.89ms&lt;/td&gt;&lt;td&gt;0.64ms&lt;/td&gt;&lt;td&gt;0.74ms&lt;/td&gt;&lt;td&gt;0.85 ms&lt;/td&gt;&lt;td&gt;2.67ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;平均慢 11%，P90 慢 5%&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt; strong&gt;环境运行1&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;0.80ms&lt;/td&gt;&lt;td&gt;0.6ms&lt;/td&gt;&lt;td&gt;0.71ms&lt;/td&gt;&lt;td&gt;0.81ms&lt;/td&gt;&lt; td&gt;1.4ms&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;无网格运行 2&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;0.86ms&lt;/td&gt;&lt; td&gt;0.65ms&lt;/td&gt;&lt;td&gt;0.75ms&lt;/td&gt;&lt;td&gt;0.86ms&lt;/td&gt;&lt;td&gt;1.71ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;平均慢 6%，慢 4%对于 P90&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;环境运行 2&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;0.81ms&lt;/td&gt;&lt;td&gt;0.61ms&lt;/ td&gt;&lt;td&gt;0.72ms&lt;/td&gt;&lt;td&gt;0.83ms&lt;/td&gt;&lt;td&gt;1.56ms&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;否网格运行3&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;0.90ms&lt;/td&gt;&lt;td&gt;0.65ms&lt;/td&gt;&lt;td&gt;0.76ms&lt;/td&gt;&lt;td&gt;0.88ms&lt;/td&gt;&lt;td&gt; 1.92ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;平均慢 10%，P90 慢 5%&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;环境运行 3&lt;/strong &gt;&lt;/td&gt;&lt;td&gt;0.82ms&lt;/td&gt;&lt;td&gt;0.63ms&lt;/td&gt;&lt;td&gt;0.72ms&lt;/td&gt;&lt;td&gt;0.84ms&lt;/td&gt;&lt;td&gt;1.5ms&lt;/td&gt; &lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;表 1：Fortio 到详细信息服务 100 RPS 10 个连接&lt;/figcaption&gt;&lt;/figure &gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;为什么应用程序有时在环境网格中速度更快？&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我们被告知服务网格可以添加延迟。此处复制的 Quentin 的结果显示了通过服务网格运行时工作负载&lt;em&gt;更快&lt;/em&gt;的情况。发生了什么事？&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;第一个理论&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;当您的应用程序位于环境网格中时，负载请求首先通过名为 &lt;a href=&#34;https://istio.io/latest/docs/ambient/overview/#ztunnel&#34;&gt;ztunnel 的轻量级本地节点代理传输&lt;/a&gt;，然后到目的地 ztunnel，然后继续到服务。详细信息服务使用 HTTP/1.1 和 Ruby 中的 Webrick 库，我们发现旧的或配置不当的 HTTP 库中的连接管理和保持活动行为很差。我的第一个假设是，当客户端和服务器位于不同节点上时，如果应用程序未使用高效的 HTTP/2 连接，则通过客户端和服务器 ztunnel 进行代理实际上可能会更快。 Ztunnel 使用连接池和 &lt;a href=&#34;https://en.wikipedia.org/wiki/HTTP_tunnel&#34;&gt;HTTP Connect&lt;/a&gt; 在节点之间建立安全隧道，以在负载下利用并行性和 HTTP/2 流复用。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXdkVHCotSRWKoih2aQLCioo38lsv_PtQFILzTPQvVd3vZYFY5VKaIoVPH_VWLeLla9yZGZBhiTo5H1wH-O3EApb2RvUjM- A3Q5k8B9ffCIoN12sRL8UG_FMLIhxti0iZaYXWu7dttoiubPD0GyDyKDcGmE?key=7Xu51UOF6Vd1czS7dgW7gA&#34; alt=&#34;图像“referrerpolicy =“no-referrer”&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;然而，这一理论存在一些挑战。为什么我只在详细信息服务中观察到这一点，而在任何其他 Bookinfo 服务中却没有观察到这一点？&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;进一步研究，我发现我们的 fortio 加载工具具有 &lt;a href=&#34;https://github.com/fortio/fortio/blob/8a7d9112667e637139c788b68cb063f456d20cb4/bincommon/commonflags.go#L55&#34;&gt;通过以下方式启用连接保持活动状态默认&lt;/a&gt;。从 fortio 到详细信息服务有 10 个连接，并且详细信息服务（使用 WEBrick Ruby 库）遵循连接保持活动设置，因此可以在没有环境的情况下有效地重用连接。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;连接关闭时进行负载测试&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;接下来，我尝试通过设置“Connection: close”标头来运行相同的负载测试。这会强制禁用任何 HTTP 连接池，这是测试这一假设的好方法。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;curl -v -d &#39;{&#34;metadata&#34;: {&#34;url&#34;:&#34;http://details:9080/details/0&#34;, &#34; c”：“10”，“qps”：“100”，“n”：“2000”，“异步”：“on”，“保存”：“on”}}&#39;“localhost：8081/fortio/rest/ run?jsonPath=.metadata&#34; -H &#34;连接：关闭&#34;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXfc-HDPourI5Dwlo3n-jkc5TMiqJdm0k0oSb1Z4HZkKIkVgCKKFyJbBv6fp40pS6XwTORrUvYSYfmL7M6Dqu7ZdBSiJYv Xo-O7f4weYTsuQHarX3uit-jQEL4HlWiwNc7PEFPS1DQgm6csv5FhdMhXxUUc?key=7Xu51UOF6Vd1czS7dgW7gA&#34; alt=&#34;图片&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;无网格：Fortio 到详细服务 100 RPS 10 个连接h 连接关闭&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXfBoHXMf2xaXMboBVCNYNmDBkoFIdefso_IbfLft83aStyTTcm4yOAv3zkEwUtddn1gnFZgT9tf_Z0S494iE6TliMgHFuv24T nEMEDdXsFtk2JcS41jUZhTTvAljd9bDA25AGqyjKlt_ZUjZUDoawkBmwP4?key=7Xu51UOF6Vd1czS7dgW7gA&#34; alt=&#34;图片&#34;referrerpolicy=&#34; no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;环境：Fortio 到详细信息服务 100 RPS 10 连接，连接关闭&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-fixed-layout&#34;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Fortio &lt;/strong&gt;&lt;strong&gt;详细信息&lt;/strong&gt; &lt;/td&gt;&lt;td&gt;&lt;strong&gt;平均&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P50&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P75&lt;/strong&gt;&lt;/td&gt;&lt; td&gt;&lt;strong&gt;P90&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P99&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;差异&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr &gt;&lt;td&gt;&lt;strong&gt;无网格&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;1.90ms&lt;/td&gt;&lt;td&gt;1.72ms&lt;/td&gt;&lt;td&gt;2.28ms&lt;/td&gt;&lt;td&gt;2.77ms&lt; /td&gt;&lt;td&gt;3.98ms&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;环境&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;2.06ms&lt;/td&gt; &lt;td&gt;2.15ms&lt;/td&gt;&lt;td&gt;2.65ms&lt;/td&gt;&lt;td&gt;2.94ms&lt;/td&gt;&lt;td&gt;4ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;平均慢 8%，慢 6%对于 P90&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;表 2：Fortio 到详细信息服务 100 RPS 10 个连接（连接关闭）&lt; /图标题&gt;&lt;/图&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;与表 1 结果相比，表 2 数字的响应时间要长得多，这是预期的，因为每个连接在详细信息服务的每次响应后立即关闭。鉴于 P50、P75、P90 和 P99 在连接关闭的环境运行中都较慢，因此可以安全地从第一个理论中排除 ztunnel 中的连接池可以使请求更快。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;第二种理论&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我注意到 John Howard 在详细信息和产品页面服务中有一个 &lt;a href=&#34;https://github.com/istio/istio/pull/51428/files&#34;&gt;与性能相关的 PR&lt;/a&gt;我们新的 Istio v1.23 版本中的 Bookinfo 应用程序。对于详细信息服务，PR 为详细信息 WEBrick 服务器启用了 &lt;a href=&#34;https://brooker.co.za/blog/2024/05/09/nagle.html&#34;&gt;TCP_NODELAY&lt;/a&gt; 标志，这将减少响应时间中不必要的延迟（最多 &lt;a href=&#34;https://vorner.github.io/2020/11/06/40-ms-bug.html&#34;&gt;40ms&lt;/a&gt;）细节服务。  对于productpage 服务，PR 启用了传入请求的保持活动状态，这将重用现有的传入连接，从而提高性能。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;通过包含修复程序的最新更新的详细信息部署，我重复了相同的测试，通过 10 个连接向详细信息服务发送 100 RPS。无网格和环境的结果非常接近，因此我将每个测试运行了三次以确保结果一致。以下是每个场景第一次运行的屏幕截图：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXdjKAWCsxQBxdyihff3W_P4lB51q2BrhbDaqaF2zPooyH2LaoKVgZhFvhAVkBoUteAa0e3XNaBprLWLW6SweAsNw1YmFuk7FbDnnZKwVLC84URGBRt839qLPXKDOkI9F4dIfJU6UcVCaFbMfXEHpSmQlnph?key=7Xu51UOF6Vd1czS7dgW7gA&#34; alt=&#34;无网格：Fortio 到新的详细信息服务 100 RPS 10 个连接&#34; Caption class=&#34;wp-element-caption&#34;&gt;无网格：Fortio 到新的详情服务 100 RPS 10 个连接&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXe2lvcrz94RNS_ewSFqOFRy01z3RRRs5kh7Fx8boQiGHGMHIzaRsO4Fmfo-3wOFAmnPez0SmDJsPiBRqq85L7_5xfOjdDhJbTef dG6QB-bZVmXhgwuNtZOHFpiLtvceT_OmEm7UMdkdXdlHe9OXGJ6tCTeX?key=7Xu51UOF6Vd1czS7dgW7gA&#34; alt=&#34;环境：Fortio 到新的详细信息服务 100 RPS 10 个连接”referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我为每个场景的三次运行构建了一个表：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-fixed-layout&#34;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td colspan=&#34;2&#34;&gt;&lt;strong&gt;Fortio 至 &lt;/strong&gt;&lt;strong&gt;详细信息&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;平均&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P50&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P75&lt;/strong&gt; &lt;/td&gt;&lt;td&gt;&lt;strong&gt;P90&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P99&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;差异&lt;/strong&gt;&lt;/td&gt;&lt; /tr&gt;&lt;tr&gt;&lt;td rowspan=&#34;2&#34;&gt;&lt;strong&gt;1&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;无网格&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;0.76ms&lt;/td &gt;&lt;td&gt;0.58ms&lt;/td&gt;&lt;td&gt;0.69ms&lt;/td&gt;&lt;td&gt;0.81ms&lt;/td&gt;&lt;td&gt;1.56ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;平均慢 5%，P90 。 P99 上慢 25%&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;环境&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;0.72ms&lt;/td&gt;&lt;td&gt;0.57ms&lt; /td&gt;&lt;td&gt;0.66ms&lt;/td&gt;&lt;td&gt;0.76ms&lt;/td&gt;&lt;td&gt;1.24ms&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&#34;2 &#34;&gt;&lt;strong&gt;2&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;无网格&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;0.72ms&lt;/td&gt;&lt;td&gt;0.59ms&lt;/td&gt;&lt;td &gt;0.7ms&lt;/td&gt;&lt;td&gt;0.82ms&lt;/td&gt;&lt;td&gt;1.6ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P90 上慢 3%&lt;/strong&gt; &lt;strong&gt;和&lt;/strong&gt; &lt;strong P99 上速度慢 &gt;18%&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;环境光&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;0.76ms&lt;/td&gt;&lt;td&gt;0.59ms &lt;/td&gt;&lt;td&gt;0.69ms&lt;/td&gt;&lt;td&gt;0.8ms&lt;/td&gt;&lt;td&gt;1.37ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;平均慢 5%&lt;/strong&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&#34;2&#34;&gt;&lt;strong&gt;3&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;无网格&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;0.77ms&lt;/ td&gt;&lt;td&gt;0.58ms&lt;/td&gt;&lt;td&gt;0.7ms&lt;/td&gt;&lt;td&gt;0.8ms&lt;/td&gt;&lt;td&gt;1.49ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;平均慢 1% P99 上慢 8%&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;环境&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;0.76ms&lt;/td&gt;&lt;td&gt;0.59ms&lt; /td&gt;&lt;td&gt;0.69ms&lt;/td&gt;&lt;td&gt;0.81ms&lt;/td&gt;&lt;td&gt;1.38ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P90 上慢 1%&lt;/strong&gt;&lt;/td&gt;&lt; /tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;表 3：Fortio 到新的详细信息服务 100 RPS 10 个连接&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;与表 1 中的先前结果相比，表 3 中的无网格数已改善相当多（比环境数更高的百分比），现在更接近环境数。 Ztunnel 默认启用 &lt;a href=&#34;https://github.com/istio/ztunnel/pulls?q=is%3Apr+is%3Aclose+TCP_NODELAY&#34;&gt;TCP_NODELAY&lt;/a&gt;，这有助于改善环境性能当旧的详细信息服务未启用 TCP_NODELAY 时，表 1 中没有网格。当新的详细信息服务启用 TCP_NODELAY 时，它具有所有因此稍微改善了环境响应时间。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;表 3 还显示，对于启用 TCP_NODELAY 的新详细信息服务进行此类负载测试，无网格运行和环境运行之间的平均值、P50、P75、P90 没有太大差异。这些运行之间的差异可能是噪音，但 P99 除外，其中无网格始终慢 8% 或更多。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 class=&#34;wp-block-heading&#34;&gt;第三种理论&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;继续查看表 3 中的测试结果，当到 ztunnel pod 的额外跳数以及环境提供的显着优势（例如 fortio 和细节服务之间的 mTLS 和 L4 可观察性）时，为什么无网格和环境之间会存在类似的延迟？对于P99的情况，为什么环境模式下的细节服务会始终更快？ &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;Ztunnel 通过 HTTP/2 多路复用提供出色的读/写缓冲区管理，这可以有效地最小化甚至有时甚至消除通过客户端和服务器 ztunnel pod 的额外跃点所增加的开销。我决定通过使用来自 fortio 和细节服务的 &lt;a href=&#34;https://strace.io/&#34;&gt;strace&lt;/a&gt; 的系统调用来测量这一点，方法是进入 Kubernetes 工作节点并使用 strace while filter 附加 pid去掉不相关的痕迹：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;strace -fp {pid} -e trace=write,writev,read,recvfrom,sendto,readv&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;对于无网格和环境情况，详细信息服务的 strace 输出类似：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;...&#xA;读取（9，“GET /details/0 HTTP/1.1\r\n主机：d”...，8192）= 118&#xA;写（9，“HTTP/1.1 200 OK\r\n内容类型：a”...，180）= 180&#xA;写(9, &#34;{\&#34;id\&#34;:0,\&#34;作者\&#34;:\&#34;William Shakes&#34;..., 178) = 178&#xA;写（2，“192.168.239.19 - - [2024年8月13日：”...，80）= 80&#xA;...&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;输出 1：无网格或环境 - 将 strace 附加到详细信息服务的 PID&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;fortio 服务对于无网格和环境的 strace 输出是不同的。在无网格的情况下，我们看到 fortio 执行了两次读取，一次针对 HTTP 标头，另一次针对正文。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;...&#xA;读取（13，“HTTP/1.1 200 OK\r\n内容类型：a”...，4096）= 180&#xA;读(13, &#34;{\&#34;id\&#34;:0,\&#34;作者\&#34;:\&#34;William Shakes&#34;..., 4096) = 178&#xA;……&#xA;写（19，“获取/详细信息/0 HTTP/1.1\r\n主机：d”...，118）= 118&#xA;...&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;输出 2：无网格 - 将 strace 附加到 fortio 的 PID&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在环境情况下，我们始终看到标题和正文都只读取一次。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;wp-block-code&#34;&gt;&lt;code class=&#34;&#34;&gt;...&#xA;读取（19，“HTTP/1.1 200 OK\r\n内容类型：a”...，4096）= 358&#xA;……&#xA;写（19，“获取/详细信息/0 HTTP/1.1\r\n主机：d”...，118）= 118&#xA;...&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;输出 3：环境网格 - 将 strace 附加到 fortio 的 PID&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;为什么会发生这种情况？写调用保持不变是有道理的，因为它们完全基于应用程序行为，在这种情况下不会改变。环境将这些多因素结合在一起多个应用程序写入并将它们转换为单个网络写入，并暗示对等体中的单个读取。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;在上面的测试场景中，我观察到启用环境的 fortio 服务的系统调用总数减少了 60%。这是&lt;strong&gt;&lt;em&gt;非常&lt;/em&gt;&lt;/strong&gt;的重要原因，并且解释了使用环境&lt;strong&gt;在高峰时间 fortio pod 的延迟改善和约 25% CPU 减少的大部分原因。系统调用的减少足以抵消 mTLS 和 ztunnel 其他功能的成本。我预计这种模式在企业中非常常见，一些 HTTP 库和应用程序在缓冲和刷新方面做得更好，而另一些则不然。通常，这与应用程序的年龄及其构建的 SDK 相关。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXckX5qK1dCRPqok1gI6sHxku5DJJxzFAmapskr64-aYLcqipl8umxksqvZ0Z8na1Bdp-ScO8a85gKB3WiO72BQLmDrVozVzf q6L69xdD9j-aagct2AOfPX8Aq5RE7_4ykgMwysUbb16gsiO7RL3w993LZF-?key=7Xu51UOF6Vd1czS7dgW7gA&#34; 替代=&#34;Image&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;无网格和环境运行：Fortio 到详细信息服务 100 QPS 10 个连接&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;整个 Bookinfo 应用程序怎么样？&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;通过新更新的详细信息和产品页面部署，我开始通过 100 个连接向 Bookinfo 应用程序发送 1000 RPS，并观察到没有网格和环境的良好结果。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXeUhDIyse5YzHS0A73L7-g_kkXGijAzrF3dhDTs7aSlU6GcyI6vpo_GcyhR0gz-TtlMdUfvT-Tz62TXqK3pvskvgTPAS kH16IYpseRgauXP0o7pgjLIHNEdp03CYWv99-kf9-iYlkpbaMwpmaaiENEL4bSC?key= 7Xu51UOF6Vd1czS7dgW7gA&#34; alt=&#34;Image&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;无网格：Fortio 到新的 Bookinfo 应用程序 1000 RPS 100 个连接。&lt;br&gt;&lt;/figcaption&gt;&lt;/图&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image size-full is-resized&#34;&gt;&lt;imgloading=&#34;lazy&#34;decoding=&#34;async&#34;width=&#34;1600&#34;height=&#34;493&#34;src=&#34;https://www.cncf .io/wp-content/uploads/2024/08/istio-1.png&#34; alt=&#34;Ambient：Fortio 到新 Bookinfo 应用程序 1000 RPS 100 个连接&#34; class=&#34;wp-image-116452&#34; style=&#34;width:900px ;高度：自动” srcset =“https://www.cncf.io/wp-content/uploads/2024/08/istio-1.png 1600w，https://www.cncf.io/wp-content/uploads /2024/08/istio-1-300x92.png 300w，https://www.cncf.io/wp-content/uploads/2024/08/istio-1-1024x316.png 1024w，https://www.cncf .io/wp-content/uploads/2024/08/istio-1-768x237.png 768w，https://www.cncf.io/wp-content/uploads/2024/08/istio-1-900x277.png 900w ，https://www.cncf.io/wp-content/uploads/2024/08/istio-1-600x185.png 600w，https://www.cncf.io/wp-content/uploads/2024/08/ istio-1-1200x370.png 1200w&#34;sizes=&#34;(max-width: 1600px) 100vw, 1600px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;环境：Fortio 到新书信息应用程序 1000 RPS 100 个连接&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-fixed-layout&#34;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Fortio 到 Bookinfo&lt;/strong&gt;&lt;/td&gt;&lt;td&gt; &lt;strong&gt;平均&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P50&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P75&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P90&lt; /strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P99&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;平均差异&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong &gt;无网格&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;1.39ms&lt;/td&gt;&lt;td&gt;1.32ms&lt;/td&gt;&lt;td&gt;1.42ms&lt;/td&gt;&lt;td&gt;1.67ms&lt;/td&gt;&lt;td&gt; 2.19ms&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;环境&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;1.40ms&lt;/td&gt;&lt;td&gt;1.34ms&lt; /td&gt;&lt;td&gt;1.48ms&lt;/td&gt;&lt;td&gt;1.68ms&lt;/td&gt;&lt;td&gt;2.94ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;平均和 P90 慢不到 1%&lt;/strong&gt;&lt; /td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;&lt;em&gt;表 4：Fortio 到新 Bookinfo 应用程序 1000 RPS 100 个连接。&lt;/em&gt;&lt;/图标题&gt;&lt;/图&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;为了进行比较，我还对 v1.22.3 中提供的旧 Bookinfo 示例进行了相同的测试，您可以看到新的 Bookinfo 在响应时间上取得了 &lt;strong&gt;5-10X&lt;/strong&gt; 改进，无论是没有网格或环境！&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-fixed-layout&#34;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Fortio 到 Bookinfo&lt;/strong&gt;&lt;/td&gt;&lt;td&gt; &lt;strong&gt;平均&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P50&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P75&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P90&lt; /strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P99&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;平均差异&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong &gt;无网格&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;6.35ms&lt;/td&gt;&lt;td&gt;4.68ms&lt;/td&gt;&lt;td&gt;7.44ms&lt;/td&gt;&lt;td&gt;11.4ms&lt;/td&gt;&lt;td&gt; 36.63ms&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;环境&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;6.74ms&lt;/td&gt;&lt;td&gt;4.9ms&lt; /td&gt;&lt;td&gt;7.79ms&lt;/td&gt;&lt;td&gt;12.12ms&lt;/td&gt;&lt;td&gt;41.14ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;慢 6%&lt;/strong&gt;&lt;/td&gt;&lt;/tr &gt;&lt;/tbody&gt;&lt;/table&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;表 5：Fortio 到旧 Bookinfo 应用程序 1000 RPS 100 个连接&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;通过新的 Bookinfo 部署将负载增加到 4000 RPS，有 400 个连接：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXcgUs18Og7Bcmeq5hw8UjiCDB3BJ7fG7h7f8NWeJGnPFmKShR189-K4humffSN-YEPtVnGssIJoRDWEHw9Ju6MmWW9hedRHd TDS29l6z9OEfh5Jp7CT5GR66RQ8tVeDW_muGy1Zl5hJSJrCGKLAVukvH3k?key=7Xu51UOF6Vd1czS7dgW7gA&#34; alt=&#34;图像&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;无网格：Fortio 到新的 Bookinfo 应用程序 4000 RPS 400 个连接&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-image&#34;&gt;&lt;img解码=&#34;async&#34; src=&#34;https://lh7-rt.googleusercontent.com/docsz/AD_4nXfwlAWXixnPjf9bfZCBc61qZLIVGMnHcxiUl7e_yFc4ApV_PJsXTF6YyVCx1NNRhfSTaNNkcW1xKqw-igF716pNF9dCoP ra8lEPwIRLu8Rm_1bnUj06Bh0Ca6gVsZmpxN_N2hYaMCHH89G27Xfy2aAeUC5n?key=7Xu51UOF6Vd1czS7dgW7gA&#34; alt=&#34;图片&#34; 推荐政策=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;环境：Fortio 到新的 Bookinfo 应用程序 4000 RPS 400 连接&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;响应时间仍然非常好，比只有 1000 RPS 和 100 个连接的旧 Bookinfo 应用程序要好得多（表 5）：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;wp-block-table&#34;&gt;&lt;table class=&#34;has-fixed-layout&#34;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Fortio 到 Bookinfo&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;平均&lt;/strong&gt;&lt;/td&gt;&lt; td&gt;&lt;strong&gt;P50&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P75&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;P90&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt; P99&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;平均差异&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;无网格&lt;/strong&gt;&lt;/td&gt;&lt;td &gt;1.54ms&lt;/td&gt;&lt;td&gt;1.33ms&lt;/td&gt;&lt;td&gt;1.54ms&lt;/td&gt;&lt;td&gt;2.25ms&lt;/td&gt;&lt;td&gt;3.98ms&lt;/td&gt;&lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;环境&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;1.58ms&lt;/td&gt;&lt;td&gt;1.37ms&lt;/td&gt;&lt;td&gt;1.57ms&lt;/td&gt;&lt; td&gt;2.33ms&lt;/td&gt;&lt;td&gt;4.9ms&lt;/td&gt;&lt;td&gt;&lt;strong&gt;平均慢 3%，P90 慢 4%&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt; &lt;/table&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;表 6：Fortio 到新 Bookinfo 应用程序 4000 RPS 400 个连接&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;很高兴看到 Bookinfo 可以毫无错误地处理 4000 RPS，环境模式比无网格慢约 3-4%，并且具有 mTLS 和 L4 可观测性传输加密的所有优势。我记得使用旧的 Bookinfo 应用程序只能达到 1200 RPS，这已经导致了一小部分错误。现在我可以将负载增加到 4000 或更高 RPS，而不会出现错误。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 class=&#34;wp-block-heading&#34;&gt;总结：&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;L4 的环境模式只会产生非常小的影响 - 有时甚至会自动&lt;em&gt;改进&lt;/em&gt;！ — 用户的应用程序延迟。通过标记命名空间来将应用程序注册到环境中而无需重新启动任何工作负载，与简单的用户体验相结合，它为用户提供了令人愉快的体验，这正是我们最初将其命名为环境时所希望的。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p&gt;我要感谢所有 Istio 维护者，他们构建了如此令人愉快的项目，并感谢 CNCF 为 Istio 项目提供了对 &lt;a href=&#34;https://www.cncf.io/community-infrastruct-lab/ 的访问权限我进行测试的“基础设施实验室”。我还要感谢 Quentin Joly 和许多用户，他们向我提供了“环境有时比没有网格要快一些”的反馈，这促使我运行上述基准测试，以亲自体验负载下的改进或微小的延迟影响。&lt; /p&gt;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div style=&#34;height:80px&#34; aria-hidden=&#34;true&#34; class=&#34;wp-block-spacer is-style-80-120&#34;&gt;&#xA;&lt;/div&gt;</description>
      <pubDate>Thu, 22 Aug 2024 16:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>