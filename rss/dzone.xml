<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>DZone.com Feed</title>
    <link>https://feeds.dzone.com/home</link>
    <description>Recent posts on DZone.com</description>
    <item>
      <title>【Decoding the Secret Language of LLM Tokenizers】解码LLM Tokenizers的秘密语言</title>
      <link>https://dzone.com/articles/llm-tokenization-costs-performance</link>
      <description>【&lt;p&gt;&lt;a href=&#34;https://dzone.com/refcardz/getting-started-with-large-language-models&#34;&gt;LLMs&lt;/a&gt; may speak in words, but under the hood they think in &lt;a href=&#34;https://dzone.com/articles/bye-tokens-hello-patches&#34;&gt;tokens&lt;/a&gt;: compact numeric IDs representing character sequences. If you grasp why tokens exist, how they are formed, and where the real-world costs arise, you can trim your invoices, slash latency, and squeeze higher throughput from any model, whether you rent a commercial endpoint or serve one in-house.&lt;/p&gt;&#xA;&lt;h2&gt;&lt;strong&gt;Why LLMs Don’t Generate Text One Character at a Time&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;p&gt;Imagine predicting &lt;em&gt;“language”&lt;/em&gt; character by character. When decoding the very last “e,” the network must still replay the entire hidden state for the preceding seven characters. Multiply that overhead by thousands of characters in a long prompt and you get eye-watering compute.&lt;/p&gt;】&lt;p&gt; &lt;a href =“ https://dzone.com/refcardz/getting-with-large-lange-langue-models”&gt; llms &lt;/a&gt;可能会说话，但在hood中，他们在&lt;a href =“序列。如果您掌握了为什么存在令牌，它们的形成方式以及实际成本出现的位置，则可以修剪发票，削减延迟和从任何模型中挤出更高的吞吐量，无论您是租用商业端点还是在内部提供一个。&lt;/p&gt; &lt;/p&gt; &lt;/p&gt;&#xA;&lt;h2&gt; &lt;strong&gt;为什么llms一次不会生成文本一个字符&lt;/strong&gt; &lt;/h2&gt;&#xA;&lt;p&gt;想象一下按字符预测&lt;em&gt;“语言” &lt;/em&gt;字符。当解码最后一个“ E”时，网络仍必须为前面的七个字符重新重播整个隐藏状态。在很长的提示中将开销乘以数千个字符，您会得到令人叹为观止的计算。&lt;/p&gt;</description>
      <pubDate>Thu, 10 Jul 2025 18:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Contract-Driven ML: The Missing Link to Trustworthy Machine Learning】合同驱动的ML：与值得信赖的机器学习的缺失链接</title>
      <link>https://dzone.com/articles/prevent-ml-failures-with-data-contracts</link>
      <description>【&lt;p&gt;In the age of machine learning and &lt;a href=&#34;https://dzone.com/articles/agentic-ai-and-generative-ai&#34;&gt;AI-driven decision-making&lt;/a&gt;, model accuracy is often touted as the holy grail. Teams boast of hitting 95%+ F1 scores or outshining baselines by double digits. However, high accuracy in development environments means very little if the model is fed garbage in production. That’s where &lt;a href=&#34;https://dzone.com/events/video-library/data-contracts-and-data-observability-whatnot-s-full-circle-journey-to-data-trust&#34;&gt;data contracts&lt;/a&gt; come in: the unsung hero of reliable, scalable machine learning systems.&lt;/p&gt;&#xA;&lt;p&gt;Without robust data quality, schema validation, and pipeline reliability, even the most accurate model is nothing more than a fragile sandbox experiment. In this article, we’ll explore the critical role of data contracts in ML systems, why accuracy metrics can be deceptive, and how enforcing contracts can save your models from silent failure in production.&lt;/p&gt;】&lt;p&gt;在机器学习的时代和&lt;a href =“ https://dzone.com/articles/agentic-aiai-aibai-and-generative-iai”&gt; ai-drive-drive-drive-make &lt;/a&gt;，模型准确性通常被吹捧为圣杯。团队拥有95％+ F1的得分或以两位数为单位的基线。但是，开发环境中的高精度很小，如果模型在生产中被喂食。那就是&lt;a href =“ https://dzone.com/events/video-library/data-contracts-and-data-data-observability-whatot-s-furll-circle-journey-journey-journey-to-data-tha-tha-tha-tha-tha-tha-tata-tha-tata-tha-&gt; ​​in&gt;数据合同&lt;/a&gt;&#xA;&lt;p&gt;没有强大的数据质量，架构验证和管道可靠性，即使是最准确的模型也无非是一个脆弱的沙盒实验。在本文中，我们将探讨数据合同在ML系统中的关键作用，为什么准确度指标可以具有欺骗性以及执行合同如何使您的模型免于生产中的无声失败。&lt;/p&gt;</description>
      <pubDate>Thu, 10 Jul 2025 19:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【When Caches Collide: Solving Race Conditions in Fare Updates】当缓存碰撞时：解决票价更新中的比赛条件</title>
      <link>https://dzone.com/articles/fare-cache-race-conditions-troubleshooting</link>
      <description>【&lt;p data-pm-slice=&#34;1 1 []&#34;&gt;Distributed flight-pricing systems rely on layered caches to balance low latency and fresh data. In practice, caches often use short &lt;code&gt;TTL&lt;/code&gt;s (minutes to hours) supplemented by &lt;a href=&#34;https://dzone.com/articles/understanding-api-caching-and-its-benefits-in-impr&#34;&gt;event-driven invalidation&lt;/a&gt;. However, concurrent cache writes – for example when multiple instances update fares simultaneously – can trigger subtle race conditions. These manifest as stale or inconsistent prices, duplicate cache entries, or &#34;split-brain&#34; behavior across regions. To diagnose and prevent these issues, experienced teams use end-to-end observability and proven patterns. In particular, embedding &lt;code&gt;correlation ID&lt;/code&gt;s in every log and trace, combined with&amp;nbsp;&lt;a href=&#34;https://dzone.com/articles/secrets-management-datadog-secret-backend-utility&#34;&gt;&lt;code&gt;Datadog&lt;/code&gt;&lt;/a&gt;&#39;s&amp;nbsp;&lt;code&gt;metrics&lt;/code&gt;/&lt;code&gt;trace&lt;/code&gt;/&lt;code&gt;log&lt;/code&gt; stack, lets engineers pinpoint exactly where a fare-update went wrong. The key is to instrument cache operations thoroughly (&lt;code&gt;hits&lt;/code&gt;,&amp;nbsp;&lt;code&gt;misses&lt;/code&gt;,&amp;nbsp;&lt;code&gt;writes&lt;/code&gt;,&amp;nbsp;&lt;code&gt;expirations&lt;/code&gt;) and watch for anomalies in real telemetry such as&amp;nbsp;&lt;code&gt;cache hit rate&lt;/code&gt; or&amp;nbsp;&lt;code&gt;TTL variance&lt;/code&gt;.&lt;/p&gt;&#xA;&lt;h3&gt;Observability: Traces, Logs, and Correlation IDs&lt;/h3&gt;&#xA;&lt;p&gt;Every flight search or booking request should carry a unique transaction or&amp;nbsp;&lt;code&gt;correlation ID&lt;/code&gt; across services. In airline data standards, for example, a&amp;nbsp;&lt;code&gt;Correlation ID&lt;/code&gt; is a&amp;nbsp;&lt;code&gt;UUID&lt;/code&gt; included by the seller and echoed by the airline to link related messages. In modern systems, that ID is logged by each microservice and also attached to traces.&amp;nbsp;&lt;code&gt;Datadog&lt;/code&gt; recommends injecting&amp;nbsp;&lt;code&gt;trace/span IDs&lt;/code&gt; and&amp;nbsp;&lt;code&gt;env&lt;/code&gt;/&lt;code&gt;service&lt;/code&gt;/&lt;code&gt;version&lt;/code&gt; into structured logs so that logs and traces automatically correlate. With this in place, an engineer can query &#34;show me all logs for request X&#34; and see cache lookups, price calculations, rule-engine calls, etc. in one timeline. This end-to-end view is critical for spotting race conditions: for instance, two&amp;nbsp;&lt;code&gt;cache-write&lt;/code&gt; spans with the same timestamp but different data hints at a write-write conflict. Teams should also set up&amp;nbsp;&lt;code&gt;Datadog&lt;/code&gt; alerts on slow&amp;nbsp;&lt;code&gt;cache write latencies&lt;/code&gt; or abnormal request paths. For example, if a cache refresh suddenly takes much longer than usual (as seen in traces), that can indicate contention or serialization issues.&lt;/p&gt;】&lt;p data-pm-slice =“ 1 1 []&gt;分布式飞行定价系统依靠分层的缓存来平衡低延迟和新鲜数据。实际上，缓存通常使用&lt;a href =“ https://dzone.com/articles/understanding-api-caching-and-caching-and-ist-benefits-in-benefits-in-impr”&gt; event-event-event-event-trive-drive diven diven diven Invelidation &lt;/a&gt;。但是，并发缓存写入（例如，当多个实例同时更新票价时）可以触发微妙的种族条件。这些表现为既定价格或不一致的价格，重复的缓存条目或各个地区的“分裂脑”行为。为了诊断和预防这些问题，经验丰富的团队使用端到端的可观察性和经过验证的模式。特别是，在每个日志和跟踪中嵌入&lt;code&gt;相关性ID &lt;/code&gt; s，结合&lt;a href =“ https://dzone.com/articles/secrets-management-management-datadog-secret-secret-secret-backend-backend-ietility”&gt;让工程师精确地指出了票价更高的问题。 The key is to instrument cache operations thoroughly (&lt;code&gt;hits&lt;/code&gt;, &lt;code&gt;misses&lt;/code&gt;, &lt;code&gt;writes&lt;/code&gt;, &lt;code&gt;expirations&lt;/code&gt;) and watch for anomalies in real telemetry such as &lt;code&gt;cache hit rate&lt;/code&gt; or &lt;code&gt;TTL variance&lt;/code&gt;.&lt;/p&gt;&#xA;&lt;H3&gt;可观察性：迹线，日志和相关ID &lt;/h3&gt;&#xA;&lt;p&gt;每个飞行搜索或预订请求都应在服务范围内携带唯一的交易或&lt;code&gt;相关ID &lt;/code&gt;。例如，在航空公司数据标准中，&lt;code&gt;相关ID &lt;/code&gt;是卖方包含的&lt;code&gt; uuid &lt;/code&gt;，并由航空公司回应以链接相关消息。在现代系统中，该ID由每个微服务记录并附加到痕迹上。 &lt;code&gt; datadog &lt;/code&gt;建议注入&lt;code&gt;跟踪/跨度IDS &lt;/code&gt;和&lt;code&gt; env &lt;/code&gt;/&lt;code&gt;服务&gt;服务&lt;/code&gt;/&lt;code&gt;/&lt;code&gt; version &lt;/code&gt;版本&lt;/code&gt;中的结构化日志，以便日志和跟踪自动相关。有了这样做，工程师可以在一个时间表中查询“向我展示请求X的所有日志”，并查看缓存查找，价格计算，规则引擎呼叫等。这种端到端的视图对于发现种族条件至关重要：例如，两个&lt;code&gt; Cache-Write &lt;/code&gt;具有相同时间戳的跨度，但在写入写冲突中的数据提示不同。团队还应设置&lt;code&gt; datadog &lt;/code&gt;慢&lt;code&gt;缓存写入潜伏期&lt;/code&gt;或异常请求路径上的警报。例如，如果高速缓存刷新突然需要比平时更长的时间（如在痕迹中所示），则可能表明争夺或序列化问题。&lt;/p&gt;</description>
      <pubDate>Thu, 10 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Building an AI Nutrition Coach With OpenAI, Gradio, and gTTS】使用OpenAI，Gradio和GTTS建立AI营养教练</title>
      <link>https://dzone.com/articles/building-an-ai-nutrition-coach-with-openai-gradio</link>
      <description>【&lt;p data-end=&#34;321&#34; data-start=&#34;98&#34;&gt;Ever thought about building your own AI-powered app that gives personalized nutrition tips, and even talks back to you? In this hands-on tutorial, you’ll learn how to create &lt;strong data-end=&#34;286&#34; data-start=&#34;275&#34;&gt;Nurture&lt;/strong&gt;, your very own AI nutrition coach.&lt;/p&gt;&#xA;&lt;p data-end=&#34;659&#34; data-start=&#34;323&#34;&gt;We’ll use &lt;a href=&#34;https://dzone.com/articles/the-top-6-use-cases-of-gpt-4&#34;&gt;&lt;strong data-end=&#34;342&#34; data-start=&#34;333&#34;&gt;GPT-4&lt;/strong&gt;&lt;/a&gt; for natural, intelligent conversations, &lt;a href=&#34;https://dzone.com/articles/exploring-python-tools-for-generative-ai?fromrel=true&#34;&gt;&lt;strong data-end=&#34;393&#34; data-start=&#34;383&#34;&gt;Gradio&lt;/strong&gt;&lt;/a&gt; to build a simple, interactive web interface, and &lt;strong data-end=&#34;452&#34; data-start=&#34;444&#34;&gt;gTTS&lt;/strong&gt; (Google Text-to-Speech) so your app can speak its responses aloud. Nurture will be able to chat with users, calculate their BMI, and provide helpful audio feedback, all wrapped in a clean, shareable web app.&lt;/p&gt;】&lt;p data-end =“ 321” data-start =“ 98”&gt;曾经考虑过构建自己的AI驱动应用程序，该应用程序提供了个性化的营养技巧，甚至与您交谈？在本动手教程中，您将学习如何创建&lt;strong data-end =“ 286” data-start =“ 275”&gt; nurture &lt;/strong&gt;，您自己的AI营养教练。&lt;/p&gt;&#xA;&lt;p data-end=&#34;659&#34; data-start=&#34;323&#34;&gt;We’ll use &lt;a href=&#34;https://dzone.com/articles/the-top-6-use-cases-of-gpt-4&#34;&gt;&lt;strong data-end=&#34;342&#34; data-start=&#34;333&#34;&gt;GPT-4&lt;/strong&gt;&lt;/a&gt; for natural, intelligent conversations, &lt;a href =“ https://dzone.com/articles/exploring-python-tools-for-generative-generative-generative-gerrel=true”&gt; &lt;strong data-end =“ 393” data data-start =“ 383”&gt; gradio &lt;/strong&gt; &lt;/strong&gt; &lt;/a&gt;构建简单的，交互的网络界面，以及data-start =“ 444”&gt; gtts &lt;/strong&gt;（Google文本到语音），因此您的应用程序可以大声说出其响应。培育将能够与用户聊天，计算其BMI并提供有用的音频反馈，所有这些都包裹在一个干净，可共享的Web应用程序中。&lt;/p&gt;</description>
      <pubDate>Thu, 10 Jul 2025 15:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Why Tailwind CSS Can Be Used Instead of Bootstrap CSS】为什么可以使用tailwind CSS代替Bootstrap CSS</title>
      <link>https://dzone.com/articles/where-tailwindcss-can-be-used-instead-of-bootstrap</link>
      <description>【&lt;p&gt;While Bootstrap has been a component-based approach for quick UI development, Tailwind CSS has emerged as a more zero-runtime, flexible, and utility-based approach, helping us to give more freedom for website development.&lt;/p&gt;&#xA;&lt;h2 dir=&#34;ltr&#34;&gt;Tailwind CSS vs. Bootstrap Comparison&lt;/h2&gt;&#xA;&lt;div align=&#34;left&#34; dir=&#34;ltr&#34;&gt;&#xA; &lt;div class=&#34;table-responsive&#34; style=&#34;border: none;&#34;&gt;&#xA;  &lt;table style=&#34;max-width: 100%; width: auto; table-layout: fixed; display: table;&#34; width=&#34;auto&#34;&gt;&#xA;   &lt;thead&gt;&#xA;    &lt;tr style=&#34;overflow-wrap: break-word; width: auto;&#34; width=&#34;auto&#34;&gt;&#xA;     &lt;th style=&#34;overflow-wrap: break-word; width: auto;&#34; width=&#34;auto&#34;&gt;&#xA;      &lt;p dir=&#34;ltr&#34;&gt;&lt;strong&gt;Feature&lt;/strong&gt;&lt;/p&gt;】&lt;p&gt;虽然Bootstrap是一种基于组件的快速UI开发方法，但Tailwind CSS已成为一种更零，基于柔性且基于公用事业的方法，帮助我们为网站开发提供了更多的自由。&lt;/p&gt;&#xA;&lt;h2 dir =“ ltr”&gt; tailwind CSS与Bootstrap比较&lt;/h2&gt;&#xA;&lt;div align =“ left” dir =“ ltr”&gt;&#xA; &lt;div class =“ table响应”样式=“ border：none;”&gt;&#xA;  &lt;table style =“最大宽度：100％;宽度：自动; table-layout：filest; display：table;&#39;&#39;宽度=“自动”&gt;&#xA;   &lt;Thead&gt;&#xA;    &lt;tr style =“溢出 -  wrap：break-word; width：auto;”宽度=“自动”&gt;&#xA;     &lt;th style =“溢出 -  wrap：break-word; width：auto;”宽度=“自动”&gt;&#xA;      &lt;p dir =“ ltr”&gt; &lt;strong&gt;功能&lt;/strong&gt; &lt;/p&gt;</description>
      <pubDate>Thu, 10 Jul 2025 13:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Master AI Development: The Ultimate Guide to LangChain, LangGraph, LangFlow, and LangSmith】AI大师开发：Langchain，Langgraph，Langflow和Langsmith的最终指南</title>
      <link>https://dzone.com/articles/langchain-langgraph-langflow-langsmith-ai-guide</link>
      <description>【&lt;p&gt;&lt;span data-contrast=&#34;auto&#34; lang=&#34;EN-US&#34;&gt;&lt;span data-ccp-parastyle=&#34;First Paragraph&#34;&gt;Large language models (LLMs) like GPT-4 and Llama 3 have become essential for creating powerful applications. However, building these applications involves challenges such as managing prompts, integrating external data, maintaining context, and ensuring scalability.&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;span data-contrast=&#34;auto&#34; lang=&#34;EN-US&#34;&gt;&lt;span data-ccp-parastyle=&#34;First Paragraph&#34;&gt;The&amp;nbsp;&lt;/span&gt;&lt;span data-ccp-parastyle=&#34;First Paragraph&#34;&gt;LangChain&lt;/span&gt;&lt;span data-ccp-parastyle=&#34;First Paragraph&#34;&gt;&amp;nbsp;ecosystem, including&lt;/span&gt;&lt;span data-ccp-parastyle=&#34;First Paragraph&#34;&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;a href=&#34;https://python.langchain.com/docs/introduction/&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;&lt;span data-contrast=&#34;none&#34; lang=&#34;EN-US&#34;&gt;&lt;span data-ccp-charstyle=&#34;Hyperlink&#34;&gt;LangChain&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-contrast=&#34;auto&#34; lang=&#34;EN-US&#34;&gt;&lt;span data-ccp-parastyle=&#34;First Paragraph&#34;&gt;,&lt;/span&gt;&lt;span data-ccp-parastyle=&#34;First Paragraph&#34;&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;a href=&#34;https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;&lt;span data-contrast=&#34;none&#34; lang=&#34;EN-US&#34;&gt;&lt;span data-ccp-charstyle=&#34;Hyperlink&#34;&gt;LangGraph&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-contrast=&#34;auto&#34; lang=&#34;EN-US&#34;&gt;&lt;span data-ccp-parastyle=&#34;First Paragraph&#34;&gt;,&lt;/span&gt;&lt;span data-ccp-parastyle=&#34;First Paragraph&#34;&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;a href=&#34;https://docs.langflow.org/&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;&lt;span data-contrast=&#34;none&#34; lang=&#34;EN-US&#34;&gt;&lt;span data-ccp-charstyle=&#34;Hyperlink&#34;&gt;LangFlow&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-contrast=&#34;auto&#34; lang=&#34;EN-US&#34;&gt;&lt;span data-ccp-parastyle=&#34;First Paragraph&#34;&gt;, and&lt;/span&gt;&lt;span data-ccp-parastyle=&#34;First Paragraph&#34;&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;a href=&#34;https://docs.smith.langchain.com/&#34; rel=&#34;noreferrer noopener&#34; target=&#34;_blank&#34;&gt;&lt;span data-contrast=&#34;none&#34; lang=&#34;EN-US&#34;&gt;&lt;span data-ccp-charstyle=&#34;Hyperlink&#34;&gt;LangSmith&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-contrast=&#34;auto&#34; lang=&#34;EN-US&#34;&gt;&lt;span data-ccp-parastyle=&#34;First Paragraph&#34;&gt;, addresses these challenges at&amp;nbsp;&lt;/span&gt;&lt;span data-ccp-parastyle=&#34;First Paragraph&#34;&gt;different stages&lt;/span&gt;&lt;span data-ccp-parastyle=&#34;First Paragraph&#34;&gt;&amp;nbsp;of the development lifecycle. This article explores each tool, their differences, and when to use them, enhanced with diagrams.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;】&lt;p&gt; &lt;span data-contrast =“ auto” lang =“ en-us”&gt; &lt;span data-ccp-parestyle =“第一段”&gt;诸如GPT-4和Llama 3之类的大语言模型（LLMS）对于创建功能强大的应用程序至关重要。但是，构建这些应用程序涉及挑战，例如管理提示，集成外部数据，维护上下文以及确保可伸缩性。 &lt;/span&gt; &lt;/span&gt; &lt;/p&gt;&#xA;&lt;p&gt; &lt;span data-contrast =“ auto” lang =“ en-us”&gt; &lt;span data-ccp-parastyle =“第一段”&gt; &lt;/span&gt; &lt;span data-ccp-parastyle =“ first段&gt; langchain&gt; langchain&gt; langchain &lt;/span&gt; &lt;span-ccp-parastyle =” “&gt; &lt;/span&gt; &lt;/span&gt; &lt;a href =” data-ccp-charstyle =“超链接”&gt; langchain &lt;/span&gt; &lt;/span&gt; &lt;/a&gt; &lt;span data-contrast =“自动” lang =“ en-us”&gt; &lt;span data-ccp-parastyle =“第一部分href =“ https://langchain-ai.github.io/langgraph/conectects/agentic_concepts/” rel =“ noreferrer noopener” target =“ _ blank”&gt; &lt;span data data data data data data-contrast =“ none” data-ccp-charstyle =“超链接”&gt; langgraph &lt;/span&gt; &lt;/span&gt; &lt;/a&gt; &lt;span data-contrast =“ auto” auto“ lang =” en-us&#39;&gt; &lt;span data-ccp-parastyle =“第一部分href =“ https://docs.langflow.org/” rel =“ noreferrer noopener” target =“ _ black”&gt; &lt;span data-contrast =“ none” none“ lang” lang =“ en-us”&gt; &lt;span data-ccp-parastyle =“第一部分”&gt;和&lt;/span&gt; &lt;span data-ccp-parastyle =“第一段”&gt; &lt;/span&gt; &lt;/span&gt; &lt;a href =“ https://dtps://docs.smith.smith.langchain.langchain.com/ data-contrast=&#34;none&#34; lang=&#34;EN-US&#34;&gt;&lt;span data-ccp-charstyle=&#34;Hyperlink&#34;&gt;LangSmith&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-contrast=&#34;auto&#34; lang=&#34;EN-US&#34;&gt;&lt;span data-ccp-parastyle=&#34;First Paragraph&#34;&gt;, addresses these challenges at &lt;/span&gt;&lt;span data-ccp-parastyle=&#34;First段落“&gt;不同的阶段&lt;/span&gt; &lt;span-ccp-parastyle =“开发生命周期的第一段”&gt;。本文探讨了每个工具，它们的差异以及何时使用它们的图表。&lt;/span&gt; &lt;/span&gt; &lt;/p&gt;</description>
      <pubDate>Thu, 10 Jul 2025 17:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Top 5 Trends in Big Data Quality and Governance in 2025】2025年大数据质量和治理的前5个趋势</title>
      <link>https://dzone.com/articles/top-trends-in-big-data-quality-and-governance</link>
      <description>【&lt;p data-pm-slice=&#34;1 1 []&#34;&gt;Big data isn’t just about collecting more information. It’s about making sure the data you rely on is trustworthy. As we head into 2025, the pressure on developers and data teams to deliver clean, reliable, and compliant data is stronger than ever. With AI tools getting smarter, pipelines becoming more distributed, and privacy regulations continuing to evolve, we’re entering a new phase where quality isn’t a bonus. It’s a requirement.&lt;/p&gt;&#xA;&lt;p&gt;For developers and data engineers, this shift means being responsible not just for how data flows, but also for how it’s validated, documented, and governed. A bad dataset today can ripple downstream into broken dashboards, faulty ML models, and costly compliance issues.&lt;/p&gt;】&lt;p data-pm-slice =“ 1 1 []&gt;大数据不仅仅是收集更多信息。这是要确保您依赖的数据值得信赖。当我们进入2025年时，开发人员和数据团队提供清洁，可靠和兼容的数据的压力比以往任何时候都更强。随着AI工具变得更聪明，管道变得越来越分布，并且隐私法规继续发展，我们进入了一个新阶段，质量不是奖励。这是一个要求。&lt;/p&gt;&#xA;&lt;p&gt;对于开发人员和数据工程师来说，这种转变意味着不仅要对数据流的方式负责，而且还要对其验证，记录和管理的方式负责。今天，一个不好的数据集可以向下游旋转到破损的仪表板，错误的ML模型和昂贵的合规性问题。&lt;/p&gt;</description>
      <pubDate>Thu, 10 Jul 2025 11:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【How My AI Agents Learned to Talk to Each Other With A2A】我的AI代理商如何与A2A互相交谈</title>
      <link>https://dzone.com/articles/multi-agent-ai-architecture-a2a-protocol</link>
      <description>【&lt;p&gt;Alright, welcome to the final post in this three-part series. Let&#39;s do a quick recap of the journey so far:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA; &lt;li&gt;In Part 1, I laid out the &lt;a href=&#34;https://dzone.com/articles/multi-agent-ai-vs-monolithic&#34;&gt;problem with monolithic AI &#34;brains&#34; and designed the architecture for a specialist team of agents&lt;/a&gt; to power my &#34;InstaVibe Ally&#34; feature.&lt;/li&gt;&#xA; &lt;li&gt;In Part 2, we did &lt;a href=&#34;https://dzone.com/articles/ai-agents-api-integration-with-mcp&#34;&gt;a deep dive into the Model Context Protocol (MCP)&lt;/a&gt;, and I showed you exactly how I connected my Platform Interaction Agent to my application&#39;s existing REST APIs, turning them into reusable tools.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;But my agents are still living on isolated islands. My Social Profiling Agent has no way to give its insights to the Event Planner. My platform integrator can create post and event. I&#39;ve built a team of specialists, but I haven&#39;t given them a way to collaborate. They&#39;re a team that can&#39;t talk.&lt;/p&gt;】&lt;p&gt;好吧，欢迎来到这个三部分系列的最后一篇文章。到目前为止，让我们快速回顾一下旅程：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA; &lt;li&gt;在第1部分中，我布置了&lt;a href =“ https://dzone.com/articles/multi-agent-ai-vs-monolithic”&gt;单层AI“ brains”的问题，并为代理商设计了建筑，并为代理商的专业团队&lt;/a&gt;为我的“ Instavibe ally ally”功能提供动力。&#xA; &lt;li&gt;在第2部分中，我们做了&lt;a href =“ https://dzone.com/articles/ai-aigents-apents-api-integration-with-mcp”&gt;对模型上下文协议（MCP）&lt;/a&gt;进行深入研究，我向您展示了我如何将我的平台交互代理与应用程序的现有REST APIS连接到Reus reus reus lie lius lie lie。&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;，但我的特工仍生活在孤立的岛屿上。我的社会分析代理人无法将其见解给活动策划者。我的平台集成商可以创建帖子和事件。我已经建立了一个专家团队，但我还没有给他们一种合作的方法。他们是一个无法说话的团队。&lt;/p&gt;</description>
      <pubDate>Thu, 10 Jul 2025 12:00:06 +0000</pubDate>
    </item>
    <item>
      <title>【Build Real-Time Analytics Applications With AWS Kinesis and Amazon Redshift】使用AWS Kinesis和Amazon Redshift构建实时分析应用程序</title>
      <link>https://dzone.com/articles/building-real-time-analytics-applications-with-aws</link>
      <description>【&lt;p data-end=&#34;435&#34; data-start=&#34;189&#34;&gt;Real-time analytics enables businesses to make immediate, data-driven decisions. Unlike traditional batch processing, real-time processing allows for faster insights, better customer experiences, and more responsive operations.&lt;/p&gt;&#xA;&lt;p data-end=&#34;614&#34; data-start=&#34;437&#34;&gt;In this tutorial, you’ll learn how to build a real-time analytics pipeline using AWS Kinesis for streaming data and Amazon Redshift for querying and analyzing that data.&lt;/p&gt;】&lt;p data-end =“ 435” data-start =“ 189”&gt;实时分析使企业能够立即做出数据驱动的决策。与传统的批处理处理不同，实时处理可以更快的见解，更好的客户体验和更敏感的操作。&lt;/p&gt;&#xA;&lt;p data-end =“ 614” data-start =“ 437”&gt;在本教程中，您将学习如何使用AWS Kinesis来构建实时分析管道，以进行流式数据和Amazon RedShift查询和分析数据。&lt;/p&gt;</description>
      <pubDate>Thu, 10 Jul 2025 14:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Modernize Your IAM Into Identity Fabric Powered by Connectors】将您的IAM现代化为由连接器提供动力的身份结构</title>
      <link>https://dzone.com/articles/modern-identity-fabric-iam</link>
      <description>【&lt;p&gt;It’s no secret that technology is evolving much faster than our traditional &lt;a href=&#34;https://dzone.com/refcardz/identity-and-access-management-2&#34;&gt;Identity and Access Management&lt;/a&gt; systems can handle. These legacy systems were designed for simpler times, when everything was hosted locally and security was perimeter-based.&lt;/p&gt;&#xA;&lt;p&gt;So, in an era where most enterprises, if not all, are moving their workloads to hybrid, multi-cloud, and AI-driven environments, these outdated IAM systems are being pushed to their breaking points. Quite frankly, they aren’t doing so well.&lt;/p&gt;】&lt;p&gt;技术的发展速度要比我们的传统&lt;a href =“ https://dzone.com/refcardz/nistity-andity-and-yccess-management-2”&gt;身份和访问管理&lt;/a&gt;系统可以处理。这些传统系统是为了简单的时期而设计的，当时一切都是在本地托管的，并且安全性是基于周围的。&lt;/p&gt;&#xA;&lt;p&gt;因此，在大多数企业（即使不是全部）将其工作负载转移到混合，多云和AI驱动的环境的时代，这些过时的IAM系统都被推到了他们的突破点。坦率地说，他们做得不好。&lt;/p&gt;</description>
      <pubDate>Thu, 10 Jul 2025 20:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>