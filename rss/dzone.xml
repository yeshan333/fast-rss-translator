<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>DZone.com Feed</title>
    <link>https://feeds.dzone.com/home</link>
    <description>Recent posts on DZone.com</description>
    <item>
      <title>【Looking at the Evolving Landscape of ITSM Through the Lens of AI】从人工智能的角度审视 ITSM 的演变格局</title>
      <link>https://dzone.com/articles/evolving-landscape-of-itsm-through-ai</link>
      <description>【&lt;p&gt;As today’s businesses march forward alongside &lt;a href=&#34;https://dzone.com/articles/ai-for-ai-systems-automation&#34;&gt;rapid developments in artificial intelligence (AI)&lt;/a&gt;, progress has reached nearly every major functional area of technology. One such area on the cusp of transformational change is Information Technology Service Management (ITSM). For the last decades, traditional ITSM systems have relied heavily on manual workflows and unstructured processes. One can argue that while these systems introduced order and consistency, they also created bottlenecks, long resolution times, and reactive operations.&lt;/p&gt;&#xA;&lt;p data-end=&#34;1190&#34; data-start=&#34;684&#34;&gt;With the advent of large language models (LLMs) and agentic AI, this technology paradigm is undergoing a rapid shift. As we speak, AI is reshaping how services are delivered, managed, and optimized. With the power of AI, traditional support channels across service desks are gradually evolving into proactive, self-healing ecosystems where issues are anticipated before they disrupt business, and routine manual tasks resolve themselves automatically. In this article, we explore the key ways AI has become the driving force behind the &lt;a href=&#34;https://dzone.com/articles/harnessing-ai-to-revolutionize-it-service&#34;&gt;ITSM revolution&lt;/a&gt;.&lt;/p&gt;】&lt;p&gt;随着当今的企业随着&lt;a href=&#34;https://dzone.com/articles/ai-for-ai-systems-automation&#34;&gt;人工智能 (AI) 的快速发展&lt;/a&gt;不断前进，几乎所有主要的技术功能领域都取得了进步。信息技术服务管理 (ITSM) 就是处于转型变革尖端的此类领域之一。在过去的几十年里，传统的 ITSM 系统严重依赖手动工作流程和非结构化流程。有人可能会说，虽然这些系统引入了秩序和一致性，但它们也造成了瓶颈、较长的解决时间和反应性操作。&lt;/p&gt;&#xA;&lt;p data-end=&#34;1190&#34; data-start=&#34;684&#34;&gt;随着大型语言模型 (LLM) 和代理 AI 的出现，这种技术范式正在经历快速转变。正如我们所说，人工智能正在重塑服务的交付、管理和优化方式。借助人工智能的力量，跨服务台的传统支持渠道正在逐渐演变为主动、自我修复的生态系统，在问题扰乱业务之前就可以预见到问题，并且日常手动任务会自动解决。在本文中，我们将探讨人工智能成为 &lt;a href=&#34;https://dzone.com/articles/harnessing-ai-to-revolutionize-it-service&#34;&gt;ITSM 革命&lt;/a&gt;背后驱动力的关键方式。&lt;/p&gt;</description>
      <pubDate>Thu, 18 Dec 2025 20:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Building AI Agents Using Docker cagent and GitHub Models】使用 Docker cagent 和 GitHub 模型构建 AI 代理</title>
      <link>https://dzone.com/articles/building-ai-agents-using-docker-cagent-and-github</link>
      <description>【&lt;p&gt;The landscape of AI development is rapidly evolving, and one of the most exciting developments in 2025 from Docker is the release of &lt;strong data-end=&#34;405&#34; data-start=&#34;388&#34;&gt;Docker cagent&lt;/strong&gt;. cagent is Docker’s open-source multi-agent runtime that orchestrates AI agents through declarative YAML configuration. Rather than managing Python environments, SDK versions, and orchestration logic, developers define agent behavior in a single configuration file and execute it with &lt;code data-end=&#34;703&#34; data-start=&#34;691&#34;&gt;cagent run&lt;/code&gt;.&lt;/p&gt;&#xA;&lt;p data-end=&#34;1189&#34; data-start=&#34;706&#34;&gt;In this article, we’ll explore how cagent’s integration with GitHub Models delivers true vendor independence, demonstrate building a real-world podcast generation agent that leverages multiple specialized sub-agents, and show you how to package and distribute your &lt;a href=&#34;https://dzone.com/articles/docker-model-runner-running-ai-models&#34;&gt;AI agents through Docker&lt;/a&gt; Hub. By the end, you’ll understand how to break free from vendor lock-in and build AI agent systems that remain flexible, cost-effective, and production-ready throughout their entire lifecycle.&lt;/p&gt;】&lt;p&gt;人工智能开发的格局正在迅速发展，Docker 2025 年最令人兴奋的发展之一是 &lt;strong data-end=&#34;405&#34; data-start=&#34;388&#34;&gt;Docker cagent&lt;/strong&gt; 的发布。 cagent 是 Docker 的开源多代理运行时，它通过声明性 YAML 配置来编排 AI 代理。开发人员无需管理 Python 环境、SDK 版本和编排逻辑，而是在单个配置文件中定义代理行为，并使用 &lt;code data-end=&#34;703&#34; data-start=&#34;691&#34;&gt;cagent run&lt;/code&gt; 执行它。&lt;/p&gt;&#xA;&lt;p data-end=&#34;1189&#34; data-start=&#34;706&#34;&gt;在本文中，我们将探讨 cagent 与 GitHub Models 的集成如何实现真正的供应商独立性，演示如何构建利用多个专用子代理的真实播客生成代理，并向您展示如何通过 Docker Hub 打包和分发&lt;a href=&#34;https://dzone.com/articles/docker-model-runner-running-ai-models&#34;&gt;AI 代理&lt;/a&gt; Hub。最后，您将了解如何摆脱供应商锁定并构建在整个生命周期中保持灵活、经济高效且可投入生产的 AI 代理系统。&lt;/p&gt;</description>
      <pubDate>Thu, 18 Dec 2025 19:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【When DNS Breaks The Internet: Lessons From The Amazon Outage】当 DNS 破坏互联网时：亚马逊中断的教训</title>
      <link>https://dzone.com/articles/when-dns-breaks-the-internet-lessons-from-the-amaz</link>
      <description>【&lt;p data-end=&#34;524&#34; data-start=&#34;241&#34;&gt;Have you ever had an “Oh boy” moment when your favorite application does not load and you assume there is a fault with your Internet connection? In October 2025, this occurred on a global scale — but in point of fact, it was not &lt;em data-end=&#34;474&#34; data-start=&#34;468&#34;&gt;your&lt;/em&gt; Internet connection that failed; it was Amazon’s.&lt;/p&gt;&#xA;&lt;p data-end=&#34;771&#34; data-start=&#34;526&#34;&gt;A slight misconfiguration of DNS on behalf of Amazon Web Services (AWS) caused a nationwide catastrophe on the Internet, taking with it such corporate behemoths as Fortnite, Alexa, and, not forgetting, the mobile ordering facility at McDonald’s.&lt;/p&gt;】&lt;p data-end=&#34;524&#34; data-start=&#34;241&#34;&gt;当您最喜欢的应用程序无法加载并且您认为您的互联网连接出现故障时，您是否曾经有过“天哪”的时刻？ 2025 年 10 月，这种情况在全球范围内发生 - 但事实上，并不是&lt;em data-end=&#34;474&#34; data-start=&#34;468&#34;&gt;您&lt;/em&gt;的互联网连接失败了；而是您的互联网连接失败了。这是亚马逊的。&lt;/p&gt;&#xA;&lt;p data-end=&#34;771&#34; data-start=&#34;526&#34;&gt;亚马逊网络服务 (AWS) 的 DNS 轻微配置错误在互联网上引发了一场全国性的灾难，并卷走了 Fortnite、Alexa 等企业巨头，当然还有麦当劳的移动订购设施。&lt;/p&gt;</description>
      <pubDate>Thu, 18 Dec 2025 18:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Vision Language Action (VLA) Models Powering Robotics of Tomorrow】视觉语言动作 (VLA) 模型为未来的机器人技术提供动力</title>
      <link>https://dzone.com/articles/vision-language-action-vla-models-powering-robotic</link>
      <description>【&lt;div data-cy=&#34;blog-post-article&#34;&gt;&#xA; &lt;br&gt;&#xA;&lt;/div&gt;&#xA;&lt;div data-cy=&#34;blog-post-article&#34;&gt;&#xA; The &lt;a href=&#34;https://dzone.com/articles/robotics-software-automation&#34;&gt;robotics&lt;/a&gt; industry is undergoing a fundamental transformation. For decades, robots have been confined to narrow, pre-programmed tasks in controlled environments — assembly lines, warehouses, and labs where predictability reigns.&#xA;&lt;/div&gt;&#xA;&lt;p&gt;Vision-language-action (VLA) models represent a critical breakthrough in this evolution by combining visual perception, language understanding, action generation, and the potential for generalization. VLA models are poised to redefine what machines can do in the physical world. We will go over different VLA models in the industry today that you can leverage in your work.&lt;/p&gt;&#xA;&lt;h2&gt;What Are Vision-Language-Action (VLA) Models&lt;/h2&gt;&#xA;&lt;p&gt;Vision-language-action (VLA) models combine visual perception and natural language understanding to generate contextually appropriate actions. Traditional computer vision models are designed to recognize objects, whereas VLA models interpret scenes, reason about them, and guide physical actions in real-world environments.&lt;/p&gt;】&lt;div data-cy=&#34;blog-post-article&#34;&gt;&#xA; &lt;br&gt;&#xA;&lt;/div&gt;&#xA;&lt;div data-cy=&#34;blog-post-article&#34;&gt;&#xA; &lt;a href=&#34;https://dzone.com/articles/robotics-software-automation&#34;&gt;机器人&lt;/a&gt;行业正在经历根本性变革。几十年来，机器人一直局限于受控环境中执行狭窄的、预先编程的任务——可预测性占主导地位的装配线、仓库和实验室。&#xA;&lt;/div&gt;&#xA;&lt;p&gt;视觉-语言-动作 (VLA) 模型通过结合视觉感知、语言理解、动作生成和泛化潜力，代表了这一演变的关键突破。 VLA 模型准备重新定义机器在物理世界中的功能。今天我们将介绍业界可以在工作中利用的不同 VLA 模型。&lt;/p&gt;&#xA;&lt;h2&gt;什么是视觉-语言-动作 (VLA) 模型&lt;/h2&gt;&#xA;&lt;p&gt;视觉-语言-动作 (VLA) 模型将视觉感知和自然语言理解结合起来，生成适合上下文的动作。传统的计算机视觉模型旨在识别物体，而 VLA 模型则解释场景、推理场景并指导现实环境中的物理动作。&lt;/p&gt;</description>
      <pubDate>Thu, 18 Dec 2025 17:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【We Taught AI to Talk — Now It&#39;s Learning to Talk to Itself: A Deep Dive】我们教人工智能说话——现在它正在学习自言自语：深入探讨</title>
      <link>https://dzone.com/articles/we-taught-ai-to-talk-now-its-learning-to-talk-to-it</link>
      <description>【&lt;h2 data-end=&#34;201&#34; data-start=&#34;136&#34;&gt;A Master Blueprint for the Next Era of Human-AI Interaction&lt;/h2&gt;&#xA;&lt;p data-end=&#34;894&#34; data-start=&#34;203&#34;&gt;In the rapidly evolving world of artificial intelligence, &lt;a href=&#34;https://dzone.com/articles/mastering-prompt-engineering-for-generative-ai&#34;&gt;prompt engineering&lt;/a&gt; has become a crucial component of effective human-AI interaction. However, as large language models (LLMs) become increasingly complex, the traditional human-focused approach to prompting is reaching a critical point. What was once a delicate skill of crafting precise instructions is now becoming a bottleneck, causing inefficiencies and subpar results. This article explores the concept of AI-generated intent, arguing that the future of human-AI collaboration hinges not on humans becoming more proficient at crafting prompts, but on AI&#39;s learning to generate and refine their prompts and those of their peers.&lt;/p&gt;&#xA;&lt;h2 data-end=&#34;960&#34; data-start=&#34;901&#34;&gt;I. The Breaking Point: Why Human Prompting is Failing&lt;/h2&gt;&#xA;&lt;p data-end=&#34;1441&#34; data-start=&#34;962&#34;&gt;The inherent limitations of human language and cognitive biases often restrict the full potential of advanced AI models. While early LLMs responded well to carefully crafted human prompts, the growing sophistication of these models, particularly in multi-step reasoning tasks, has exposed the limitations of this approach. The issue isn’t a lack of human ingenuity, but rather the fundamental mismatch between human communication styles and the optimal operational logic of AI.&lt;img style=&#34;width: 716px;&#34; class=&#34;fr-fic fr-dib lazyload&#34; data-image=&#34;true&#34; data-new=&#34;false&#34; data-sizeformatted=&#34;132.9 kB&#34; data-mimetype=&#34;image/png&#34; data-creationdate=&#34;1756109778258&#34; data-creationdateformatted=&#34;08/25/2025 08:16 AM&#34; data-type=&#34;temp&#34; data-url=&#34;https://dz2cdn1.dzone.com/storage/temp/18601327-ai-instruction.png&#34; data-modificationdate=&#34;null&#34; data-size=&#34;132920&#34; data-name=&#34;ai-instruction.png&#34; data-id=&#34;18601327&#34; data-src=&#34;https://dz2cdn1.dzone.com/storage/temp/18601327-ai-instruction.png&#34; alt=&#34;AI Instruction Performance&#34;&gt;&lt;/p&gt;】&lt;h2 data-end=&#34;201&#34; data-start=&#34;136&#34;&gt;下一个人机交互时代的总体蓝图&lt;/h2&gt;&#xA;&lt;p data-end=&#34;894&#34; data-start=&#34;203&#34;&gt;在快速发展的人工智能世界中，&lt;a href=&#34;https://dzone.com/articles/mastering-prompt-engineering-for-generative-ai&#34;&gt;即时工程&lt;/a&gt;已成为有效的人机交互的重要组成部分。然而，随着大型语言模型 (LLM) 变得越来越复杂，传统的以人为本的提示方法正在达到一个临界点。制定精确指令曾经是一项微妙的技能，现在却成为了瓶颈，导致效率低下和结果不佳。本文探讨了人工智能生成意图的概念，认为人类与人工智能协作的未来并不取决于人类变得更加熟练地制作提示，而是取决于人工智能学习生成和完善自己及其同伴的提示。&lt;/p&gt;&#xA;&lt;h2 data-end=&#34;960&#34; data-start=&#34;901&#34;&gt;我。转折点：为什么人类提示会失败&lt;/h2&gt;&#xA;&lt;p data-end=&#34;1441&#34; data-start=&#34;962&#34;&gt;人类语言的固有局限性和认知偏差常常限制高级 AI 模型的全部潜力。虽然早期的法学硕士对精心设计的人类提示反应良好，但这些模型的日益复杂，特别是在多步骤推理任务中，暴露了这种方法的局限性。问题不在于人类缺乏聪明才智，而在于人类的沟通方式与人工智能的最佳操作逻辑之间根本不匹配。&lt;img style=&#34;width: 716px;&#34;类=“fr-fic fr-diblazyload”data-image=“true”data-new=“false”data-sizeformatted=“132.9kB”data-mimetype=“image/png”data-creationdate=“1756109778258”data-creationdateformatted=“08/25/2025 08:16 AM”data-type=“temp” data-url=&#34;https://dz2cdn1.dzone.com/storage/temp/18601327-ai-instruction.png&#34; data-modificationdate=&#34;null&#34; data-size=&#34;132920&#34; data-name=&#34;ai-instruction.png&#34; data-id=&#34;18601327&#34; data-src=&#34;https://dz2cdn1.dzone.com/storage/temp/18601327-ai-instruction.png&#34; alt=&#34;AI指令性能&#34;&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 18 Dec 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Why Your UEBA Isn&#39;t Working (and How to Fix It)】为什么您的 UEBA 不起作用（以及如何修复它）</title>
      <link>https://dzone.com/articles/why-ueba-isnt-working-how-to-fix</link>
      <description>【&lt;p name=&#34;0942&#34;&gt;User Entity Behavior Analysis (&lt;strong&gt;UEBA&lt;/strong&gt;) is a security layer that uses machine learning and analytics to detect threats by analyzing patterns in user and entity behavior.&lt;/p&gt;&#xA;&lt;p name=&#34;a9e4&#34;&gt;Here’s an oversimplified example of &lt;a href=&#34;https://dzone.com/articles/challenges-using-anonymous-user-data-for-ueba&#34;&gt;UEBA&lt;/a&gt;: suppose you live in Chicago. You’ve lived there for several years and rarely travel. But suddenly there’s a charge to your credit card from a restaurant in Italy. Someone is using your card to pay for their lasagna! Luckily, your credit card company recognizes the behavior as suspicious, flags the transaction, and stops it from settling. This is easy for your credit card company to flag: they have plenty of historical information on your habits and have created a set of logical rules and analytics for when to flag your transactions.&lt;/p&gt;】&lt;p name=&#34;0942&#34;&gt;用户实体行为分析 (&lt;strong&gt;UEBA&lt;/strong&gt;) 是一个安全层，它使用机器学习和分析通过分析用户和实体行为模式来检测威胁。&lt;/p&gt;&#xA;&lt;p name=&#34;a9e4&#34;&gt;这是一个过于简化的 &lt;a href=&#34;https://dzone.com/articles/challenges-using-anonymous-user-data-for-ueba&#34;&gt;UEBA&lt;/a&gt; 示例：假设您住在芝加哥。您在那里住了几年，很少旅行。但意大利的一家餐馆突然向你的信用卡扣款。有人正在使用您的卡来支付他们的烤宽面条！幸运的是，您的信用卡公司会识别出该行为可疑，标记该交易并阻止其结算。这对于您的信用卡公司来说很容易标记：他们拥有大量有关您习惯的历史信息，并针对何时标记您的交易创建了一套逻辑规则和分析。&lt;/p&gt;</description>
      <pubDate>Thu, 18 Dec 2025 15:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Agile Manifesto: The Reformation That Became the Church】敏捷宣言：成为教会的改革</title>
      <link>https://dzone.com/articles/agile-manifesto-reformation-to-church</link>
      <description>【&lt;h2&gt;TL, DR: The Reformation That Became the Church&lt;/h2&gt;&#xA;&lt;p&gt;The Agile Manifesto followed Luther’s Reformation arc: radical simplicity hardened into scaling frameworks, transformation programs, and debates about what counts as “real Agile.” Learn to recognize when you’re inside the orthodoxy and how to practice the principles without the apparatus.&lt;/p&gt;&#xA;&lt;h2&gt;How Every Disruptive Movement Hardens Into the Orthodoxy It Opposed&lt;/h2&gt;&#xA;&lt;p&gt;In 1517, Martin Luther nailed his 95 theses to a church door to protest the sale of salvation. The Catholic Church had turned faith into a transaction: Pay for indulgences, reduce your time in purgatory. Luther&#39;s message was plain: You could be saved through faith alone, you didn&#39;t need the church to interpret scripture for you, and every believer could approach God directly.&lt;/p&gt;】&lt;h2&gt;TL、DR：成为教会的宗教改革&lt;/h2&gt;&#xA;&lt;p&gt;《敏捷宣言》遵循了路德的改革路线：彻底的简单性被强化为扩展框架、转型计划以及关于什么才是“真正的敏捷”的辩论。学会识别自己何时处于正统观念中，以及如何在没有设备的情况下实践这些原则。&lt;/p&gt;&#xA;&lt;h2&gt;每次颠覆性运动如何强化其所反对的正统观念&lt;/h2&gt;&#xA;&lt;p&gt;1517 年，马丁·路德将他的 95 条论纲钉在教堂门上，抗议出售救赎。天主教会把信仰变成了一种交易：支付赎罪券的费用，减少你在炼狱中的时间。路德的信息很明确：你单靠信心就可以得救，不需要教会为你解释圣经，每个信徒都可以直接接近神。&lt;/p&gt;</description>
      <pubDate>Thu, 18 Dec 2025 14:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Infrastructure as Code: How Automation Evolved to Power AI Workloads】基础设施即代码：自动化如何发展为人工智能工作负载提供动力</title>
      <link>https://dzone.com/articles/infrastructure-as-code-automation-ai-workloads</link>
      <description>【&lt;p&gt;If you read my articles published on DZone this year, you would have sensed that I love &lt;a href=&#34;https://dzone.com/articles/cloud-automation-excellence-terraform-ansible-amp&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt;automation&lt;/a&gt; and that Infrastructure as Code (IaC) is my buddy for automating infrastructure provisioning. Recently, I started exploring and learning about the major shifts happening in the IaC landscape.&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;As part of my weekend readings in the last couple of months, I came across several exciting announcements from HashiConf 2025, &lt;a href=&#34;https://dzone.com/articles/pulumi-infrastructure-as-code&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt;Pulumi&lt;/a&gt;&#39;s new AI capabilities, and a revolutionary platform called &lt;a href=&#34;https://dzone.com/articles/formae-pkl-infrastructure-automation&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt;Formae&lt;/a&gt;. In this article, let&#39;s learn about how IaC progressed in 2025 and how it helped automation, particularly for provisioning AI infrastructure.&lt;/p&gt;】&lt;p&gt;如果您阅读我今年在 DZone 上发表的文章，您会感觉到我喜欢&lt;a href=&#34;https://dzone.com/articles/cloud-automation-excellence-terraform-ansible-amp&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt;自动化&lt;/a&gt;，并且基础设施即代码 (IaC) 是我自动化基础设施配置的好伙伴。最近，我开始探索和了解 IaC 领域发生的重大转变。 &lt;/p&gt;&#xA;&lt;p&gt;作为过去几个月周末阅读的一部分，我看到了 HashiConf 2025 的几项激动人心的公告、&lt;a href=&#34;https://dzone.com/articles/pulumi-infrastruct-as-code&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt;Pulumi&lt;/a&gt; 的新 AI 功能以及名为 &lt;a href=&#34;https://dzone.com/articles/formae-pkl-infrastruct-automation&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt;Formae&lt;/a&gt;。在本文中，让我们了解 IaC 在 2025 年的进展以及它如何帮助自动化，特别是在配置人工智能基础设施方面。&lt;/p&gt;</description>
      <pubDate>Thu, 18 Dec 2025 13:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Agentic AI in Cloud-Native Systems: Security and Architecture Patterns】云原生系统中的代理人工智能：安全和架构模式</title>
      <link>https://dzone.com/articles/agentic-ai-security-architecture-cloud-native</link>
      <description>【&lt;p&gt;&lt;span&gt;AI has long progressed past statistical models that generate forecasts or probabilities. The next generation of AI systems is agents, autonomous cloud-native systems capable of acting and intervening in an environment without human intervention or approval. Agents can provision infrastructure, reroute workloads, or optimize costs. They can also remediate incidents or apply other autonomous transformations at scale in cloud-native systems.&lt;/span&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;span&gt;Autonomy is particularly powerful in cloud-native ecosystems: think of self-tuning&amp;nbsp;&lt;/span&gt;&lt;a href=&#34;https://dzone.com/articles/kubernetes-cluster-deploy-1&#34;&gt;&lt;span&gt;Kubernetes clusters&lt;/span&gt;&lt;/a&gt;&lt;span&gt;, self-adapting CI/CD pipelines that dynamically route riskier code to human gatekeepers, or self-orchestrating serverless functions that maintain performance SLAs under previously unseen load spikes. But with autonomy comes a great responsibility: giving an AI agent the power to act in the cloud-native environment changes the nature of the threat surface in a fundamental way.&lt;/span&gt;&lt;/p&gt;】&lt;p&gt;&lt;span&gt;人工智能早已超越了生成预测或概率的统计模型。下一代人工智能系统是代理，即能够在没有人工干预或批准的情况下在环境中行动和干预的自主云原生系统。代理可以配置基础设施、重新路由工作负载或优化成本。他们还可以在云原生系统中大规模修复事件或应用其他自主转换。&lt;/span&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;span&gt;自主性在云原生生态系统中尤其强大：考虑一下自我调优&lt;/span&gt;&lt;a href=&#34;https://dzone.com/articles/kubernetes-cluster-deploy-1&#34;&gt;&lt;span&gt;Kubernetes 集群&lt;/span&gt;&lt;/a&gt;&lt;span&gt;、将风险较高的代码动态路由给人工看门人的自适应 CI/CD 管道，或者在维持性能 SLA 的情况下自编排无服务器功能以前未见过的负载峰值。但是，自主性带来了巨大的责任：赋予人工智能代理在云原生环境中行动的能力，从根本上改变威胁面的性质。&lt;/span&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 18 Dec 2025 12:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Momento Migrates Object Cache as a Service to Ampere® Altra®】Momento 将对象缓存作为服务迁移到 Ampere® Altra®</title>
      <link>https://dzone.com/articles/momento-object-cache-service-ampere-altra</link>
      <description>【&lt;h2 dir=&#34;ltr&#34;&gt;Organization&lt;/h2&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;Momento caching infrastructure for cloud applications is complex and time-consuming. Traditional caching solutions require significant effort in replication, failover management, backups, restoration, and lifecycle management for upgrades and deployments. This operational burden diverts resources from core business activities and feature development.&lt;/p&gt;&#xA;&lt;h2 dir=&#34;ltr&#34;&gt;Solution&lt;/h2&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;Momento provides a serverless cache solution, utilizing Ampere-based Google Tau T2A instances, that automates resource management and optimization, allowing developers to integrate a fast and reliable cache without worrying about the underlying infrastructure. Based on the Apache Pelikan open-source project, Momento’s serverless cache eliminates the need for manual provisioning and operational tasks, offering a reliable API for seamless results.&lt;/p&gt;】&lt;h2 dir=&#34;ltr&#34;&gt;组织&lt;/h2&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;Momento 云应用程序缓存基础设施复杂且耗时。传统的缓存解决方案需要在复制、故障转移管理、备份、恢复以及升级和部署的生命周期管理方面投入大量精力。这种运营负担分散了核心业务活动和功能开发的资源。&lt;/p&gt;&#xA;&lt;h2 dir=&#34;ltr&#34;&gt;解决方案&lt;/h2&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;Momento 提供无服务器缓存解决方案，利用基于 Ampere 的 Google Tau T2A 实例，自动执行资源管理和优化，使开发人员能够集成快速可靠的缓存，而无需担心底层基础设施。 Momento 的无服务器缓存基于 Apache Pelikan 开源项目，无需手动配置和操作任务，提供可靠的 API 以实现无缝结果。&lt;/p&gt;</description>
      <pubDate>Wed, 17 Dec 2025 20:30:01 +0000</pubDate>
    </item>
  </channel>
</rss>