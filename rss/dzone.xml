<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>DZone.com Feed</title>
    <link>https://feeds.dzone.com/home</link>
    <description>Recent posts on DZone.com</description>
    <item>
      <title>【Apache Flink 101: A Guide for Developers】Apache Flink 101：开发人员指南</title>
      <link>https://dzone.com/articles/apache-flink-101-a-guide-for-developers</link>
      <description>【&lt;p dir=&#34;ltr&#34;&gt;In recent years, Apache Flink has established itself as the de facto standard for real-time stream processing. Stream processing is a paradigm for system building that treats event streams (sequences of events in time) as its most essential building block. A stream processor, such as Flink, consumes input streams produced by event sources and produces output streams that are consumed by sinks (the sinks store results and make them available for further processing).&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;Household names like Amazon, Netflix, and Uber rely on Flink to power data pipelines running at tremendous scale at the heart of their businesses, but Flink also plays a key role in many smaller companies with similar requirements for being able to react quickly to critical business events.&lt;/p&gt;】&lt;p dir=&#34;ltr&#34;&gt;近年来，Apache Flink 已成为实时流处理的事实上的标准。流处理是系统构建的范例，它将事件流（时间上的事件序列）视为其最重要的构建块。流处理器（例如 Flink）使用事件源生成的输入流，并生成由接收器使用的输出流（接收器存储结果并使其可用于进一步处理）。&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;Amazon、Netflix 和 Uber 等家喻户晓的公司依靠 Flink 来为其业务核心的大规模数据管道提供支持，但 Flink 在许多具有类似需求的小型公司中也发挥着关键作用。能够对关键业务事件快速做出反应。&lt;/p&gt;</description>
      <pubDate>Thu, 08 Aug 2024 18:30:01 +0000</pubDate>
    </item>
    <item>
      <title>【Demystifying the Magic: A Look Inside the Algorithms of Speech Recognition】揭秘语音识别算法的神秘面纱</title>
      <link>https://dzone.com/articles/look-inside-the-algorithms-of-speech-recognition</link>
      <description>【&lt;p dir=&#34;ltr&#34;&gt;It seems every commercial device now features some implementation of, or an attempt at, speech recognition. From cross-platform voice assistants to transcription services and accessibility tools, and more recently a differentiator for &lt;a href=&#34;https://dzone.com/refcardz/getting-started-with-large-language-models&#34;&gt;LLMs&lt;/a&gt; — dictation has become an everyday user interface. With the market size of voice-user interfaces (VUI) projected to &lt;a href=&#34;https://www.technavio.com/report/voice-user-interface-market-industry-analysis&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt;grow at a CAGR of 23.39% from 2023 to 2028&lt;/a&gt;, we can expect many more tech-first companies to adopt it. But how well do you understand the technology?&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;Let&#39;s start by dissecting and defining the most common technologies that go into making speech recognition possible.&lt;/p&gt;】&lt;p dir=&#34;ltr&#34;&gt;现在似乎每个商业设备都具有语音识别的某种实现或尝试。从跨平台语音助手到转录服务和辅助工具，以及最近的&lt;a href=&#34;https://dzone.com/refcardz/getting-started-with-large-language-models&#34;&gt;法学硕士&lt;/ a&gt; — 听写已成为日常用户界面。语音用户界面 (VUI) 的市场规模预计达到 &lt;a href=&#34;https://www.technavio.com/report/voice-user-interface-market-industry-analysis&#34; rel=&#34;noopener noreferrer&#34; 目标=&#34;_blank&#34;&gt;2023 年至 2028 年复合年增长率为 23.39%&lt;/a&gt;，我们预计会有更多技术优先的公司采用它。但您对这项技术了解多少？&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;让我们首先剖析和定义使语音识别成为可能的最常见技术。&lt;/p&gt;</description>
      <pubDate>Fri, 09 Aug 2024 18:00:01 +0000</pubDate>
    </item>
    <item>
      <title>【Batch vs. Real-Time Processing: Understanding the Differences】批处理与实时处理：了解差异</title>
      <link>https://dzone.com/articles/batch-vs-real-time-processing-understanding-the-differences</link>
      <description>【&lt;p&gt;The decision between batch and real-time processing is a critical one, shaping the design, architecture, and success of our data pipelines. While both methods aim to extract valuable insights from data, they differ significantly in their execution, capabilities, and use cases. Understanding the key distinctions between these two processing paradigms is crucial for organizations to make informed decisions and harness the full potential of their data.&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Key definitions can be summarized as follows:&lt;/p&gt;】&lt;p&gt;批处理和实时处理之间的决策至关重要，它决定着我们数据管道的设计、架构和成功。虽然这两种方法都旨在从数据中提取有价值的见解，但它们在执行、功能和用例方面存在显着差异。了解这两种处理范例之间的主要区别对于组织做出明智的决策并充分利用数据潜力至关重要。 &lt;/p&gt;&#xA;&lt;p&gt;主要定义可概括如下：&lt;/p&gt;</description>
      <pubDate>Thu, 08 Aug 2024 19:20:39 +0000</pubDate>
    </item>
    <item>
      <title>【Running PyTorch on GPUs】在 GPU 上运行 PyTorch</title>
      <link>https://dzone.com/articles/running-pytorch-on-gpus</link>
      <description>【&lt;p&gt;Running an AI workload on a &lt;a href=&#34;https://dzone.com/articles/applications-for-gpu-based-ai-and-machine-learning&#34;&gt;GPU&lt;/a&gt; machine requires the installation of kernel drivers and user space libraries from GPU vendors such as AMD and NVIDIA. Once the driver and software are installed, to use AI frameworks such as &lt;a href=&#34;https://dzone.com/articles/natural-language-processing-pytorch&#34;&gt;PyTorch&lt;/a&gt; and &lt;a href=&#34;https://dzone.com/articles/ai-frameworks-for-software-engineers-part-1&#34;&gt;TensorFlow&lt;/a&gt;, one needs to use the proper framework built against the GPU target. Usually, the AI applications run on top of popular AI frameworks and as such hide the tedious installation steps. This article highlights the importance of the hardware, driver, software, and frameworks for running AI applications or workloads.&lt;/p&gt;&#xA;&lt;p&gt;This article deals with the Linux operating system, ROCm software stack for AMD GPU, CUDA software stack for NVIDIA GPU, and PyTorch for AI frameworks. Docker plays a critical part in bringing up the entire stack allowing the launch of various workloads in parallel.&lt;/p&gt;】&lt;p&gt;在 &lt;a href=&#34;https://dzone.com/articles/applications-for-gpu-based-ai-and-machine-learning&#34;&gt;GPU&lt;/a&gt; 计算机上运行 AI 工作负载需要安装来自 AMD 和 NVIDIA 等 GPU 供应商的内核驱动程序和用户空间库。安装驱动程序和软件后，即可使用 AI 框架，例如 &lt;a href=&#34;https://dzone.com/articles/natural-language-processing-pytorch&#34;&gt;PyTorch&lt;/a&gt; 和 &lt;a href=&#34;https ://dzone.com/articles/ai-frameworks-for-software-engineers-part-1&#34;&gt;TensorFlow&lt;/a&gt;，需要使用针对 GPU 目标构建的正确框架。通常，人工智能应用程序在流行的人工智能框架之上运行，因此隐藏了繁琐的安装步骤。本文强调了运行人工智能应用程序或工作负载的硬件、驱动程序、软件和框架的重要性。&lt;/p&gt;&#xA;&lt;p&gt;本文介绍了 Linux 操作系统、适用于 AMD GPU 的 ROCm 软件堆栈、适用于 NVIDIA GPU 的 CUDA 软件堆栈以及适用于 AI 框架的 PyTorch。 Docker 在启动整个堆栈以允许并行启动各种工作负载方面发挥着关键作用。&lt;/p&gt;</description>
      <pubDate>Thu, 08 Aug 2024 14:00:03 +0000</pubDate>
    </item>
    <item>
      <title>【Use Mistral AI To Build Generative AI Applications With Go】使用 Mistral AI 通过 Go 构建生成式 AI 应用程序</title>
      <link>https://dzone.com/articles/use-mistral-ai-to-build-generative-ai-apps-with-go</link>
      <description>【&lt;p&gt;Mistral AI offers models with varying characteristics across performance, cost, and more:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA; &lt;li&gt;&lt;strong&gt;Mistral 7B:&lt;/strong&gt; The first dense model released by Mistral AI, perfect for experimentation, customization, and quick iteration&lt;/li&gt;&#xA; &lt;li&gt;&lt;strong&gt;Mixtral 8x7B:&amp;nbsp;&lt;/strong&gt;A sparse mixture of experts model&lt;/li&gt;&#xA; &lt;li&gt;&lt;strong&gt;Mistral Large:&amp;nbsp;&lt;/strong&gt;Ideal for complex tasks that require large reasoning capabilities or are highly specialized (Synthetic Text Generation, Code Generation, RAG, or Agents)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Let&#39;s walk through how to use these Mistral AI models on Amazon Bedrock with Go, and in the process, also get a better understanding of its prompt tokens.&lt;/p&gt;】&lt;p&gt;Mistral AI 提供的模型在性能、成本等方面具有不同的特征：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA; &lt;li&gt;&lt;strong&gt;Mistral 7B：&lt;/strong&gt;Mistral AI 发布的第一个密集模型，非常适合实验、定制和快速迭代&lt;/li&gt;&#xA; &lt;li&gt;&lt;strong&gt;Mixtral 8x7B：&lt;/strong&gt;专家模型的稀疏混合&lt;/li&gt;&#xA; &lt;li&gt;&lt;strong&gt;Mistral Large：&lt;/strong&gt;非常适合需要大量推理能力或高度专业化的复杂任务（合成文本生成、代码生成、RAG 或代理）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;让我们逐步了解如何通过 Go 在 Amazon Bedrock 上使用这些 Mistral AI 模型，并在此过程中更好地了解其提示令牌。&lt;/p&gt;</description>
      <pubDate>Fri, 09 Aug 2024 15:00:01 +0000</pubDate>
    </item>
    <item>
      <title>【The Case for Working on Non-Glamorous Migration Projects】从事非光鲜亮丽的移民项目的案例</title>
      <link>https://dzone.com/articles/case-for-working-on-non-glamorous-migration-projects</link>
      <description>【&lt;p dir=&#34;ltr&#34;&gt;In my 13 years of engineering experience, I saw many people make career decisions based on the opportunity to work on a brand-new service. There is nothing wrong with that decision. However, today we are going to make a contradictory case of working on boring migration projects. What I did not realize early on in my career was that most of my foundational software development learning came from projects that were migration projects — e.g., migrating an underlying data store to another cloud-based technology or deprecating a monolithic service in favor of new microservices, etc.&amp;nbsp;&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;This is because migrations are inherently hard: you are forced to meet, if not exceed, an existing bar on availability, scale, latency, and customer experience which was built and honed over the years by multiple engineers. You won’t face those constraints on a brand-new system because you are free to define them. Not only that, no matter how thorough you are with migrations, there will be hidden skeletons in the closet to deal with when you switch over to new parts of the system (Check out this &lt;a href=&#34;https://doordash.engineering/2022/01/19/making-applications-compatible-with-postgres-tables-bigint-update/&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt;interesting article&lt;/a&gt;&lt;a href=&#34;https://doordash.engineering/2022/01/19/making-applications-compatible-with-postgres-tables-bigint-update/on&#34;&gt;&amp;nbsp;&lt;/a&gt;on how Doordash’s migration from Int to BigInt for a database field was fraught with blockers).&amp;nbsp;&lt;/p&gt;】&lt;p dir=&#34;ltr&#34;&gt;在我 13 年的工程经验中，我看到许多人根据从事全新服务的机会做出职业决定。这个决定并没有什么错。然而，今天我们要举一个矛盾的例子，那就是从事无聊的迁移项目。在我职业生涯的早期，我没有意识到的是，我的大部分基础软件开发学习都来自迁移项目，例如，将底层数据存储迁移到另一种基于云的技术，或者弃用单一服务以支持新的微服务等等。&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;这是因为迁移本质上是困难的：您被迫满足（如果不能超越的话）可用性、规模、延迟和客户体验方面的现有标准，这些标准是由多名工程师多年来建立和磨练的。您不会在全新系统上面临这些限制，因为您可以自由定义它们。不仅如此，无论您的迁移有多彻底，当您切换到系统的新部分时，壁橱里都会有隐藏的骨架需要处理（查看此 &lt;a href=&#34;https://doordash.engineering /2022/01/19/making-applications-compat-with-postgres-tables-bigint-update/&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt;有趣的文章&lt;/a&gt;&lt;a href=&#34;https:// /doordash.engineering/2022/01/19/making-applications-known-with-postgres-tables-bigint-update/on&#34;&gt; &lt;/a&gt;了解 Doordash 将数据库字段从 Int 迁移到 BigInt 时如何充满了阻碍）。 &lt;/p&gt;</description>
      <pubDate>Thu, 08 Aug 2024 21:00:01 +0000</pubDate>
    </item>
    <item>
      <title>【How To Create a CRUD Application in Less Than 15 Minutes】如何在 15 分钟内创建 CRUD 应用程序</title>
      <link>https://dzone.com/articles/create-a-crud-application-in-less-than-15-mins</link>
      <description>【&lt;p&gt;&lt;span data-contrast=&#34;auto&#34; lang=&#34;EN-US&#34;&gt;CRUD applications form the backbone of most software projects today. If you&#39;re reading this article, chances are your project encountered some challenges, you’re seeking a faster way to accomplish this task, or you are looking for a Java framework to start with. You&#39;re not alone.&lt;/span&gt;&lt;span data-ccp-props=&#34;{&amp;quot;201341983&amp;quot;:0,&amp;quot;335559739&amp;quot;:160,&amp;quot;335559740&amp;quot;:259}&#34;&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;span data-contrast=&#34;auto&#34; lang=&#34;EN-US&#34;&gt;With the tech world constantly evolving, especially with tighter budgets,&amp;nbsp;there&#39;s&amp;nbsp;a noticeable shift towards frameworks that bring everything under one roof to reduce the need for oversized teams.&lt;/span&gt;&lt;span data-ccp-props=&#34;{&amp;quot;201341983&amp;quot;:0,&amp;quot;335559739&amp;quot;:160,&amp;quot;335559740&amp;quot;:259}&#34;&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;】&lt;p&gt;&lt;span data-contrast=&#34;auto&#34; lang=&#34;EN-US&#34;&gt;CRUD 应用程序构成了当今大多数软件项目的支柱。如果您正在阅读本文，那么您的项目很可能遇到了一些挑战，您正在寻找一种更快的方法来完成此任务，或者您正在寻找一个 Java 框架来开始。您并不孤单。&lt;/span&gt;&lt;span data-ccp-props=&#34;{&#34;201341983&#34;:0,&#34;335559739&#34;:160,&#34;335559740&#34;:259}&#34;&gt; &lt;/span&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;span data-contrast=&#34;auto&#34; lang=&#34;EN-US&#34;&gt;随着科技世界的不断发展，特别是在预算紧张的情况下，出现了明显的向框架的转变，这些框架将所有内容集中在一个屋檐下，以减少对超大数据的需求团队。&lt;/span&gt;&lt;span data-ccp-props=&#34;{&#34;201341983&#34;:0,&#34;335559739&#34;:160,&#34;335559740&#34;:259}&#34;&gt; &lt;/span&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 08 Aug 2024 16:00:01 +0000</pubDate>
    </item>
    <item>
      <title>【Why I Use RTK Query for API Calls in React】为什么我在 React 中使用 RTK 查询进行 API 调用</title>
      <link>https://dzone.com/articles/why-i-use-rtk-query-for-api-calls-in-react</link>
      <description>【&lt;p&gt;The RTK Query part of the Redux Essentials tutorial is phenomenal, but since it’s part of a much larger suite of documentation, I feel like the gem that is RTK Query is getting lost.&lt;/p&gt;&#xA;&lt;h2&gt;What Is Redux?&lt;/h2&gt;&#xA;&lt;p&gt;Many people think of Redux as a state management library, which it is. To them, the main value of Redux is that it makes it possible to access (and change) the application state from anywhere in the application. This misses the point of using something like Redux, so let’s zoom out a bit and take another look.&lt;/p&gt;】&lt;p&gt;Redux Essentials 教程中的 RTK 查询部分非常出色，但由于它是更大文档套件的一部分，我觉得 RTK 查询这一宝石正在迷失。&lt;/p&gt;&#xA;&lt;h2&gt;什么是 Redux？&lt;/h2&gt;&#xA;&lt;p&gt;很多人认为 Redux 是一个状态管理库，事实也确实如此。对于他们来说，Redux 的主要价值在于它可以从应用程序中的任何位置访问（和更改）应用程序状态。这忽略了使用 Redux 之类的东西的意义，所以让我们缩小一点，再看一下。&lt;/p&gt;</description>
      <pubDate>Fri, 09 Aug 2024 16:30:01 +0000</pubDate>
    </item>
    <item>
      <title>【Content Detection Technologies in Data Loss Prevention (DLP) Products】数据丢失防护 (DLP) 产品中的内容检测技术</title>
      <link>https://dzone.com/articles/content-detection-technologies-in-dlp-products</link>
      <description>【&lt;p dir=&#34;ltr&#34;&gt;Having worked with enterprise customers for a decade, I still see potential gaps in data protection. This article addresses the key content detection technologies needed in a &lt;a href=&#34;https://dzone.com/articles/create-data-loss-prevention-policy&#34;&gt;Data Loss Prevention (DLP)&lt;/a&gt; product that developers need to focus on while developing a first-class solution. First, let’s look at a brief overview of the functionalities of a DLP product before diving into detection.&lt;/p&gt;&#xA;&lt;h2 dir=&#34;ltr&#34;&gt;Functionalities of a Data Loss Prevention Product&lt;/h2&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;The primary functionalities of a DLP product are policy enforcement, data monitoring, sensitive data loss prevention, and &lt;a href=&#34;https://dzone.com/articles/insights-from-incident-management&#34;&gt;incident remediation&lt;/a&gt;. Policy enforcement allows security administrators to create policies and apply them to specific channels or enforcement points. These enforcement points include email, network traffic interceptors, endpoints (including BYOD), cloud applications, and data storage repositories. Sensitive data monitoring focuses on protecting critical data from leaking out of the organization&#39;s control, ensuring business continuity. Incident remediation may involve restoring data with proper access permissions, data encryption, blocking suspicious transfers, and more.&lt;/p&gt;】&lt;p dir=&#34;ltr&#34;&gt;与企业客户合作了十年，我仍然看到数据保护方面的潜在差距。本文介绍了开发人员开发的&lt;a href=&#34;https://dzone.com/articles/create-data-loss-prevention-policy&#34;&gt;数据丢失防护 (DLP)&lt;/a&gt; 产品所需的关键内容检测技术开发一流的解决方案时需要重点关注。首先，在深入讨论检测之前，我们先简要概述一下 DLP 产品的功能。&lt;/p&gt;&#xA;&lt;h2 dir=&#34;ltr&#34;&gt;数据丢失防护产品的功能&lt;/h2&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;DLP 产品的主要功能是策略执行、数据监控、敏感数据丢失防护和&lt;a href=&#34;https://dzone.com/articles/insights-from-incident-management ”事件补救&lt;/a&gt;。策略实施允许安全管理员创建策略并将其应用到特定渠道或实施点。这些执行点包括电子邮件、网络流量拦截器、端点（包括 BYOD）、云应用程序和数据存储库。敏感数据监控的重点是保护关键数据免遭泄露出组织的控制范围，确保业务连续性。事件补救可能涉及使用适当的访问权限恢复数据、数据加密、阻止可疑传输等。&lt;/p&gt;</description>
      <pubDate>Fri, 09 Aug 2024 13:30:01 +0000</pubDate>
    </item>
    <item>
      <title>【Connecting ChatGPT to Code Review Made Easy】将 ChatGPT 连接到代码审查变得容易</title>
      <link>https://dzone.com/articles/connecting-chatgpt-to-code-review-made-easy</link>
      <description>【&lt;p dir=&#34;ltr&#34;&gt;The era of artificial intelligence is already already in bloom. Everyone working in IT is already familiar with our &#34;new best friend&#34; for development — AI. Working as a DevOps Engineer at Innovecs, I’d like to share one of my latest findings.&lt;/p&gt;&#xA;&lt;h2 dir=&#34;ltr&#34;&gt;Concept&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA; &lt;li dir=&#34;ltr&#34;&gt;Would you like every pull/merge request to be checked by ChatGPT-4 first and then by you?&lt;/li&gt;&#xA; &lt;li dir=&#34;ltr&#34;&gt;Do you want instant feedback on code changes before your colleagues see them?&lt;/li&gt;&#xA; &lt;li dir=&#34;ltr&#34;&gt;How about detecting who committed confidential data or API keys and where with the ability to tag the &#34;culprit&#34; for correction immediately?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;We’re perfectly aware that GPT can generate code quite well. . . but it turns out it can review it just as smoothly! I will immediately show how this works in practice (parts of the code are blurred to avoid showing too much).&lt;/p&gt;】&lt;p dir=&#34;ltr&#34;&gt;人工智能时代已经全面开花。每个从事 IT 工作的人都已经熟悉我们的开发“新最好的朋友”——人工智能。作为 Innovecs 的 DevOps 工程师，我想分享我的最新发现之一。&lt;/p&gt;&#xA;&lt;h2 dir=&#34;ltr&#34;&gt;概念&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA; &lt;li dir=&#34;ltr&#34;&gt;您希望每个拉取/合并请求首先由 ChatGPT-4 检查，然后由您检查吗？&lt;/li&gt;&#xA; &lt;li dir=&#34;ltr&#34;&gt;您希望在同事看到代码更改之前获得即时反馈吗？&lt;/li&gt;&#xA; &lt;li dir=&#34;ltr&#34;&gt;如何检测谁提交了机密数据或 API 密钥，以及在何处提交了“罪魁祸首”并立即进行更正？&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;我们非常清楚 GPT 可以很好地生成代码。 。 。但事实证明它也可以顺利复习！我将立即展示这在实践中是如何工作的（部分代码被模糊以避免显示太多）。&lt;/p&gt;</description>
      <pubDate>Fri, 09 Aug 2024 12:00:01 +0000</pubDate>
    </item>
  </channel>
</rss>