<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>DZone.com Feed</title>
    <link>https://feeds.dzone.com/home</link>
    <description>Recent posts on DZone.com</description>
    <item>
      <title>【Parameters to Measure in Chaos Engineering Experiments】在混乱工程实验中测量的参数</title>
      <link>https://dzone.com/articles/measure-chaos-engineering-experiments-parameters</link>
      <description>【&lt;p&gt;&lt;strong&gt;Keywords&lt;/strong&gt;: Chaos Engineering, System Resilience, Failure Injection, Performance Metrics, Fault Tolerance&lt;/p&gt;&#xA;&lt;h2&gt;Abstract&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://dzone.com/articles/chaos-engineering-for-microservices&#34;&gt;Chaos Engineering&lt;/a&gt; is an essential practice for testing system resilience by intentionally injecting failures and analyzing the system’s response. This journal explores key parameters to measure in Chaos Engineering experiments, including system performance, availability, fault tolerance, and user experience metrics. By systematically monitoring these parameters, organizations can proactively identify weaknesses, enhance failover mechanisms, and optimize recovery strategies. The study also provides a structured experiment template to help teams document and analyze chaos experiments effectively. The ultimate goal is to build confidence in a system’s ability to withstand turbulent operational conditions and ensure reliable service delivery.&lt;/p&gt;】&lt;p&gt; &lt;strong&gt;关键字&lt;/strong&gt;：混乱工程，系统弹性，失败注入，性能指标，容错&lt;/p&gt;&#xA;&lt;h2&gt;摘要&lt;/h2&gt;&#xA;&lt;p&gt; &lt;a href =“ https://dzone.com/articles/chaos-eenteering-for-microservices”&gt;混乱工程&lt;/a&gt;是通过故意注入故障并分析系统响应来测试系统弹性的必要实践。该期刊探讨了在混乱工程实验中测量的关键参数，包括系统性能，可用性，容错性和用户体验指标。通过系统地监视这些参数，组织可以主动识别弱点，增强故障转移机制并优化恢复策略。该研究还提供了一个结构化的实验模板，以帮助团队有效地记录和分析混乱实验。最终目标是建立对系统承受动荡的操作条件并确保可靠服务交付的能力的信心。&lt;/p&gt;</description>
      <pubDate>Tue, 20 May 2025 15:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Building Reliable LLM-Powered Microservices With Kubernetes on AWS】在AWS上使用Kubernetes构建可靠的LLM供电微服务</title>
      <link>https://dzone.com/articles/reliable-llm-microservices-kubernetes-aws</link>
      <description>【&lt;p dir=&#34;ltr&#34;&gt;Software development environments have evolved due to large language models (LLMs), which offer advanced natural language processing capabilities that were previously unimaginable. To improve user experiences through conversational interfaces, content creation, data analysis, and other features, organizations are progressively integrating these models into their systems.&amp;nbsp;&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;However, implementing LLMs in production settings, especially as microservices, presents special difficulties that conventional application deployment techniques are not designed to handle.&lt;/p&gt;】&lt;p dir =“ ltr”&gt;由于大型语言模型（LLMS）而发展的软件开发环境，该环境提供了以前无法想象的高级自然语言处理功能。为了通过对话界面，内容创建，数据分析和其他功能来改善用户体验，组织正在逐步将这些模型集成到其系统中。 &lt;/p&gt;&#xA;&lt;p dir =“ ltr”&gt;但是，在生产环境中实施LLM，尤其是在微服务时，会遇到特殊困难，即常规的应用程序部署技术并非旨在处理。&lt;/p&gt;</description>
      <pubDate>Tue, 20 May 2025 18:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Manual Sharding in PostgreSQL: A Step-by-Step Implementation Guide】PostgreSQL中的手动分解：逐步实施指南</title>
      <link>https://dzone.com/articles/manual-sharding-postgresql-implementation-guide</link>
      <description>【&lt;p&gt;Learn how to implement manual sharding in native PostgreSQL using Foreign Data Wrappers. This tutorial walks through creating distributed tables without additional extensions like Citus.&lt;/p&gt;&#xA;&lt;h2&gt;The Challenge With Database Scaling&lt;/h2&gt;&#xA;&lt;p&gt;As applications grow, single-node databases face several challenges:&lt;/p&gt;】&lt;p&gt;学习如何使用外国数据包装器在本机PostgreSQL中实现手动碎片。本教程将浏览创建分布式桌子，而没有其他扩展名。&lt;/p&gt;&#xA;&lt;h2&gt;数据库缩放的挑战&lt;/h2&gt;&#xA;&lt;p&gt;随着应用程序的增长，单节点数据库面临几个挑战：&lt;/p&gt;</description>
      <pubDate>Tue, 20 May 2025 20:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Secrets Sprawl and AI: Why Your Non-Human Identities Need Attention Before You Deploy That LLM】Secrets蔓延和AI：为什么您的非人类身份在部署LLM之前需要注意</title>
      <link>https://dzone.com/articles/secrets-sprawl-ai-non-human-identities-llm-deployment</link>
      <description>【&lt;p&gt;It seems every company today is excited about AI. Whether they are rolling out GitHub Copilot to help teams write boilerplate code in seconds or creating internal chatbots to answer support tickets faster than ever, large language models (LLMs) have driven us into a new frontier of productivity very rapidly. Advancements like retrieval-augmented generation (RAG) have let teams plug LLMs into internal knowledge bases, making them context-aware and therefore much more helpful to the end user.&lt;/p&gt;&#xA;&lt;p&gt;However, if you haven’t gotten your secrets under control, especially those tied to your growing fleet of &lt;a href=&#34;https://dzone.com/articles/understanding-non-human-identities-governance&#34;&gt;non-human identities&lt;/a&gt; (NHIs), &lt;strong&gt;AI might speed up your security incident rate, not just your team&#39;s output&lt;/strong&gt;. Before you deploy a new LLM or connect Jira, Confluence, or your internal API docs to your internal chat-based agent, let’s talk about the real risk hiding in plain sight: secrets sprawl and the world of ungoverned non-human identities.&lt;/p&gt;】&lt;p&gt;似乎今天的每个公司都对AI感到兴奋。无论他们是推出GitHub Copilot以帮助团队在几秒钟内编写样板代码，还是创建内部聊天机器人以比以往任何时候都更快地回答支持门票，大型语言模型（LLMS）都将我们驱使我们进入了一个新的生产力领域。诸如检索型生成（RAG）之类的进步使团队将LLM插入了内部知识库，使其成为上下文感知，因此对最终用户更有帮助。&lt;/p&gt;&#xA;&lt;p&gt;但是，如果您没有得到控制的秘密，尤其是那些与您不断增长的&lt;a href =“ https://dzone.com/articles/understanding-non-human-isentities-governance”&gt; non-human Identities的&lt;a href =“ https://dzone.com/articles” &lt;/a&gt;（NHIS），&lt;强&gt; ai可能会加快您的安全率，不仅是您的安全率，&lt;/在您部署新的LLM或Connect Jira，Confluence或您的内部API文档与您的内部聊天代理商之前，让我们谈谈真正隐藏的真正风险：Secrets Sprawl and of the Spranss sprawl and of the of the of the novered norgreded nongraned nonverned nonthen ven。&lt;/p&gt;。&lt;/p&gt;</description>
      <pubDate>Tue, 20 May 2025 14:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Next Evolution in Integration: Architecting With Intent Using Model Context Protocol】集成的下一个演变：使用模型上下文协议意图进行架构</title>
      <link>https://dzone.com/articles/intent-driven-integration-with-mcp</link>
      <description>【&lt;p style=&#34;text-align: left;&#34;&gt;Integration has moved beyond system connectivity. In todays distributed digital first environments the focus has shifted from building statics connections to intelligent context aware interactions. The next phase of integration is to build the integration with intent using &lt;a href=&#34;https://dzone.com/articles/building-custom-tools-model-context-protocol&#34;&gt;Model Context Protocol (MCP)&lt;/a&gt; design pattern. In this article, I will explain how integration evolved over the period from traditional middleware to cloud native approach to a design centric approach that aligns integration with meaning and intent. We will examine the architecture of MCP and how it&#39;s going to play a pivotal role in driving next-generation integration strategies.&amp;nbsp;&lt;/p&gt;&#xA;&lt;h2 style=&#34;text-align: left;&#34;&gt;Integration in Middleware Era: Reliable, but Rigid&lt;/h2&gt;&#xA;&lt;p style=&#34;text-align: left;&#34;&gt;Early integration strategies relied on centralized middleware and formal contracts like SOAP and XML. Systems were prioritized for consistency and reliability. The rigid contract definition and static service definition made them slow to adapt and very expensive to evolve. Development were often done in tools which required deep expertise and managing this has become huge overhead for organizations.&amp;nbsp;&lt;/p&gt;】&lt;p style =“ text-align：left;”&gt;集成已经超越了系统连接性。在当今分布式数字第一环境中，重点已从构建静态连接转变为智能上下文意识交互。集成的下一个阶段是使用&lt;a href =“ https://dzone.com/articles/building-custom-tools-tools-model-context-protocol”&gt;模型上下文协议（MCP）&lt;/a&gt;设计模式。在本文中，我将解释整合如何在从传统中间件到云本机方法再到以设计为中心的方法的时期演变，该方法将集成与意义和意图保持一致。我们将研究MCP的架构以及它将如何在推动下一代整合策略中发挥关键作用。 &lt;/p&gt;&#xA;&lt;h2 style =“ text-align：left;”&gt;中间件时代的集成：可靠，但僵化&lt;/h2&gt;&#xA;&lt;p style =“ text-align：left;”&gt;早期集成策略依赖于集中式中间件和正式合同，例如SOAP和XML。将系统优先考虑一致性和可靠性。严格的合同定义和静态服务定义使它们适应缓慢，并且进化非常昂贵。开发通常是在需要深厚专业知识的工具中进行的，并且对组织进行管理已成为组织的巨大开销。 &lt;/p&gt;</description>
      <pubDate>Tue, 20 May 2025 19:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Tired of Spring Overhead? Try Dropwizard for Your Next Java Microservice】厌倦了春天的头顶？尝试下一个Java微服务的Dropwizard</title>
      <link>https://dzone.com/articles/dropwizard-for-java-microservices</link>
      <description>【&lt;p dir=&#34;ltr&#34;&gt;Instead of a monolith, build your first Java microservice with Dropwizard.&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;Hello, my fellow programmers! I’m positive you do not want to read another complex article on how to build Java microservices. We are going to take a look at Dropwizard today. It is fairly convenient as it has everything loaded in it, i.e., Jetty, Jersey, Jackson, etc., and also provides you with the ability to set your business logic without the boilerplates.&lt;/p&gt;】&lt;p dir =“ ltr”&gt;而不是整体，用dropwizard构建第一个Java微服务。&lt;/p&gt;&#xA;&lt;p dir =“ ltr”&gt;您好，我的程序员！我很肯定，您不想阅读有关如何构建Java微服务的另一篇复杂文章。我们今天要看看Dropwizard。它非常方便，因为它装有所有内容，即码头，泽西岛，杰克逊等，还为您提供了在没有锅炉的情况下设置业务逻辑的能力。&lt;/p&gt;</description>
      <pubDate>Tue, 20 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Kullback–Leibler Divergence: Theory, Applications, and Implications】Kullback -Leibler Divergence：理论，应用和含义</title>
      <link>https://dzone.com/articles/kullbackleibler-divergence-theory-applications-implications</link>
      <description>【&lt;p&gt;Kullback–Leibler divergence (KL divergence), also known as relative entropy, is a fundamental concept in statistics and information theory. It measures how one probability distribution diverges from a second, reference probability distribution. This article delves into the mathematical foundations of KL divergence, its interpretation, properties, applications across various fields, and practical considerations for its implementation.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;1. Introduction&lt;/strong&gt;&lt;/p&gt;】&lt;p&gt; kullback -leibler差异（KL Divergence），也称为相对熵，是统计和信息理论中的一个基本概念。它衡量一个概率分布与第二个参考概率分布的分歧。本文深入研究了KL Divergence的数学基础，其解释，属性，各个领域的应用以及其实施的实际考虑。&lt;/p&gt;&#xA;&lt;p&gt; &lt;strong&gt; 1。简介&lt;/strong&gt; &lt;/p&gt;</description>
      <pubDate>Tue, 20 May 2025 20:06:44 +0000</pubDate>
    </item>
    <item>
      <title>【Orchestrating Microservices with Dapr: A Unified Approach】使用DAPR编排微服务：统一方法</title>
      <link>https://dzone.com/articles/orchestrating-microservices-with-dapr</link>
      <description>【&lt;h2 data-pm-slice=&#34;1 1 []&#34;&gt;&lt;strong&gt;Introduction&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;p data-pm-slice=&#34;1 1 []&#34;&gt;Modern software architectures are increasingly embracing microservices to improve scalability, flexibility, and resilience. However, as the number of systems expands, managing inter-service communication, data persistence, event-driven messaging, and security becomes more complex. Additionally, as a product scales, organizations often inadvertently develop strong dependencies on specific database providers, messaging middleware, or cloud vendors. This tight coupling makes future changes challenging, often requiring extensive refactoring.&lt;/p&gt;&#xA;&lt;p data-end=&#34;1050&#34; data-start=&#34;791&#34;&gt;&lt;a href=&#34;https://dapr.io/&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt;&lt;strong data-end=&#34;833&#34; data-start=&#34;791&#34;&gt;Dapr&lt;/strong&gt;&lt;/a&gt;&lt;strong data-end=&#34;833&#34; data-start=&#34;791&#34;&gt;&amp;nbsp;(Distributed Application Runtime)&lt;/strong&gt; offers a unified abstraction for handling these concerns, allowing microservices to interact with databases, message queues, APIs, and secrets stores in a cloud-agnostic and infrastructure-independent manner.&lt;/p&gt;】&lt;H2 data-pm-slice =“ 1 1 []”&gt; &lt;strong&gt;简介&lt;/strong&gt; &lt;/h2&gt;&#xA;&lt;p data-pm-slice =“ 1 1 []&gt;现代软件体系结构越来越多地采用微服务，以提高可扩展性，灵活性和弹性。但是，随着系统数量的扩展，管理服务间通信，数据持久性，事件驱动的消息传递和安全性变得更加复杂。此外，随着产品量表，组织通常会无意间对特定数据库提供商，消息中间件或云供应商产生强大的依赖性。这种紧密的耦合使未来的变化具有挑战性，通常需要大量重构。&lt;/p&gt;&#xA;&lt;p data-end =“ 1050” data-start =“ 791”&gt; &lt;a href =“ https://dapr.io/” rel =“ noopener noreferrer” target =“ _ black”&gt; &lt;strong data-end-end =“ 833” data-data-start =“ data-start =” 791“ 791”&gt; dapr&gt; dapr&gt; dapr&gt; dapr&gt; dapr&gt;应用程序运行时）&lt;/strong&gt;提供了一个统一的抽象来处理这些问题，允许微服务与数据库，消息队列，API和Secrets以云语言和基础结构独立的方式进行交互。&lt;/p&gt;。&lt;/p&gt;</description>
      <pubDate>Tue, 20 May 2025 22:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Building an AI/ML Data Lake With Apache Iceberg】用Apache冰山建造AI/ML数据湖</title>
      <link>https://dzone.com/articles/building-an-aiml-data-lake-with-apache-iceberg</link>
      <description>【&lt;p&gt;As companies collect massive amounts of data to fuel their artificial intelligence and machine learning initiatives, finding the right data architecture for storing, managing, and accessing such data is crucial. Traditional data storage practices are likely to fall short to meet the scale, variety, and velocity required by modern AI/ML workflows. Apache Iceberg steps in as a strong open-source table format to build solid and efficient data lakes for AI and ML.&lt;/p&gt;&#xA;&lt;h2 dir=&#34;ltr&#34;&gt;What Is Apache Iceberg?&lt;/h2&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;&lt;a href=&#34;https://dzone.com/articles/unlocking-the-potential-of-apache-iceberg&#34;&gt;Apache Iceberg&lt;/a&gt; is an open table format for big analytical datasets, initially built at Netflix. It solves many of the limitations of data lakes, especially when handling the needs of AI/ML workloads. Iceberg offers a table layer over file systems or object stores, introducing database-like functionality into data lakes. The most important aspects that make Iceberg valuable for Artificial Intelligence and machine learning workloads are:&lt;/p&gt;】&lt;p&gt;随着公司收集大量数据以促进其人工智能和机器学习计划，找到用于存储，管理和访问此类数据的正确数据架构至关重要。传统的数据存储实践可能会降低，以满足现代AI/ML工作流所需的规模，多样性和速度。 Apache Iceberg作为强大的开源表格式，为AI和ML构建固​​体和高效的数据湖。&lt;/p&gt;&#xA;&lt;h2 dir =“ ltr”&gt;什么是apache冰山？&lt;/h2&gt;&#xA;&lt;p dir =“ ltr”&gt; &lt;a href =“ https://dzone.com/articles/unlocking-the-potential-of-apache-iceberg-”&gt; apache Iceberg &lt;/a&gt;是最初在Netflix建立的大分析数据集的开放式餐桌格式。它解决了许多数据湖泊的局限性，尤其是在处理AI/ML工作负载的需求时。冰山在文件系统或对象存储上提供了一个表层，将类似数据库的功能引入数据湖泊。使冰山对人工智能和机器学习工作有价值的最重要方面是：&lt;/p&gt;</description>
      <pubDate>Tue, 20 May 2025 17:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Next-Gen IoT Performance Depends on Advanced Power Management ICs】下一代物联网绩效取决于高级电源管理IC</title>
      <link>https://dzone.com/articles/next-gen-iot-power-management-ics</link>
      <description>【&lt;p dir=&#34;ltr&#34;&gt;The rise of Internet of Things (IoT) applications is a key integrated circuit (IC) market driver. As these internet-connected technologies become increasingly smaller, complex, and energy-intensive, advanced power management ICs are exponentially important. Factoring in potential energy reliability issues due to heightened demand emphasizes this situation’s urgency.&amp;nbsp;&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;Thanks to its convenience and affordability, &lt;a href=&#34;https://dzone.com/articles/the-internet-of-things-development-and-examples&#34;&gt;the IoT&lt;/a&gt; is quickly becoming a staple in industrial, medical, and technology spaces. Since demand is so high, research and development are flourishing. However, progress may soon stall unless professionals leverage advanced power management integrated circuit (PMIC) design to handle variable input and regulate voltage.&lt;/p&gt;】&lt;p dir =“ ltr”&gt;物联网应用程序（IoT）应用程序的兴起是关键集成电路（IC）市场驱动程序。随着这些与互联网连接的技术变得越来越小，复杂且能源密集型，高级电力管理IC非常重要。考虑到需求增强引起的势能可靠性问题，强调了这种情况的紧迫性。 &lt;/p&gt;&#xA;&lt;p dir =“ ltr”&gt;多亏了它的便利性和可负担性，&lt;a href =“ https://dzone.com/articles/the-internet-of-things-development-and-examples”&gt; iot &lt;/a&gt; &lt;/a&gt; &lt;/a&gt;正在迅速成为工业，医疗和技术空间的主食。由于需求太高，因此研发蓬勃发展。但是，除非专业人员利用高级电源集成电路（PMIC）设计来处理可变输入并调节电压，否则进展可能很快就会失速。&lt;/p&gt;。&lt;/p&gt;</description>
      <pubDate>Tue, 20 May 2025 21:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>