<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>DZone.com Feed</title>
    <link>https://feeds.dzone.com/home</link>
    <description>Recent posts on DZone.com</description>
    <item>
      <title>【Dive Into Tokenization, Attention, and Key-Value Caching】潜入令牌化，注意力和键值缓存</title>
      <link>https://dzone.com/articles/dive-into-tokenization-attention-key-value-caching</link>
      <description>【&lt;h2 data-selectable-paragraph=&#34;&#34; style=&#34;text-align: left;&#34;&gt;&lt;strong&gt;The Rise of LLMs and the Need for Efficiency&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;p style=&#34;text-align: left;&#34;&gt;In recent years, large language models (LLMs) such as GPT, Llama, and Mistral have impacted natural language understanding and generation. However, a significant challenge in deploying these models lies in optimizing their performance, particularly for tasks involving long text generation. One powerful technique to address this challenge is &lt;strong&gt;k&lt;/strong&gt;&lt;strong&gt;ey-value caching (KV cache)&lt;/strong&gt;.&amp;nbsp;&lt;/p&gt;&#xA;&lt;p style=&#34;text-align: left;&#34;&gt;In this article, we will delve into how KV caching works, its role within the attention mechanism, and how it enhances efficiency in LLMs.&lt;/p&gt;】&lt;H2数据选择 - 段落=“” style =“ text-align：left;”&gt; &lt;strong&gt; llms的兴起和效率的需求&lt;/strong&gt; &lt;/h2&gt;&#xA;&lt;p style =“ text-align：left;”&gt;近年来，大型语言模型（LLMS），例如GPT，Llama和Mistral都影响了自然语言的理解和产生。但是，部署这些模型的重大挑战在于优化其性能，尤其是对于涉及长文本生成的任务。应对这一挑战的一种强大技术是&lt;strong&gt; k &lt;/strong&gt; &lt;strong&gt; ey-ey-value缓存（KV缓存）&lt;/strong&gt;。 &lt;/p&gt;&#xA;&lt;p style =“ text-align：left;”&gt;在本文中，我们将深入研究KV缓存的工作原理，其在注意机制中的作用以及它如何提高LLMS的效率。&lt;/p&gt;</description>
      <pubDate>Tue, 18 Feb 2025 20:30:00 +0000</pubDate>
    </item>
    <item>
      <title>【Container Checkpointing in Kubernetes With a Custom API】具有自定义API的Kubernetes中的容器检查点</title>
      <link>https://dzone.com/articles/container-checkpointing-kubernetes-api</link>
      <description>【&lt;h2&gt;Problem Statement&lt;/h2&gt;&#xA;&lt;h3&gt;Challenge&lt;/h3&gt;&#xA;&lt;p&gt;Organizations running containerized applications in Kubernetes often need to capture and preserve the state of running containers for:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA; &lt;li&gt;Disaster recovery&lt;/li&gt;&#xA; &lt;li&gt;Application migration&lt;/li&gt;&#xA; &lt;li&gt;Debug/troubleshooting&lt;/li&gt;&#xA; &lt;li&gt;State preservation&lt;/li&gt;&#xA; &lt;li&gt;Environment reproduction&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;However, there&#39;s no straightforward, automated way to:&lt;/p&gt;】&lt;h2&gt;问题语句&lt;/h2&gt;&#xA;&lt;H3&gt;挑战&lt;/h3&gt;&#xA;&lt;p&gt;在Kubernetes中运行容器的应用程序的组织通常需要捕获和保留运行容器的状态：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA; &lt;li&gt;灾难恢复&lt;/li&gt;&#xA; &lt;li&gt;应用程序迁移&lt;/li&gt;&#xA; &lt;li&gt;调试/故障排除&lt;/li&gt;&#xA; &lt;li&gt;国家保存&lt;/li&gt;&#xA; &lt;li&gt;环境繁殖&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;但是，没有直接的自动化方法来：&lt;/p&gt;</description>
      <pubDate>Tue, 18 Feb 2025 17:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Multimodal RAG With Colpali, Milvus, and VLMs】与Colpali，Milvus和VLMS的多模式抹布</title>
      <link>https://dzone.com/articles/multimodal-rag-with-colpali-milvus-and-vlms</link>
      <description>【&lt;p&gt;&lt;span style=&#34;margin: 0px; padding: 0px;&#34;&gt;In this post, we will see how to do multimodal RAG with &lt;a href=&#34;https://arxiv.org/abs/2407.01449&#34; target=&#34;_blank&#34;&gt;ColPali&lt;/a&gt;, &lt;a href=&#34;https://milvus.io/&#34; target=&#34;_blank&#34;&gt;Milvus,&lt;/a&gt; and a visual language model (Gemini/GPT-4o).&lt;/span&gt;&lt;/p&gt;&#xA;&lt;p&gt;We will build an application to upload a PDF and then do Q&amp;amp;A queries on it. Q&amp;amp;A can be done on both text and visual elements of the PDF. We will not extract text from the PDF; instead, we will treat it as an image and use ColPali to get embeddings for the PDF pages. These embeddings will be indexed to Milvus, and then we will use a VLM to do Q&amp;amp;A queries on the PDF pages.&lt;/p&gt;】&lt;p&gt; &lt;span style =“ margin：0px; padding：0px;“&gt;在这篇文章中，我们将看到如何使用&lt;a href =” https://arxiv.org/abs/2407.01449“ https：// href =” target = “ _blank”&gt; colpali &lt;/a&gt;，&lt;a href =“ https://milvus.io/” target =“ _ blank”&gt; milvus，&lt;/a&gt;和视觉语言模型（gemini/gpt-4o）。&lt;/span&gt; &lt;/p&gt;&#xA;&lt;p&gt;我们将构建一个应用程序来上传PDF，然后对其进行问答查询。可以在PDF的文本和视觉元素上完成问答。我们不会从PDF中提取文本；取而代之的是，我们将其视为图像，并使用Colpali获取PDF页面的嵌入。这些嵌入将被索引到米尔弗斯，然后我们将使用VLM在PDF页面上进行问答查询。&lt;/p&gt;</description>
      <pubDate>Tue, 18 Feb 2025 14:00:08 +0000</pubDate>
    </item>
    <item>
      <title>【Generate Unit Tests With AI Using Ollama and Spring Boot】使用Ollama和Spring Boot使用AI生成单元测试</title>
      <link>https://dzone.com/articles/generate-unit-tests-ai-ollama-spring-boot</link>
      <description>【&lt;p&gt;There are scenarios where we would not want to use commercial large language models (LLMs) because the queries and data would go into the public domain. There are ways to run open-source LLMs locally. This article explores the option of running Ollama locally interfaced with the Sprint boot application using the SpringAI package.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;We will create an API endpoint that will generate unit test cases for the &lt;a href=&#34;https://dzone.com/articles/title-exploring-exciting-new-features-in-java-17-w&#34;&gt;Java&lt;/a&gt; code that has been passed as part of the prompt using AI with the help of &lt;a href=&#34;https://dzone.com/articles/enhance-your-workflow-with-ollama-langchain-and-rag&#34;&gt;Ollama LLM&lt;/a&gt;. &amp;nbsp;&lt;/p&gt;】&lt;p&gt;在某些情况下，我们不想使用商业大型语言模型（LLMS），因为查询和数据将进入公共领域。有多种方法可以在本地运行开源LLMS。本文探讨了使用Springai软件包与Sprint Boot应用程序进行本地连接的Ollama的选项。&lt;/p&gt;&#xA;&lt;p&gt;我们将创建一个API端点，该端点将生成&lt;a href =“ https://dzone.com/articles/title-exploring-exciting-exciting-new-features-new-features-in-java-17-w”“ &gt; java &lt;/a&gt;在&lt;a的帮助下，使用AI作为提示的一部分已通过href =“ https://dzone.com/articles/enhance-your-workflow-with-olama-langchain-and-and-rag”&gt; ollama llm &lt;/a&gt;。  &lt;/p&gt;</description>
      <pubDate>Tue, 18 Feb 2025 15:15:00 +0000</pubDate>
    </item>
    <item>
      <title>【The Delegated Chain of Thought Architecture】委派的思想架构链</title>
      <link>https://dzone.com/articles/delegated-chain-of-thought-architecture-decoupling</link>
      <description>【&lt;p dir=&#34;ltr&#34;&gt;This article introduces the Delegated Chain of Thought (D-CoT) Architecture, a novel framework for large language models (LLMs) that decouples reasoning from execution.The architecture centralises reasoning in a &#34;modulith&#34; model while delegating execution tasks to smaller, specialised models.&amp;nbsp;&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;We are collaborating with AI engineers to create tools that software engineers can easily use. Merging these two disciplines is essential to mastering tools and integrating them into our information system effectively. This approach draws heavily on software architecture analogies and focuses on integrating advanced LLM techniques, such as Chain-of-Thought (CoT) prompting, ReAct, Toolformer, and modular AI design principles.&amp;nbsp;&lt;/p&gt;】&lt;p dir =“ ltr”&gt;本文介绍了委派的思想链（D-COT）体系结构，这是一个大语模型（LLMS）的新型框架，将推理从执行中解除推理。架构中心在“模量”模型中推理了“模型”模型。将执行任务委派给较小的专业模型。 &lt;/p&gt;&#xA;&lt;p dir =“ ltr”&gt;我们正在与AI工程师合作，以创建软件工程师可以轻松使用的工具。合并这两个学科对于掌握工具并有效地将其集成到我们的信息系统中至关重要。这种方法在很大程度上借鉴了软件体系结构类比，并专注于集成高级LLM技术，例如Thebough（COT）提示，React，Toolformer和Modular AI设计原理。 &lt;/p&gt;</description>
      <pubDate>Tue, 18 Feb 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Data Privacy and Governance in Real-Time Data Streaming】实时数据流中的数据隐私和治理</title>
      <link>https://dzone.com/articles/data-privacy-governance-real-time-data-streaming</link>
      <description>【&lt;p&gt;Real-time data streaming is changing the way organizations handle information. Whether it’s IoT devices sending sensor updates, retail platforms tracking customer activity, or financial institutions monitoring transactions for fraud, processing data “as it happens” gives you a major edge. When done well, real-time data streaming fuels faster decision-making, more personalized services, and even proactive threat detection.&lt;/p&gt;&#xA;&lt;p&gt;Despite these advantages, &lt;a href=&#34;https://gdpr.eu&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt;privacy and governance&lt;/a&gt; often don’t get the attention they deserve. Many streaming analytics initiatives focus heavily on throughput and latency — valid concerns — but that can mean overlooking critical items like encryption, access controls, and &lt;a href=&#34;https://dzone.com/articles/the-developers-guide-to-saas-compliance&#34;&gt;compliance requirements&lt;/a&gt;. This article looks at the main pitfalls of handling streaming data in a regulated environment, followed by proven strategies for building and maintaining secure, compliant pipelines.&lt;/p&gt;】&lt;p&gt;实时数据流正在改变组织处理信息的方式。无论是IoT设备发送传感器更新，跟踪客户活动的零售平台，还是为欺诈行为监控交易的金融机构，处理“碰巧”的数据可为您带来重要优势。做得好时，实时数据流动为更快的决策，更多个性化的服务甚至主动威胁检测。&lt;/p&gt;&#xA;&lt;p&gt;尽管有这些优势，&lt;a href =“ https://gdpr.eu” rel =“ noopener noreferrer” target =“ _ blank”&gt;隐私和治理&lt;/a&gt;常常没有引起他们应有的关注。许多流媒体分析计划主要关注吞吐量和延迟（有效的问题），但这可能意味着忽略关键项目，例如加密，访问控制和&lt;a href =“ https://dzone.com/articles/articles/the-developers-guide--guide-to- - 合规性要求&lt;/a&gt;。本文着眼于在受规定的环境中处理流数据的主要陷阱，然后是构建和维护安全，兼容管道的策略。&lt;/p&gt;</description>
      <pubDate>Tue, 18 Feb 2025 21:30:00 +0000</pubDate>
    </item>
    <item>
      <title>【A Step-by-Step Guide to Enterprise Application Development】企业应用程序开发的分步指南</title>
      <link>https://dzone.com/articles/a-step-by-step-guide-to-enterprise-application-dev</link>
      <description>【&lt;p&gt;Having spent more late nights untangling enterprise spaghetti code than I care to admit, I can confidently say developing enterprise applications is not for the faint of heart.&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;While hobby apps crash because someone forgot a semicolon, enterprise code glitches could mean accidentally buying every employee a yacht. We’re talking about software that keeps multinational supply chains from imploding because someone in accounting fat-fingered a CSV export.&lt;/p&gt;】&lt;p&gt;我花了更多的时间来解开企业意大利面条代码，我可以自信地说开发企业应用程序并不适合胆小的人。&lt;/p&gt;&#xA;&lt;p dir =“ ltr”&gt; hobby应用程序崩溃时，因为有人忘记了半隆，企业代码故障可能意味着不小心将每位员工购买游艇。我们正在谈论的软件可以防止跨国供应链崩溃，因为有人在会计脂肪指示CSV出口。&lt;/p&gt;</description>
      <pubDate>Tue, 18 Feb 2025 13:00:04 +0000</pubDate>
    </item>
    <item>
      <title>【Building Intelligent Microservices With Go and AWS AI Services】使用GO和AWS AI服务构建智能微服务</title>
      <link>https://dzone.com/articles/building-intelligent-microservices-with-go-and-aws</link>
      <description>【&lt;p&gt;Coupling Go&#39;s lightweight programming capabilities with AWS&#39; robust AI services allows developers to build performant, scalable, and intelligent microservices devoted to diverse business needs. This blog explains how Go, and AWS AI services can be combined to create intelligent microservices, discusses the benefits of this approach, and provides a step-by-step guide to getting started.&lt;/p&gt;&#xA;&lt;h2&gt;&lt;strong&gt;Why Use Go for Microservices?&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://dzone.com/articles/golang-tutorial-learn-golang-by-examples&#34;&gt;Golang, or Go&lt;/a&gt;, is a statically typed, compiled programming language that speaks Google. It aims to meet some requirements regarding simplicity, performance, and scalability. Combined, they make it an excellent choice for building microservices:&lt;/p&gt;】&lt;p&gt;耦合GO的轻量级编程功能与AWS的强大AI服务使开发人员可以构建专门针对各种业务需求的性能，可扩展和智能的微服务。该博客解释了可以合并AWS AI服务以创建智能微服务，讨论这种方法的好处，并为入门提供了逐步指南。&lt;/p&gt;，&#xA;&lt;H2&gt; &lt;strong&gt;为什么要使用微服务？&lt;/strong&gt; &lt;/h2&gt;&#xA;&lt;p&gt; &lt;a href =“ https://dzone.com/articles/golang-tutorial-learn-golang-by-examples”&gt; golang&gt; golang，或go &lt;/a&gt;，是一种静态打字的编译，可说的语言谷歌。它旨在满足有关简单性，性能和可扩展性的一些要求。结合在一起，它们成为构建微服务的绝佳选择：&lt;/p&gt;</description>
      <pubDate>Tue, 18 Feb 2025 22:30:00 +0000</pubDate>
    </item>
    <item>
      <title>【Creating an Agentic RAG for Text-to-SQL Applications】为文本到SQL应用程序创建代理抹布</title>
      <link>https://dzone.com/articles/creating-an-agentic-rag-for-text-to-sql-applications</link>
      <description>【&lt;p&gt;The blend of retrieval-augmented generation (RAG) and generative AI models has brought changes to natural language processing by improving the responses to queries. In the realm of Agentic RAG, this conventional method of relying on a monolithic model for tasks has been enhanced by introducing modularity and autonomy. By breaking down the problem-solving process into tools integrated within an agent, Agentic RAG provides benefits like accuracy, transparency, scalability, and debugging capabilities.&lt;/p&gt;&#xA;&lt;h2&gt;The Vision Behind Agentic RAG for Text-to-SQL&lt;/h2&gt;&#xA;&lt;p&gt;Traditional RAG systems often retrieve relevant documents and rely on a single monolithic model to generate responses. Although this is an effective method in some cases, when it comes to structural outputs like the case of generating SQL, this approach may not be the most effective. This is where we can leverage the power of the Agentic RAG framework, where we:&lt;/p&gt;】&lt;p&gt;通过改进对查询的响应，通过检索效果生成（RAG）和生成AI模型的混合物带来了自然语言处理的变化。在代理抹布的领域中，通过引入模块化和自主权来增强这种依赖整体模型的常规方法。通过将解决问题的过程分解为代理中集成的工具，代理抹布提供了准确性，透明度，可扩展性和调试功能等好处。&lt;/p&gt;&#xA;&lt;h2&gt;文本到sql &lt;/h2&gt;的代理抹布背后的愿景&lt;/h2&gt;&#xA;&lt;p&gt;传统的抹布系统通常会检索相关文档，并依靠单个单片模型来产生响应。尽管在某些情况下，这是一种有效的方法，但是在结构输出（例如生成SQL的情况）时，这种方法可能不是最有效的。这是我们可以利用代理抹布框架的力量的地方，我们：&lt;/p&gt;</description>
      <pubDate>Tue, 18 Feb 2025 19:30:00 +0000</pubDate>
    </item>
    <item>
      <title>【Implement Amazon S3 Cross-Region Replication With Terraform】用Terraform实施Amazon S3跨区域复制</title>
      <link>https://dzone.com/articles/amazon-s3-cross-region-replication-terraform</link>
      <description>【&lt;p data-pm-slice=&#34;1 1 []&#34;&gt;With the information technology element finding its roots in every financial organization and across all industries, strong storage capacity forms the backbone for availability, durability, and scalability. Among these, Amazon S3 is one of the most popular services to meet these needs. As enterprises expand geographically, the need for data replication between locations starts to be felt significantly. Hence, the need arose to develop Cross-Region Replication in Amazon S3, where data replication between one bucket sourced from one AWS region to another bucket in a different AWS region is allowed.&lt;/p&gt;&#xA;&lt;p&gt;The article will describe how to configure Cross-Region Replication in Amazon S3 using &lt;a href=&#34;https://dzone.com/articles/terraform-explained-in-5-minutes&#34;&gt;Terraform, an IaC software&lt;/a&gt;. It gives a general overview of how to set up SLAs, discusses why one would implement cross-region replication, and shows how to get a proof of concept running.&lt;/p&gt;】&lt;p data-pm-slice =“ 1 1 []&gt;随着信息技术要素在每个金融组织和所有行业中找到根源，强大的存储容量构成了可用性，耐用性和可伸缩性的骨干。其中，亚马逊S3是满足这些需求的最受欢迎的服务之一。随着企业在地理位置上的扩展，对位置之间的数据复制的需求开始显着感受到。因此，在亚马逊S3中出现了开发跨区域复制的需求，其中允许一个从一个AWS区域到另一个AWS区域中的一个存储桶之间的数据复制。&lt;/p&gt;。&lt;/p&gt;&#xA;&lt;p&gt;本文将使用&lt;a href =“ https://dzone.com/articles/terraform-explaining-in-5-minutes”&gt; terraform &lt;p &lt; /a&gt;。它提供了有关如何设置SLA的一般概述，讨论了为什么人们会实现跨区域复制，并展示了如何获得概念证明。&lt;/p&gt;</description>
      <pubDate>Tue, 18 Feb 2025 18:15:00 +0000</pubDate>
    </item>
  </channel>
</rss>