<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>DZone.com Feed</title>
    <link>https://feeds.dzone.com/home</link>
    <description>Recent posts on DZone.com</description>
    <item>
      <title>【Federated Learning: Training Models Without Sharing Raw Data】联合学习：培训模型而无需共享原始数据</title>
      <link>https://dzone.com/articles/federated-learning-training-models-without-sharing</link>
      <description>【&lt;p dir=&#34;ltr&#34;&gt;As machine learning programs require ever-larger sets of data to train and improve, traditional central training routines creak under the burden of privacy requirements, inefficiencies in operations, and growing consumer skepticism. Liability information, such as medical records or payment history, can&#39;t easily be collected together in a place due to ethical and legal restrictions.&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;&lt;a href=&#34;https://dzone.com/articles/federated-learning-collaborative-machine-learning&#34;&gt;Federated learning&lt;/a&gt; (FL) has a different answer. Rather than forwarding data to a model, it forwards the model to the data. Institutions and devices locally train models on their own data and forward only learned updates, not data.&lt;/p&gt;】&lt;p dir =“ ltr”&gt;由于机器学习计划需要越来越多的数据集来训练和改进传统的中央培训常规训练，这是在隐私要求的负担，运营效率低下以及消费者的持怀疑态度下的责任。责任信息，例如医疗记录或付款历史记录，由于道德和法律限制，不能轻易地一起在一个地方一起收集。&lt;/p&gt;&#xA;&lt;p dir =“ ltr”&gt; &lt;a href =“ https://dzone.com/articles/federated-learning-collaborative-machine-learning”&gt;联合学习&lt;/a&gt;（fl）有不同的答案。它没有将数据转发到模型，而是将模型转发到数据。机构和设备在自己的数据上本地训练模型，而仅向前学习的更新，而不是数据。&lt;/p&gt;</description>
      <pubDate>Fri, 26 Sep 2025 19:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Networking’s Open Source Era Is Just Getting Started】Networking的开源时代才刚刚开始</title>
      <link>https://dzone.com/articles/open-source-networking-era</link>
      <description>【&lt;p dir=&#34;ltr&#34;&gt;For most of its history, networking has been a standards-first, protocol-governed domain. From the OSI model to the TCP/IP stack, progress was measured in working groups and RFCs, not GitHub commits. But that is changing fast. Projects like eBPF and Cilium, along with the architectural demands of Kubernetes, are moving networking from a specification-bound world into a software-driven, open source ecosystem. What happened to servers, developer tooling, and CI/CD pipelines is now happening to the network layer.&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;The open source future has arrived, and it is finally catching up to the packet path.&lt;/p&gt;】&lt;p dir =“ ltr”&gt;在其大多数历史中，网络一直是标准优先，协议管理的域。从OSI模型到TCP/IP堆栈，在工作组和RFC（而不是GitHub提交）中测量了进度。但这正在快速变化。 EBPF和Cilium等项目，以及Kubernetes的建筑需求，正在将网络从规范结合的世界转移到软件驱动的开源生态系统。服务器，开发人员工具和CI/CD管道发生了什么事。&lt;/p&gt;现在正在发生。&lt;/p&gt;&#xA;&lt;p dir =“ ltr”&gt;开源未来已经到来，终于赶上了数据包路径。&lt;/p&gt;</description>
      <pubDate>Fri, 26 Sep 2025 18:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【LLM-First Vibe Coding】LLM优先的Vibe编码</title>
      <link>https://dzone.com/articles/llm-first-vibe-coding</link>
      <description>【&lt;p dir=&#34;ltr&#34;&gt;For many years now, software engineers have used the Integrated Development Environment (IDE) as their main place to write and debug code. Your IDE should become a partner that helps you by predicting what you need to do, correcting mistakes automatically, and making complex code from simple prompts. &#34;Vibe coding&#34; is changing the field of software engineering rapidly. Its main idea is LLM-first development.&lt;br&gt;&lt;br&gt;&#xA; Andrej Karpathy, who was Tesla&#39;s AI Director at the time, came up with the idea of vibe coding. He came up with this way of working that lets developers participate in LLM code generation [1]. The developer now needs designers to act as high-level architects who use natural language prompts to guide AI systems while they work on developing the vision for the product. Karpathy says that he builds projects and web apps by looking at them visually, giving them verbal commands, running the system, and copying code, which all lead to functional results [1].&lt;br&gt;&lt;br&gt;&#xA; &amp;nbsp;With the traditional IDE-first development method, developers have to write every line of code. With vibe coding, on the other hand, this is not the case. Vibe coding changes software development at its core because it lets developers use AI tools to make a development environment that is completely interactive. The article shows that this trend is more than just a passing fad because it changes how software is made and kept up-to-date.&lt;/p&gt;&#xA;&lt;h2 dir=&#34;ltr&#34;&gt;Why LLM-First Development?&lt;/h2&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;The quick rise of LLM-first development is due to big productivity gains for developers and a complete change in the cognitive requirements of software engineering. The best thing about vibe coding is that it makes development work easier, so engineers can focus on more creative and strategic tasks.&amp;nbsp;&lt;/p&gt;】&lt;p dir =“ ltr”&gt;多年来，软件工程师将集成开发环境（IDE）用作编写和调试代码的主要场所。您的IDE应该成为一个合作伙伴，通过预测您需要做的事情，自动纠正错误并通过简单提示制作复杂的代码来帮助您。 “ Vibe编码”正在迅速改变软件工程领域。它的主要思想是LLM优先开发。&lt;br&gt; &lt;br&gt;&#xA; 当时是特斯拉AI主任的Andrej Karpathy提出了Vibe编码的想法。他想出了这种工作方式，使开发人员可以参与LLM代码生成[1]。现在，开发人员需要设计师充当使用自然语言提示的高级建筑师，以指导AI系统，同时他们致力于开发产品的愿景。 KarPathy说，他通过视觉查看它们来构建项目和Web应用程序，赋予他们口头命令，运行系统并复制代码，这都导致功能结果[1]。&lt;br&gt; &lt;br&gt; &lt;br&gt;&#xA;  使用传统的IDE优先开发方法，开发人员必须编写每一行代码。另一方面，使用Vibe编码，情况并非如此。 Vibe编码更改其核心软件开发，因为它使开发人员可以使用AI工具来制作完全互动的开发环境。文章表明，这种趋势不仅仅是传递的时尚，因为它改变了制造软件的制作方式和最新方式。&lt;/p&gt;&#xA;&lt;h2 dir =“ ltr”&gt;为什么要llm-first开发？&lt;/h2&gt;&#xA;&lt;p dir =“ ltr”&gt; LLM优先开发的快速崛起是由于开发人员的生产率较大，并且软件工程认知要求的完全改变。关于Vibe编码的最好的事情是，它使开发工作更加容易，因此工程师可以专注于更具创意和战略性的任务。 &lt;/p&gt;</description>
      <pubDate>Fri, 26 Sep 2025 17:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Why One-Week Sprints Make Vibe Coding Work Better】为什么一周的冲刺使氛围编码更好</title>
      <link>https://dzone.com/articles/one-week-sprints-vibe-coding</link>
      <description>【&lt;p&gt;One-week sprint cycles in Scrum can significantly improve project outcomes through vibe coding approaches. Research shows that Agile techniques increase the success rate of projects by 21% compared to traditional methods (Ogirri &amp;amp; Idugie, 2024). Developers using AI assistance produce 26% more and finish 55% faster. Vibe coding maximizes the developer&#39;s flow state and focused attention, which works well with shorter cycle iterations.&lt;/p&gt;&#xA;&lt;p&gt;Teams that use one-week sprints can leverage knowing how to deliver working functionality more often. It aligns with Agile&#39;s purpose of delivering continuous value to stakeholders. Moreover, shorter sprints lower prompt drift and allow quicker verification of features developed by AI. Product managers and entrepreneurs who utilize Lean practices may see their &#39;build, measure, learn&#39; loop accelerated by incorporating vibe coding into Agile development. Cross-functional teams use this potent combination to develop functional prototypes, as detailed coding experience or significant investment is no longer required.&lt;/p&gt;】&lt;p&gt; Scrum中的一周冲刺循环可以通过振动编码方法显着改善项目结果。研究表明，与传统方法相比，敏捷技术将项目的成功率提高了21％（Ogirri＆Idugie，2024）。使用AI援助的开发人员会增加26％，并快速完成55％。 VIBE编码最大化开发人员的流量状态并集中注意力，这与较短的循环迭代效果很好。&lt;/p&gt;&#xA;&lt;p&gt;使用一周冲刺的团队可以利用知道如何更频繁地交付工作功能的团队。它符合敏捷的目的，即为利益相关者提供持续价值。此外，较短的冲刺较低的及时漂移，并更快地验证AI开发的功能。利用精益实践的产品经理和企业家可能会看到他们的“构建，测量，学习”循环通过将氛围编码纳入敏捷开发中，从而加速了循环。跨职能团队使用这种有效的组合来开发功能原型，因为不再需要详细的编码经验或大量投资。&lt;/p&gt;</description>
      <pubDate>Fri, 26 Sep 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Complex Data Tasks Are Now One-Liners With AI in Databricks SQL】复杂的数据任务现在是单线，在Databricks SQL中使用AI</title>
      <link>https://dzone.com/articles/ai-databricks-sql-one-liners</link>
      <description>【&lt;p data-end=&#34;975&#34; data-start=&#34;107&#34;&gt;As data engineers, we’ve all encountered those recurring requests from business stakeholders: “Can you summarize all this text into something executives can read quickly?”, “Can we translate customer reviews into English so everyone can analyze them?”, or “Can we measure customer sentiment at scale without building a new pipeline?”. Traditionally, delivering these capabilities required a lot of heavy lifting. You’d have to export raw data from the warehouse into a Python notebook, clean and preprocess it, connect to an external NLP API or host your own machine learning model, handle retries, manage costs, and then write another job to push the results back into a Delta table. The process was brittle, required multiple moving parts, and — most importantly — took the analysis out of the governed environment, creating compliance and reproducibility risks.&lt;/p&gt;&#xA;&lt;p data-end=&#34;1445&#34; data-start=&#34;977&#34;&gt;With the introduction of &lt;strong data-end=&#34;1036&#34; data-start=&#34;1002&#34;&gt;AI functions in Databricks SQL&lt;/strong&gt;, that complexity is abstracted away. Summarization, translation, sentiment detection, document parsing, masking, and even semantic search can now be expressed in one-line SQL functions, running directly against governed data. There’s no need for additional infrastructure, no external services to maintain, and no custom ML deployments to babysit. Just SQL, governed and scalable, inside the &lt;a href=&#34;https://dzone.com/articles/the-future-of-data-lakehouses-apache-iceberg&#34;&gt;Lakehouse&lt;/a&gt;.&lt;/p&gt;】&lt;p data-end =“ 975” data-start =“ 107”&gt;作为数据工程师，我们都遇到了从商业利益相关者那里反复出现的请求：“您可以将所有这些文本汇总到主管人员可以快速阅读的内容中吗？传统上，提供这些功能需要大量繁重的工作。您必须将原始数据从仓库导出到Python笔记本中，清洁和预处理，连接到外部NLP API或主持您自己的机器学习模型，处理重试，管理成本，然后再写另一个作业以将结果推回Delta表中。该过程很脆弱，需要多个运动部件，最重要的是 - 将分析从受管制的环境中取出，造成了合规性和可重复性风险。&lt;/p&gt;&#xA;&lt;p data-end =“ 1445” data-start =“ 977”&gt;随着&lt;strong data-end =“ 1036” data-start =“ 1002”&gt; ai在databricks sql &lt;/strong&gt;中的功能，该复杂性被抽象出来。现在，可以以单行SQL函数来表达摘要，翻译，情感检测，文档解析，掩盖甚至语义搜索，直接与管辖数据直接运行。不需要额外的基础设施，没有外部服务来维护，也没有自定义的ML部署来保姆。仅在&lt;a a href =“ https://dzone.com/articles/the-future-of-data-lakeshouses-apache-iceberg-”&gt; Lakehouse &lt;/a&gt;。&lt;/a&gt;。</description>
      <pubDate>Fri, 26 Sep 2025 15:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Basic Security Setup for Startups】初创企业的基本安全设置</title>
      <link>https://dzone.com/articles/basic-security-setup-for-startups</link>
      <description>【&lt;h2&gt;Preamble&lt;/h2&gt;&#xA;&lt;p&gt;I recently had a conversation with my friend about starting a new company. We discussed the various stages a company should go through to become mature and secure enough to operate in the modern market. This article will outline those stages. The suggested approach is based on the following principles:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA; &lt;li&gt;Security by default&lt;/li&gt;&#xA; &lt;li&gt;Security by design&lt;/li&gt;&#xA; &lt;li&gt;Identification, authentication, and authorization&lt;/li&gt;&#xA; &lt;li&gt;Segregation of responsibilities&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;You can follow this flow assuming that you&#39;re starting a product from scratch without any existing VNETs, IDPs, or parent companies&#39; networks. However, if you have any of these things, you must adjust the flow accordingly.&lt;/p&gt;】&lt;H2&gt;序言&lt;/h2&gt;&#xA;&lt;p&gt;我最近与我的朋友谈论了一家新公司。我们讨论了公司应该经历的各个阶段，以使其成熟和安全，可以在现代市场上运作。本文将概述这些阶段。建议的方法基于以下原则：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA; &lt;li&gt;默认情况下的安全性&lt;/li&gt;&#xA; &lt;li&gt;设计安全&lt;/li&gt;&#xA; &lt;li&gt;识别，身份验证和授权&lt;/li&gt;&#xA; &lt;li&gt;责任的隔离&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;您可以遵循此流程，假设您在没有任何现有的VNET，IDP或母公司网络的情况下从头开始启动产品。但是，如果您有任何这些东西，则必须相应地调整流程。&lt;/p&gt;</description>
      <pubDate>Fri, 26 Sep 2025 14:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Implementing a Multi-Agent KYC System】实施多代理KYC系统</title>
      <link>https://dzone.com/articles/implementing-a-multi-agent-kyc-systems</link>
      <description>【&lt;p dir=&#34;ltr&#34;&gt;Every engineer who implemented KYC systems has dealt with a frustrating reality. You build rule-based engines that break every time regulations change. Document processing takes days because everything goes through manual review queues. API integrations become brittle nightmares when you&#39;re trying to coordinate identity verification, OCR services, and watchlist screening.&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;The numbers tell the story: most KYC systems process documents in 2–3 days with false positive rates hitting 15-20%. That means one in five legitimate customers gets flagged for manual review. Meanwhile, compliance teams burn out reviewing thousands of documents daily, and customer support fields endless calls about delayed approvals.&lt;/p&gt;】&lt;p dir =“ ltr”&gt;每个实施KYC系统的工程师都处理了令人沮丧的现实。您构建基于规则的引擎，每次都会破坏法规时。文档处理需要几天，因为一切都经过手动审查队列。当您尝试协调身份验证，OCR服务和监视清单筛选时，API集成成为脆弱的噩梦。&lt;/p&gt;&#xA;&lt;p dir =“ ltr”&gt;数字讲述了故事：大多数KYC系统处理文件在2-3天内，误报率达到15-20％。这意味着将五分之一的合法客户标记为手动审查。同时，合规团队每天烧毁了数千份文档的审查，并且客户支持领域无休止的有关延迟批准的电话。&lt;/p&gt;</description>
      <pubDate>Fri, 26 Sep 2025 13:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Building a Real-Time Data Mesh With Apache Iceberg and Flink】用Apache Iceberg和Flink构建实时数据网格</title>
      <link>https://dzone.com/articles/real-time-data-mesh-apache-iceberg-flink</link>
      <description>【&lt;p data-end=&#34;683&#34; data-start=&#34;202&#34;&gt;If you’ve ever tried to scale your organization’s data infrastructure beyond a few teams, you know how fast a carefully planned “data lake” can degenerate into an unruly “data swamp.” Pipelines are pushing files nonstop, tables sprout like mushrooms after a rainy day, and no one is quite sure who owns which dataset. Meanwhile, your real-time consumers are impatient for fresh data, your batch pipelines crumble on every schema change, and governance is an afterthought at best.&lt;/p&gt;&#xA;&lt;p data-end=&#34;1032&#34; data-start=&#34;685&#34;&gt;At that point, someone in a meeting inevitably utters the magic word: &lt;a href=&#34;https://dzone.com/articles/data-mesh-a-paradigm-shift-in-data-management&#34;&gt;data mesh&lt;/a&gt;. Decentralized data ownership, domain-oriented pipelines, and self-service access all sound perfect on paper. But in practice, it can feel like you’re trying to build an interstate highway system while traffic is already barreling down dirt roads at full speed.&lt;/p&gt;】&lt;p data-end =“ 683” data-start =“ 202”&gt;如果您曾经试图将组织的数据基础架构扩展到几个团队之外，那么您知道精心计划的“数据湖”可以多快地退化为不守规矩的“数据沼泽”。雨天后，管道不停地推动文件，表像蘑菇一样发芽，没有人确定谁拥有哪个数据集。同时，您的实时消费者对新的数据不耐烦，您的批处理管道在每次架构上都崩溃了，治理充其量是事后的想法。&lt;/p&gt;&#xA;&lt;p data-end =“ 1032” data-start =“ 685”&gt;当时，会议中的某人不可避免地会说明魔术词：&lt;a href =“ https：//dzone.com/articles/data-mesh-a-a-a-a-a-paradigm-shift--shift-shift-nift-nift-in-data-management-in-data-management”分散的数据所有权，面向域的管道和自助服务访问在纸上听起来很完美。但是实际上，您可能会感觉像是在试图建立一个州际公路系统，而交通已经全速驶入土路。&lt;/p&gt;</description>
      <pubDate>Fri, 26 Sep 2025 12:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【AI Transformation Déjà Vu】AI转换已经看到</title>
      <link>https://dzone.com/articles/ai-transformation-deja-vu</link>
      <description>【&lt;h2&gt;TL;DR: AI Transformation Failures&lt;/h2&gt;&#xA;&lt;p&gt;Organizations seem to fail their AI transformation using the same patterns that killed their Agile transformations: Performing demos instead of solving problems, buying tools before identifying needs, celebrating pilots that can’t scale, and measuring activity instead of outcomes.&lt;/p&gt;&#xA;&lt;p&gt;These aren’t technology failures; they are organizational patterns of performing change instead of actually changing. Your advantage isn’t AI expertise; it’s pattern recognition from surviving &lt;a href=&#34;https://dzone.com/articles/the-agile-the-fragile-and-the-iron-fist-of-branchi&#34;&gt;Agile&lt;/a&gt;. Use it to spot theater, demand real problems before tools, insist on integration from day one, and measure actual value delivered.&lt;/p&gt;】&lt;H2&gt; TL; DR：AI转换故障&lt;/h2&gt;&#xA;&lt;p&gt;组织似乎使用杀死其敏捷转型的相同模式失败了他们的AI转换：执行演示而不是解决问题，在识别需求之前购买工具，庆祝无法扩展的飞行员以及衡量活动而不是结果。&lt;/p&gt;。&lt;/p&gt;&#xA;&lt;p&gt;这些不是技术故障；它们是执行变革而不是实际变化的组织模式。您的优势不是AI专业知识；幸存的&lt;a href =“ https://dzone.com/articles/the-agile-the-agile-the-fragile-and-the-rir-fist-of-branchi”&gt;敏捷&lt;/a&gt;的模式识别。使用它来发现剧院，在工具之前要求真正的问题，坚持从第一天起进行集成，并衡量交付的实际价值。&lt;/p&gt;</description>
      <pubDate>Fri, 26 Sep 2025 11:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Implementing Vector Search in Databricks】在Databricks中实施矢量搜索</title>
      <link>https://dzone.com/articles/implementing-vector-search-in-databricks</link>
      <description>【&lt;p dir=&#34;ltr&#34;&gt;Search has always been at the heart of analytics. Whether you’re tracking down the right transaction, filtering a customer record, or pulling a specific review, the default approach has traditionally been keyword search.&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;&lt;a href=&#34;https://dzone.com/articles/from-keywords-to-context-a-deep-dive-into-modern&#34;&gt;Keyword search&lt;/a&gt; is simple and effective when you know exactly what you’re looking for, but it quickly falls apart when the language is messy, ambiguous, or when meaning matters more than exact words. That’s where vector search changes the game. Instead of matching literal keywords, vector search relies on embeddings — high-dimensional numeric representations of text, images, or other unstructured content — that capture semantic meaning.&amp;nbsp;&lt;/p&gt;】&lt;p dir =“ ltr”&gt;搜索一直是分析的核心。无论您是跟踪正确的交易，过滤客户记录还是提取特定的评论，默认方法传统上都是关键字搜索。&lt;/p&gt;&#xA;&lt;p dir =“ ltr”&gt; &lt;a href =“ https://dzone.com/articles/from-keywords-to-context-context-a-deep-deep-dive-into-modern”&gt;关键字搜索&lt;/a&gt;当您确切地知道什么时，当您在语言中很快就会崩溃，当您觉得杂乱无章时，比如觉得很奇怪，或者在言语中更重要的是，当您很快就会崩溃时，它是简单而有效的。那就是向量搜索改变游戏的地方。向量搜索不匹配文字关键字，而是依赖嵌入 - 捕获语义含义的文本，图像或其他非结构化内容的高维数字表示。 &lt;/p&gt;</description>
      <pubDate>Thu, 25 Sep 2025 19:00:03 +0000</pubDate>
    </item>
  </channel>
</rss>