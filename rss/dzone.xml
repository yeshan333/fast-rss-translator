<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>DZone.com Feed</title>
    <link>https://feeds.dzone.com/home</link>
    <description>Recent posts on DZone.com</description>
    <item>
      <title>【Why Encryption Alone Is Not Enough in Cloud Security】为什么云安全中仅加密还不够</title>
      <link>https://dzone.com/articles/why-encryption-alone-is-not-enough-in-cloud-security</link>
      <description>【&lt;p data-end=&#34;645&#34; data-start=&#34;237&#34;&gt;It is often assumed that &lt;a href=&#34;https://dzone.com/articles/fundamentals-of-cryptography&#34;&gt;encryption&lt;/a&gt; is the gold standard method for securing assets in the cloud. Cloud providers give assurances that all their services are “encrypted by default.” Several regulatory and cloud compliance policies mandate that organizations encrypt data at rest, in use, and in transit. All of this should make cloud environments secure, right? However, the reality is slightly more nuanced.&lt;/p&gt;&#xA;&lt;p data-end=&#34;1020&#34; data-start=&#34;647&#34;&gt;Many breaches occur not because encryption algorithms are weak or because attackers can crack them. They occur because attackers never need to. Instead, attackers exploit other weaknesses. Access may be over-permissive, key governance may be poorly managed, configurations may be exposed, and there may be an overall lack of visibility into how data is actually being used.&lt;/p&gt;】&lt;p data-end=&#34;645&#34; data-start=&#34;237&#34;&gt;人们通常认为&lt;a href=&#34;https://dzone.com/articles/fundamentals-of-cryptography&#34;&gt;加密&lt;/a&gt;是保护云中资产的黄金标准方法。云提供商保证他们的所有服务都是“默认加密的”。多项监管和云合规性策略要求组织对静态、使用中和传输中的数据进行加密。所有这些都应该使云环境安全，对吧？然而，现实情况稍微微妙一些。&lt;/p&gt;&#xA;&lt;p data-end=&#34;1020&#34; data-start=&#34;647&#34;&gt;许多漏洞的发生并不是因为加密算法较弱，也不是因为攻击者可以破解它们。它们的发生是因为攻击者从来不需要这样做。相反，攻击者会利用其他弱点。访问可能过于宽松，关键治理可能管理不善，配置可能会暴露，并且可能总体上缺乏对数据实际使用方式的可见性。&lt;/p&gt;</description>
      <pubDate>Fri, 09 Jan 2026 20:00:12 +0000</pubDate>
    </item>
    <item>
      <title>【The Rise of Diskless Kafka: Rethinking Brokers, Storage, and the Kafka Protocol】无盘 Kafka 的兴起：重新思考代理、存储和 Kafka 协议</title>
      <link>https://dzone.com/articles/rise-of-diskless-kafka-rethinking-brokers-storage</link>
      <description>【&lt;p data-end=&#34;796&#34; data-start=&#34;354&#34;&gt;Apache Kafka has come a long way from being just a scalable &lt;a href=&#34;https://dzone.com/articles/building-scalable-data-lake-using-aws&#34;&gt;data ingestion layer for data lakes&lt;/a&gt;. Today, it is the backbone of real-time transactional applications. In many organizations, Kafka serves as the central nervous system connecting both operational and analytical workloads. Over time, its architecture has shifted significantly — from brokers managing all storage, to Tiered Storage, and now toward a new paradigm: &lt;strong data-end=&#34;795&#34; data-start=&#34;777&#34;&gt;Diskless Kafka&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;p data-end=&#34;1018&#34; data-start=&#34;798&#34;&gt;Diskless Kafka refers to a Kafka architecture in which brokers use no local disk storage. Instead, all event data is stored directly in cloud object storage such as Amazon S3, Google Cloud Storage, or Azure Blob Storage.&lt;/p&gt;】&lt;p data-end=&#34;796&#34; data-start=&#34;354&#34;&gt;Apache Kafka 已经从一个可扩展的&lt;a href=&#34;https://dzone.com/articles/building-scalable-data-lake-using-aws&#34;&gt;数据湖的数据摄取层&lt;/a&gt;走过了很长的路。如今，它已成为实时事务应用程序的支柱。在许多组织中，Kafka 充当连接操作和分析工作负载的中枢神经系统。随着时间的推移，其架构发生了显着变化——从管理所有存储的代理，到分层存储，现在又转向了一种新的范例：&lt;strong data-end=&#34;795&#34; data-start=&#34;777&#34;&gt;Diskless Kafka&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;p data-end=&#34;1018&#34; data-start=&#34;798&#34;&gt;无盘 Kafka 是指代理不使用本地磁盘存储的 Kafka 架构。相反，所有事件数据都直接存储在云对象存储中，例如 Amazon S3、Google Cloud Storage 或 Azure Blob Storage。&lt;/p&gt;</description>
      <pubDate>Fri, 09 Jan 2026 19:00:10 +0000</pubDate>
    </item>
    <item>
      <title>【Beyond Extensions: Architectural Deep-Dives into File Upload Security】超越扩展：架构深入探讨文件上传安全性</title>
      <link>https://dzone.com/articles/architectural-deep-dives-into-file-upload-security</link>
      <description>【&lt;p data-end=&#34;560&#34; data-start=&#34;263&#34;&gt;Allowing users to upload files is a staple of modern web applications, from profile pictures to enterprise document management. However, for a security engineer or backend developer, an upload field is essentially an open invitation for an attacker to place an arbitrary binary on your filesystem.&lt;/p&gt;&#xA;&lt;p data-end=&#34;908&#34; data-start=&#34;562&#34;&gt;When validation fails, the consequences range from localized data theft to a total &lt;a href=&#34;https://dzone.com/articles/securing-parquet-files-vulnerabilities-mitigations&#34;&gt;Remote Code Execution (RCE) scenario&lt;/a&gt;, where an attacker gains a web shell and full control over the host. This article explores why standard defenses often fail and how modern architectural patterns — and their flaws — impact the security posture of your application.&lt;/p&gt;】&lt;p data-end=&#34;560&#34; data-start=&#34;263&#34;&gt;允许用户上传文件是现代 Web 应用程序（从个人资料图片到企业文档管理）的主要内容。然而，对于安全工程师或后端开发人员来说，上传字段本质上是对攻击者在您的文件系统上放置任意二进制文件的公开邀请。&lt;/p&gt;&#xA;&lt;p data-end=&#34;908&#34; data-start=&#34;562&#34;&gt;当验证失败时，后果包括局部数据盗窃和总体&lt;a href=&#34;https://dzone.com/articles/securing-parquet-files-vulnerability-mitigations&#34;&gt;远程代码执行 (RCE) 场景&lt;/a&gt;，其中攻击者获得 Web shell 并完全控制主机。本文探讨了为什么标准防御经常失败，以及现代架构模式及其缺陷如何影响应用程序的安全状况。&lt;/p&gt;</description>
      <pubDate>Fri, 09 Jan 2026 17:00:11 +0000</pubDate>
    </item>
    <item>
      <title>【Mastering Fluent Bit: Developer Guide to Telemetry Pipeline Routing (Part 12)】掌握 Fluent Bit：遥测管道路由开发人员指南（第 12 部分）</title>
      <link>https://dzone.com/articles/mastering-fluent-bit-developer-guide-to-telemetry</link>
      <description>【&lt;p data-end=&#34;440&#34; data-start=&#34;287&#34;&gt;This series is a general-purpose getting-started guide for those who want to learn about the Cloud Native Computing Foundation (CNCF) project Fluent Bit.&lt;/p&gt;&#xA;&lt;p data-end=&#34;684&#34; data-start=&#34;442&#34;&gt;Each article in this series addresses a single topic by providing insights into what the topic is, why it is worth exploring, where to get started, and how to get hands-on with learning about the topic as it relates to the Fluent Bit project.&lt;/p&gt;】&lt;p data-end=&#34;440&#34; data-start=&#34;287&#34;&gt;本系列是为那些想要了解云原生计算基金会 (CNCF) 项目 Fluent Bit 的人提供的通用入门指南。&lt;/p&gt;&#xA;&lt;p data-end=&#34;684&#34; data-start=&#34;442&#34;&gt;本系列中的每篇文章都针对一个主题，深入介绍该主题是什么、为什么值得探索、从哪里开始以及如何实际了解该主题（因为该主题与 Fluent Bit 项目相关）。&lt;/p&gt;</description>
      <pubDate>Fri, 09 Jan 2026 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【How to Build and Deploy an AI Agent on Kubernetes With AWS Bedrock, FastAPI and Helm】如何使用 AWS Bedrock、FastAPI 和 Helm 在 Kubernetes 上构建和部署 AI 代理</title>
      <link>https://dzone.com/articles/how-to-build-and-deploy-an-ai-agent-on-kubernetes</link>
      <description>【&lt;p data-end=&#34;697&#34; data-start=&#34;115&#34;&gt;The capabilities offered by AI are no longer limited to large, centralized platforms. Today, engineering teams are increasingly embracing lightweight, specialized &lt;a href=&#34;https://dzone.com/articles/ai-agentic-101-understanding-ai-agents&#34;&gt;AI agents&lt;/a&gt; that can be managed, scaled, and deployed just like microservices in a cloud-native environment — whether for summarizing large documents, translation, classification, or other analytical tasks. In this tutorial, you will create, deploy, and run an AI model that provides REST APIs for summarization and translation using AWS Bedrock, FastAPI, Docker, and deployment on Amazon EKS via Helm.&lt;/p&gt;&#xA;&lt;p data-end=&#34;859&#34; data-start=&#34;699&#34;&gt;This provides a reusable process for integrating AI into operations: one agent, one task, clear boundaries, and full Kubernetes-native visibility and control.&lt;/p&gt;】&lt;p data-end=&#34;697&#34; data-start=&#34;115&#34;&gt;人工智能提供的功能不再局限于大型集中式平台。如今，工程团队越来越多地采用轻量级、专业化的人工智能代理，它们可以像云原生环境中的微服务一样进行管理、扩展和部署，无论是用于汇总大型文档、翻译、分类还是其他分析任务。在本教程中，您将创建、部署和运行一个 AI 模型，该模型提供 REST API，以便使用 AWS Bedrock、FastAPI、Docker 进行摘要和翻译，并通过 Helm 在 Amazon EKS 上进行部署。&lt;/p&gt;&#xA;&lt;p data-end=&#34;859&#34; data-start=&#34;699&#34;&gt;这提供了一个可重用的流程，用于将 AI 集成到操作中：一个代理、一项任务、清晰的边界以及完整的 Kubernetes 原生可见性和控制。&lt;/p&gt;</description>
      <pubDate>Fri, 09 Jan 2026 15:00:14 +0000</pubDate>
    </item>
    <item>
      <title>【Essential Techniques for Production Vector Search Systems Part 2 - Binary Quantization】生产矢量搜索系统的基本技术第 2 部分 - 二进制量化</title>
      <link>https://dzone.com/articles/production-vector-search-techniques-binary-quantization</link>
      <description>【&lt;p data-end=&#34;434&#34; data-start=&#34;240&#34;&gt;After implementing vector search systems at multiple companies, I wanted to document efficient techniques that can be very helpful for successful production deployments of &lt;a href=&#34;https://dzone.com/articles/vector-search-hottest-topic-in-information-retrieval&#34;&gt;vector search systems&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p data-end=&#34;741&#34; data-start=&#34;436&#34;&gt;I want to present these techniques by showcasing when to apply each one, how they complement each other, and the trade-offs they introduce. This will be a multi-part series that introduces all of the techniques one by one in each article. I have also included code snippets to quickly test each technique.&lt;/p&gt;】&lt;p data-end=&#34;434&#34; data-start=&#34;240&#34;&gt;在多家公司实施矢量搜索系统后，我想记录一些有效的技术，这些技术对于&lt;a href=&#34;https://dzone.com/articles/vector-search-hottest-topic-in-information-retrieval&#34;&gt;矢量搜索系统&lt;/a&gt;的成功生产部署非常有帮助。&lt;/p&gt;&#xA;&lt;p data-end=&#34;741&#34; data-start=&#34;436&#34;&gt;我想通过展示何时应用每种技术、它们如何相互补充以及它们引入的权衡来展示这些技术。这将是一个由多部分组成的系列，每篇文章都会一一介绍所有技术。我还提供了代码片段来快速测试每种技术。&lt;/p&gt;</description>
      <pubDate>Fri, 09 Jan 2026 14:16:27 +0000</pubDate>
    </item>
    <item>
      <title>【Multi-Region Apache Kafka using Synchronous Replication for Disaster Recovery With Zero Data Loss (RPO=0)】多区域 Apache Kafka 使用同步复制实现零数据丢失 (RPO=0) 的灾难恢复</title>
      <link>https://dzone.com/articles/multi-region-apache-kafka-using-synchronous-replic</link>
      <description>【&lt;p&gt;Apache Kafka is the backbone of modern event-driven systems. It powers real-time use cases across industries. But deploying Kafka is not a one-size-fits-all decision. The right strategy depends on performance, compliance, and operational needs.&lt;/p&gt;&#xA;&lt;p&gt;From self-managed clusters to fully managed services and &lt;a href=&#34;https://dzone.com/articles/sass-pass-data-streaming-kafka-flink-streaming&#34;&gt;Bring-Your-Own-Cloud (BYOC) models&lt;/a&gt;, each approach offers different levels of control, simplicity, and scalability. Selecting the right deployment model is a strategic decision that affects cost, agility, and risk.&lt;/p&gt;】&lt;p&gt;Apache Kafka 是现代事件驱动系统的支柱。它为跨行业的实时用例提供支持。但部署 Kafka 并不是一个一刀切的决定。正确的策略取决于性能、合规性和运营需求。&lt;/p&gt;&#xA;&lt;p&gt;从自我管理集群到完全托管服务和&lt;a href=&#34;https://dzone.com/articles/sass-pass-data-streaming-kafka-flink-streaming&#34;&gt;自带云 (BYOC) 模型&lt;/a&gt;，每种方法都提供不同级别的控制、简单性和可扩展性。选择正确的部署模型是一项影响成本、敏捷性和风险的战略决策。&lt;/p&gt;</description>
      <pubDate>Fri, 09 Jan 2026 14:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【From Code to Runtime: How AI Is Bridging the SAST–DAST Gap】从代码到运行时：AI 如何弥合 SAST-DAST 差距</title>
      <link>https://dzone.com/articles/from-code-to-runtime-how-ai-is-bridging-the-sastda</link>
      <description>【&lt;p data-end=&#34;701&#34; data-start=&#34;267&#34;&gt;Let’s start with two pillars that modern application security teams rely on: &lt;a href=&#34;https://dzone.com/articles/the-need-for-application-security-testing&#34;&gt;Static Application Security Testing (SAST) and Dynamic Application Security Testing (DAST)&lt;/a&gt;. SAST is a method in which source code is analyzed early in the application development lifecycle to identify potential vulnerabilities. On the other hand, DAST is used to test running applications to uncover hidden flaws — specifically from an attacker’s perspective.&lt;/p&gt;&#xA;&lt;p data-end=&#34;1009&#34; data-start=&#34;703&#34;&gt;Both approaches are equally valuable. However, they are often not used together. Security teams juggle multiple point solutions and, on top of that, are overwhelmed by false positives. As a result, they struggle to answer a simple question: &lt;strong data-end=&#34;1009&#34; data-start=&#34;944&#34;&gt;Which vulnerabilities are actually exploitable in production?&lt;/strong&gt;&lt;/p&gt;】&lt;p data-end=&#34;701&#34; data-start=&#34;267&#34;&gt;让我们从现代应用安全团队依赖的两大支柱开始：&lt;a href=&#34;https://dzone.com/articles/the-need-for-application-security-testing&#34;&gt;静态应用安全测试 (SAST) 和动态应用安全测试 (DAST)&lt;/a&gt;。 SAST 是一种在应用程序开发生命周期的早期分析源代码以识别潜在漏洞的方法。另一方面，DAST 用于测试正在运行的应用程序以发现隐藏的缺陷 - 特别是从攻击者的角度来看。&lt;/p&gt;&#xA;&lt;p data-end=&#34;1009&#34; data-start=&#34;703&#34;&gt;这两种方法同样有价值。然而，它们通常不一起使用。安全团队需要兼顾多点解决方案，最重要的是，他们会被误报淹没。因此，他们很难回答一个简单的问题：&lt;strong data-end=&#34;1009&#34; data-start=&#34;944&#34;&gt;哪些漏洞实际上可以在生产中利用？&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 09 Jan 2026 13:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【How AI Is Rewriting DevOps: Practical Patterns for Faster, Safer Releases】AI 如何重写 DevOps：实现更快、更安全发布的实用模式</title>
      <link>https://dzone.com/articles/how-ai-is-rewriting-devops-practical-patterns</link>
      <description>【&lt;p data-end=&#34;1009&#34; data-start=&#34;233&#34;&gt;DevOps has always sought to deliver software faster without breaking things — a balancing act between velocity and stability. Now, artificial intelligence is dramatically shifting that balance. &lt;a href=&#34;https://dzone.com/articles/a-complete-guide-to-modern-ai-developer-tools&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt;AI-powered tools and practices&lt;/a&gt; are weaving into every stage of the delivery pipeline, helping teams ship code at lightning speed with greater safety. Analysts predict that by 2027, over 50% of enterprise teams will have AI agents in their pipelines to boost speed, quality, and governance. Early adopters are already seeing significant gains; one study found that embedding AI into development led to 20% to 30% faster delivery with 40% fewer defects in releases. These improvements aren’t about traditional automation alone — they’re driven by intelligent systems that learn and adapt.&lt;/p&gt;&#xA;&lt;p data-end=&#34;1689&#34; data-start=&#34;1011&#34;&gt;In this article, we’ll explore how AI is rewriting DevOps from an engineer’s perspective. We’ll examine real-world tools and examples, from coding assistants like GitHub Copilot to AIOps platforms, and highlight practical AI-driven patterns that enable faster, safer software releases. This is not just hype or theory; it’s a trend analysis grounded in emerging best practices that advanced engineering teams are adopting today. We’ll look at how AI assists in coding, testing, deployments, and operations, all while keeping quality and security in focus. Let’s dive into the key areas where AI is transforming DevOps and the patterns you can leverage for speed and reliability.&lt;/p&gt;】&lt;p data-end=&#34;1009&#34; data-start=&#34;233&#34;&gt;DevOps 始终寻求在不破坏事物的情况下更快地交付软件 - 这是速度和稳定性之间的平衡行为。现在，人工智能正在极大地改变这种平衡。 &lt;a href=&#34;https://dzone.com/articles/a-complete-guide-to-modern-ai-developer-tools&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt;人工智能驱动的工具和实践&lt;/a&gt;正在融入交付管道的每个阶段，帮助团队以闪电般的速度更安全地交付代码。分析师预测，到 2027 年，超过 50% 的企业团队将在其管道中配备人工智能代理，以提高速度、质量和治理。早期采用者已经看到了显着的收益；一项研究发现，将 AI 嵌入到开发中可以使交付速度提高 20% 到 30%，同时发布中的缺陷减少 40%。这些改进不仅仅涉及传统自动化——它们是由学习和适应的智能系统驱动的。&lt;/p&gt;&#xA;&lt;p data-end=&#34;1689&#34; data-start=&#34;1011&#34;&gt;在本文中，我们将从工程师的角度探讨 AI 如何重写 DevOps。我们将研究现实世界的工具和示例，从 GitHub Copilot 等编码助手到 AIOps 平台，并重点介绍实用的人工智能驱动模式，这些模式可实现更快、更安全的软件发布。这不仅仅是炒作或理论；而是事实。这是一种基于先进工程团队当今采用的新兴最佳实践的趋势分析。我们将研究人工智能如何协助编码、测试、部署和操作，同时保持质量和安全性。让我们深入探讨人工智能正在改变 DevOps 的关键领域，以及可用来提高速度和可靠性的模式。&lt;/p&gt;</description>
      <pubDate>Fri, 09 Jan 2026 12:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Speak Their Language: How Communication Profiling Prevents Agile Delivery Breakdowns】说他们的语言：沟通分析如何防止敏捷交付故障</title>
      <link>https://dzone.com/articles/communication-profiling-prevents-agile-delivery-breakdowns</link>
      <description>【&lt;p data-end=&#34;419&#34; data-start=&#34;204&#34;&gt;&lt;a href=&#34;https://dzone.com/articles/ensuring-on-time-delivery-in-agile-driven-projects&#34;&gt;Agile delivery&lt;/a&gt; failures are usually explained with comfortable excuses. The backlog was unclear. The scope changed. The estimates were wrong. The architecture was fragile. The process wasn’t followed closely enough.&lt;/p&gt;&#xA;&lt;p data-end=&#34;530&#34; data-start=&#34;421&#34;&gt;In real delivery environments, especially complex or hybrid ones, those explanations rarely hold up for long.&lt;/p&gt;】&lt;p data-end=&#34;419&#34; data-start=&#34;204&#34;&gt;&lt;a href=&#34;https://dzone.com/articles/ensuring-on-time-delivery-in-agile-driven-projects&#34;&gt;敏捷交付失败&lt;/a&gt;通常可以用舒服的借口来解释。积压情况不清楚。范围变了。估计是错误的。该建筑很脆弱。该过程没有得到足够严格的遵循。&lt;/p&gt;&#xA;&lt;p data-end=&#34;530&#34; data-start=&#34;421&#34;&gt;在真实的交付环境中，尤其是复杂或混合的环境中，这些解释很少能长期站得住脚。&lt;/p&gt;</description>
      <pubDate>Thu, 08 Jan 2026 20:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>