<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>DZone.com Feed</title>
    <link>https://feeds.dzone.com/home</link>
    <description>Recent posts on DZone.com</description>
    <item>
      <title>【Building a Reactive Event-Driven App With Dead Letter Queue】使用死信队列构建反应式事件驱动应用程序</title>
      <link>https://dzone.com/articles/reactive-event-driven-app-with-dead-letter-queue</link>
      <description>【&lt;p dir=&#34;ltr&#34;&gt;Event-driven architecture facilitates systems to reply to real-life events, such as when the user&#39;s profile is updated. This post illustrates building reactive event-driven applications that handle data loss by combining Spring WebFlux, Apache Kafka, and Dead Letter Queue. When used together, these provide the framework for creating fault-tolerant, resilient, and high-performance systems that are important for large applications that need to handle massive volumes of data efficiently.&lt;/p&gt;&#xA;&lt;h2 dir=&#34;ltr&#34;&gt;&lt;strong&gt;Features Used in this Article&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA; &lt;li dir=&#34;ltr&#34;&gt;&lt;span style=&#34;margin: 0px; padding: 0px;&#34;&gt;&lt;strong&gt;Spring Webflux&lt;/strong&gt;: It provides a &lt;/span&gt;&lt;a href=&#34;https://dzone.com/articles/embracing-reactive-programming-with-spring-webflux&#34;&gt;&lt;span style=&#34;margin: 0px; padding: 0px;&#34;&gt;Reactive paradigm&lt;/span&gt;&lt;/a&gt;&lt;span style=&#34;margin: 0px; padding: 0px;&#34;&gt; that depends on non-blocking back pressure for the simultaneous processing of events.&lt;/span&gt;&lt;/li&gt;&#xA; &lt;li dir=&#34;ltr&#34;&gt;&lt;strong&gt;Apache Kafka&lt;/strong&gt;: Reactive Kafka producers and consumers help in building competent and adaptable processing pipelines.&lt;/li&gt;&#xA; &lt;li dir=&#34;ltr&#34;&gt;&lt;span style=&#34;margin: 0px; padding: 0px;&#34;&gt;&lt;strong&gt;Reactive Streams&lt;/strong&gt;: They do not block the execution of Kafka producers and consumers&#39; streams.&lt;/span&gt;&lt;/li&gt;&#xA; &lt;li dir=&#34;ltr&#34;&gt;&lt;strong&gt;Dead Letter Queue (DLQ)&lt;/strong&gt;: A DLQ stores messages temporarily that could not have been processed due to various reasons. DLQ messages can be later used to reprocess messages to prevent data loss and make event processing resilient.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 dir=&#34;ltr&#34;&gt;&lt;strong&gt;Reactive Kafka Producer&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;A &lt;a href=&#34;https://dzone.com/articles/reactive-kafka-with-spring-boot&#34;&gt;Reactive Kafka&lt;/a&gt; Producer pushes messages in parallel and does not block other threads while publishing. It is beneficial where large data to be processed. It blends well with Spring WebFlux and handles backpressure within microservices architectures. This integration helps in not only processing large messages but also managing cloud resources well.&amp;nbsp;&lt;/p&gt;】&lt;p dir=&#34;ltr&#34;&gt;事件驱动架构有助于系统回复现实生活中的事件，例如用户的个人资料更新时。这篇文章阐述了如何构建反应式事件驱动的应用程序，通过结合 Spring WebFlux、Apache Kafka 和死信队列来处理数据丢失。当一起使用时，它们提供了创建容错、弹性和高性能系统的框架，这对于需要有效处理大量数据的大型应用程序非常重要。&lt;/p&gt;&#xA;&lt;h2 dir=&#34;ltr&#34;&gt;&lt;strong&gt;本文中使用的功能&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA; &lt;li dir=&#34;ltr&#34;&gt;&lt;span style=&#34;margin: 0px; padding: 0px;&#34;&gt;&lt;strong&gt;Spring Webflux&lt;/strong&gt;：它提供了&lt;/span&gt;&lt;a href=&#34;https://dzone .com/articles/embracing-reactive-programming-with-spring-webflux&#34;&gt;&lt;span style=&#34;margin: 0px; padding: 0px;&#34;&gt;反应式范例&lt;/span&gt;&lt;/a&gt;&lt;span style=&#34;margin: 0px; padding: 0px;&#34;&gt;这取决于同时处理事件的非阻塞背压。&lt;/span&gt;&lt;/li&gt;&#xA; &lt;li dir=&#34;ltr&#34;&gt;&lt;strong&gt;Apache Kafka&lt;/strong&gt;：反应式 Kafka 生产者和消费者帮助构建有能力且适应性强的处理管道。&lt;/li&gt;&#xA; &lt;li dir=&#34;ltr&#34;&gt;&lt;span style=&#34;margin: 0px; padding: 0px;&#34;&gt;&lt;strong&gt;反应式流&lt;/strong&gt;：它们不会阻止 Kafka 生产者和消费者流的执行。&lt;/span &gt;&lt;/li&gt;&#xA; &lt;li dir=&#34;ltr&#34;&gt;&lt;strong&gt;死信队列 (DLQ)&lt;/strong&gt;：DLQ 临时存储由于各种原因无法处理的消息。 DLQ 消息稍后可用于重新处理消息，以防止数据丢失并使事件处理具有弹性。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 dir=&#34;ltr&#34;&gt;&lt;strong&gt;反应式 Kafka 生产者&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;A &lt;a href=&#34;https://dzone.com/articles/reactive-kafka-with-spring-boot&#34;&gt;反应式 Kafka&lt;/a&gt; 生产者并行推送消息且不会阻塞发布时的其他线程。当需要处理大数据时，这是有利的。它与 Spring WebFlux 很好地融合，并处理微服务架构中的背压。这种集成不仅有助于处理大消息，还有助于很好地管理云资源。 &lt;/p&gt;</description>
      <pubDate>Mon, 20 Jan 2025 15:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Troubleshooting Connection Issues When Connecting to MySQL Server】解决连接到 MySQL 服务器时的连接问题</title>
      <link>https://dzone.com/articles/troubleshooting-mysql-connection-issues</link>
      <description>【&lt;div data-element_type=&#34;container&#34; data-id=&#34;13e2500&#34;&gt;&#xA; Encountering connection problems while accessing a MySQL server is a common challenge for database users. These issues often arise due to incorrect configuration, user permissions, or compatibility problems. Below are the most common errors and their solutions to help you resolve connection issues efficiently.&#xA; &lt;h2&gt;1. Error: &lt;strong&gt;Host ‘xxx.xx.xxx.xxx’ is not allowed to connect to this MySQL server&lt;/strong&gt;&lt;/h2&gt;&#xA; &lt;h3&gt;Cause&lt;/h3&gt;&#xA; &lt;p&gt;This error indicates that the &lt;a href=&#34;https://dzone.com/articles/an-introduction-to-ddl-dml-and-dcl-commands-in-mys&#34;&gt;MySQL server&lt;/a&gt; does not permit the specified host or user to access the database. It is typically due to insufficient privileges assigned to the user or client host.&lt;/p&gt;&#xA; &lt;h3&gt;Solution&lt;/h3&gt;&#xA; &lt;p&gt;To resolve this issue, grant the required privileges to the user from the MySQL command line:&lt;/p&gt;】&lt;div data-element_type=&#34;容器&#34; data-id=&#34;13e2500&#34;&gt;&#xA; 访问 MySQL 服务器时遇到连接问题是数据库用户面临的常见挑战。这些问题通常是由于不正确的配置、用户权限或兼容性问题而引起的。以下是最常见的错误及其解决方案，可帮助您有效解决连接问题。&#xA; &lt;h2&gt;1。错误：&lt;strong&gt;不允许主机“xxx.xx.xxx.xxx”连接到此 MySQL 服务器&lt;/strong&gt;&lt;/h2&gt;&#xA; &lt;h3&gt;原因&lt;/h3&gt;&#xA; &lt;p&gt;此错误表明 &lt;a href=&#34;https://dzone.com/articles/an-introduction-to-ddl-dml-and-dcl-commands-in-mys&#34;&gt;MySQL 服务器&lt;/a&gt;不允许指定的主机或用户访问数据库。这通常是由于分配给用户或客户端主机的权限不足造成的。&lt;/p&gt;&#xA; &lt;h3&gt;解决方案&lt;/h3&gt;&#xA; &lt;p&gt;要解决此问题，请从 MySQL 命令行向用户授予所需的权限：&lt;/p&gt;</description>
      <pubDate>Mon, 20 Jan 2025 13:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Evolution of Recommendation Systems: From Legacy Rules Engines to Machine Learning】推荐系统的演变：从遗留规则引擎到机器学习</title>
      <link>https://dzone.com/articles/legacy-rules-engines-and-machine-learning</link>
      <description>【&lt;p data-pm-slice=&#34;1 1 []&#34;&gt;In the world of technology, personalization is the key to keeping users engaged and satisfied. One of the most visible implementations of personalization is through recommendation systems, which provide users with tailored content, products, or experiences based on their interactions and preferences. Historically, the first implementations of recommendation systems were built on legacy rule-based engines like IBM ODM (Operational Decision Manager) and Red Hat JBoss BRMS (Business Rule Management System).&amp;nbsp;&lt;/p&gt;&#xA;&lt;p data-pm-slice=&#34;1 1 []&#34;&gt;However, recent advances in machine learning have fundamentally changed how recommendations are generated. This article explores how &lt;a href=&#34;https://dzone.com/articles/from-old-to-bold-a-strategic-guide-to-legacy-syste&#34;&gt;legacy rules-based systems&lt;/a&gt; operate, their limitations, and how machine learning has disrupted this space.&lt;/p&gt;】&lt;p data-pm-slice=&#34;1 1 []&#34;&gt;在技术领域，个性化是保持用户参与度和满意度的关键。个性化最明显的实现之一是通过推荐系统，它根据用户的交互和偏好为用户提供定制的内容、产品或体验。从历史上看，推荐系统的首次实现是基于传统的基于规则的引擎构建的，例如 IBM ODM（操作决策管理器）和 Red Hat JBoss BRMS（业务规则管理系统）。 &lt;/p&gt;&#xA;&lt;p data-pm-slice=&#34;1 1 []&#34;&gt;但是，机器学习的最新进展从根本上改变了推荐的生成方式。本文探讨了&lt;a href=&#34;https://dzone.com/articles/from-old-to-bold-a-strategic-guide-to-legacy-syste&#34;&gt;基于规则的旧系统&lt;/a&gt;如何运行、它们的局限性，以及机器学习如何颠覆这个领域。&lt;/p&gt;</description>
      <pubDate>Mon, 20 Jan 2025 17:00:05 +0000</pubDate>
    </item>
    <item>
      <title>【Optimizing Prometheus Queries With PromQL】使用 PromQL 优化 Prometheus 查询</title>
      <link>https://dzone.com/articles/optimizing-prometheus-queries-with-promql</link>
      <description>【&lt;p data-pm-slice=&#34;1 1 []&#34;&gt;Prometheus is a powerful monitoring tool that provides extensive metrics and insights into your infrastructure and applications, especially in k8s and OCP (enterprise k8s). While crafting PromQL (Prometheus Query Language) expressions, ensuring accuracy and compatibility is essential, especially when comparing metrics or calculating thresholds.&amp;nbsp;&lt;/p&gt;&#xA;&lt;p data-pm-slice=&#34;1 1 []&#34;&gt;In this article, we will explore how to count worker nodes and track changes in resources effectively using &lt;a href=&#34;https://dzone.com/articles/getting-started-with-prometheus-workshop-using-adv&#34;&gt;PromQL&lt;/a&gt;.&lt;/p&gt;】&lt;p data-pm-slice=&#34;1 1 []&#34;&gt;Prometheus 是一款功能强大的监控工具，可为您的基础设施和应用程序提供广泛的指标和见解，特别是在 k8s 和 OCP（企业 k8s）中。在制作 PromQL（Prometheus 查询语言）表达式时，确保准确性和兼容性至关重要，尤其是在比较指标或计算阈值时。 &lt;/p&gt;&#xA;&lt;p data-pm-slice=&#34;1 1 []&#34;&gt;在本文中，我们将探讨如何使用 &lt;a href=&#34;https://dzone.com/articles/getting 有效地计算工作节点数量并跟踪资源变化-started-with-prometheus-workshop-using-adv&#34;&gt;PromQL&lt;/a&gt;。&lt;/p&gt;</description>
      <pubDate>Mon, 20 Jan 2025 14:00:02 +0000</pubDate>
    </item>
    <item>
      <title>【Real-Time Data Streaming With AI】人工智能实时数据流</title>
      <link>https://dzone.com/articles/real-time-data-streaming-with-ai</link>
      <description>【&lt;p&gt;Over the years, data has become more and more meaningful and powerful. Both the world and artificial intelligence move at a very quick pace. In this case, AI is very useful for implementations of real-time data use cases.&lt;/p&gt;&#xA;&lt;p&gt;Furthermore, streaming data with AI offers a competitive edge for businesses and industries. AI for real-time and streaming data analytics allows for the most current data to be managed in a timely, continuous flow, as opposed to the traditional way, with several batches of information being handled in varying intervals. Data silos with one platform for streaming and batching data are old news, and pipelines that simplify operations with automated tooling and unified governance are the way of the future.&lt;/p&gt;】&lt;p&gt;多年来，数据变得越来越有意义和强大。世界和人工智能都在快速发展。在这种情况下，人工智能对于实现实时数据用例非常有用。&lt;/p&gt;&#xA;&lt;p&gt;此外，人工智能流数据为企业和行业提供了竞争优势。用于实时和流数据分析的人工智能允许及时、连续地管理最新数据，而不是传统方式，以不同的时间间隔处理多批信息。具有一个用于流式处理和批处理数据的平台的数据孤岛已不再是新闻，而通过自动化工具和统一治理简化操作的管道才是未来的发展方向。&lt;/p&gt;</description>
      <pubDate>Mon, 20 Jan 2025 20:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Create a Custom Logger to Log Response Details With Playwright Java】使用 Playwright Java 创建自定义记录器来记录响应详细信息</title>
      <link>https://dzone.com/articles/custom-logger-playwright-java-log-response-details</link>
      <description>【&lt;p name=&#34;83d0&#34;&gt;While working on the series of tutorial blogs for GET, POST, PUT, PATCH, and DELETE requests for API Automation using Playwright Java. I noticed that there is no logging method provided by the Playwright Java framework to log the requests and responses.&lt;/p&gt;&#xA;&lt;p name=&#34;f5fb&#34;&gt;In the&lt;a data-href=&#34;https://rest-assured.io/&#34; href=&#34;https://dzone.com/articles/rest-assured-crud-framework&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt;&amp;nbsp;REST-assured&lt;/a&gt; framework, we have the &lt;code&gt;log().all()&lt;/code&gt;&lt;em&gt;&amp;nbsp;&lt;/em&gt;method available that is used for logging the request as well as the response. However, Playwright does not provide any such method. However, Playwright offers a &lt;code&gt;text()&lt;/code&gt; method in the &lt;code&gt;APIResponse&lt;/code&gt; interface that could be well used to extract the response text.&lt;/p&gt;】&lt;p name=&#34;83d0&#34;&gt;同时致力于使用 Playwright Java 编写 API 自动化的 GET、POST、PUT、PATCH 和 DELETE 请求的系列教程博客。我注意到 Playwright Java 框架没有提供记录请求和响应的日志方法。&lt;/p&gt;&#xA;&lt;p name=&#34;f5fb&#34;&gt;在&lt;a data-href=&#34;https://rest-assured.io/&#34; href=&#34;https://dzone.com/articles/rest-assured-crud-framework&#34; 相关中=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt; REST-assured&lt;/a&gt; 框架，我们有 &lt;code&gt;log().all()&lt;/code&gt;&lt;em&gt; &lt;/em&gt; 方法可用于记录请求以及 回复。然而，Playwright不提供任何这样的方法。不过，Playwright 在 &lt;code&gt;APIResponse&lt;/code&gt; 接口中提供了一个 &lt;code&gt;text()&lt;/code&gt; 方法，可以很好地用于提取响应文本。&lt;/p&gt;</description>
      <pubDate>Mon, 20 Jan 2025 19:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【How to Edit a PowerPoint PPTX Document in Java】如何用 Java 编辑 PowerPoint PPTX 文档</title>
      <link>https://dzone.com/articles/edit-a-powerpoint-pptx-document-in-java</link>
      <description>【&lt;p&gt;Building applications for programmatically editing Open Office XML (OOXML) documents like PowerPoint, Excel, and Word has never been easier to accomplish. Depending on the scope of their projects, Java developers can leverage open-source libraries in their code — or plugin-simplified API services — to manipulate content stored and displayed in the OOXML structure.&lt;/p&gt;&#xA;&lt;h2&gt;&lt;strong&gt;Introduction&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;p&gt;In this article, we’ll specifically discuss how PowerPoint Presentation XML (PPTX) files are structured, and we’ll learn the basic processes involved in navigating and manipulating PPTX content. We’ll transition into talking about a popular open-source Java library for programmatically manipulating &lt;a href=&#34;https://dzone.com/articles/how-to-convert-a-powerpoint-to-pdf-in-java&#34;&gt;PPTX files&lt;/a&gt; (specifically, replacing instances of a text string), and we’ll subsequently explore a free third-party API solution that can help simplify that process and reduce local memory consumption.&lt;/p&gt;】&lt;p&gt;构建以编程方式编辑 Open Office XML (OOXML) 文档（如 PowerPoint、Excel 和 Word）的应用程序从未如此简单。根据项目的范围，Java 开发人员可以在代码中利用开源库（或插件简化的 API 服务）来操作 OOXML 结构中存储和显示的内容。&lt;/p&gt;&#xA;&lt;h2&gt;&lt;strong&gt;简介&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;p&gt;在本文中，我们将具体讨论 PowerPoint 演示文稿 XML (PPTX) 文件的结构，并将了解导航和操作 PPTX 内容所涉及的基本过程。我们将转而讨论一个流行的开源 Java 库，用于以编程方式操作 &lt;a href=&#34;https://dzone.com/articles/how-to-convert-a-powerpoint-to-pdf-in-java&#34; &gt;PPTX 文件&lt;/a&gt;（具体来说，替换文本字符串的实例），我们随后将探索免费的第三方 API 解决方案，该解决方案可以帮助简化该过程并减少本地内存消耗。&lt;/p&gt;</description>
      <pubDate>Mon, 20 Jan 2025 18:00:08 +0000</pubDate>
    </item>
    <item>
      <title>【A Guide to Deploying AI for Real-Time Content Moderation】部署人工智能进行实时内容审核的指南</title>
      <link>https://dzone.com/articles/deploy-ai-content-moderation-system</link>
      <description>【&lt;p&gt;Content moderation is crucial for any digital platform to ensure the trust and safety of the users. While human moderation can handle some tasks, AI-driven real-time moderation becomes essential as platforms scale. Machine learning (ML) powered systems can moderate content efficiently at scale with minimal retraining and operational costs. This step-by-step guide outlines an approach to deploying an AI-powered real-time moderation system.&amp;nbsp;&lt;/p&gt;&#xA;&lt;h2&gt;Attributes of Real-Time Moderation System&lt;/h2&gt;&#xA;&lt;p data-pm-slice=&#34;1 1 []&#34;&gt;A real-time content moderation system evaluates user-submitted content — text, images, videos, or other formats — to ensure compliance with platform policies. Key attributes of an effective system include:&lt;/p&gt;】&lt;p&gt;内容审核对于任何数字平台来说都至关重要，以确保用户的信任和安全。虽然人工审核可以处理某些任务，但随着平台规模的扩大，人工智能驱动的实时审核变得至关重要。机器学习 (ML) 支持的系统可以以最小的再培训和运营成本有效地大规模管理内容。本分步指南概述了部署人工智能驱动的实时审核系统的方法。 &lt;/p&gt;&#xA;&lt;h2&gt;实时审核系统的属性&lt;/h2&gt;&#xA;&lt;p data-pm-slice=&#34;1 1 []&#34;&gt;实时内容审核系统评估用户提交的内容（文本、图像、视频或其他格式），以确保符合平台政策。有效系统的关键属性包括：&lt;/p&gt;</description>
      <pubDate>Mon, 20 Jan 2025 16:00:09 +0000</pubDate>
    </item>
    <item>
      <title>【AWS CloudTrail Insights for AWS Glue】适用于 AWS Glue 的 AWS CloudTrail 见解</title>
      <link>https://dzone.com/articles/aws-cloudtrail-insights-for-aws-glue</link>
      <description>【&lt;p data-pm-slice=&#34;1 1 []&#34;&gt;&lt;strong&gt;AWS CloudTrail Insights&lt;/strong&gt; is a part of AWS CloudTrail that always checks API activity in your AWS account to spot unusual patterns and behaviors. CloudTrail Insights helps you find potential security risks, operational oddities, or resource setup problems by looking at CloudTrail logs and pointing out differences from normal activity.&lt;/p&gt;&#xA;&lt;p&gt;For AWS Glue, &lt;a href=&#34;https://dzone.com/articles/aws-cloudtrail-vs-cloudwatch-features-amp-instruct&#34;&gt;CloudTrail Insights&lt;/a&gt; can keep an eye on:&lt;/p&gt;】&lt;p data-pm-slice=&#34;1 1 []&#34;&gt;&lt;strong&gt;AWS CloudTrail Insights&lt;/strong&gt; 是 AWS CloudTrail 的一部分，它始终检查您的 AWS 账户中的 API 活动以发现异常模式和行为。 CloudTrail Insights 通过查看 CloudTrail 日志并指出与正常活动的差异，帮助您发现潜在的安全风险、操作异常或资源设置问题。&lt;/p&gt;&#xA;&lt;p&gt;对于 AWS Glue，&lt;a href=&#34;https://dzone.com/articles/aws-cloudtrail-vs-cloudwatch-features-amp-instruct&#34;&gt;CloudTrail Insights&lt;/a&gt; 可以关注：&lt; /p&gt;</description>
      <pubDate>Mon, 20 Jan 2025 22:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Seamless Transition from Elasticsearch to OpenSearch】从 Elasticsearch 无缝过渡到 OpenSearch</title>
      <link>https://dzone.com/articles/transition-from-elasticsearch-to-opensearch</link>
      <description>【&lt;p&gt;Elasticsearch and OpenSearch are powerful tools for handling search and analytics workloads, offering scalability, real-time capabilities, and a rich ecosystem of plugins and integrations. Elasticsearch is widely used for full-text search, log monitoring, and data visualization across industries due to its mature ecosystem. OpenSearch, a community-driven fork of Elasticsearch, provides a fully open-source alternative with many of the same capabilities, making it an excellent choice for organizations prioritizing open-source principles and cost efficiency.&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Migration to &lt;a href=&#34;https://dzone.com/articles/master-observability-with-opensearch&#34;&gt;OpenSearch&lt;/a&gt; should be considered if you are using Elasticsearch versions up to 7.10 and want to avoid licensing restrictions introduced with Elasticsearch&#39;s SSPL license. It is also ideal for those seeking continued access to an open-source ecosystem while maintaining compatibility with existing &lt;a href=&#34;https://dzone.com/articles/elasticsearch-api-101&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt;Elasticsearch APIs&lt;/a&gt; and tools. Organizations with a focus on community-driven innovation, transparent governance, or cost control will find OpenSearch a compelling option.&lt;/p&gt;】&lt;p&gt;Elasticsearch 和 OpenSearch 是处理搜索和分析工作负载的强大工具，提供可扩展性、实时功能以及丰富的插件和集成生态系统。 Elasticsearch因其成熟的生态系统而被广泛应用于各行业的全文搜索、日志监控、数据可视化等领域。 OpenSearch 是社区驱动的 Elasticsearch 分支，提供了具有许多相同功能的完全开源替代方案，使其成为优先考虑开源原则和成本效率的组织的绝佳选择。 &lt;/p&gt;&#xA;&lt;p&gt;如果您使用的 Elasticsearch 版本高达 7.10 并且希望避免使用，则应考虑迁移到 &lt;a href=&#34;https://dzone.com/articles/master-observability-with-opensearch&#34;&gt;OpenSearch&lt;/a&gt; Elasticsearch 的 SSPL 许可证引入了许可限制。对于那些寻求持续访问开源生态系统同时保持与现有 &lt;a href=&#34;https://dzone.com/articles/elasticsearch-api-101&#34; rel=&#34;noopener noreferrer&#34; target=&#34; 的兼容性的人来说，它也是理想的选择_blank&#34;&gt;Elasticsearch API&lt;/a&gt; 和工具。专注于社区驱动的创新、透明治理或成本控制的组织会发现 OpenSearch 是一个引人注目的选择。&lt;/p&gt;</description>
      <pubDate>Mon, 20 Jan 2025 21:00:01 +0000</pubDate>
    </item>
  </channel>
</rss>