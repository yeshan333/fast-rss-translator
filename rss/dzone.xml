<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>DZone.com Feed</title>
    <link>https://feeds.dzone.com/home</link>
    <description>Recent posts on DZone.com</description>
    <item>
      <title>【Why the MITRE ATT&amp;amp;CK Framework Actually Works】为什么 MITRE ATT&amp;CK 框架确实有效</title>
      <link>https://dzone.com/articles/why-the-mitre-attampck-framework-actually-works</link>
      <description>【&lt;p dir=&#34;ltr&#34;&gt;The alert goes off at 2:17 p.m.&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;You count yourself lucky that this one’s in the afternoon, not morning. You drop what you’re doing, open the console, and start digging in.&lt;/p&gt;】&lt;p dir=&#34;ltr&#34;&gt;警报于下午 2:17 响起&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;你很幸运，这是在下午，而不是早上。您放下手头的事情，打开控制台，然后开始深入研究。&lt;/p&gt;</description>
      <pubDate>Fri, 21 Nov 2025 21:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Building Multimodal Agents with Google ADK — Practical Insights from My Implementation Journey】使用 Google ADK 构建多模式代理 - 来自我的实施之旅的实用见解</title>
      <link>https://dzone.com/articles/building-multimodal-agents-google-adk</link>
      <description>【&lt;p style=&#34;margin-top:0in;margin-right:0in;margin-bottom:8.0pt;margin-left:0in;line-height:115%;font-size:16px;font-family:&amp;quot;Calibri&amp;quot;,sans-serif;&#34;&gt;The landscape of AI agents is rapidly evolving, moving far beyond the early days of simple language models and retrieval-augmented generation (RAG). The diagram below depicts the evolution in the last two years:&lt;/p&gt;&#xA;&lt;figcaption class=&#34;fr-inner&#34; contenteditable=&#34;true&#34;&gt;&#xA; &lt;div style=&#34;margin-left: 280px;&#34;&gt;&#xA;  &lt;strong&gt;AI Agents Evolution&lt;/strong&gt;&#xA; &lt;/div&gt;&#xA;&lt;/figcaption&gt;&#xA;&lt;p&gt;&lt;br&gt;&lt;/p&gt;】&lt;p style=&#34;margin-top:0in;margin-right:0in;margin-bottom:8.0pt;margin-left:0in;line-height:115%;font-size:16px;font-family:&#34;Calibri&#34;,sans-serif;&#34;&gt;AI 代理的前景正在迅速发展，远远超出了早期的简单语言模型和检索增强生成 (RAG)。下图描绘了过去两年的演变：&lt;/p&gt;&#xA;&lt;figcaption class=&#34;fr-inner&#34; contenteditable=&#34;true&#34;&gt;&#xA; &lt;div style=&#34;margin-left: 280px;&#34;&gt;&#xA;  &lt;strong&gt;人工智能代理的演变&lt;/strong&gt;&#xA; &lt;/div&gt;&#xA;&lt;/图标题&gt;&#xA;&lt;p&gt;&lt;br&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 21 Nov 2025 14:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Revolutionizing Supply Chain Optimization with AI-Driven Constraint Programming】通过人工智能驱动的约束编程彻底改变供应链优化</title>
      <link>https://dzone.com/articles/revolutionizing-supply-chain-optimization-with-ai-1</link>
      <description>【&lt;p dir=&#34;ltr&#34;&gt;Optimizing the supply chain has been no easy task. Success entails making decisions on the firm&#39;s supply, production, inventory, and logistics functions, all in the real world where demand is not fixed, suppliers are not infinite, and disturbances are not rare. Conventional optimization approaches are suitable for steady-state scenarios but fail in dynamic and complex environments.&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;AI and CP are the technologies that are changing the way of supply chain management and enabling organizations to build adaptive, efficient and resilient supply networks. However, in this article I will explain how AI constraint programming works, the how of it, and how AI professionals can develop high-level applications using it.&lt;/p&gt;】&lt;p dir=&#34;ltr&#34;&gt;优化供应链并非易事。成功需要对公司的供应、生产、库存和物流功能做出决策，所有这些都是在需求不固定、供应商不是无限的、干扰并不罕见的现实世界中进行的。传统的优化方法适用于稳态场景，但在动态、复杂的环境中却失效。&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;AI 和 CP 技术正在改变供应链管理方式，使组织能够建立适应性、高效且有弹性的供应网络。不过，在本文中，我将解释人工智能约束编程的工作原理、具体原理，以及人工智能专业人员如何使用它来开发高级应用程序。&lt;/p&gt;</description>
      <pubDate>Fri, 21 Nov 2025 13:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Software Testing in the AI Era - Evolving Beyond the Pyramid】AI时代的软件测试——超越金字塔</title>
      <link>https://dzone.com/articles/software-testing-in-the-ai-era-beyond-the-pyramid-1</link>
      <description>【&lt;p dir=&#34;ltr&#34;&gt;If the 1990s was the internet era and the 2010s was the smartphones era, then it&#39;s clear that the 2020s will be defined by Large Language Models (LLMs) and AI tools. In a decade where nearly every field is being defined by advancements in AI, software testing is no exception.&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;Software testing is a fundamental building block in the foundation upon which software quality assurance is built. The development of testing techniques has a long and storied history stretching back to the early days of software development itself.&amp;nbsp;&lt;/p&gt;】&lt;p dir=&#34;ltr&#34;&gt;如果 2010 年代是互联网时代，2010 年代是智能手机时代，那么很明显，2020 年代将由大型语言模型 (LLM) 和人工智能工具定义。在这十年里，几乎每个领域都被人工智能的进步所定义，软件测试也不例外。&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;软件测试是软件质量保证的基础构建块。测试技术的发展有着悠久而传奇的历史，可以追溯到软件开发本身的早期。 &lt;/p&gt;</description>
      <pubDate>Fri, 21 Nov 2025 12:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Deploying a Serverless Application on Google Cloud】在 Google Cloud 上部署无服务器应用程序</title>
      <link>https://dzone.com/articles/deploying-serverless-application-google-cloud</link>
      <description>【&lt;p dir=&#34;ltr&#34;&gt;Deploying a serverless application is a modern approach to building scalable and cost-efficient software without managing the underlying infrastructure. This blog will walk you through the process with a practical Python example deployed on Google Cloud Functions, one of the major cloud providers offering serverless capabilities.&lt;/p&gt;&#xA;&lt;h2 dir=&#34;ltr&#34;&gt;What Is Serverless Deployment?&lt;/h2&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;Serverless deployment means that developers write code without worrying about servers or infrastructure. The cloud provider dynamically manages the resource allocation, scaling, and availability of the functions. You are billed only for the actual execution time of your code, making it highly cost-effective and efficient. Serverless architectures promote modular, event-driven development, perfect for microservices or APIs.&lt;/p&gt;】&lt;p dir=&#34;ltr&#34;&gt;部署无服务器应用程序是一种构建可扩展且经济高效的软件的现代方法，无需管理底层基础设施。本博客将通过部署在 Google Cloud Functions 上的实用 Python 示例引导您完成整个过程，Google Cloud Functions 是提供无服务器功能的主要云提供商之一。&lt;/p&gt;&#xA;&lt;h2 dir=&#34;ltr&#34;&gt;什么是无服务器部署？&lt;/h2&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;无服务器部署意味着开发人员编写代码时无需担心服务器或基础设施。云提供商动态管理资源分配、扩展和功能的可用性。您只需按代码的实际执行时间付费，这使其具有极高的成本效益和效率。无服务器架构促进模块化、事件驱动的开发，非常适合微服务或 API。&lt;/p&gt;</description>
      <pubDate>Thu, 20 Nov 2025 20:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Advanced Usage of Decodable in Swift: Handling Dynamic Keys】Swift 中 Decodable 的高级用法：处理动态键</title>
      <link>https://dzone.com/articles/advanced-decodable-swift-dynamic-keys</link>
      <description>【&lt;p dir=&#34;ltr&#34;&gt;When your backend sends responses that don&#39;t follow a consistent structure, Swift&#39;s Decodable system can begin to reveal its limitations. It expects structure. Predictability. Stability. However, real-world APIs — especially those powering social feeds, content backends, or any CMS-driven application — rarely fit that mold.&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;This article takes a look under the hood of Swift&#39;s decoding system. The goal isn&#39;t to memorize recipes, but to understand what&#39;s really happening so you can build decoding logic that scales with the unpredictable nature of your APIs.&lt;/p&gt;】&lt;p dir=&#34;ltr&#34;&gt;当您的后端发送不遵循一致结构的响应时，Swift 的 Decodable 系统可能会开始暴露其局限性。它期望结构。可预测性。稳定。然而，现实世界的 API——尤其是那些为社交源、内容后端或任何 CMS 驱动的应用程序提供支持的 API——很少符合这种模式。&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;本文将深入了解 Swift 解码系统。目标不是记住食谱，而是了解实际发生的情况，以便您可以构建可根据 API 的不可预测性进行扩展的解码逻辑。&lt;/p&gt;</description>
      <pubDate>Thu, 20 Nov 2025 19:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【The Slow/Fast Call Orchestration: Parallelizing for Perception】慢/快调用编排：并行化感知</title>
      <link>https://dzone.com/articles/slow-fast-call-orchestration-parallelization</link>
      <description>【&lt;p dir=&#34;ltr&#34;&gt;You hit “play” on a video. Seconds pass, but nothing happens — just that spinning wheel. It’s a small delay, but it feels huge.&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;Now imagine a different experience: the video starts playing almost instantly. The first few seconds are slightly lower resolution, but by the time you register it, the stream has already sharpened to full HD. On slower networks — the kind that can sustain HD once the stream stabilizes but are too sluggish to start it quickly — this change is transformative. A tiny shift in how data is delivered can completely reshape how fast the experience feels. A moment that once felt like waiting suddenly becomes a moment of progress.&lt;/p&gt;】&lt;p dir=&#34;ltr&#34;&gt;您在视频上点击了“播放”。时间一分一秒地过去了，但什么也没发生——只有那个旋转的轮子。虽然延迟很小，但感觉却很大。&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;现在想象一下不同的体验：视频几乎立即开始播放。前几秒的分辨率稍低，但当您注册时，流已经锐化为全高清。在较慢的网络上——一旦流稳定就可以维持高清但速度太慢而无法快速启动的网络——这种变化是革命性的。数据传输方式的微小转变可以彻底重塑体验的速度。曾经感觉等待的时刻突然变成了进步的时刻。&lt;/p&gt;</description>
      <pubDate>Thu, 20 Nov 2025 18:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【How I Cut Kubernetes Debugging Time by 80% With One Bash Script】我如何使用一个 Bash 脚本将 Kubernetes 调试时间减少 80%</title>
      <link>https://dzone.com/articles/cut-kubernetes-debugging-time</link>
      <description>【&lt;p&gt;Here&#39;s the truth about Kubernetes troubleshooting: 80% of your time goes into finding WHAT broke and WHERE it broke. Only 20% goes into actually fixing it. For months, I lived this reality, managing eight Kubernetes clusters. Every issue followed the same pattern: 30 minutes of kubectl detective work, five minutes to fix the actual problem. I was spending hours hunting for needles in haystacks. Then one weekend, I flipped that ratio.&lt;/p&gt;&#xA;&lt;p&gt;Every Monday at 8 AM, our team&#39;s Teams chat explodes. &#34;Hey, the dashboard is down.&#34; &#34;Perf team can&#39;t access their pods.&#34; &#34;Build agents crashed overnight.&#34;&lt;/p&gt;】&lt;p&gt;以下是有关 Kubernetes 故障排除的真相：您 80% 的时间都花在查找出现问题的内容以及出现问题的位置上。只有 20% 的人投入到实际修复中。几个月来，我一直生活在这个现实中，管理着八个 Kubernetes 集群。每个问题都遵循相同的模式：30 分钟的 kubectl 侦探工作，5 分钟修复实际问题。我花了几个小时在大海捞针。然后一个周末，我改变了这个比率。&lt;/p&gt;&#xA;&lt;p&gt;每周一上午 8 点，我们团队的 Teams 聊天都会爆发。 “哎呀，仪表板掉下来了。” “Perf 团队无法访问他们的 pod。” “构建代理一夜之间崩溃了。”&lt;/p&gt;</description>
      <pubDate>Thu, 20 Nov 2025 17:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Beyond Vector Databases: Integrating RAG as a First-Class Data Platform Workload】超越矢量数据库：将 RAG 集成为一流的数据平台工作负载</title>
      <link>https://dzone.com/articles/beyond-vector-databases-integrating-rag</link>
      <description>【&lt;p&gt;&amp;nbsp;Retrieval-augmented generation (RAG) has become critical for groundbreaking large language models (LLMs) in enterprise knowledge, yet more than half of them failed in production due to retrieval latency or data issues. The root cause isn’t the LLM or embedding model used in RAG; it is due to treating RAG as an add-on instead of an integrated RAG, where retrieval and generation evolve together.&amp;nbsp;&lt;/p&gt;&#xA;&lt;h2 dir=&#34;ltr&#34;&gt;The Production RAG Crisis&lt;/h2&gt;&#xA;&lt;h3 dir=&#34;ltr&#34;&gt;The Promise vs. Reality&lt;/h3&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;RAG is supposed to enhance the accuracy and relevance of LLMs by retrieving relevant context, augmenting the prompt, and generating grounded answers. It is designed to mitigate hallucinations, one of the most significant challenges facing large language models.&lt;/p&gt;】&lt;p&gt; 检索增强生成 (RAG) 已成为企业知识领域突破性大型语言模型 (LLM) 的关键，但其中一半以上由于检索延迟或数据问题而在生产中失败。根本原因不是LLM或RAG中使用的嵌入模型；这是由于将 RAG 视为附加组件而不是集成的 RAG，其中检索和生成一起发展。 &lt;/p&gt;&#xA;&lt;h2 dir=&#34;ltr&#34;&gt;生产 RAG 危机&lt;/h2&gt;&#xA;&lt;h3 dir=&#34;ltr&#34;&gt;承诺与现实&lt;/h3&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;RAG 旨在通过检索相关上下文、增强提示并生成有依据的答案来提高 LLM 的准确性和相关性。它旨在减轻幻觉，这是大型语言模型面临的最重大挑战之一。&lt;/p&gt;</description>
      <pubDate>Thu, 20 Nov 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Kubernetes CSI Drivers】Kubernetes CSI 驱动程序</title>
      <link>https://dzone.com/articles/kubernetes-csi-drivers</link>
      <description>【&lt;p data-end=&#34;566&#34; data-start=&#34;156&#34;&gt;In the Kubernetes ecosystem, storage has many facets. The most obvious ones are StorageClass, PersistentVolume, and PersistentVolumeClaim. We have all used them to get storage mounted to pods, but that is just the surface of how storage really gets plugged into Kubernetes pods. Beneath the PVs and PVCs lies a complex standard consisting of multiple components, and every component is crucial for it to work.&lt;/p&gt;&#xA;&lt;p data-end=&#34;1149&#34; data-start=&#34;568&#34;&gt;In this article, I am going to dive deep into how this standard works, what each component does, and build a working architecture. But first, let’s define the standard. The official definition of CSI is: a standard interface that enables container orchestration systems (like Kubernetes) to expose arbitrary storage systems to containers in a consistent way — or, as stated more formally, the Container Storage Interface (CSI) is a specification that enables storage vendors to develop plugins that expose storage systems to containerized workloads in a standardized, portable way.&lt;/p&gt;】&lt;p data-end=&#34;566&#34; data-start=&#34;156&#34;&gt;在 Kubernetes 生态系统中，存储有很多方面。最明显的是 StorageClass、PersistentVolume 和 PersistentVolumeClaim。我们都使用它们将存储安装到 Pod，但这只是存储真正插入 Kubernetes Pod 的表面。 PV 和 PVC 的背后是一个由多个组件组成的复杂标准，每个组件对于它的工作都至关重要。&lt;/p&gt;&#xA;&lt;p data-end=&#34;1149&#34; data-start=&#34;568&#34;&gt;在本文中，我将深入探讨该标准的工作原理、每个组件的作用，并构建一个工作架构。但首先，让我们定义标准。 CSI 的官方定义是：一个标准接口，使容器编排系统（如 Kubernetes）能够以一致的方式向容器公开任意存储系统 - 或者，更正式地说，容器存储接口 (CSI) 是一个规范，使存储供应商能够开发插件，以标准化、可移植的方式将存储系统公开给容器化工作负载。&lt;/p&gt;</description>
      <pubDate>Thu, 20 Nov 2025 15:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>