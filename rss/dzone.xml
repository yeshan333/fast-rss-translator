<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>DZone.com Feed</title>
    <link>https://feeds.dzone.com/home</link>
    <description>Recent posts on DZone.com</description>
    <item>
      <title>【Observability Without Cost Telemetry Is Broken Engineering】没有成本遥测的可观测性是破坏性的工程</title>
      <link>https://dzone.com/articles/observability-without-cost-telemetry-is-broken</link>
      <description>【&lt;p data-end=&#34;592&#34; data-start=&#34;288&#34;&gt;I&#39;ve run production systems where we could tell you the p99 latency of any endpoint down to the microsecond, but couldn&#39;t explain why our AWS bill jumped $40,000 in a single weekend. That disconnect — between operational visibility and financial reality — is where most observability strategies quietly fail.&lt;/p&gt;&#xA;&lt;p data-end=&#34;992&#34; data-start=&#34;594&#34;&gt;The orthodox telemetry trinity (metrics, logs, traces) gives you performance. Error rates. Request volumes. Latency distributions that let you argue about whether 250 ms is acceptable for a search API. What it won&#39;t tell you is that the microservice you just optimized for speed now costs $0.03 per invocation instead of $0.002, and at scale, that rounding error becomes someone&#39;s quarterly budget.&lt;/p&gt;】&lt;p data-end=&#34;592&#34; data-start=&#34;288&#34;&gt;我运行过生产系统，我们可以告诉您任何端点的 p99 延迟精确到微秒，但无法解释为什么我们的 AWS 账单在一个周末就上涨了 40,000 美元。运营可视性和财务现实之间的这种脱节是大多数可观察性策略悄然失败的地方。&lt;/p&gt;&#xA;&lt;p data-end=&#34;992&#34; data-start=&#34;594&#34;&gt;正统的遥测三位一体（指标、日志、跟踪）为您提供性能。错误率。请求卷。延迟分布让您可以争论搜索 API 是否可以接受 250 毫秒。它不会告诉您的是，您刚刚针对速度进行优化的微服务现在每次调用的成本为 0.03 美元，而不是 0.002 美元，并且在规模上，该舍入误差将成为某人的季度预算。&lt;/p&gt;</description>
      <pubDate>Fri, 20 Feb 2026 20:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【From Command Lines to Intent Interfaces: Reframing Git Workflows Using Model Context Protocol】从命令行到意图接口：使用模型上下文协议重构 Git 工作流程</title>
      <link>https://dzone.com/articles/from-command-lines-to-intent-interfaces-reframing-git</link>
      <description>【&lt;p data-end=&#34;949&#34; data-start=&#34;153&#34;&gt;My recent journey into agentic developer systems has been driven by a desire to understand how AI moves from passive assistance to active participation in software workflows. In an earlier article, &lt;a href=&#34;https://dzone.com/articles/ai-cocreation-developer-debugging-workflows&#34;&gt;AI Co-creation in Developer Debugging Workflows&lt;/a&gt;, I explored how developers and AI systems collaboratively reason about code. As I went deeper into this space, I came across the &lt;a href=&#34;https://dzone.com/articles/model-context-protocol-mcp-guide-architecture-uses-implementation&#34;&gt;Model Context Protocol (MCP)&lt;/a&gt; and became keen to understand what this component is and why it is important. I noticed that MCP was frequently referenced in discussions about agentic systems, yet rarely explained in a concrete, developer-centric way. This article is a direct outcome of that learning process, using a practical Git workflow example to clarify the role and value of MCP in intent-driven developer tooling.&lt;/p&gt;&#xA;&lt;h2 data-end=&#34;976&#34; data-start=&#34;951&#34;&gt;What Is an MCP Server?&lt;/h2&gt;&#xA;&lt;p data-end=&#34;1282&#34; data-start=&#34;978&#34;&gt;At a conceptual level, an MCP server acts as a control plane between an AI assistant and external systems. Rather than allowing an LLM to issue arbitrary API calls, the MCP server implements the Model Context Protocol and exposes a constrained, well-defined set of capabilities that the model can invoke.&lt;/p&gt;】&lt;p data-end=&#34;949&#34; data-start=&#34;153&#34;&gt;我最近进入代理开发系统的原因是希望了解人工智能如何从被动协助转变为主动参与软件工作流程。在之前的文章&lt;a href=&#34;https://dzone.com/articles/ai-cocreation-developer-debugging-workflows&#34;&gt;开发人员调试工作流程中的 AI 共同创建&lt;/a&gt;中，我探讨了开发人员和 AI 系统如何协作推理代码。当我深入这个领域时，我遇到了&lt;a href=&#34;https://dzone.com/articles/model-context-protocol-mcp-guide-architecture-uses-implementation&#34;&gt;模型上下文协议（MCP）&lt;/a&gt;，并开始热衷于了解这个组件是什么以及它为何如此重要。我注意到 MCP 在有关代理系统的讨论中经常被引用，但很少以具体的、以开发人员为中心的方式进行解释。本文是该学习过程的直接成果，使用实用的 Git 工作流程示例来阐明 MCP 在意图驱动的开发人员工具中的作用和价值。&lt;/p&gt;&#xA;&lt;h2 data-end=&#34;976&#34; data-start=&#34;951&#34;&gt;什么是 MCP 服务器？&lt;/h2&gt;&#xA;&lt;p data-end=&#34;1282&#34; data-start=&#34;978&#34;&gt;在概念层面上，MCP 服务器充当 AI 助手和外部系统之间的控制平面。 MCP 服务器不是允许 LLM 发出任意 API 调用，而是实现模型上下文协议并公开模型可以调用的一组受约束的、定义良好的功能。&lt;/p&gt;</description>
      <pubDate>Fri, 20 Feb 2026 19:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【The Missing Primitive in Data Platforms: Agent Contracts for Tool Calls】数据平台中缺失的原语：工具调用的代理合约</title>
      <link>https://dzone.com/articles/missing-primitive-in-data-platforms-agent-contracts</link>
      <description>【&lt;p data-end=&#34;672&#34; data-start=&#34;208&#34;&gt;Analytics agents are moving from answering questions to doing things — running SQL, resolving metrics, fetching lineage, creating exports, and triggering workflows. This shift breaks a common assumption in &lt;a href=&#34;https://dzone.com/articles/genai-prompt-to-production&#34;&gt;GenAI projects&lt;/a&gt;: that production will be fine if the agent’s prompt is good. In reality, once an agent can call tools, you are operating a distributed system whose behavior can drift with every model upgrade, prompt change, routing adjustment, or schema change.&lt;/p&gt;&#xA;&lt;p data-end=&#34;1214&#34; data-start=&#34;674&#34;&gt;Most teams respond by adding a few guardrails, tuning prompts, or rate-limiting tool access. That helps, but it doesn’t address the failure mode that matters most in data platforms: the same question leading to different tool behavior over time. A small change can turn a safe metric lookup into raw SQL, increasing retries and introducing silent correctness drift without any explicit error. Traditional data platforms solved this problem with data contracts, which consist of SLOs, explicit interfaces, controlled rollouts, and ownership.&lt;/p&gt;】&lt;p data-end=&#34;672&#34; data-start=&#34;208&#34;&gt;分析代理正在从回答问题转向执行操作 - 运行 SQL、解析指标、获取沿袭、创建导出和触发工作流程。这种转变打破了 GenAI 项目中的一个常见假设：如果代理的提示良好，那么生产就会很好。实际上，一旦代理可以调用工具，您就正在操作一个分布式系统，其行为可能会随着每次模型升级、提示更改、路由调整或架构更改而发生变化。&lt;/p&gt;&#xA;&lt;p data-end=&#34;1214&#34; data-start=&#34;674&#34;&gt;大多数团队通过添加一些护栏、调整提示或速率限制工具访问来做出响应。这有帮助，但它并没有解决数据平台中最重要的故障模式：随着时间的推移，同一问题会导致不同的工具行为。一个小小的改变就可以将安全的指标查找变成原始 SQL，增加重试次数并引入静默的正确性漂移，而不会出现任何显式错误。传统数据平台通过数据契约解决了这个问题，数据契约由 SLO、显式接口、受控部署和所有权组成。&lt;/p&gt;</description>
      <pubDate>Fri, 20 Feb 2026 18:00:10 +0000</pubDate>
    </item>
    <item>
      <title>【Amazon Q Developer for AI Infrastructure: Architecting Automated ML Pipelines】适用于 AI 基础设施的 Amazon Q 开发人员：构建自动化 ML 管道</title>
      <link>https://dzone.com/articles/amazon-q-developer-for-ai-infrastructure-ml</link>
      <description>【&lt;p data-end=&#34;737&#34; data-start=&#34;244&#34;&gt;The landscape of &lt;a href=&#34;https://dzone.com/articles/mlops-best-practices-for-deployment&#34;&gt;Machine Learning Operations (MLOps)&lt;/a&gt; is shifting from manual configuration to AI-driven orchestration. As organizations scale their AI initiatives, the bottleneck is rarely the model architecture itself, but rather the underlying infrastructure required to train, deploy, and monitor these models at scale. Amazon Q Developer, a generative AI–powered assistant, has emerged as a critical tool for architects and engineers looking to automate the lifecycle of AI infrastructure.&lt;/p&gt;&#xA;&lt;p data-end=&#34;1292&#34; data-start=&#34;739&#34;&gt;Traditionally, setting up a robust ML pipeline involved complex &lt;a href=&#34;https://dzone.com/articles/infrastructure-as-code-iac-beyond-the-basics&#34;&gt;Infrastructure as Code (IaC)&lt;/a&gt;, intricate IAM permissioning, and manual tuning of compute resources like NVIDIA H100s or AWS Trainium. Amazon Q Developer streamlines this by translating high-level architectural requirements into production-ready scripts, optimizing resource allocation, and troubleshooting connectivity issues within the AWS ecosystem. This article explores the technical architecture of using Amazon Q for ML infrastructure and provides practical implementation strategies.&lt;/p&gt;】&lt;p data-end=&#34;737&#34; data-start=&#34;244&#34;&gt;&lt;a href=&#34;https://dzone.com/articles/mlops-best-practices-for-deployment&#34;&gt;机器学习操作 (MLOps)&lt;/a&gt; 正在从手动配置转向 AI 驱动的编排。随着组织扩展其人工智能计划，瓶颈很少不是模型架构本身，而是大规模训练、部署和监控这些模型所需的底层基础设施。 Amazon Q Developer 是一款基于 AI 的生成助手，已成为寻求自动化 AI 基础设施生命周期的架构师和工程师的重要工具。&lt;/p&gt;&#xA;&lt;p data-end=&#34;1292&#34; data-start=&#34;739&#34;&gt;传统上，建立强大的机器学习管道涉及复杂的&lt;a href=&#34;https://dzone.com/articles/infrastruct-as-code-iac-beyond-the-basics&#34;&gt;基础设施即代码 (IaC)&lt;/a&gt;、复杂的 IAM 权限以及对 NVIDIA H100s 或 AWS Trainium 等计算资源的手动调整。 Amazon Q Developer 通过将高级架构要求转换为生产就绪脚本、优化资源分配以及解决 AWS 生态系统内的连接问题来简化这一过程。本文探讨了使用 Amazon Q 进行 ML 基础设施的技术架构并提供了实用的实施策略。&lt;/p&gt;</description>
      <pubDate>Fri, 20 Feb 2026 17:00:01 +0000</pubDate>
    </item>
    <item>
      <title>【Architecting Zero-Trust Database Access in Kubernetes With Vault Dynamic Secrets】使用 Vault 动态机密在 Kubernetes 中构建零信任数据库访问</title>
      <link>https://dzone.com/articles/zero-trust-db-access-kubernetes-vault</link>
      <description>【&lt;h2&gt;The Death of the Static Credential: An Operational Imperative&lt;/h2&gt;&#xA;&lt;p data-path-to-node=&#34;6&#34;&gt;In modern software architecture, speed is the primary driver of innovation. We deploy faster and scale wider, yet this velocity introduces a parallel vector of risk: complexity. Amidst this, one vulnerability remains persistently simple: the static database credential.&lt;/p&gt;&#xA;&lt;p data-path-to-node=&#34;7&#34;&gt;For decades, the &#34;database password&#34; was a fixed artifact. In the monolithic era, this was manageable. In the era of Kubernetes and ephemeral infrastructure, it is a liability. &lt;a href=&#34;https://dzone.com/articles/zero-trust-ci-cd-secure-pipelines&#34;&gt;Zero trust&lt;/a&gt; is now an architectural mandate: trust is never granted implicitly based on network location. In the database layer, this necessitates the elimination of &#34;standing privileges.&#34;&lt;/p&gt;】&lt;h2&gt;静态凭证的消亡：操作上的当务之急&lt;/h2&gt;&#xA;&lt;p data-path-to-node=&#34;6&#34;&gt;在现代软件架构中，速度是创新的主要驱动力。我们部署得更快，规模更广，但这种速度引入了并行的风险向量：复杂性。其中，有一个漏洞始终很简单：静态数据库凭据。&lt;/p&gt;&#xA;&lt;p data-path-to-node=&#34;7&#34;&gt;几十年来，“数据库密码”一直是一个固定的工件。在整体时代，这是可以管理的。在 Kubernetes 和临时基础设施时代，这是一种负担。 &lt;a href=&#34;https://dzone.com/articles/zero-trust-ci-cd-secure-pipelines&#34;&gt;零信任&lt;/a&gt;现在是一项架构要求：永远不会根据网络位置隐式授予信任。在数据库层，这需要消除“常设特权”。&lt;/p&gt;</description>
      <pubDate>Fri, 20 Feb 2026 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Hurley: A High-Performance HTTP Client and Load Testing Tool Engineered in Rust】Hurley：用 Rust 设计的高性能 HTTP 客户端和负载测试工具</title>
      <link>https://dzone.com/articles/hurley-http-client-load-testing-rust</link>
      <description>【&lt;h2 data-selectable-paragraph=&#34;&#34;&gt;Introduction and Motivation&lt;/h2&gt;&#xA;&lt;p&gt;This article examines the technical architecture, capabilities, and use cases of hurley, a project developed in Rust that functions as both a general-purpose HTTP client and a performance testing tool. It explores the efficiency advantages gained by managing API testing and performance analysis through a unified tool within software development processes.&lt;/p&gt;&#xA;&lt;p data-selectable-paragraph=&#34;&#34;&gt;With the proliferation of microservices architectures and distributed systems, communication via the HTTP protocol has become the lifeblood of the software ecosystem. In this context, developers face two fundamental needs: (1) A flexible HTTP client to verify the functional correctness of API endpoints, and (2) Performance testing tools to analyze system behavior under load.&lt;/p&gt;】&lt;h2 data-selectable-paragraph=&#34;&#34;&gt;介绍和动机&lt;/h2&gt;&#xA;&lt;p&gt;本文探讨了 hurley 的技术架构、功能和用例，这是一个用 Rust 开发的项目，既充当通用 HTTP 客户端又充当性能测试工具。它探讨了通过软件开发流程中的统一工具管理 API 测试和性能分析所获得的效率优势。&lt;/p&gt;&#xA;&lt;p data-selectable-paragraph=&#34;&#34;&gt;随着微服务架构和分布式系统的激增，通过 HTTP 协议进行通信已成为软件生态系统的命脉。在此背景下，开发人员面临两个基本需求：(1) 灵活的 HTTP 客户端，用于验证 API 端点的功能正确性；(2) 性能测试工具，用于分析负载下的系统行为。&lt;/p&gt;</description>
      <pubDate>Fri, 20 Feb 2026 15:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Why End-to-End Testing Fails in Microservice Architectures】为什么微服务架构中的端到端测试失败</title>
      <link>https://dzone.com/articles/end-to-end-testing-fails-microservices</link>
      <description>【&lt;p&gt;End-to-end testing is often described as the ultimate safety net for modern software systems. In theory, it validates real user workflows across all components and ensures that the system behaves correctly as a whole.&lt;/p&gt;&#xA;&lt;p&gt;In practice, however, end-to-end testing frequently fails to deliver reliable value in microservice architectures. Teams invest heavily in E2E suites, only to face slow pipelines, flaky tests, and low confidence in test results.&lt;/p&gt;】&lt;p&gt;端到端测试通常被描述为现代软件系统的终极安全网。理论上，它验证所有组件的真实用户工作流程，并确保系统作为一个整体正确运行。&lt;/p&gt;&#xA;&lt;p&gt;然而，在实践中，端到端测试经常无法在微服务架构中提供可靠的价值。团队在 E2E 套件上投入巨资，却面临着缓慢的管道、不稳定的测试以及对测试结果信心度低的问题。&lt;/p&gt;</description>
      <pubDate>Fri, 20 Feb 2026 14:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【A Unified Defense Against MITRE’s Top Injection Attacks】针对 MITRE 顶级注入攻击的统一防御</title>
      <link>https://dzone.com/articles/go-safeinput-mitre-injection-defense</link>
      <description>【&lt;p data-selectable-paragraph=&#34;&#34;&gt;This is how I created a Go library to address 41 actively exploited vulnerabilities.&lt;/p&gt;&lt;/h2&gt;&#xA;&lt;/figure&gt;&#xA;&lt;h2 data-selectable-paragraph=&#34;&#34;&gt;The Problem That Keeps Security Teams Up at Night&lt;/h2&gt;&#xA;&lt;p data-selectable-paragraph=&#34;&#34;&gt;On December 11, 2025, MITRE released its annual &lt;a href=&#34;https://cwe.mitre.org/top25/archive/2025/2025_cwe_top25.html&#34; rel=&#34;noopener ugc nofollow&#34; target=&#34;_blank&#34;&gt;2025 CWE Top 25 Most Dangerous Software Weaknesses&lt;/a&gt; list, analyzing 39,080 CVE records from the past year. The results should concern every developer.&lt;/p&gt;】&lt;p data-selectable-paragraph=&#34;&#34;&gt;这就是我创建 Go 库来解决 41 个被主动利用的漏洞的方法。&lt;/p&gt;&lt;/h2&gt;&#xA;&lt;/图&gt;&#xA;&lt;h2 data-selectable-paragraph=&#34;&#34;&gt;让安全团队夜不能寐的问题&lt;/h2&gt;&#xA;&lt;p data-selectable-paragraph=&#34;&#34;&gt;2025 年 12 月 11 日，MITRE 发布了年度&lt;a href=&#34;https://cwe.mitre.org/top25/archive/2025/2025_cwe_top25.html&#34; rel=&#34;noopener ugc nofollow&#34; target=&#34;_blank&#34;&gt;2025 年 CWE 25 个最危险软件弱点&lt;/a&gt;列表，分析了去年的 39,080 条 CVE 记录。结果应该引起每个开发人员的关注。&lt;/p&gt;</description>
      <pubDate>Fri, 20 Feb 2026 13:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Queueing Theory for LLM Inference】LLM 推理的排队论</title>
      <link>https://dzone.com/articles/queueing-theory-for-llm-inference</link>
      <description>【&lt;p&gt;If you are deploying LLM inference in production, you are no longer just doing machine learning. You are doing applied mathematics plus systems engineering.&lt;/p&gt;&#xA;&lt;p&gt;Most teams tune prompts, choose a model, then wonder why latency explodes at peak traffic. The root cause is usually not the model. It is load, variability, and the queue that forms when the arrival rate approaches the service capacity.&lt;/p&gt;】&lt;p&gt;如果您在生产中部署 LLM 推理，那么您不再只是在进行机器学习。您正在研究应用数学和系统工程。&lt;/p&gt;&#xA;&lt;p&gt;大多数团队会调整提示、选择模型，然后想知道为什么延迟会在高峰流量时激增。根本原因通常不是模型。是负载、可变性以及到达率接近服务能力时形成的队列。&lt;/p&gt;</description>
      <pubDate>Fri, 20 Feb 2026 12:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【From Prompts to Platforms: Scaling Agentic AI (Part 2)】从提示到平台：扩展 Agentic AI（第 2 部分）</title>
      <link>https://dzone.com/articles/from-prompts-to-platforms-scaling-agentic-ai-part</link>
      <description>【&lt;p data-end=&#34;469&#34; data-start=&#34;148&#34;&gt;The &lt;a href=&#34;https://dzone.com/articles/scaling-agentic-ai-platforms&#34;&gt;tenets I introduced in Part 1&lt;/a&gt; covered the functional mechanics — the core features that power an AI platform. But in production, functionality is only half the battle. These next six Operational Tenets are about how the platform survives the chaos of the real world and scales without breaking under its own complexity.&lt;/p&gt;&#xA;&lt;p data-end=&#34;538&#34; data-start=&#34;471&#34;&gt;Here are the pillars critical to operating an AI platform at scale:&lt;/p&gt;】&lt;p data-end=&#34;469&#34; data-start=&#34;148&#34;&gt;我在第 1 部分中介绍的原则&lt;/a&gt;涵盖了功能机制 - 为 AI 平台提供动力的核心功能。但在生产中，功能只是成功的一半。接下来的六个运营原则是关于平台如何在现实世界的混乱中生存并在不打破自身复杂性的情况下进行扩展。&lt;/p&gt;&#xA;&lt;p data-end=&#34;538&#34; data-start=&#34;471&#34;&gt;以下是大规模运营 AI 平台的关键支柱：&lt;/p&gt;</description>
      <pubDate>Thu, 19 Feb 2026 20:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>