<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>DZone.com Feed</title>
    <link>https://feeds.dzone.com/home</link>
    <description>Recent posts on DZone.com</description>
    <item>
      <title>【90% Cost Reduction With Prefix Caching for LLMs】LLM的前缀缓存90％降低成本</title>
      <link>https://dzone.com/articles/ninety-cost-reduction-prefix-caching-llms</link>
      <description>【&lt;p style=&#34;text-align: right;&#34;&gt;&lt;em&gt;Do you know there’s a technique by which you could slash your LLM inference cost by up to 90%? Prefix caching is the idea that could save your application those much needed dollars. A game changing optimization technique that is not just for giants like Anthropic but also available to anyone using open- source LLMs.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;Let&#39;s pull back the curtain on this technique!&lt;/p&gt;】&lt;p style =“ text-align：对;”&gt; &lt;em&gt;您知道有一种技术可以将LLM推理成本削减多达90％吗？前缀缓存是可以节省您急需的美元的想法。一种更改优化技术的游戏，不仅适用于诸如人类之类的巨人，还适用于使用Open-Source LLM的任何人。&lt;/em&gt; &lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;让我们在此技术上拉回窗帘！&lt;/p&gt;</description>
      <pubDate>Mon, 03 Feb 2025 15:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Java Stream API: 3 Things Every Developer Should Know About】Java Stream API：每个开发人员应该知道的3件事</title>
      <link>https://dzone.com/articles/java-stream-api-things-developer-should-know</link>
      <description>【&lt;p dir=&#34;ltr&#34;&gt;Time flies! I remember the time when Java 8 was such a reference, and everybody was talking about it like something new and revolutionary. Frankly speaking, it was new and revolutionary. But now, projects using Java 8 might be labeled &#34;legacy.&#34; If Java 8 itself became a legacy, the features introduced in that version would still be actual. And let’s talk today about one of them — Stream API.&amp;nbsp;&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;In case you don’t know, &lt;a href=&#34;https://dzone.com/articles/overview-of-java-stream-api-extensions&#34;&gt;Java Stream API&lt;/a&gt; is a powerful tool that allows programmers to write Java code in a functional programming style. Introduced long ago, it makes working with collections easier by enabling filtering, transformation, and aggregation.&amp;nbsp;&lt;/p&gt;】&lt;p dir =“ ltr”&gt;时间飞飞！我记得Java 8是这样的参考时间，每个人都在谈论它，就像新事物和革命性的东西一样。坦率地说，这是新颖而革命性的。但是现在，使用Java 8的项目可能被标记为“遗产”。如果Java 8本身成为遗产，那么该版本中引入的功能仍然是实际的。今天让我们谈谈其中一个 - 流API。 &lt;/p&gt;&#xA;&lt;p dir =“ ltr”&gt;如果您不知道，&lt;a href =” https://dzone.com/articles/overview-ob-java-java-stream-api-extensions&#39;&gt; java stream api &lt;/a &gt;是一个强大的工具，允许程序员以功能编程样式编写Java代码。很久以前引入，它通过启用过滤，转换和聚合使收集工作变得更加容易。 &lt;/p&gt;</description>
      <pubDate>Mon, 03 Feb 2025 20:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Building a Full-Stack Resume Screening Application With AI】使用AI构建全栈简历筛选应用</title>
      <link>https://dzone.com/articles/smarter-hiring-building-an-ai-powered-full-stack-r</link>
      <description>【&lt;p&gt;The release of the DeepSeek open-source AI model has created a lot of excitement in the technology community. It allows developers to build applications entirely locally without needing to connect to online AI models such as Claude, ChatGPT, and more. Open-source models have opened doors to new opportunities when building enterprise applications that integrate with generative AI.&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;In this article, you will learn how to run such a model locally on your personal machine and build a full-stack &lt;a href=&#34;https://dzone.com/articles/advanced-react-js-concepts-a-deep-dive&#34;&gt;React&lt;/a&gt; and &lt;a href=&#34;https://dzone.com/articles/a-comprehensive-exploration-of-nodejs-a-practical&#34;&gt;NodeJS-powered&lt;/a&gt; application that is not just another chatbot. You will be able to use this application to analyze resumes faster and make smarter hiring decisions. Before you build the application, it is important to understand the benefits of open-source LLMs.&lt;/p&gt;】&lt;p&gt; DeepSeek开源AI模型的发布在技术界引起了很多兴奋。它允许开发人员完全在本地构建应用程序，而无需连接到在线AI模型（例如Claude，Chatgpt等）。开源模型在构建与生成AI集成的企业应用程序时为新机会打开了大门。 &lt;/p&gt;&#xA;&lt;p&gt;在本文中，您将学习如何在个人机器上本地运行这样的模型并构建全堆栈&lt;a href =“ https://dzone.com/articles/advanced-react-react-js-concepts--concepts--concepts- a-deep-dive“&gt; react &lt;/a&gt;和&lt;a href =” https://dzone.com/articles/a-comprehand--comprehend-ecploration-ecploration-ecploration-of-nodejs-a-practical&gt; nodejs-powered &lt;/a&gt;应用程序不仅仅是另一个聊天机器人。您将能够使用此应用程序来更快地分析简历并做出更明智的招聘决定。在构建应用程序之前，重要的是要了解开源LLM的好处。&lt;/p&gt;</description>
      <pubDate>Mon, 03 Feb 2025 22:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Managing Distributed System Locks With Azure Storage】使用Azure存储管理分布式系统锁</title>
      <link>https://dzone.com/articles/locks-in-distributed-systems-timeout-lease-based</link>
      <description>【&lt;p&gt;Distributed systems have been there for a while now and there are well-known patterns already established when designing them. Today, we will discuss one of the popular patterns: &#34;locks.&#34;&lt;/p&gt;&#xA;&lt;p&gt;Simply put, &lt;a href=&#34;https://dzone.com/articles/everything-i-know-about-distributed-locks&#34;&gt;locks&lt;/a&gt; are how processes gain exclusive access to a resource to perform a certain action. For example, imagine there are a bunch of Blobs in a storage account, and you need one instance of your service to process each blob to avoid duplicate processing. The way to do it would be to acquire a lock on the blob, complete processing, and release it. &amp;nbsp;However, a potential issue arises if a process fails before releasing the lock, either because the process died or due to a network partition, leaving the resource locked indefinitely. This can lead to deadlocks and resource contention.&amp;nbsp;&lt;/p&gt;】&lt;p&gt;分布式系统现在已经存在了一段时间，并且在设计它们时已经建立了众所周知的模式。今天，我们将讨论一种流行的模式：“锁”。&lt;/p&gt;&#xA;&lt;p&gt;简单地说，&lt;a href =“ https://dzone.com/articles/everything-i--know-i--------- know-about-distribed-locks”&gt;锁&lt;/a&gt;是流程如何获得对资源的独特访问来执行的方式一定的动作。例如，想象一下存储帐户中有很多斑点，您需要一个服务的实例来处理每个斑点以避免重复处理。这样做的方法是在斑点上获取锁，完成处理并释放它。  但是，如果一个过程在发布锁之前失败，则会出现潜在的问题，要么是因为该过程死亡或由于网络分区而导致，因此资源无限期地锁定。这可能导致僵局和资源争夺。 &lt;/p&gt;</description>
      <pubDate>Mon, 03 Feb 2025 18:00:12 +0000</pubDate>
    </item>
    <item>
      <title>【Best Practices for API Rate Limits and Quotas】API费率限制和配额的最佳实践</title>
      <link>https://dzone.com/articles/api-rate-limits-and-quotas-best-practices</link>
      <description>【&lt;p&gt;Like any online service, your API users expect high availability and good performance. This also means one customer should not be able to starve another customer&#39;s access to your API. Adding rate limiting is a defensive measure that can protect your API from being overwhelmed with requests and improve general availability.&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Similarly, adding quota management also ensures customers stay within their contract terms and obligations, ensuring you&#39;re able to monetize your API. This is even more important for Data and GenAI APIs, where the cost of an API can be high and part of your COGS (Cost of Goods Sold). Without quota management, a customer could easily use far more resources than their plan allows, even if they stay within your overall server rate limits.&amp;nbsp;&lt;/p&gt;】&lt;p&gt;像任何在线服务一样，您的API用户期望可以高可用性和良好的性能。这也意味着一个客户应该无法饿死另一个客户对您的API的访问。增加速率限制是一种防御措施，可以保护您的API免受请求不知所措并提高一般可用性。 &lt;/p&gt;&#xA;&lt;p&gt;同样，添加配额管理还确保客户保持其合同条款和义务，以确保您能够将API获利。这对于数据和Genai API来说更为重要，在该数据中，API的成本可能很高，并且是您的COG的一部分（出售商品成本）。如果没有配额管理，即使客户保持在您的整体服务器速率限制范围内，客户也可以轻松地使用远远超过计划所允许的资源。 &lt;/p&gt;</description>
      <pubDate>Mon, 03 Feb 2025 19:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Exploring the Purpose of Pytest Fixtures: A Practical Guide】探索Pytest固定装置的目的：实用指南</title>
      <link>https://dzone.com/articles/purpose-of-pytest-fixtures-guide</link>
      <description>【&lt;p&gt;To set the groundwork for this article, let&#39;s first understand what Pytest is.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://docs.pytest.org/en/stable/getting-started.html&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt;Pytest&lt;/a&gt; is a popular testing framework for Python that simplifies the process of writing scalable and maintainable test cases. It supports fixtures, parameterized testing, and detailed test reporting, making it a powerful choice for both unit and functional testing. Pytest&#39;s simplicity and flexibility have made it a go-to framework for developers and testers alike.&lt;/p&gt;】&lt;p&gt;要为本文设定基础，让我们首先了解什么是Pytest。&lt;/p&gt;&#xA;&lt;p&gt; &lt;a href =“ https://docs.pytest.org/en/stable/getting-started.html” rel =“ noopener noreferrer” target =“ _ blank”&gt; pytest &lt;/a&gt;是一个受欢迎的测试框架对于Python来说，简化了编写可扩展和可维护的测试用例的过程。它支持固定装置，参数化测试和详细的测试报告，使其成为单元和功能测试的有力选择。 Pytest的简单性和灵活性使其成为开发人员和测试人员的首选框架。&lt;/p&gt;</description>
      <pubDate>Mon, 03 Feb 2025 21:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Building Neural Networks With Automatic Differentiation】建立具有自动差异化的神经网络</title>
      <link>https://dzone.com/articles/build-neural-networks-automatic-differentiation</link>
      <description>【&lt;p dir=&#34;ltr&#34;&gt;One of the biggest reasons for the fast pace of research and progress in modern AI is due to the availability of Python libraries such as PyTorch, TensorFlow, and JAX. Python itself is considered one of the easiest programming languages to pick up, and these ML/DeepLearning libraries make prototyping and testing sophisticated ML models much more accessible to engineers, researchers, and even enthusiasts.&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;One key idea &lt;span style=&#34;margin: 0px; padding: 0px;&#34;&gt;that has driven tremendous success in training large ML and neural network models is&lt;span style=&#34;margin: 0px; padding: 0px;&#34;&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&#34;https://dzone.com/articles/accelerated-automatic-differentiation-with-jax-how&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt;automatic differentiation&lt;/a&gt;&lt;/span&gt; (AD). It is the mechanism that enables backpropagation in neural networks. The main idea behind AD is to recursively calculate the partial derivatives (using the chain rule) for a neural network, which is represented as a directed acyclic graph (DAG). It’s a simple technique but very powerful.&amp;nbsp;&lt;/p&gt;】&lt;p dir =“ ltr”&gt;在现代AI中快速发展和进步的最大原因之一是由于Pytorch，Tensorflow和Jax等Python库的可用性。 Python本身被认为是最简单的编程语言之一，这些ML/深度学习库使工程师，研究人员甚至发烧友更容易访问原型和测试复杂的ML模型。&lt;/p&gt;&#xA;&lt;p dir =“ ltr”&gt;一个关键思想&lt;span style =“ margin：0px; padding：0px;“&gt;在训练大型ML和神经网络模型中取得了巨大成功的成功率是&lt;span style =” Margin; 0px; Padding ：0px;“&gt; &lt;/span&gt; &lt;a href =” https://dzone.com/articles/accelerated-automation-differentiation-with-jax-how“ rel =” noopener noreferrer“ noopener noreferrer” target =“ _ blank”&gt;自动差异&lt;/a&gt; &lt;/span&gt;（ad）。这是能够在神经网络中进行反向传播的机制。 AD背后的主要思想是递归计算神经网络的部分衍生物（使用链条规则），该网络表示为有向的无环图（DAG）。这是一种简单的技术，但非常强大。 &lt;/p&gt;</description>
      <pubDate>Mon, 03 Feb 2025 14:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【MuleSoft OAuth 2.0 Provider: Password Grant Type】Mulesoft Oauth 2.0提供商：密码授予类型</title>
      <link>https://dzone.com/articles/mulesoft-oauth-2-0-password-grant</link>
      <description>【&lt;p dir=&#34;ltr&#34;&gt;OAuth 2.0 is a widely used authorization framework that allows third-party applications to access user resources on a resource server without sharing the user&#39;s credentials.&amp;nbsp;&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;The Password Grant type, also known as Resource Owner Password Credentials Grant, is a specific authorization grant defined in the &lt;a href=&#34;https://dzone.com/articles/oauth-20-beginners-guide&#34;&gt;OAuth 2.0 specification&lt;/a&gt;. It&#39;s particularly useful in scenarios where the client application is highly trusted and has a direct relationship with the user (e.g., a native mobile app or a first-party web application). This grant type allows the client to request an access token by directly providing the user&#39;s username and password to the authorization server. While convenient, it&#39;s crucial to implement this grant type securely, as it involves handling sensitive user credentials.&amp;nbsp;&lt;/p&gt;】&lt;p dir =“ ltr”&gt; oauth 2.0是一个广泛使用的授权框架，允许第三方应用程序访问资源服务器上的用户资源，而无需共享用户的凭据。 &lt;/p&gt;&#xA;&lt;p dir =“ ltr”&gt;密码授予类型，也称为资源所有者密码凭据授予，是&lt;a href =“ https://dzone.com/articles/oauth-20-beginners中定义的特定授权赠款 - 指导“&gt; OAuth 2.0规格&lt;/a&gt;。在客户端应用程序高度信任并且与用户有直接关系的情况下（例如，本机移动应用程序或第一方Web应用程序），它特别有用。此赠款类型允许客户端通过直接将用户的用户名和密码提供给授权服务器来请求访问令牌。尽管方便，但要安全地实施此赠款类型至关重要，因为它涉及处理敏感的用户凭证。 &lt;/p&gt;</description>
      <pubDate>Mon, 03 Feb 2025 17:00:06 +0000</pubDate>
    </item>
    <item>
      <title>【Building RAG Apps With Apache Cassandra, Python, and Ollama】使用Apache Cassandra，Python和Ollama构建抹布应用程序</title>
      <link>https://dzone.com/articles/build-rag-apps-apache-cassandra-python-ollama</link>
      <description>【&lt;p&gt;Retrieval-augmented generation (RAG) is the most popular approach for obtaining real-time data or updated data from a data source based on text input by users. Thus empowering all our search applications with state-of-the-art neural search.&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;In RAG search systems, each user request is converted into a vector representation by embedding model, and this vector comparison is performed using various algorithms such as cosine similarity, longest common sub-sequence, etc., with existing vector representations stored in our vector-supporting database.&lt;/p&gt;】&lt;p&gt;检索增强的生成（RAG）是根据用户的文本输入从数据源中获取实时数据或更新数据的最流行方法。因此，通过最先进的神经搜索赋予我们所有搜索应用程序的能力。 &lt;/p&gt;&#xA;&lt;p&gt;在抹布搜索系统中，每个用户请求都通过嵌入模型转换为向量表示，并且使用各种算法（例如余弦相似性，最长的常见子序列等）进行此矢量比较，并将现有的向量表示存储在我们的矢量支持数据库。&lt;/p&gt;</description>
      <pubDate>Mon, 03 Feb 2025 13:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【All You Need to Know About Apache Spark】您需要了解的有关Apache Spark</title>
      <link>https://dzone.com/articles/apache-spark-all-you-need-to-know</link>
      <description>【&lt;p data-selectable-paragraph=&#34;&#34;&gt;Apache Spark is a general-purpose and lightning-quick cluster computing framework and an open-source technology based on a wide range of data processing platforms. Moreover, it reveals development APIs that succeed data workers in achieving streaming, machine learning (ML), and SQL workloads. It also requires repeated accessibility to the data sets.&amp;nbsp;&lt;/p&gt;&#xA;&lt;p data-selectable-paragraph=&#34;&#34;&gt;Spark can perform stream processing and batch processing. For context, stream processing deals with data streaming, whereas batch processing means processing the previously gathered task in a single batch.&amp;nbsp;&lt;/p&gt;】&lt;P数据选择 - 段落=“”&gt; Apache Spark是一种通用和闪电量的集群计算框架，并且是基于广泛的数据处理平台的开源技术。此外，它揭示了成功的数据工作者在实现流媒体，机器学习（ML）和SQL工作负载方面成功的开发API。它还需要重复访问数据集。 &lt;/p&gt;&#xA;&lt;p数​​据选择 - 段落=“”&gt; Spark可以执行流处理和批处理处理。对于上下文，流处理处理数据流，而批处理处理意味着在单个批处理中处理先前收集的任务。 &lt;/p&gt;</description>
      <pubDate>Mon, 03 Feb 2025 16:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>