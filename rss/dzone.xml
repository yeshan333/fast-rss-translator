<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>DZone.com Feed</title>
    <link>https://feeds.dzone.com/home</link>
    <description>Recent posts on DZone.com</description>
    <item>
      <title>【Incremental Jobs and Data Quality Are On a Collision Course】增量工作和数据质量正在发生冲突</title>
      <link>https://dzone.com/articles/incremental-jobs-and-data-quality-are-on-a-collision-course</link>
      <description>【&lt;p dir=&#34;ltr&#34;&gt;If you keep an eye on the data space ecosystem like I do, then you’ll be aware of the rise of DuckDB and its &lt;a href=&#34;https://motherduck.com/blog/big-data-is-dead/&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt;message that big data is dead&lt;/a&gt;. The idea comes from two industry papers (and associated data sets), one from the Redshift team (&lt;a href=&#34;https://assets.amazon.science/24/3b/04b31ef64c83acf98fe3fdca9107/why-tpc-is-not-enough-an-analysis-of-the-amazon-redshift-fleet.pdf&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt;paper&lt;/a&gt; and &lt;a href=&#34;https://github.com/amazon-science/redset&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt;dataset&lt;/a&gt;) and one from Snowflake (&lt;a href=&#34;https://event.cwi.nl/lsde/papers/p215-dageville-snowflake.pdf&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt;paper&lt;/a&gt; and &lt;a href=&#34;https://github.com/resource-disaggregation/snowset&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt;dataset&lt;/a&gt;). Each paper analyzed the queries run on their platforms, and some surprising conclusions were drawn — one being that most queries were run over quite small data. The conclusion (of &lt;a href=&#34;https://dzone.com/articles/developers-guide-to-duckdb-optimization&#34;&gt;DuckDB&lt;/a&gt;) was that big data was dead, and you could use simpler query engines rather than a data warehouse. It’s far more nuanced than that, but data shows that most queries are run over smaller datasets.&amp;nbsp;&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;Why?&lt;/p&gt;】&lt;p dir=&#34;ltr&#34;&gt;如果您像我一样关注数据空间生态系统，那么您就会意识到 DuckDB 及其&lt;a href=&#34;https://motherduck.com/blog/ 的崛起big-data-is-dead/&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt;大数据已死的消息&lt;/a&gt;。这个想法来自两篇行业论文（以及相关数据集），其中一篇来自 Redshift 团队 (&lt;a href=&#34;https://assets.amazon.science/24/3b/04b31ef64c83acf98fe3fdca9107/why-tpc-is-not-enough -an-analysis-of-the-amazon-redshift-fleet.pdf&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt;论文&lt;/a&gt;和&lt;a href=&#34;https://github.com/amazon-science/redset&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt;数据集&lt;/a&gt;）和来自 Snowflake 的一份 (&lt;a href=&#34;https://event.cwi.nl/lsde/papers/p215-dageville-snowflake.pdf&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt;论文&lt;/a&gt;和&lt;a href=&#34;https://github.com/resource-disaggregation/snowset&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt;数据集&lt;/a&gt;）。每篇论文都分析了在其平台上运行的查询，并得出了一些令人惊讶的结论——其中之一是大多数查询都是在相当小的数据上运行的。结论（&lt;a href=&#34;https://dzone.com/articles/developers-guide-to-duckdb-optimization&#34;&gt;DuckDB&lt;/a&gt;）是大数据已死，您可以使用更简单的查询引擎而不是数据仓库。它比这要微妙得多，但数据显示大多数查询都是在较小的数据集上运行的。 &lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;为什么？&lt;/p&gt;</description>
      <pubDate>Wed, 01 Jan 2025 17:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Effective Exception Handling in Microservices Integration】微服务集成中的有效异常处理</title>
      <link>https://dzone.com/articles/effective-exception-handling-in-microservices-integration</link>
      <description>【&lt;p style=&#34;text-align: left;&#34;&gt;Microservices architecture offers benefits such as scalability, agility, and maintainability, making it ideal for building robust applications. Spring Boot, as the preferred framework for developing microservices, provides various mechanisms to simplify integration with different systems. The modules offered by the Spring framework abstract much of the complexity, allowing developers to integrate seamlessly with external systems.&lt;/p&gt;&#xA;&lt;p style=&#34;text-align: left;&#34;&gt;Integration types may vary depending on the system, including &lt;a href=&#34;https://dzone.com/articles/what-is-an-api-integration-example&#34;&gt;API integration&lt;/a&gt;, messaging system integration, or database connectivity. Each system requires specific error-handling mechanisms. Regardless of the integration type, the API layer should not directly expose errors returned by the integrated systems to ensure a consistent and user-friendly response.&lt;/p&gt;】&lt;p style=&#34;text-align: left;&#34;&gt;微服务架构具有可扩展性、敏捷性和可维护性等优势，使其成为构建健壮应用程序的理想选择。 Spring Boot作为开发微服务的首选框架，提供了各种机制来简化与不同系统的集成。 Spring框架提供的模块抽象了大部分复杂性，允许开发人员与外部系统无缝集成。&lt;/p&gt;&#xA;&lt;p style=&#34;text-align: left;&#34;&gt;集成类型可能因系统而异，包括&lt;a href=&#34;https://dzone.com/articles/what-is-an-api-integration-example&#34; &gt;API 集成&lt;/a&gt;、消息系统集成或数据库连接。每个系统都需要特定的错误处理机制。无论集成类型如何，API 层都不应该直接暴露集成系统返回的错误，以确保一致且用户友好的响应。&lt;/p&gt;</description>
      <pubDate>Tue, 31 Dec 2024 20:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Streamlining Database Management: Running PostgreSQL in Docker Containers】简化数据库管理：在 Docker 容器中运行 PostgreSQL</title>
      <link>https://dzone.com/articles/running-postgresql-in-docker-containers</link>
      <description>【&lt;p&gt;Docker containers offer a lightweight, portable, and consistent way to deploy databases across different environments. This article will guide you through the process of running a PostgreSQL database in a Docker container, providing you with a flexible and scalable solution for your database needs.&lt;/p&gt;&#xA;&lt;h2&gt;Why Docker for PostgreSQL?&lt;/h2&gt;&#xA;&lt;p&gt;Before diving into the how-to, let&#39;s briefly discuss why running &lt;a href=&#34;https://dzone.com/articles/postgresql-everywhere-and-for-everything&#34;&gt;PostgreSQL&lt;/a&gt; in a &lt;a href=&#34;https://dzone.com/articles/docker-explained-an-introductory-guide-to-docker&#34;&gt;Docker container&lt;/a&gt; is beneficial:&lt;/p&gt;】&lt;p&gt;Docker 容器提供了一种轻量级、可移植且一致的方式来跨不同环境部署数据库。本文将指导您完成在 Docker 容器中运行 PostgreSQL 数据库的过程，为您提供满足您的数据库需求的灵活且可扩展的解决方案。&lt;/p&gt;&#xA;&lt;h2&gt;为什么选择 Docker for PostgreSQL？&lt;/h2&gt;&#xA;&lt;p&gt;在深入了解操作方法之前，我们先简要讨论一下为什么在 &lt;a href=&#34;https://dzone.com/articles/postgresql-everywhere-and-for-everything&#34;&gt;PostgreSQL&lt;/a&gt; 中运行 &lt; href=&#34;https://dzone.com/articles/docker-explained-an-introductory-guide-to-docker&#34;&gt;Docker 容器&lt;/a&gt; 是有益的：&lt;/p&gt;</description>
      <pubDate>Tue, 31 Dec 2024 21:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Driving RAG-Based AI Infrastructure】驱动基于 RAG 的人工智能基础设施</title>
      <link>https://dzone.com/articles/driving-rag-based-ai-infrastructure</link>
      <description>【&lt;p&gt;&lt;span&gt;Large language models (LLMs) have transformed AI with their ability to process and generate human-like text. However, their static pre-trained knowledge presents challenges for dynamic, real-time tasks requiring current information or domain-specific expertise. Retrieval-augmented generation (RAG) addresses these limitations by integrating LLMs with external data sources. When paired with AI agents that orchestrate workflows, RAG-based infrastructure becomes a powerful tool for real-time decision-making, analytics, and automation.&lt;/span&gt;&lt;/p&gt;&#xA;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;System Architecture&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img class=&#34;fr-fic fr-dib lazyload&#34; data-image=&#34;true&#34; data-new=&#34;false&#34; data-sizeformatted=&#34;288.0 kB&#34; data-mimetype=&#34;image/png&#34; data-creationdate=&#34;1732867884442&#34; data-creationdateformatted=&#34;11/29/2024 08:11 AM&#34; data-type=&#34;temp&#34; data-url=&#34;https://dz2cdn1.dzone.com/storage/temp/18074068-agents-rag.png&#34; data-modificationdate=&#34;null&#34; data-size=&#34;288029&#34; data-name=&#34;agents-rag.png&#34; data-id=&#34;18074068&#34; data-src=&#34;https://dz2cdn1.dzone.com/storage/temp/18074068-agents-rag.png&#34; style=&#34;width: 502px;&#34; alt=&#34;System architecture&#34;&gt;&lt;/span&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;】&lt;p&gt;&lt;span&gt;大型语言模型 (LLM) 凭借其处理和生成类人文本的能力改变了人工智能。然而，他们的静态预训练知识对需要当前信息或特定领域专业知识的动态实时任务提出了挑战。检索增强生成 (RAG) 通过将法学硕士与外部数据源集成来解决这些限制。当与编排工作流程的人工智能代理配合使用时，基于 RAG 的基础设施成为实时决策、分析和自动化的强大工具。&lt;/span&gt;&lt;/p&gt;&#xA;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;系统架构&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img class=&#34;fr-fic fr-diblazyload&#34; data-image=&#34;true&#34; data-new=&#34;false&#34; data-sizeformatted=&#34;288.0 kB&#34; data-mimetype=&#34;image /png&#34; data-creationdate=&#34;1732867884442&#34; data-creationdateformatted=&#34;11/29/2024 08:11 AM&#34; data-type=&#34;temp&#34; data-url =“https://dz2cdn1.dzone.com/storage/temp/18074068-agents-rag.png”data-modificationdate =“null”data-size =“288029”data-name =“agents-rag。 png&#34; data-id=&#34;18074068&#34; data-src =“https://dz2cdn1.dzone.com/storage/temp/18074068-agents-rag.png”样式=“宽度：502px;” alt=&#34;系统架构&#34;&gt;&lt;/span&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 01 Jan 2025 13:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【CI/CD Pipelines for Kubernetes Using GitLab CI】使用 GitLab CI 的 Kubernetes CI/CD 管道</title>
      <link>https://dzone.com/articles/cicd-pipelines-for-kubernetes-using-gitlab-ci</link>
      <description>【&lt;p data-pm-slice=&#34;1 1 []&#34;&gt;Modern software development demands rapid deployment cycles, scalability, and resilience. Kubernetes has emerged as the go-to orchestration platform, enabling scalable containerized application management. When combined with GitLab CI/CD pipelines, Kubernetes deployments become automated, repeatable, and reliable.&amp;nbsp;&lt;/p&gt;&#xA;&lt;p data-pm-slice=&#34;1 1 []&#34;&gt;This article explores the technical details of setting up &lt;a href=&#34;https://dzone.com/articles/gitlab-cicd-pipelines-integrated-workflow-oci-kubernetes-and-registry&#34;&gt;CI/CD pipelines&lt;/a&gt; for Kubernetes using GitLab CI.&lt;/p&gt;】&lt;p data-pm-slice=&#34;1 1 []&#34;&gt;现代软件开发需要快速的部署周期、可扩展性和弹性。 Kubernetes 已成为首选编排平台，支持可扩展的容器化应用程序管理。当与 GitLab CI/CD 管道结合使用时，Kubernetes 部署变得自动化、可重复且可靠。 &lt;/p&gt;&#xA;&lt;p data-pm-slice=&#34;1 1 []&#34;&gt;本文探讨了设置&lt;a href=&#34;https://dzone.com/articles/gitlab-cicd-pipelines-integrated-workflow-oci 的技术细节-kubernetes-and-registry&#34;&gt;使用 GitLab CI 的 Kubernetes 的 CI/CD 管道&lt;/a&gt;。&lt;/p&gt;</description>
      <pubDate>Wed, 01 Jan 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Understanding JavaScript Promises: A Comprehensive Guide to Create Your Own from Scratch】了解 JavaScript Promise：从头开始创建自己的 Promise 的综合指南</title>
      <link>https://dzone.com/articles/understanding-javascript-promises</link>
      <description>【&lt;p&gt;Asynchronous programming is an essential pillar of modern web development. Since the earliest days of Ajax, developers have grappled with different techniques for handling asynchronous tasks. JavaScript’s single-threaded nature means that long-running operations — like network requests, reading files, or performing complex calculations — must be done in a manner that does not block the main thread. Early solutions relied heavily on callbacks, leading to issues like “callback hell,” poor error handling, and tangled code logic.&lt;/p&gt;&#xA;&lt;p&gt;Promises offer a cleaner, more structured approach to managing async operations. They address the shortcomings of raw callbacks by providing a uniform interface for asynchronous work, enabling easier composition, more readable code, and more reliable error handling. For intermediate web engineers who already know the basics of JavaScript, understanding promises in depth is critical to building robust, efficient, and maintainable applications.&lt;/p&gt;】&lt;p&gt;异步编程是现代 Web 开发的重要支柱。从 Ajax 诞生之初起，开发人员就一直致力于使用不同的技术来处理异步任务。 JavaScript 的单线程特性意味着长时间运行的操作（例如网络请求、读取文件或执行复杂计算）必须以不阻塞主线程的方式完成。早期的解决方案严重依赖回调，导致出现“回调地狱”、糟糕的错误处理和混乱的代码逻辑等问题。&lt;/p&gt;&#xA;&lt;p&gt;Promise 提供了一种更清晰、更结构化的方法来管理异步操作。它们通过为异步工作提供统一的接口、实现更简单的组合、更易读的代码和更可靠的错误处理来解决原始回调的缺点。对于已经了解 JavaScript 基础知识的中级 Web 工程师来说，深入理解 Promise 对于构建健壮、高效和可维护的应用程序至关重要。&lt;/p&gt;</description>
      <pubDate>Wed, 01 Jan 2025 12:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Data Lake vs. Data Warehouse vs. Data Lakehouse】数据湖、数据仓库、数据湖屋</title>
      <link>https://dzone.com/articles/data-lake-vs-data-warehouse-vs-data-lakehouse</link>
      <description>【&lt;p&gt;Let us look into the strengths and weaknesses of leading data storage solutions.&lt;/p&gt;&#xA;&lt;p&gt;Data is central to modern business and society. Depending on what sort of leaky analogy you prefer, data can be the new oil, gold, or even electricity. Of course, even the biggest data sets are worthless and might even be a liability if they aren’t organized properly.&lt;/p&gt;】&lt;p&gt;让我们研究一下领先的数据存储解决方案的优点和缺点。&lt;/p&gt;&#xA;&lt;p&gt;数据是现代商业和社会的核心。根据您喜欢哪种泄漏类比，数据可以是新的石油、黄金，甚至电力。当然，即使是最大的数据集也毫无价值，如果组织不当，甚至可能成为一种负担。&lt;/p&gt;</description>
      <pubDate>Tue, 31 Dec 2024 22:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Boosting Performance and Efficiency: Enhancing React Applications With GraphQL Over REST APIs】提高性能和效率：通过 REST API 的 GraphQL 增强 React 应用程序</title>
      <link>https://dzone.com/articles/enhancing-react-applications-with-graphql-over-rest-apis</link>
      <description>【&lt;p&gt;In web development, optimizing and scaling applications have always been an issue. React.js had extraordinary success in front-end development as a tool, providing a robust way to create user interfaces. But it gets complicated with growing applications, especially when it comes to multiple REST API endpoints. Concerns such as over-fetching, where excessive data is required, can be a source of performance bottlenecks and a poor user experience.&lt;/p&gt;&#xA;&lt;p&gt;Among the solutions to these challenges is adopting the use of &lt;a href=&#34;https://dzone.com/articles/what-is-graphql-2&#34;&gt;GraphQL&lt;/a&gt; with React applications. If your backend has multiple REST endpoints, then introducing a GraphQL layer that internally calls your REST API endpoints can enhance your application from overfetching and streamline your frontend application. In this article, you will find how to use it, the advantages and disadvantages of this approach, various challenges, and how to address them. We will also dive deeper into some practical examples of how GraphQL can help you improve the ways you work with your data.&lt;/p&gt;】&lt;p&gt;在 Web 开发中，优化和扩展应用程序始终是一个问题。 React.js 作为一种工具在前端开发方面取得了非凡的成功，提供了创建用户界面的强大方法。但随着应用程序的不断增长，情况会变得复杂，特别是当涉及多个 REST API 端点时。过度获取（需要过多数据）等问题可能会成为性能瓶颈和糟糕的用户体验的根源。&lt;/p&gt;&#xA;&lt;p&gt;应对这些挑战的解决方案之一是在 React 应用程序中使用 &lt;a href=&#34;https://dzone.com/articles/what-is-graphql-2&#34;&gt;GraphQL&lt;/a&gt;。如果您的后端有多个 REST 端点，那么引入在内部调用 REST API 端点的 GraphQL 层可以增强您的应用程序，防止过度获取并简化您的前端应用程序。在本文中，您将了解如何使用它、这种方法的优点和缺点、各种挑战以及如何解决它们。我们还将深入探讨一些实际示例，说明 GraphQL 如何帮助您改进数据处理方式。&lt;/p&gt;</description>
      <pubDate>Wed, 01 Jan 2025 14:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Logical Reasoning in Network Problems】网络问题中的逻辑推理</title>
      <link>https://dzone.com/articles/logical-reasoning-in-network-problems</link>
      <description>【&lt;h2&gt;Classic Case 1&lt;/h2&gt;&#xA;&lt;p&gt;Many software professionals lack in-depth knowledge of TCP/IP logic reasoning, which often leads to misidentifying problems as mysterious problems. Some are discouraged by the complexity of TCP/IP networking literature, while others are misled by confusing details in Wireshark. For instance, a DBA facing performance problems might misinterpret packet capture data in Wireshark, erroneously concluding that TCP retransmissions are the cause.&lt;/p&gt;&#xA;&lt;figcaption class=&#34;fr-inner&#34; contenteditable=&#34;true&#34;&gt;&#xA; &lt;em&gt;Figure 1. Packet capture screenshot provided by DBA suspecting retransmission problems&lt;/em&gt;&#xA;&lt;/figcaption&gt;&#xA;&lt;p&gt;&lt;/p&gt;】&lt;h2&gt;经典案例1&lt;/h2&gt;&#xA;&lt;p&gt;许多软件专业人员缺乏对 TCP/IP 逻辑推理的深入了解，这常常导致将问题误认为是神秘问题。有些人因 TCP/IP 网络文献的复杂性而灰心丧气，而另一些人则被 Wireshark 中令人困惑的细节所误导。例如，面临性能问题的 DBA 可能会误解 Wireshark 中的数据包捕获数据，错误地得出 TCP 重传是原因的结论。&lt;/p&gt;&#xA;&lt;figcaption class=&#34;fr-inner&#34; contenteditable=&#34;true&#34;&gt;&#xA; &lt;em&gt;图 1. DBA 提供的怀疑重传问题的数据包捕获屏幕截图&lt;/em&gt;&#xA;&lt;/图标题&gt;&#xA;&lt;p&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 01 Jan 2025 15:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Integrating Lighthouse Test Automation Into Your CI/CD Pipeline】将 Lighthouse 测试自动化集成到您的 CI/CD 管道中</title>
      <link>https://dzone.com/articles/integrating-lighthouse-test-automation-into-your-ci-cd-pipeline</link>
      <description>【&lt;p&gt;Web performance can make or break your digital presence. While developers constantly push new features and updates, maintaining consistent quality across deployments remains a challenge. Lighthouse test automation has emerged as a powerful solution, transforming how development teams approach quality assurance and performance optimization.&lt;/p&gt;&#xA;&lt;h2&gt;Understanding Lighthouse Test Automation Fundamentals&lt;/h2&gt;&#xA;&lt;p&gt;Lighthouse test automation serves as the foundation for comprehensive performance testing. When integrated into continuous integration workflows, Google Lighthouse&amp;nbsp;provides consistent, objective measurements of web application performance. This integration enables teams to catch performance regressions before they impact users.&lt;/p&gt;】&lt;p&gt;网络性能可以成就或毁掉您的数字形象。尽管开发人员不断推出新功能和更新，但在部署中保持一致的质量仍然是一个挑战。 Lighthouse 测试自动化已成为一种强大的解决方案，改变了开发团队实现质量保证和性能优化的方式。&lt;/p&gt;&#xA;&lt;h2&gt;了解 Lighthouse 测试自动化基础知识&lt;/h2&gt;&#xA;&lt;p&gt;Lighthouse 测试自动化是全面性能测试的基础。当集成到持续集成工作流程中时，Google Lighthouse 可以提供一致、客观的 Web 应用程序性能测量。这种集成使团队能够在性能下降影响用户之前捕获它们。&lt;/p&gt;</description>
      <pubDate>Wed, 01 Jan 2025 18:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>