<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>DZone.com Feed</title>
    <link>https://feeds.dzone.com/home</link>
    <description>Recent posts on DZone.com</description>
    <item>
      <title>【How to Perform Custom Error Handling With ANTLR】如何使用ANTLR执行自定义错误处理</title>
      <link>https://dzone.com/articles/how-to-perform-custom-error-handling-with-antlr</link>
      <description>【&lt;p&gt;ANTLR is a very popular parser generator that helps build parsers for various language syntaxes, especially query languages or domain-specific languages. This tool provides default error handling, which is useful in many circumstances, but for more robust and user-friendly applications, more graceful error handling is required.&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;In this article, we will describe this requirement with a simple example and will guide you through the process of implementing &lt;a href=&#34;https://dzone.com/articles/custom-error-handling-framework-for-an-enterprise&#34;&gt;custom error handling&lt;/a&gt; with ANTLR.&lt;/p&gt;】&lt;p&gt; antlr是一种非常流行的解析器生成器，可帮助为各种语言语法，尤其是查询语言或特定于域的语言构建解析器。该工具提供默认错误处理，这在许多情况下很有用，但是对于更健壮和用户友好的应用程序，需要更优雅的错误处理。 &lt;/p&gt;&#xA;&lt;p&gt;在本文中，我们将以一个简单的示例来描述这一要求，并将指导您完成&lt;a href =“ https://dzone.com/articles/custom-error andling-framework-framework-for-for-an-enterprise”&gt;使用antlr。</description>
      <pubDate>Mon, 19 May 2025 21:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Role of Cloud Architecture in Conversational AI】云体系结构在对话AI中的作用</title>
      <link>https://dzone.com/articles/role-of-cloud-architecture-in-conversational-ai</link>
      <description>【&lt;p dir=&#34;ltr&#34;&gt;Imagine a world where customer support is instant, personalized, and available 24/7—this is the promise of conversational AI. From smart chatbots to virtual assistants, these technologies leverage &lt;a href=&#34;https://dzone.com/articles/transforming-translation-the-power-of-context-in-n-1&#34;&gt;natural language processing (NLP)&lt;/a&gt; and machine learning to create seamless, human-like interactions.&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;But behind every smooth conversation lies a robust backbone: cloud architecture. By delivering scalability, speed, and security, the cloud ensures that conversational AI systems perform flawlessly, even under fluctuating demands.&lt;/p&gt;】&lt;p dir =“ ltr”&gt;想象一下一个世界，即客户支持即时，个性化和可用的24/7，这是对话式AI的承诺。从智能聊天机器人到虚拟助手，这些技术将利用&lt;a href =“ https://dzone.com/articles/transforming-transfration-translation-translation-translation-translation-the-power-the-power-of-context-in-n-n-n-n-&gt;自然语言处理（nlp）&lt;/a&gt; &lt;/a&gt;和机器学习以创造无缝的，类似的人类互动。&#xA;&lt;p dir =“ ltr”&gt;，但是每个平稳的对话背后都是一个强大的骨干：云体系结构。通过提供可伸缩性，速度和安全性，云可确保对话式AI系统完美地发挥作用，即使在波动的需求下也是如此。&lt;/p&gt;</description>
      <pubDate>Mon, 19 May 2025 18:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【The Smart Way to Talk to Your Database: Why Hybrid API + NL2SQL Wins】与您的数据库交谈的明智方式：为什么混合API + NL2SQL获胜</title>
      <link>https://dzone.com/articles/the-smart-way-to-talk-to-your-database</link>
      <description>【&lt;p&gt;Hybrid is not a fallback — it&#39;s the real strategy.&lt;/p&gt;&#xA;&lt;h2&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Databases weren&#39;t designed to &#34;listen,&#34; meaning to understand flexible human intentions. They were designed to &#34;obey&#34; or strictly execute SQL commands. Now it&#39;s time to teach them both.&lt;/p&gt;】&lt;p&gt;混合动力不是后备 - 这是真正的策略。&lt;/p&gt;&#xA;&lt;h2&gt;简介&lt;/h2&gt;&#xA;&lt;p&gt;数据库不是为了“倾听”而设计的，意思是了解灵活的人类意图。它们旨在“服从”或严格执行SQL命令。现在是时候教他们俩了。&lt;/p&gt;</description>
      <pubDate>Mon, 19 May 2025 14:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Integrating Model Context Protocol (MCP) With Microsoft Copilot Studio AI Agents】将模型上下文协议（MCP）与Microsoft Copilot Studio AI代理集成</title>
      <link>https://dzone.com/articles/mcp-microsoft-copilot-ai-agents</link>
      <description>【&lt;p dir=&#34;ltr&#34;&gt;AI assistants are getting smarter. They can write code, summarize reports, and help users solve complex problems. But they still have one big limitation. They can’t access live data or internal systems. As a result, their answers are often not in real time.&lt;/p&gt;&#xA;&lt;p&gt;The &lt;a href=&#34;https://dzone.com/articles/model-context-protocol-vs-http&#34;&gt;Model Context Protocol (MCP)&lt;/a&gt; is a new solution to this problem. It acts like a universal connector between AI models and enterprise tools. With MCP, AI systems can access up-to-date data during a conversation. That means smarter answers, fewer hallucinations, and better results.&lt;/p&gt;】&lt;p dir =“ ltr”&gt; AI助手变得更聪明。他们可以编写代码，总结报告并帮助用户解决复杂的问题。但是他们仍然有一个很大的限制。他们无法访问实时数据或内部系统。结果，他们的答案通常不是实时的。&lt;/p&gt;&#xA;&lt;p&gt; &lt;a href =“ https://dzone.com/articles/model-context-protocol-vs-http”&gt;模型上下文协议（MCP）&lt;/a&gt;是解决此问题的新解决方案。它就像AI模型和企业工具之间的通用连接器一样。使用MCP，AI系统可以在对话期间访问最新数据。这意味着更聪明的答案，更少的幻觉和更好的结果。&lt;/p&gt;</description>
      <pubDate>Mon, 19 May 2025 12:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Metrics at a Glance for Production Clusters】一眼生产集群的指标</title>
      <link>https://dzone.com/articles/essential-metrics-production-clusters</link>
      <description>【&lt;p name=&#34;d2de&#34;&gt;Keeping a close eye on your production clusters is not just good practice — it’s essential for survival. Whether you’re managing applications at scale or ensuring robust service delivery, understanding the vital signs of your clusters through metrics is like having a dashboard in a race car, giving you real-time insights and foresight into performance bottlenecks, resource usage and the operational health of your car.&lt;/p&gt;&#xA;&lt;p name=&#34;d912&#34;&gt;However, too much happens in any cluster. There are so many metrics to track that the huge observability data you may collect could become another obstacle to viewing what is actually happening with your cluster. That’s why you should only collect the important metrics that offer you a complete picture of your cluster’s health without overwhelming you.&lt;/p&gt;】&lt;p name =“ d2de”&gt;密切关注您的生产簇不仅是好习惯，而且对生存至关重要。无论您是按大规模管理应用程序还是确保服务良好的服务交付，通过指标了解群集的生命体征就像在赛车中拥有仪表板，为您提供实时见解和对性能瓶颈，资源使用情况和汽车运营健康的预识。&lt;/p&gt;。&lt;/p&gt;&#xA;&lt;p name =“ d912”&gt;但是，在任何集群中都会发生太多。有太多的指标可以跟踪，以至于您可能收集的巨大可观察性数据可能会成为查看群集实际发生的事情的另一个障碍。这就是为什么您只应该收集重要的指标，这些指标在不压倒您的情况下为您的群集健康提供完整的图片。&lt;/p&gt;</description>
      <pubDate>Mon, 19 May 2025 17:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Building Resilient Identity Systems: Lessons from Securing Billions of Authentication Requests】建筑弹性身份系统：获得数十亿个身份验证请求的教训</title>
      <link>https://dzone.com/articles/resilient-identity-systems-best-practices</link>
      <description>【&lt;p dir=&#34;ltr&#34; style=&#34;text-align: left;&#34;&gt;As workforce becomes more digital, &amp;nbsp;identity security has become the center of enterprise cyber security. This is particularly challenging given that more than 40 billion authentication requests are processed each day, across platforms and devices, and more solutions than ever are being created in order to successfully enable users to establish their identity online, in a manner that is both fluid and resilient. These systems have to perform 99.9% without a hitch, block cyber threats &lt;em&gt;and&amp;nbsp;&lt;/em&gt;be foolproof. The stakes are high—81% of data breaches are attributed to compromised credentials.&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34; style=&#34;text-align: left;&#34;&gt;Security is as much about user experience as it is about safety. If authentication takes longer than 30 seconds, 65% of users will simply abandon their transactions. Having spent years building authentication risk assessment systems, I’d like to use that experience to communicate some key insights I’ve gained about securing identities at scale, while also measuring attack in a way that meets your security objectives, and minimizing friction for legitimate users.&lt;/p&gt;】&lt;p dir =“ ltr” style =“ text-align：left;”&gt;随着劳动力变得越来越数字，身份安全已成为企业网络安全的中心。鉴于每天在平台和设备之间处理超过400亿个身份验证请求，这一点尤其具有挑战性，并且创建的解决方案比以往任何时候都多，以便成功地使用户以流动性和弹性的方式在线建立自己的身份。这些系统必须执行99.9％的情况，而无需障碍，阻止网络威胁&lt;em&gt;和&lt;/em&gt;是万无一失的。赌注很高 -  81％的数据泄露归因于受损的凭据。&lt;/p&gt;&#xA;&lt;p dir =“ ltr” style =“ text-align：left;”&gt;安全性与用户体验和安全有关。如果身份验证需要超过30秒的时间，则65％的用户将简单地放弃其交易。花了多年的时间建立身份验证风险评估系统，我想利用这种经验来传达一些我对确保身份进行大规模确保身份的关键见解，同时还以满足您的安全目标的方式来衡量攻击，并最大程度地减少合法用户的摩擦。&lt;/p&gt; &lt;/p&gt;</description>
      <pubDate>Mon, 19 May 2025 13:00:04 +0000</pubDate>
    </item>
    <item>
      <title>【AI-Driven Test Automation Techniques for Multimodal Systems】AI驱动的多模式系统的AI驱动测试自动化技术</title>
      <link>https://dzone.com/articles/ai-driven-test-automation-multimodal-systems</link>
      <description>【&lt;h2&gt;Abstract&lt;/h2&gt;&#xA;&lt;p&gt;The prominent growth of multimodal systems, which integrate text, speech, vision, and gesture as inputs, has introduced new challenges for software testing. Traditional testing frameworks are not designed to address the dynamic interactions and contextual dependencies inherent to these systems. AI-driven test automation solutions provide transformative solutions by automating test scenario generation, bug detection, and continuous performance monitoring, ensuring efficient testing workflows and integration testing between multiple AI models.&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;This paper presents a comprehensive review of AI-driven techniques employed for the automated testing of multimodal systems, and critically handling integration of diversified tools, scenario generation frameworks, test data creation approach, and their role in continuous integration pipelines.&lt;/p&gt;】&lt;h2&gt;摘要&lt;/h2&gt;&#xA;&lt;p&gt;将文本，语音，视觉和手势整合为输入的多模式系统的显着增长引入了软件测试的新挑战。传统的测试框架并非旨在解决这些系统固有的动态交互和上下文依赖关系。 AI驱动的测试自动化解决方案通过自动化测试方案，错误检测和持续性能监视，提供变革性解决方案，从而确保多个AI模型之间的有效测试工作流程和集成测试。 &lt;/p&gt;&#xA;&lt;p&gt;本文对用于自动测试的多模式系统的AI驱动技术进行了全面综述，并严格处理多元化工具的集成，场景生成框架，测试数据创建方法及其在连续集成管道中的作用。&lt;/p&gt;。&lt;/p&gt;。&lt;/p&gt;</description>
      <pubDate>Mon, 19 May 2025 15:00:10 +0000</pubDate>
    </item>
    <item>
      <title>【How to Ensure Cross-Time Zone Data Integrity and Consistency in Global Data Pipelines】如何确保全局数据管道中的跨时间数据完整性和一致性</title>
      <link>https://dzone.com/articles/cross-time-zone-integrity-pipelines</link>
      <description>【&lt;p&gt;In the modern interconnected world, companies increasingly work on a global level, requiring the data to be managed across different time zones. This creates challenges in preserving data integrity, especially when handling time-sensitive information. The need for strong cross-timezone data management has never been more paramount. Let&#39;s see the main considerations and best practices for maintaining consistency in global data pipelines.&lt;/p&gt;&#xA;&lt;h2 dir=&#34;ltr&#34;&gt;The Fundamental Challenge&lt;/h2&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;At its core, the challenge of cross-time zone data integrity stems from the simple fact that different parts of the world experience time differently. For example, if it is 5:00 PM on a Thursday, local time in Pacific Daylight Time, then it&#39;s Friday in most parts of the world. This difference can generate a myriad of problems—from timestamps not in sync to conflict of schedules and data inconsistencies which can severely impact operations.&lt;/p&gt;】&lt;p&gt;在现代相互联系的世界中，公司越来越多地在全球范围内工作，要求在不同时区管理数据。这在保留数据完整性方面引起了挑战，尤其是在处理时间敏感信息时。强大的跨时区数据管理的需求从未如此重要。让我们看一下维持全球数据管道一致性的主要考虑因素和最佳实践。&lt;/p&gt;&#xA;&lt;h2 dir =“ ltr”&gt;基本挑战&lt;/h2&gt;&#xA;&lt;p dir =“ ltr”&gt;在其核心上，跨时间数据完整性的挑战源于一个简单的事实，即世界各地的经历时间不同。例如，如果是星期四的下午5:00，那么在太平洋夏令时的当地时间，那么在世界大部分地区是星期五。这种差异可能会产生无数的问题 - 从时间戳不同步到时间戳和数据不一致的冲突，这可能会严重影响操作。&lt;/p&gt;</description>
      <pubDate>Mon, 19 May 2025 19:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Operational Principles, Architecture, Benefits, and Limitations of Artificial Intelligence Large Language Models】人工智能的运营原理，建筑，利益和局限性大语言模型</title>
      <link>https://dzone.com/articles/principles-benefits-and-limitations-of-AI-LLMs</link>
      <description>【&lt;h2 title=&#34;Page 1&#34;&gt;Abstract&lt;/h2&gt;&#xA;&lt;div title=&#34;Page 1&#34;&gt;&#xA; Large Language Models (LLMs) are sophisticated AI systems designed to understand and generate human-like text, leveraging extensive datasets and advanced neural network architectures. This paper provides a comprehensive overview of LLMs, detailing their purpose, operational principles, and deployment architectures. The purpose of LLMs spans various applications, including content creation, customer support, and personalized tutoring. The operational mechanics of LLMs are rooted in deep learning techniques, especially neural networks, and involve extensive training on diverse textual datasets to learn language patterns and contextual understanding. The paper distinguishes between server-side and on-device LLM implementations, each offering unique advantages and limitations. Server-side LLMs operate in cloud environments, providing scalable resources and centralized updates, but face challenges like latency and data privacy concerns. Conversely, on-device LLMs run locally on user devices, offering benefits such as lower latency and enhanced privacy, but are constrained by device capabilities and require manual updates. By examining these two deployment paradigms, the paper aims to illustrate the trade-offs involved and the &lt;a href=&#34;https://dzone.com/articles/understanding-llm-technology&#34;&gt;potential of&amp;nbsp;&lt;/a&gt;&lt;span style=&#34;margin: 0px; padding: 0px;&#34;&gt;&lt;a href=&#34;https://dzone.com/articles/understanding-llm-technology&#34; target=&#34;_blank&#34;&gt;LLMs&amp;nbsp;&lt;/a&gt;to transform&lt;/span&gt; human-computer interaction and automate complex language-based tasks, paving the way for future advancements in AI-driven applications.&#xA; &lt;h2&gt;Understanding Large Language Models &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;/h2&gt;&#xA; &lt;p&gt;LLM is an advanced AI system for understanding and generating human-like text based on the input it receives.&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;They are &lt;a href=&#34;https://dzone.com/articles/generative-ai-comprehensive-guide&#34;&gt;trained on vast datasets&lt;/a&gt; comprising books, articles, websites, and other forms of written language, enabling them to perform a variety of tasks, including: &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/p&gt;&#xA; &lt;ul&gt;&#xA;  &lt;li&gt;Answering questions&lt;/li&gt;&#xA;  &lt;li&gt;Writing essays or articles&lt;/li&gt;&#xA;  &lt;li&gt;Assisting with programming&amp;nbsp;&lt;/li&gt;&#xA;  &lt;li&gt;Translating languages&lt;/li&gt;&#xA;  &lt;li&gt;Engaging in conversations &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;/li&gt;&#xA; &lt;/ul&gt;&#xA; &lt;p&gt;These models leverage deep learning techniques, particularly neural networks, to process and understand nuanced language patterns.&lt;/p&gt;】&lt;H2 title =“ Page 1”&gt;摘要&lt;/h2&gt;&#xA;&lt;div title =“第1页”&gt;&#xA; 大型语言模型（LLM）是精致的AI系统，旨在了解和生成类似人类的文本，利用广泛的数据集和高级神经网络体系结构。本文提供了LLM的全面概述，详细介绍了其目的，操作原则和部署体系结构。 LLM的目的涵盖了各种应用程序，包括创建内容，客户支持和个性化辅导。 LLM的运营力学植根于深度学习技术，尤其是神经网络，并涉及对各种文本数据集进行广泛的培训，以学习语言模式和上下文理解。本文区分了服务器端和设备LLM实现，每种实现都提供了独特的优势和限制。服务器端LLM在云环境中运行，提供可扩展的资源和集中式更新，但面临诸如延迟和数据隐私问题之类的挑战。相反，启用LLMS在用户设备上本地运行，提供较低的延迟和增强的隐私权，但受设备功能的限制，需要手动更新。通过检查这两个部署范例，本文旨在说明所涉及的权衡，&lt;a href =“ https://dzone.com/articles/understanding-llm-technology”&gt; &lt;/a&gt; &lt;span style =“ margin =” margin =“ margin：0px; 0px; padding; padding; 0px; padding;&gt; &lt; href =“ https://dzone.com/articles/understanding-llm-technology” target =“ _ blank”&gt; llms &lt;/a&gt;转换&lt;/span&gt;人类 -  computer互动并自动化基于复杂的语言的任务，为AI-Driven的应用程序铺平了进步的方式。&#xA; &lt;H2&gt;了解大语言模型&lt;/h2&gt;&#xA; &lt;p&gt;LLM is an advanced AI system for understanding and generating human-like text based on the input it receives.&lt;strong&gt; &lt;/strong&gt;They are &lt;a href=&#34;https://dzone.com/articles/generative-ai-comprehensive-guide&#34;&gt;trained on vast datasets&lt;/a&gt; comprising books, articles, websites, and other forms of written language, enabling them to perform a variety of tasks, including:            &lt;/p&gt;&#xA; &lt;ul&gt;&#xA;  &lt;li&gt;回答问题&lt;/li&gt;&#xA;  &lt;li&gt;写论文或文章&lt;/li&gt;&#xA;  &lt;li&gt;协助编程&lt;/li&gt;&#xA;  &lt;li&gt;翻译语言&lt;/li&gt;&#xA;  &lt;li&gt;进行对话&lt;/li&gt;&#xA; &lt;/ul&gt;&#xA; &lt;p&gt;这些模型利用深度学习技术，尤其是神经网络来处理和了解细微的语言模式。&lt;/p&gt;</description>
      <pubDate>Mon, 19 May 2025 20:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Beyond Simple Responses: Building Truly Conversational LLM Chatbots】超越简单的回应：建立真正的对话llm聊天机器人</title>
      <link>https://dzone.com/articles/building-conversational-llm-chatbots</link>
      <description>【&lt;p&gt;“I’m sorry, I don’t understand. Please rephrase your question.”&lt;/p&gt;&#xA;&lt;p&gt;We’ve all been there. You’re trying to get help from a chatbot, thinking you’re being crystal clear, and then bam—this frustrating response appears. Just when you think you’re having a productive conversation, the bot fails to grasp context, forgets what you said two messages ago, or simply can’t handle anything beyond its pre-programmed scripts. I still remember spending 20 minutes with a customer service bot last year, only to end up calling the support line anyway. The experience leaves users disappointed and companies questioning the value of their chatbot investments.&lt;/p&gt;】&lt;p&gt;“对不起，我不明白。请改写您的问题。” &lt;/p&gt;&#xA;&lt;p&gt;我们都去过那里。您正在尝试从聊天机器人那里获得帮助，以为您的水晶清晰，然后是BAM，这令人沮丧的回应。就在您认为自己进行了有效的对话时，该机器人无法掌握上下文，忘记了您在两条消息前说的话，或者根本无法处理其预编程的脚本以外的任何内容。我仍然记得去年与客户服务机器人呆了20分钟，但无论如何还是最终致电了支持线。这一经验使用户失望，公司质疑其聊天机器人投资的价值。&lt;/p&gt;</description>
      <pubDate>Mon, 19 May 2025 16:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>