<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>DZone.com Feed</title>
    <link>https://feeds.dzone.com/home</link>
    <description>Recent posts on DZone.com</description>
    <item>
      <title>【Building AI Agents With .NET: A Practical Guide】用.NET构建AI代理：实用指南</title>
      <link>https://dzone.com/articles/agentic-ai-in-dotnet</link>
      <description>【&lt;p data-end=&#34;641&#34; data-start=&#34;292&#34;&gt;As software systems evolve, there&#39;s a growing demand for applications that are not just reactive but proactive, adaptive, and intelligent. This is where &lt;strong data-end=&#34;459&#34; data-start=&#34;445&#34;&gt;Agentic AI&lt;/strong&gt; comes in. Unlike traditional AI that simply follows instructions, Agentic AI involves autonomous agents that can perceive, reason, act, and learn just like intelligent assistants.&lt;/p&gt;&#xA;&lt;p data-end=&#34;788&#34; data-start=&#34;643&#34;&gt;In this article, we’ll explore how to bring Agentic AI concepts into the world of &lt;a href=&#34;https://dzone.com/refcardz/coredotnet&#34;&gt;.NET&lt;/a&gt; development, creating smarter, self-directed applications.&lt;/p&gt;】&lt;p data-end =“ 641” data-start =“ 292”&gt;随着软件系统的发展，对应用的需求不仅是反应性，而且是主动，自适应和智能的。这是&lt;strong data-end =“ 459” data-start =“ 445”&gt; agesic ai &lt;/strong&gt;出现的地方。与传统的AI仅遵循指示不同，代理AI涉及可以感知，推理，行动和学习的自主剂，就像智能助理一样。&lt;/p&gt;。&lt;/p&gt;。&lt;/p&gt;。&lt;/p&gt;。&#xA;&lt;p data-end =“ 788” data-start =“ 643”&gt;在本文中，我们将探讨如何将代理AI概念带入&lt;a href =“ https://dzone.com/refcardz/refcardz/coredotnet”&gt; .net&gt; .net &lt;/a&gt;开发，创建SMARTER，自我定义的应用程序。</description>
      <pubDate>Mon, 18 Aug 2025 14:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Prompt-Based ETL: Automating SQL Generation for Data Movement With LLMs】基于及时的ETL：使用LLM的数据移动自动化SQL生成</title>
      <link>https://dzone.com/articles/prompt-based-etl-sql-automation-llms</link>
      <description>【&lt;p&gt;Every modern data team has experienced it: A product manager asks for a quick metric, “total signups in Asia over the last quarter, broken down by device type,” and suddenly the analytics backlog grows.&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Somewhere deep in the data warehouse, an engineer is now tracing join paths across five tables, crafting a carefully optimized SQL query, validating edge cases, and packaging it into a pipeline that will likely break the next time the schema changes.&lt;/p&gt;】&lt;p&gt;每个现代数据团队都经历了它：产品经理要求快速指标“在上一季度亚洲的总注册，按设备类型分解”，突然间，Analytics Backlog增长了。 &lt;/p&gt;&#xA;&lt;p&gt;在数据仓库深处的某个地方，工程师现在正在追踪五个桌子上的连接路径，制作精心优化的SQL查询，验证边缘案例，并将其包装到管道中，该管道可能会破坏下一次架构时。&lt;/p&gt; &lt;/p&gt; &lt;/p&gt;</description>
      <pubDate>Mon, 18 Aug 2025 16:00:10 +0000</pubDate>
    </item>
    <item>
      <title>【The Kill Switch: A Coder&#39;s Silent Act of Revenge】杀戮开关：编码人员的复仇行为</title>
      <link>https://dzone.com/articles/kill-switch-coders-silent-act-of-revenge</link>
      <description>【&lt;p&gt;In the age of code dominance, where billions of dollars are controlled by lines of code, a frustrated coder crossed the boundary between protest and cybercrime. What began as a grudge became an organized act of sabotage, one that now could land him 10 years in federal prison.&lt;/p&gt;&#xA;&lt;p&gt;Recently, a contract programmer was fired by a US trucking and logistics company. But unbeknownst to his bosses, he had secretly embedded a digital kill switch in their production infrastructure. A week later, the company&#39;s systems were knocked offline, their settings scrambled, and vital services grounded.&lt;/p&gt;】&lt;p&gt;在代码统治时代，数十亿美元由代码线控制，一个沮丧的编码员越过抗议和网络犯罪之间的边界。最初的怨恨成为有组织的破坏行为，现在可以将他送入联邦监狱10年。&lt;/p&gt; &lt;/p&gt;&#xA;&lt;p&gt;最近，合同程序员是由一家美国卡车运输公司解雇的。但是他的老板不为人知，他秘密地将数字杀戮开关嵌入了他们的生产基础设施中。一周后，该公司的系统被撞倒，设置扰乱，而重要的服务扎根。&lt;/p&gt;</description>
      <pubDate>Mon, 18 Aug 2025 18:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Real-Time Analytics Using Zero-ETL for MySQL】实时分析使用MySQL的零ETL</title>
      <link>https://dzone.com/articles/real-time-analytics-zero-etl-mysql</link>
      <description>【&lt;p&gt;Organizations rely on real-time analytics to gain insights into their core business drivers, enhance operational efficiency, and maintain a competitive edge. Traditionally, this has involved the use of complex extract, transform, and load (ETL) pipelines. ETL is the process of combining, cleaning, and normalizing data from different sources to prepare it for analytics, AI, and machine learning (ML) workloads. Although ETL processes have long been a staple of data integration, they often prove time-consuming, complex, and less adaptable to the fast-changing demands of modern data architectures. By transitioning towards zero-ETL architectures, businesses can foster agility in analytics, streamline processes, and make sure that data is immediately actionable.&lt;/p&gt;&#xA;&lt;p&gt;In this post, we demonstrate how to set up a zero-ETL integration between &lt;a href=&#34;https://aws.amazon.com/rds/mysql/&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt;Amazon Relational Database Service (Amazon RDS) for MySQL&lt;/a&gt; (source) and Amazon Redshift (destination). The transactional data from the source gets refreshed in near real time on the destination, which processes analytical queries.&lt;/p&gt;】&lt;p&gt;组织依靠实时分析来了解其核心业务驱动力，提高运营效率并保持竞争优势。传统上，这涉及使用复杂提取物，转换和负载（ETL）管道的使用。 ETL是将来自不同来源的数据组合，清洁和标准化的过程，以准备分析，AI和机器学习（ML）工作量。尽管ETL过程长期以来一直是数据集成的主要内容，但它们通常证明是耗时，复杂的，并且不适合现代数据体系结构的快速变化需求。通过向零元素架构过渡，企业可以在分析，简化流程中促进敏捷性，并确保数据立即可行。&lt;/p&gt;&#xA;&lt;p&gt;在这篇文章中，我们演示了如何在&lt;a href =“ https://aws.amazon.com/rds/mysql/”之间建立零ETL集成。来自源的交易数据在目的地几乎实时刷新，该数据处理分析查询。&lt;/p&gt;</description>
      <pubDate>Mon, 18 Aug 2025 15:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Expert Techniques to Trim Your Docker Images and Speed Up Build Times】专家技术来修剪您的码头图像并加快构建时间</title>
      <link>https://dzone.com/articles/trim-docker-images-speed-up-builds</link>
      <description>【&lt;h2 dir=&#34;ltr&#34;&gt;Key Takeaways&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA; &lt;li dir=&#34;ltr&#34;&gt;&lt;strong&gt;Pick your base image like you&#39;re choosing a foundation for your house&lt;/strong&gt;. Going with a minimal variant like &lt;code&gt;python-slim&lt;/code&gt; or a runtime-specific CUDA image, is hands down the quickest way to slash your image size and reduce security risks.&lt;/li&gt;&#xA; &lt;li dir=&#34;ltr&#34;&gt;&lt;strong&gt;Multi-stage builds are your new best friend for keeping things organized&lt;/strong&gt;. Think of it like having a messy workshop (your &#34;builder&#34; stage) where you do all the heavy lifting with compilers and testing tools, then only moving the finished product to your clean showroom (the &#34;runtime&#34; stage).&lt;/li&gt;&#xA; &lt;li dir=&#34;ltr&#34;&gt;&lt;strong&gt;Layer your Dockerfile with caching in mind, always&lt;/strong&gt;. Put the stuff that rarely changes (like dependency installation) before the stuff that changes all the time (like your app code). This simple trick can cut your build times from minutes to mere seconds.&lt;/li&gt;&#xA; &lt;li dir=&#34;ltr&#34;&gt;&lt;strong&gt;Remember that every &lt;code&gt;RUN&lt;/code&gt; command creates a permanent layer&lt;/strong&gt;. You&#39;ve got to chain your installation and cleanup commands together with &lt;code&gt;&amp;amp;&amp;amp;&lt;/code&gt; to make sure temporary files actually disappear within the same layer. Otherwise, you&#39;re just hiding a mess under the rug while still paying for the storage.&lt;/li&gt;&#xA; &lt;li dir=&#34;ltr&#34;&gt;&lt;strong&gt;Stop treating &lt;code&gt;.dockerignore&lt;/code&gt; like an afterthought&lt;/strong&gt;. Make it your first line of defense to keep huge datasets, model checkpoints, and (yikes!) credentials from ever getting near your build context.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;So you&#39;ve built your AI model, containerized everything, and hit &lt;code&gt;docker build&lt;/code&gt;. The build finishes, and there it is: a multi-gigabyte monster staring back at you. If you&#39;ve worked with AI containers, you know this pain. Docker&#39;s convenience comes at a price, and that price is bloated, sluggish images that slow down everything from developer workflows to CI/CD pipelines while burning through your cloud budget.&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;This guide isn&#39;t just another collection of Docker tips. We&#39;re going deep into the fundamental principles that make containers efficient. We&#39;ll tackle both sides of the optimization coin:&lt;/p&gt;】&lt;h2 dir =“ ltr”&gt;键外卖&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA; &lt;li dir =“ ltr”&gt; &lt;strong&gt;选择您的基本图像，就像您为您的房屋选择基础&lt;/strong&gt;一样。使用最小的变体，例如&lt;code&gt; python-slim &lt;/code&gt;或特定于运行时的CUDA图像，是最快的方法来削减图像大小并降低安全风险。&lt;/li&gt;&#xA; &lt;li dir =“ ltr”&gt; &lt;strong&gt;多阶段构建是您保持井井有条的新最好的朋友&lt;/strong&gt;。将其视为拥有一个凌乱的工作坊（您的“建筑商”阶段），在这里您可以使用编译器和测试工具进行所有繁重的工作，然后将成品移至干净的陈列室（“运行时”阶段）。&lt;/li&gt; &lt;/li&gt;&#xA; &lt;li dir =“ ltr”&gt; &lt;strong&gt;将您的dockerfile层置于牢记，始终&lt;/strong&gt;。将很少更改的内容（例如依赖安装）放在一直在更改的内容之前（例如您的应用程序代码）。这个简单的技巧可以将您的构建时间从几分钟到几秒钟。&lt;/li&gt;&#xA; &lt;li dir =“ ltr”&gt; &lt;strong&gt;请记住，每个&lt;code&gt;运行&lt;/code&gt;命令都会创建一个永久层&lt;/strong&gt;。您必须将安装和清理命令与&lt;code&gt; &amp;&amp; &lt;/code&gt;一起链接，以确保临时文件实际上消失在同一层中。否则，您只是将一团糟在地毯下藏起来，同时仍在为存储付费。&lt;/li&gt;&#xA; &lt;li dir =“ ltr”&gt; &lt;strong&gt;停止处理&lt;code&gt; .dockerignore &lt;/code&gt;像事后&lt;/strong&gt;一样。使其成为您的第一道防线，以保持巨大的数据集，模型检查点和（yikes！）凭据靠近您的构建上下文。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p dir =“ ltr”&gt;因此，您已经构建了AI模型，对所有内容进行了容器，然后击中&lt;code&gt; docker build &lt;/code&gt;。构建结束了，就在那里：一个多gabyte怪物盯着您。如果您使用AI容器，您会知道这种痛苦。 Docker的便利性是有代价的，价格膨胀，较短的图像，这些图像放慢了从开发人员工作流程到CI/CD管道的所有内容，同时燃烧您的云预算。&lt;/p&gt;&#xA;&lt;p dir =“ ltr”&gt;本指南不仅仅是Docker提示的另一集。我们深入探讨了使容器高效的基本原则。我们将解决优化硬币的两面：&lt;/p&gt;</description>
      <pubDate>Mon, 18 Aug 2025 17:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【10 Essential Bash Scripts to Boost DevOps Efficiency】10个基本狂欢脚本以提高DevOps效率</title>
      <link>https://dzone.com/articles/10-essential-bash-scripts-to-boost-devops-efficien</link>
      <description>【&lt;p&gt;Automation is a major aspect of the DevOps workflow, enhancing efficiency, and Bash script is one of the oldest and powerful tools for achieving this automation. Bash scripts help engineers and system admins to eliminate mundane workflow, repetitive tasks, and reduce errors across multiple environments. With its simplicity and adaptability in many Unix-based systems, the Bash script is used in day-to-day operations without the overhead of complex automation tooling.&lt;/p&gt;&#xA;&lt;p&gt;In this article, you will learn 10 essential Bash scripts that can boost your DevOps productivity. These range from automating simple &lt;a href=&#34;https://dzone.com/articles/what-is-a-cicd-pipeline&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt;CI/CD&lt;/a&gt; DevOps workflow, backups, and Docker container management to monitoring system health and environment provisioning.&lt;/p&gt;】&lt;p&gt;自动化是DevOps工作流程的主要方面，提高效率，而Bash脚本是实现此自动化的最古老，最有力的工具之一。 bash脚本可帮助工程师和系统管理员消除平凡的工作流程，重复性任务，并减少多种环境中的错误。 BASH脚本在许多基于UNIX的系统中的简单性和适应性，在日常操作中使用，而没有复杂的自动化工具的开销。&lt;/p&gt;&#xA;&lt;p&gt;在本文中，您将学习10个必需的bash脚本，以提高您的DevOps生产力。这些范围从自动化简单&lt;a href =“ https://dzone.com/articles/what-is-a-cicd-pipeline” rer =“ noopener noreferrer” target =“ _ black”&gt; ci/cd&gt; ci/cd&gt; ci/cd &lt;/a&gt; DevOps Workflow，备份，备份，备份，备份和DOCKER容器以监测系统的健康和环境服务。</description>
      <pubDate>Mon, 18 Aug 2025 13:00:01 +0000</pubDate>
    </item>
    <item>
      <title>【Logging MCP Protocol When Using stdio- Part II】使用stdio-part II时记录MCP协议</title>
      <link>https://dzone.com/articles/logging-mcp-protocol-when-using-stdio-part-ii</link>
      <description>【&lt;p&gt;In &lt;a href=&#34;https://dzone.com/articles/logging-mcp-protocol-when-using-stdio-part-i&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt;Part 1&lt;/a&gt;, we introduced the challenge of logging MCP’s stdio communication and outlined three powerful techniques to solve it. Now, let’s get our hands dirty. This part provides a complete, practical walkthrough, demonstrating how to apply these concepts by building a Spring AI-based MCP server from scratch, configuring a GitHub Copilot client, and even creating a custom client to showcase the full power of the protocol.&lt;/p&gt;&#xA;&lt;h2&gt;Copilot Conversation Illustration&lt;/h2&gt;&#xA;&lt;h3&gt;&lt;strong&gt;&lt;img data-new=&#34;false&#34; data-mimetype=&#34;image/png&#34; data-creationdateformatted=&#34;08/06/2025 07:49 AM&#34; data-url=&#34;https://dz2cdn1.dzone.com/storage/temp/18569888-1754466565008.png&#34; data-size=&#34;33960&#34; data-id=&#34;18569888&#34; class=&#34;fr-fic fr-dib lazyload&#34; data-image=&#34;true&#34; data-sizeformatted=&#34;34.0 kB&#34; data-creationdate=&#34;1754466564425&#34; data-type=&#34;temp&#34; data-modificationdate=&#34;null&#34; data-name=&#34;1754466565008.png&#34; data-src=&#34;https://dz2cdn1.dzone.com/storage/temp/18569888-1754466565008.png&#34; alt=&#34;Copilot conversation illustration&#34;&gt;&#xA;  &lt;p&gt;&lt;br&gt;&lt;/p&gt;】&lt;p&gt; in &lt;a href =“ https://dzone.com/articles/logging-mcp-protocol-when-using-stdio-part-i” rel =“ noopener noreferrer” target =“ _ black”&gt;第1部分&lt;/a&gt;，我们引入了登录MCP沟通的挑战，以解决三个强大的技巧。现在，让我们弄脏双手。这部分提供了完整，实用的演练，展示了如何通过从头开始构建基于Spring AI的MCP服务器，配置Github Copilot客户端，甚至创建自定义客户端来展示协议的全部功能。&lt;/p&gt;&gt;&#xA;&lt;H2&gt;副副言对话插图&lt;/h2&gt;&#xA;&lt;h3&gt;&lt;strong&gt;&lt;img data-new=&#34;false&#34; data-mimetype=&#34;image/png&#34; data-creationdateformatted=&#34;08/06/2025 07:49 AM&#34; data-url=&#34;https://dz2cdn1.dzone.com/storage/temp/18569888-1754466565008.png&#34; data-size =“ 33960” data-id =“ 18569888” class =“ fr-fic fr-dib lazyload” data-image =“ true” data-sizeFormatted =“ 34.0 kb” data-creationdate =“ 17544466564425” data-name =“ 17544666565008.png” data-src =“ https://dz2cdn1.dzone.com/storage/storage/temp/18569888888-17544466656565008.png”&#xA;  &lt;p&gt; &lt;br&gt; &lt;/p&gt;</description>
      <pubDate>Mon, 18 Aug 2025 14:30:00 +0000</pubDate>
    </item>
    <item>
      <title>【Logging MCP Protocol When Using stdio, Part I】使用STDIO时记录MCP协议，第一部分</title>
      <link>https://dzone.com/articles/logging-mcp-protocol-when-using-stdio-part-i</link>
      <description>【&lt;h2 style=&#34; border-box;font-family: &amp;quot;Helvetica Neue&amp;quot;, Helvetica, Arial, sans-serif;font-weight: 600;line-height: 1.2;color: rgb(34, 38, 53);margin: 20px 0px 5px;font-size: 30px;clear: both;letter-spacing: -0.5px;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;orphans: 2;text-align: left;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;&#34;&gt;&lt;strong style=&#34; border-box;font-weight: bold;font-style: normal;&#34;&gt;Logging MCP Protocol When Using stdio&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;p style=&#34; border-box;margin: 5px 0px 15px;color: rgb(34, 38, 53);font-family: Cambria, serif;font-size: 19px;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-align: left;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;&#34;&gt;If you haven’t heard of MCP — the Model Context Protocol — you’ve probably been living under a rock. The Model Context Protocol (MCP) is becoming widely recognized, standardizing how applications provide context to LLMs. It barely needs an introduction anymore. Still, for the sake of completeness, let me borrow selectively from the &lt;a href=&#34;https://modelcontextprotocol.io/introduction&#34; rel=&#34;noopener noreferrer&#34; style=&#34; border-box;background: transparent;color: rgb(41, 168, 255);text-decoration: none;user-select: auto;&#34; target=&#34;_blank&#34;&gt;official MCP site&lt;/a&gt;. &amp;nbsp;Do take a moment to explore the well-explained pages if you&#39;re new to MCP.&lt;/p&gt;&#xA;&lt;p style=&#34; border-box;margin: 5px 0px 15px;color: rgb(34, 38, 53);font-family: Cambria, serif;font-size: 19px;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-align: left;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;&#34;&gt;MCP is an open protocol that standardizes how applications provide context to LLMs. It’s designed to help developers build agents and complex workflows on top of LLMs. Since LLMs often need to interact with external data and tools, MCP offers:&lt;/p&gt;】&lt;h2 style =“ border-box; font-family：“ helvetica neue”，helvetica，arial，sans-serif; font-weight：600; line-heiver：1.2; color：rgb（34，38，53）; margin; margin; margin; margin; margin：20px 0px 5px; font size：30px; font size：30px; cele; cele; cele; normal;font-variant-ligatures: normal;font-variant-caps: normal;orphans: 2;text-align: left;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;&#34;&gt;&lt;strong style=&#34; border-box;font-weight: bold;font-style: normal;&#34;&gt;Logging MCP Protocol When Using stdio&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;p style =“边界框；边距：5px 0px 15px;颜色：rgb（34、38、53）; font-family：cambria，serif; font-size; font-size：19px; font-style; forman; formal; fort-font-variant; font-variant; font-var; 2;text-align: left;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;&#34;&gt;If您还没有听说过MCP（模型上下文协议），您可能一直生活在岩石之下。模型上下文协议（MCP）正被广泛认可，标准化应用程序如何为LLM提供上下文。它几乎不再需要介绍了。尽管如此，为了完整，让我从&lt;a href =“ https://modelcontextprotocol.io/introduction”中有选择地借钱。 target =“ _ blank”&gt;官方MCP网站&lt;/a&gt;。  如果您是MCP的新手，请花一点时间探索解释的页面。&lt;/p&gt;&#xA;&lt;p style =“边界框；边距：5px 0px 15px;颜色：rgb（34、38、53）; font-family：cambria，serif; font-size; font-size：19px; font-style; forman; formal; fort-font-variant; font-variant; font-var; 2; text-align：左;文本 -  0px;文本转变：无；初始;“&gt; MCP是一个开放协议，标准化应用程序如何为LLM提供上下文。它旨在帮助开发人员在LLM上建立代理和复杂的工作流程。由于LLMS通常需要与外部数据和工具进行交互，因此MCP提供：&lt;/p&gt;</description>
      <pubDate>Mon, 18 Aug 2025 13:30:00 +0000</pubDate>
    </item>
    <item>
      <title>【What’s Wrong With Data Validation — and How It Relates to the Liskov Substitution Principle】数据验证有什么问题 - 及其与Liskov替代原则的关系</title>
      <link>https://dzone.com/articles/whats-wrong-with-data-validation</link>
      <description>【&lt;div data-article-id=&#34;2739646&#34;&gt;&#xA; &lt;h2&gt;Introduction: When You Don’t Know if You Should Validate&lt;/h2&gt;&#xA; &lt;p&gt;In everyday software development, many engineers find themselves asking the same question: “Do I need to validate this data again, or can I assume it’s already valid?”&lt;/p&gt;&#xA; &lt;p&gt;Sometimes, the answer feels uncertain. One part of the code performs validation “just in case,” while another trusts the input, leading to either redundant checks or dangerous omissions. This situation creates tension between performance and safety, and often results in code that is both harder to maintain and more error-prone.&lt;/p&gt;】&lt;Div Data-Article-id =“ 2739646”&gt;&#xA; &lt;H2&gt;简介：当您不知道是否应该验证&lt;/h2&gt;时&#xA; &lt;p&gt;在日常软件开发中，许多工程师发现自己问了同样的问题：“我需要再次验证这些数据，还是可以假设它已经有效？” &lt;/p&gt;&#xA; &lt;p&gt;有时候，答案感到不确定。代码的一部分“以防万一”执行验证，而另一部分则信任输入，导致冗余检查或危险的遗漏。这种情况会在性能和安全之间产生张力，并且通常会导致代码更难维护，而且更容易容易出错。&lt;/p&gt;</description>
      <pubDate>Mon, 18 Aug 2025 20:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Combine Node.js and WordPress Under One Domain】在一个域下组合node.js和wordpress</title>
      <link>https://dzone.com/articles/combining-nodejs-and-wordpress</link>
      <description>【&lt;p&gt;I have been working on a website that combines a custom Node.js application with a WordPress blog, and I am excited to share my journey. After trying out different hosting configurations, I found a simple way to create a smooth online presence using Nginx on AlmaLinux.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;em&gt;Important note&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;:&amp;nbsp;&lt;/em&gt;&lt;em&gt;Throughout this guide, replace example.com with your actual domain name. For instance, if your domain is mydomain.com, you will substitute all instances of example.com with mydomain.com.&lt;/em&gt;&lt;/p&gt;】&lt;p&gt;我一直在一个网站上工作，该网站将自定义Node.js应用程序与WordPress博客相结合，我很高兴分享我的旅程。尝试不同的托管配置后，我找到了一种简单的方法，可以在Almalinux上使用Nginx创建平稳的在线形象。&lt;/p&gt;&#xA;&lt;p&gt; &lt;strong&gt; &lt;em&gt;重要说明&lt;/em&gt; &lt;/strong&gt; &lt;em&gt;：&lt;/em&gt; &lt;em&gt;在本指南中，用您的实际域名替换example.com。例如，如果您的域是mydomain.com，则将example.com的所有实例替换为mydomain.com。&lt;/em&gt; &lt;/p&gt;</description>
      <pubDate>Mon, 18 Aug 2025 19:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>