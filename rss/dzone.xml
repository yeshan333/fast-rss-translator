<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>DZone.com Feed</title>
    <link>https://feeds.dzone.com/home</link>
    <description>Recent posts on DZone.com</description>
    <item>
      <title>【Scaling Azure Microservices for Holiday Peak Traffic Using Automated CI/CD Pipelines and Cost Optimization】使用自动化的CI/CD管道和成本优化来缩放Azure微服务用于假期高峰流量</title>
      <link>https://dzone.com/articles/azure-microservices-holiday-traffic-cicd-cost-optimization</link>
      <description>【&lt;p dir=&#34;ltr&#34;&gt;Scaling microservices for holiday peak traffic is crucial to prevent downtime and ensure a seamless user experience. This guide explores Azure DevOps automation, CI/CD pipelines, and cost-optimization strategies to handle high-demand traffic seamlessly. Manual scaling quickly becomes a bottleneck as organizations deploy dozens, sometimes hundreds, of microservices powered by distinct backend services like Cosmos DB, Event Hubs, App Configuration, and Traffic Manager.&amp;nbsp;&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;Multiple teams juggling these components risk costly delays and errors at the worst possible moments. This is where automation comes in: a game-changing solution that transforms complex, error-prone processes into streamlined, efficient operations.&lt;/p&gt;】&lt;p dir =“ ltr”&gt;假期峰值流量的缩放微服务对于防止停机时间至关重要，并确保无缝的用户体验。本指南探讨了Azure DevOps自动化，CI/CD管道和成本优化的策略，以无缝处理高需求的流量。随着组织部署由Cosmos DB，Event Hubs，App配置和流量管理器等独特的后端服务提供支持的微量服务的组织，手动缩放很快就变成了瓶颈。 &lt;/p&gt;&#xA;&lt;p dir =“ ltr”&gt;在最糟糕的时刻，多个团队将这些组件杂耍的差异和错误风险延误和错误。这是自动化所在的地方：改变游戏的解决方案，将复杂的，容易出错的过程转换为流线型，高效的操作。&lt;/p&gt;</description>
      <pubDate>Fri, 30 May 2025 20:00:07 +0000</pubDate>
    </item>
    <item>
      <title>【Source-Driven Development in Salesforce: Managing Metadata and API Versions】Salesforce源驱动的开发：管理元数据和API版本</title>
      <link>https://dzone.com/articles/source-driven-development-in-salesforce</link>
      <description>【&lt;p dir=&#34;ltr&#34;&gt;Development on Salesforce has seen major changes in the last few years. SDD has made it possible for teams to match their Salesforce processes to the best modern DevOps approaches. Fundamentally, SDD depends on version control, automated deployments, and coding your data’s metadata. With benefits like consistency, traceability, and automation, such changes introduce new challenges about how versions and metadata should be managed throughout the project.&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;Here, we’ll look at SDD principles and guide you through properly managing metadata and API versions in a Salesforce environment.&lt;/p&gt;】&lt;p dir =“ ltr”&gt; Salesforce的开发在过去几年中发生了重大变化。 SDD使团队有可能将他们的Salesforce流程与最佳现代DevOps方法相匹配。从根本上讲，SDD取决于版本控制，自动部署以及编码数据的元数据。凭借一致性，可追溯性和自动化等好处，此类更改引发了有关在整个项目中如何管理版本和元数据的新挑战。&lt;/p&gt;&#xA;&lt;p dir =“ ltr”&gt;在这里，我们将研究SDD原理，并指导您正确管理Salesforce环境中的元数据和API版本。&lt;/p&gt;</description>
      <pubDate>Fri, 30 May 2025 14:00:07 +0000</pubDate>
    </item>
    <item>
      <title>【Resolving Parameter Sensitivity With Parameter Sensitive Plan Optimization in SQL Server 2022】通过参数敏感计划优化在SQL Server 2022中解决参数灵敏度</title>
      <link>https://dzone.com/articles/optimizing-parameter-sensitivity-psp-sql-server</link>
      <description>【&lt;p&gt;For years, database administrators and developers working with SQL Server faced a persistent performance issue known as &lt;strong&gt;parameter sniffing&lt;/strong&gt;. This problem arises because SQL Server’s traditional query plan caching mechanism generates only a single execution plan for a parameterized query. That plan is based on the parameter values used during the query&#39;s first execution.&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;While efficient in many cases, this behavior leads to significant performance degradation when parameter values vary widely in terms of their data selectivity or distribution. For example, a plan optimized for a parameter value that filters a small subset of rows can be reused for a parameter that retrieves millions of rows, causing inefficient scans and resource overuse.&amp;nbsp;&lt;/p&gt;】&lt;p&gt;多年来，与SQL Server合作的数据库管理员和开发人员面临着持续的性能问题，称为&lt;strong&gt;参数嗅探&lt;/strong&gt;。之所以出现此问题，是因为SQL Server的传统查询计划缓存机制仅生成一个参数化查询的单个执行计划。该计划基于查询第一个执行期间使用的参数值。 &lt;/p&gt;&#xA;&lt;p&gt;虽然在许多情况下有效，但当参数值在数据选择性或分布方面差异很大时，这种行为会导致显着的性能降解。例如，可以针对过滤一小部分行的参数值进行优化的计划，以重复使用以检索数百万行的参数，从而导致效率低下的扫描和资源过度使用。 &lt;/p&gt;</description>
      <pubDate>Fri, 30 May 2025 15:00:30 +0000</pubDate>
    </item>
    <item>
      <title>【Designing Fault-Tolerant Messaging Workflows Using State Machine Architecture】使用状态机架构设计容忍故障的消息传递工作流程</title>
      <link>https://dzone.com/articles/fault-tolerant-workflows-with-state-machine-architecture</link>
      <description>【&lt;h2 dir=&#34;ltr&#34;&gt;Abstract&amp;nbsp;&lt;/h2&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;As a leader of projects for the backend of a global messaging platform that maintains millions of users daily, I was also responsible for a couple of efforts intended to enhance the stability and failure tolerance of our backend services. We replaced essential sections of our system with the help of the state machine patterns, notably Stateful Workflows. The usage of this model led to the elimination of problems in the field of message delivery, visibility of the read receipt, and device sync, such as a mismatch of phone directories.&amp;nbsp;&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;The intention of this article is to let the reader know how to keep a messaging infrastructure highly available and adaptable by sharing the practicalities and trials one faces when bringing the said architectures into production.&lt;/p&gt;】&lt;h2 dir =“ ltr”&gt;摘要&lt;/h2&gt;&#xA;&lt;p dir =“ ltr”&gt;作为一个全球消息平台的项目负责人，该平台每天维持数百万用户，我还负责一些旨在增强我们后端服务的稳定性和失败承受能力的努力。我们借助州机器模式（尤其是状态工作流程）替换了系统的基本部分。该模型的使用导致消除消息传递领域的问题，读取收据的可见性以及设备同步，例如电话目录的不匹配。 &lt;/p&gt;&#xA;&lt;p dir =“ ltr”&gt;本文的目的是让读者知道如何通过分享将上述架构投入生产时面对的实用性和试验来保持消息传递基础架构的高度可观和适应性。&lt;/p&gt;</description>
      <pubDate>Fri, 30 May 2025 13:00:10 +0000</pubDate>
    </item>
    <item>
      <title>【My Favorite Interview Question】我最喜欢的面试问题</title>
      <link>https://dzone.com/articles/my-favorite-interview-question</link>
      <description>【&lt;p&gt;&lt;a href=&#34;https://dzone.com/articles/30-common-cicd-interview-questions-with-answers&#34;&gt;Interviews&lt;/a&gt; are on my mind again (read into that whatever you want) and I’ve been having conversations about the experience on both sides of the Zoom camera.&lt;/p&gt;&#xA;&lt;p&gt;Finding out whether a candidate can do the job is incredibly challenging. The usual slate of techniques—from so-called “experiential questions” (“tell me about a time when you didn’t agree with a coworker”) to google-style brain teasers (“how would you go about finding out the weight of the moon using nothing but croutons”) to supposed leetcode questions (“You have two linked lists and you need to combine them”)—fall short in so many ways, but primarily they fail in the most critical way:&lt;/p&gt;】&lt;p&gt; &lt;a href =“ https://dzone.com/articles/30-common-common-cicd-interview-questions-with-answers”&gt;访谈&lt;/a&gt; &lt;/a&gt; &lt;/a&gt; &lt;/a&gt;再次在我心中（无论您想要什么，我一直在阅读），并且我一直在对Zoom Camera的两侧进行对话。&lt;/p&gt;&gt;&gt;&gt;&gt;&gt;&#xA;&lt;p&gt;找出候选人能否完成这项工作是极具挑战性的。从所谓的“体验问题”（“告诉我您不同意同事的时间”）到Google式的脑告车赛（“您将如何使用除面包壳以外的小面包箱除了面包壳以外什么都不是））到假定的leetcode问题（“您有两个链接的列表，他们有两个关键的方法），但要对许多链接的列表，但是，许多链接的方法 - 方式：&lt;/p&gt;</description>
      <pubDate>Fri, 30 May 2025 17:00:08 +0000</pubDate>
    </item>
    <item>
      <title>【Agentic AI Systems: Smarter Automation With LangChain and LangGraph】代理AI系统：与Langchain和Langgraph的更智能自动化</title>
      <link>https://dzone.com/articles/smart-ai-automation-with-langchain-and-langgraph</link>
      <description>【&lt;p&gt;Things are changing fast in the world of automation. We&#39;re not just talking about those old, clunky robots that do the same thing over and over. Now, we&#39;re seeing really clever systems that can actually adapt and figure things out on their own. Leading the charge in this exciting shift are what we call &lt;strong&gt;Agentic AI Systems&lt;/strong&gt;, and they&#39;re powered by some seriously cool tools like LangChain and LangGraph.&lt;/p&gt;&#xA;&lt;p&gt;These technologies are opening up a whole new level of &#39;smart automation.&#39; We&#39;re talking about systems that can actually &lt;em&gt;think&lt;/em&gt; through problems, make plans, take action, and even learn as they go. This makes them incredibly useful for those tricky tasks and situations that are always changing.&lt;/p&gt;】&lt;p&gt;自动化世界中的情况正在迅速变化。我们不仅在谈论那些一遍又一遍地做同样的事情的古老，笨拙的机器人。现在，我们看到了真正聪明的系统，这些系统实际上可以自行适应和弄清楚事情。我们所说的&lt;strong&gt; Agesic AI Systems &lt;/strong&gt;在这一激动人心的转变中领导指控，并且由Langchain和Langgraph等一些非常酷的工具提供动力。&lt;/p&gt;&#xA;&lt;p&gt;这些技术正在开放一个全新的“智能自动化”。我们正在谈论的是可以通过问题，制定计划，采取行动甚至学习时实际上可以思考的系统。这使得它们对于始终在变化的棘手任务和情况中非常有用。&lt;/p&gt;</description>
      <pubDate>Fri, 30 May 2025 19:00:10 +0000</pubDate>
    </item>
    <item>
      <title>【Web Crawling for RAG With Crawl4AI】Web爬行与crawl4ai的抹布</title>
      <link>https://dzone.com/articles/web-crawling-for-rag-with-crawl4ai</link>
      <description>【&lt;p&gt;The importance of AI-powered web crawling and data extraction cannot be overstated. With the exponential growth of online data, businesses and organizations need efficient and accurate methods for collecting and analyzing data to inform their decision-making processes. Crawl4AI and Ollama offer a range of features and benefits that can help address these challenges, from automated web crawling and data extraction to natural language processing and machine learning.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a data-text-link=&#34;&#34; href=&#34;https://github.com/unclecode/crawl4ai&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt;Crawl4AI&lt;/a&gt; is a powerful tool for AI-powered web crawling and data extraction. It offers a range of features and benefits, including automated web crawling, data extraction, and natural language processing. With Crawl4AI, users can easily extract data from websites, social media platforms, and other online sources, and then analyze and visualize the data using a range of tools and techniques. Crawl4AI is particularly useful for data scientists and machine learning engineers who need to collect and analyze large datasets for their projects.&lt;/p&gt;】&lt;p&gt; AI驱动的Web爬行和数据提取的重要性不能被夸大。随着在线数据的指数增长，企业和组织需要有效，准确的方法来收集和分析数据以告知其决策过程。 Crawl4ai和Ollama提供了一系列功能和好处，可以帮助应对这些挑战，从自动化的网络爬行和数据提取到自然语言处理和机器学习。&lt;/p&gt;&#xA;&lt;p&gt; &lt;a data-text-link =“” href =“ https://github.com/unclecode/crawl4ai” rel =“ noopener noreferrer” target =“ _ black”&gt; crawl4ai &lt;/a&gt;是AI-Power的Web Rawling和数据提取的强大工具。它提供了一系列功能和好处，包括自动化的网络爬行，数据提取和自然语言处理。使用Crawl4AI，用户可以轻松地从网站，社交媒体平台和其他在线资源中提取数据，然后使用一系列工具和技术来分析和可视化数据。 Crawl4AI对于需要收集和分析其项目的大型数据集的数据科学家和机器学习工程师特别有用。&lt;/p&gt;</description>
      <pubDate>Fri, 30 May 2025 18:00:05 +0000</pubDate>
    </item>
    <item>
      <title>【Yet Another GenAI Nightmare: Seven Shadow AI Pitfalls to Avoid】又是一场Genai的噩梦：七个影子AI陷阱以避免</title>
      <link>https://dzone.com/articles/genai-pitfalls-to-avoid</link>
      <description>【&lt;p&gt;If you’re ancient like me, you probably remember Lotus Notes. The leading groupware platform of the last millennium, it not only provided corporate email and pre-Slack communications, it also empowered anyone in the organization to build and publish mini-web sites for anyone to use.&lt;/p&gt;&#xA;&lt;p&gt;It didn’t take long for this whole employee empowerment train to go off the rails. Suddenly, Madge in accounting could slap up a site that exposed private corporate data—with the IT organization none the wiser. No testing, no compliance, no oversight at all.&lt;/p&gt;】&lt;p&gt;如果您像我一样古老，您可能还记得莲花笔记。它是上一个千年的领先组件平台，它不仅提供了公司电子邮件和前偏僻的通信，而且还授权组织中的任何人建立和发布迷你WEB网站，以供任何人使用。&lt;/p&gt;&#xA;&lt;p&gt;整个员工授权火车不久就要脱离轨道。突然，会计中的Madge可能会打开一个曝光私人公司数据的站点，而IT组织也不明智。没有测试，没有合规性，根本没有监督。&lt;/p&gt;</description>
      <pubDate>Fri, 30 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Is Low Code the Developer&#39;s Ally or Replacement? Debunking Myths and Misconceptions】低码是开发人员的盟友还是替代？揭穿神话和误解</title>
      <link>https://dzone.com/articles/low-code-ally-or-replacement</link>
      <description>【&lt;p&gt;The rise of low-code development platforms has ignited passionate debates within the software development community. As these tools promise to democratize application creation and accelerate development cycles, a fundamental question emerges: Are low-code platforms here to supplement professional developers, or will they eventually render traditional coding obsolete? This tension between opportunity and threat has generated numerous myths and misconceptions about low-code&#39;s place in the development ecosystem.&lt;/p&gt;&#xA;&lt;p&gt;For professional developers, the question isn&#39;t merely academic — it&#39;s existential. With organizations increasingly adopting low-code solutions to address development backlogs and resource constraints, understanding the true relationship between traditional development and low-code approaches has never been more important. This article examines the reality behind the rhetoric, offering evidence-based insights into how low-code is reshaping — not replacing — the developer profession.&lt;/p&gt;】&lt;p&gt;低代码开发平台的兴起激发了软件开发社区中热情的辩论。由于这些工具有望使应用程序创建和加速开发周期民主化，因此出现了一个基本问题：这里的低代码平台是为了补充专业开发人员，还是最终会使传统的编码过时？机会和威胁之间的这种紧张关系引起了人们对低代码在开发生态系统中的地位的许多神话和误解。&lt;/p&gt;&#xA;&lt;p&gt;对于专业开发人员而言，这个问题不仅仅是学术 - 它是存在的。随着组织越来越多地采用低代码解决方案来解决发展积压和资源限制，了解传统发展与低代码方法之间的真实关系从未如此重要。本文探讨了言论背后的现实，提供了基于证据的洞察力，即对低代码的重塑（而不是更换）开发者职业。&lt;/p&gt;。&lt;/p&gt;</description>
      <pubDate>Fri, 30 May 2025 11:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Apache Spark 4.0: Transforming Big Data Analytics to the Next Level】Apache Spark 4.0：将大数据分析转换为一个新级别</title>
      <link>https://dzone.com/articles/apache-spark-4-0-new-features-2025</link>
      <description>【&lt;p dir=&#34;ltr&#34;&gt;Hurray! Apache Spark 4.0, released in 2025, redefines big data processing with innovations that enhance performance, accessibility, and developer productivity. With contributions from over 400 developers across organizations like Databricks, Apple, and NVIDIA, Spark 4.0 resolves thousands of JIRA issues, introducing transformative features: native plotting in PySpark, Python Data Source API, polymorphic User-Defined Table Functions (UDTFs), state store enhancements, SQL scripting, and Spark Connect improvements. This report provides an in-depth exploration of these features, their technical underpinnings, and practical applications through original examples and diagrams.&lt;/p&gt;&#xA;&lt;h2 dir=&#34;ltr&#34;&gt;The Evolution of Apache Spark&lt;/h2&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;&lt;a href=&#34;https://dzone.com/refcardz/apache-spark&#34;&gt;Apache Spark&lt;/a&gt;’s in-memory processing delivers up to 100x faster performance than Hadoop MapReduce, making it a cornerstone for big data analytics. Spark 4.0 builds on this foundation by introducing optimizations that enhance query execution, expand Python accessibility, and improve streaming capabilities. These advancements make it a versatile tool for industries like finance, healthcare, and retail, where scalability and real-time analytics are critical. The community-driven development ensures Spark 4.0 meets enterprise needs while remaining accessible to diverse users, from data scientists to engineers.&lt;/p&gt;】&lt;p dir =“ ltr”&gt;欢呼！ Apache Spark 4.0于2025年发布，重新定义了大数据处理，并通过创新，可提高性能，可访问性和开发人员的生产率。 With contributions from over 400 developers across organizations like Databricks, Apple, and NVIDIA, Spark 4.0 resolves thousands of JIRA issues, introducing transformative features: native plotting in PySpark, Python Data Source API, polymorphic User-Defined Table Functions (UDTFs), state store enhancements, SQL scripting, and Spark Connect improvements.该报告通过原始示例和图表提供了对这些功能，其技术基础以及实际应用的深入探索。&lt;/p&gt;&#xA;&lt;h2 dir =“ ltr”&gt; apache spark &lt;/h2&gt;的演变&#xA;&lt;p dir =“ ltr”&gt; &lt;a href =“ https://dzone.com/refcardz/apache-spark”&gt; apache spark &lt;/a&gt;的内存过程比Hadoop MapReduce更快地提供了高达100倍的性能，使其成为大数据分析的基础。 SPARK 4.0通过引入优化，以增强查询执行，扩展Python可访问性并提高流式传输功能来建立Spark 4.0。这些进步使其成为金融，医疗保健和零售等行业的多功能工具，在该行业中，可扩展性和实时分析至关重要。社区驱动的发展可确保Spark 4.0满足企业需求，同时还可以访问各种用户，从数据科学家到工程师。&lt;/p&gt;</description>
      <pubDate>Fri, 30 May 2025 12:00:07 +0000</pubDate>
    </item>
  </channel>
</rss>