<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>DZone.com Feed</title>
    <link>https://feeds.dzone.com/home</link>
    <description>Recent posts on DZone.com</description>
    <item>
      <title>【From 0.68 to 10 Requests/Second: Optimizing LLM Serving With vLLM】从0.68到10个请求/秒：优化使用VLLM服务的LLM</title>
      <link>https://dzone.com/articles/optimizing-llm-serving-with-vllm</link>
      <description>【&lt;p&gt;GPUs are essential for running large language models (LLMs). But when companies deploy LLMs to production, having powerful GPUs alone isn&#39;t enough.&lt;/p&gt;&#xA;&lt;p&gt;What becomes equally important is handling available GPUs efficiently, so that multiple concurrent user requests can be served within sub-second response times. This requires a software layer above GPUs that can provide request batching, memory optimization, and dynamic resource management. That&#39;s exactly what vLLM strives to provide. In this article, we will explore how vLLM achieves this and examine the performance improvements it delivers.&lt;/p&gt;】&lt;p&gt; GPU对于运行大型语言模型（LLMS）至关重要。但是，当公司部署LLMS生产时，仅拥有强大的GPU就不够。&lt;/p&gt;&#xA;&lt;p&gt;同样重要的是有效地处理可用的GPU，因此可以在次秒响应时间内提供多个并发用户请求。这需要高于GPU的软件层，该软件层可以提供请求批处理，内存优化和动态资源管理。这正是VLLM努力提供的。在本文中，我们将探讨VLLM如何实现这一目标并研究其提供的性能改进。&lt;/p&gt;</description>
      <pubDate>Tue, 30 Sep 2025 19:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Caching Mechanisms Using Spring Boot With Redis or AWS ElastiCache】使用redis或AWS Elasticache使用弹簧靴的缓存机制</title>
      <link>https://dzone.com/articles/caching-spring-boot-redis-elasticache</link>
      <description>【&lt;p data-id=&#34;7eee5e92-e2b2-4404-a72d-6eba92c0a8c1&#34; data-pm-slice=&#34;1 1 []&#34;&gt;&lt;span data-copy-source=&#34;unknown&#34; data-insertion-type=&#34;copied&#34;&gt;To decrease latency, improve responsiveness, and lessen database loads, caching has become crucial for today&#39;s performance-demanding applications. Successful caching strategies can be implemented by developers using Redis or AWS ElastiCache in conjunction with Spring Boot&#39;s elegant caching abstraction.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&#xA;&lt;p data-id=&#34;7eee5e92-e2b2-4404-a72d-6eba92c0a8c1&#34; data-pm-slice=&#34;1 1 []&#34;&gt;&lt;span data-ai-insert=&#34;true&#34; data-feature-name=&#34;LanguageSuggestion&#34; data-insertion-type=&#34;ai-generated&#34; data-req-id=&#34;&#34; data-source=&#34;SIDE_BAR&#34;&gt;&lt;span data-copy-source=&#34;unknown&#34; data-insertion-type=&#34;copied&#34;&gt;Low-latency&lt;/span&gt;&lt;/span&gt;&lt;span data-copy-source=&#34;unknown&#34; data-insertion-type=&#34;copied&#34;&gt;&amp;nbsp;responses, high throughput, cost-effectiveness, and scalability are all becoming more and more important for modern applications. Effective caching can improve responsiveness to requests for recently requested data by 10–100 times&lt;/span&gt;&lt;span data-ai-insert=&#34;true&#34; data-feature-name=&#34;LanguageSuggestion&#34; data-insertion-type=&#34;ai-generated&#34; data-req-id=&#34;&#34; data-source=&#34;SIDE_BAR&#34;&gt;&lt;span data-copy-source=&#34;unknown&#34; data-insertion-type=&#34;copied&#34;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;span data-copy-source=&#34;unknown&#34; data-insertion-type=&#34;copied&#34;&gt;&amp;nbsp;while reducing&amp;nbsp;&lt;/span&gt;&lt;span data-ai-insert=&#34;true&#34; data-feature-name=&#34;LanguageSuggestion&#34; data-insertion-type=&#34;ai-generated&#34; data-req-id=&#34;&#34; data-source=&#34;SIDE_BAR&#34;&gt;&lt;span data-copy-source=&#34;unknown&#34; data-insertion-type=&#34;copied&#34;&gt;the&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;span data-copy-source=&#34;unknown&#34; data-insertion-type=&#34;copied&#34;&gt;database load by 70–90%.&lt;/span&gt;&lt;/p&gt;】&lt;p data-id=&#34;7eee5e92-e2b2-4404-a72d-6eba92c0a8c1&#34; data-pm-slice=&#34;1 1 []&#34;&gt;&lt;span data-copy-source=&#34;unknown&#34; data-insertion-type=&#34;copied&#34;&gt;To decrease latency, improve responsiveness, and lessen database loads, caching has become crucial for today&#39;s绩效需求应用程序。成功的缓存策略可以由使用Redis或AWS Elasticache与Spring Boot的优雅缓存抽象结合使用来实现。 &lt;/span&gt; &lt;/p&gt;&#xA;&lt;p data-id =“ 7EEE5E92-E2B2-4404-A72D-6EBA92C0A8C1” data-pm-slice =“ 1 1 [1 []&gt; &lt;span data-ai-ai-iNsert =“ true” data-feature-name-name =“ latchanages ungresageSuggestion” data-insertion-typepe =“ data-insertion-type =” data-source =“ side_bar”&gt; &lt;span data-copy-source =“未知” data-insertion-type =“ copied”&gt;低延迟&lt;/span&gt; &lt;/span&gt; &lt;span data-copy-source =“未知” data Insertion-type =“ copied”&gt;“复制”&gt;响应，高通过，成本效率和量表更加重要。 Effective caching can improve responsiveness to requests for recently requested data by 10–100 times&lt;/span&gt;&lt;span data-ai-insert=&#34;true&#34; data-feature-name=&#34;LanguageSuggestion&#34; data-insertion-type=&#34;ai-generated&#34; data-req-id=&#34;&#34; data-source=&#34;SIDE_BAR&#34;&gt;&lt;span data-copy-source=&#34;unknown&#34; data-insertion-type =“复制”&gt;，&lt;/span&gt; &lt;span data-copy-source =“未知” data-insertion-type =“ copied”&gt;，而还原&lt;/span&gt; &lt;span data-ai-ai-insert =“ true” data-feature-name =“ data-feature-name =” dancement-interagundion data-insertion-insertion-data-insertion-data-typepepepepepepepepepe =“” data-source =“ side_bar”&gt; &lt;span data-copy-source =“未知” data-insertion-type =“ copied”&gt; &lt;/span&gt; &lt;/span&gt; &lt;span data data-copy-source =“ data-insertion-type =“ data-insertion-type =“ copied” copied“ copied”&gt; database“&gt; database”&gt; database load乘以70-90％。</description>
      <pubDate>Tue, 30 Sep 2025 18:00:01 +0000</pubDate>
    </item>
    <item>
      <title>【Creating Real-Time Dashboards Using AWS OpenSearch, EventBridge, and WebSockets】使用AWS OpenSearch，EventBridge和WebSockets创建实时仪表板</title>
      <link>https://dzone.com/articles/aws-realtime-dashboards-opensearch-eventbridge</link>
      <description>【&lt;p dir=&#34;ltr&#34;&gt;If you&#39;ve attempted to build a dashboard, then you&#39;re familiar with the hassle of polling. You hit your API every couple of seconds, grab updates, and pray your data doesn&#39;t feel stale. However, if we&#39;re being honest, polling is inefficient, wasteful, and antiquated. In the modern era, users expect supplies to be dynamic and flowing. We, as developers, should meet that expectation without melting our servers.&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;In this post, I will walk you through a serverless, event-driven architecture that I&#39;ve leveraged to build real-time dashboards using AWS. This architecture will tie together EventBridge, &lt;a href=&#34;https://dzone.com/articles/opensearch-introduction-and-data-management-patter&#34;&gt;OpenSearch&lt;/a&gt;, and API Gateway WebSockets with a hint of Lambda and DynamoDB. By the end, you&#39;ll have some understanding of how all the pieces are tied together to create a live dashboard data pipeline that can scale, can be cost-friendly, and actually feels fast for the end-user.&lt;/p&gt;】&lt;p dir =“ ltr”&gt;如果您尝试构建仪表板，那么您熟悉投票的麻烦。您每隔几秒钟就达到API，获取更新，并祈祷您的数据并不陈旧。但是，如果我们说实话，民意调查效率低下，浪费和过时。在现代时代，用户期望供应动态和流动。作为开发人员，我们应该满足期望，而不会融化服务器。&lt;/p&gt;&#xA;&lt;p dir =“ ltr”&gt;在这篇文章中，我将带您浏览无服务器，事件驱动的架构，我利用该体系结构使用AWS构建实时仪表板。该体系结构将把EventBridge绑在一起，&lt;a href =“ https://dzone.com/articles/opensearch-introduction-and-data-management-patter-OpenSearch &lt;/a&gt;和API Gateway Websockockets，以及lambda and dynamodb的提示。到最后，您将对所有部件如何捆绑在一起，以创建一个可以扩展，可能会易于友好的实时仪表板数据管道，并且实际上对最终用户感到很快。&lt;/p&gt;</description>
      <pubDate>Tue, 30 Sep 2025 17:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Building GitOps Pipelines With Helm on OpenShift: Lessons From the Trenches】在OpenShift上构建Gitops管道：从沟渠上的教训</title>
      <link>https://dzone.com/articles/gitops-pipelines-helm-openshift-lessons</link>
      <description>【&lt;p&gt;After spending the last two years knee-deep in Kubernetes deployments and watching too many &#34;quick fixes&#34; turn into production incidents, I&#39;ve become a true believer in GitOps. Not because it&#39;s the latest buzzword, but because it actually works when you need to sleep at night.&lt;/p&gt;&#xA;&lt;p&gt;Last month, our team finally finished migrating our entire microservices platform to a GitOps workflow using &lt;a href=&#34;https://dzone.com/articles/how-to-handle-secrets-in-helm&#34;&gt;Helm&lt;/a&gt; and &lt;a href=&#34;https://dzone.com/refcardz/getting-started-with-openshift&#34;&gt;OpenShift&lt;/a&gt;. It wasn&#39;t pretty, and we definitely learned some things the hard way. But now that the dust has settled, I wanted to share what we&#39;ve discovered about making this stack work in the real world.&lt;/p&gt;】&lt;p&gt;在过去两年中，在Kubernetes部署中度过了最后两年，观看了太多的“快速修复”变成生产事件后，我成为了Gitops的真正信徒。不是因为这是最新的流行语，而是因为它在晚上需要睡觉时实际上可以工作。&lt;/p&gt;&#xA;&lt;p&gt;上个月，我们的团队终于完成了使用&lt;a href =“ https://dzone.com/articles/how-to-to-how-the-holdle-secrets-in-helm”&gt; helm&gt; helm &lt;/a&gt;和&lt;a &lt;a href =“ https://dzone.com/refcardz/getting-with-with-openshift”&gt; openshift &lt;/a&gt;。这并不漂亮，我们肯定会以艰难的方式学到了一些东西。但是，既然灰尘已经解决了，我想分享我们发现的关于使这个堆栈在现实世界中起作用的东西。&lt;/p&gt;</description>
      <pubDate>Tue, 30 Sep 2025 16:00:04 +0000</pubDate>
    </item>
    <item>
      <title>【Experts Say This Is the Best LLM for Front-End Tasks】专家说，这是前端任务的最佳LLM</title>
      <link>https://dzone.com/articles/best-llm-for-front-end-tasks</link>
      <description>【&lt;p dir=&#34;ltr&#34;&gt;Front-end development is seeing a new wave of automation thanks to large language models (LLMs). From generating UI code to reviewing pull requests, these AI models promise to speed up workflows. But which LLMs truly shine for front-end tasks?&amp;nbsp;&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;We found three experts who had shared their opinions on this topic. In this article, we will analyze their findings and opinions and try to understand which models deliver the most value when integrated into modern &lt;a href=&#34;https://dzone.com/articles/top-tools-for-front-end-developers&#34;&gt;front-end workflows&lt;/a&gt;.&lt;/p&gt;】&lt;p dir =“ ltr”&gt;前端开发借助大型语言模型（LLM）看到了新的自动化浪潮。从生成UI代码到查看拉的请求，这些AI模型有望加快工作流程。但是，哪些LLM确实可以完成前端任务？ &lt;/p&gt;&#xA;&lt;p dir =“ ltr”&gt;我们找到了三位专家，他们对此主题分享了意见。在本文中，我们将分析他们的发现和观点，并尝试了解哪种模型在集成到现代&lt;a href =“ https://dzone.com/articles/top-top-toop-tools-for-for-for-front-end-develpers”&gt;前端 - 前端工作流程&lt;/a&gt;。</description>
      <pubDate>Tue, 30 Sep 2025 15:00:04 +0000</pubDate>
    </item>
    <item>
      <title>【Scoped Filtering: A Practical Bridge to RBAC】范围过滤：通往RBAC的实用桥</title>
      <link>https://dzone.com/articles/scoped-filtering-rbac</link>
      <description>【&lt;p&gt;You’re a startup fresh out of your development-focused cycle, starting to gain traction and demo your product to potential clients. As someone working at a freshly minted Series A company, I understand the priority: get the product working. In our case, that meant demonstrating our data insights solution worked — before implementing sophisticated (but necessary) controls like role-based access control (RBAC).&lt;/p&gt;&#xA;&lt;p&gt;But now, it’s time. Clients are onboarding, and you need to ensure that only the right people can access the right customer data.&lt;/p&gt;】&lt;p&gt;您是以开发为中心的周期中刚成立的初创公司，开始吸引您的产品并将您的产品演示给潜在的客户。作为在一家新鲜铸造的A系列公司工作的人，我理解优先事项：让产品工作。在我们的情况下，这意味着要证明我们的数据见解解决方案有效 - 在实施基于角色的访问控制（RBAC）之类的复杂（但必要）的控件之前。&lt;/p&gt;。&#xA;&lt;p&gt;但是现在是时候了。客户正在入职，您需要确保只有合适的人才能访问正确的客户数据。&lt;/p&gt;</description>
      <pubDate>Tue, 30 Sep 2025 14:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【The Secret to Fast-Tracking Legacy System Modernization With GenAI】使用Genai的快速追踪遗产系统现代化的秘诀</title>
      <link>https://dzone.com/articles/genai-legacy-system-modernization</link>
      <description>【&lt;blockquote&gt;&#xA; &lt;p&gt;“Generative AI is shifting from coding assistants to enterprise transformation, enabling organizations to analyze and modernize complex legacy systems.” — Gartner, Generative AI for Enterprise Transformation, 2024&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;Generative AI (GenAI) is often framed as a tool for accelerating developer productivity, with most discussions centering on code generation. Although that narrative captures attention, it fails to address a deeper, high-value opportunity: transforming and modernizing legacy systems. Enterprises grappling with decades-old applications can leverage GenAI not just to write code faster, but to analyze, refactor, and modernize legacy applications intelligently.&lt;/p&gt;】&lt;BlockQuote&gt;&#xA; &lt;p&gt;“生成的AI正在从编码助手转变为企业转型，使组织能够分析和现代化复杂的遗产系统。” -  Gartner，企业转化的生成AI，2024 &lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;生成的AI（Genai）通常被构架为加速开发人员生产率的工具，大多数讨论都以代码生成为中心。尽管这种叙述引起了人们的关注，但它无法解决更深入，高价值的机会：改变和现代化的遗产系统。企业与数十年历史的应用程序陷入困境，不仅可以更快地编写代码，而且可以智能地分析，重构和现代化遗产应用程序。&lt;/p&gt;</description>
      <pubDate>Tue, 30 Sep 2025 13:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Master Advanced Error-Handling to Make PySpark Pipelines Production-Ready】主高级错误处理以使Pyspark管道准备就绪</title>
      <link>https://dzone.com/articles/pyspark-error-handling-production-pipelines</link>
      <description>【&lt;p dir=&#34;ltr&#34;&gt;In PySpark, processing massive datasets across distributed clusters is powerful but comes with challenges. A single bad record, missing file, or network glitch can crash an entire job, wasting compute resources and leaving you with stack traces that have many lines.&amp;nbsp;&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;Spark’s lazy evaluation, where transformations don’t execute until an action is triggered, makes errors harder to catch early, and debugging them can feel like very, very difficult.&lt;/p&gt;】&lt;p dir =“ ltr”&gt;在pyspark中，跨分布式簇的大量数据集很强大，但遇到了挑战。单个糟糕的记录，缺少文件或网络故障会崩溃整个工作，浪费计算资源，并为您提供具有许多行的堆栈跟踪。 &lt;/p&gt;&#xA;&lt;p dir =“ ltr”&gt; Spark的懒惰评估，在触发动作之前，转换不会执行，使得更难及早捕捉，并且调试它们可能非常非常困难。&lt;/p&gt;</description>
      <pubDate>Tue, 30 Sep 2025 12:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【AI Risks in Product】人工智能在产品中冒险</title>
      <link>https://dzone.com/articles/ai-risks-in-product</link>
      <description>【&lt;h2&gt;TL; DR: AI Risks — It’s A Trap!&lt;/h2&gt;&#xA;&lt;p&gt;AI is tremendously helpful in the hands of a skilled operator. It can accelerate research, generate insights, and support better decision-making. But here’s what the AI evangelists won’t tell you: it can be equally damaging when fundamental AI risks are ignored.&lt;/p&gt;&#xA;&lt;p&gt;The main risk is a gradual transfer of product strategy from business leaders to technical systems — often without anyone deciding this should happen. Teams add “AI” and often report more output, not more learning. That pattern is consistent with long-standing human-factors findings: under time pressure, people over-trust automated cues and under-practice independent verification, which proves especially dangerous when the automation is probabilistic rather than deterministic (Parasuraman &amp;amp; Riley, 1997; see all sources listed below). That’s not a model failure first; it’s a system and decision-making failure that AI accelerates.&lt;/p&gt;】&lt;H2&gt; TL; DR：AI风险 - 这是一个陷阱！&lt;/h2&gt;&#xA;&lt;p&gt; AI在熟练的操作员的手中非常有帮助。它可以加速研究，产生见解并支持更好的决策。但是，这是AI福音传教士不会告诉您的：当忽略基本AI风险时，这同样会造成损害。&lt;/p&gt;&#xA;&lt;p&gt;主要风险是将产品策略从业务领导者逐步转移到技术系统 - 通常没有人决定这种情况。团队添加“ AI”，经常报告更多的输出，而不是更多的学习。这种模式与长期存在的人类因素发现一致：在时间压力下，人们过度信任的自动化提示和独立的独立验证，这在自动化是概率而不是确定性时尤其危险（Parasuraman＆Riley，1997；请参见下面列出的所有消息来源）。首先不是模型故障；这是AI加速的系统和决策故障。&lt;/p&gt;</description>
      <pubDate>Tue, 30 Sep 2025 11:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【5 Manual Testing Techniques Every Tester Should Know】5手动测试技术每个测试人员都应该知道</title>
      <link>https://dzone.com/articles/manual-testing-techniques</link>
      <description>【&lt;p&gt;Despite rapid advancements in test automation and the use of AI in software testing, manual testing is still a fundamental part of software Quality Assurance in 2025. Recent data from multiple industry reports confirm the ongoing value of manual testing in comparison to test automation. For example, only about 5% of companies perform fully automated testing, meaning all test cases are automated without manual intervention. Approximately 2/3rds of companies&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;use a mixed approach, trying to balance both manual and automated testing efforts.&lt;/p&gt;&#xA;&lt;p&gt;Manual testing remains inevitable for the areas that require human insight, judgment, and flexibility. According to this, we may confidently say that you must have the main manual testing techniques to succeed in ensuring quality assurance on your project. So, let&#39;s walk through 5 key manual testing techniques:&amp;nbsp;&lt;/p&gt;】&lt;p&gt;尽管在测试自动化方面取得了迅速的进步和在软件测试中使用AI，但手动测试仍然是2025年软件质量保证的基本组成部分。来自多个行业报告的最新数据证实了与测试自动化相比，手动测试的持续价值。例如，只有大约5％的公司执行全自动测试，这意味着所有测试用例均无需手动干预即可自动化。大约有2/3公司的公司&lt;strong&gt; &lt;/strong&gt;使用混合方法，试图平衡手动和自动测试工作。&lt;/p&gt;&#xA;对于需要人类洞察力，判断力和灵活性的领域，手动测试仍然不可避免。据此，我们可能会自信地说，您必须拥有主要的手动测试技术，以确保您项目的质量保证。因此，让我们浏览5个关键的手动测试技术：&lt;/p&gt;</description>
      <pubDate>Mon, 29 Sep 2025 19:00:07 +0000</pubDate>
    </item>
  </channel>
</rss>