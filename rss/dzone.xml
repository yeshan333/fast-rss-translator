<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>DZone.com Feed</title>
    <link>https://feeds.dzone.com/home</link>
    <description>Recent posts on DZone.com</description>
    <item>
      <title>【Running PyTorch on GPUs】在 GPU 上运行 PyTorch</title>
      <link>https://dzone.com/articles/running-pytorch-on-gpus</link>
      <description>【&lt;p&gt;Running an AI workload on a &lt;a href=&#34;https://dzone.com/articles/applications-for-gpu-based-ai-and-machine-learning&#34;&gt;GPU&lt;/a&gt; machine requires the installation of kernel drivers and user space libraries from GPU vendors such as AMD and NVIDIA. Once the driver and software are installed, to use AI frameworks such as &lt;a href=&#34;https://dzone.com/articles/natural-language-processing-pytorch&#34;&gt;PyTorch&lt;/a&gt; and &lt;a href=&#34;https://dzone.com/articles/ai-frameworks-for-software-engineers-part-1&#34;&gt;TensorFlow&lt;/a&gt;, one needs to use the proper framework built against the GPU target. Usually, the AI applications run on top of popular AI frameworks and as such hide the tedious installation steps. This article highlights the importance of the hardware, driver, software, and frameworks for running AI applications or workloads.&lt;/p&gt;&#xA;&lt;p&gt;This article deals with the Linux operating system, ROCm software stack for AMD GPU, CUDA software stack for NVIDIA GPU, and PyTorch for AI frameworks. Docker plays a critical part in bringing up the entire stack allowing the launch of various workloads in parallel.&lt;/p&gt;】&lt;p&gt;在 &lt;a href=&#34;https://dzone.com/articles/applications-for-gpu-based-ai-and-machine-learning&#34;&gt;GPU&lt;/a&gt; 计算机上运行 AI 工作负载需要安装来自 AMD 和 NVIDIA 等 GPU 供应商的内核驱动程序和用户空间库。安装驱动程序和软件后，即可使用 AI 框架，例如 &lt;a href=&#34;https://dzone.com/articles/natural-language-processing-pytorch&#34;&gt;PyTorch&lt;/a&gt; 和 &lt;a href=&#34;https ://dzone.com/articles/ai-frameworks-for-software-engineers-part-1&#34;&gt;TensorFlow&lt;/a&gt;，需要使用针对 GPU 目标构建的正确框架。通常，人工智能应用程序在流行的人工智能框架之上运行，因此隐藏了繁琐的安装步骤。本文强调了运行人工智能应用程序或工作负载的硬件、驱动程序、软件和框架的重要性。&lt;/p&gt;&#xA;&lt;p&gt;本文介绍了 Linux 操作系统、适用于 AMD GPU 的 ROCm 软件堆栈、适用于 NVIDIA GPU 的 CUDA 软件堆栈以及适用于 AI 框架的 PyTorch。 Docker 在启动整个堆栈以允许并行启动各种工作负载方面发挥着关键作用。&lt;/p&gt;</description>
      <pubDate>Thu, 08 Aug 2024 14:00:03 +0000</pubDate>
    </item>
    <item>
      <title>【Semi-Supervised Learning: How To Overcome the Lack of Labels】半监督学习：如何克服标签的缺失</title>
      <link>https://dzone.com/articles/semi-supervised-learning-overcome-lack-of-labels</link>
      <description>【&lt;p dir=&#34;ltr&#34;&gt;All successfully implemented machine learning models are backed by at least two strong components: data and model. In my discussions with ML engineers, I heard many times that, instead of spending a significant amount of time on data preparation, including labeling for supervised learning, they would rather spend their time on model development. When it comes to most problems, labeling huge amounts of data is way more difficult than obtaining it in the first place.&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;Unlabeled data fails to provide the desired accuracy during training, and labeling huge datasets for supervised learning can be time-consuming and expensive. What if the data labeling budget was limited? What data should be labeled first? These are just some of the daunting questions facing ML engineers who would rather be doing productive work instead.&lt;/p&gt;】&lt;p dir=&#34;ltr&#34;&gt;所有成功实施的机器学习模型都至少有两个强大的组件支持：数据和模型。在与机器学习工程师的讨论中，我多次听到，他们宁愿将时间花在模型开发上，而不是花大量时间在数据准备上，包括监督学习的标签。对于大多数问题，标记大量数据比首先获取数据要困难得多。&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;未标记的数据无法在训练期间提供所需的准确性，并且为监督学习标记巨大的数据集可能既耗时又昂贵。如果数据标签预算有限怎么办？首先应该标记哪些数据？这些只是 ML 工程师面临的一些令人畏惧的问题，他们宁愿从事富有成效的工作。&lt;/p&gt;</description>
      <pubDate>Wed, 07 Aug 2024 19:00:01 +0000</pubDate>
    </item>
    <item>
      <title>【How To Create a CRUD Application in Less Than 15 Minutes】如何在 15 分钟内创建 CRUD 应用程序</title>
      <link>https://dzone.com/articles/create-a-crud-application-in-less-than-15-mins</link>
      <description>【&lt;p&gt;&lt;span data-contrast=&#34;auto&#34; lang=&#34;EN-US&#34;&gt;CRUD applications form the backbone of most software projects today. If you&#39;re reading this article, chances are your project encountered some challenges, you’re seeking a faster way to accomplish this task, or you are looking for a Java framework to start with. You&#39;re not alone.&lt;/span&gt;&lt;span data-ccp-props=&#34;{&amp;quot;201341983&amp;quot;:0,&amp;quot;335559739&amp;quot;:160,&amp;quot;335559740&amp;quot;:259}&#34;&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;span data-contrast=&#34;auto&#34; lang=&#34;EN-US&#34;&gt;With the tech world constantly evolving, especially with tighter budgets,&amp;nbsp;there&#39;s&amp;nbsp;a noticeable shift towards frameworks that bring everything under one roof to reduce the need for oversized teams.&lt;/span&gt;&lt;span data-ccp-props=&#34;{&amp;quot;201341983&amp;quot;:0,&amp;quot;335559739&amp;quot;:160,&amp;quot;335559740&amp;quot;:259}&#34;&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;】&lt;p&gt;&lt;span data-contrast=&#34;auto&#34; lang=&#34;EN-US&#34;&gt;CRUD 应用程序构成了当今大多数软件项目的支柱。如果您正在阅读本文，那么您的项目很可能遇到了一些挑战，您正在寻找一种更快的方法来完成此任务，或者您正在寻找一个 Java 框架来开始。您并不孤单。&lt;/span&gt;&lt;span data-ccp-props=&#34;{&#34;201341983&#34;:0,&#34;335559739&#34;:160,&#34;335559740&#34;:259}&#34;&gt; &lt;/span&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;span data-contrast=&#34;auto&#34; lang=&#34;EN-US&#34;&gt;随着科技世界的不断发展，特别是在预算紧张的情况下，出现了明显的向框架的转变，这些框架将所有内容集中在一个屋檐下，以减少对超大数据的需求团队。&lt;/span&gt;&lt;span data-ccp-props=&#34;{&#34;201341983&#34;:0,&#34;335559739&#34;:160,&#34;335559740&#34;:259}&#34;&gt; &lt;/span&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 08 Aug 2024 16:00:01 +0000</pubDate>
    </item>
    <item>
      <title>【Apache Flink 101: A Guide for Developers】Apache Flink 101：开发人员指南</title>
      <link>https://dzone.com/articles/apache-flink-101-a-guide-for-developers</link>
      <description>【&lt;p dir=&#34;ltr&#34;&gt;In recent years, Apache Flink has established itself as the de facto standard for real-time stream processing. Stream processing is a paradigm for system building that treats event streams (sequences of events in time) as its most essential building block. A stream processor, such as Flink, consumes input streams produced by event sources and produces output streams that are consumed by sinks (the sinks store results and make them available for further processing).&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;Household names like Amazon, Netflix, and Uber rely on Flink to power data pipelines running at tremendous scale at the heart of their businesses, but Flink also plays a key role in many smaller companies with similar requirements for being able to react quickly to critical business events.&lt;/p&gt;】&lt;p dir=&#34;ltr&#34;&gt;近年来，Apache Flink 已成为实时流处理的事实上的标准。流处理是系统构建的范例，它将事件流（时间上的事件序列）视为其最重要的构建块。流处理器（例如 Flink）使用事件源生成的输入流，并生成由接收器使用的输出流（接收器存储结果并使其可用于进一步处理）。&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;Amazon、Netflix 和 Uber 等家喻户晓的公司依靠 Flink 来为其业务核心的大规模数据管道提供支持，但 Flink 在许多具有类似需求的小型公司中也发挥着关键作用。能够对关键业务事件快速做出反应。&lt;/p&gt;</description>
      <pubDate>Thu, 08 Aug 2024 18:30:01 +0000</pubDate>
    </item>
    <item>
      <title>【JavaScript Frameworks: The Past, the Present, and the Future】JavaScript 框架：过去、现在和未来</title>
      <link>https://dzone.com/articles/javascript-frameworks-past-present-and-future</link>
      <description>【&lt;p dir=&#34;ltr&#34;&gt;When we talk about web development, we cannot help but mention JavaScript. Throughout the past several decades, JavaScript frameworks have been the backbone of web development, defining its direction. The capabilities of JavaScript tools have been steadily growing, enabling the creation of faster, more complex, and more efficient websites. This evolution has made a huge leap from jQuery to React, Angular, and Vue.js. We will look at the major milestones in the evolution of the JavaScript framework that have defined web development as we know it today.&lt;/p&gt;&#xA;&lt;h2 dir=&#34;ltr&#34;&gt;The Early Days: jQuery and Its Impact&lt;/h2&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;&lt;a href=&#34;https://dzone.com/refcardz/jquery-selectors&#34;&gt;jQuery&lt;/a&gt; was created in 2005 by developer John Resig, who set out on a journey to realize an audacious idea for the time being: making JavaScript code writing fun. To achieve this daring goal, he stripped common and repetitive tasks of excessive markup and made them short and understandable. This simple recipe helped him create the most popular JavaScript library in the history of the internet.&lt;/p&gt;】&lt;p dir=&#34;ltr&#34;&gt;当我们谈论Web开发时，我们不能不提到JavaScript。在过去的几十年里，JavaScript 框架一直是 Web 开发的支柱，定义了它的方向。 JavaScript 工具的功能一直在稳步增长，能够创建更快、更复杂、更高效的网站。这种演变实现了从 jQuery 到 React、Angular 和 Vue.js 的巨大飞跃。我们将了解 JavaScript 框架发展过程中的主要里程碑，这些里程碑定义了我们今天所知的 Web 开发。&lt;/p&gt;&#xA;&lt;h2 dir=&#34;ltr&#34;&gt;早期：jQuery 及其影响&lt;/h2&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;&lt;a href=&#34;https://dzone.com/refcardz/jquery-selectors&#34;&gt;jQuery&lt;/a&gt; 由开发人员 John Resig 于 2005 年创建，他踏上了实现目前有一个大胆的想法：让 JavaScript 代码编写变得有趣。为了实现这个大胆的目标，他去除了常见和重复性任务的过多标记，使它们变得简短易懂。这个简单的秘诀帮助他创建了互联网历史上最受欢迎的 JavaScript 库。&lt;/p&gt;</description>
      <pubDate>Thu, 08 Aug 2024 13:00:01 +0000</pubDate>
    </item>
    <item>
      <title>【Batch vs. Real-Time Processing: Understanding the Differences】批处理与实时处理：了解差异</title>
      <link>https://dzone.com/articles/batch-vs-real-time-processing-understanding-the-differences</link>
      <description>【&lt;p&gt;The decision between batch and real-time processing is a critical one, shaping the design, architecture, and success of our data pipelines. While both methods aim to extract valuable insights from data, they differ significantly in their execution, capabilities, and use cases. Understanding the key distinctions between these two processing paradigms is crucial for organizations to make informed decisions and harness the full potential of their data.&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Key definitions can be summarized as follows:&lt;/p&gt;】&lt;p&gt;批处理和实时处理之间的决策至关重要，它决定着我们数据管道的设计、架构和成功。虽然这两种方法都旨在从数据中提取有价值的见解，但它们在执行、功能和用例方面存在显着差异。了解这两种处理范例之间的主要区别对于组织做出明智的决策并充分利用数据潜力至关重要。 &lt;/p&gt;&#xA;&lt;p&gt;主要定义可概括如下：&lt;/p&gt;</description>
      <pubDate>Thu, 08 Aug 2024 19:20:39 +0000</pubDate>
    </item>
    <item>
      <title>【How To Scale RAG and Build More Accurate LLMs】如何扩展 RAG 并构建更准确的法学硕士</title>
      <link>https://dzone.com/articles/how-to-scale-rag-and-build-more-accurate-llms</link>
      <description>【&lt;p dir=&#34;ltr&#34;&gt;&lt;a href=&#34;https://www.eweek.com/artificial-intelligence/what-is-retrieval-augmented-generation-rag/&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt;Retrieval augmented generation&lt;/a&gt; (RAG) has emerged as a leading pattern to combat hallucinations and other inaccuracies that affect large language model content generation. However, RAG needs the right data architecture around it to scale effectively and efficiently. A data streaming approach grounds the optimal architecture for supplying LLMs with large volumes of continuously enriched, trustworthy data to generate accurate results. This approach also allows data and application teams to work and scale independently to accelerate innovation.&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;Foundational LLMs like GPT and Llama are trained on vast amounts of data and can often generate reasonable responses about a broad range of topics, but do generate erroneous content. As Forrester noted recently, public LLMs “regularly produce results that are irrelevant or flat wrong,” because their training data is weighted toward publicly available internet data. In addition, these foundational LLMs are completely blind to the corporate data locked away in customer databases, ERP systems, corporate Wikis, and other internal data sources. This hidden data must be leveraged to improve accuracy and unlock real business value.&lt;/p&gt;】&lt;p dir=&#34;ltr&#34;&gt;&lt;a href=&#34;https://www.eweek.com/artificial-intelligence/what-is-retrieval-augmented- Generation-rag/&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank &#34;&gt;检索增强生成&lt;/a&gt; (RAG) 已成为对抗影响大型语言模型内容生成的幻觉和其他不准确性的主要模式。然而，RAG 需要围绕其正确的数据架构才能有效且高效地扩展。数据流方法奠定了最佳架构的基础，为法学硕士提供大量不断丰富的、值得信赖的数据，以生成准确的结果。这种方法还允许数据和应用程序团队独立工作和扩展，以加速创新。&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;GPT 和 Llama 等基础法学硕士接受了大量数据的培训，通常可以针对广泛的主题生成合理的响应，但确实会生成错误的内容。正如 Forrester 最近指出的那样，公共法学硕士“经常产生不相关或完全错误的结果”，因为他们的训练数据是针对公开的互联网数据进行加权的。此外，这些基础法学硕士对锁定在客户数据库、ERP 系统、企业 Wiki 和其他内部数据源中的企业数据完全视而不见。必须利用这些隐藏数据来提高准确性并释放真正的商业价值。&lt;/p&gt;</description>
      <pubDate>Thu, 08 Aug 2024 12:00:01 +0000</pubDate>
    </item>
    <item>
      <title>【Leveraging Snowflake’s AI/ML Capabilities for Anomaly Detection】利用 Snowflake 的 AI/ML 功能进行异常检测</title>
      <link>https://dzone.com/articles/leveraging-snowflake-aiml-for-anomaly-detection</link>
      <description>【&lt;p&gt;Anomaly detection is the process of identifying the data deviation from the expected results in a &lt;a href=&#34;https://dzone.com/articles/overview-of-classical-time-series-analysis&#34;&gt;time-series data&lt;/a&gt;. This deviation can have a huge impact on forecasting models if not identified before the model creation. &lt;a href=&#34;https://dzone.com/articles/introduction-to-snowflake-for-junior-software-engi&#34;&gt;Snowflake&lt;/a&gt; Cortex AL/ML suite helps you train the models to spot and correct these outliers in order to help improve the quality of your results. Detecting outliers also helps in identifying the source of the deviations in processes.&lt;/p&gt;&#xA;&lt;p&gt;Anomaly detection works with both single and multi-series data. Multi-series data represents multiple independent threads of events. For example, if you have sales data for multiple stores, each store’s sales can be checked separately by a single model based on the store identifier. These outliers can be detected in time-series data using the Snowflake built-in class &lt;code&gt;SNOWFLAKE.ML.ANOMALY_DETECTION&lt;/code&gt;.&lt;/p&gt;】&lt;p&gt;异常检测是识别&lt;a href=&#34;https://dzone.com/articles/overview-of-classical-time-series-analysis&#34;&gt;时间序列中的数据与预期结果的偏差的过程数据&lt;/a&gt;。如果在模型创建之前未识别出这种偏差，则可能会对预测模型产生巨大影响。 &lt;a href=&#34;https://dzone.com/articles/introduction-to-snowflake-for-junior-software-engi&#34;&gt;Snowflake&lt;/a&gt; Cortex AL/ML 套件可帮助您训练模型来发现和纠正这些问题异常值，以帮助提高结果的质量。检测异常值还有助于识别流程偏差的根源。&lt;/p&gt;&#xA;&lt;p&gt;异常检测适用于单系列数据和多系列数据。多系列数据代表多个独立的事件线程。例如，如果您有多个商店的销售数据，则可以根据商店标识符通过单个模型单独检查每个商店的销售额。可以使用 Snowflake 内置类 &lt;code&gt;SNOWFLAKE.ML.ANOMALY_DETECTION&lt;/code&gt; 在时间序列数据中检测这些异常值。&lt;/p&gt;</description>
      <pubDate>Thu, 08 Aug 2024 11:00:01 +0000</pubDate>
    </item>
    <item>
      <title>【The Case for Working on Non-Glamorous Migration Projects】从事非光鲜亮丽的移民项目的案例</title>
      <link>https://dzone.com/articles/case-for-working-on-non-glamorous-migration-projects</link>
      <description>【&lt;p dir=&#34;ltr&#34;&gt;In my 13 years of engineering experience, I saw many people make career decisions based on the opportunity to work on a brand-new service. There is nothing wrong with that decision. However, today we are going to make a contradictory case of working on boring migration projects. What I did not realize early on in my career was that most of my foundational software development learning came from projects that were migration projects — e.g., migrating an underlying data store to another cloud-based technology or deprecating a monolithic service in favor of new microservices, etc.&amp;nbsp;&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;This is because migrations are inherently hard: you are forced to meet, if not exceed, an existing bar on availability, scale, latency, and customer experience which was built and honed over the years by multiple engineers. You won’t face those constraints on a brand-new system because you are free to define them. Not only that, no matter how thorough you are with migrations, there will be hidden skeletons in the closet to deal with when you switch over to new parts of the system (Check out this &lt;a href=&#34;https://doordash.engineering/2022/01/19/making-applications-compatible-with-postgres-tables-bigint-update/&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt;interesting article&lt;/a&gt;&lt;a href=&#34;https://doordash.engineering/2022/01/19/making-applications-compatible-with-postgres-tables-bigint-update/on&#34;&gt;&amp;nbsp;&lt;/a&gt;on how Doordash’s migration from Int to BigInt for a database field was fraught with blockers).&amp;nbsp;&lt;/p&gt;】&lt;p dir=&#34;ltr&#34;&gt;在我 13 年的工程经验中，我看到许多人根据从事全新服务的机会做出职业决定。这个决定并没有什么错。然而，今天我们要举一个矛盾的例子，那就是从事无聊的迁移项目。在我职业生涯的早期，我没有意识到的是，我的大部分基础软件开发学习都来自迁移项目，例如，将底层数据存储迁移到另一种基于云的技术，或者弃用单一服务以支持新的微服务等等。&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;这是因为迁移本质上是困难的：您被迫满足（如果不能超越的话）可用性、规模、延迟和客户体验方面的现有标准，这些标准是由多名工程师多年来建立和磨练的。您不会在全新系统上面临这些限制，因为您可以自由定义它们。不仅如此，无论您的迁移有多彻底，当您切换到系统的新部分时，壁橱里都会有隐藏的骨架需要处理（查看此 &lt;a href=&#34;https://doordash.engineering /2022/01/19/making-applications-compat-with-postgres-tables-bigint-update/&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt;有趣的文章&lt;/a&gt;&lt;a href=&#34;https:// /doordash.engineering/2022/01/19/making-applications-known-with-postgres-tables-bigint-update/on&#34;&gt; &lt;/a&gt;了解 Doordash 将数据库字段从 Int 迁移到 BigInt 时如何充满了阻碍）。 &lt;/p&gt;</description>
      <pubDate>Thu, 08 Aug 2024 21:00:01 +0000</pubDate>
    </item>
    <item>
      <title>【10 Kubernetes Cost Optimization Techniques】10 种 Kubernetes 成本优化技术</title>
      <link>https://dzone.com/articles/10-kubernetes-cost-optimisation-techniques</link>
      <description>【&lt;p&gt;These are 10 strategies for reducing Kubernetes costs. We’ve split them into pre-deployment, post-deployment, and ongoing cost optimization techniques to help people at the beginning and middle of their cloud journeys, as well as those who have fully adopted the cloud and are just looking for a few extra pointers.&lt;/p&gt;&#xA;&lt;p&gt;So, let’s get started.&lt;/p&gt;】&lt;p&gt;这是降低 Kubernetes 成本的 10 种策略。我们将它们分为部署前、部署后和持续成本优化技术，以帮助人们在云之旅的开始和中期，以及那些已经完全采用云但只是寻求一些额外的帮助的人指针。&lt;/p&gt;&#xA;&lt;p&gt;那么，让我们开始吧。&lt;/p&gt;</description>
      <pubDate>Wed, 07 Aug 2024 18:00:01 +0000</pubDate>
    </item>
  </channel>
</rss>