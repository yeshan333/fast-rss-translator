<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>DZone.com Feed</title>
    <link>https://feeds.dzone.com/home</link>
    <description>Recent posts on DZone.com</description>
    <item>
      <title>【The Future of Data Streaming with Apache Flink for Agentic AI】使用 Apache Flink 实现代理 AI 的数据流的未来</title>
      <link>https://dzone.com/articles/future-of-data-streaming-apache-flink-for-agentic-ai</link>
      <description>【&lt;p data-end=&#34;604&#34; data-start=&#34;230&#34;&gt;&lt;a href=&#34;https://dzone.com/articles/how-autonomous-ai-agents-are-redefining-enterprise-analytics&#34;&gt;Agentic AI is changing how enterprises think about automation and intelligence&lt;/a&gt;. Agents are no longer reactive systems. They are goal-driven, context-aware, and capable of autonomous decision-making. But to operate effectively, agents must be connected to the real-time pulse of the business. This is where data streaming with Apache Kafka and Apache Flink becomes essential.&lt;/p&gt;&#xA;&lt;p data-end=&#34;876&#34; data-start=&#34;606&#34;&gt;Apache Flink is entering a new phase with the proposal of Flink Agents, a sub-project designed to power system-triggered, event-driven AI agents natively within Flink’s streaming runtime. Let’s explore what this means for the future of agentic systems in the enterprise.&lt;/p&gt;】&lt;p data-end=&#34;604&#34; data-start=&#34;230&#34;&gt;&lt;a href=&#34;https://dzone.com/articles/how-autonomous-ai-agents-are-redefining-enterprise-analytics&#34;&gt;代理 AI 正在改变企业对自动化和智能的看法&lt;/a&gt;。代理不再是反应性系统。他们以目标为导向，具有情境感知能力，并且能够自主决策。但为了有效运作，代理必须连接到业务的实时脉搏。这就是使用 Apache Kafka 和 Apache Flink 进行数据流处理变得至关重要的地方。&lt;/p&gt;&#xA;&lt;p data-end=&#34;876&#34; data-start=&#34;606&#34;&gt;随着 Flink Agents 的提议，Apache Flink 正在进入一个新阶段，Flink Agents 是一个子项目，旨在为 Flink 流运行时内的系统触发、事件驱动的 AI 代理提供原生支持。让我们探讨一下这对于企业中代理系统的未来意味着什么。&lt;/p&gt;</description>
      <pubDate>Wed, 21 Jan 2026 20:00:09 +0000</pubDate>
    </item>
    <item>
      <title>【An Automated Inventory Pattern for Managing AWS EC2】用于管理 AWS EC2 的自动库存模式</title>
      <link>https://dzone.com/articles/automated-inventory-pattern-for-managing-aws-ec2</link>
      <description>【&lt;p data-end=&#34;490&#34; data-start=&#34;248&#34;&gt;In the &lt;a href=&#34;https://dzone.com/articles/hybrid-cloud-vs-multi-cloud&#34;&gt;hybrid cloud era&lt;/a&gt;, managing infrastructure visibility is a constant battle. We spin up EC2 instances for testing, leave them running, and forget about them. Security groups become bloated, and cost management turns into a guessing game.&lt;/p&gt;&#xA;&lt;p data-end=&#34;741&#34; data-start=&#34;492&#34;&gt;While high-end tools like Datadog or CloudHealth offer solutions, they often come with significant licensing costs and integration overhead. Sometimes, you just need a lightweight, customizable way to see exactly what is running in your environment.&lt;/p&gt;】&lt;p data-end=&#34;490&#34; data-start=&#34;248&#34;&gt;在&lt;a href=&#34;https://dzone.com/articles/hybrid-cloud-vs-multi-cloud&#34;&gt;混合云时代&lt;/a&gt;，管理基础设施可见性是一场持久战。我们启动 EC2 实例进行测试，让它们运行，然后忘记它们。安全团队变得臃肿，成本管理变成了猜谜游戏。&lt;/p&gt;&#xA;&lt;p data-end=&#34;741&#34; data-start=&#34;492&#34;&gt;虽然 Datadog 或 CloudHealth 等高端工具提供解决方案，但它们通常会带来高昂的许可成本和集成开销。有时，您只需要一种轻量级、可自定义的方式来准确查看环境中正在运行的内容。&lt;/p&gt;</description>
      <pubDate>Wed, 21 Jan 2026 19:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Where AI Fits and Fails in Workday Integrations】人工智能在工作日集成中的适用和失败之处</title>
      <link>https://dzone.com/articles/where-ai-fits-and-fails-in-workday-integrations</link>
      <description>【&lt;p data-end=&#34;913&#34; data-start=&#34;257&#34;&gt;Workday integrations sit at the heart of enterprise HR and finance systems, connecting Workday with myriad external applications. As &lt;a href=&#34;https://dzone.com/articles/the-ai-revolution-software-development&#34;&gt;artificial intelligence (AI) makes inroads into enterprise software&lt;/a&gt;, Workday engineers are exploring how AI can augment integration development and operations. From mapping data fields to detecting anomalies, AI promises to reduce manual effort and improve reliability. Yet amid the excitement, it is critical to distinguish where AI adds clear value versus where it overpromises or introduces risk. This strategic overview examines both sides, providing a balanced perspective for technically fluent Workday professionals.&lt;/p&gt;&#xA;&lt;p data-end=&#34;1581&#34; data-start=&#34;915&#34;&gt;Workday itself has signaled a strong commitment to AI, embedding machine learning and automation into its platform. The goal is to weave intelligence into the flow of work rather than create standalone AI silos. For integration teams, this means new tools and features are emerging to streamline workflows. At the same time, seasoned engineers know that complex integrations require human insight. As we will see, AI will likely serve as an enhancer — not a replacement — for the expertise and judgment of Workday integration developers. With that context, let’s explore specific use cases where AI fits in Workday integrations and where it fails to live up to the hype.&lt;/p&gt;】&lt;p data-end=&#34;913&#34; data-start=&#34;257&#34;&gt;Workday 集成是企业人力资源和财务系统的核心，将 Workday 与无数外部应用程序连接起来。随着&lt;a href=&#34;https://dzone.com/articles/the-ai-revolution-software-development&#34;&gt;人工智能 (AI) 进军企业软件&lt;/a&gt;，Workday 工程师正在探索 AI 如何增强集成开发和运营。从绘制数据字段到检测异常，人工智能有望减少人工工作并提高可靠性。然而，在兴奋之际，区分人工智能在哪些方面增加了明显的价值，以及在哪些方面过度承诺或引入了风险，这一点至关重要。此战略概述对双方进行了审视，为技术流利的 Workday 专业人士提供了平衡的视角。&lt;/p&gt;&#xA;&lt;p data-end=&#34;1581&#34; data-start=&#34;915&#34;&gt;Workday 本身就表明了对人工智能的坚定承诺，将机器学习和自动化嵌入到其平台中。目标是将智能融入到工作流程中，而不是创建独立的人工智能孤岛。对于集成团队来说，这意味着新的工具和功能正在出现，以简化工作流程。与此同时，经验丰富的工程师知道复杂的集成需要人类的洞察力。正如我们将看到的，人工智能很可能会增强而非替代 Workday 集成开发人员的专业知识和判断力。在此背景下，让我们探讨一下人工智能适合 Workday 集成以及它未能达到宣传效果的具体用例。&lt;/p&gt;</description>
      <pubDate>Wed, 21 Jan 2026 18:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【RAG Architectures AI Builders Should Understand】AI 构建者应该了解的 RAG 架构</title>
      <link>https://dzone.com/articles/rag-ai-for-ai-builders</link>
      <description>【&lt;p&gt;Large language models are exceptionally good at producing fluent text. They are not, by default, good at staying current, respecting boundaries of private knowledge, or documenting the sources of an answer. That gap is exactly where most AI products fail: the demo looks impressive, but the system is not trustworthy when users rely on it.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://dzone.com/articles/introduction-to-retrieval-augmented-generation-rag&#34;&gt;Retrieval-augmented generation&lt;/a&gt; (RAG) closes the gap by designing an evidence path. Instead of letting the model “reason from memory,” you route the request through retrieval, enforce access rules, collect supporting sources, and then ask the model to answer from those sources with citations. In practice, RAG is less about prompting and more about engineering: a data pipeline, a contract, and an operational loop.&lt;/p&gt;】&lt;p&gt;大型语言模型非常擅长生成流畅的文本。默认情况下，他们不擅长保持最新状态、尊重私人知识的界限或记录答案的来源。这一差距正是大多数人工智能产品失败的地方：演示看起来令人印象深刻，但当用户依赖它时，系统并不值得信赖。&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://dzone.com/articles/introduction-to-retrieval-augmented- Generation-rag&#34;&gt;检索增强生成&lt;/a&gt; (RAG) 通过设计证据路径来缩小差距。您不是让模型“从记忆中推理”，而是通过检索来路由请求，强制执行访问规则，收集支持源，然后要求模型通过引用从这些源中回答。在实践中，RAG 较少涉及提示，而更多涉及工程：数据管道、合同和操作循环。&lt;/p&gt;</description>
      <pubDate>Wed, 21 Jan 2026 17:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【The No-Buffering Strategy: Streaming Search Results】无缓冲策略：流式传输搜索结果</title>
      <link>https://dzone.com/articles/no-buffering-strategy-streaming-search-results</link>
      <description>【&lt;h2 dir=&#34;ltr&#34;&gt;The &#34;Buffering&#34; Problem&lt;/h2&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;Let’s draw a parallel to video streaming. Modern protocols break the video into small, ordered chunks. This allows the client to render content immediately while the rest buffers in the background. The total data and the download time stay roughly the same, but the perceived speed improves dramatically.&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;Complex search engines can be architected in a similar streaming fashion.&lt;/p&gt;】&lt;h2 dir=&#34;ltr&#34;&gt;“缓冲”问题&lt;/h2&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;让我们与视频流进行类比。现代协议将视频分成小的、有序的块。这允许客户端立即渲染内容，而其余内容在后台缓冲。总数据量和下载时间大致保持不变，但感知速度显着提高。&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;复杂的搜索引擎可以以类似的流媒体方式构建。&lt;/p&gt;</description>
      <pubDate>Wed, 21 Jan 2026 16:00:06 +0000</pubDate>
    </item>
    <item>
      <title>【MERGE and Liquid Clustering: Common Performance Issues】MERGE 和 Liquid Clustering：常见性能问题</title>
      <link>https://dzone.com/articles/merge-liquid-clustering-common-issues</link>
      <description>【&lt;p&gt;As a Spark support engineer, I still encounter many cases where MERGE or JOIN operations on Delta tables do not perform as expected, even when liquid clustering is used. While liquid clustering is a significant improvement over traditional partitioning and offers many advantages, people still sometimes struggle with it. There is often an assumption that enabling liquid clustering will automatically result in efficient merges, but in practice, this is not always true, and the reason is a lack of understanding.&amp;nbsp;&lt;/p&gt;&#xA;&lt;p&gt;Here are the most common issues when executing a merge on a liquid clustering table.&amp;nbsp;&lt;/p&gt;】&lt;p&gt;作为一名 Spark 支持工程师，我仍然遇到很多情况，即 Delta 表上的 MERGE 或 JOIN 操作未按预期执行，即使使用了流动集群也是如此。虽然液体聚类相对于传统分区来说是一个显着的改进，并提供了许多优点，但人们有时仍然会遇到困难。人们常常假设启用流动集群会自动产生高效的合并，但在实践中，这并不总是正确的，原因是缺乏理解。 &lt;/p&gt;&#xA;&lt;p&gt;以下是在流动集群表上执行合并时最常见的问题。 &lt;/p&gt;</description>
      <pubDate>Wed, 21 Jan 2026 15:00:01 +0000</pubDate>
    </item>
    <item>
      <title>【Why High-Availability Java Systems Fail Quietly Before They Fail Loudly】为什么高可用性 Java 系统在严重失败之前会悄然失败</title>
      <link>https://dzone.com/articles/java-high-availability-failures</link>
      <description>【&lt;p data-end=&#34;679&#34; data-start=&#34;432&#34;&gt;Most engineers imagine failures as sudden events. A service crashes. A node goes down. An alert fires, and everyone jumps into action. In real high-availability Java systems, failures rarely behave that way. They almost always arrive quietly first.&lt;/p&gt;&#xA;&lt;p data-end=&#34;1014&#34; data-start=&#34;681&#34;&gt;Systems that have been running reliably for months or years begin to show small changes. Latency creeps up. Garbage collection pauses last a little longer. Thread pools spend more time near saturation. Nothing looks broken, and dashboards stay mostly green. Then one day, the system tips over, and the failure suddenly looks dramatic.&lt;/p&gt;】&lt;p data-end=&#34;679&#34; data-start=&#34;432&#34;&gt;大多数工程师将故障视为突发事件。服务崩溃。一个节点宕机了。警报响起，每个人都立即采取行动。在真正的高可用性 Java 系统中，故障很少会出现这种情况。他们几乎总是先悄悄到达。&lt;/p&gt;&#xA;&lt;p data-end=&#34;1014&#34; data-start=&#34;681&#34;&gt;已经可靠运行数月或数年的系统开始出现微小的变化。延迟逐渐增加。垃圾收集暂停的时间会更长一些。线程池花费更多时间接近饱和。看起来没有任何损坏，仪表板大部分保持绿色。然后有一天，系统崩溃了，故障突然看起来很戏剧化。&lt;/p&gt;</description>
      <pubDate>Wed, 21 Jan 2026 14:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Multimodal AI Architecture: Unifying Vision, Text, and Sensor Intelligence】多模态 AI 架构：统一视觉、文本和传感器智能</title>
      <link>https://dzone.com/articles/multimodal-ai-vision-text-sensor</link>
      <description>【&lt;p&gt;Most Android AI features today are still single-modal&lt;/p&gt;&#xA;&lt;ul&gt;&#xA; &lt;li&gt;A camera screen that does object detection.&lt;/li&gt;&#xA; &lt;li&gt;A chat screen that calls an LLM.&lt;/li&gt;&#xA; &lt;li&gt;A sensor-driven feature that runs in the background.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;The real fun starts when you &lt;strong&gt;combine&lt;/strong&gt; these: camera, text, sensors, history, and context. That’s where multimodal AI shines — and where architecture makes or breaks your app.&lt;/p&gt;】&lt;p&gt;如今大多数 Android AI 功能仍然是单模式&lt;/p&gt;&#xA;&lt;ul&gt;&#xA; &lt;li&gt;进行物体检测的摄像头屏幕。&lt;/li&gt;&#xA; &lt;li&gt;调用 LLM 的聊天屏幕。&lt;/li&gt;&#xA; &lt;li&gt;在后台运行的传感器驱动功能。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;当您&lt;strong&gt;组合&lt;/strong&gt;这些时，真正的乐趣就开始了：相机、文本、传感器、历史记录和背景。这就是多模式人工智能的闪光点，也是架构决定你的应用程序的成败的地方。&lt;/p&gt;</description>
      <pubDate>Wed, 21 Jan 2026 13:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【AI-Driven Autonomous CI/CD for Risk-Aware DevOps】AI 驱动的自主 CI/CD 用于风险意识 DevOps</title>
      <link>https://dzone.com/articles/autonomous-cicd-ai-risk-aware-devops</link>
      <description>【&lt;p dir=&#34;ltr&#34;&gt;Currently, the software development process relies on integrating development and operations (DevOps) to accelerate delivery without compromising quality. When the system becomes very complex, it becomes risky and delays the manual control of the continuous integration or continuous deployment (CI/CD) processes. AI-based autonomous pipelines manage the entire process by automating decisions, optimizing, and eliminating human errors.&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;Continuous risk-aware DevOps involves monitoring and signaling issues, as well as predicting failures. The self-healing mechanisms handle the whole thing in a way that minimises disruption and improves system stability across different deployments.&lt;/p&gt;】&lt;p dir=&#34;ltr&#34;&gt;目前，软件开发流程依靠集成开发和运营 (DevOps) 来加速交付而不影响质量。当系统变得非常复杂时，就会变得有风险并延迟持续集成或持续部署（CI/CD）流程的手动控制。基于人工智能的自主管道通过自动化决策、优化和消除人为错误来管理整个流程。&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;持续的风险意识 DevOps 涉及监控和发出信号问题，以及预测故障。自我修复机制以最小化中断并提高不同部署中的系统稳定性的方式处理整个问题。&lt;/p&gt;</description>
      <pubDate>Wed, 21 Jan 2026 12:00:13 +0000</pubDate>
    </item>
    <item>
      <title>【Automating Traceability with Generative AI】利用生成式人工智能实现自动化追踪</title>
      <link>https://dzone.com/articles/automating-traceability-with-generative-ai</link>
      <description>【&lt;p data-end=&#34;392&#34; data-start=&#34;240&#34;&gt;In the world of software engineering, we &lt;a href=&#34;https://dzone.com/articles/ci-cd-autonomous-pipelines-automation&#34;&gt;have robust CI/CD pipelines&lt;/a&gt; that ensure code traceability. We know exactly which commit caused a build failure.&lt;/p&gt;&#xA;&lt;p data-end=&#34;758&#34; data-start=&#34;394&#34;&gt;However, in Infrastructure Systems Engineering (Infrastructure SE), traceability is often broken. The documentation says one thing, the server configuration says another, and the test specification says a third. Verifying that the &lt;strong data-end=&#34;642&#34; data-start=&#34;625&#34;&gt;design intent&lt;/strong&gt; matches the &lt;strong data-end=&#34;671&#34; data-start=&#34;655&#34;&gt;actual state&lt;/strong&gt; is usually a manual process involving screenshots, spreadsheets, and human eyeballing.&lt;/p&gt;】&lt;p data-end=&#34;392&#34; data-start=&#34;240&#34;&gt;在软件工程领域，我们&lt;a href=&#34;https://dzone.com/articles/ci-cd-autonomous-pipelines-automation&#34;&gt;拥有强大的 CI/CD 管道&lt;/a&gt;来确保代码可追溯性。我们确切地知道哪个提交导致了构建失败。&lt;/p&gt;&#xA;&lt;p data-end=&#34;758&#34; data-start=&#34;394&#34;&gt;但是，在基础设施系统工程 (Infrastruction SE) 中，可追溯性常常被破坏。文档说的是一件事，服务器配置说的是另一件事，测试规范说的是第三件事。验证&lt;strong data-end=&#34;642&#34; data-start=&#34;625&#34;&gt;设计意图&lt;/strong&gt;是否与&lt;strong data-end=&#34;671&#34; data-start=&#34;655&#34;&gt;实际状态&lt;/strong&gt;匹配通常是一个手动过程，涉及屏幕截图、电子表格和人工目视。&lt;/p&gt;</description>
      <pubDate>Tue, 20 Jan 2026 20:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>