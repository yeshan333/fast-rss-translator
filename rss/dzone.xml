<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>DZone.com Feed</title>
    <link>https://feeds.dzone.com/home</link>
    <description>Recent posts on DZone.com</description>
    <item>
      <title>【Mastering Date-Time APIs: Challenges With Java&#39;s Calendar and JDK Date/Time APIs】掌握日期/时间 API：Java 日历和 JDK 日期/时间 API 的挑战</title>
      <link>https://dzone.com/articles/mastering-date-time-apis-challenges-with-javas</link>
      <description>【&lt;p&gt;In this article, we&#39;ll address four problems covering different date-time topics. These problems are mainly focused on the &lt;a href=&#34;https://dzone.com/articles/finding-a-time-to-meet-via-the-google-calendar-api&#34;&gt;Calendar API&lt;/a&gt; and on the &lt;a href=&#34;https://dzone.com/articles/deeper-look-java-8-date-and&#34;&gt;JDK Date/Time API&lt;/a&gt;.&amp;nbsp;&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA; &lt;p&gt;&lt;em&gt;Disclaimer: This article is an abstract from my recent book&amp;nbsp;&lt;/em&gt;&lt;a href=&#34;https://packt.link/wpywI&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Java Coding Problems, Second Edition&lt;/em&gt;&lt;/a&gt;&lt;em&gt;.&lt;/em&gt;&lt;/p&gt;】&lt;p&gt;在本文中，我们将解决涉及不同日期时间主题的四个问题。这些问题主要集中在 &lt;a href=&#34;https://dzone.com/articles/finding-a-time-to-meet-via-the-google-calendar-api&#34;&gt;Calendar API&lt;/a&gt; 和在 &lt;a href=&#34;https://dzone.com/articles/deeper-look-java-8-date-and&#34;&gt;JDK 日期/时间 API&lt;/a&gt; 上。 &lt;/p&gt;&#xA;&lt;块引用&gt;&#xA; &lt;p&gt;&lt;em&gt;免责声明：本文是我最近出版的一本书的摘要&lt;/em&gt;&lt;a href=&#34;https://packt.link/wpywI&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt;&lt;em&gt; &gt;Java 编码问题，第二版&lt;/em&gt;&lt;/a&gt;&lt;em&gt;.&lt;/em&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 15 Oct 2024 21:00:03 +0000</pubDate>
    </item>
    <item>
      <title>【Event-Driven vs Event-Sourced: A Common Misunderstanding】事件驱动与事件源：一个常见的误解</title>
      <link>https://dzone.com/articles/event-driven-vs-event-sourced</link>
      <description>【&lt;p data-selectable-paragraph=&#34;&#34;&gt;In today’s world of software development, systems containing some sort of event constructs are increasing in popularity. While this is primarily driven by message-based communication mechanisms, events are also used in different scopes and contexts. The frequent use of the term “event” leads to confusion, which is often observed in discussions about various software architectures among people who are new to these concepts. The terms “event-driven” and “event-sourced” are often used interchangeably, while in reality, the two are very different concepts. In this article, we are going to explore the key characteristics of each, explain how they differ, and how they complement each other. We will focus on clarifying the key differences, not a deep dive into each concept.&lt;/p&gt;&#xA;&lt;p data-selectable-paragraph=&#34;&#34;&gt;Before we dive in, let’s clarify the definition of an “event” in both event-driven and event-sourced systems. An event is an immutable record describing something that has happened in the past. Therefore, the data that an event contains cannot be changed. Immutability and description of the past are fundamental characteristics of events.&lt;/p&gt;】&lt;p data-selectable-paragraph=&#34;&#34;&gt;在当今的软件开发世界中，包含某种事件构造的系统越来越受欢迎。虽然这主要是由基于消息的通信机制驱动的，但事件也用于不同的范围和上下文。频繁使用“事件”一词会导致混乱，这种情况在刚接触这些概念的人们讨论各种软件架构时经常出现。 “事件驱动”和“事件溯源”这两个术语经常互换使用，但实际上，两者是非常不同的概念。在本文中，我们将探讨它们的关键特征，解释它们的不同之处以及它们如何相互补充。我们将专注于澄清关键差异，而不是深入探讨每个概念。&lt;/p&gt;&#xA;&lt;p data-selectable-paragraph=&#34;&#34;&gt;在深入讨论之前，我们先澄清一下事件驱动系统和事件溯源系统中“事件”的定义。事件是描述过去发生的事情的不可变记录。因此，事件包含的数据无法更改。不变性和对过去的描述是事件的基本特征。&lt;/p&gt;</description>
      <pubDate>Wed, 16 Oct 2024 11:00:03 +0000</pubDate>
    </item>
    <item>
      <title>【Enhancing Agile Software Development Through Effective Visual Content】通过有效的视觉内容增强敏捷软件开发</title>
      <link>https://dzone.com/articles/enhancing-agile-software-development-through-effec</link>
      <description>【&lt;p dir=&#34;ltr&#34;&gt;Agile has emerged as one of the go-to approaches for software development teams worldwide in recent years. &lt;a href=&#34;https://www.statista.com/statistics/1233917/software-development-methodologies-practiced/&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt;According to Statista&lt;/a&gt;, it’s second only to DevOps/DevSecOps and beats other approaches like Waterfall and Lean methodology.&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;This is not unsurprising. Organizations are increasingly looking to stay competitive, and Agile’s emphasis on collaboration, iteration, customer involvement, and delivering value early resonates with fast-paced teams.&lt;/p&gt;】&lt;p dir=&#34;ltr&#34;&gt;近年来，敏捷已成为全球软件开发团队的首选方法之一。 &lt;a href=&#34;https://www.statista.com/statistics/1233917/software-development-methodologies-practiced/&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt;根据 Statista&lt;/a&gt;，排名第二仅适用于 DevOps/DevSecOps，并且击败了瀑布和精益方法等其他方法。&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;这并不奇怪。组织越来越希望保持竞争力，敏捷对协作、迭代、客户参与和尽早交付价值的重视与快节奏的团队产生了共鸣。&lt;/p&gt;</description>
      <pubDate>Wed, 16 Oct 2024 18:45:07 +0000</pubDate>
    </item>
    <item>
      <title>【How to Convert HTML to DOCX in Java】如何在 Java 中将 HTML 转换为 DOCX</title>
      <link>https://dzone.com/articles/how-to-convert-html-to-docx-in-java</link>
      <description>【&lt;p&gt;There&#39;s a far smaller audience of folks who understand the intricacies of HTML document structure than those who understand the user-friendly Microsoft (MS) Word application. Automating HTML-to-DOCX conversions makes a lot of sense if we frequently need to generate well-formatted documents from dynamic web content, streamline reporting workflows, or convert any other web-based information into editable Word documents for a non-technical business audience.&lt;/p&gt;&#xA;&lt;p&gt;Automating HTML-to-DOCX conversions with APIs reduces the time and effort it takes to generate MS Word content for non-technical users. In this article, we&#39;ll review open-source and proprietary API solutions for streamlining HTML-to-DOCX conversions in Java, and we&#39;ll explore the relationship between HTML and DOCX file structures that makes this conversion relatively straightforward.&lt;/p&gt;】&lt;p&gt;了解复杂的 HTML 文档结构的受众比了解用户友好的 Microsoft (MS) Word 应用程序的受众要少得多。如果我们经常需要从动态 Web 内容生成格式良好的文档、简化报告工作流程或将任何其他基于 Web 的信息转换为可供非技术业务受众使用的可编辑 Word 文档，那么自动化 HTML 到 DOCX 转换就非常有意义.&lt;/p&gt;&#xA;&lt;p&gt;使用 API 自动进行 HTML 到 DOCX 的转换可以减少非技术用户生成 MS Word 内容所需的时间和精力。在本文中，我们将回顾用于简化 Java 中 HTML 到 DOCX 转换的开源和专有 API 解决方案，并将探讨 HTML 和 DOCX 文件结构之间的关系，使这种转换相对简单。&lt;/p&gt;</description>
      <pubDate>Wed, 16 Oct 2024 15:00:04 +0000</pubDate>
    </item>
    <item>
      <title>【An Interview About Navigating the Cloud-Native Ecosystem】关于云原生生态系统的采访</title>
      <link>https://dzone.com/articles/navigating-the-cloud-native-ecosystem</link>
      <description>【&lt;p&gt;In this interview with Julian Fischer, CEO of the cloud computing and automation company &lt;a href=&#34;https://anynines.com&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt;anynines GmbH&lt;/a&gt;, we explore the evolving landscape of cloud-native technologies with a strong focus on the roles of Kubernetes and Cloud Foundry in modern enterprise environments.&lt;/p&gt;&#xA;&lt;h2&gt;About the Interviewee&lt;/h2&gt;&#xA;&lt;p&gt;The interviewee, Julian Fischer, has extensive experience in Cloud Foundry and Kubernetes ops. Julian leads anynines in helping organizations operate applications at scale. Under his guidance, they&#39;re also pioneering advancements in managing data services across many Kubernetes clusters via the open-source &lt;a href=&#34;https://klutch.io&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt;Klutch project&lt;/a&gt;.&lt;/p&gt;】&lt;p&gt;在对云计算和自动化公司 &lt;a href=&#34;https://anynines.com&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt;anynines GmbH&lt;/a&gt; 首席执行官 Julian Fischer 的采访中，我们探索云原生技术不断发展的前景，重点关注 Kubernetes 和 Cloud Foundry 在现代企业环境中的作用。&lt;/p&gt;&#xA;&lt;h2&gt;关于受访者&lt;/h2&gt;&#xA;&lt;p&gt;受访者 Julian Fischer 在 Cloud Foundry 和 Kubernetes 运营方面拥有丰富的经验。 Julian 在帮助组织大规模运营应用程序方面处于领先地位。在他的指导下，他们还通过开源 &lt;a href=&#34;https://klutch.io&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt;Klutch 项目在跨多个 Kubernetes 集群管理数据服务方面取得了开创性进展&lt;/a&gt;.&lt;/p&gt;</description>
      <pubDate>Wed, 16 Oct 2024 17:00:04 +0000</pubDate>
    </item>
    <item>
      <title>【Automate Azure Databricks Unity Catalog Permissions at the Catalog Level】在目录级别自动化 Azure Databricks Unity 目录权限</title>
      <link>https://dzone.com/articles/automate-databricks-unity-catalog-permissions</link>
      <description>【&lt;p&gt;&lt;strong&gt;&lt;em&gt;Disclaimer:&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;&amp;nbsp;All the views and opinions expressed in the blog belong&amp;nbsp;&lt;/em&gt;&lt;strong&gt;&lt;em&gt;solely&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;&amp;nbsp;to the author and not necessarily to the author&#39;s employer or any other group or individual. This article is&amp;nbsp;&lt;/em&gt;&lt;strong&gt;&lt;em&gt;not&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;&amp;nbsp;a promotion for any cloud/data management platform. All the images and code snippets are publicly available on the Azure/Databricks website&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;h2&gt;What Is Unity Catalog in Databricks?&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.databricks.com/product/unity-catalog&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt;Databricks Unity Catalog&lt;/a&gt; is a data cataloging tool that helps manage and organize data across an organization in a simple, secure way. It allows companies to keep track of all their data, making it easier to find, share, and control who can access it. Unity Catalog works across different cloud storage systems and lets teams manage permissions, governance, and data access from one place, ensuring data is used safely and efficiently.&amp;nbsp;&lt;/p&gt;】&lt;p&gt;&lt;strong&gt;&lt;em&gt;免责声明：&lt;/em&gt;&lt;/strong&gt;&lt;em&gt; 博客中表达的所有观点和意见&lt;/em&gt;&lt;strong&gt;&lt;em&gt;仅代表&lt;/em&gt;&lt;/strong &gt;&lt;em&gt; 向作者提供，但不一定向作者的雇主或任何其他团体或个人提供。本文并非针对任何云/数据管理平台的宣传。&lt;/em&gt;&lt;strong&gt;&lt;em&gt;并非&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;。所有图像和代码片段均可在 Azure/Databricks 网站上公开获取&lt;/em&gt;&lt;em&gt;。&lt;/em&gt;&lt;/p&gt;&#xA;&lt;h2&gt;Databricks 中的 Unity 目录是什么？&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.databricks.com/product/unity-catalog&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt;Databricks Unity Catalog&lt;/a&gt; 是一个数据编目工具，可帮助以简单、安全的方式管理和组织整个组织的数据。它允许公司跟踪所有数据，从而更轻松地查找、共享和控制谁可以访问这些数据。 Unity Catalog 可以跨不同的云存储系统工作，让团队可以从一个地方管理权限、治理和数据访问，确保安全高效地使用数据。 &lt;/p&gt;</description>
      <pubDate>Wed, 16 Oct 2024 23:15:07 +0000</pubDate>
    </item>
    <item>
      <title>【DevoxxGenie: Your AI Assistant for IntelliJ IDEA】DevoxxGenie：您的 IntelliJ IDEA 人工智能助手</title>
      <link>https://dzone.com/articles/devoxxgenie-LLM-code-assistant-plugin-intellij-idea</link>
      <description>【&lt;p&gt;DevoxxGenie is a fully Java-based LLM code assistant plugin for IntelliJ IDEA, designed to integrate with local LLM providers and cloud-based LLMs. In this blog, you will learn how to get started with the plugin and get the most out of it. Enjoy!&lt;/p&gt;&#xA;&lt;h2&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;AI coding assistants are getting more and more attention. Multiple cloud services are available and IDEs provide their own services. However, with this approach, you are tied to a specific vendor and most of the time, these services are cloud based only. What should you do when your company policy does not allow you to use these cloud-based services? Or what do you do when a new, more accurate model is released? When using IntelliJ IDEA, you can make use of the &lt;a href=&#34;https://github.com/devoxx/DevoxxGenieIDEAPlugin&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt;DevoxxGenie&lt;/a&gt; plugin, created by Stephan Janssen, founder of the Devoxx conference. The plugin allows you to choose between several cloud based and local LLMs. You are not tied to a specific cloud vendor or a specific model. This is important because every few weeks a new model is released, which outperforms previous ones.&lt;/p&gt;】&lt;p&gt;DevoxxGenie 是一款适用于 IntelliJ IDEA 的完全基于 Java 的 LLM 代码助手插件，旨在与本地 LLM 提供商和基于云的 LLM 集成。在本博客中，您将学习如何开始使用该插件并充分利用它。享受吧！&lt;/p&gt;&#xA;&lt;h2&gt;简介&lt;/h2&gt;&#xA;&lt;p&gt;人工智能编码助手越来越受到关注。有多种云服务可用，IDE 提供自己的服务。然而，通过这种方法，您将与特定的供应商联系在一起，并且大多数时候，这些服务仅基于云。当您的公司政策不允许您使用这些基于云的服务时，您应该怎么做？或者当一个新的、更准确的模型发布时你会做什么？使用 IntelliJ IDEA 时，您可以使用 Stephan 创建的 &lt;a href=&#34;https://github.com/devoxx/DevoxxGenieIDEAPlugin&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt;DevoxxGenie&lt;/a&gt; 插件Janssen，Devoxx 会议创始人。该插件允许您在多个基于云的法学硕士和本地法学硕士之间进行选择。您不受特定云供应商或特定模型的束缚。这很重要，因为每隔几周就会发布一个新模型，其性能优于以前的模型。&lt;/p&gt;</description>
      <pubDate>Wed, 16 Oct 2024 14:00:05 +0000</pubDate>
    </item>
    <item>
      <title>【Introduction to Next.js Middleware: How It Works With Examples】Next.js 中间件简介：它如何工作并提供示例</title>
      <link>https://dzone.com/articles/introduction-to-nextjs-middleware-how-it-works</link>
      <description>【&lt;p&gt;Let&#39;s talk about routing in Next.js. Today, we will talk about the one of most powerful things: middleware. Middleware in Next.js offers a powerful and flexible way both to intercept requests from the server and control request flow (redirects, URL rewriting) and globally enhance features like authentication, headers, and cookie persistence.&lt;/p&gt;&#xA;&lt;h2&gt;&lt;a name=&#34;creating-middleware&#34; href=&#34;https://dev.to/sheraz4194/introduction-to-nextjs-middleware-how-it-works-with-examples-46pp#creating-middleware&#34;&gt;&lt;/a&gt;Creating Middleware&lt;/h2&gt;&#xA;&lt;p&gt;Let&#39;s create a Middleware Next.js application. First of all, we&#39;ll create a new file for middleware like &lt;code&gt;middleware.js&lt;/code&gt; or &lt;code&gt;middleware.ts&lt;/code&gt;, in the src folder. Middleware in Next.js then needs to allow you fine control over where it will be active (ie custom matcher configuration, or using isXXX functions)&lt;/p&gt;】&lt;p&gt;我们来谈谈 Next.js 中的路由。今天，我们将讨论最强大的东西之一：中间件。 Next.js 中的中间件提供了一种强大而灵活的方法来拦截来自服务器的请求并控制请求流（重定向、URL 重写）并全局增强身份验证、标头和 cookie 持久性等功能。&lt;/p&gt;&#xA;&lt;h2&gt;&lt;a name=&#34;creating-middleware&#34; href=&#34;https://dev.to/sheraz4194/introduction-to-nextjs-middleware-how-it-works-with-examples-46pp#creating-middleware&#34;&gt; &lt;/a&gt;创建中间件&lt;/h2&gt;&#xA;&lt;p&gt;让我们创建一个 Middleware Next.js 应用程序。首先，我们将在 src 文件夹中为中间件创建一个新文件，例如 &lt;code&gt;middleware.js&lt;/code&gt; 或 &lt;code&gt;middleware.ts&lt;/code&gt;。然后，Next.js 中的中间件需要允许您精细控制它将处于活动状态（即自定义匹配器配置，或使用 isXXX 函数）&lt;/p&gt;</description>
      <pubDate>Wed, 16 Oct 2024 13:00:04 +0000</pubDate>
    </item>
    <item>
      <title>【Artificial Intelligence and Machine Learning in Cloud-Native Environments】云原生环境中的人工智能和机器学习</title>
      <link>https://dzone.com/articles/ai-and-ml-in-cloud-native-environments</link>
      <description>【&lt;p dir=&#34;ltr&#34;&gt;In our industry, few pairings have been as exciting and game-changing as the union of artificial intelligence (AI) and machine learning (ML) with cloud-native environments. It&#39;s a union designed for innovation, scalability, and yes, even cost efficiency. So put on your favorite Kubernetes hat and let&#39;s dive into this dynamic world where data science meets the cloud!&amp;nbsp;&lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;Before we explore the synergy between AI/ML and cloud-native technologies, let’s set a few definitions.&amp;nbsp;&lt;/p&gt;】&lt;p dir=&#34;ltr&#34;&gt;在我们的行业中，很少有配对能够像人工智能 (AI) 和机器学习 (ML) 与云原生环境的结合那样令人兴奋和改变游戏规则。这是一个专为创新、可扩展性，甚至成本效率而设计的联盟。因此，戴上您最喜欢的 Kubernetes 帽子，让我们深入了解这个数据科学与云相遇的动态世界！ &lt;/p&gt;&#xA;&lt;p dir=&#34;ltr&#34;&gt;在探索 AI/ML 和云原生技术之间的协同作用之前，让我们先定义一些定义。 &lt;/p&gt;</description>
      <pubDate>Wed, 16 Oct 2024 16:00:06 +0000</pubDate>
    </item>
    <item>
      <title>【Building an Interactive Chatbot With Streamlit, LangChain, and Bedrock】使用 Streamlit、LangChain 和 Bedrock 构建交互式聊天机器人</title>
      <link>https://dzone.com/articles/building-an-interactive-chatbot-with-streamlit</link>
      <description>【&lt;p&gt;In the ever-evolving landscape of AI, chatbots have become indispensable tools for enhancing user engagement and streamlining information delivery. This article will walk you through the process of building an interactive chatbot using Streamlit for the front end, LangChain for orchestrating interactions, and Anthropic’s Claude Model powered by Amazon Bedrock as the &lt;a href=&#34;https://dzone.com/articles/decoding-large-language-models-and-how-they-work&#34;&gt;Large Language Model&lt;/a&gt; (LLM) backend. We&#39;ll dive into the code snippets for both the backend and front end and explain the key components that make this chatbot work.&lt;/p&gt;&#xA;&lt;h2&gt;&lt;strong&gt;Core Components&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul type=&#34;disc&#34;&gt;&#xA; &lt;li&gt;&lt;strong&gt;Streamlit frontend:&lt;/strong&gt; Streamlit&#39;s intuitive interface allows us to create a low-code user-friendly chat interface with minimal effort. We&#39;ll explore how the code sets up the chat window, handles user input, and displays the chatbot&#39;s responses.&lt;/li&gt;&#xA; &lt;li&gt;&lt;strong&gt;LangChain orchestration:&lt;/strong&gt; &lt;a href=&#34;https://dzone.com/articles/what-is-langchain-and-large-language-models&#34;&gt;LangChain&lt;/a&gt; empowers us to manage the conversation flow and memory, ensuring the chatbot maintains context and provides relevant responses. We&#39;ll discuss how LangChain&#39;s ConversationSummaryBufferMemory and ConversationChain are integrated.&lt;/li&gt;&#xA; &lt;li&gt;&lt;strong&gt;Bedrock/Claude LLM backend:&lt;/strong&gt; The true magic lies in the LLM backend. We&#39;ll look at how to leverage Amazon Bedrock’s claude foundation model to generate intelligent and contextually aware responses.&amp;nbsp;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2&gt;&lt;strong&gt;Chatbot Architecture&lt;/strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;br&gt;&lt;img data-new=&#34;false&#34; data-mimetype=&#34;image/jpeg&#34; data-creationdateformatted=&#34;10/15/2024 07:49 PM&#34; data-url=&#34;https://dz2cdn1.dzone.com/storage/temp/17982326-1729021774175.jpeg&#34; data-size=&#34;210650&#34; data-id=&#34;17982326&#34; data-image=&#34;true&#34; data-sizeformatted=&#34;210.7 kB&#34; data-creationdate=&#34;1729021774861&#34; data-type=&#34;temp&#34; data-modificationdate=&#34;null&#34; data-name=&#34;1729021774175.jpeg&#34; alt=&#34;chatbot architecture&#34; class=&#34;fr-fic fr-dib lazyload&#34; style=&#34;width: 768px;&#34; data-src=&#34;https://dz2cdn1.dzone.com/storage/temp/17982326-1729021774175.jpeg&#34;&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;h2&gt;&lt;strong&gt;Conceptual Walkthrough of the Architecture&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ol start=&#34;1&#34; type=&#34;1&#34;&gt;&#xA; &lt;li&gt;&lt;strong&gt;User interaction:&lt;/strong&gt; The user initiates the conversation by typing a message into the chat interface created by Streamlit. This message can be a question, a request, or any other form of input the user wishes to provide.&lt;/li&gt;&#xA; &lt;li&gt;&lt;strong&gt;Input capture and processing:&lt;/strong&gt; Streamlit&#39;s chat input component captures the user&#39;s message and passes it on to the LangChain framework for further processing.&lt;/li&gt;&#xA; &lt;li&gt;&lt;strong&gt;Contextualization with LangChain memory:&lt;/strong&gt; LangChain plays a crucial role in maintaining the context of the conversation. It combines the user&#39;s latest input with the relevant conversation history stored in its memory. This ensures that the chatbot has the necessary information to generate a meaningful and contextually appropriate response.&lt;/li&gt;&#xA; &lt;li&gt;&lt;strong&gt;Leveraging the LLM:&lt;/strong&gt; The combined context is then sent to the Bedrock/Claude LLM. This powerful language model uses its vast knowledge and understanding of language to analyze the context and generate a response that addresses the user&#39;s input in an informative way.&lt;/li&gt;&#xA; &lt;li&gt;&lt;strong&gt;Response retrieval:&lt;/strong&gt; LangChain receives the generated response from the LLM and prepares it for presentation to the user.&lt;/li&gt;&#xA; &lt;li&gt;&lt;strong&gt;Response display:&lt;/strong&gt; Finally, &lt;a href=&#34;https://dzone.com/articles/streamlit-empowering-data-scientists-with-interact&#34; rel=&#34;noopener noreferrer&#34; target=&#34;_blank&#34;&gt;Streamlit&lt;/a&gt; takes the chatbot&#39;s response and displays it in the chat window, making it appear as if the chatbot is engaging in a natural conversation with the user. This creates an intuitive and user-friendly experience, encouraging further interaction.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2&gt;&lt;strong&gt;Code Snippets&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;div&gt;&#xA; &lt;h3&gt;&lt;strong&gt;Frontend (Streamlit)&lt;/strong&gt;&lt;/h3&gt;&#xA; &lt;div class=&#34;codeMirror-wrapper&#34; contenteditable=&#34;false&#34;&gt;&#xA;  &lt;div contenteditable=&#34;false&#34;&gt;&#xA;   &lt;div class=&#34;codeHeader&#34;&gt;&#xA;    &lt;div class=&#34;nameLanguage&#34;&gt;&#xA;     Python&#xA;    &lt;/div&gt;&lt;i class=&#34;icon-cancel-circled-1 cm-remove&#34;&gt;&amp;nbsp;&lt;/i&gt;&#xA;   &lt;/div&gt;&#xA;   &lt;div class=&#34;codeMirror-code--wrapper&#34; data-code=&#34;import streamlit &#xA; import chatbot_backend &#xA; from langchain.chains import ConversationChain&#xA; from langchain.memory import ConversationSummaryBufferMemory&#xA; import boto3&#xA; from langchain_aws import ChatBedrock&#xA; import pandas as pd&#xA; &#xA; # 2 Set Title for Chatbot - streamlit.title(&amp;quot;Hi, This is your Chatbott&amp;quot;)&amp;nbsp;&amp;nbsp;&#xA; &#xA; # 3 LangChain memory to the session cache - Session State - &#xA; if &#39;memory&#39; not in streamlit.session_state:&#xA; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;streamlit.session_state.memory = demo.demo_memory()&amp;nbsp;&amp;nbsp;&#xA;&#xA; # 4 Add the UI chat history to the session cache - Session State &#xA; if &#39;chat_history&#39; not in streamlit.session_state:&amp;nbsp;&amp;nbsp;&#xA; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;streamlit.session_state.chat_history = []&amp;nbsp;&amp;nbsp;&#xA;&#xA; # 5 Re-render the chat history &#xA; for message in streamlit.session_state.chat_history:&#xA; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;with streamlit.chat_message(message[&amp;quot;role&amp;quot;]):&#xA; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;streamlit.markdown(message[&amp;quot;text&amp;quot;])&#xA; &#xA; # 6 Enter the details for chatbot input box&#xA; input_text = streamlit.chat_input(&amp;quot;Powered by Bedrock&amp;quot;)&amp;nbsp;&amp;nbsp;&#xA;&#xA; if input_text:&#xA; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;with streamlit.chat_message(&amp;quot;user&amp;quot;):&#xA; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;streamlit.markdown(input_text)&#xA; &#xA; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;streamlit.session_state.chat_history.append({&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;text&amp;quot;: input_text})&#xA; &#xA; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;chat_response = demo.demo_conversation(input_text=input_text,&#xA; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;memory=streamlit.session_state.memory)&amp;nbsp;&amp;nbsp;&#xA; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;with streamlit.chat_message(&amp;quot;assistant&amp;quot;):&#xA; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;streamlit.markdown(chat_response)&#xA; &#xA; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;streamlit.session_state.chat_history.append({&amp;quot;role&amp;quot;: &amp;quot;assistant&amp;quot;, &amp;quot;text&amp;quot;: chat_response})&#xA;&#34; data-lang=&#34;text/x-python&#34;&gt;&#xA;    &lt;pre&gt;&lt;code lang=&#34;text/x-python&#34;&gt;import streamlit &#xA; import chatbot_backend &#xA; from langchain.chains import ConversationChain&#xA; from langchain.memory import ConversationSummaryBufferMemory&#xA; import boto3&#xA; from langchain_aws import ChatBedrock&#xA; import pandas as pd&#xA; &#xA; # 2 Set Title for Chatbot - streamlit.title(&#34;Hi, This is your Chatbott&#34;)&amp;nbsp;&amp;nbsp;&#xA; &#xA; # 3 LangChain memory to the session cache - Session State - &#xA; if &#39;memory&#39; not in streamlit.session_state:&#xA; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;streamlit.session_state.memory = demo.demo_memory()&amp;nbsp;&amp;nbsp;&#xA;&#xA; # 4 Add the UI chat history to the session cache - Session State &#xA; if &#39;chat_history&#39; not in streamlit.session_state:&amp;nbsp;&amp;nbsp;&#xA; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;streamlit.session_state.chat_history = []&amp;nbsp;&amp;nbsp;&#xA;&#xA; # 5 Re-render the chat history &#xA; for message in streamlit.session_state.chat_history:&#xA; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;with streamlit.chat_message(message[&#34;role&#34;]):&#xA; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;streamlit.markdown(message[&#34;text&#34;])&#xA; &#xA; # 6 Enter the details for chatbot input box&#xA; input_text = streamlit.chat_input(&#34;Powered by Bedrock&#34;)&amp;nbsp;&amp;nbsp;&#xA;&#xA; if input_text:&#xA; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;with streamlit.chat_message(&#34;user&#34;):&#xA; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;streamlit.markdown(input_text)&#xA; &#xA; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;streamlit.session_state.chat_history.append({&#34;role&#34;: &#34;user&#34;, &#34;text&#34;: input_text})&#xA; &#xA; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;chat_response = demo.demo_conversation(input_text=input_text,&#xA; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;memory=streamlit.session_state.memory)&amp;nbsp;&amp;nbsp;&#xA; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;with streamlit.chat_message(&#34;assistant&#34;):&#xA; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;streamlit.markdown(chat_response)&#xA; &#xA; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;streamlit.session_state.chat_history.append({&#34;role&#34;: &#34;assistant&#34;, &#34;text&#34;: chat_response})&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;   &lt;/div&gt;&#xA;  &lt;/div&gt;&#xA; &lt;/div&gt;&#xA; &lt;p&gt;&lt;br&gt;&lt;/p&gt;】&lt;p&gt;在不断发展的人工智能领域，聊天机器人已成为增强用户参与度和简化信息传递不可或缺的工具。本文将引导您完成使用 Streamlit 作为前端、LangChain 用于编排交互以及由 Amazon Bedrock 提供支持的 Anthropic 的 Claude 模型作为 &lt;a href=&#34;https://dzone.com/articles/解码大型语言模型及其工作方式&#34;&gt;大型语言模型&lt;/a&gt; (LLM) 后端。我们将深入研究后端和前端的代码片段，并解释使该聊天机器人工作的关键组件。&lt;/p&gt;&#xA;&lt;h2&gt;&lt;strong&gt;核心组件&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul类型=“光盘”&gt;&#xA; &lt;li&gt;&lt;strong&gt;Streamlit 前端：&lt;/strong&gt;Streamlit 直观的界面使我们能够轻松创建低代码、用户友好的聊天界面。我们将探讨代码如何设置聊天窗口、处理用户输入以及显示聊天机器人的响应。&lt;/li&gt;&#xA; &lt;li&gt;&lt;strong&gt;LangChain编排：&lt;/strong&gt;&lt;a href=&#34;https://dzone.com/articles/what-is-langchain-and-large-language-models&#34;&gt;LangChain&lt;/a&gt;为我们赋能管理对话流和内存，确保聊天机器人维护上下文并提供相关响应。我们将讨论LangChain的ConversationSummaryBufferMemory和ConversationChain是如何集成的。&lt;/li&gt;&#xA; &lt;li&gt;&lt;strong&gt;Bedrock/Claude LLM 后端：&lt;/strong&gt;真正的魔力在于 LLM 后端。我们将了解如何利用 Amazon Bedrock 的克劳德基础模型来生成智能且上下文感知的响应。 &lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2&gt;&lt;strong&gt;聊天机器人架构&lt;/strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;br&gt;&lt;img data-new=&#34;false&#34; data-mimetype=&#34;image/jpeg&#34; data-creationdateformatted=&#34;10/15/2024 07 :49 PM&#34; data-url=&#34;https://dz2cdn1.dzone.com/storage/temp/17982326-1729021774175.jpeg&#34; data-size=&#34;210650&#34; data-id=&#34;17982326&#34; data-image=&#34;true&#34; data-sizeformatted =“210.7 kB”data-creationdate =“1729021774861”data-type =“temp”data-modificationdate =“null”data-name =“1729021774175.jpeg”alt =“聊天机器人架构”class =“fr-fic” fr-dib 延迟加载&#34; style=&#34;width: 768px;&#34; data-src=&#34;https://dz2cdn1.dzone.com/storage/temp/17982326-1729021774175.jpeg&#34;&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;h2&gt;&lt;strong&gt;架构的概念演练&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ol开始=“1”类型=“1”&gt;&#xA; &lt;li&gt;&lt;strong&gt;用户交互：&lt;/strong&gt;用户通过在 Streamlit 创建的聊天界面中输入消息来发起对话。该消息可以是问题、请求或用户希望提供的任何其他形式的输入。&lt;/li&gt;&#xA; &lt;li&gt;&lt;strong&gt;输入捕获和处理：&lt;/strong&gt;Streamlit 的聊天输入组件捕获用户的消息并将其传递到 LangChain 框架进行进一步处理。&lt;/li&gt;&#xA; &lt;li&gt;&lt;strong&gt;利用LangChain内存进行语境化&lt;/strong&gt;：LangChain在维持对话的语境方面发挥着至关重要的作用。它将用户的最新输入与存储在其内存中的相关对话历史记录相结合。这确保了聊天机器人具有必要的y 信息以生成有意义且适合上下文的响应。&lt;/li&gt;&#xA; &lt;li&gt;&lt;strong&gt;利用 LLM&lt;/strong&gt;：然后将合并后的上下文发送至 Bedrock/Claude LLM。这个强大的语言模型利用其丰富的知识和对语言的理解来分析上下文并生成以信息丰富的方式处理用户输入的响应。&lt;/li&gt;&#xA; &lt;li&gt;&lt;strong&gt;响应检索：&lt;/strong&gt;LangChain 接收 LLM 生成的响应并准备将其呈现给用户。&lt;/li&gt;&#xA; &lt;li&gt;&lt;strong&gt;回复显示：&lt;/strong&gt;最后，&lt;a href=&#34;https://dzone.com/articles/streamlit-empowering-data-scientists-with-interact&#34; rel=&#34;noopener noreferrer&#34; target= &#34;_blank&#34;&gt;Streamlit&lt;/a&gt; 获取聊天机器人的响应并将其显示在聊天窗口中，使聊天机器人看起来好像正在与用户进行自然对话。这创造了直观且用户友好的体验，鼓励进一步的互动。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2&gt;&lt;strong&gt;代码片段&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;div&gt;&#xA; &lt;h3&gt;&lt;strong&gt;前端（Streamlit）&lt;/strong&gt;&lt;/h3&gt;&#xA; &lt;div class=&#34;codeMirror-wrapper&#34; contenteditable=&#34;false&#34;&gt;&#xA;  &lt;div contenteditable=&#34;false&#34;&gt;&#xA;   &lt;div 类=“codeHeader”&gt;&#xA;    &lt;div class=&#34;nameLanguage&#34;&gt;&#xA;     Python&#xA;    &lt;/div&gt;&lt;i class=&#34;icon-cancel-circled-1 cm-remove&#34;&gt; &lt;/i&gt;&#xA;   &lt;/div&gt;&#xA;   &lt;div class=&#34;codeMirror-code--wrapper&#34; data-code=&#34;导入 Streamlit &#xA; 导入chatbot_backend &#xA; 从 langchain.chains 导入 ConversationChain&#xA; 从 langchain.memory 导入 ConversationSummaryBufferMemory&#xA; 导入boto3&#xA; 从 langchain_aws 导入 ChatBedrock&#xA; 将 pandas 导入为 pd&#xA; &#xA; # 2 设置聊天机器人的标题 -streamlit.title(&#34;Hi, This is your Chatbott&#34;)  &#xA; &#xA; #3 LangChain内存到会话缓存-会话状态- &#xA; 如果“内存”不在streamlit.session_state中：&#xA;     Streamlit.session_state.memory = demo.demo_memory()  &#xA;&#xA; # 4 将UI聊天记录添加到会话缓存-会话状态 &#xA; 如果“chat_history”不在streamlit.session_state中：  &#xA;     Streamlit.session_state.chat_history = []  &#xA;&#xA; # 5 重新渲染聊天记录 &#xA; 对于streamlit.session_state.chat_history中的消息：&#xA;     与streamlit.chat_message（消息[“角色”]）：&#xA;         Streamlit.markdown(消息[“文本”])&#xA; &#xA; # 6 在聊天机器人输入框中输入详细信息&#xA; input_text = streamlit.chat_input(&#34;由基岩提供支持&#34;)  &#xA;&#xA; 如果输入文本：&#xA;     与streamlit.chat_message（“用户”）：&#xA;         Streamlit.markdown(input_text)&#xA; &#xA;     Streamlit.session_state.chat_history.append({&#34;角色&#34;: &#34;用户&#34;, &#34;文本&#34;: input_text})&#xA; &#xA;     chat_response = demo.demo_conversation(input_text=input_text,&#xA;                      ＆n公共服务提供商；                     内存=streamlit.session_state.内存）  &#xA;     与streamlit.chat_message（“助理”）：&#xA;         Streamlit.markdown(chat_response)&#xA; &#xA;     Streamlit.session_state.chat_history.append({&#34;角色&#34;: &#34;助理&#34;, &#34;文本&#34;: chat_response})&#xA;“ data-lang =“文本/ x-python”&gt;&#xA;    &lt;pre&gt;&lt;code lang=&#34;text/x-python&#34;&gt;导入streamlit &#xA; 导入chatbot_backend &#xA; 从 langchain.chains 导入 ConversationChain&#xA; 从 langchain.memory 导入 ConversationSummaryBufferMemory&#xA; 导入boto3&#xA; 从 langchain_aws 导入 ChatBedrock&#xA; 将 pandas 导入为 pd&#xA; &#xA; # 2 设置聊天机器人的标题 -streamlit.title(&#34;Hi, This is your Chatbott&#34;)  &#xA; &#xA; #3 LangChain内存到会话缓存-会话状态- &#xA; 如果“内存”不在streamlit.session_state中：&#xA;     Streamlit.session_state.memory = demo.demo_memory()  &#xA;&#xA; # 4 将UI聊天记录添加到会话缓存-会话状态 &#xA; 如果“chat_history”不在streamlit.session_state中：  &#xA;     Streamlit.session_state.chat_history = []  &#xA;&#xA; # 5 重新渲染聊天记录 &#xA; 对于streamlit.session_state.chat_history中的消息：&#xA;     与streamlit.chat_message（消息[“角色”]）：&#xA;         Streamlit.markdown(消息[“文本”])&#xA; &#xA; # 6 在聊天机器人输入框中输入详细信息&#xA; input_text = streamlit.chat_input(&#34;由基岩提供支持&#34;)  &#xA;&#xA; 如果输入文本：&#xA;     与streamlit.chat_message（“用户”）：&#xA;         Streamlit.markdown(input_text)&#xA; &#xA;     Streamlit.session_state.chat_history.append({&#34;角色&#34;: &#34;用户&#34;, &#34;文本&#34;: input_text})&#xA; &#xA;     chat_response = demo.demo_conversation(input_text=input_text,&#xA;                                            内存=streamlit.session_state.内存）  &#xA;     与streamlit.chat_message（“助理”）：&#xA;         Streamlit.markdown(chat_response)&#xA; &#xA;     Streamlit.session_state.chat_history.append({&#34;角色&#34;: &#34;助理&#34;, &#34;文本&#34;: chat_response})&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;   &lt;/div&gt;&#xA;  &lt;/div&gt;&#xA; &lt;/div&gt;&#xA; &lt;p&gt;&lt;br&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 16 Oct 2024 12:00:11 +0000</pubDate>
    </item>
  </channel>
</rss>