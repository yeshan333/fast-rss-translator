<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Grafana Labs blog on Grafana Labs</title>
    <link>/blog/index.xml</link>
    <description>Recent content in Grafana Labs blog on Grafana Labs</description>
    <item>
      <title>【Grafana Labs expands its open source observability community in Japan】Grafana Labs 扩大其在日本的开源可观测性社区</title>
      <link>https://grafana.com/blog/2024/07/26/grafana-labs-expands-its-open-source-observability-community-in-japan/</link>
      <description>【&lt;p&gt;Whether it&amp;rsquo;s attending community meetups, developing new data sources, or even landing on the moon, the open source observability community in Japan has been an integral part of the larger Grafana community.&lt;/p&gt;&#xA;&lt;p&gt;And with our latest regional expansion, we&amp;rsquo;re excited to see what more the community can achieve. We recently added a &lt;a href=&#34;/docs/grafana-cloud/account-management/regional-availability/&#34;&gt;Grafana Cloud region in Tokyo&lt;/a&gt; as well as hosted two local meetups — one featuring &lt;a href=&#34;https://www.youtube.com/watch?v=F1BK7H79Gw8&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;JAXA&lt;/a&gt; and its successful lunar landing using Grafana and another highlighting the visualization of 130 factories worldwide at &lt;a href=&#34;https://www.youtube.com/watch?v=FaarevjZnls&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;DENSO&lt;/a&gt;. Each meetup welcomed more than 100 observability experts and enthusiasts to help foster learning, sharing, and networking within the local open source observability community. The meetups were also streamed online, with hundreds of participants joining in real-time.We&amp;rsquo;ve also updated our website to include resources in Japanese for the community.&lt;/p&gt;&#xA;&lt;p&gt;This work aligns with our mission to make Grafana easy to use, no matter where your data (or our users) live. While the magic of open source is that our universal language is code, we are always working on ways to extend our global community, which now has more than 20 million users, and meet them where we are.&lt;/p&gt;&#xA;&lt;p&gt;But in the end, our real superpower lies in the powerful connections that are made within the open source &lt;a href=&#34;/blog/2023/12/12/the-story-of-grafana-documentary-the-community-behind-the-code/&#34;&gt;Grafana community&lt;/a&gt;. “Every time I have a question or an idea I’ve never tried or Grafana has never tried, we always want to try it together,” says Mikhail Volkov, CEO and founder of Volkov Labs and a longtime Grafana contributor. “You can do whatever you want with Grafana with the help of the community.”&lt;/p&gt;&#xA;&lt;p&gt;When the Grafana community wanted an Amazon CloudWatch data source, it was a community member who responded in 2015. “This was my first time contributing to a big OSS like Grafana,” says Mitsuhiro Tanda, Lead Engineer at GREE, Inc. “The community came together and talked about it together. It was very nice to have built something up together. This is a very Grafana-like way of being a community.”&lt;/p&gt;&#xA;&lt;p&gt;And it has remained that way for &lt;a href=&#34;/blog/2024/02/12/the-story-of-grafana-documentary-from-one-developers-dream-to-20-million-users-worldwide/&#34;&gt;more than a decade&lt;/a&gt;. When Satoshi Nakahira implemented Grafana into JAXA&amp;rsquo;s systems to help Japan become the fifth country to land on the moon, &amp;ldquo;We were able to build our entire system quite easily and the visualization capability was broad from simple to detailed graphs. We were also able to create dashboards that were well-received and visually impressive,&amp;rdquo; says Satoshi, whose &lt;a href=&#34;/events/grafanacon/2024/grafana-used-to-monitor-japan-slim-moon-lander/&#34;&gt;GrafanaCON session is available to watch on demand&lt;/a&gt;. &amp;ldquo;Thank you very much to the Grafana community.&amp;rdquo;&lt;/p&gt;】&lt;p&gt;无论是参加社区聚会、开发新数据源，甚至登陆月球，日本的开源可观测性社区一直是更大的 Grafana 社区不可或缺的一部分。&lt;/p&gt;&#xA;&lt;p&gt;随着我们最新的区域扩张，我们很高兴看到社区能够取得更多成就。我们最近在东京添加了一个 &lt;a href=&#34;/docs/grafana-cloud/account-management/regional-availability/&#34;&gt;Grafana Cloud 区域&lt;/a&gt;，并举办了两场本地聚会 - 其中一场以 &lt;a href=&#34; https://www.youtube.com/watch?v=F1BK7H79Gw8&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;JAXA&lt;/a&gt; 及其使用 Grafana 的成功登月，以及另一个重点介绍了全球 130 家工厂的可视化&lt;a href=&#34;https://www.youtube.com/watch?v=FaarevjZnls&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;电装&lt;/a&gt;。每次聚会都会迎来 100 多名可观测性专家和爱好者，帮助促进本地开源可观测性社区内的学习、共享和交流。聚会还在线直播，有数百名参与者实时加入。我们还更新了我们的网站，为社区提供日语资源。&lt;/p&gt;&#xA;&lt;p&gt;这项工作符合我们的使命，即让 Grafana 易于使用，无论您的数据（或我们的用户）位于何处。虽然开源的魔力在于我们的通用语言是代码，但我们始终致力于扩展我们的全球社区（该社区现已拥有超过 2000 万用户），并在我们所在的地方与他们见面。&lt;/p&gt;&#xA;&lt;p&gt;但最终，我们真正的超级力量在于开源内部建立的强大联系&lt;a href=&#34;/blog/2023/12/12/the-story-of-grafana-documentary-the-community -behind-the-code/&#34;&gt;Grafana 社区&lt;/a&gt;。 “每当我有一个问题或一个我从未尝试过的想法或 Grafana 从未尝试过的想法时，我们总是想一起尝试，”Volkov Labs 的首席执行官兼创始人、Grafana 的长期贡献者 Mikhail Volkov 说道。 “在社区的帮助下，你可以使用 Grafana 做任何你想做的事。”&lt;/p&gt;&#xA;&lt;p&gt;当 Grafana 社区想要 Amazon CloudWatch 数据源时，一位社区成员于 2015 年做出了回应。“这是我第一次为 Grafana 这样的大型 OSS 做出贡献，”GREE, Inc. 的首席工程师 Mitsuhiro Tanda 说道。 “社区聚集在一起，共同讨论这个问题。一起建立一些东西真是太好了。这是一种非常类似于 Grafana 的社区方式。”&lt;/p&gt;&#xA;&lt;p&gt;对于&lt;a href=&#34;/blog/2024/02/12/the-story-of-grafana-documentary-from-one-developers-dream-to-20-million-users- 来说，情况仍然如此-全球/&#34;&gt;十多年&lt;/a&gt;。当 Satoshi Nakahira 在 JAXA 的系统中实施 Grafana 来帮助日本成为第五个登陆月球的国家时，“我们能够非常轻松地构建整个系统，并且可视化功能非常广泛，从简单的图表到详细的图表。我们还能够创建广受好评且视觉效果令人印象深刻的仪表板，”Sat 说道oshi，其&lt;a href=&#34;/events/grafanacon/2024/grafana-used-to-monitor-japan-slim-moon-lander/&#34;&gt;GrafanaCON 会议可供点播观看&lt;/a&gt;。 “非常感谢 Grafana 社区。”&lt;/p&gt;</description>
      <pubDate>Fri, 26 Jul 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Prometheus data source update: Redefining our big tent philosophy】Prometheus 数据源更新：重新定义我们的大帐篷理念</title>
      <link>https://grafana.com/blog/2024/08/06/prometheus-data-source-update-redefining-our-big-tent-philosophy/</link>
      <description>【&lt;p&gt;As we continue adding to our growing catalog of more than 100 plugins for Grafana, we have been focused on developing data sources for Grafana that are more purpose-built for the respective technologies.&lt;/p&gt;&#xA;&lt;p&gt;One example has been the recent update to our core Prometheus data source. We have deprecated AWS authentication from the original Prometheus data source, and we created a new dedicated &lt;a href=&#34;/grafana/plugins/grafana-amazonprometheus-datasource/?tab=overview&#34;&gt;Amazon Managed Service for Prometheus plugin&lt;/a&gt; that will specifically cater to the AWS use case. If you are a Grafana user who uses Amazon Managed Prometheus (AMP), you can learn more about how to install or migrate to the new plugin in &lt;a href=&#34;/grafana/plugins/grafana-amazonprometheus-datasource/?tab=installation&#34;&gt;our Amazon Managed Service for Prometheus documentation&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;We plan to do the same update in regards to Prometheus and Microsoft Azure, and we will continue to explore how to make other data sources in the Grafana ecosystem more purpose-built over time.&lt;/p&gt;&#xA;&lt;h2 id=&#34;a-bigger-big-tent&#34;&gt;A bigger &amp;ldquo;big tent&amp;rdquo;&lt;/h2&gt;&#xA;&lt;p&gt;This refined focus on our data sources is a reflection of our commitment to meet our users where they are.&lt;/p&gt;&#xA;&lt;p&gt;Observability today is a complicated space. Companies of all sizes have adopted numerous open source and commercial tools to monitor an ever expanding sprawl of infrastructure, applications, and even physical devices. In our recent &lt;a href=&#34;/observability-survey/?pg=blog&amp;amp;plcmt=body-txt#so.-many.-tools.&#34;&gt;2024 Observability Survey&lt;/a&gt;, 72% of the active Grafana users polled had at least four data sources configured in Grafana. Not to mention, one in 10 Grafana users said they pull in data from &lt;em&gt;more than 50 data sources&lt;/em&gt;.&lt;/p&gt;&#xA;&lt;p&gt;It shouldn&amp;rsquo;t come as a surprise to anyone reading this, that this explosion in observability tools has been a pretty great wave for Grafana Labs to ride thanks to our commitment to our &amp;ldquo;big tent&amp;rdquo; philosophy. We believe that organizations should own their observability strategy, have the freedom to choose their own tools, and have the ability to bring all their data together in one view, no matter where it lives. As a result, Grafana has quickly become the de facto visualization tool for centralized observability.&lt;/p&gt;&#xA;&lt;p&gt;But over the years, we have evolved our understanding of what &amp;ldquo;big tent&amp;rdquo; stands for. While we still prioritize software interoperability, &amp;ldquo;big tent&amp;rdquo; also means surfacing the meaningful differences between data sources so users can form clear expectations and avoid solving for the lowest common denominator. These differences are in the values of each upstream project as much as they are in APIs.&lt;/p&gt;&#xA;&lt;p&gt;In our opinion, data sources with open source and foundation-run projects should be exclusively compatible with the upstream APIs and reflect the project’s vendor neutrality. Vendors adjacent to these open source projects, with their own API and differences, are also invited into the big tent: You can build data sources that are tailored to your specific technology and still reach the Grafana community. (Potential partners can enquire about working directly with us on commercial data source publishing options at &lt;a href=&#34;mailto:integrations@grafana.com&#34;&gt;integrations@grafana.com&lt;/a&gt;.) But whether it comes from a commercial partner or the community, we believe that each data source should have a clear purpose and lean into that goal.&lt;/p&gt;&#xA;&lt;p&gt;Prometheus is a standout example. Throughout a decade of development, this open source project has grown into a gold standard for time series metrics data and is critical infrastructure for businesses across the industry. It remains a vibrant and independent project under the governance of the &lt;a href=&#34;https://www.cncf.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Cloud Native Computing Foundation&lt;/a&gt; (CNCF), with countless open source contributors continuing to evolve the code to support challenges, and a thriving community providing a colossal support apparatus.&lt;/p&gt;&#xA;&lt;p&gt;Users of our core Prometheus data source should expect this data source to closely mirror the functionality developed and supported within this community. The data source itself should not be overcomplicated or otherwise confuse users with proprietary functionality that branches off of the Prometheus project.&lt;/p&gt;&#xA;&lt;p&gt;Meanwhile, the proprietary projects in Prometheus’s orbit should be built and welcomed into the community as separate data sources. This is why we have provided Grafana users who use Amazon Managed Prometheus (AMP) with access to the Amazon Managed Service for Prometheus plugin, which supports platform-specific AWS Signature Version 4 authentication.&lt;/p&gt;&#xA;&lt;h2 id=&#34;whats-next&#34;&gt;What&amp;rsquo;s next&lt;/h2&gt;&#xA;&lt;p&gt;We feel this new &amp;ldquo;big tent&amp;rdquo; approach has been a natural evolution we&amp;rsquo;ve seen in the industry as we continue to field requests for new data sources that span a wide range of licensing models and that support every flavor of platform-specific auth, query language, feature, and more.&lt;/p&gt;&#xA;&lt;p&gt;But interoperability continues to be one of the primary drivers of our roadmap. We maintain &lt;a href=&#34;/grafana/plugins/all-plugins/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;100+ plugins&lt;/a&gt; for Grafana and &lt;a href=&#34;/docs/grafana-cloud/data-configuration/integrations/integration-reference/&#34;&gt;65+ Grafana Cloud integrations&lt;/a&gt; for monitoring third-party tools. Our open source projects, including the core technology behind the Grafana LGTM Stack (&lt;a href=&#34;/oss/loki/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Loki&lt;/a&gt; for logs, &lt;a href=&#34;/oss/grafana?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana&lt;/a&gt; for visualization, &lt;a href=&#34;/oss/tempo/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Tempo&lt;/a&gt; for traces, and &lt;a href=&#34;/oss/mimir/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Mimir&lt;/a&gt; for metrics), are built on &amp;ldquo;big tent&amp;rdquo; principles. We also contribute to OSS projects such as Prometheus (we are the No. 1 company contributor) and OpenTelemetry, with a focus on making the &lt;a href=&#34;/blog/2023/07/20/a-practical-guide-to-data-collection-with-opentelemetry-and-prometheus/&#34;&gt;two projects more interoperable&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;While this is our current thinking on &amp;ldquo;big tent&amp;rdquo; and interoperability, we want to continue to listen to our community, partners, and users to better refine our approach. Please reach out to the team at &lt;a href=&#34;mailto:integrations@grafana.com&#34;&gt;integrations@grafana.com&lt;/a&gt; if you have any feedback, questions, or concerns.&lt;/p&gt;&#xA;&lt;p&gt;We are also delighted to share that we are creating a new &lt;a href=&#34;/docs/grafana-cloud/whats-new/2024-07-24-roadmap-for-new-data-sources/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;public roadmap&lt;/a&gt; that shows all of the date source plugins being built by Grafana Labs, our partners, and our community. Grafana Cloud users can now see our current plans and request new plugins, upvote existing requests, or comment with ideas and requirements. Grafana OSS and Grafana Enterprise users will soon have access to the public roadmap as well.&lt;/p&gt;&#xA;&lt;p&gt;No matter how you engage with our community, we want to hear from you and learn how we can make Grafana&amp;rsquo;s &amp;ldquo;big tent&amp;rdquo; bigger and better.&lt;/p&gt;】&lt;p&gt;随着我们不断向 Grafana 的 100 多个插件添加目录，我们一直专注于为 Grafana 开发更适合各自技术的数据源。&lt;/p&gt;&#xA;&lt;p&gt;一个例子是我们的核心 Prometheus 数据源的最近更新。我们已弃用原始 Prometheus 数据源中的 AWS 身份验证，并创建了一个新的专用 &lt;a href=&#34;/grafana/plugins/grafana-amazonprometheus-datasource/?tab=overview&#34;&gt;Amazon Managed Service for Prometheus 插件&lt;/a&gt;这将专门满足 AWS 用例。如果您是使用 Amazon Managed Prometheus (AMP) 的 Grafana 用户，您可以在 &lt;a href=&#34;/grafana/plugins/grafana-amazonprometheus-datasource/?tab=installation 中了解有关如何安装或迁移到新插件的更多信息&#34;&gt;我们的 Amazon Managed Service for Prometheus 文档&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;我们计划对 Prometheus 和 Microsoft Azure 进行相同的更新，并且随着时间的推移，我们将继续探索如何使 Grafana 生态系统中的其他数据源更加专用。&lt;/p&gt;&#xA;&lt;h2 id=&#34;a-bigger-big-tent&#34;&gt;更大的“大帐篷”&lt;/h2&gt;&#xA;&lt;p&gt;对数据源的高度关注体现了我们满足用户需求的承诺。&lt;/p&gt;&#xA;&lt;p&gt;当今的可观察性是一个复杂的空间。各种规模的公司都采用了大量的开源和商业工具来监控不断扩大的基础设施、应用程序甚至物理设备。在我们最近的&lt;a href=&#34;/observability-survey/?pg=blog&amp;plcmt=body-txt#so.-many.-tools.&#34;&gt;2024 年可观测性调查&lt;/a&gt;中，接受调查的活跃 Grafana 用户中有 72% Grafana 中至少配置了四个数据源。更不用说，十分之一的 Grafana 用户表示他们从&lt;em&gt;超过 50 个数据源&lt;/em&gt;提取数据。&lt;/p&gt;&#xA;&lt;p&gt;读到这篇文章的人应该不会感到惊讶，由于我们对“大帐篷”理念的承诺，可观察性工具的爆炸式增长对 Grafana Labs 来说是一个相当大的浪潮。我们认为，组织应该拥有自己的可观察性策略，可以自由选择自己的工具，并且有能力将所有数据整合到一个视图中，无论数据位于何处。因此，Grafana 迅速成为事实上的集中式可观测可视化工具。&lt;/p&gt;&#xA;&lt;p&gt;但多年来，我们对“大帐篷”的含义有了更深的理解。虽然我们仍然优先考虑软件互操作性，但“大帐篷”也意味着暴露数据源之间有意义的差异，以便用户可以形成明确的期望，并避免解决最低公分母。这些差异既存在于每个上游项目的价值中，也存在于 API 中。&lt;/p&gt;&#xA;&lt;p&gt;我们认为，开源和基金会运行的项目的数据源应该与上游 API 完全兼容，并体现项目的供应商中立性。与这些开源项目相邻的供应商都有自己的API 和差异也被邀请进入大帐篷：您可以构建适合您的特定技术的数据源，并且仍然可以到达 Grafana 社区。 （潜在合作伙伴可以通过 &lt;a href=&#34;mailto:integrations@grafana.com&#34;&gt;integrations@grafana.com&lt;/a&gt; 询问是否直接与我们就商业数据源发布选项进行合作。）但它是否来自商业合作伙伴或社区，我们认为每个数据源都应该有明确的目的并倾向于该目标。&lt;/p&gt;&#xA;&lt;p&gt;普罗米修斯是一个突出的例子。经过十年的发展，这个开源项目已经发展成为时间序列指标数据的黄金标准，并且是整个行业企业的关键基础设施。在&lt;a href=&#34;https://www.cncf.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;云原生计算基金会&lt;/a&gt; (CNCF ），无数开源贡献者不断改进代码以支持挑战，并且蓬勃发展的社区提供了巨大的支持工具。&lt;/p&gt;&#xA;&lt;p&gt;我们核心 Prometheus 数据源的用户应该期望该数据源能够密切反映该社区内开发和支持的功能。数据源本身不应过于复杂，否则会使用户对 Prometheus 项目分支的专有功能感到困惑。&lt;/p&gt;&#xA;&lt;p&gt;与此同时，普罗米修斯轨道上的专有项目应该作为单独的数据源构建并欢迎进入社区。因此，我们为使用 Amazon Managed Prometheus (AMP) 的 Grafana 用户提供了对 Amazon Managed Service for Prometheus 插件的访问权限，该插件支持特定于平台的 AWS 签名版本 4 身份验证。&lt;/p&gt;&#xA;&lt;h2 id=&#34;whats-next&#34;&gt;下一步是什么&lt;/h2&gt;&#xA;&lt;p&gt;我们认为，这种新的“大帐篷”方法是我们在行业中看到的自然演变，因为我们不断满足对新数据源的请求，这些数据源涵盖广泛的许可模型并支持各种平台 -特定的身份验证、查询语言、功能等等。&lt;/p&gt;&#xA;&lt;p&gt;但互操作性仍然是我们路线图的主要驱动因素之一。我们为 Grafana 和 &lt;a href=&#34;/docs/grafana-cloud/data- 维护&lt;a href=&#34;/grafana/plugins/all-plugins/?pg=blog&amp;plcmt=body-txt&#34;&gt;100 多个插件&lt;/a&gt; configuration/integrations/integration-reference/&#34;&gt;65 多个 Grafana Cloud 集成&lt;/a&gt;，用于监控第三方工具。我们的开源项目，包括 Grafana LGTM Stack 背后的核心技术（&lt;a href=&#34;/oss/loki/?pg=blog&amp;plcmt=body-txt&#34;&gt;Loki&lt;/a&gt; 用于日志、&lt;a href=&#34;/oss /grafana?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana&lt;/a&gt; 用于可视化，&lt;a href=&#34;/oss/tempo/?pg=blog&amp;plcmt=body-txt&#34;&gt;Tempo&lt;/a&gt; 用于跟踪，以及 &lt; a href=&#34;/oss/mimir/?pg=blog&amp;plcmt=body-txt&#34;&gt;Mimir&lt;/a&gt; 用于指标），是建立在“大帐篷”原则之上的。我们还为 Prometheus（我们是排名第一的公司贡献者）和 OpenT 等 OSS 项目做出贡献elemetry，重点是使&lt;a href=&#34;/blog/2023/07/20/a-practical-guide-to-data-collection-with-opentelemetry-and-prometheus/&#34;&gt;两个项目更具互操作性&lt;/一个&gt;.&lt;/p&gt;&#xA;&lt;p&gt;虽然这是我们目前对“大帐篷”和互操作性的想法，但我们希望继续倾听社区、合作伙伴和用户的意见，以更好地完善我们的方法。如果您有任何反馈、问题或疑虑，请通过 &lt;a href=&#34;mailto:integrations@grafana.com&#34;&gt;integrations@grafana.com&lt;/a&gt; 与团队联系。&lt;/p&gt;&#xA;&lt;p&gt;我们还很高兴地告诉大家，我们正在创建一个新的&lt;a href=&#34;/docs/grafana-cloud/whats-new/2024-07-24-roadmap-for-new-data-sources/?pg= blog&amp;plcmt=body-txt&#34;&gt;公共路线图&lt;/a&gt;显示了 Grafana Labs、我们的合作伙伴和我们的社区正在构建的所有日期源插件。 Grafana Cloud 用户现在可以查看我们当前的计划并请求新插件、对现有请求进行投票或评论想法和要求。 Grafana OSS 和 Grafana Enterprise 用户很快也将可以访问公共路线图。&lt;/p&gt;&#xA;&lt;p&gt;无论您如何与我们的社区互动，我们都希望听到您的声音并了解如何使 Grafana 的“大帐篷”变得更大更好。&lt;/p&gt;</description>
      <pubDate>Tue, 06 Aug 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Grafana Alloy 1.3 release: Debug pipelines in real time】Grafana Alloy 1.3 版本：实时调试管道</title>
      <link>https://grafana.com/blog/2024/08/05/grafana-alloy-1.3-release-debug-pipelines-in-real-time/</link>
      <description>【&lt;p&gt;&lt;a href=&#34;https://github.com/grafana/alloy/releases/tag/v1.3.0&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Grafana Alloy 1.3&lt;/a&gt; is here!&lt;/p&gt;&#xA;&lt;p&gt;First introduced &lt;a href=&#34;/blog/2024/04/09/grafana-alloy-opentelemetry-collector-with-prometheus-pipelines/&#34;&gt;earlier this year&lt;/a&gt;, Alloy is our open source distribution of the OpenTelemetry Collector. It has native pipelines for OpenTelemetry and Prometheus telemetry formats, and it uses the same components, code, and concepts that were previously introduced in Grafana Agent Flow.&lt;/p&gt;&#xA;&lt;p&gt;This new release introduces &lt;a href=&#34;/docs/alloy/v1.3/troubleshoot/debug/&#34;&gt;live debugging&lt;/a&gt;, enhancing debugging capabilities across key &lt;a href=&#34;/docs/alloy/latest/get-started/components/&#34;&gt;components&lt;/a&gt;, which are the building blocks of Alloy. This feature allows for real-time monitoring of your data pipelines so you can quickly:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Visualize data transformations&lt;/li&gt;&#xA;&lt;li&gt;Identify and isolate errors&lt;/li&gt;&#xA;&lt;li&gt;Analyze pipeline behavior&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Live debugging makes troubleshooting more efficient and provides deeper insights into data flow so you can streamline your development and optimization processes.&lt;/p&gt;&#xA;&lt;h2 id=&#34;configure-live-debugging&#34;&gt;Configure live debugging&lt;/h2&gt;&#xA;&lt;p&gt;Live debugging is disabled by default to avoid accidentally displaying sensitive telemetry data. You can enable it by adding the &lt;a href=&#34;/docs/alloy/v1.3/reference/config-blocks/livedebugging/&#34;&gt;live debugging&lt;/a&gt; block to your config:&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet &#34;&gt;&lt;div class=&#34;lang-toolbar&#34;&gt;&#xA;&lt;span class=&#34;lang-toolbar__item&#34;&gt;alloy&lt;/span&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;button x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;Copy code to clipboard&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;Copy&lt;/span&gt;&#xA;&lt;/button&gt;&#xA;&lt;/span&gt;&#xA;&lt;div class=&#34;lang-toolbar__border&#34;&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet &#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-alloy&#34;&gt;livedebugging {&#xA;enabled = true&#xA;}&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;p&gt;Since this feature is experimental, you will need to set the stability level to &lt;code&gt;experimental&lt;/code&gt;:&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet &#34;&gt;&lt;div class=&#34;lang-toolbar&#34;&gt;&#xA;&lt;span class=&#34;lang-toolbar__item&#34;&gt;bash&lt;/span&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;button x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;Copy code to clipboard&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;Copy&lt;/span&gt;&#xA;&lt;/button&gt;&#xA;&lt;/span&gt;&#xA;&lt;div class=&#34;lang-toolbar__border&#34;&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet &#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-bash&#34;&gt;alloy run config.alloy --stability.level experimental&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;p&gt;Visit http://localhost:12345/ to open the UI. Press the &lt;strong&gt;Live Debugging&lt;/strong&gt; button on a component page to start a session for that component.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1791px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&#xA;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/alloy-1-3/live-debugging-in-ui.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/alloy-1-3/live-debugging-in-ui.png&#34;data-srcset=&#34;/media/blog/alloy-1-3/live-debugging-in-ui.png?w=320 320w, /media/blog/alloy-1-3/live-debugging-in-ui.png?w=550 550w, /media/blog/alloy-1-3/live-debugging-in-ui.png?w=750 750w, /media/blog/alloy-1-3/live-debugging-in-ui.png?w=900 900w, /media/blog/alloy-1-3/live-debugging-in-ui.png?w=1040 1040w, /media/blog/alloy-1-3/live-debugging-in-ui.png?w=1240 1240w, /media/blog/alloy-1-3/live-debugging-in-ui.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;&#34;&#xA;width=&#34;1791&#34;&#xA;height=&#34;1190&#34;&#xA;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/alloy-1-3/live-debugging-in-ui.png&#34;&#xA;alt=&#34;&#34;&#xA;width=&#34;1791&#34;&#xA;height=&#34;1190&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;/a&gt;&#xA;&lt;/figure&gt;&#xA;&lt;p&gt;You can scroll through, filter, and sample the data. You can also manage the flow using the pause/unpause feature and the &lt;strong&gt;Clear&lt;/strong&gt; button.&lt;/p&gt;&#xA;&lt;p&gt;The following components support live debugging in this version:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;loki.process&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;loki.relabel&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;otelcol.processor&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;otelcol.receiver&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;prometheus.relabel&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Both &lt;code&gt;otelcol.processor&lt;/code&gt; and &lt;code&gt;otelcol.receiver&lt;/code&gt; include all corresponding components.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h2 id=&#34;build-your-pipelines-step-by-step&#34;&gt;Build your pipelines step by step&lt;/h2&gt;&#xA;&lt;p&gt;In the previous version of Alloy, you had to build your entire pipeline and check your databases in the hope that the telemetry data was delivered in the expected format. But with live debugging, you can add components incrementally and verify that the data meets your expectations before sending it to the cloud.&lt;/p&gt;&#xA;&lt;p&gt;Watch the following videos to learn more about how to build pipelines with live debugging. In the first one, you&amp;rsquo;ll see how to send Prometheus metrics to Grafana Cloud using Alloy.&lt;/p&gt;&#xA;&lt;div class=&#34;shortcode youtube&#34;&gt;&#xA;&lt;iframe src=&#34;https://www.youtube.com/embed/_MbB8IVKMfw?rel=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;And if you&amp;rsquo;re using OpenTelemetry, this second video will show you how to receive OpenTelemetry Protocol (OTLP) metrics from your application and send them to Grafana Cloud with the help of live debugging.&lt;/p&gt;&#xA;&lt;div class=&#34;shortcode youtube&#34;&gt;&#xA;&lt;iframe src=&#34;https://www.youtube.com/embed/IRqQEzc0kvA?rel=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&#xA;&lt;h2 id=&#34;learn-more-about-grafana-alloy&#34;&gt;Learn more about Grafana Alloy&lt;/h2&gt;&#xA;&lt;p&gt;To learn more about other features in the latest release, please refer to our &lt;a href=&#34;/docs/alloy/v1.3/&#34;&gt;Grafana Alloy documentation&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;As always, we’d love to hear from you, so feel free to drop by our &lt;a href=&#34;https://slack.grafana.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Grafana Labs community Slack&lt;/a&gt; or check out the &lt;a href=&#34;https://github.com/grafana/alloy&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Alloy repo&lt;/a&gt; directly. We look forward to your comments and feedback!&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;/products/cloud/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Cloud &lt;/a&gt;is the easiest way to get started with metrics, logs, traces, dashboards, and more. We have a generous forever-free tier and plans for every use case. &lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Sign up for free now!&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;】&lt;p&gt;&lt;a href=&#34;https://github.com/grafana/alloy/releases/tag/v1.3.0&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Grafana Alloy 1.3&lt;/a&gt; 就在这里！ &lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;/blog/2024/04/09/grafana-alloy-opentelemetry-collector-with-prometheus-pipelines/&#34;&gt;今年早些时候&lt;/a&gt;首次推出，Alloy 是我们OpenTelemetry 收集器。它具有适用于 OpenTelemetry 和 Prometheus 遥测格式的本机管道，并且使用之前在 Grafana Agent Flow 中引入的相同组件、代码和概念。&lt;/p&gt;&#xA;&lt;p&gt;此新版本引入了&lt;a href=&#34;/docs/alloy/v1.3/troubleshoot/debug/&#34;&gt;实时调试&lt;/a&gt;，增强了关键&lt;a href=&#34;/docs/alloy/latest 的调试功能/get-started/components/&#34;&gt;组件&lt;/a&gt;，它们是 Alloy 的构建块。此功能允许实时监控您的数据管道，以便您可以快速：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;可视化数据转换&lt;/li&gt;&#xA;&lt;li&gt;识别并隔离错误&lt;/li&gt;&#xA;&lt;li&gt;分析管道行为&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;实时调试使故障排除更加高效，并提供对数据流的更深入洞察，以便您可以简化开发和优化流程。&lt;/p&gt;&#xA;&lt;h2 id=&#34;configure-live-debugging&#34;&gt;配置实时调试&lt;/h2&gt;&#xA;&lt;p&gt;默认情况下禁用实时调试，以避免意外显示敏感遥测数据。您可以通过将&lt;a href=&#34;/docs/alloy/v1.3/reference/config-blocks/livedebugging/&#34;&gt;实时调试&lt;/a&gt;块添加到您的配置中来启用它：&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet&#34;&gt;&lt;div class=&#34;lang-toolbar&#34;&gt;&#xA;&lt;span class=&#34;lang-toolbar__item&#34;&gt;合金&lt;/span&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;按钮 x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;将代码复制到剪贴板&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;复制&lt;/span&gt;&#xA;&lt;/按钮&gt;&#xA;&lt;/span&gt;&#xA;&lt;div class=&#34;lang-toolbar__border&#34;&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-alloy&#34;&gt;实时调试 {&#xA;启用=真&#xA;}&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;p&gt;由于此功能是实验性的，因此您需要将稳定性级别设置为&lt;code&gt;实验性&lt;/code&gt;：&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet&#34;&gt;&lt;div class=&#34;lang-toolbar&#34;&gt;&#xA;&lt;span class=&#34;lang-toolbar__item&#34;&gt;bash&lt;/span&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;按钮 x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;将代码复制到剪贴板&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;复制&lt;/span&gt;&#xA;&lt;/按钮&gt;&#xA;&lt;/span&gt;&#xA;&lt;div class=&#34;lang-toolbar__border&#34;&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-bash&#34;&gt;合金运行 config.alloy --stability.level 实验性&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;p&gt;访问http://localhost:12345/打开UI。按组件页面上的&lt;strong&gt;实时调试&lt;/strong&gt;按钮启动该组件的会话。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1791px；”&#xA;itemprop=“关联”泰德媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&#xA;&lt;一&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/alloy-1-3/live-debugging-in-ui.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src =“/media/blog/alloy-1-3/live-debugging-in-ui.png”data-srcset =“/media/blog/alloy-1-3/live-debugging-in-ui.png” png?w=320 320w，/media/blog/alloy-1-3/live-debugging-in-ui.png?w=550 550w，/media/blog/alloy-1-3/live-debugging-in- ui.png?w=750 750w, /media/blog/alloy-1-3/live-debugging-in-ui.png?w=900 900w, /media/blog/alloy-1-3/live-debugging- in-ui.png?w=1040 1040w，/media/blog/alloy-1-3/live-debugging-in-ui.png?w=1240 1240w，/media/blog/alloy-1-3/live-调试-in-ui.png?w=1920 1920w&#34;&#xA;数据大小=“自动”alt=“”&#xA;宽度=“1791”&#xA;高度=“1190”&#xA;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/alloy-1-3/live-debugging-in-ui.png”&#xA;替代=“”&#xA;宽度=“1791”&#xA;高度=“1190”&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;/a&gt;&#xA;&lt;/图&gt;&#xA;&lt;p&gt;您可以滚动、过滤和采样数据。您还可以使用暂停/取消暂停功能和&lt;strong&gt;清除&lt;/strong&gt;按钮来管理流程。&lt;/p&gt;&#xA;&lt;p&gt;此版本中以下组件支持实时调试：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;loki.process&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;loki.relabel&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;otelcol.processor&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;otelcol.receiver&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;prometheus.relabel&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;块引用&gt;&#xA;&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;&lt;code&gt;otelcol.processor&lt;/code&gt; 和 &lt;code&gt;otelcol.receiver&lt;/code&gt; 都包含所有相应的组件。&lt;/p&gt;&#xA;&lt;/块引用&gt;&#xA;&lt;h2 id=&#34;build-your-pipelines-step-by-step&#34;&gt;逐步构建您的管道&lt;/h2&gt;&#xA;&lt;p&gt;在 Alloy 的早期版本中，您必须构建整个管道并检查数据库，希望遥测数据以预期的格式交付。但通过实时调试，您可以增量添加组件并在将数据发送到云之前验证数据是否满足您的期望。&lt;/p&gt;&#xA;&lt;p&gt;观看以下视频，详细了解如何通过实时调试构建管道。在第一个中，您将了解如何使用 Alloy 将 Prometheus 指标发送到 Grafana Cloud。&lt;/p&gt;&#xA;&lt;div class=&#34;shortcode youtube&#34;&gt;&#xA;&lt;iframe src=&#34;https://www.youtube.com/embed/_MbB8IVKMfw?rel=0&#34; style=&#34;位置：绝对；顶部：0；左侧：0；宽度：100%；高度：100%；边框： 0;” allowedfullscreen title=&#34;YouTube 视频&#34;&gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;如果您使用 OpenTelemetry，第二个视频将向您展示如何从应用程序接收 OpenTelemetry Protocol (OTLP) 指标，并借助实时调试将它们发送到 Grafana Cloud。&lt;/p&gt;&#xA;&lt;div class=&#34;shortcode youtube&#34;&gt;&#xA;&lt;iframe src=&#34;https://www.youtube.com/embed/IRqQEzc0kvA?rel=0&#34; style=&#34;位置：绝对；顶部：0；左侧：0；宽度：100%；高度：100%；边框： 0;” allowedfullscreen title=&#34;YouTube 视频&#34;&gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&#xA;&lt;h2 id=&#34;learn-more-about-grafana-alloy&#34;&gt;了解有关 Grafana 合金的更多信息&lt;/h2&gt;&#xA;&lt;p&gt;要了解有关最新版本中其他功能的更多信息，请参阅我们的 &lt;a href=&#34;/docs/alloy/v1.3/&#34;&gt;Grafana Alloy 文档n&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;一如既往，我们很乐意听取您的意见，因此请随时访问我们的 &lt;a href=&#34;https://slack.grafana.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt; Grafana Labs 社区 Slack&lt;/a&gt; 或直接查看 &lt;a href=&#34;https://github.com/grafana/alloy&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Alloy 存储库&lt;/a&gt;。我们期待您的意见和反馈！&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;/products/cloud/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt;是开始使用指标、日志、跟踪、仪表板等的最简单方法。我们为每个用例提供慷慨的永久免费套餐和计划。 &lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;plcmt=body-txt&#34;&gt;立即免费注册！&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 05 Aug 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Observe deleted Kubernetes components in Grafana Cloud to boost troubleshooting and resource management】观察 Grafana Cloud 中已删除的 Kubernetes 组件，以促进故障排除和资源管理</title>
      <link>https://grafana.com/blog/2024/08/08/observe-deleted-kubernetes-components-in-grafana-cloud-to-boost-troubleshooting-and-resource-management/</link>
      <description>【&lt;p&gt;As a site reliability engineer, you need constant vigilance and a keen eye for detail if you want to manage your Kubernetes infrastructure effectively.&lt;/p&gt;&#xA;&lt;p&gt;As part of that effort, you need to see the historical data from your pods, nodes, and clusters — even after they&amp;rsquo;ve been deleted or recreated. Many SREs rely on kubectl for this, and while it&amp;rsquo;s indispensable for real-time Kubernetes management, it presents some significant challenges with historical data:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Manual effort:&lt;/strong&gt; You have to continuously intervene to capture and retain the necessary data.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Complexity:&lt;/strong&gt; You have to orchestrate multiple commands and tools to get a complete historical view.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Data retention:&lt;/strong&gt; You have to set up and maintain additional infrastructure to ensure the data is available long-term.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Not only is this time-consuming and expensive, it can also open the door to mistakes and missing data. And those errors can lead to a lack of visibility that hinders effective troubleshooting, resource management, and compliance. But with &lt;a href=&#34;/solutions/kubernetes/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Kubernetes Monitoring in Grafana Cloud&lt;/a&gt;, you can quickly overcome these challenges. To illustrate this, let&amp;rsquo;s follow the journey of a SRE facing multiple issues and see how historical visibility in Kubernetes Monitoring can help.&lt;/p&gt;&#xA;&lt;h3 id=&#34;scenario-1-debugging-post-deployment-application-issues&#34;&gt;&lt;strong&gt;Scenario 1: Debugging post-deployment application issues&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;p&gt;Let&amp;rsquo;s say you’re working at a bustling tech company, and you&amp;rsquo;ve just overseen the deployment of a new version of your application. Everything seems fine until users start reporting intermittent failures. Panic sets in as you realize the issue might be with the pods that were created and deleted during the deployment.&lt;/p&gt;&#xA;&lt;p&gt;Initially, you frantically run &lt;code&gt;kubectl get pods --all-namespaces&lt;/code&gt; to capture pod states, but the problematic pods were deleted. You then try to find logs using &lt;code&gt;kubectl logs &amp;lt;pod-name&amp;gt;&lt;/code&gt;, but the pods no longer exist. Desperate, you look for events with &lt;code&gt;kubectl describe pod&lt;/code&gt;, hoping to piece together the puzzle. This process is time consuming and error prone, causing further delays and frustration.&lt;/p&gt;&#xA;&lt;p&gt;But with Grafana Cloud, you get &lt;a href=&#34;/docs/grafana-cloud/monitor-infrastructure/kubernetes-monitoring/navigate-k8s-monitoring/?pg=blog&amp;amp;plcmt=body-txt#analyze-historical-data&#34;&gt;historical visibility out of the box&lt;/a&gt;. You can easily view the state and logs of those deleted pods. Instead of scrambling through ephemeral logs, you’re able to calmly access a timeline that shows exactly what happened before the deployment went awry. This not only helps you pinpoint the issue but also reduces downtime and user frustration.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 2446px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&#xA;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/docs/grafana-cloud/k8s/find-deletd-node.gif&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/docs/grafana-cloud/k8s/find-deletd-node.gif&#34;alt=&#34;Analyzing &amp;#39;No data&amp;#39; status on a node in Kubernetes Monitoring&#34;&#xA;width=&#34;2446&#34;&#xA;height=&#34;1806&#34;&#xA;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/docs/grafana-cloud/k8s/find-deletd-node.gif&#34;&#xA;alt=&#34;Analyzing &amp;#39;No data&amp;#39; status on a node in Kubernetes Monitoring&#34;&#xA;width=&#34;2446&#34;&#xA;height=&#34;1806&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;/a&gt;&#xA;&lt;/figure&gt;&#xA;&lt;p&gt;There are other times where historical data comes in handy for debugging. For example, maybe you&amp;rsquo;re working with an Azure Kubernetes Service cluster and you mistakenly delete all nodes, thinking the cluster would self-heal. This leads to all pods being in a pending state with no nodes available. The immediate impact is severe: applications become unavailable, user requests fail, and the overall system stability is compromised. You then decide to upgrade the cluster to bring it back to a functional state. After upgrading the cluster, nodes come back online, and pods move from pending to running state.&lt;/p&gt;&#xA;&lt;p&gt;With Kubernetes Monitoring in Grafana Cloud, you can access historical visibility to understand the sequence of events leading to the issue. You can see when the &lt;a href=&#34;/docs/grafana-cloud/monitor-infrastructure/kubernetes-monitoring/navigate-k8s-monitoring/?pg=blog&amp;amp;plcmt=body-txt#find-deleted-kubernetes-objects&#34;&gt;nodes were deleted&lt;/a&gt;, the exact state changes of the pods, and how the system responded over time.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1512px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&#xA;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/docs/grafana-cloud/k8s/nodata-on-node.gif&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/docs/grafana-cloud/k8s/nodata-on-node.gif&#34;alt=&#34;Analyzing &amp;#39;No date&amp;#39; status on a node in Kubernetes Monitoring&#34;&#xA;width=&#34;1512&#34;&#xA;height=&#34;824&#34;&#xA;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/docs/grafana-cloud/k8s/nodata-on-node.gif&#34;&#xA;alt=&#34;Analyzing &amp;#39;No date&amp;#39; status on a node in Kubernetes Monitoring&#34;&#xA;width=&#34;1512&#34;&#xA;height=&#34;824&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;/a&gt;&#xA;&lt;/figure&gt;&#xA;&lt;p&gt;This detailed historical data allows you to identify the root cause quickly and implement preventive measures to avoid such disruptions in the future. The ability to review the entire timeline in Grafana Cloud not only helps to resolve the current issue; it also provides insights for improving the overall system resilience.&lt;/p&gt;&#xA;&lt;h3 id=&#34;scenario-2-optimizing-resource-usage&#34;&gt;&lt;strong&gt;Scenario 2: Optimizing resource usage&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;p&gt;With the deployment issues resolved, your next task is optimizing the resource usage of your Kubernetes nodes. You’ve noticed some nodes are consistently running hot, while others are underutilized. Using kubectl, you can check current usage with commands like &lt;code&gt;kubectl top nodes&lt;/code&gt; and &lt;code&gt;kubectl top pods&lt;/code&gt;. But it requires more effort to understand past usage trends.&lt;/p&gt;&#xA;&lt;p&gt;To achieve this with kubectl, you must:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Set up persistent logging solutions to capture metrics over time.&lt;/li&gt;&#xA;&lt;li&gt;Periodically export and store these metrics manually.&lt;/li&gt;&#xA;&lt;li&gt;Painstakingly combine data from various sources to get a historical view.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;Kubernetes Monitoring in Grafana Cloud replaces this tedious process. Historical data on &lt;a href=&#34;/docs/grafana-cloud/monitor-infrastructure/kubernetes-monitoring/optimize-resource-usage/?pg=blog&amp;amp;plcmt=body-txt#discover-usage-over-time&#34;&gt;node and pod resource usage&lt;/a&gt; is readily available, which allows you to analyze trends and make informed decisions about resource allocation. This level of visibility helps you optimize your infrastructure for a more efficient and cost-effective operation.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1512px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&#xA;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/docs/grafana-cloud/k8s/pod-last-30-days.gif&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/docs/grafana-cloud/k8s/pod-last-30-days.gif&#34;alt=&#34;Analyzing the last 30 days in Kubernetes Monitoring&#34;&#xA;width=&#34;1512&#34;&#xA;height=&#34;824&#34;&#xA;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/docs/grafana-cloud/k8s/pod-last-30-days.gif&#34;&#xA;alt=&#34;Analyzing the last 30 days in Kubernetes Monitoring&#34;&#xA;width=&#34;1512&#34;&#xA;height=&#34;824&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;/a&gt;&#xA;&lt;/figure&gt;&#xA;&lt;p&gt;So, there you are in the middle of a resource optimization task, when you remember the cumbersome, manual approach you used to perform to export metrics periodically and store them for historical analysis. But with Grafana Cloud, your historical data can be viewed directly, so you can make quicker and more accurate decisions about resource allocation.&lt;/p&gt;&#xA;&lt;h3 id=&#34;scenario-3-analyzing-past-incidents-for-better-future-planning&#34;&gt;&lt;strong&gt;Scenario 3: Analyzing past incidents for better future planning&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;p&gt;Just when things seem to be running smoothly, a major outage occurs. As an SRE, it&amp;rsquo;s your job to analyze the incident and ensure it doesn&amp;rsquo;t happen again. You need to look back at the state of your Kubernetes infrastructure before, during, and after the outage.&lt;/p&gt;&#xA;&lt;p&gt;If you were to use kubectl to complete this task, you would have to follow a series of steps that presents the same challenges we&amp;rsquo;ve been discussing throughout this blog:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Manually record the state of pods and nodes at regular intervals.&lt;/li&gt;&#xA;&lt;li&gt;Correlate logs from various sources to reconstruct the sequence of events.&lt;/li&gt;&#xA;&lt;li&gt;Piece together data from different tools to get a comprehensive view.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;This can lead to incomplete analysis and overlooked root causes. For example, let&amp;rsquo;s say you discover the outage happened because a particular node was lost after an upgrade, causing significant disruption. It would be difficult to piece together the event logs and states of the nodes manually.&lt;/p&gt;&#xA;&lt;p&gt;Instead, you could use Grafana Cloud to quickly access historical data and understand the sequence of events that led to the outage. With the Kubernetes Monitoring, you can identify patterns and root causes of the incident with ease. And with a few clicks, you can visualize the state of your clusters over time, correlate metrics and &lt;a href=&#34;/docs/grafana-cloud/monitor-infrastructure/kubernetes-monitoring/navigate-k8s-monitoring/?pg=blog&amp;amp;plcmt=body-txt#view-logs-and-events&#34;&gt;logs&lt;/a&gt;, and derive actionable insights that translate to more effective incident analysis and better planning for the future.&lt;/p&gt;&#xA;&lt;h2 id=&#34;start-using-kubernetes-monitoring-today&#34;&gt;Start using Kubernetes Monitoring today&lt;/h2&gt;&#xA;&lt;p&gt;There are good reasons to delete pods and nodes in Kubernetes, including:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Application updates:&lt;/strong&gt; Deploying new versions of applications that may require deleting old pods.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Scaling operations:&lt;/strong&gt; Adjusting the number of pods or nodes to handle varying loads.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Security concerns:&lt;/strong&gt; Addressing vulnerabilities by removing compromised or outdated pods.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;But as we&amp;rsquo;ve shown here, it can lead to significant problems when it isn&amp;rsquo;t handled properly. Kubernetes Monitoring in Grafana Cloud turns potential nightmares into manageable tasks, making it an essential tool for any SRE, cloud infrastructure admin, or developer. For more information, visit the &lt;a href=&#34;/docs/grafana-cloud/monitor-infrastructure/kubernetes-monitoring/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Kubernetes Monitoring documentation&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;/products/cloud/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt; is the easiest way to get started with metrics, logs, traces, dashboards, and more. We have a generous forever-free tier and plans for every use case.&lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt; Sign up for free now&lt;/a&gt;!&lt;/em&gt;&lt;/p&gt;】&lt;p&gt;作为一名站点可靠性工程师，如果您想有效管理 Kubernetes 基础设施，您需要时刻保持警惕并敏锐地关注细节。&lt;/p&gt;&#xA;&lt;p&gt;作为这项工作的一部分，您需要查看 Pod、节点和集群的历史数据 - 即使它们已被删除或重新创建。许多 SRE 都依赖 kubectl 来实现这一点，虽然它对于实时 Kubernetes 管理是不可或缺的，但它对历史数据提出了一些重大挑战：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;手动操作：&lt;/strong&gt;您必须持续干预以捕获和保留必要的数据。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;复杂性：&lt;/strong&gt;您必须协调多个命令和工具才能获得完整的历史视图。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;数据保留&lt;/strong&gt;：您必须设置和维护额外的基础设施，以确保数据长期可用。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;这不仅耗时且昂贵，而且还可能导致错误和数据丢失。这些错误可能会导致缺乏可见性，从而阻碍有效的故障排除、资源管理和合规性。但借助 &lt;a href=&#34;/solutions/kubernetes/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana Cloud 中的 Kubernetes 监控&lt;/a&gt;，您可以快速克服这些挑战。为了说明这一点，让我们跟随一个面临多个问题的 SRE 的旅程，看看 Kubernetes 监控中的历史可见性如何提供帮助。&lt;/p&gt;&#xA;&lt;h3 id=&#34;scenario-1-debugging-post-deployment-application-issues&#34;&gt;&lt;strong&gt;场景 1：调试部署后应用程序问题&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;p&gt;假设您在一家繁忙的科技公司工作，并且您刚刚监督了应用程序新版本的部署。一切看起来都很好，直到用户开始报告间歇性故障。当您意识到问题可能出在部署期间创建和删除的 Pod 时，恐慌就开始了。&lt;/p&gt;&#xA;&lt;p&gt;最初，您疯狂地运行 &lt;code&gt;kubectl get pods --all-namespaces&lt;/code&gt; 来捕获 Pod 状态，但有问题的 Pod 被删除了。然后，您尝试使用 kubectl logs &lt;pod-name&gt; 查找日志，但 Pod 不再存在。绝望之下，您使用 kubectl describe pod 寻找事件，希望能够拼凑出这个谜题。此过程非常耗时且容易出错，从而导致进一步的延误和挫败感。&lt;/p&gt;&#xA;&lt;p&gt;但是使用 Grafana Cloud，您可以获得 &lt;a href=&#34;/docs/grafana-cloud/monitor-infrastruct/kubernetes-monitoring/navigate-k8s-monitoring/?pg=blog&amp;plcmt=body-txt#analyze-historical-data ”开箱即用的历史可见性&lt;/a&gt;。您可以轻松查看那些已删除 Pod 的状态和日志。您不必费力地浏览临时日志，而是可以平静地访问时间线，该时间线准确显示部署出错之前发生的情况。这不仅可以帮助您查明问题，还可以减少停机时间和用户的挫败感。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：2446px；”&#xA;项目专业p =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&#xA;&lt;一&#xA;类=“灯箱链接”&#xA;href=&#34;/media/docs/grafana-cloud/k8s/find-deletd-node.gif&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/docs/grafana-cloud/k8s/find-deletd-node.gif&#34;alt=&#34;在 Kubernetes 监控中分析节点上的“无数据”状态&#34;&#xA;宽度=“2446”&#xA;高度=“1806”&#xA;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/docs/grafana-cloud/k8s/find-deletd-node.gif”&#xA;alt=&#34;在 Kubernetes 监控中分析节点上的“无数据”状态&#34;&#xA;宽度=“2446”&#xA;高度=“1806”&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;/a&gt;&#xA;&lt;/图&gt;&#xA;&lt;p&gt;在其他时候，历史数据对于调试也很有用。例如，也许您正在使用 Azure Kubernetes 服务集群，并且您错误地删除了所有节点，认为集群会自我修复。这会导致所有 pod 都处于挂起状态，没有可用的节点。直接影响是严重的：应用程序不可用、用户请求失败、整体系统稳定性受到损害。然后，您决定升级集群以使其恢复到功能状态。升级集群后，节点重新上线，Pod 从挂起状态变为运行状态。&lt;/p&gt;&#xA;&lt;p&gt;借助 Grafana Cloud 中的 Kubernetes 监控，您可以访问历史可见性，以了解导致问题的事件顺序。您可以看到&lt;a href=&#34;/docs/grafana-cloud/monitor-infrastruct/kubernetes-monitoring/navigate-k8s-monitoring/?pg=blog&amp;plcmt=body-txt#find-deleted-kubernetes-objects&#34;&gt;节点何时被删除&lt;/a&gt;、Pod 的确切状态变化以及系统随时间的响应方式。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1512px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&#xA;&lt;一&#xA;类=“灯箱链接”&#xA;href=&#34;/media/docs/grafana-cloud/k8s/nodata-on-node.gif&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/docs/grafana-cloud/k8s/nodata-on-node.gif&#34;alt=&#34;在 Kubernetes 监控中分析节点上的“无日期”状态”&#xA;宽度=“1512”&#xA;高度=“824”&#xA;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/docs/grafana-cloud/k8s/nodata-on-node.gif”&#xA;alt=&#34;在 Kubernetes 监控中分析节点上的“无日期”状态”&#xA;宽度=“1512”&#xA;高度=“824”&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;/a&gt;&#xA;&lt;/图&gt;&#xA;&lt;p&gt;这些详细的历史数据使您能够快速确定根本原因并采取预防措施，以避免将来出现此类中断。在 Grafana Cloud 中查看整个时间线的能力不仅有助于解决当前问题；它还提供了提高整体系统弹性的见解。&lt;/p&gt;&#xA;&lt;h3 id=&#34;scenario-2-optimizing-resource-usage&#34;&gt;&lt;strong&gt;场景 2：优化资源使用&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;p&gt;解决了部署问题后，您的下一个任务是优化 Kubernetes 节点的资源使用。您已经注意到一些节点一直运行得很热，w而其他的则未得到充分利用。使用 kubectl，您可以使用 &lt;code&gt;kubectl top Nodes&lt;/code&gt; 和 &lt;code&gt;kubectl top pods&lt;/code&gt; 等命令检查当前使用情况。但了解过去的使用趋势需要付出更多努力。&lt;/p&gt;&#xA;&lt;p&gt;要使用 kubectl 实现此目的，您必须：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;设置持久日志记录解决方案以捕获一段时间内的指标。&lt;/li&gt;&#xA;&lt;li&gt;定期手动导出并存储这些指标。&lt;/li&gt;&#xA;&lt;li&gt;精心组合来自不同来源的数据以获得历史视图。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;Grafana Cloud 中的 Kubernetes 监控取代了这个繁琐的过程。 &lt;a href=&#34;/docs/grafana-cloud/monitor-infrastruct/kubernetes-monitoring/optimize-resource-usage/?pg=blog&amp;plcmt=body-txt#discover-usage-over-time&#34;&gt;节点和 pod 上的历史数据资源使用情况&lt;/a&gt;随时可用，使您能够分析趋势并就资源分配做出明智的决策。这种级别的可见性可帮助您优化基础架构，实现更高效、更具成本效益的运营。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1512px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&#xA;&lt;一&#xA;类=“灯箱链接”&#xA;href=&#34;/media/docs/grafana-cloud/k8s/pod-last-30-days.gif&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/docs/grafana-cloud/k8s/pod-last-30-days.gif&#34;alt=&#34;分析 Kubernetes 监控中的过去 30 天&#34;&#xA;宽度=“1512”&#xA;高度=“824”&#xA;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/docs/grafana-cloud/k8s/pod-last-30-days.gif”&#xA;alt=&#34;在 Kubernetes 监控中分析最近 30 天&#34;&#xA;宽度=“1512”&#xA;高度=“824”&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;/a&gt;&#xA;&lt;/图&gt;&#xA;&lt;p&gt;因此，您正处于资源优化任务的中间，您还记得您用来定期导出指标并将其存储以进行历史分析的繁琐的手动方法。但借助 Grafana Cloud，您可以直接查看您的历史数据，因此您可以更快、更准确地做出资源分配决策。&lt;/p&gt;&#xA;&lt;h3 id=&#34;scenario-3-analyzing-past-incidents-for-better-future-planning&#34;&gt;&lt;strong&gt;场景 3：分析过去的事件以更好地规划未来&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;p&gt;就在事情看起来进展顺利时，却发生了严重的停电。作为 SRE，您的工作是分析事件并确保不再发生。您需要回顾 Kubernetes 基础设施在中断之前、期间和之后的状态。&lt;/p&gt;&#xA;&lt;p&gt;如果您要使用 kubectl 来完成此任务，则必须执行一系列步骤，这些步骤提出了我们在本博客中讨论的相同挑战：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;定期手动记录 Pod 和节点的状态。&lt;/li&gt;&#xA;&lt;li&gt;关联不同来源的日志以重建事件顺序。&lt;/li&gt;&#xA;&lt;li&gt;将来自不同工具的数据拼凑起来以获得全面的视图。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;这可能会导致分析不完整并忽视根本原因。对于前例如，假设您发现由于升级后某个特定节点丢失而发生中断，导致严重中断。手动拼凑事件日志和节点状态是很困难的。&lt;/p&gt;&#xA;&lt;p&gt;相反，您可以使用 Grafana Cloud 快速访问历史数据并了解导致中断的事件顺序。通过 Kubernetes 监控，您可以轻松识别事件的模式和根本原因。只需点击几下，您就可以可视化集群随时间的状态、关联指标和=body-txt#view-logs-and-events&#34;&gt;日志&lt;/a&gt;，并得出可操作的见解，转化为更有效的事件分析和更好的未来规划。&lt;/p&gt;&#xA;&lt;h2 id=&#34;start-using-kubernetes-monitoring-today&#34;&gt;立即开始使用 Kubernetes 监控&lt;/h2&gt;&#xA;&lt;p&gt;删除 Kubernetes 中的 Pod 和节点有充分的理由，包括：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;应用更新&lt;/strong&gt;：部署可能需要删除旧 Pod 的新版本应用。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;扩展操作&lt;/strong&gt;：调整 Pod 或节点的数量以处理不同的负载。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;安全问题&lt;/strong&gt;：通过删除受损或过时的 pod 来解决漏洞。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;但正如我们在此所示，如果处理不当，可能会导致严重问题。 Grafana Cloud 中的 Kubernetes 监控将潜在的噩梦变成可管理的任务，使其成为任何 SRE、云基础设施管理员或开发人员的必备工具。如需了解更多信息，请访问 &lt;a href=&#34;/docs/grafana-cloud/monitor-infrastruct/kubernetes-monitoring/?pg=blog&amp;plcmt=body-txt&#34;&gt;Kubernetes 监控文档&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;/products/cloud/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt; 是开始使用指标、日志、跟踪、仪表板等的最简单方法。我们为每个用例提供慷慨的永久免费套餐和计划。&lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;plcmt=body-txt&#34;&gt;立即免费注册&lt;/a&gt; ！&lt;/em&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 08 Aug 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Empowering every user: How Schwarz IT harnesses Grafana Enterprise for their diverse observability needs】赋能每位用户：Schwarz IT 如何利用 Grafana Enterprise 满足其多样化的可观察性需求</title>
      <link>https://grafana.com/blog/2024/08/09/empowering-every-user-how-schwarz-it-harnesses-grafana-enterprise-for-their-diverse-observability-needs/</link>
      <description>【&lt;p&gt;At Schwarz IT, they have a mission statement: deliver the right information to all employees, at the right time, and through the right channels. And to achieve that goal, they use Grafana.&lt;/p&gt;&#xA;&lt;p&gt;“Grafana is an interface for everyone,” says Felix Spitzer, Monitoring Specialist at Schwarz IT, the internal IT service provider for multinational retailer the Schwarz Group. “We have teams that are working closely with Grafana that are very technical, but we also have teams using it that are not technical users. With Grafana, we reach more customers — a bigger variety of users — than ever before.”&lt;/p&gt;&#xA;&lt;p&gt;In fact, this versatility was one of the biggest reasons Schwarz IT chose to implement &lt;a href=&#34;/oss/&#34;&gt;Grafana OSS&lt;/a&gt; in 2014, and then later move to &lt;a href=&#34;/products/enterprise/&#34;&gt;Grafana Enterprise&lt;/a&gt; in 2022. Yes, the team found significant value in being able to centralize and streamline their overall monitoring strategy with Grafana, but the “biggest selling point” for the platform, they say, is its ability to empower such a wide variety of users — both business and technical — to visualize the data that’s most important to them.&lt;/p&gt;&#xA;&lt;p&gt;“Our internal customers know best what they need to see and how to interpret it,” says Michael Dallmann, team lead for Monitoring and Observability Solutions at Schwarz IT. “With Grafana, we provide a tool where the customer can build their own view.”&lt;/p&gt;&#xA;&lt;p&gt;Schwarz IT, headquartered in Germany, is responsible for the IT infrastructure and software solutions that support the various divisions of the Schwarz Group. These include the Lidl and Kaufland food retailers; food production firm Schwarz Produktion; environmental services provider PreZero; and digital innovation firm Schwarz Digits. All in all, Schwarz IT ensures IT operations run smoothly for roughly 575,00 employees across 32 different countries.&lt;/p&gt;&#xA;&lt;p&gt;Today, Grafana Enterprise is used by more than 100 organizations within Schwarz IT. They have more than 6,000 dashboards and close to 1,500 active users. In addition, Schwarz IT supports the open source Grafana instances used by Lidl and Kaufland.&lt;/p&gt;&#xA;&lt;p&gt;But the monitoring team has done so much more than enable users to visualize data in Grafana. With a commitment to knowledge-sharing and dedicated time for innovation (hackathons, anyone?), they’ve fostered an active and thriving Grafana community that today spans nearly all facets of the Schwarz Group.&lt;/p&gt;&#xA;&lt;p&gt;“We don&amp;rsquo;t have a community around other tools like we have with Grafana,” says Spitzer. “I would say a big part of that community is because you can use Grafana in so many different ways.”&lt;/p&gt;&#xA;&lt;p&gt;Grafana Labs recently sat down with Spitzer to talk about the variety of ways Schwarz Group employees use Grafana, how his team has supported such large-scale adoption, and the unique culture and community Schwarz IT has created around the observability platform.&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;Note: The below interview has been edited for brevity and clarity.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;can-you-tell-us-more-about-the-team-youre-on-at-schwarz-it&#34;&gt;Can you tell us more about the team you’re on at Schwarz IT?&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Felix&lt;/strong&gt;: On the monitoring solutions team – we are about 18 people at the moment — we are supporting the Lidl and Kaufland countries, mostly, and the internal IT colleagues when they have monitoring questions. We maintain the monitoring environment. We have different products including Splunk, Dynatrace, our own Open Monitoring Distribution appliance with the NAGIOS fork Naemon, Prometheus, and Grafana, which is a very, very big part of it at the moment. We use Grafana Enterprise to monitor the health of systems, including our network, website and Windows Server.&lt;/p&gt;&#xA;&lt;p&gt;We use Grafana Enterprise as the foundation for all the raw monitoring data we have, and then we provide and administer open source Grafana instances, so other teams can also use it for themselves.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1999px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&#xA;&lt;a&#xA;class=&#34;lightbox-link captioned&#34;&#xA;href=&#34;/media/blog/schwarz-IT-spotlight/schwarz-IT-SPACE-dashboard.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload mb-0&#34;&#xA;data-src=&#34;/media/blog/schwarz-IT-spotlight/schwarz-IT-SPACE-dashboard.png&#34;data-srcset=&#34;/media/blog/schwarz-IT-spotlight/schwarz-IT-SPACE-dashboard.png?w=320 320w, /media/blog/schwarz-IT-spotlight/schwarz-IT-SPACE-dashboard.png?w=550 550w, /media/blog/schwarz-IT-spotlight/schwarz-IT-SPACE-dashboard.png?w=750 750w, /media/blog/schwarz-IT-spotlight/schwarz-IT-SPACE-dashboard.png?w=900 900w, /media/blog/schwarz-IT-spotlight/schwarz-IT-SPACE-dashboard.png?w=1040 1040w, /media/blog/schwarz-IT-spotlight/schwarz-IT-SPACE-dashboard.png?w=1240 1240w, /media/blog/schwarz-IT-spotlight/schwarz-IT-SPACE-dashboard.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A screenshot of the Schwarz IT SPACE Grafana dashboard.&#34;&#xA;width=&#34;1999&#34;&#xA;height=&#34;1061&#34;&#xA;title=&#34;*A Grafana dashboard for Schwarz IT’s end-to-end website monitoring product S.P.A.C.E. (Schwarz Playwright automatic check execution).*&#34;&#xA;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/schwarz-IT-spotlight/schwarz-IT-SPACE-dashboard.png&#34;&#xA;alt=&#34;A screenshot of the Schwarz IT SPACE Grafana dashboard.&#34;&#xA;width=&#34;1999&#34;&#xA;height=&#34;1061&#34;&#xA;title=&#34;*A Grafana dashboard for Schwarz IT’s end-to-end website monitoring product S.P.A.C.E. (Schwarz Playwright automatic check execution).*&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;figcaption class=&#34;w-100p caption text-gray-13 &#34;&gt;&lt;em&gt;A Grafana dashboard for Schwarz IT’s end-to-end website monitoring product S.P.A.C.E. (Schwarz Playwright automatic check execution).&lt;/em&gt;&lt;/figcaption&gt;&#xA;&lt;/a&gt;&#xA;&lt;/figure&gt;&#xA;&lt;h2 id=&#34;what-are-some-of-the-other-grafana-use-cases-you-see-across--schwarz-it-or-the-schwarz-group-more-broadly&#34;&gt;What are some of the other Grafana use cases you see across Schwarz IT or the Schwarz Group, more broadly?&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Felix&lt;/strong&gt;: So, the website teams use Grafana for an overview of JavaScript errors. We also have a team that created their own end-to-end website monitoring program that simulates user input and then uses Grafana as an endpoint to display results related to response time and latency.&lt;/p&gt;&#xA;&lt;p&gt;We have a team using Grafana to track orders and check the resources and warehouses for Lidl food retailers. They have big data in Oracle and MongoDB, and then get the data into Grafana, where they can track, for example, the stock of a product across different stores in the German division.&lt;/p&gt;&#xA;&lt;p&gt;The countries have different use cases because they want to monitor things that are specific to their retail stores.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1999px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&#xA;&lt;a&#xA;class=&#34;lightbox-link captioned&#34;&#xA;href=&#34;/media/blog/schwarz-IT-spotlight/schwarz-IT-IoT-dashboard.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload mb-0&#34;&#xA;data-src=&#34;/media/blog/schwarz-IT-spotlight/schwarz-IT-IoT-dashboard.png&#34;data-srcset=&#34;/media/blog/schwarz-IT-spotlight/schwarz-IT-IoT-dashboard.png?w=320 320w, /media/blog/schwarz-IT-spotlight/schwarz-IT-IoT-dashboard.png?w=550 550w, /media/blog/schwarz-IT-spotlight/schwarz-IT-IoT-dashboard.png?w=750 750w, /media/blog/schwarz-IT-spotlight/schwarz-IT-IoT-dashboard.png?w=900 900w, /media/blog/schwarz-IT-spotlight/schwarz-IT-IoT-dashboard.png?w=1040 1040w, /media/blog/schwarz-IT-spotlight/schwarz-IT-IoT-dashboard.png?w=1240 1240w, /media/blog/schwarz-IT-spotlight/schwarz-IT-IoT-dashboard.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A screenshot of an IoT dashboard in Grafana.&#34;&#xA;width=&#34;1999&#34;&#xA;height=&#34;875&#34;&#xA;title=&#34;*A Grafana dashboard providing an overview of IoT devices, inventory, and the uninterrupted power supply (UPS) for Kaufland stores in Germany.*&#34;&#xA;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/schwarz-IT-spotlight/schwarz-IT-IoT-dashboard.png&#34;&#xA;alt=&#34;A screenshot of an IoT dashboard in Grafana.&#34;&#xA;width=&#34;1999&#34;&#xA;height=&#34;875&#34;&#xA;title=&#34;*A Grafana dashboard providing an overview of IoT devices, inventory, and the uninterrupted power supply (UPS) for Kaufland stores in Germany.*&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;figcaption class=&#34;w-100p caption text-gray-13 &#34;&gt;&lt;em&gt;A Grafana dashboard providing an overview of IoT devices, inventory, and the uninterrupted power supply (UPS) for Kaufland stores in Germany.&lt;/em&gt;&lt;/figcaption&gt;&#xA;&lt;/a&gt;&#xA;&lt;/figure&gt;&#xA;&lt;h2 id=&#34;how-did-you-help-facilitate-grafana-adoption-at-such-large-scale&#34;&gt;How did you help facilitate Grafana adoption at such large scale?&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Felix&lt;/strong&gt;: We started to get specific questions about how to do things in Grafana. Grafana Labs has very good &lt;a href=&#34;/videos/&#34;&gt;webinars and videos&lt;/a&gt; on their site, but they aren’t customized for our environment.&lt;/p&gt;&#xA;&lt;p&gt;So we started our own internal Grafana training. We created this big Teams channel where we share dashboard ideas, the next big thing we’re going to try, success stories — and everyday somebody new would join. We would look for customers using Grafana and ask them about their use case and dashboards, and ask them to share a blog post about it on our Teams channel.&lt;/p&gt;&#xA;&lt;p&gt;We also hold a training session every three to four months. We are doing a basic one and are starting an advanced one this year. But every training is around 100 users. It’s very big, and we need even more.&lt;/p&gt;&#xA;&lt;h2 id=&#34;what-inspired-you-to-host-your-internal-grafana-hackathon-and-what-has-the-impact-been&#34;&gt;What inspired you to host your internal Grafana hackathon and what has the impact been?&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Felix&lt;/strong&gt;: The idea for the first hackathon in March 2023 stemmed from wanting to help drive Grafana use within the countries. In person, you can do little team workshops and be face-to-face — we wanted knowledge transfer. The Schwarz Group is so big and the Lidl countries are like their own companies, so there isn’t much knowledge transfer or communication between them. So we thought, okay, we are like the connection point for them. Let’s create a hackathon.&lt;/p&gt;&#xA;&lt;p&gt;We had an agenda where we showed them our goals. Then we asked about their goals with Grafana and what problems they wanted to solve. We were brainstorming with the different countries, and then we broke off into groups to build a dashboard for their particular problem. Everybody then shared their dashboard and was really excited; people were sharing the JSON because everybody was like, “yeah, I need that.”&lt;/p&gt;&#xA;&lt;p&gt;After the hackathon, we had a very big increase in Grafana usage throughout the countries. In a few weeks, there was an increase of more than 100 dashboards. And that was one of our main goals.&lt;/p&gt;&#xA;&lt;h2 id=&#34;you-use-a-number-of-products-in-your-monitoring-stack-why-focus-only-on-grafana-for-these-hackathons&#34;&gt;You use a number of products in your monitoring stack. Why focus only on Grafana for these hackathons?&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Felix&lt;/strong&gt;: Because you can use Grafana in so many different ways; we are using it as a visualization layer for everything. That’s created this sense of community, and it’s why the hackathons work so well. We’re really trying to push all the data we have to Grafana, making it possible for the end user who’s not technical, and the one who is technical, to use the same interface.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;h3 id=&#34;whats-next-for-schwarz-it&#34;&gt;What’s next for Schwarz IT&lt;/h3&gt;&#xA;&lt;p&gt;Schwarz IT recently held a second Grafana hackathon for their IT hub in Sofia to further expand Grafana usage.&lt;/p&gt;&#xA;&lt;p&gt;“We will also push standard dashboards for the countries to use predefined views and include business process monitoring visualizations,” said Michael Dallman, team lead for Monitoring and Observability Solutions. “For the countries, we will also set up a deep dive for all our monitoring tools, which will include, of course, Grafana.”&lt;/p&gt;&#xA;&lt;/blockquote&gt;】&lt;p&gt;在 Schwarz IT，他们有一个使命宣言：在正确的时间通过正确的渠道向所有员工提供正确的信息。为了实现这一目标，他们使用 Grafana。&lt;/p&gt;&#xA;&lt;p&gt;“Grafana 是适合所有人的界面，”跨国零售商 Schwarz Group 的内部 IT 服务提供商 Schwarz IT 的监控专家 Felix Spitzer 说道。 “我们有一些与 Grafana 密切合作的技术性很强的团队，但我们也有一些使用它的团队不是技术用户。借助 Grafana，我们比以往接触到了更多的客户——更多种类的用户。”&lt;/p&gt;&#xA;&lt;p&gt;事实上，这种多功能性是 Schwarz IT 选择在 2014 年实施 &lt;a href=&#34;/oss/&#34;&gt;Grafana OSS&lt;/a&gt; 并随后转向 &lt;a href=&#34;/products /enterprise/&#34;&gt;Grafana Enterprise&lt;/a&gt; 于 2022 年推出。是的，该团队发现能够通过 Grafana 集中和简化其整体监控策略具有重大价值，但他们表示，该平台的“最大卖点”是它能够让各种各样的用户（包括业务用户和技术用户）可视化对他们来说最重要的数据。&lt;/p&gt;&#xA;&lt;p&gt;“我们的内部客户最了解他们需要看到什么以及如何解释它，”Schwarz IT 监控和可观测性解决方案团队负责人 Michael Dallmann 说道。 “通过 Grafana，我们提供了一个工具，客户可以在其中构建自己的视图。”&lt;/p&gt;&#xA;&lt;p&gt;Schwarz IT 总部位于德国，负责支持 Schwarz 集团各个部门的 IT 基础设施和软件解决方案。其中包括 Lidl 和 Kaufland 食品零售商；食品生产公司 Schwarz Produktion；环境服务提供商PreZero；以及数字创新公司 Schwarz Digits。总而言之，Schwarz IT 确保 32 个不同国家/地区约 575,00 名员工的 IT 运营平稳运行。&lt;/p&gt;&#xA;&lt;p&gt;如今，Grafana Enterprise 已被 Schwarz IT 内的 100 多个组织使用。他们拥有 6,000 多个仪表板和近 1,500 名活跃用户。此外，Schwarz IT 支持 Lidl 和 Kaufland 使用的开源 Grafana 实例。&lt;/p&gt;&#xA;&lt;p&gt;但是监控团队所做的不仅仅是让用户在 Grafana 中可视化数据。通过致力于知识共享和投入创新时间（黑客马拉松，有人吗？），他们培育了一个活跃且蓬勃发展的 Grafana 社区，如今该社区几乎涵盖了 Schwarz Group 的各个方面。&lt;/p&gt;&#xA;&lt;p&gt;“我们没有像 Grafana 那样围绕其他工具建立社区，”Spitzer 说。 “我想说这个社区的一个重要部分是因为你可以通过多种不同的方式使用 Grafana。”&lt;/p&gt;&#xA;&lt;p&gt;Grafana Labs 最近与 Spitzer 坐下来讨论了 Schwarz Group 员工使用 Grafana 的各种方式、他的团队如何支持如此大规模的采用，以及 Schwarz IT 围绕可观察性平台创建的独特文化和社区。&lt; /p&gt;&#xA;&lt;p&gt;&lt;em&gt;注：以下采访已为简洁明了而进行了编辑。&lt;/em&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;can-you-tell-us-more-about-the-team-youre-on-at-schwarz-it&#34;&gt;您能告诉我们更多有关您在 Schwarz IT 团队的信息吗？&lt;/ H2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Felix&lt;/strong&gt;：在监控解决方案团队中，我们目前大约有 18 人，我们主要为 Lidl 和 Kaufland 国家提供支持，并在内部 IT 同事遇到监控问题时提供支持。我们维护监控环境。我们有不同的产品，包括 Splunk、Dynatrace、我们自己的开放式监控分发设备以及 NAGIOS 分支 Naemon、Prometheus 和 Grafana，目前这是其中非常非常重要的一部分。我们使用 Grafana Enterprise 来监控系统的运行状况，包括我们的网络、网站和 Windows Server。&lt;/p&gt;&#xA;&lt;p&gt;我们使用 Grafana Enterprise 作为我们拥有的所有原始监控数据的基础，然后我们提供和管理开源 Grafana 实例，以便其他团队也可以自己使用它。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1999px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&#xA;&lt;一&#xA;类=“灯箱链接标题”&#xA;href=&#34;/media/blog/schwarz-IT-spotlight/schwarz-IT-SPACE-dashboard.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“lazyload mb-0”&#xA;data-src=&#34;/media/blog/schwarz-IT-spotlight/schwarz-IT-SPACE-dashboard.png&#34;data-srcset=&#34;/media/blog/schwarz-IT-spotlight/schwarz-IT-SPACE-仪表板。 png?w=320 320w，/media/blog/schwarz-IT-spotlight/schwarz-IT-SPACE-dashboard.png?w=550 550w，/media/blog/schwarz-IT-spotlight/schwarz-IT-SPACE-仪表板.png?w=750 750w, /media/blog/schwarz-IT-spotlight/schwarz-IT-SPACE-dashboard.png?w=900 900w, /media/blog/schwarz-IT-spotlight/schwarz-IT-空间-dashboard.png?w=1040 1040w，/media/blog/schwarz-IT-spotlight/schwarz-IT-SPACE-dashboard.png?w=1240 1240w，/media/blog/schwarz-IT-spotlight/schwarz- IT-SPACE-dashboard.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;Schwarz IT SPACE Grafana 仪表板的屏幕截图。&#34;&#xA;宽度=“1999”&#xA;高度=“1061”&#xA;title=&#34;*Schwarz IT 端到端网站监控产品 S.P.A.C.E.（Schwarz Playwright 自动检查执行）的 Grafana 仪表板。*&#34;&#xA;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src=&#34;/media/blog/schwarz-IT-spotlight/schwarz-IT-SPACE-dashboard.png&#34;&#xA;alt=&#34;Schwarz IT SPACE Grafana 仪表板的屏幕截图。&#34;&#xA;宽度=“1999”&#xA;高度=“1061”&#xA;title=&#34;*Schwarz IT 端到端网站监控产品 S.P.A.C.E.（Schwarz Playwright 自动检查执行）的 Grafana 仪表板。*&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;figcaption class=&#34;w-100p title text-gray-13 &#34;&gt;&lt;em&gt;用于 Schwarz IT 端到端网站监控产品 S.P.A.C.E. 的 Grafana 仪表板。 （施瓦茨剧作家自动检查执行）。&lt;/em&gt;&lt;/figcaption&gt;&#xA;&lt;/a&gt;&#xA;&lt;/图&gt;&#xA;&lt;h2 id=&#34;what-are-some-of-the-other-grafana-use-cases-you-see-across--schwarz-it-or-the-schwarz-group-more-broadly&#34;&gt;有哪些您在 Schwarz IT 或 Schwarz Group 看到的其他 Grafana 用例，更广泛？&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Felix&lt;/strong&gt;：因此，网站团队使用 Grafana 来概述 JavaScript 错误。我们还有一个团队创建了自己的端到端网站监控程序，该程序模拟用户输入，然后使用 Grafana 作为端点来显示与响应时间和延迟相关的结果。&lt;/p&gt;&#xA;&lt;p&gt;我们有一个团队使用 Grafana 来跟踪 Lidl 食品零售商的订单并检查资源和仓库。他们在 Oracle 和 MongoDB 中拥有大数据，然后将数据输入 Grafana，在那里他们可以跟踪德国分部不同商店中产品的库存等情况。&lt;/p&gt;&#xA;&lt;p&gt;这些国家/地区有不同的用例，因为他们想要监控其零售店特有的事物。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1999px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&#xA;&lt;一&#xA;类=“灯箱链接标题”&#xA;href=&#34;/media/blog/schwarz-IT-spotlight/schwarz-IT-IoT-dashboard.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“lazyload mb-0”&#xA;data-src=&#34;/media/blog/schwarz-IT-spotlight/schwarz-IT-IoT-dashboard.png&#34;data-srcset=&#34;/media/blog/schwarz-IT-spotlight/schwarz-IT-IoT-dashboard. png?w=320 320w，/media/blog/schwarz-IT-spotlight/schwarz-IT-IoT-dashboard.png?w=550 550w，/media/blog/schwarz-IT-spotlight/schwarz-IT-IoT-仪表板.png?w=750 750w，/media/blog/schwarz-IT-spotlight/schwarz-IT-IoT-dashboard.png?w=900 900w，/media/blog/schwarz-IT-spotlight/schwarz-IT- IoT-dashboard.png?w=1040 1040w，/media/blog/schwarz-IT-spotlight/schwarz-IT-IoT-dashboard.png?w=1240 1240w，/media/blog/schwarz-IT-spotlight/schwarz- IT-IoT-dashboard.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;Grafana 中 IoT 仪表板的屏幕截图。&#34;&#xA;宽度=“1999”&#xA;高度=“875”&#xA;title=&#34;*Grafana 仪表板，提供德国 Kaufland 商店的物联网设备、库存和不间断电源 (UPS) 的概述。*&#34;&#xA;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src=&#34;/media/blog/schwarz-IT-spotlight/schwarz-IT-IoT-dashboard.png&#34;&#xA;alt=&#34;Grafana 中 IoT 仪表板的屏幕截图。&#34;&#xA;宽度=“1999”&#xA;高度=“875”&#xA;title=&#34;*Grafana 仪表板，提供德国 Kaufland 商店的物联网设备、库存和不间断电源 (UPS) 的概述。*&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;figcaption class=&#34;w-100p title text-gray-13 &#34;&gt;&lt;em&gt;Grafana 仪表板，提供德国 Kaufland 商店的 IoT 设备、库存和不间断电源 (UPS) 的概览。&lt;/em&gt;&lt; /图标题&gt;&#xA;&lt;/a&gt;&#xA;&lt;/图&gt;&#xA;&lt;h2 id=&#34;how-did-you-help-facilitate-grafana-adoption-at-such-large-scale&#34;&gt;您如何帮助促进 Grafana 如此大规模的采用？&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Felix&lt;/strong&gt;：我们开始收到有关如何在 Grafana 中执行操作的具体问题。 Grafana Labs 的网站上有非常好的&lt;a href=&#34;/videos/&#34;&gt;网络研讨会和视频&lt;/a&gt;，但它们并未针对我们的环境进行定制。&lt;/p&gt;&#xA;&lt;p&gt;因此我们开始了自己的内部 Grafana 培训。我们创建了这个大团队陈我们在其中分享仪表板创意、我们要尝试的下一件大事、成功故事——每天都会有新人加入。我们会寻找使用 Grafana 的客户，询问他们的用例和仪表板，并要求他们在我们的 Teams 频道上分享有关它的博客文章。&lt;/p&gt;&#xA;&lt;p&gt;我们还每三到四个月举办一次培训课程。我们正在做一个基础的，今年将开始一个高级的。但每次培训大约有 100 名用户。它非常大，我们需要更多。&lt;/p&gt;&#xA;&lt;h2 id=&#34;what-inspired-you-to-host-your-internal-grafana-hackathon-and-what-has-the-impact-been&#34;&gt;是什么促使您举办内部 Grafana 黑客马拉松以及产生了什么影响去过吗？&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Felix&lt;/strong&gt;：2023 年 3 月举办首届黑客马拉松的想法源于希望帮助推动 Grafana 在各国的使用。面对面地，你可以举办小型团队研讨会并进行面对面的交流——我们想要知识转移。施瓦茨集团太大了，Lidl国家就像他们自己的公司一样，所以他们之间没有太多的知识转移或交流。所以我们想，好吧，我们就像他们的连接点。让我们创建一个黑客马拉松。&lt;/p&gt;&#xA;&lt;p&gt;我们制定了一个议程，向他们展示了我们的目标。然后我们询问了他们使用 Grafana 的目标以及他们想要解决的问题。我们与不同的国家进行集思广益，然后分成小组，为他们的特定问题构建一个仪表板。然后每个人都分享了他们的仪表板，并且非常兴奋；人们共享 JSON 是因为每个人都说，“是的，我需要它。”&lt;/p&gt;&#xA;&lt;p&gt;黑客马拉松之后，我们在各个国家/地区的 Grafana 使用量有了很大的增长。几周之内，增加了 100 多个仪表板。这是我们的主要目标之一。&lt;/p&gt;&#xA;&lt;h2 id=&#34;you-use-a-number-of-products-in-your-monitoring-stack-why-focus-only-on-grafana-for-these-hackathons&#34;&gt;您在您的监控中使用了多种产品监控堆栈。为什么这些黑客马拉松只关注 Grafana？&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Felix&lt;/strong&gt;：因为您可以通过多种不同方式使用 Grafana；我们将它用作一切的可视化层。这创造了这种社区意识，也是黑客马拉松如此成功的原因。我们确实在努力将所有数据推送到 Grafana，使非技术人员和技术人员都可以使用相同的界面。&lt;/p&gt;&#xA;&lt;块引用&gt;&#xA;&lt;h3 id=&#34;whats-next-for-schwarz-it&#34;&gt;Schwarz IT 的下一步发展&lt;/h3&gt;&#xA;&lt;p&gt;Schwarz IT 最近为其位于索非亚的 IT 中心举办了第二届 Grafana 黑客马拉松，以进一步扩大 Grafana 的使用。&lt;/p&gt;&#xA;&lt;p&gt;“我们还将为各国推出标准仪表板，以使用预定义视图并包括业务流程监控可视化，”监控和可观察性解决方案团队负责人 Michael Dallman 说道。 “对于这些国家，我们还将深入研究我们所有的监控工具，当然包括 Grafana。”&lt;/p&gt;&#xA;&lt;/块q评级&gt;</description>
      <pubDate>Fri, 09 Aug 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Understand your Kubernetes cost drivers and the best ways to rein in spending】了解 Kubernetes 成本驱动因素以及控制支出的最佳方法</title>
      <link>https://grafana.com/blog/2024/07/30/understand-your-kubernetes-cost-drivers-and-the-best-ways-to-rein-in-spending/</link>
      <description>【&lt;p&gt;In the &lt;a href=&#34;/blog/2024/07/29/monitor-these-kubernetes-signals-to-help-rightsize-your-fleet/&#34;&gt;previous blog post&lt;/a&gt; in this two-part series, we discussed the critical signals you need to monitor in your Kubernetes environment to ensure optimal resource provisioning. These signals include high CPU and memory utilization, frequent pod evictions, slow application performance, and other indicators that your resources are over- or under-provisioned. Monitoring these signals is essential for maintaining an efficient, cost-effective, and environmentally sustainable Kubernetes environment.&lt;/p&gt;&#xA;&lt;p&gt;In this post, we&amp;rsquo;ll go a step further by providing actionable information on how to reduce your Kubernetes-related costs. We&amp;rsquo;ll break down what drives these costs, who is responsible for them, and how you can effectively measure and optimize your resource usage. Let&amp;rsquo;s dive in.&lt;/p&gt;&#xA;&lt;h2 id=&#34;what-drives-kubernetes-costs&#34;&gt;What drives Kubernetes costs?&lt;/h2&gt;&#xA;&lt;p&gt;At its core, the cost associated with running a Kubernetes environment can be summarized with the formula:&lt;/p&gt;&#xA;&lt;p&gt;Spend = usage × rate&lt;/p&gt;&#xA;&lt;p&gt;Here, &lt;em&gt;usage&lt;/em&gt; refers to the amount of resources consumed that are either unused or underused. &lt;em&gt;Rate&lt;/em&gt; is the cost per unit of these resources. To manage and reduce costs, you need to focus on both components—reducing unnecessary usage and optimizing the rates you pay for the resources you actually use.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1109px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&#xA;&lt;a&#xA;class=&#34;lightbox-link captioned&#34;&#xA;href=&#34;/media/blog/kubernetes-optimization-series/spend.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload mb-0&#34;&#xA;data-src=&#34;/media/blog/kubernetes-optimization-series/spend.png&#34;data-srcset=&#34;/media/blog/kubernetes-optimization-series/spend.png?w=320 320w, /media/blog/kubernetes-optimization-series/spend.png?w=550 550w, /media/blog/kubernetes-optimization-series/spend.png?w=750 750w, /media/blog/kubernetes-optimization-series/spend.png?w=900 900w, /media/blog/kubernetes-optimization-series/spend.png?w=1040 1040w, /media/blog/kubernetes-optimization-series/spend.png?w=1240 1240w, /media/blog/kubernetes-optimization-series/spend.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;Spend graph in Grafana&#34;&#xA;width=&#34;1109&#34;&#xA;height=&#34;394&#34;&#xA;title=&#34;*A bar chart shows CPU and memory costs tracked in the Kubernetes Monitoring app in Grafana Cloud.*&#34;&#xA;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/kubernetes-optimization-series/spend.png&#34;&#xA;alt=&#34;Spend graph in Grafana&#34;&#xA;width=&#34;1109&#34;&#xA;height=&#34;394&#34;&#xA;title=&#34;*A bar chart shows CPU and memory costs tracked in the Kubernetes Monitoring app in Grafana Cloud.*&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;figcaption class=&#34;w-100p caption text-gray-13 &#34;&gt;&lt;em&gt;A bar chart shows CPU and memory costs tracked in the Kubernetes Monitoring app in Grafana Cloud.&lt;/em&gt;&lt;/figcaption&gt;&#xA;&lt;/a&gt;&#xA;&lt;/figure&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;em&gt;For a deeper discussion on this formula, check out this &lt;a href=&#34;https://www.youtube.com/watch?v=8eiLXtL3oLk&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;KubeCon 2023 talk&lt;/a&gt; by my colleagues Mark Poko and JuanJo Ciarlante.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;Next, let&amp;rsquo;s break down the resources, actions, and users that drive those costs.&lt;/p&gt;&#xA;&lt;h3 id=&#34;resources&#34;&gt;Resources&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Compute resources:&lt;/strong&gt; CPU and memory are primary cost drivers. The more you use, the higher your bill.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Storage:&lt;/strong&gt; Persistent volumes and disk I/O also contribute significantly to costs.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Networking:&lt;/strong&gt; Data transfer costs can add up, especially for applications with high bandwidth requirements.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Managed services:&lt;/strong&gt; If you are using managed Kubernetes services like GKE (Google Kubernetes Engine) or EKS (Amazon Elastic Kubernetes Service), the service fees will be part of your cost structure.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;actions&#34;&gt;Actions&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Over-provisioning:&lt;/strong&gt; Allocating more resources than necessary typically leads to unnecessary spending.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Letting resources sit idle:&lt;/strong&gt; Inactive nodes or persistent volumes can still incur costs.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Not setting request limits:&lt;/strong&gt; Applications can rack up unnecessary costs without appropriate consumption guardrails.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Unchecked scaling:&lt;/strong&gt; Constantly scaling clusters up without properly scaling them down can lead to inefficiencies.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Storage mismanagement:&lt;/strong&gt; Mismanaging storage resources can lead to high costs, especially if you use high-performance storage when you don&amp;rsquo;t need to.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;users&#34;&gt;Users&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;DevOps engineers:&lt;/strong&gt; Responsible for managing the Kubernetes clusters, configuring nodes, and setting up auto scaling.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Developers:&lt;/strong&gt; Write the applications that run on the Kubernetes clusters. Their code and resource requests directly impact usage.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Cloud architects:&lt;/strong&gt; Design the overall cloud infrastructure and strategies for resource utilization.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Finance teams:&lt;/strong&gt; While these individuals don’t affect how large your bill is, they do monitor and manage cloud spending, often pushing for cost optimization strategies.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;lessons-learned-top-cost-saving-tips-from-grafana-labs&#34;&gt;Lessons Learned: top cost-saving tips from Grafana Labs&lt;/h2&gt;&#xA;&lt;p&gt;Now that we&amp;rsquo;ve covered what drives Kubernetes costs, let&amp;rsquo;s look at how you can bring those bills down. Optimization involves continuous learning and improvement, and after years of managing Kubernetes at scale internally, we&amp;rsquo;ve learned a thing or two.&lt;/p&gt;&#xA;&lt;p&gt;Our platform team runs a highly reliable and efficient deployment on Grafana Cloud, our SaaS platform, for customers across the globe. Here are our top three takeaways about operating Kubernetes clusters efficiently.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;1. Regularly monitor and adjust.&lt;/strong&gt; Use tools like &lt;a href=&#34;/oss/prometheus/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Prometheus&lt;/a&gt; and &lt;a href=&#34;/grafana/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana&lt;/a&gt; to keep a close eye on resource utilization. Regularly review and adjust resource requests and limits based on observed usage patterns.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;2. Leverage auto scaling.&lt;/strong&gt; Implement auto scaling tools such as Horizontal Pod Autoscaler (HPA) and Cluster Autoscaler. They help ensure that your cluster scales up and down based on actual demand, preventing over-provisioning and under-utilization.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;3. Optimize resource allocation.&lt;/strong&gt; Remove unnecessary processes, fine-tune application performance, and ensure that resource requests and limits are set appropriately. This step helps in making efficient use of available resources and reduces costs.&lt;/p&gt;&#xA;&lt;h2 id=&#34;monitor-usage-in-order-to-know-where-to-cut&#34;&gt;Monitor usage in order to know where to cut&lt;/h2&gt;&#xA;&lt;p&gt;If you want to properly implement any of these strategies, you need to accurately measure usage so you can adjust accordingly. Here are some of the dimensions to observe to help reduce Kubernetes costs.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1999px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&#xA;&lt;a&#xA;class=&#34;lightbox-link captioned&#34;&#xA;href=&#34;/media/blog/kubernetes-optimization-series/kubernetes-overview.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload mb-0&#34;&#xA;data-src=&#34;/media/blog/kubernetes-optimization-series/kubernetes-overview.png&#34;data-srcset=&#34;/media/blog/kubernetes-optimization-series/kubernetes-overview.png?w=320 320w, /media/blog/kubernetes-optimization-series/kubernetes-overview.png?w=550 550w, /media/blog/kubernetes-optimization-series/kubernetes-overview.png?w=750 750w, /media/blog/kubernetes-optimization-series/kubernetes-overview.png?w=900 900w, /media/blog/kubernetes-optimization-series/kubernetes-overview.png?w=1040 1040w, /media/blog/kubernetes-optimization-series/kubernetes-overview.png?w=1240 1240w, /media/blog/kubernetes-optimization-series/kubernetes-overview.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;Kubernetes overview page in the Kubernetes Monitoring app&#34;&#xA;width=&#34;1999&#34;&#xA;height=&#34;1059&#34;&#xA;title=&#34;*The overview page in the Kubernetes Monitoring app provides a high-level look at your system.*&#34;&#xA;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/kubernetes-optimization-series/kubernetes-overview.png&#34;&#xA;alt=&#34;Kubernetes overview page in the Kubernetes Monitoring app&#34;&#xA;width=&#34;1999&#34;&#xA;height=&#34;1059&#34;&#xA;title=&#34;*The overview page in the Kubernetes Monitoring app provides a high-level look at your system.*&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;figcaption class=&#34;w-100p caption text-gray-13 &#34;&gt;&lt;em&gt;The overview page in the Kubernetes Monitoring app provides a high-level look at your system.&lt;/em&gt;&lt;/figcaption&gt;&#xA;&lt;/a&gt;&#xA;&lt;/figure&gt;&#xA;&lt;p&gt;&lt;strong&gt;Nodes&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;CPU utilization:&lt;/strong&gt; Ensure nodes are not consistently over- or under-utilized.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Memory utilization:&lt;/strong&gt; Monitor memory usage to prevent out-of-memory errors and unnecessary costs.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Disk I/O:&lt;/strong&gt; High disk operations can indicate bottlenecks or inefficient storage usage.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;Workloads&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Application performance metrics:&lt;/strong&gt; Use tools like Prometheus to gather detailed metrics on application performance.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Resource requests and limits:&lt;/strong&gt; Ensure that pods have appropriate resource requests and limits set.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;Idle resources&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Underutilized nodes:&lt;/strong&gt; Nodes that consistently show low utilization should be consolidated or scaled down.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Underutilized nodes:&lt;/strong&gt; Nodes that consistently show low utilization should be consolidated or scaled down.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Persistent volumes:&lt;/strong&gt; Check for unused or underutilized persistent volumes.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;h4 id=&#34;tuning-the-scheduler&#34;&gt;&lt;strong&gt;Tuning the scheduler&lt;/strong&gt;&lt;/h4&gt;&#xA;&lt;p&gt;If you&amp;rsquo;re using AWS or Google Cloud, optimizing the Kubernetes scheduler can help in better resource utilization:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;OPTIMIZE_UTILIZATION&lt;/code&gt; in GKE: GKE offers configurations to optimize resource utilization. Tuning these settings can help reduce costs.&lt;/li&gt;&#xA;&lt;li&gt;Karpenter on AWS: If using AWS, Karpenter is an open source, flexible, high-performance Kubernetes cluster autoscaler that you can use to improve resource efficiency.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h2 id=&#34;implement-grafana-for-monitoring&#34;&gt;Implement Grafana for monitoring&lt;/h2&gt;&#xA;&lt;p&gt;Grafana is a powerful tool for monitoring and visualizing Kubernetes metrics. It integrates well with Prometheus and other data sources, providing a comprehensive view of your cluster’s performance and resource usage.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Set up dashboards:&lt;/strong&gt; Create dashboards to monitor CPU, memory, disk I/O, and network usage.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Leverage OpenCost:&lt;/strong&gt; Gain detailed insights into resource usage and costs, enabling more efficient and cost-effective management of your infrastructure.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Alerting:&lt;/strong&gt; Configure alerts for key metrics to proactively manage resource usage and prevent cost overruns.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Use Kubernetes Monitoring:&lt;/strong&gt; The Kubernetes Monitoring application provides a managed solution for resource utilization visualizations, metrics, and alerts.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;shortcode youtube&#34;&gt;&#xA;&lt;iframe src=&#34;https://www.youtube.com/embed/OpIzdlArRMM?rel=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;With a little bit of practice and the right tools, any team can create actionable strategies for reducing Kubernetes-related costs. And don’t forget, all of the tools you need to monitor and optimize their resource utilization are available in Grafana Cloud’s turnkey &lt;a href=&#34;/solutions/kubernetes/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Kubernetes Monitoring application&lt;/a&gt;. This is the easy path to gain insights quickly, and it’s available on all tiers of Grafana Cloud, including our forever-free tier.&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;/products/cloud/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt; is the easiest way to get started with metrics, logs, traces, dashboards, and more. We have a generous forever-free tier and plans for every use case.&lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt; Sign up for free now&lt;/a&gt;!&lt;/em&gt;&lt;/p&gt;】&lt;p&gt;在&lt;a href=&#34;/blog/2024/07/29/monitor-these-kubernetes-signals-to-help-rightsize-your-fleet/&#34;&gt;上一篇博客文章&lt;/a&gt;中的这两篇文章中 -在系列部分中，我们讨论了您需要在 Kubernetes 环境中监控的关键信号，以确保最佳的资源配置。这些信号包括高 CPU 和内存利用率、频繁的 Pod 驱逐、应用程序性能缓慢以及资源过度配置或配置不足的其他指标。监控这些信号对于维持高效、经济高效且环境可持续的 Kubernetes 环境至关重要。&lt;/p&gt;&#xA;&lt;p&gt;在这篇文章中，我们将进一步提供有关如何降低 Kubernetes 相关成本的可操作信息。我们将详细分析导致这些成本的原因、谁负责这些成本，以及如何有效地衡量和优化资源使用情况。让我们深入探讨一下。&lt;/p&gt;&#xA;&lt;h2 id=&#34;what-drives-kubernetes-costs&#34;&gt;是什么驱动了 Kubernetes 成本？&lt;/h2&gt;&#xA;&lt;p&gt;从本质上讲，与运行 Kubernetes 环境相关的成本可以用以下公式总结：&lt;/p&gt;&#xA;&lt;p&gt;支出=使用量×费率&lt;/p&gt;&#xA;&lt;p&gt;此处，&lt;em&gt;使用&lt;/em&gt;是指未使用或未充分利用的资源消耗量。 &lt;em&gt;费率&lt;/em&gt;是这些资源的每单位成本。为了管理和降低成本，您需要关注这两个组成部分 - 减少不必要的使用并优化为实际使用的资源支付的费率。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1109px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&#xA;&lt;一&#xA;类=“灯箱链接标题”&#xA;href=&#34;/media/blog/kubernetes-optimization-series/spend.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“lazyload mb-0”&#xA;data-src=&#34;/media/blog/kubernetes-optimization-series/spend.png&#34;data-srcset=&#34;/media/blog/kubernetes-optimization-series/spend.png?w=320 320w，/media/blog/ kubernetes-optimization-series/spend.png?w=550 550w，/media/blog/kubernetes-optimization-series/spend.png?w=750 750w，/media/blog/kubernetes-optimization-series/spend.png？ w=900 900w，/media/blog/kubernetes-optimization-series/spend.png？w=1040 1040w，/media/blog/kubernetes-optimization-series/spend.png？w=1240 1240w，/media/blog/ kubernetes-optimization-series/spend.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;Grafana 中的支出图&#34;&#xA;宽度=“1109”&#xA;高度=“394”&#xA;title=&#34;*条形图显示 Grafana Cloud 中 Kubernetes 监控应用程序中跟踪的 CPU 和内存成本。*&#34;&#xA;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/kubernetes-optimization-series/spend.png”&#xA;alt=&#34;Grafana 中的支出图&#34;&#xA;宽度=“1109”&#xA;高度=“394”&#xA;title=&#34;*条形图显示 Grafana Cloud 中 Kubernetes 监控应用程序中跟踪的 CPU 和内存成本。*&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;figcaption class=&#34;w-100p title text-gray-13 &#34;&gt;&lt;em&gt;条形图显示 Grafana Cloud 中 Kubernetes 监控应用中跟踪的 CPU 和内存成本。&lt;/em&gt;&lt;/figcaption&gt;&#xA;&lt;/a&gt;&#xA;&lt;/图&gt;&#xA;&lt;块引用&gt;&#xA;&lt;p&gt;&lt;em&gt;为了更深入有关此公式的讨论，请查看我的 &lt;a href=&#34;https://www.youtube.com/watch?v=8eiLXtL3oLk&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;KubeCon 2023 演讲&lt;/a&gt;同事 Mark Poko 和 JuanJo Ciarlante。&lt;/em&gt;&lt;/p&gt;&#xA;&lt;/块引用&gt;&#xA;&lt;p&gt;接下来，让我们细分导致这些成本的资源、操作和用户。&lt;/p&gt;&#xA;&lt;h3 id=&#34;resources&#34;&gt;资源&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;计算资源&lt;/strong&gt;：CPU 和内存是主要成本驱动因素。您使用的越多，您的账单就越高。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;存储&lt;/strong&gt;：持久卷和磁盘 I/O 也会显着增加成本。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;网络&lt;/strong&gt;：数据传输成本可能会增加，特别是对于带宽要求较高的应用程序。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;托管服务&lt;/strong&gt;：如果您使用 GKE (Google Kubernetes Engine) 或 EKS (Amazon Elastic Kubernetes Service) 等托管 Kubernetes 服务，服务费将成为您成本结构的一部分。&lt;/li &gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;actions&#34;&gt;操作&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;过度配置：&lt;/strong&gt;分配超过必要的资源通常会导致不必要的支出。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;让资源闲置&lt;/strong&gt;：不活动的节点或持久卷仍然会产生成本。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;不设置请求限制&lt;/strong&gt;：如果没有适当的消耗防护措施，应用程序可能会产生不必要的成本。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;未经检查的扩展&lt;/strong&gt;：不断扩展集群而不适当缩小集群可能会导致效率低下。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;存储管理不善&lt;/strong&gt;：存储资源管理不善可能会导致高昂的成本，尤其是在不需要时使用高性能存储的情况下。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;users&#34;&gt;用户&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;DevOps 工程师：&lt;/strong&gt;负责管理 Kubernetes 集群、配置节点和设置自动扩展。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;开发人员&lt;/strong&gt;：编写在 Kubernetes 集群上运行的应用程序。他们的代码和资源请求直接影响使用情况。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;云架构师：&lt;/strong&gt;设计整体云基础设施和资源利用策略。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;财务团队&lt;/strong&gt;：虽然这些人不会影响您的账单金额，但他们会监控和管理云支出，通常会推动成本优化策略。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;lessons-learned-top-cost- saving-tips-from-grafana-labs&#34;&gt;经验教训：Grafana Labs 提供的最佳成本节省技巧&lt;/h2&gt;&#xA;&lt;p&gt;现在我们已经介绍了 Kubernetes 成本的驱动因素，让我们看看如何降低这些费用。优化涉及持续学习和改进，经过多年内部大规模管理 Kubernetes，我们已经学到了一两件事。&lt;/p&gt;&#xA;&lt;p&gt;我们的平台团队在我们的 SaaS 平台 Grafana Cloud 上为全球客户运行高度可靠且高效的部署。以下是我们关于高效运营 Kubernetes 集群的三大要点。&lt;/p&gt;&#xA;&lt;p&gt;&lt;强&gt;1。雷古尔尽早监控和调整。&lt;/strong&gt;使用&lt;a href=&#34;/oss/prometheus/?pg=blog&amp;plcmt=body-txt&#34;&gt;Prometheus&lt;/a&gt;和&lt;a href=&#34;/grafana/?pg=blog&amp;plcmt等工具=body-txt&#34;&gt;Grafana&lt;/a&gt; 密切关注资源利用率。根据观察到的使用模式定期审查和调整资源请求和限制。&lt;/p&gt;&#xA;&lt;p&gt;&lt;强&gt;2。利用自动扩展。&lt;/strong&gt;实施自动扩展工具，例如 Horizo​​ntal Pod Autoscaler (HPA) 和 Cluster Autoscaler。它们有助于确保您的集群根据实际需求进行扩展和缩减，从而防止过度配置和利用率不足。&lt;/p&gt;&#xA;&lt;p&gt;&lt;强&gt;3。优化资源分配。&lt;/strong&gt;删除不必要的进程，微调应用程序性能，并确保正确设置资源请求和限制。此步骤有助于有效利用可用资源并降低成本。&lt;/p&gt;&#xA;&lt;h2 id=&#34;monitor-usage-in-order-to-know-where-to-cut&#34;&gt;监控使用情况以了解在哪里剪切&lt;/h2&gt;&#xA;&lt;p&gt;如果您想正确实施这些策略，则需要准确衡量使用情况，以便进行相应调整。以下是一些需要观察的维度，有助于降低 Kubernetes 成本。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1999px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&#xA;&lt;一&#xA;类=“灯箱链接标题”&#xA;href=&#34;/media/blog/kubernetes-optimization-series/kubernetes-overview.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“lazyload mb-0”&#xA;data-src=&#34;/media/blog/kubernetes-optimization-series/kubernetes-overview.png&#34;data-srcset=&#34;/media/blog/kubernetes-optimization-series/kubernetes-overview.png?w=320 320w, /媒体/博客/kubernetes-optimization-series/kubernetes-overview.png？w=550 550w，/media/blog/kubernetes-optimization-series/kubernetes-overview.png？w=750 750w，/media/blog/kubernetes- optimization-series/kubernetes-overview.png?w=900 900w，/media/blog/kubernetes-optimization-series/kubernetes-overview.png?w=1040 1040w，/media/blog/kubernetes-optimization-series/kubernetes- Overview.png?w=1240 1240w，/media/blog/kubernetes-optimization-series/kubernetes-overview.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;Kubernetes 监控应用程序中的 Kubernetes 概述页面&#34;&#xA;宽度=“1999”&#xA;高度=“1059”&#xA;title=&#34;*Kubernetes 监控应用程序中的概述页面提供了系统的高级视图。*&#34;&#xA;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/kubernetes-optimization-series/kubernetes-overview.png”&#xA;alt=&#34;Kubernetes 监控应用程序中的 Kubernetes 概述页面&#34;&#xA;宽度=“1999”&#xA;高度=“1059”&#xA;title=&#34;*Kubernetes 监控应用程序中的概述页面提供了系统的高级视图。*&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;figcaption class=&#34;w-100p title text-gray-13 &#34;&gt;&lt;em&gt;Kubernetes 监控应用中的概述页面提供了系统的高级视图。&lt;/em&gt;&lt;/figcaption&gt;&#xA;&lt;/a&gt;&#xA;&lt;/图&gt;&#xA;&lt;p&gt;&lt;strong&gt;节点&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;CPU利用率：&lt;/strong&gt;确保节点不一致性略微过度或未充分利用。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;内存利用率：&lt;/strong&gt;监控内存使用情况，以防止内存不足错误和不必要的成本。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;磁盘 I/O&lt;/strong&gt;：磁盘操作过多可能表明存在瓶颈或存储使用效率低下。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;工作负载&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;应用程序性能指标&lt;/strong&gt;：使用 Prometheus 等工具收集有关应用程序性能的详细指标。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;资源请求和限制&lt;/strong&gt;：确保 Pod 设置了适当的资源请求和限制。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;闲置资源&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;未充分利用的节点&lt;/strong&gt;：应整合或缩减始终显示利用率较低的节点。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;未充分利用的节点&lt;/strong&gt;：应整合或缩减始终显示利用率较低的节点。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;持久卷：&lt;/strong&gt;检查未使用或未充分利用的持久卷。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;块引用&gt;&#xA;&lt;h4 id=&#34;tuning-the-scheduler&#34;&gt;&lt;strong&gt;调整调度程序&lt;/strong&gt;&lt;/h4&gt;&#xA;&lt;p&gt;如果您使用 AWS 或 Google Cloud，优化 Kubernetes 调度程序有助于提高资源利用率：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;GKE 中的&lt;code&gt;OPTIMIZE_UTILIZATION&lt;/code&gt;：GKE 提供配置来优化资源利用率。调整这些设置有助于降低成本。&lt;/li&gt;&#xA;&lt;li&gt;AWS 上的 Karpenter：如果使用 AWS，Karpenter 是一个开源、灵活、高性能的 Kubernetes 集群自动扩缩器，您可以用它来提高资源效率。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/块引用&gt;&#xA;&lt;h2 id=&#34;implement-grafana-for-monitoring&#34;&gt;实施 Grafana 进行监控&lt;/h2&gt;&#xA;&lt;p&gt;Grafana 是一个用于监控和可视化 Kubernetes 指标的强大工具。它与 Prometheus 和其他数据源完美集成，提供集群性能和资源使用情况的全面视图。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;设置仪表板&lt;/strong&gt;：创建仪表板来监控 CPU、内存、磁盘 I/O 和网络使用情况。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;利用 OpenCost&lt;/strong&gt;：详细了解资源使用情况和成本，从而更高效、更具成本效益地管理您的基础架构。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;警报&lt;/strong&gt;：为关键指标配置警报，以主动管理资源使用情况并防止成本超支。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;使用 Kubernetes 监控&lt;/strong&gt;：Kubernetes 监控应用程序为资源利用率可视化、指标和警报提供托管解决方案。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;shortcode youtube&#34;&gt;&#xA;&lt;iframe src=&#34;https://www.youtube.com/embed/OpIzdlArRMM?rel=0&#34; style=&#34;位置：绝对；顶部：0；左侧：0；宽度：100%；高度：100%；边框： 0;” allowedfullscreen title=&#34;YouTube 视频&#34;&gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;通过一点实践和正确的工具，任何团队都可以制定可行的策略来降低 Kubernetes 相关成本。不要忘记，监控和优化资源利用率所需的所有工具都可以在 Grafana Cloud 的统包中使用&lt;a href=&#34;/solutions/kubernetes/?pg=blog&amp;plcmt=body-txt&#34;&gt;Kubernetes 监控应用程序&lt;/a&gt;。这是快速获得见解的简单途径，并且在 Grafana Cloud 的所有层级上都可用，包括我们的永久免费层级。&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;/products/cloud/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt; 是开始使用指标、日志、跟踪、仪表板等的最简单方法。我们为每个用例提供慷慨的永久免费套餐和计划。&lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;plcmt=body-txt&#34;&gt;立即免费注册&lt;/a&gt; ！&lt;/em&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 30 Jul 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Monitor these Kubernetes signals to help rightsize your fleet】监控这些 Kubernetes 信号以帮助调整您的车队规模</title>
      <link>https://grafana.com/blog/2024/07/29/monitor-these-kubernetes-signals-to-help-rightsize-your-fleet/</link>
      <description>【&lt;p&gt;Organizations that run Kubernetes clusters in cloud native environments should do so in a way that&amp;rsquo;s both operationally efficient and cost effective. However, many organizations don&amp;rsquo;t prioritize cost optimization until it becomes a pressing need.&lt;/p&gt;&#xA;&lt;p&gt;This may be due to a directive from senior leadership, a significant scale-up or migration of Kubernetes clusters, or an unexpected surge in the cloud bill. Regardless of the reason, the mandate to reduce cloud costs can be sudden and urgent, pushing teams to scrutinize their resource usage meticulously.&lt;/p&gt;&#xA;&lt;p&gt;Beyond just the financial implications, there’s also an environmental impact associated with uncontrolled resource usage. Over-provisioned resources contribute to unnecessary energy consumption and carbon emissions, making it imperative for organizations to optimize not just for cost but for sustainability as well.&lt;/p&gt;&#xA;&lt;p&gt;So, how do we find that optimal balance with our Kubernetes resources? This post will delve into the signals and indicators to watch for, ensuring that your Kubernetes objects are neither starved nor excessively padded.&lt;/p&gt;&#xA;&lt;h2 id=&#34;finding-the-middle-ground-with-kubernetes-provisioning&#34;&gt;Finding the middle ground with Kubernetes provisioning&lt;/h2&gt;&#xA;&lt;p&gt;To properly allocate resources in a Kubernetes environment, you have to carefully monitor your setup and make adjustments based on key indicators. Let&amp;rsquo;s explore the signals that can help us determine whether our Kubernetes resources are over-provisioned or under-provisioned.&lt;/p&gt;&#xA;&lt;h3 id=&#34;indicators-of-under-provisioning&#34;&gt;Indicators of under-provisioning&lt;/h3&gt;&#xA;&lt;h4 id=&#34;high-cpu-or-memory-utilization&#34;&gt;High CPU or memory utilization&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Node level:&lt;/strong&gt; When nodes consistently hit 80% - 90% CPU utilization, it may indicate that the resources are under strain. For some types of workloads—like a non-spiky, non-SLA workload—this would be completely fine. However, this high utilization typically suggests that the nodes are working at or near their capacity, leaving little room for additional workloads or spikes in demand. The same goes for memory resources.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Pod level:&lt;/strong&gt; When pods experience CPU throttling, it can severely impact application performance. CPU throttling occurs when CPU usage and requests begin to overload the pod, causing Kubernetes to restrict the CPU cycles available.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1134px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&#xA;&lt;a&#xA;class=&#34;lightbox-link captioned&#34;&#xA;href=&#34;/media/blog/kubernetes-optimization-series/cpu-usage.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload mb-0&#34;&#xA;data-src=&#34;/media/blog/kubernetes-optimization-series/cpu-usage.png&#34;data-srcset=&#34;/media/blog/kubernetes-optimization-series/cpu-usage.png?w=320 320w, /media/blog/kubernetes-optimization-series/cpu-usage.png?w=550 550w, /media/blog/kubernetes-optimization-series/cpu-usage.png?w=750 750w, /media/blog/kubernetes-optimization-series/cpu-usage.png?w=900 900w, /media/blog/kubernetes-optimization-series/cpu-usage.png?w=1040 1040w, /media/blog/kubernetes-optimization-series/cpu-usage.png?w=1240 1240w, /media/blog/kubernetes-optimization-series/cpu-usage.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;CPU usage dashboard in Grafana&#34;&#xA;width=&#34;1134&#34;&#xA;height=&#34;605&#34;&#xA;title=&#34;*CPU and memory usage times series displayed in the Kubernetes Monitoring app*&#34;&#xA;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/kubernetes-optimization-series/cpu-usage.png&#34;&#xA;alt=&#34;CPU usage dashboard in Grafana&#34;&#xA;width=&#34;1134&#34;&#xA;height=&#34;605&#34;&#xA;title=&#34;*CPU and memory usage times series displayed in the Kubernetes Monitoring app*&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;figcaption class=&#34;w-100p caption text-gray-13 &#34;&gt;&lt;em&gt;CPU and memory usage times series displayed in the Kubernetes Monitoring app&lt;/em&gt;&lt;/figcaption&gt;&#xA;&lt;/a&gt;&#xA;&lt;/figure&gt;&#xA;&lt;h4 id=&#34;high-disk-io&#34;&gt;High disk I/O&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Node level:&lt;/strong&gt; High disk read/write latency is a signal of I/O (input/output) bottlenecks. If nodes are consistently experiencing high disk I/O wait times, it could lead to slower data retrieval and storage operations, impacting the performance of all the pods using local disk resources on that node.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Pod level:&lt;/strong&gt; When pods experience slow disk performance, it can be an indicator of insufficient disk I/O capacity. Applications relying heavily on disk operations will suffer from delays and performance degradation.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;high-network-latency&#34;&gt;High network latency&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Node level:&lt;/strong&gt; Network interfaces showing high packet loss or latency are critical signals of under-provisioned network resources. High network latency can slow down communication between services, affecting overall system performance. (Note that some cloud service providers only make higher bandwidth nodes available through VMs with higher CPU, RAM, and disk resources.)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Pod level:&lt;/strong&gt; Applications experiencing slow network responses suggest that the pods&amp;rsquo; network bandwidth is insufficient. This can lead to poor user experiences and/or SLA violations, especially for applications dependent on real-time data exchange.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;frequent-pod-evictions&#34;&gt;Frequent pod evictions&lt;/h4&gt;&#xA;&lt;p&gt;Pods that are evicted often indicate that the cluster cannot support the resource demands of its workloads, leading to instability and service interruptions.&lt;/p&gt;&#xA;&lt;p&gt;Technically, this is more of an issue of underestimating workload specifications than an under-provisioning problem, with workloads not respecting their specific CPU, memory requests, and limits. Still, it&amp;rsquo;s relevant to what we&amp;rsquo;re discussing here, so it&amp;rsquo;s still worth keeping an eye on.&lt;/p&gt;&#xA;&lt;h4 id=&#34;slow-application-performance&#34;&gt;Slow application performance&lt;/h4&gt;&#xA;&lt;p&gt;Applications showing increased response times or timeout errors typically signal that the resources provided are insufficient to handle the workload. This can lead to poor user experiences and/or SLA violations&lt;/p&gt;&#xA;&lt;h4 id=&#34;failed-deployments-and-restarts&#34;&gt;Failed deployments and restarts&lt;/h4&gt;&#xA;&lt;p&gt;Pods failing to start, or restarting frequently due to insufficient resources, can disrupt the deployment process and reduce application availability. This instability can hinder development cycles and impact business operations.&lt;/p&gt;&#xA;&lt;h4 id=&#34;insufficient-node-capacity&#34;&gt;Insufficient node capacity&lt;/h4&gt;&#xA;&lt;p&gt;Nodes frequently running out of CPU or memory, causing pods to be stuck in a “pending” status, indicate that the cluster lacks the necessary capacity to handle the current workload. This situation can delay new deployments and scale-up/scale-out operations.&lt;/p&gt;&#xA;&lt;h3 id=&#34;indicators-of-over-provisioning&#34;&gt;Indicators of over-provisioning&lt;/h3&gt;&#xA;&lt;h4 id=&#34;low-cpu-or-memory-utilization&#34;&gt;Low CPU or memory utilization&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Node level:&lt;/strong&gt; Nodes consistently below 20% - 30% CPU utilization suggest that they are over-provisioned. This underutilization means that you are paying for more CPU capacity than needed, leading to wasted resources and higher costs. Likewise for memory resources.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Pod level:&lt;/strong&gt; Pods using a small fraction of their allocated CPU also indicate over-provisioning. Allocating more CPU than required can lead to inefficient use of resources and unnecessary expenditure.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;low-disk-io&#34;&gt;Low disk I/O&lt;/h4&gt;&#xA;&lt;p&gt;Low disk read/write operations indicate underutilization of disk resources. This scenario suggests that while you may have sufficient disk capacity, your IOPS are not fully utilized. This can lead to inefficient resource usage and potentially higher costs due to the tiered pricing models of cloud providers.&lt;/p&gt;&#xA;&lt;h4 id=&#34;low-network-utilization&#34;&gt;Low network utilization&lt;/h4&gt;&#xA;&lt;p&gt;Network interfaces showing low bandwidth usage indicate over-provisioned network resources. This underutilization suggests that you are paying for more network capacity than required, leading to unnecessary costs.&lt;/p&gt;&#xA;&lt;h4 id=&#34;high-cost-without-proportional-usage&#34;&gt;High cost without proportional usage&lt;/h4&gt;&#xA;&lt;p&gt;If your cloud costs are higher than your workload demands, it suggests inefficiency. If your cloud bills are high, but the resource utilization is low, it’s a clear sign that you are over-provisioning.&lt;/p&gt;&#xA;&lt;h4 id=&#34;unused-or-idle-resources&#34;&gt;Unused or idle resources&lt;/h4&gt;&#xA;&lt;p&gt;Unused capacity in cluster nodes, persistent volumes, IP addresses, or other resources remaining unused indicate over-provisioning. Unused and idle resources still incur costs, contributing to higher cloud bills without any operational benefit.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1999px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&#xA;&lt;a&#xA;class=&#34;lightbox-link captioned&#34;&#xA;href=&#34;/media/blog/kubernetes-optimization-series/navigation.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload mb-0&#34;&#xA;data-src=&#34;/media/blog/kubernetes-optimization-series/navigation.png&#34;data-srcset=&#34;/media/blog/kubernetes-optimization-series/navigation.png?w=320 320w, /media/blog/kubernetes-optimization-series/navigation.png?w=550 550w, /media/blog/kubernetes-optimization-series/navigation.png?w=750 750w, /media/blog/kubernetes-optimization-series/navigation.png?w=900 900w, /media/blog/kubernetes-optimization-series/navigation.png?w=1040 1040w, /media/blog/kubernetes-optimization-series/navigation.png?w=1240 1240w, /media/blog/kubernetes-optimization-series/navigation.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;Navigation menu in Grafana&#34;&#xA;width=&#34;1999&#34;&#xA;height=&#34;1034&#34;&#xA;title=&#34;*Idle resources displayed in the Kubernetes Monitoring app*&#34;&#xA;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/kubernetes-optimization-series/navigation.png&#34;&#xA;alt=&#34;Navigation menu in Grafana&#34;&#xA;width=&#34;1999&#34;&#xA;height=&#34;1034&#34;&#xA;title=&#34;*Idle resources displayed in the Kubernetes Monitoring app*&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;figcaption class=&#34;w-100p caption text-gray-13 &#34;&gt;&lt;em&gt;Idle resources displayed in the Kubernetes Monitoring app&lt;/em&gt;&lt;/figcaption&gt;&#xA;&lt;/a&gt;&#xA;&lt;/figure&gt;&#xA;&lt;h2 id=&#34;best-practices-for-rightsizing-your-fleet&#34;&gt;Best practices for rightsizing your fleet&lt;/h2&gt;&#xA;&lt;p&gt;To strike the right balance between under and over-provisioning, regular monitoring and adjustment of resource allocations are essential. Here are some best practices to help you optimize your Kubernetes environment.&lt;/p&gt;&#xA;&lt;h3 id=&#34;regular-monitoring&#34;&gt;Regular monitoring&lt;/h3&gt;&#xA;&lt;p&gt;Use tools like Prometheus and Grafana to monitor resource usage. They provide valuable insights into your Kubernetes cluster&amp;rsquo;s performance and resource utilization, helping you identify areas of inefficiency and make informed decisions about resource allocation. Or, use Grafana Cloud’s &lt;a href=&#34;/solutions/kubernetes/&#34;&gt;Kubernetes Monitoring application&lt;/a&gt; for turnkey resource monitoring.&lt;/p&gt;&#xA;&lt;div class=&#34;shortcode youtube&#34;&gt;&#xA;&lt;iframe src=&#34;https://www.youtube.com/embed/OpIzdlArRMM?rel=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&#xA;&lt;h3 id=&#34;autoscaling&#34;&gt;Autoscaling&lt;/h3&gt;&#xA;&lt;p&gt;Implement Horizontal Pod Autoscaler (HPA), Vertical Pod Autoscaler (VPA), and Cluster Autoscaler (CA) to automatically scale resources based on demand. Autoscaling ensures that your cluster can dynamically adjust to workload changes, maintaining optimal resource utilization.&lt;/p&gt;&#xA;&lt;h3 id=&#34;resource-quotas-and-limits&#34;&gt;Resource quotas and limits&lt;/h3&gt;&#xA;&lt;p&gt;Set appropriate resource requests and limits for your pods to avoid over- or under-allocation. Defining these limits is critical to ensure that resources are used efficiently and that applications have the necessary capacity to perform well.&lt;/p&gt;&#xA;&lt;h3 id=&#34;continuously-optimize-workloads&#34;&gt;Continuously optimize workloads&lt;/h3&gt;&#xA;&lt;p&gt;Analyze workloads to optimize resource allocation and understand workloads’ resource utilization, remove unnecessary processes, and improve application performance. Optimizing workloads over time will lead to better resource utilization and cost savings.&lt;/p&gt;&#xA;&lt;h2 id=&#34;whats-next&#34;&gt;What&amp;rsquo;s next&lt;/h2&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1999px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&#xA;&lt;a&#xA;class=&#34;lightbox-link captioned&#34;&#xA;href=&#34;/media/blog/kubernetes-optimization-series/cluster-panels.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload mb-0&#34;&#xA;data-src=&#34;/media/blog/kubernetes-optimization-series/cluster-panels.png&#34;data-srcset=&#34;/media/blog/kubernetes-optimization-series/cluster-panels.png?w=320 320w, /media/blog/kubernetes-optimization-series/cluster-panels.png?w=550 550w, /media/blog/kubernetes-optimization-series/cluster-panels.png?w=750 750w, /media/blog/kubernetes-optimization-series/cluster-panels.png?w=900 900w, /media/blog/kubernetes-optimization-series/cluster-panels.png?w=1040 1040w, /media/blog/kubernetes-optimization-series/cluster-panels.png?w=1240 1240w, /media/blog/kubernetes-optimization-series/cluster-panels.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;Cluster panels&#34;&#xA;width=&#34;1999&#34;&#xA;height=&#34;1034&#34;&#xA;title=&#34;*Cluster-level data displayed in the Kubernetes Monitoring app*&#34;&#xA;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/kubernetes-optimization-series/cluster-panels.png&#34;&#xA;alt=&#34;Cluster panels&#34;&#xA;width=&#34;1999&#34;&#xA;height=&#34;1034&#34;&#xA;title=&#34;*Cluster-level data displayed in the Kubernetes Monitoring app*&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;figcaption class=&#34;w-100p caption text-gray-13 &#34;&gt;&lt;em&gt;Cluster-level data displayed in the Kubernetes Monitoring app&lt;/em&gt;&lt;/figcaption&gt;&#xA;&lt;/a&gt;&#xA;&lt;/figure&gt;&#xA;&lt;p&gt;By keeping a close eye on the signals of under- and over-provisioning and making informed adjustments, you can reach a happy state in your Kubernetes environment that is both cost-effective and environmentally sustainable. To quickly stand up Kubernetes observability and resource monitoring, try out&lt;a href=&#34;/solutions/kubernetes/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt; Kubernetes Monitoring in Grafana Cloud&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;And check out the &lt;a href=&#34;/blog/2024/07/30/understand-your-kubernetes-cost-drivers-and-the-best-ways-to-rein-in-spending/&#34;&gt;second part of this series&lt;/a&gt;, where we&amp;rsquo;ll help you achieve even greater efficiency and cost savings in your Kubernetes clusters.&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;/products/cloud/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Cloud &lt;/a&gt;is the easiest way to get started with metrics, logs, traces, dashboards, and more. We have a generous forever-free tier and plans for every use case. &lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Sign up for free now!&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;】&lt;p&gt;在云原生环境中运行 Kubernetes 集群的组织应该以既高效运营又具有成本效益的方式运行。然而，许多组织并没有优先考虑成本优化，直到它成为迫切需要。&lt;/p&gt;&#xA;&lt;p&gt;这可能是由于高层领导的指示、Kubernetes 集群的大幅扩展或迁移，或者云账单的意外激增。无论出于何种原因，降低云成本的任务可能是突然而紧急的，迫使团队仔细审查其资源使用情况。&lt;/p&gt;&#xA;&lt;p&gt;除了财务影响之外，不受控制的资源使用还会对环境产生影响。过度配置的资源会导致不必要的能源消耗和碳排放，因此组织不仅必须优化成本，还要优化可持续性。&lt;/p&gt;&#xA;&lt;p&gt;那么，我们如何找到 Kubernetes 资源的最佳平衡呢？这篇文章将深入研究需要观察的信号和指标，确保您的 Kubernetes 对象既不会匮乏，也不会过度填充。&lt;/p&gt;&#xA;&lt;h2 id=&#34;finding-the-middle-ground-with-kubernetes-provisioning&#34;&gt;通过 Kubernetes 配置找到中间立场&lt;/h2&gt;&#xA;&lt;p&gt;要在 Kubernetes 环境中正确分配资源，您必须仔细监控您的设置并根据关键指标进行调整。让我们探讨一下可以帮助我们确定 Kubernetes 资源是否过度配置或配置不足的信号。&lt;/p&gt;&#xA;&lt;h3 id=&#34;indicators-of-under-provisioning&#34;&gt;配置不足的指标&lt;/h3&gt;&#xA;&lt;h4 id=&#34;high-cpu-or-memory-utilization&#34;&gt;CPU 或内存利用率高&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;节点级别&lt;/strong&gt;：当节点的 CPU 利用率持续达到 80% - 90% 时，可能表明资源紧张。对于某些类型的工作负载（例如非尖峰、非 SLA 工作负载），这完全没问题。然而，这种高利用率通常表明节点正在以其容量或接近其容量工作，为额外工作负载或需求峰值留下的空间很小。内存资源也是如此。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Pod 级别&lt;/strong&gt;：当 Pod 遇到 CPU 限制时，可能会严重影响应用程序性能。当 CPU 使用率和请求开始使 Pod 过载时，就会发生 CPU 限制，导致 Kubernetes 限制可用的 CPU 周期。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1134px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&#xA;&lt;一&#xA;类=“灯箱链接标题”&#xA;href=&#34;/media/blog/kubernetes-optimization-series/cpu-usage.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“lazyload mb-0”&#xA;data-src=&#34;/media/blog/kubernetes-optimization-series/cpu-usage.png&#34;data-srcset=&#34;/media/blog/kubernetes-optimization-series/cpu-usage.png?w=320 320w,/媒体/博客/kubernetes-optimization-series/cpu-usage.png?w=550 550w,/媒体/博客/kubernetes-optimization-series/cpu-usage.png？w=750 750w，/media/blog/kubernetes-optimization-series/cpu-usage.png？w=900 900w，/media/blog/kubernetes- optimization-series/cpu-usage.png?w=1040 1040w，/media/blog/kubernetes-optimization-series/cpu-usage.png?w=1240 1240w，/media/blog/kubernetes-optimization-series/cpu-用法.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;Grafana 中的 CPU 使用情况仪表板&#34;&#xA;宽度=“1134”&#xA;高度=“605”&#xA;title=&#34;*Kubernetes 监控应用程序中显示的 CPU 和内存使用时间序列*&#34;&#xA;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/kubernetes-optimization-series/cpu-usage.png”&#xA;alt=&#34;Grafana 中的 CPU 使用情况仪表板&#34;&#xA;宽度=“1134”&#xA;高度=“605”&#xA;title=&#34;*Kubernetes 监控应用程序中显示的 CPU 和内存使用时间序列*&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;figcaption class=&#34;w-100p title text-gray-13 &#34;&gt;&lt;em&gt;Kubernetes 监控应用中显示的 CPU 和内存使用时间序列&lt;/em&gt;&lt;/figcaption&gt;&#xA;&lt;/a&gt;&#xA;&lt;/图&gt;&#xA;&lt;h4 id=&#34;high-disk-io&#34;&gt;高磁盘 I/O&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;节点级别：&lt;/strong&gt;高磁盘读/写延迟是 I/O（输入/输出）瓶颈的信号。如果节点持续经历较长的磁盘 I/O 等待时间，可能会导致数据检索和存储操作变慢，从而影响该节点上使用本地磁盘资源的所有 Pod 的性能。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Pod 级别：&lt;/strong&gt;当 Pod 遇到磁盘性能缓慢时，可能表明磁盘 I/O 容量不足。严重依赖磁盘操作的应用程序将遭受延迟和性能下降的影响。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;high-network-latency&#34;&gt;网络延迟较高&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;节点级别&lt;/strong&gt;：网络接口出现高数据包丢失或延迟是网络资源配置不足的关键信号。高网络延迟会减慢服务之间的通信速度，从而影响整体系统性能。 （请注意，某些云服务提供商仅通过具有更高 CPU、RAM 和磁盘资源的虚拟机提供更高带宽的节点。）&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Pod 级别&lt;/strong&gt;：应用程序网络响应缓慢表明 Pod 的网络带宽不足。这可能会导致糟糕的用户体验和/或违反 SLA，尤其是对于依赖实时数据交换的应用程序。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;frequent-pod-evictions&#34;&gt;频繁的 Pod 驱逐&lt;/h4&gt;&#xA;&lt;p&gt;被驱逐的 Pod 通常表明集群无法支持其工作负载的资源需求，从而导致不稳定和服务中断。&lt;/p&gt;&#xA;&lt;p&gt;从技术上讲，这更多的是低估工作负载规格的问题，而不是配置不足的问题，即工作负载不尊重其特定的 CPU、内存请求和限制。不过，它与我们在这里讨论的内容相关，因此仍然值得关注。&lt;/p&gt;&#xA;&lt;h4 id=&#34;slow-application-performance&#34;&gt;应用程序性能缓慢&lt;/h4&gt;&#xA;&lt;p&gt;显示响应时间增加或超时错误的应用程序通常表明资源提供的 ces 不足以处理工作量。这可能会导致糟糕的用户体验和/或违反 SLA&lt;/p&gt;&#xA;&lt;h4 id=&#34;failed-deployments-and-restarts&#34;&gt;部署和重启失败&lt;/h4&gt;&#xA;&lt;p&gt;Pod 无法启动或由于资源不足而频繁重新启动可能会中断部署过程并降低应用程序可用性。这种不稳定性会阻碍开发周期并影响业务运营。&lt;/p&gt;&#xA;&lt;h4 id=&#34;insufficient-node-capacity&#34;&gt;节点容量不足&lt;/h4&gt;&#xA;&lt;p&gt;节点频繁耗尽 CPU 或内存，导致 Pod 陷入“待处理”状态，表明集群缺乏处理当前工作负载所需的能力。这种情况可能会延迟新的部署和扩展/扩展操作。&lt;/p&gt;&#xA;&lt;h3 id=&#34;indicators-of-over-provisioning&#34;&gt;过度配置指标&lt;/h3&gt;&#xA;&lt;h4 id=&#34;low-cpu-or-memory-utilization&#34;&gt;CPU 或内存利用率低&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;节点级别&lt;/strong&gt;：CPU 利用率持续低于 20% - 30% 的节点表明它们存在过度配置。这种未充分利用意味着您要为超出所需的 CPU 容量付费，从而导致资源浪费和成本上升。内存资源也是如此。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Pod 级别&lt;/strong&gt;：Pod 使用其分配的 CPU 的一小部分也表明存在过度配置。分配超过所需的 CPU 可能会导致资源使用效率低下和不必要的支出。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;low-disk-io&#34;&gt;低磁盘 I/O&lt;/h4&gt;&#xA;&lt;p&gt;低磁盘读/写操作表明磁盘资源未充分利用。这种情况表明，虽然您可能有足够的磁盘容量，但您的 IOPS 并未得到充分利用。由于云提供商的分层定价模型，这可能会导致资源使用效率低下，并可能导致更高的成本。&lt;/p&gt;&#xA;&lt;h4 id=&#34;low-network-utilization&#34;&gt;网络利用率低&lt;/h4&gt;&#xA;&lt;p&gt;显示低带宽使用率的网络接口表明网络资源过度配置。这种未充分利用的情况表明您为超出所需的网络容量支付了费用，从而导致不必要的成本。&lt;/p&gt;&#xA;&lt;h4 id=&#34;high-cost-without-proportional-usage&#34;&gt;成本高但不按比例使用&lt;/h4&gt;&#xA;&lt;p&gt;如果您的云成本高于工作负载需求，则表明效率低下。如果您的云费用很高，但资源利用率很低，则明确表明您存在过度配置。&lt;/p&gt;&#xA;&lt;h4 id=&#34;unused-or-idle-resources&#34;&gt;未使用或空闲的资源&lt;/h4&gt;&#xA;&lt;p&gt;集群节点中未使用的容量、持久卷、IP 地址或其他未使用的资源表示过度配置。未使用和闲置的资源仍然会产生成本，从而导致更高的云费用，而没有任何运营效益。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1999px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&#xA;&lt;一&#xA;类=“灯箱链接标题”&#xA;href=&#34;/media/blog/kubernetes-optimization-series/navigation.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“lazyload mb-0”&#xA;data-src=&#34;/media/blog/kubernetes-optimization-series/navigation.png&#34;data-srcset=&#34;/media/blog/kubernetes-optimization-series/navigation.png?w=320 320w，/media/blog/ kubernetes-optimization-series/navigation.png?w=550 550w，/media/blog/kubernetes-optimization-series/navigation.png?w=750 750w，/media/blog/kubernetes-optimization-series/navigation.png？ w=900 900w，/media/blog/kubernetes-optimization-series/navigation.png？w=1040 1040w，/media/blog/kubernetes-optimization-series/navigation.png？w=1240 1240w，/media/blog/ kubernetes-optimization-series/navigation.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;Grafana 中的导航菜单&#34;&#xA;宽度=“1999”&#xA;高度=“1034”&#xA;title=&#34;*Kubernetes 监控应用中显示的空闲资源*&#34;&#xA;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/kubernetes-optimization-series/navigation.png”&#xA;alt=&#34;Grafana 中的导航菜单&#34;&#xA;宽度=“1999”&#xA;高度=“1034”&#xA;title=&#34;*Kubernetes 监控应用中显示的空闲资源*&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;figcaption class=&#34;w-100p title text-gray-13 &#34;&gt;&lt;em&gt;Kubernetes 监控应用中显示的空闲资源&lt;/em&gt;&lt;/figcaption&gt;&#xA;&lt;/a&gt;&#xA;&lt;/图&gt;&#xA;&lt;h2 id=&#34;best-practices-for-rightsizing-your-fleet&#34;&gt;调整车队规模的最佳实践&lt;/h2&gt;&#xA;&lt;p&gt;为了在供应不足和供应过剩之间取得适当的平衡，定期监测和调整资源分配至关重要。以下是一些可帮助您优化 Kubernetes 环境的最佳实践。&lt;/p&gt;&#xA;&lt;h3 id=&#34;regular-monitoring&#34;&gt;定期监控&lt;/h3&gt;&#xA;&lt;p&gt;使用 Prometheus 和 Grafana 等工具来监控资源使用情况。它们提供有关 Kubernetes 集群的性能和资源利用率的宝贵见解，帮助您识别效率低下的领域并就资源分配做出明智的决策。或者，使用 Grafana Cloud 的 &lt;a href=&#34;/solutions/kubernetes/&#34;&gt;Kubernetes 监控应用程序&lt;/a&gt; 进行交钥匙资源监控。&lt;/p&gt;&#xA;&lt;div class=&#34;shortcode youtube&#34;&gt;&#xA;&lt;iframe src=&#34;https://www.youtube.com/embed/OpIzdlArRMM?rel=0&#34; style=&#34;位置：绝对；顶部：0；左侧：0；宽度：100%；高度：100%；边框： 0;” allowedfullscreen title=&#34;YouTube 视频&#34;&gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&#xA;&lt;h3 id=&#34;autoscaling&#34;&gt;自动缩放&lt;/h3&gt;&#xA;&lt;p&gt;实施 Horizo​​ntal Pod Autoscaler (HPA)、Vertical Pod Autoscaler (VPA) 和 Cluster Autoscaler (CA)，以根据需求自动扩展资源。自动缩放可确保您的集群可以动态调整以适应工作负载变化，从而保持最佳的资源利用率。&lt;/p&gt;&#xA;&lt;h3 id=&#34;resource-quotas-and-limits&#34;&gt;资源配额和限制&lt;/h3&gt;&#xA;&lt;p&gt;为 Pod 设置适当的资源请求和限制，以避免分配过度或不足。定义这些限制对于确保资源得到有效利用以及应用程序具有良好运行所需的能力至关重要。&lt;/p&gt;&#xA;&lt;h3 id=&#34;continuously-optimize-workloads&#34;&gt;持续优化工作负载&lt;/h3&gt;&#xA;&lt;p&gt;分析工作负载以优化资源分配并了解工作负载的资源利用率，删除不必要的进程，并提高应用程序性能。随着时间的推移优化工作负载将提高资源利用率并节省成本。&lt;/p&gt;&#xA;&lt;h2 id=&#34;whats-next&#34;&gt;下一步是什么&lt;/h2&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1999px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&#xA;&lt;一&#xA;类=“灯箱链接标题”&#xA;href=&#34;/media/blog/kubernetes-optimization-series/cluster-panels.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“lazyload mb-0”&#xA;data-src =“/media/blog/kubernetes-optimization-series/cluster-panels.png”data-srcset =“/media/blog/kubernetes-optimization-series/cluster-panels.png？w = 320 320w，/媒体/博客/kubernetes-optimization-series/cluster-panels.png？w=550 550w，/media/blog/kubernetes-optimization-series/cluster-panels.png？w=750 750w，/media/blog/kubernetes- optimization-series/cluster-panels.png?w=900 900w，/media/blog/kubernetes-optimization-series/cluster-panels.png?w=1040 1040w，/media/blog/kubernetes-optimization-series/cluster- panel.png?w=1240 1240w，/media/blog/kubernetes-optimization-series/cluster-panels.png?w=1920 1920w&#34;&#xA;data-size=&#34;auto&#34;alt=&#34;集群面板&#34;&#xA;宽度=“1999”&#xA;高度=“1034”&#xA;title=&#34;*Kubernetes 监控应用中显示的集群级数据*&#34;&#xA;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/kubernetes-optimization-series/cluster-panels.png”&#xA;alt=&#34;集群面板&#34;&#xA;宽度=“1999”&#xA;高度=“1034”&#xA;title=&#34;*Kubernetes 监控应用中显示的集群级数据*&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;figcaption class=&#34;w-100p title text-gray-13 &#34;&gt;&lt;em&gt;Kubernetes 监控应用中显示的集群级数据&lt;/em&gt;&lt;/figcaption&gt;&#xA;&lt;/a&gt;&#xA;&lt;/图&gt;&#xA;&lt;p&gt;通过密切关注配置不足和过度配置的信号并进行明智的调整，您可以在 Kubernetes 环境中达到既经济高效又环境可持续的良好状态。要快速建立 Kubernetes 可观察性和资源监控，请尝试&lt;a href=&#34;/solutions/kubernetes/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana Cloud 中的 Kubernetes 监控&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;并查看&lt;a href=&#34;/blog/2024/07/30/understand-your-kubernetes-cost-drivers-and-the-best-ways-to-rein-in-spending/&#34;&gt;第二个这是本系列的一部分&lt;/a&gt;，我们将帮助您在 Kubernetes 集群中实现更高的效率并节省成本。&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;/products/cloud/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt;是开始使用指标、日志、跟踪、仪表板等的最简单方法。我们为每个用例提供慷慨的永久免费套餐和计划。 &lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;plcmt=body-txt&#34;&gt;立即免费注册！&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 29 Jul 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【An overview of Grafana SSO: Benefits, recent updates, and best practices to get started】Grafana SSO 概述：优点、最新更新和入门最佳实践</title>
      <link>https://grafana.com/blog/2024/07/31/an-overview-of-grafana-sso-benefits-recent-updates-and-best-practices-to-get-started/</link>
      <description>【&lt;p&gt;Grafana began as an open and composable platform for data visualization. Today, Grafana has evolved into an all-in-one observability platform, providing everything from infrastructure and application performance monitoring to load testing and incident response.&lt;/p&gt;&#xA;&lt;p&gt;As organizations extend their use of Grafana, efficient and secure authentication and authorization is essential. Fortunately, Grafana provides multiple ways to authenticate users, including&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;/docs/grafana/latest/setup-grafana/configure-security/configure-authentication/ldap/&#34;&gt;Lightweight Directory Access Protocol (LDAP) authentication&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;/docs/grafana/latest/setup-grafana/configure-security/configure-authentication/grafana/#basic-authentication&#34;&gt;Basic authentication&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;/docs/grafana/latest/setup-grafana/configure-security/configure-authentication/jwt/&#34;&gt;JSON Web Token (JWT) authentication&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;/docs/grafana/latest/setup-grafana/configure-security/configure-authentication/&#34;&gt;Single sign-on (SSO)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;In this post, we&amp;rsquo;ll provide an overview of Grafana SSO, including how it compares to other authentication methods, its benefits, and recent updates that make it easier to configure SSO in your environment.&lt;/p&gt;&#xA;&lt;h2 id=&#34;a-comparison-of-authentication-methods&#34;&gt;A comparison of authentication methods&lt;/h2&gt;&#xA;&lt;p&gt;Before we dive into the details of SSO, specifically, let&amp;rsquo;s compare the supported authentication methods in Grafana. &lt;em&gt;Note: For more information on which methods are supported in Grafana OSS, Grafana Cloud, and Grafana Enterprise, please refer to &lt;a href=&#34;/docs/grafana/latest/setup-grafana/configure-security/configure-authentication/&#34;&gt;our technical documentation&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;table&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;&lt;strong&gt;Method&lt;/strong&gt;&#xA;&lt;/td&gt;&#xA;&lt;td&gt;&lt;strong&gt;LDAP&lt;/strong&gt;&#xA;&lt;/td&gt;&#xA;&lt;td&gt;&lt;strong&gt;Basic authentication&lt;/strong&gt;&#xA;&lt;/td&gt;&#xA;&lt;td&gt;&lt;strong&gt;JWT authentication&lt;/strong&gt;&#xA;&lt;/td&gt;&#xA;&lt;td&gt;&lt;strong&gt;Single sign-on (SSO)&lt;/strong&gt;&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Description&#xA;&lt;/td&gt;&#xA;&lt;td&gt;Allows users to login with their LDAP credentials&#xA;&lt;/td&gt;&#xA;&lt;td&gt;Uses username and password stored locally&#xA;&lt;/td&gt;&#xA;&lt;td&gt;Uses JSON Web Tokens for stateless authentication. Allows Grafana to accept a JWT token provided in the HTTP header.&#xA;&lt;/td&gt;&#xA;&lt;td&gt;Allows for the use of a centralized identity management provider, using OAuth and SAML in Grafana. Built-in support for multiple known identity providers (IdPs), as well as support for setting up Generic OAuth.&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Security level&#xA;&lt;/td&gt;&#xA;&lt;td&gt;High (centralized and managed externally)&#xA;&lt;/td&gt;&#xA;&lt;td&gt;Low (depends on password strength, user input)&#xA;&lt;/td&gt;&#xA;&lt;td&gt;Moderate (in certain configurations can lead to the token being exposed – for example, in logs – which leaves room for hijacking)&#xA;&lt;/td&gt;&#xA;&lt;td&gt;High (centralized and managed by the IdP, and allows for the implementation of multi-factor authentication on the IdP side)&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;User management&#xA;&lt;/td&gt;&#xA;&lt;td&gt;Centralized (managed in LDAP directory)&#xA;&lt;/td&gt;&#xA;&lt;td&gt;Local (managed within Grafana)&#xA;&lt;/td&gt;&#xA;&lt;td&gt;Distributed (tokens issued by third-party trusted provider)&#xA;&lt;/td&gt;&#xA;&lt;td&gt;Centralized (managed by the IdP)&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Ease of setup&#xA;&lt;/td&gt;&#xA;&lt;td&gt;Moderate (requires LDAP server and configuration)&#xA;&lt;/td&gt;&#xA;&lt;td&gt;Easy (built-in, minimal setup)&#xA;&lt;/td&gt;&#xA;&lt;td&gt;Moderate (requires token generation, validation, and ensuring security)&#xA;&lt;/td&gt;&#xA;&lt;td&gt;Moderate to high (depends on the IdP and protocol used)&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Scalability&#xA;&lt;/td&gt;&#xA;&lt;td&gt;High (suitable for large organizations)&#xA;&lt;/td&gt;&#xA;&lt;td&gt;Low (best for smaller setups, or testing)&#xA;&lt;/td&gt;&#xA;&lt;td&gt;High (scales well with stateless tokens)&#xA;&lt;/td&gt;&#xA;&lt;td&gt;High (ideal for large organizations with multiple services)&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/table&gt;&#xA;&lt;p&gt;Additionally, you can configure Grafana to use &lt;a href=&#34;/docs/grafana/latest/setup-grafana/configure-security/configure-authentication/#anonymous-authentication&#34;&gt;Anonymous authentication&lt;/a&gt;, which allows users to access Grafana without requiring any login.&lt;/p&gt;&#xA;&lt;p&gt;Ultimately, your choice of authentication type depends on your organization’s unique requirements. Most of these authentication methods also allow you to sync user permissions from external providers to Grafana and, therefore, easily control access. While this is beyond the scope of this blog post, you can read more in &lt;a href=&#34;/docs/grafana/latest/setup-grafana/configure-security/configure-authentication/&#34;&gt;our technical documentation&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;why-use-sso-with-grafana&#34;&gt;Why use SSO with Grafana?&lt;/h2&gt;&#xA;&lt;p&gt;While SSO might not be applicable to all types of organizations and users, it comes with several advantages compared to other forms of authentication, including:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Enhanced security and better compliance&lt;/strong&gt;: Centralized authentication reduces the risk of compromised credentials. It makes it easier to enforce policies and maintain audit trails, and also scales really well.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Better user experience&lt;/strong&gt;: Users can access Grafana resources without needing to log in separately (aka, no password fatigue), and administrators can manage user access and permissions from a centralized place (for example, their IdP).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;whats-new-in-grafana-sso-configuration&#34;&gt;What&amp;rsquo;s new in Grafana SSO configuration?&lt;/h2&gt;&#xA;&lt;p&gt;Historically, configuring SSO in Grafana required updating static configuration files and restarting the Grafana instance for the changes to take effect. This process could be cumbersome and disruptive.&lt;/p&gt;&#xA;&lt;p&gt;With the Grafana 10 release, we &lt;a href=&#34;/blog/2023/07/27/new-in-grafana-10-a-ui-to-easily-configure-saml-authentication/&#34;&gt;introduced a new UI to easily configure SAML authentication&lt;/a&gt;. Thanks to feedback from our community, we decided to streamline the entire SSO setup process and introduced the following updates, starting with &lt;a href=&#34;/blog/2024/04/09/grafana-11-release-all-the-new-features/&#34;&gt;Grafana 11&lt;/a&gt;:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;UI configuration&lt;/strong&gt;: Configure SSO directly through the Grafana user interface.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;API support&lt;/strong&gt;: Automate SSO setup and management using Grafana&amp;rsquo;s API. &lt;a href=&#34;/docs/grafana/latest/developers/http_api/sso-settings/&#34;&gt;Refer to the documentation&lt;/a&gt; for more information.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Terraform integration&lt;/strong&gt;: Manage SSO configurations as code with Terraform support. &lt;a href=&#34;https://registry.terraform.io/providers/grafana/grafana/latest/docs/resources/sso_settings&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Refer to the documentation&lt;/a&gt; for more information.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;configuration-files-vs-the-uiapi&#34;&gt;Configuration files vs. the UI/API&lt;/h3&gt;&#xA;&lt;p&gt;Configuring SSO through Grafana configuration files is still supported and might be applicable in certain scenarios, including when there’s limited infrastructure automation. That said, using the UI or API instead of configuration files has the following advantages:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Available in Grafana Cloud&lt;/strong&gt;: Set up SSO inside of your Grafana Cloud instance without needing to file a support request.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Real-time configuration validation&lt;/strong&gt;: When using the UI or API, all settings are validated in real time, providing immediate feedback on the validity of the configuration.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;No need to restart Grafana&lt;/strong&gt;: Using the UI or API eliminates the need to restart Grafana after making changes.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;RBAC authorization&lt;/strong&gt;: You have the flexibility to authorize specific users to access the UI or API by using role-based access control (RBAC).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;It is not recommended to mix configuration methods (for example, to define some fields in a config file and some through the API). If, for some reason, configuration has to be done using both options, Grafana will follow a specific precedence order when loading the configuration:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Settings that were configured using the UI/API, or Terraform.&lt;/li&gt;&#xA;&lt;li&gt;Settings from environment variables.&lt;/li&gt;&#xA;&lt;li&gt;Settings from the Grafana configuration file.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;exploring-the-authentication-user-interface&#34;&gt;Exploring the Authentication user interface&lt;/h2&gt;&#xA;&lt;p&gt;To access the UI in Grafana or Grafana Cloud, navigate to &lt;strong&gt;Administration &amp;gt; Authentication&lt;/strong&gt; in the navigation menu of your Grafana instance.&lt;/p&gt;&#xA;&lt;p&gt;Please note that in order to access this page, a user must have the &lt;em&gt;settings:read&lt;/em&gt; and &lt;em&gt;settings:write&lt;/em&gt; permissions. By using the *settings:auth.{provider}:** scope with appropriate providers, you can control access by indicating which specific providers a user can set up.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img&#xA;class=&#34;lazyload d-inline-block&#34;&#xA;data-src=&#34;/media/blog/grafana-SSO-overview/grafana-SSO-authentication-settings.png&#34;&#xA;alt=&#34;A screenshot of the authentication settings page. &#34; width=&#34;1882&#34;&#xA;height=&#34;1248&#34;/&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;best-practices-to-set-up-sso&#34;&gt;Best practices to set up SSO&lt;/h2&gt;&#xA;&lt;p&gt;Setting up SSO requires knowledge of both identity providers and Grafana. With hundreds of identity providers available, offering built-in support for all of them is not feasible. This is why Grafana supports a Generic OAuth configuration, which can be used to set up SSO with any identity provider that supports OAuth 2.0.&lt;/p&gt;&#xA;&lt;p&gt;Here are a few generic guidelines to follow when setting up SSO in Grafana:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Understand your identity provider&lt;/strong&gt;: Each IdP has specific requirements and quirks, so consult their documentation thoroughly before moving forward.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Configure redirect Uniform Resource Identifier (URIs) correctly&lt;/strong&gt;: Make sure the redirect URIs configured in your IdP match exactly with those specified in Grafana. Incorrect URIs can cause authentication failures.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Avoid using Generic OAuth if your provider is supported by Grafana&lt;/strong&gt;. If you are using Azure Active Directory, Okta, Google, GitHub or GitLab, use the appropriate configuration for them and avoid Generic OAuth. This approach simplifies setup and is less error-prone. Additionally, configuration is much more fine-grained, as certain functionality won’t be available with Generic OAuth.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;When using OAuth, configure &lt;em&gt;allowed_domains, allowed_groups&lt;/em&gt; or &lt;em&gt;allowed_organizations&lt;/em&gt;&lt;/strong&gt;: This will reduce the attack surface for user accounts and create defense in depth (DiD) in case authentication is bypassed.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Enable &lt;em&gt;use_pkce=true&lt;/em&gt; for OAuth integrations:&lt;/strong&gt; &lt;a href=&#34;https://auth0.com/docs/get-started/authentication-and-authorization-flow/authorization-code-flow-with-pkce&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Proof Key for Code Exchange (PKCE)&lt;/a&gt; is an important addition to OAuth and it might be obligatory in future versions of the protocol. Enable it from the start to avoid breakage on IdP updates (it’s been enabled by default since Grafana 10.1).&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Use request signing when setting up SAML&lt;/strong&gt;: Request signing is a critical security feature in SAML that enhances the overall security of the authentication process. It ensures SAML requests are genuine, unaltered, and originate from a trusted service provider, thereby protecting the system from various threats and ensuring compliance with security standards.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Set up auto login&lt;/strong&gt;: Available for OAuth and SAML, this will improve the user experience.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;troubleshooting-sso-setup&#34;&gt;Troubleshooting SSO setup&lt;/h2&gt;&#xA;&lt;p&gt;Setting up SSO requires configuration in multiple places, and sometimes, it doesn’t work out the first time. Being prepared and having the right tools for debugging can streamline the process.&lt;/p&gt;&#xA;&lt;h3 id=&#34;be-familiar-with-identity-protocols&#34;&gt;Be familiar with identity protocols&lt;/h3&gt;&#xA;&lt;p&gt;Most of the authentication protocols involve browser redirects and HTTP requests/responses between several components, so troubleshooting will be easier if you are familiar with the expected sequence of interaction for a particular scenario. Specifically, it will be helpful to know:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The parameters expected by each protocol endpoint&lt;/li&gt;&#xA;&lt;li&gt;The responses and error codes returned by each endpoint&lt;/li&gt;&#xA;&lt;li&gt;The identity provider APIs&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;have-the-right-tools&#34;&gt;Have the right tools&lt;/h3&gt;&#xA;&lt;p&gt;Tools to capture and view &lt;strong&gt;HTTP traces&lt;/strong&gt; are especially helpful to troubleshoot during SSO setup. Most internet browsers offer dev tools with built-in capabilities to capture an HTTP trace in the &amp;ldquo;Network&amp;rdquo; tab. It is also convenient to be able to dump the HTTP trace to an HTTP Archive format (.har file), which will capture everything, including the cleartext value of any secret.&lt;/p&gt;&#xA;&lt;p&gt;Other examples of tools for SSO debugging and troubleshooting include:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postman.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Postman&lt;/a&gt; or &lt;a href=&#34;https://insomnia.rest/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Insomnia&lt;/a&gt; to test API calls&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://docs.telerik.com/fiddler/configure-fiddler/tasks/configurefiddler&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Fiddler&lt;/a&gt; or &lt;a href=&#34;https://www.charlesproxy.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Charlesproxy&lt;/a&gt; to capture and view network traces of backend API calls&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://jwt.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;https://jwt.io/&lt;/a&gt; to view and create JWTs&lt;/li&gt;&#xA;&lt;li&gt;SAML-tracer, available for &lt;a href=&#34;https://addons.mozilla.org/en-US/firefox/addon/saml-tracer/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Firefox&lt;/a&gt; and &lt;a href=&#34;https://chromewebstore.google.com/detail/saml-tracer/mpdajninpobndbfcldcmbpnnbhibjmch?hl=en&amp;amp;pli=1&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Chrome&lt;/a&gt;, to inspect SAML requests&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;know-these-debugging-basics&#34;&gt;Know these debugging basics&lt;/h3&gt;&#xA;&lt;p&gt;When something is not working as expected, especially when it comes to authentication, it’s best to start checking the simple things. For example:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Check that the identity provider is accessible and not experiencing any issues&lt;/li&gt;&#xA;&lt;li&gt;Ensure the supplied credentials are correct for the environment&lt;/li&gt;&#xA;&lt;li&gt;Check that the login account and credentials are not disabled or expired&lt;/li&gt;&#xA;&lt;li&gt;Make sure Grafana is using the correct URL for the identity provider&lt;/li&gt;&#xA;&lt;li&gt;Verify the client ID matches the one registered in identity provider&lt;/li&gt;&#xA;&lt;li&gt;Check the redirect/callback URL&lt;/li&gt;&#xA;&lt;li&gt;Read all error messages to see if they provide valuable clues&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;whats-next&#34;&gt;What’s next?&lt;/h2&gt;&#xA;&lt;p&gt;We hope the recent updates we’ve made related to the UI, API, and Terraform enhance your experience with Grafana and simplify the SSO setup process. Looking ahead, we plan to introduce a new UI and API for configuring LDAP, which will make authentication setup even easier.&lt;/p&gt;&#xA;&lt;p&gt;In the meantime, if you want to learn more about how to organize your users and teams in Grafana to ensure optimal security, please refer to &lt;a href=&#34;/blog/2022/03/14/how-to-best-organize-your-teams-and-resources-in-grafana/&#34;&gt;this blog post&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;/products/cloud/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt; is the easiest way to get started with metrics, logs, traces, dashboards, and more. We have a generous forever-free tier and plans for every use case. &lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Sign up for free now&lt;/a&gt;!&lt;/em&gt;&lt;/p&gt;】&lt;p&gt;Grafana 最初是一个开放且可组合的数据可视化平台。如今，Grafana 已发展成为一个一体化的可观测平台，提供从基础设施和应用程序性能监控到负载测试和事件响应的一切功能。&lt;/p&gt;&#xA;&lt;p&gt;随着组织扩展 Grafana 的使用，高效、安全的身份验证和授权至关重要。幸运的是，Grafana 提供了多种对用户进行身份验证的方法，包括&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;/docs/grafana/latest/setup-grafana/configure-security/configure-authentication/ldap/&#34;&gt;轻量级目录访问协议 (LDAP) 身份验证&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;/docs/grafana/latest/setup-grafana/configure-security/configure-authentication/grafana/#basic-authentication&#34;&gt;基本身份验证&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;/docs/grafana/latest/setup-grafana/configure-security/configure-authentication/jwt/&#34;&gt;JSON Web 令牌 (JWT) 身份验证&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;/docs/grafana/latest/setup-grafana/configure-security/configure-authentication/&#34;&gt;单点登录 (SSO)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;在这篇文章中，我们将概述 Grafana SSO，包括它与其他身份验证方法的比较、其优点以及使您可以更轻松地在环境中配置 SSO 的最新更新。&lt;/p&gt;&#xA;&lt;h2 id=&#34;a-comparison-of-authentication-methods&#34;&gt;身份验证方法比较&lt;/h2&gt;&#xA;&lt;p&gt;在我们深入了解 SSO 的详细信息之前，具体来说，让我们比较一下 Grafana 中支持的身份验证方法。 &lt;em&gt;注意：有关 Grafana OSS、Grafana Cloud 和 Grafana Enterprise 支持哪些方法的更多信息，请参阅 &lt;a href=&#34;/docs/grafana/latest/setup-grafana/configure-security/configure-authentication /&#34;&gt;我们的技术文档&lt;/a&gt;。&lt;/em&gt;&lt;/p&gt;&#xA;&lt;表&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;&lt;strong&gt;方法&lt;/strong&gt;&#xA;&lt;/td&gt;&#xA;&lt;td&gt;&lt;strong&gt;LDAP&lt;/strong&gt;&#xA;&lt;/td&gt;&#xA;&lt;td&gt;&lt;strong&gt;基本身份验证&lt;/strong&gt;&#xA;&lt;/td&gt;&#xA;&lt;td&gt;&lt;strong&gt;JWT 身份验证&lt;/strong&gt;&#xA;&lt;/td&gt;&#xA;&lt;td&gt;&lt;strong&gt;单点登录 (SSO)&lt;/strong&gt;&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;描述&#xA;&lt;/td&gt;&#xA;&lt;td&gt;允许用户使用其 LDAP 凭据登录&#xA;&lt;/td&gt;&#xA;&lt;td&gt;使用本地存储的用户名和密码&#xA;&lt;/td&gt;&#xA;&lt;td&gt;使用 JSON Web 令牌进行无状态身份验证。允许 Grafana 接受 HTTP 标头中提供的 JWT 令牌。&#xA;&lt;/td&gt;&#xA;&lt;td&gt;允许使用集中式身份管理提供程序，在 Grafana 中使用 OAuth 和 SAML。对多个已知身份提供商 (IdP) 的内置支持，以及对设置通用 OAuth 的支持。&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;安全级别&#xA;&lt;/td&gt;&#xA;&lt;td&gt;高（集中且外部管理）&#xA;&lt;/td&gt;&#xA;&lt;td&gt;低（取决于密码强度、用户输入）&#xA;&lt;/td&gt;&#xA;&lt;td&gt;中等（在某些配置中可能会导致令牌被暴露——例如，在日志中——这为劫持留下了空间）&#xA;&lt;/td&gt;&#xA;&lt;td&gt;高（由IdP集中管理，并允许在IdP端实施多重身份验证）&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;用户管理&#xA;&lt;/td&gt;&#xA;&lt;td&gt;集中式（在 LDAP 目录中管理）&#xA;&lt;/td&gt;&#xA;&lt;td&gt;洛卡l（在 Grafana 内管理）&#xA;&lt;/td&gt;&#xA;&lt;td&gt;分布式（由第三方可信提供商发行的令牌）&#xA;&lt;/td&gt;&#xA;&lt;td&gt;集中式（由 IdP 管理）&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;易于设置&#xA;&lt;/td&gt;&#xA;&lt;td&gt;中等（需要 LDAP 服务器和配置）&#xA;&lt;/td&gt;&#xA;&lt;td&gt;简单（内置，最少设置）&#xA;&lt;/td&gt;&#xA;&lt;td&gt;中等（需要令牌生成、验证并确保安全）&#xA;&lt;/td&gt;&#xA;&lt;td&gt;中到高（取决于所使用的 IdP 和协议）&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;可扩展性&#xA;&lt;/td&gt;&#xA;&lt;td&gt;高（适合大型组织）&#xA;&lt;/td&gt;&#xA;&lt;td&gt;低（最适合较小的设置或测试）&#xA;&lt;/td&gt;&#xA;&lt;td&gt;高（可与无状态令牌很好地扩展）&#xA;&lt;/td&gt;&#xA;&lt;td&gt;高（非常适合拥有多种服务的大型组织）&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/表&gt;&#xA;&lt;p&gt;此外，您可以将 Grafana 配置为使用&lt;a href=&#34;/docs/grafana/latest/setup-grafana/configure-security/configure-authentication/#anonymous-authentication&#34;&gt;匿名身份验证&lt;/a&gt;，这允许用户无需任何登录即可访问 Grafana。&lt;/p&gt;&#xA;&lt;p&gt;最终，您选择的身份验证类型取决于您组织的独特要求。大多数身份验证方法还允许您将用户权限从外部提供商同步到 Grafana，因此可以轻松控制访问。虽然这超出了本博文的范围，但您可以在&lt;a href=&#34;/docs/grafana/latest/setup-grafana/configure-security/configure-authentication/&#34;&gt;我们的技术文档&lt;/a&gt;中阅读更多内容。 &lt;/p&gt;&#xA;&lt;h2 id=&#34;why-use-sso-with-grafana&#34;&gt;为什么将 SSO 与 Grafana 结合使用？&lt;/h2&gt;&#xA;&lt;p&gt;虽然 SSO 可能不适用于所有类型的组织和用户，但与其他形式的身份验证相比，它具有多种优势，包括：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;增强安全性和更好的合规性&lt;/strong&gt;：集中身份验证可降低凭据泄露的风险。它使执行策略和维护审计跟踪变得更加容易，而且扩展性也非常好。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;更好的用户体验&lt;/strong&gt;：用户无需单独登录即可访问 Grafana 资源（也称为无密码疲劳），管理员可以从集中位置管理用户访问和权限（例如，他们的IdP）。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;whats-new-in-grafana-sso-configuration&#34;&gt;Grafana SSO 配置有哪些新增功能？&lt;/h2&gt;&#xA;&lt;p&gt;从历史上看，在 Grafana 中配置 SSO 需要更新静态配置文件并重新启动 Grafana 实例才能使更改生效。这个过程可能很麻烦并且具有破坏性。&lt;/p&gt;&#xA;&lt;p&gt;在 Grafana 10 版本中，我们&lt;a href=&#34;/blog/2023/07/27/new-in-grafana-10-a-ui-to-easily-configure-saml-authentication/&#34;&gt;引入了新的 UI 可轻松配置 SAML 身份验证&lt;/a&gt;。感谢社区的反馈，我们决定简化整个 SSO 设置流程，并引入了以下更新，从 &lt;a href=&#34;/blog/2024/04/09/grafana-11-release-all-the-new-功能/&#34;&gt;Grafana 11&lt;/a&gt;：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;UI 配置&lt;/strong&gt;：直接通过 Grafana 用户界面配置 SSO。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;API 支持&lt;/strong&gt;：使用 Grafana 的 API 自动化 SSO 设置和管理。 &lt;a href=&#34;/docs/grafana/latest/developers/http_api/sso-settings/&#34;&gt;请参阅文档&lt;/a&gt;了解更多信息。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Terraform 集成&lt;/strong&gt;：通过 Terraform 支持将 SSO 配置作为代码进行管理。 &lt;a href=&#34;https://registry.terraform.io/providers/grafana/grafana/latest/docs/resources/sso_settings&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;请参阅文档&lt;/a&gt;更多信息。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;configuration-files-vs-the-uiapi&#34;&gt;配置文件与 UI/API&lt;/h3&gt;&#xA;&lt;p&gt;仍然支持通过 Grafana 配置文件配置 SSO，并且可能适用于某些场景，包括基础设施自动化有限的情况。也就是说，使用 UI 或 API 代替配置文件具有以下优点：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;在 Grafana Cloud 中提供&lt;/strong&gt;：在 Grafana Cloud 实例内设置 SSO，无需提交支持请求。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;实时配置验证&lt;/strong&gt;：使用 UI 或 API 时，所有设置都会实时验证，从而提供有关配置有效性的即时反馈。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;无需重新启动 Grafana&lt;/strong&gt;：使用 UI 或 API 无需在进行更改后重新启动 Grafana。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;RBAC 授权&lt;/strong&gt;：您可以使用基于角色的访问控制 (RBAC) 灵活地授权特定用户访问 UI 或 API。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;不建议混合配置方法（例如，在配置文件中定义一些字段，而通过 API 定义一些字段）。如果由于某种原因必须使用这两个选项来完成配置，Grafana 在加载配置时将遵循特定的优先顺序：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;使用 UI/API 或 Terraform 配置的设置。&lt;/li&gt;&#xA;&lt;li&gt;来自环境变量的设置。&lt;/li&gt;&#xA;&lt;li&gt;Grafana 配置文件中的设置。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;exploring-the-authentication-user-interface&#34;&gt;探索身份验证用户界面&lt;/h2&gt;&#xA;&lt;p&gt;要访问 Grafana 或 Grafana Cloud 中的 UI，请导航至 Grafana 实例的导航菜单中的&lt;strong&gt;管理 &gt; 身份验证&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;p&gt;请注意，要访问此页面，用户必须具有&lt;em&gt;settings:read&lt;/em&gt;和&lt;em&gt;settings:write&lt;/em&gt;权限。通过将 *settings:auth.{provider}:** 范围与适当的提供程序结合使用，您可以通过指示用户可以设置哪些特定提供程序来控制访问。&lt;/p&gt;&#xA;&lt;p&gt;&lt;图片&#xA;类=“lazyload d-inline-block”&#xA;data-src=&#34;/media/blog/grafana-SSO-overview/grafana-SSO-authentication-settings.png&#34;&#xA;alt=&#34;身份验证设置页面的屏幕截图。&#34; width=&#34;1882&#34;&#xA;高度=“1248”/&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;best-practices-to-set-up-sso&#34;&gt;设置 SSO 的最佳实践&lt;/h2&gt;&#xA;&lt;p&gt;设置 SSO 需要了解身份提供商和 Grafana。拥有数百个可用的身份提供商，提供内置为所有这些国家提供支持是不可行的。这就是 Grafana 支持通用 OAuth 配置的原因，该配置可用于与任何支持 OAuth 2.0 的身份提供商设置 SSO。&lt;/p&gt;&#xA;&lt;p&gt;以下是在 Grafana 中设置 SSO 时需要遵循的一些通用准则：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;了解您的身份提供商&lt;/strong&gt;：每个 IdP 都有特定的要求和怪癖，因此在继续操作之前请彻底查阅他们的文档。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;正确配置重定向统一资源标识符 (URI)&lt;/strong&gt;：确保 IdP 中配置的重定向 URI 与 Grafana 中指定的重定向 URI 完全匹配。不正确的 URI 可能会导致身份验证失败。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;如果 Grafana 支持您的提供商，请避免使用通用 OAuth&lt;/strong&gt;。如果您使用的是 Azure Active Directory、Okta、Google、GitHub 或 GitLab，请为它们使用适当的配置并避免通用 OAuth。这种方法简化了设置并且不易出错。此外，配置更加细粒度，因为通用 OAuth 无法使用某些功能。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;使用 OAuth 时，配置&lt;em&gt;allowed_domains、allowed_groups&lt;/em&gt; 或&lt;em&gt;allowed_organizations&lt;/em&gt;&lt;/strong&gt;：这将减少用户帐户的攻击面并创建深度防御（ DiD）以防身份验证被绕过。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;为 OAuth 集成启用 &lt;em&gt;use_pkce=true&lt;/em&gt;：&lt;/strong&gt; &lt;a href=&#34;https://auth0.com/docs/get-started/authentication-and-authorization- flow/authorization-code-flow-with-pkce&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;代码交换证明密钥 (PKCE)&lt;/a&gt; 是 OAuth 的重要补充，在未来版本中可能是强制性的协议的。从一开始就启用它，以避免 IdP 更新中断（自 Grafana 10.1 起默认启用）。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;设置 SAML 时使用请求签名&lt;/strong&gt;：请求签名是 SAML 中的一项关键安全功能，可增强身份验证过程的整体安全性。它确保 SAML 请求是真实的、未更改的，并且来自受信任的服务提供商，从而保护系统免受各种威胁并确保符合安全标准。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;设置自动登录&lt;/strong&gt;：适用于 OAuth 和 SAML，这将改善用户体验。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;troubleshooting-sso-setup&#34;&gt;SSO 设置问题排查&lt;/h2&gt;&#xA;&lt;p&gt;设置 SSO 需要在多个位置进行配置，有时，第一次可能无法成功。做好准备并拥有正确的调试工具可以简化流程。&lt;/p&gt;&#xA;&lt;h3 id=&#34;be-familiar-with-identity-protocols&#34;&gt;熟悉身份协议&lt;/h3&gt;&#xA;&lt;p&gt;大多数身份验证协议都涉及多个组件之间的浏览器重定向和 HTTP 请求/响应，因此如果您熟悉特定场景的预期交互顺序，故障排除将会更容易。具体来说，了解以下内容会很有帮助：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;李&gt;每个协议端点期望的参数&lt;/li&gt;&#xA;&lt;li&gt;每个端点返回的响应和错误代码&lt;/li&gt;&#xA;&lt;li&gt;身份提供商 API&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;have-the-right-tools&#34;&gt;拥有合适的工具&lt;/h3&gt;&#xA;&lt;p&gt;用于捕获和查看&lt;strong&gt;HTTP 跟踪&lt;/strong&gt;的工具对于在 SSO 设置期间进行故障排除特别有帮助。大多数互联网浏览器提供的开发工具具有内置功能，可以在“网络”选项卡中捕获 HTTP 跟踪。能够将 HTTP 跟踪转储为 HTTP 存档格式（.har 文件）也很方便，这将捕获所有内容，包括任何秘密的明文值。&lt;/p&gt;&#xA;&lt;p&gt;用于 SSO 调试和故障排除的工具的其他示例包括：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.postman.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Postman&lt;/a&gt; 或 &lt;a href=&#34;https://insomnia.rest/ &#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Insomnia&lt;/a&gt; 测试 API 调用&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://docs.telerik.com/fiddler/configure-fiddler/tasks/configurefiddler&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Fiddler&lt;/a&gt; 或 &lt;a href= &#34;https://www.charlesproxy.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Charlesproxy&lt;/a&gt; 用于捕获和查看后端 API 调用的网络跟踪&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://jwt.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;https://jwt.io/&lt;/a&gt; 查看和创建 JWT&lt;/li&gt;&#xA;&lt;li&gt;SAML 跟踪器，适用于 &lt;a href=&#34;https://addons.mozilla.org/en-US/firefox/addon/saml-tracer/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Firefox &lt;/a&gt; 和 &lt;a href=&#34;https://chromewebstore.google.com/detail/saml-tracer/mpdajninpobndbfcldcmbpnnbhibjmch?hl=en&amp;pli=1&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Chrome&lt;/a &gt;，检查 SAML 请求&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;know-these-debugging-basics&#34;&gt;了解这些调试基础知识&lt;/h3&gt;&#xA;&lt;p&gt;当某些事情没有按预期工作时，尤其是在身份验证方面，最好开始检查简单的事情。例如：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;检查身份提供商是否可以访问并且没有遇到任何问题&lt;/li&gt;&#xA;&lt;li&gt;确保提供的凭据对于环境而言正确&lt;/li&gt;&#xA;&lt;li&gt;检查登录帐户和凭据是否未停用或过期&lt;/li&gt;&#xA;&lt;li&gt;确保 Grafana 使用正确的身份提供商 URL&lt;/li&gt;&#xA;&lt;li&gt;验证客户端 ID 是否与身份提供商中注册的 ID 匹配&lt;/li&gt;&#xA;&lt;li&gt;检查重定向/回调网址&lt;/li&gt;&#xA;&lt;li&gt;阅读所有错误消息，看看它们是否提供了有价值的线索&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;whats-next&#34;&gt;下一步是什么？&lt;/h2&gt;&#xA;&lt;p&gt;我们希望最近对 UI、API 和 Terraform 所做的更新能够增强您使用 Grafana 的体验并简化 SSO 设置过程。展望未来，我们计划引入新的 UI 和 API 来配置 LDAP，这将使身份验证设置更加容易。&lt;/p&gt;&#xA;&lt;p&gt;同时，如果您想详细了解如何在 Grafana 中组织用户和团队以确保最佳安全性，请参阅&lt;a href=&#34;/blog/2022/03/14/how-to-best -组织你的团队和资源-grafana/&#34;&gt;这篇博文&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;/products/cloud/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt; 是开始使用指标、日志、跟踪、仪表板等的最简单方法。我们为每个用例提供慷慨的永久免费套餐和计划。 &lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;plcmt=body-txt&#34;&gt;立即免费注册&lt;/a&gt;！&lt;/em&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 31 Jul 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【How Japan&#39;s space agency used Grafana to monitor its first moon landing in real time】日本航天局如何使用 Grafana 实时监控其首次登月</title>
      <link>https://grafana.com/blog/2024/08/01/how-japans-space-agency-used-grafana-to-monitor-its-first-moon-landing-in-real-time/</link>
      <description>【&lt;p&gt;When Japan&amp;rsquo;s space agency, JAXA, set out to make its first lunar landing in January, the goal wasn&amp;rsquo;t just to get its &lt;a href=&#34;https://global.jaxa.jp/projects/sas/slim/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;SLIM (Smart Lander for Investigating Moon)&lt;/a&gt; spacecraft on the moon&amp;rsquo;s surface. The plan also called to touch down within 100 meters of its intended target — making for the world&amp;rsquo;s first pinpoint lunar landing.&lt;/p&gt;&#xA;&lt;p&gt;JAXA&amp;rsquo;s doubly historic moment came on Jan. 19, 2024, as Japan became the fifth country to put a spacecraft on the moon. Back on Earth, the agency&amp;rsquo;s researchers and engineers monitored the operation in real time using &lt;a href=&#34;/grafana/dashboards/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana dashboards&lt;/a&gt; that tracked SLIM&amp;rsquo;s critical functions including navigation, heater status, and landing maneuvers.&lt;/p&gt;&#xA;&lt;p&gt;In a &lt;a href=&#34;/events/grafanacon/2024/grafana-used-to-monitor-japan-slim-moon-lander/&#34;&gt;GrafanaCON 2024 presentation&lt;/a&gt;, Satoshi Nakahira, an associate senior researcher at JAXA&amp;rsquo;s Institute of Space and Astronautical Science (ISAS), highlighted some of the agency&amp;rsquo;s work, discussed its observability system, and shared examples of the dashboards used during the lunar landing.&lt;/p&gt;&#xA;&lt;p&gt;Grafana, he said, &amp;ldquo;played an important role in our operation.&amp;rdquo;&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;Note: JAXA session from GrafanaCON 2024 is now available to watch on demand. You can check out the full session on YouTube below.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;div class=&#34;shortcode youtube&#34;&gt;&#xA;&lt;iframe src=&#34;https://www.youtube.com/embed/CpHQfwFPvw8?rel=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&#xA;&lt;h2 id=&#34;system-booster-engaged&#34;&gt;System booster engaged&lt;/h2&gt;&#xA;&lt;p&gt;JAXA observes its data with an in-house tool that Nakahira said has several issues. &amp;ldquo;There are many characters, so it is not easy to find certain parameters,&amp;rdquo; he said. On top of that, he added, it was built as monolithic software, so maintaining it or adding in new features was difficult.&lt;/p&gt;&#xA;&lt;p&gt;Adding Grafana helped JAXA observe the different types of telemetry collected by SLIM&amp;rsquo;s scientific probes.&lt;/p&gt;&#xA;&lt;p&gt;Nakahira divided the data into two categories:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Housekeeping data&lt;/strong&gt; covers the basic metrics that monitor the spacecraft&amp;rsquo;s real-time health and functionality, such as voltage, current, temperature, attitude, position, velocity, acceleration, status flags, and counts.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Scientific data&lt;/strong&gt;, including images, spectrograms, and bursted time series, which are analyzed on a slower time scale.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Nakahira said that the housekeeping data is &amp;ldquo;similar to what you find in IoT devices,&amp;rdquo; but with one key difference: IoT systems collect a small amount of telemetry from many devices, but JAXA&amp;rsquo;s probes collect a large volume of telemetry from one big device.&lt;/p&gt;&#xA;&lt;p&gt;&amp;ldquo;The content of the data is still similar, so as a result, inspired by IoTs, we have integrated Grafana to space probe&amp;rsquo;s operations for enhanced observability,&amp;rdquo; he said.&lt;/p&gt;&#xA;&lt;p&gt;JAXA used InfluxDB as its data source in Grafana, as well as an API to get calculations for its image generation. In front of InfluxDB, the team built a data receiver written in Python. &amp;ldquo;We were able to build our entire system quite easily and the visualization capability was broad — from simple ones to detailed graphs,&amp;rdquo; he added.&lt;/p&gt;&#xA;&lt;h2 id=&#34;a-giant-step-for-jaxaand-its-querying-abilities&#34;&gt;A giant step for JAXA—and its querying abilities&lt;/h2&gt;&#xA;&lt;p&gt;To go along with the Quick Look System, JAXA built and used more than 10 Grafana dashboards to monitor SLIM&amp;rsquo;s subsystems (e.g., power and navigation) as well as individual ones for three main phases: launch, running, and cruise.&lt;/p&gt;&#xA;&lt;p&gt;Overall, Nakahira said, Grafana gave JAXA broad &lt;a href=&#34;/docs/grafana/latest/panels-visualizations/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;visualization capabilities&lt;/a&gt; that ranged from simple gauges to xy graphs, time series panels, and bar charts. The dashboards the agency&amp;rsquo;s team created were &amp;ldquo;well-received and visually impressive,&amp;rdquo; he added. Nakahira also said editing dashboards was &amp;ldquo;straightforward — and could be done even during operations.&amp;rdquo;&lt;/p&gt;&#xA;&lt;p&gt;The real &amp;ldquo;game-changer&amp;rdquo; for the team, he explained, was Grafana&amp;rsquo;s variable feature. It allowed them to easily locate and display specific telemetry data among the thousands of series they collected. They used parameters and two query variables — &lt;strong&gt;textbox&lt;/strong&gt; and &lt;strong&gt;query&lt;/strong&gt; — to filter data across multiple graphs in Grafana.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1600px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&#xA;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-querying-USETHIS.jpg&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-querying-USETHIS.jpg&#34;data-srcset=&#34;/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-querying-USETHIS.jpg?w=320 320w, /media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-querying-USETHIS.jpg?w=550 550w, /media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-querying-USETHIS.jpg?w=750 750w, /media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-querying-USETHIS.jpg?w=900 900w, /media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-querying-USETHIS.jpg?w=1040 1040w, /media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-querying-USETHIS.jpg?w=1240 1240w, /media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-querying-USETHIS.jpg?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A slide showing a Grafana dashboard to show how easy it is to locate and display a specific telemetry&#34;&#xA;width=&#34;1600&#34;&#xA;height=&#34;900&#34;&#xA;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-querying-USETHIS.jpg&#34;&#xA;alt=&#34;A slide showing a Grafana dashboard to show how easy it is to locate and display a specific telemetry&#34;&#xA;width=&#34;1600&#34;&#xA;height=&#34;900&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;/a&gt;&#xA;&lt;/figure&gt;&#xA;&lt;h2 id=&#34;out-of-this-world-dashboards&#34;&gt;Out-of-this-world dashboards&lt;/h2&gt;&#xA;&lt;p&gt;Nakahira shared video from inside of the JAXA control room just before SLIM&amp;rsquo;s lunar landing, highlighting where Grafana dashboards were used. For example, on the wall seen below, a monitor displayed a real-time Grafana dashboard that was live streamed on YouTube during the operation. &amp;ldquo;In this critical phase, the Control Room and the YouTube audience were all looking at the same Grafana dashboard at the same time,&amp;rdquo; Nakahira said.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1600px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&#xA;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/JAXA-recap/image-JAXA-recap-inside-control-room.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/JAXA-recap/image-JAXA-recap-inside-control-room.png&#34;data-srcset=&#34;/media/blog/JAXA-recap/image-JAXA-recap-inside-control-room.png?w=320 320w, /media/blog/JAXA-recap/image-JAXA-recap-inside-control-room.png?w=550 550w, /media/blog/JAXA-recap/image-JAXA-recap-inside-control-room.png?w=750 750w, /media/blog/JAXA-recap/image-JAXA-recap-inside-control-room.png?w=900 900w, /media/blog/JAXA-recap/image-JAXA-recap-inside-control-room.png?w=1040 1040w, /media/blog/JAXA-recap/image-JAXA-recap-inside-control-room.png?w=1240 1240w, /media/blog/JAXA-recap/image-JAXA-recap-inside-control-room.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;An image of two people in a control room looking at a wall-mounted monitor with a Grafana dashboard displayed on it.&#34;&#xA;width=&#34;1600&#34;&#xA;height=&#34;870&#34;&#xA;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/JAXA-recap/image-JAXA-recap-inside-control-room.png&#34;&#xA;alt=&#34;An image of two people in a control room looking at a wall-mounted monitor with a Grafana dashboard displayed on it.&#34;&#xA;width=&#34;1600&#34;&#xA;height=&#34;870&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;/a&gt;&#xA;&lt;/figure&gt;&#xA;&lt;p&gt;Here are some of the dashboards that helped JAXA&amp;rsquo;s team make history:&lt;/p&gt;&#xA;&lt;h3 id=&#34;navigation-system-during-the-cruise-phase&#34;&gt;Navigation system during the cruise phase&lt;/h3&gt;&#xA;&lt;p&gt;Nakahira said this was easily built by connecting InfluxDB with Grafana. The panels are monitoring:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;System status&lt;/li&gt;&#xA;&lt;li&gt;Error or warning status&lt;/li&gt;&#xA;&lt;li&gt;Log messages generated by ground processing&lt;/li&gt;&#xA;&lt;li&gt;Attitude (orientation in space), atmospheric change, and solar angle&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1600px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&#xA;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-navigation-system-USETHIS.jpg&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-navigation-system-USETHIS.jpg&#34;data-srcset=&#34;/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-navigation-system-USETHIS.jpg?w=320 320w, /media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-navigation-system-USETHIS.jpg?w=550 550w, /media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-navigation-system-USETHIS.jpg?w=750 750w, /media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-navigation-system-USETHIS.jpg?w=900 900w, /media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-navigation-system-USETHIS.jpg?w=1040 1040w, /media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-navigation-system-USETHIS.jpg?w=1240 1240w, /media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-navigation-system-USETHIS.jpg?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A presentation slide with an image of a Grafana dashboard with panels of graphs displaying information related to the navigation system&#34;&#xA;width=&#34;1600&#34;&#xA;height=&#34;900&#34;&#xA;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-navigation-system-USETHIS.jpg&#34;&#xA;alt=&#34;A presentation slide with an image of a Grafana dashboard with panels of graphs displaying information related to the navigation system&#34;&#xA;width=&#34;1600&#34;&#xA;height=&#34;900&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;/a&gt;&#xA;&lt;/figure&gt;&#xA;&lt;h3 id=&#34;heater-status&#34;&gt;Heater status&lt;/h3&gt;&#xA;&lt;p&gt;Nakahira said this dashboard is important &amp;ldquo;because instruments can be damaged by extremely low temperatures in space.&amp;rdquo;&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1600px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&#xA;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-heater-status-USETHIS.jpg&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-heater-status-USETHIS.jpg&#34;data-srcset=&#34;/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-heater-status-USETHIS.jpg?w=320 320w, /media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-heater-status-USETHIS.jpg?w=550 550w, /media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-heater-status-USETHIS.jpg?w=750 750w, /media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-heater-status-USETHIS.jpg?w=900 900w, /media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-heater-status-USETHIS.jpg?w=1040 1040w, /media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-heater-status-USETHIS.jpg?w=1240 1240w, /media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-heater-status-USETHIS.jpg?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A presentation slide with a Grafana dashboard featuring several colorful graphs displaying metrics related to heater status&#34;&#xA;width=&#34;1600&#34;&#xA;height=&#34;900&#34;&#xA;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-heater-status-USETHIS.jpg&#34;&#xA;alt=&#34;A presentation slide with a Grafana dashboard featuring several colorful graphs displaying metrics related to heater status&#34;&#xA;width=&#34;1600&#34;&#xA;height=&#34;900&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;/a&gt;&#xA;&lt;/figure&gt;&#xA;&lt;p&gt;It is scrollable and has several pages of information below what he shared. The dashboard allows team members to observe power-related metrics, such as power generation and power usage. The stacked graph in the upper left, he said, &amp;ldquo;provides a clear view for total power consumption for each component.&amp;rdquo;&lt;/p&gt;&#xA;&lt;p&gt;SLIM has about 50 heaters, which are controlled autonomously, but it is important to monitor its duty cycle, Nakahira explained. He said the state timeline panel (middle-right) made that task easy because it allowed team members to compare it with the graphs in the middle of the screenshot above, which monitor temperature.&lt;/p&gt;&#xA;&lt;h3 id=&#34;thrusters-and-maneuvers&#34;&gt;Thrusters and maneuvers&lt;/h3&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1600px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&#xA;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-thrusters-and-maneuvers-USETHIS.jpg&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-thrusters-and-maneuvers-USETHIS.jpg&#34;data-srcset=&#34;/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-thrusters-and-maneuvers-USETHIS.jpg?w=320 320w, /media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-thrusters-and-maneuvers-USETHIS.jpg?w=550 550w, /media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-thrusters-and-maneuvers-USETHIS.jpg?w=750 750w, /media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-thrusters-and-maneuvers-USETHIS.jpg?w=900 900w, /media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-thrusters-and-maneuvers-USETHIS.jpg?w=1040 1040w, /media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-thrusters-and-maneuvers-USETHIS.jpg?w=1240 1240w, /media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-thrusters-and-maneuvers-USETHIS.jpg?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A presentation slide with a screenshot of a Grafana dashboard featuring several panels with graphs related to thrusters and maneuvers&#34;&#xA;width=&#34;1600&#34;&#xA;height=&#34;900&#34;&#xA;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-thrusters-and-maneuvers-USETHIS.jpg&#34;&#xA;alt=&#34;A presentation slide with a screenshot of a Grafana dashboard featuring several panels with graphs related to thrusters and maneuvers&#34;&#xA;width=&#34;1600&#34;&#xA;height=&#34;900&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;/a&gt;&#xA;&lt;/figure&gt;&#xA;&lt;p&gt;SLIM has two main thrusters and 12 smaller ones, Nakahira said, and the left side of the dashboard is arranged to reflect that layout. The gauges on the upper-right show the remaining fuel of SLIM&amp;rsquo;s thrusters and the battery. Below that, 3D images monitor SLIM&amp;rsquo;s attitude in relation to the sun and Earth. &amp;ldquo;It is implemented by Python API and images are generated by offline rendering by using &lt;a href=&#34;https://trimesh.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;trimesh&lt;/a&gt; or &lt;a href=&#34;https://pyrender.readthedocs.io/en/latest/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;pyrender&lt;/a&gt; libraries,&amp;rdquo; he said.&lt;/p&gt;&#xA;&lt;h3 id=&#34;landing&#34;&gt;Landing&lt;/h3&gt;&#xA;&lt;p&gt;Below is a snapshot of what the real-time dashboard looked like during the moon landing. (Nakahira&amp;rsquo;s presentation shows the data moving and changing.) It is similar to the dashboard above, but the panel in the bottom right is different. That new graph is charting distance on the horizontal axis and the attitude on the vertical axis. The flight line is SLIM&amp;rsquo;s actual planned trajectory, with the red section highlighting the actual trajectory during the previous five minutes.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1600px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&#xA;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-lander-in-graph-USETHIS.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-lander-in-graph-USETHIS.png&#34;data-srcset=&#34;/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-lander-in-graph-USETHIS.png?w=320 320w, /media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-lander-in-graph-USETHIS.png?w=550 550w, /media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-lander-in-graph-USETHIS.png?w=750 750w, /media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-lander-in-graph-USETHIS.png?w=900 900w, /media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-lander-in-graph-USETHIS.png?w=1040 1040w, /media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-lander-in-graph-USETHIS.png?w=1240 1240w, /media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-lander-in-graph-USETHIS.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A screenshot of a real-time Grafana dashboard that includes a graph displaying SLIM&amp;#39;s actual planned trajectory&#34;&#xA;width=&#34;1600&#34;&#xA;height=&#34;841&#34;&#xA;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-lander-in-graph-USETHIS.png&#34;&#xA;alt=&#34;A screenshot of a real-time Grafana dashboard that includes a graph displaying SLIM&amp;#39;s actual planned trajectory&#34;&#xA;width=&#34;1600&#34;&#xA;height=&#34;841&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;/a&gt;&#xA;&lt;/figure&gt;&#xA;&lt;p&gt;In the panel on the right side below, JAXA&amp;rsquo;s team was able to observe SLIM approaching and landing on the moon&amp;rsquo;s surface.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1999px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&#xA;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-lander.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-lander.png&#34;data-srcset=&#34;/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-lander.png?w=320 320w, /media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-lander.png?w=550 550w, /media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-lander.png?w=750 750w, /media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-lander.png?w=900 900w, /media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-lander.png?w=1040 1040w, /media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-lander.png?w=1240 1240w, /media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-lander.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A screenshot of a Grafana dashboard that includes a panel monitoring SLIM approaching and landing on the moon&amp;#39;s surface&#34;&#xA;width=&#34;1999&#34;&#xA;height=&#34;1078&#34;&#xA;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-lander.png&#34;&#xA;alt=&#34;A screenshot of a Grafana dashboard that includes a panel monitoring SLIM approaching and landing on the moon&amp;#39;s surface&#34;&#xA;width=&#34;1999&#34;&#xA;height=&#34;1078&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;/a&gt;&#xA;&lt;/figure&gt;&#xA;&lt;p&gt;To find out more about JAXA&amp;rsquo;s upcoming missions, launches, and other projects, visit the agency&amp;rsquo;s &lt;a href=&#34;https://global.jaxa.jp/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;official website&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Want to share your Grafana story and dashboards with the community? Drop us a note at &lt;a href=&#34;mailto:stories@grafana.com&#34;&gt;stories@grafana.com&lt;/a&gt;.&lt;/p&gt;】&lt;p&gt;当日本宇宙航空研究开发机构 (JAXA) 于 1 月份开始首次登月时，其目标不仅仅是获得&lt;a href=&#34;https://global.jaxa.jp/projects/sas/slim /&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;SLIM（月球勘察智能着陆器）&lt;/a&gt; 月球表面上的航天器。该计划还要求在距离预定目标 100 米的范围内着陆，实现世界上首次精确登月。&lt;/p&gt;&#xA;&lt;p&gt;2024 年 1 月 19 日，JAXA 迎来了双重历史性时刻，日本成为第五个将航天器送上月球的国家。回到地球后，该机构的研究人员和工程师使用 &lt;a href=&#34;/grafana/dashboards/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana 仪表板&lt;/a&gt;实时监控运行情况，跟踪 SLIM 的关键功能，包括导航、加热器状态和着陆操纵。&lt;/p&gt;&#xA;&lt;p&gt;在 &lt;a href=&#34;/events/grafanacon/2024/grafana-used-to-monitor-japan-slim-moon-lander/&#34;&gt;GrafanaCON 2024 演示文稿&lt;/a&gt;中，副高级研究员 Satoshi Nakahira JAXA 空间与宇航科学研究所 (ISAS) 重点介绍了该机构的一些工作，讨论了其可观测系统，并分享了登月期间使用的仪表板示例。&lt;/p&gt;&#xA;&lt;p&gt;他说，Grafana“在我们的运营中发挥了重要作用。”&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;注意：GrafanaCON 2024 的 JAXA 会议现已可供点播观看。您可以在下面的 YouTube 上查看完整的会议内容。&lt;/em&gt;&lt;/p&gt;&#xA;&lt;div class=&#34;shortcode youtube&#34;&gt;&#xA;&lt;iframe src=&#34;https://www.youtube.com/embed/CpHQfwFPvw8?rel=0&#34; style=&#34;位置：绝对；顶部：0；左侧：0；宽度：100%；高度：100%；边框： 0;” allowedfullscreen title=&#34;YouTube 视频&#34;&gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&#xA;&lt;h2 id=&#34;system-booster-engged&#34;&gt;系统助推器已启用&lt;/h2&gt;&#xA;&lt;p&gt;JAXA 使用内部工具观察其数据，Nakahira 表示该工具存在几个问题。 “字符很多，所以找到某些参数并不容易，”他说。他补充说，最重要的是，它是作为整体软件构建的，因此维护它或添加新功能很困难。&lt;/p&gt;&#xA;&lt;p&gt;添加 Grafana 有助于 JAXA 观察 SLIM 科学探测器收集的不同类型的遥测数据。&lt;/p&gt;&#xA;&lt;p&gt;Nakahira 将数据分为两类：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;内务数据&lt;/strong&gt;涵盖了监控航天器实时运行状况和功能的基本指标，例如电压、电流、温度、姿态、位置、速度、加速度、状态标志和计数。&lt; /里&gt;&#xA;&lt;li&gt;&lt;strong&gt;科学数据&lt;/strong&gt;，包括图像、频谱图和突发时间序列，在较慢的时间尺度上进行分析。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;Nakahira 表示，内务数据“与物联网设备中的数据类似”，但有一个关键区别：物联网系统从许多设备收集少量遥测数据，但 JAXA 的探测器从一台设备收集大量遥测数据大设备。&lt;/p&gt;&#xA;&lt;p&gt;“数据的内容是仍然相似，因此，受到物联网的启发，我们将 Grafana 集成到太空探测器的操作中，以增强可观测性。”他说。&lt;/p&gt;&#xA;&lt;p&gt;JAXA 使用 InfluxDB 作为 Grafana 中的数据源，以及用于获取图像生成计算的 API。在InfluxDB前面，团队构建了一个用Python编写的数据接收器。 “我们能够非常轻松地构建整个系统，并且可视化功能非常广泛——从简单的到详细的图表，”他补充道。&lt;/p&gt;&#xA;&lt;h2 id=&#34;a-giant-step-for-jaxaand-its-querying-bility&#34;&gt;JAXA 及其查询能力的一大进步&lt;/h2&gt;&#xA;&lt;p&gt;为了配合 Quick Look 系统，JAXA 构建并使用了 10 多个 Grafana 仪表板来监控 SLIM 的子系统（例如电源和导航）以及三个主要阶段的各个子系统：发射、运行和巡航。&lt; /p&gt;&#xA;&lt;p&gt;总体而言，Nakahira 表示，Grafana 为 JAXA 提供了广泛的&lt;a href=&#34;/docs/grafana/latest/panels-visualizations/?pg=blog&amp;plcmt=body-txt&#34;&gt;可视化功能&lt;/a&gt;，从简单的仪表到xy 图表、时间序列面板和条形图。他补充说，该机构团队创建的仪表板“很受欢迎，而且视觉效果令人印象深刻”。 Nakahira 还表示，编辑仪表板“非常简单，甚至可以在操作期间完成。”&lt;/p&gt;&#xA;&lt;p&gt;他解释说，团队真正的“游戏规则改变者”是 Grafana 的可变功能。它使他们能够在收集的数千个系列中轻松定位和显示特定的遥测数据。他们使用参数和两个查询变量（&lt;strong&gt;文本框&lt;/strong&gt;和&lt;strong&gt;查询&lt;/strong&gt;）来过滤 Grafana 中多个图表中的数据。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1600px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&#xA;&lt;一&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-querying-USETHIS.jpg&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-querying-USETHIS.jpg&#34;data-srcset=&#34;/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-查询-USETHIS.jpg？w=320 320w，/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-querying-USETHIS.jpg？w=550 550w，/media/blog/JAXA-recap/screenshot- JAXA-recap-dashboard-querying-USETHIS.jpg？w=750 750w，/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-querying-USETHIS.jpg？w=900 900w，/media/blog/ JAXA-recap/screenshot-JAXA-recap-dashboard-querying-USETHIS.jpg?w=1040 1040w，/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-querying-USETHIS.jpg?w=1240 1240w , /media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-querying-USETHIS.jpg?w=1920 1920w&#34;&#xA;data-sizes =“auto”alt =“显示 Grafana 仪表板的幻灯片，以显示定位和显示特定遥测数据是多么容易”&#xA;宽度=“1600”&#xA;高度=“900”&#xA;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/媒体/blog/JAXA-recap/屏幕截图-JAXA-recap-dashboard-querying-USETHIS.jpg&#34;&#xA;alt=&#34;显示 Grafana 仪表板的幻灯片，以展示定位和显示特定遥测数据是多么容易&#34;&#xA;宽度=“1600”&#xA;高度=“900”&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;/a&gt;&#xA;&lt;/图&gt;&#xA;&lt;h2 id=&#34;out-of-this-world-dashboards&#34;&gt;超凡脱俗的仪表板&lt;/h2&gt;&#xA;&lt;p&gt;Nakahira 在 SLIM 登月前分享了 JAXA 控制室内部的视频，重点介绍了使用 Grafana 仪表板的位置。例如，在下面看到的墙上，监视器显示了实时 Grafana 仪表板，该仪表板在操作过程中在 YouTube 上进行了直播。 “在这个关键阶段，控制室和 YouTube 观众都在同时查看同一个 Grafana 仪表板，”Nakahira 说。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1600px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&#xA;&lt;一&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/JAXA-recap/image-JAXA-recap-inside-control-room.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/blog/JAXA-recap/image-JAXA-recap-inside-control-room.png&#34;data-srcset=&#34;/media/blog/JAXA-recap/image-JAXA-recap-inside- control-room.png?w=320 320w, /media/blog/JAXA-recap/image-JAXA-recap-inside-control-room.png?w=550 550w, /media/blog/JAXA-recap/image- JAXA-recap-inside-control-room.png?w=750 750w，/media/blog/JAXA-recap/image-JAXA-recap-inside-control-room.png?w=900 900w，/media/blog/ JAXA-recap/image-JAXA-recap-inside-control-room.png?w=1040 1040w，/media/blog/JAXA-recap/image-JAXA-recap-inside-control-room.png?w=1240 1240w ，/media/blog/JAXA-recap/image-JAXA-recap-inside-control-room.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;控制室中两个人看着壁挂式显示器的图像，显​​示器上显示有 Grafana 仪表板。&#34;&#xA;宽度=“1600”&#xA;高度=“870”&#xA;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/JAXA-recap/image-JAXA-recap-inside-control-room.png”&#xA;alt=&#34;控制室中两个人看着壁挂式显示器的图像，显​​示器上显示有 Grafana 仪表板。&#34;&#xA;宽度=“1600”&#xA;高度=“870”&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;/a&gt;&#xA;&lt;/图&gt;&#xA;&lt;p&gt;以下是一些帮助 JAXA 团队创造历史的仪表板：&lt;/p&gt;&#xA;&lt;h3 id=&#34;navigation-system-during-the-cruise-phase&#34;&gt;巡航阶段的导航系统&lt;/h3&gt;&#xA;&lt;p&gt;Nakahira 表示，通过将 InfluxDB 与 Grafana 连接起来可以轻松构建这一点。面板正在监控：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;系统状态&lt;/li&gt;&#xA;&lt;li&gt;错误或警告状态&lt;/li&gt;&#xA;&lt;li&gt;地面处理生成的日志消息&lt;/li&gt;&#xA;&lt;li&gt;姿态（空间方向）、大气变化和太阳角&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1600px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&#xA;&lt;一&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-navigation-system-USETHIS.jpg&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&#xA;&lt;div类=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-navigation-system-USETHIS.jpg&#34;data-srcset=&#34;/media/blog/JAXA-recap/screenshot-JAXA-recap-仪表板导航系统-USETHIS.jpg？w=320 320w，/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-navigation-system-USETHIS.jpg？w=550 550w，/media/blog/ JAXA-recap/screenshot-JAXA-recap-dashboard-navigation-system-USETHIS.jpg？w=750 750w，/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-navigation-system-USETHIS.jpg？ w=900 900w，/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-navigation-system-USETHIS.jpg?w=1040 1040w，/media/blog/JAXA-recap/screenshot-JAXA-recap-仪表板导航系统-USETHIS.jpg？w=1240 1240w，/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-navigation-system-USETHIS.jpg？w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;演示幻灯片，其中包含 Grafana 仪表板的图像，其中的图形面板显示与导航系统相关的信息&#34;&#xA;宽度=“1600”&#xA;高度=“900”&#xA;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src=&#34;/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-navigation-system-USETHIS.jpg&#34;&#xA;alt=&#34;演示幻灯片，其中包含 Grafana 仪表板的图像，其中的图形面板显示与导航系统相关的信息&#34;&#xA;宽度=“1600”&#xA;高度=“900”&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;/a&gt;&#xA;&lt;/图&gt;&#xA;&lt;h3 id=&#34;heater-status&#34;&gt;加热器状态&lt;/h3&gt;&#xA;&lt;p&gt;Nakahira 说这个仪表板很重要，“因为仪器可能会因太空中极低的温度而损坏。”&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1600px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&#xA;&lt;一&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-heater-status-USETHIS.jpg&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-heater-status-USETHIS.jpg&#34;data-srcset=&#34;/media/blog/JAXA-recap/screenshot-JAXA-recap-仪表板-heater-status-USETHIS.jpg？w=320 320w，/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-heater-status-USETHIS.jpg？w=550 550w，/media/blog/ JAXA-recap/screenshot-JAXA-recap-dashboard-heater-status-USETHIS.jpg？w=750 750w，/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-heater-status-USETHIS.jpg？ w=900 900w，/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-heater-status-USETHIS.jpg?w=1040 1040w，/media/blog/JAXA-recap/screenshot-JAXA-recap-仪表板-heater-status-USETHIS.jpg？w=1240 1240w，/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-heater-status-USETHIS.jpg？w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;带有 Grafana 仪表板的演示幻灯片，其中包含多个彩色图表，显示与加热器状态相关的指标&#34;&#xA;宽度=“1600”&#xA;高度=“900”&#xA;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src=&#34;/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-heater-status-USETHIS.jpg&#34;&#xA;alt=&#34;带有 Grafana 仪表板的演示幻灯片，其中包含 se显示与加热器状态相关的指标的真实彩色图表”&#xA;宽度=“1600”&#xA;高度=“900”&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;/a&gt;&#xA;&lt;/图&gt;&#xA;&lt;p&gt;它是可滚动的，并且在他分享的内容下面有几页信息。仪表板允许团队成员观察与电力相关的指标，例如发电量和用电量。他说，左上角的堆叠图“提供了每个组件的总功耗的清晰视图。”&lt;/p&gt;&#xA;&lt;p&gt;SLIM 大约有 50 个加热器，这些加热器是自主控制的，但监控其工作周期非常重要，Nakahira 解释道。他说状态时间线面板（中右）使这项任务变得容易，因为它允许团队成员将其与上面屏幕截图中间监控温度的图表进行比较。&lt;/p&gt;&#xA;&lt;h3 id=&#34;thrusters-and-maneuvers&#34;&gt;推进器和机动&lt;/h3&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1600px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&#xA;&lt;一&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-thrusters-and-maneuvers-USETHIS.jpg&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-thrusters-and-maneuvers-USETHIS.jpg&#34;data-srcset=&#34;/media/blog/JAXA-recap/screenshot-JAXA- recap-dashboard-thrusters-and-maneuvers-USETHIS.jpg?w=320 320w, /media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-thrusters-and-maneuvers-USETHIS.jpg?w=550 550w , /media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-thrusters-and-maneuvers-USETHIS.jpg?w=750 750w, /media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-推进器和操纵-USETHIS.jpg？w=900 900w，/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-thrusters-and-maneuvers-USETHIS.jpg？w=1040 1040w，/media/博客/JAXA-recap/screenshot-JAXA-recap-dashboard-thrusters-and-maneuvers-USETHIS.jpg?w=1240 1240w，/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-thrusters-and-演习-USETHIS.jpg?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;演示幻灯片，其中包含 Grafana 仪表板的屏幕截图，其中包含多个面板，其中包含与推进器和操作相关的图表&#34;&#xA;宽度=“1600”&#xA;高度=“900”&#xA;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src=&#34;/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-thrusters-and-maneuvers-USETHIS.jpg&#34;&#xA;alt=&#34;演示幻灯片，其中包含 Grafana 仪表板的屏幕截图，其中包含多个面板，其中包含与推进器和操作相关的图表&#34;&#xA;宽度=“1600”&#xA;高度=“900”&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;/a&gt;&#xA;&lt;/图&gt;&#xA;&lt;p&gt;SLIM 有两个主推进器和 12 个较小的推进器，Nakahira 说，仪表板左侧的布置反映了这种布局。右上角的仪表显示 SLIM 推进器和电池的剩余燃料。下面，3D 图像监控 SLIM 相对于太阳和地球的姿态。 “它是通过Python API实现的，图像是使用&lt;a href=&#34;https”离线渲染生成的://trimesh.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;trimesh&lt;/a&gt; 或 &lt;a href=&#34;https://pyrender.readthedocs.io/en/latest/&#34; target=&#34;_blank “ rel=&#34;noopener noreferrer&#34;&gt;pyrender&lt;/a&gt; 库，”他说。&lt;/p&gt;&#xA;&lt;h3 id=&#34;landing&#34;&gt;着陆&lt;/h3&gt;&#xA;&lt;p&gt;下面是登月期间实时仪表板的快照。 （Nakahira 的演示显示了数据的移动和变化。）它与上面的仪表板类似，但右下角的面板有所不同。该新图表在水平轴上绘制距离，在垂直轴上绘制姿态。飞行路线是SLIM实际规划的轨迹，红色部分突出了前五分钟的实际轨迹。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1600px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&#xA;&lt;一&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-lander-in-graph-USETHIS.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-lander-in-graph-USETHIS.png&#34;data-srcset=&#34;/media/blog/JAXA-recap/screenshot-JAXA- recap-dashboard-lander-in-graph-USETHIS.png?w=320 320w，/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-lander-in-graph-USETHIS.png?w=550 550w ，/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-lander-in-graph-USETHIS.png?w=750 750w，/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard- lander-in-graph-USETHIS.png?w=900 900w，/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-lander-in-graph-USETHIS.png?w=1040 1040w，/media/博客/JAXA-recap/screenshot-JAXA-recap-dashboard-lander-in-graph-USETHIS.png?w=1240 1240w，/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-lander-in-图-USETHIS.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;实时 Grafana 仪表板的屏幕截图，其中包括显示 SLIM 实际计划轨迹的图表&#34;&#xA;宽度=“1600”&#xA;高度=“841”&#xA;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-lander-in-graph-USETHIS.png”&#xA;alt=&#34;实时 Grafana 仪表板的屏幕截图，其中包括显示 SLIM 实际计划轨迹的图表&#34;&#xA;宽度=“1600”&#xA;高度=“841”&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;/a&gt;&#xA;&lt;/图&gt;&#xA;&lt;p&gt;在下面右侧的面板中，JAXA 的团队能够观察到 SLIM 接近并降落在月球表面。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1999px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&#xA;&lt;一&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-lander.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-lander.png&#34;data-srcset=&#34;/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-lander.png png?w=320 320w，/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-lander.png?w=550 550w，/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard- lander.png?w=750 750w，/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-lander.png?w=900 900w，/media/blog/JAXA-recap/screenshot-JAXA-recap-仪表板-lander.png？w = 1040 1040w，/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-lander.png？w=1240 1240w，/media/blog/JAXA-recap/screenshot-JAXA-回顾-仪表板-lander.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;Grafana 仪表板的屏幕截图，其中包括一个监控 SLIM 接近和登陆月球表面的面板&#34;&#xA;宽度=“1999”&#xA;高度=“1078”&#xA;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/JAXA-recap/screenshot-JAXA-recap-dashboard-lander.png”&#xA;alt=&#34;Grafana 仪表板的屏幕截图，其中包括一个监控 SLIM 接近和登陆月球表面的面板&#34;&#xA;宽度=“1999”&#xA;高度=“1078”&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;/a&gt;&#xA;&lt;/图&gt;&#xA;&lt;p&gt;要了解有关 JAXA 即将执行的任务、发射和其他项目的更多信息，请访问该机构的&lt;a href=&#34;https://global.jaxa.jp/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;官方网站网站&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;想要与社区分享您的 Grafana 故事和仪表板吗？请通过 &lt;a href=&#34;mailto:stories@grafana.com&#34;&gt;stories@grafana.com&lt;/a&gt; 给我们留言。&lt;/p&gt;</description>
      <pubDate>Thu, 01 Aug 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【How to integrate Okta logs with Grafana Loki for enhanced SIEM capabilities】如何将 Okta 日志与 Grafana Loki 集成以增强 SIEM 功能</title>
      <link>https://grafana.com/blog/2024/08/07/how-to-integrate-okta-logs-with-grafana-loki-for-enhanced-siem-capabilities/</link>
      <description>【&lt;p&gt;Identity providers (IdPs) such as Okta play a crucial role in enterprise environments by providing seamless authentication and authorization experiences for users accessing organizational resources. These interactions generate a massive volume of event logs, containing valuable information like user details, geographical locations, IP addresses, and more.&lt;/p&gt;&#xA;&lt;p&gt;These logs are essential for security teams, especially in operations, because they&amp;rsquo;re used to detect and respond to incidents effectively. However, integrating these logs into logging and SIEM platforms can be challenging.&lt;/p&gt;&#xA;&lt;p&gt;In this blog post, we&amp;rsquo;ll show you how to effectively set up and run our Okta logs collector to send logs to &lt;a href=&#34;/oss/loki/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Loki&lt;/a&gt; instances on-premises or in the cloud. By configuring your environment variables, running the Okta logs collector Docker container, and utilizing the latest versions of Loki and &lt;a href=&#34;/oss/alloy-opentelemetry-collector/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Alloy&lt;/a&gt;, you can monitor, analyze, and set alerts on your Okta logs for deeper insights and improved system security and operational capabilities.&lt;/p&gt;&#xA;&lt;h2 id=&#34;why-we-developed-the-okta-logs-collector&#34;&gt;Why we developed the Okta logs collector&lt;/h2&gt;&#xA;&lt;p&gt;Many IdPs offer REST APIs for fetching event logs, with &lt;a href=&#34;https://developer.okta.com/docs/reference/api/system-log/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Okta&amp;rsquo;s System Log API&lt;/a&gt; providing logs in JSON format, as shown below. However, integrating these logs into existing systems often involves a complex and time-consuming process, typically requiring custom code to access the logs via an HTTP client library in programming languages like Go.&lt;/p&gt;&#xA;&lt;p&gt;To simplify and streamline this process, we developed the &lt;a href=&#34;https://github.com/grafana/okta-logs-collector&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Okta logs collector&lt;/a&gt;. This tool automates the retrieval of logs from the Okta System Log API, enriches the data, and sends it to STDOUT, making it easy to scrape and forward the logs to observability platforms like Loki using agents such as Alloy or Promtail.&lt;/p&gt;&#xA;&lt;p&gt;To further illustrate why we built the Okta logs collector, let&amp;rsquo;s briefly look at the challenge developers face with fetching event logs and how we&amp;rsquo;re attempting to address those challenges.&lt;/p&gt;&#xA;&lt;h3 id=&#34;json-log-event-example&#34;&gt;JSON log event example&lt;/h3&gt;&#xA;&lt;p&gt;Here&amp;rsquo;s an example of a JSON-formatted log event generated by Okta&amp;rsquo;s System Log API:&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet &#34;&gt;&lt;div class=&#34;lang-toolbar&#34;&gt;&#xA;&lt;span class=&#34;lang-toolbar__item&#34;&gt;JavaScript&lt;/span&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;button x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;Copy code to clipboard&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;Copy&lt;/span&gt;&#xA;&lt;/button&gt;&#xA;&lt;/span&gt;&#xA;&lt;div class=&#34;lang-toolbar__border&#34;&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet &#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-javascript&#34;&gt;{&#xA;&amp;#34;version&amp;#34;: &amp;#34;0&amp;#34;,&#xA;&amp;#34;severity&amp;#34;: &amp;#34;INFO&amp;#34;,&#xA;&amp;#34;client&amp;#34;: {&#xA;&amp;#34;zone&amp;#34;: &amp;#34;OFF_NETWORK&amp;#34;,&#xA;&amp;#34;device&amp;#34;: &amp;#34;Unknown&amp;#34;,&#xA;&amp;#34;userAgent&amp;#34;: {&#xA;&amp;#34;os&amp;#34;: &amp;#34;Unknown&amp;#34;,&#xA;&amp;#34;browser&amp;#34;: &amp;#34;UNKNOWN&amp;#34;,&#xA;&amp;#34;rawUserAgent&amp;#34;: &amp;#34;UNKNOWN-DOWNLOAD&amp;#34;&#xA;},&#xA;&amp;#34;ipAddress&amp;#34;: &amp;#34;12.97.85.90&amp;#34;&#xA;},&#xA;&amp;#34;device&amp;#34;: {&#xA;&amp;#34;id&amp;#34;: &amp;#34;guob5wtu7rBggkg9G1d7&amp;#34;,&#xA;&amp;#34;name&amp;#34;: &amp;#34;MacBookPro16,1&amp;#34;,&#xA;&amp;#34;os_platform&amp;#34;: &amp;#34;OSX&amp;#34;,&#xA;&amp;#34;os_version&amp;#34;: &amp;#34;14.3.0&amp;#34;,&#xA;&amp;#34;managed&amp;#34;: false,&#xA;&amp;#34;registered&amp;#34;: true,&#xA;&amp;#34;device_integrator&amp;#34;: null,&#xA;&amp;#34;disk_encryption_type&amp;#34;: &amp;#34;ALL_INTERNAL_VOLUMES&amp;#34;,&#xA;&amp;#34;screen_lock_type&amp;#34;: &amp;#34;BIOMETRIC&amp;#34;,&#xA;&amp;#34;jailbreak&amp;#34;: null,&#xA;&amp;#34;secure_hardware_present&amp;#34;: true&#xA;},&#xA;&amp;#34;actor&amp;#34;: {&#xA;&amp;#34;id&amp;#34;: &amp;#34;00u1qw1mqitPHM8AJ0g7&amp;#34;,&#xA;&amp;#34;type&amp;#34;: &amp;#34;User&amp;#34;,&#xA;&amp;#34;alternateId&amp;#34;: &amp;#34;admin@example.com&amp;#34;,&#xA;&amp;#34;displayName&amp;#34;: &amp;#34;John Doe&amp;#34;&#xA;},&#xA;&amp;#34;outcome&amp;#34;: {&#xA;&amp;#34;result&amp;#34;: &amp;#34;SUCCESS&amp;#34;&#xA;},&#xA;&amp;#34;uuid&amp;#34;: &amp;#34;f790999f-fe87-467a-9880-6982a583986c&amp;#34;,&#xA;&amp;#34;published&amp;#34;: &amp;#34;2017-09-31T22:23:07.777Z&amp;#34;,&#xA;&amp;#34;eventType&amp;#34;: &amp;#34;user.session.start&amp;#34;,&#xA;&amp;#34;displayMessage&amp;#34;: &amp;#34;User login to Okta&amp;#34;,&#xA;&amp;#34;transaction&amp;#34;: {&#xA;&amp;#34;type&amp;#34;: &amp;#34;WEB&amp;#34;,&#xA;&amp;#34;id&amp;#34;: &amp;#34;V04Oy4ubUOc5UuG6s9DyNQAABtc&amp;#34;&#xA;},&#xA;&amp;#34;debugContext&amp;#34;: {&#xA;&amp;#34;debugData&amp;#34;: {&#xA;&amp;#34;requestUri&amp;#34;: &amp;#34;/login/do-login&amp;#34;&#xA;}&#xA;},&#xA;&amp;#34;legacyEventType&amp;#34;: &amp;#34;core.user_auth.login_success&amp;#34;,&#xA;&amp;#34;authenticationContext&amp;#34;: {&#xA;&amp;#34;authenticationStep&amp;#34;: 0,&#xA;&amp;#34;externalSessionId&amp;#34;: &amp;#34;1013FfF-DKQSvCI4RVXChzX-w&amp;#34;&#xA;}&#xA;}&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;h3 id=&#34;challenges-with-log-retrieval&#34;&gt;Challenges with log retrieval&lt;/h3&gt;&#xA;&lt;p&gt;To retrieve these logs, you need an &lt;a href=&#34;https://help.okta.com/en-us/content/topics/security/api.htm?cshid=ext-create-api-token#create-okta-api-token&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;API token&lt;/a&gt;. You can test the API using &lt;code&gt;curl&lt;/code&gt; or similar HTTP clients:&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;button x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;Copy code to clipboard&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;Copy&lt;/span&gt;&#xA;&lt;/button&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;curl -v -X GET \&#xA;-H &amp;#34;Accept: application/json&amp;#34; \&#xA;-H &amp;#34;Content-Type: application/json&amp;#34; \&#xA;-H &amp;#34;Authorization: SSWS ${api_token}&amp;#34; \&#xA;&amp;#34;https://${yourOktaDomain}/api/v1/logs&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;p&gt;Although Okta provides a Go SDK for easier integration, developers still need to write code to fetch and handle the logs, which can be cumbersome and prone to errors. This is where the Okta logs collector shines by automating the entire process.&lt;/p&gt;&#xA;&lt;h3 id=&#34;the-okta-logs-collector-solution&#34;&gt;The Okta logs collector solution&lt;/h3&gt;&#xA;&lt;p&gt;Our &lt;code&gt;okta-logs-collector&lt;/code&gt; application periodically fetches logs from Okta’s System Logs API and sends them to the STDOUT. Our solution works in a containerized environment, in which Alloy can discover Docker Engine, receive container logs, and forward them to Loki. Alternatively, you can pipe the application logs to a file on disk, which can then be monitored and read by Alloy using the &lt;code&gt;loki.source.file&lt;/code&gt; &lt;a href=&#34;/docs/alloy/latest/reference/components/loki.source.file/&#34;&gt;component&lt;/a&gt; and sent to Loki. The containerized solution is shown in the diagram below:&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1771px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&#xA;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/okta-logs-collector/okta-logs-collector-diagram.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/okta-logs-collector/okta-logs-collector-diagram.png&#34;data-srcset=&#34;/media/blog/okta-logs-collector/okta-logs-collector-diagram.png?w=320 320w, /media/blog/okta-logs-collector/okta-logs-collector-diagram.png?w=550 550w, /media/blog/okta-logs-collector/okta-logs-collector-diagram.png?w=750 750w, /media/blog/okta-logs-collector/okta-logs-collector-diagram.png?w=900 900w, /media/blog/okta-logs-collector/okta-logs-collector-diagram.png?w=1040 1040w, /media/blog/okta-logs-collector/okta-logs-collector-diagram.png?w=1240 1240w, /media/blog/okta-logs-collector/okta-logs-collector-diagram.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;Okta logs collector diagram&#34;&#xA;width=&#34;1771&#34;&#xA;height=&#34;571&#34;&#xA;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/okta-logs-collector/okta-logs-collector-diagram.png&#34;&#xA;alt=&#34;Okta logs collector diagram&#34;&#xA;width=&#34;1771&#34;&#xA;height=&#34;571&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;/a&gt;&#xA;&lt;/figure&gt;&#xA;&lt;h2 id=&#34;how-to-use-okta-logs-collector-with-alloy&#34;&gt;How to Use Okta Logs Collector with Alloy&lt;/h2&gt;&#xA;&lt;p&gt;To effectively set up and run the application, it&amp;rsquo;s important to understand the &lt;a href=&#34;https://github.com/grafana/okta-logs-collector/blob/main/examples/cloud-config.alloy&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;example configuration file for Alloy&lt;/a&gt;. Components are the building blocks of Alloy, each handling a specific task such as retrieving logs or sending them to Loki. Reference documentation for each component can be found &lt;a href=&#34;/docs/alloy/latest/reference/components/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;here&lt;/a&gt;. The example configuration file utilizes several components, which are explained below.&lt;/p&gt;&#xA;&lt;h3 id=&#34;component-1-discoverydocker&#34;&gt;Component 1: &lt;code&gt;discovery.docker&lt;/code&gt;&lt;/h3&gt;&#xA;&lt;p&gt;The &lt;code&gt;discovery.docker&lt;/code&gt; &lt;a href=&#34;/docs/alloy/latest/reference/components/discovery.docker/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;component&lt;/a&gt; discovers&lt;a href=&#34;https://docs.docker.com/engine/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt; Docker Engine&lt;/a&gt; containers and exposes them as targets. This assumes that you’re running Docker Engine locally and you have access to the &lt;code&gt;docker.sock&lt;/code&gt; Unix domain socket, which means that you are a member of the &lt;code&gt;docker&lt;/code&gt; group on Linux or you’re running as root.&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;button x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;Copy code to clipboard&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;Copy&lt;/span&gt;&#xA;&lt;/button&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;discovery.docker &amp;#34;containers&amp;#34; {&#xA;host = &amp;#34;unix:///var/run/docker.sock&amp;#34;&#xA;}&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;h3 id=&#34;component-2-lokisourcedocker&#34;&gt;Component 2: &lt;code&gt;loki.source.docker&lt;/code&gt;&lt;/h3&gt;&#xA;&lt;p&gt;The &lt;code&gt;loki.source.docker&lt;/code&gt; &lt;a href=&#34;/docs/alloy/latest/reference/components/loki.source.docker/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;component&lt;/a&gt; reads log entries from Docker containers and forwards them to other &lt;code&gt;loki.*&lt;/code&gt; components. Each component can read from a single Docker daemon. In the following example, we’re using the same &lt;code&gt;docker.sock&lt;/code&gt; as the host that we used in Component 1. The &lt;code&gt;target&lt;/code&gt; is set to discover and collect logs from Docker containers and they will be forwarded to the next component in the chain (using the &lt;code&gt;forward_to&lt;/code&gt; argument): &lt;code&gt;loki.process.grafanacloud.receiver&lt;/code&gt;. This component will apply a single label to all the logs it retrieves and it will collect logs from containers every 10 seconds (default is &lt;code&gt;60s&lt;/code&gt;).&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;button x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;Copy code to clipboard&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;Copy&lt;/span&gt;&#xA;&lt;/button&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;loki.source.docker &amp;#34;default&amp;#34; {&#xA;host = &amp;#34;unix:///var/run/docker.sock&amp;#34;&#xA;targets = discovery.docker.containers.targets&#xA;forward_to = [loki.process.grafanacloud.receiver]&#xA;labels = {&#xA;job = &amp;#34;okta-logs-collector&amp;#34;,&#xA;}&#xA;refresh_interval = &amp;#34;10s&amp;#34;&#xA;}&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;h3 id=&#34;component-3-lokiprocess&#34;&gt;Component 3: &lt;code&gt;loki.process&lt;/code&gt;&lt;/h3&gt;&#xA;&lt;p&gt;The &lt;code&gt;loki.process&lt;/code&gt; &lt;a href=&#34;/docs/alloy/latest/reference/components/loki.process/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;component&lt;/a&gt; receives log entries from other Loki components. It then processes them through various &amp;ldquo;stages&amp;rdquo; and forwards the processed logs to specified receivers. Each stage within a &lt;code&gt;loki.process&lt;/code&gt; block can parse, transform, and filter log entries. The stages in this pipeline perform the following actions:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;Filter logs&lt;/strong&gt; to only include those from the &lt;code&gt;okta-logs-collector&lt;/code&gt; job.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Extract fields&lt;/strong&gt; (&lt;code&gt;eventType&lt;/code&gt;, &lt;code&gt;level&lt;/code&gt;, &lt;code&gt;timestamp&lt;/code&gt;) from JSON-formatted log lines.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Set the log timestamp&lt;/strong&gt; using the extracted &lt;code&gt;timestamp&lt;/code&gt; field, formatted in &lt;a href=&#34;https://www.rfc-editor.org/rfc/rfc3339.html&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;RFC3339&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Assign extracted fields&lt;/strong&gt; (&lt;code&gt;eventType&lt;/code&gt; and &lt;code&gt;level&lt;/code&gt;) as Loki labels for indexing and querying. The &lt;code&gt;level&lt;/code&gt; effectively replaces Loki log level.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;button x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;Copy code to clipboard&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;Copy&lt;/span&gt;&#xA;&lt;/button&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;loki.process &amp;#34;grafanacloud&amp;#34; {&#xA;forward_to = [loki.write.grafanacloud.receiver]&#xA;stage.match {&#xA;// Match only logs from the okta-logs-collector job&#xA;selector = &amp;#34;{job=\&amp;#34;okta-logs-collector\&amp;#34;}&amp;#34;&#xA;// Extract important labels and the timestamp from the log line&#xA;// and map them to Loki labels&#xA;stage.json {&#xA;expressions = {&#xA;eventType = &amp;#34;event.eventType&amp;#34;,&#xA;level = &amp;#34;event.severity&amp;#34;,&#xA;timestamp = &amp;#34;time&amp;#34;,&#xA;}&#xA;}&#xA;// Use the timestamp from the log line as the Loki timestamp&#xA;stage.timestamp {&#xA;source = &amp;#34;timestamp&amp;#34;&#xA;format = &amp;#34;RFC3339&amp;#34;&#xA;}&#xA;// Use the extracted labels as the Loki labels for indexing.&#xA;// These labels can be used as stream selectors in LogQL.&#xA;stage.labels {&#xA;values = {&#xA;eventType = &amp;#34;&amp;#34;,&#xA;level = &amp;#34;&amp;#34;,&#xA;}&#xA;}&#xA;}&#xA;}&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;h3 id=&#34;component-4-lokiwrite&#34;&gt;Component 4: &lt;code&gt;loki.write&lt;/code&gt;&lt;/h3&gt;&#xA;&lt;p&gt;The &lt;code&gt;loki.write&lt;/code&gt; &lt;a href=&#34;/docs/alloy/latest/reference/components/loki.write/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;component&lt;/a&gt; receives log entries from other loki components — the last three we just discussed, to be exact — and sends them to Loki using the &lt;code&gt;logproto&lt;/code&gt; &lt;a href=&#34;https://github.com/grafana/loki/blob/main/pkg/logproto/logproto.proto&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;format&lt;/a&gt;. The example uses a &lt;a href=&#34;/docs/grafana-cloud/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt; endpoint with basic authentication.&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;button x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;Copy code to clipboard&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;Copy&lt;/span&gt;&#xA;&lt;/button&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;loki.write &amp;#34;grafanacloud&amp;#34; {&#xA;endpoint {&#xA;url = &amp;#34;https://&amp;lt;subdomain&amp;gt;.grafana.net/loki/api/v1/push&amp;#34;&#xA;basic_auth {&#xA;username = &amp;#34;&amp;lt;Your Grafana.com User ID&amp;gt;&amp;#34;&#xA;password = &amp;#34;&amp;lt;Your Grafana.com API Token&amp;gt;&amp;#34;&#xA;}&#xA;}&#xA;}&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;p&gt;Environment variables can also be used to set the username and password (or even the URL):&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;button x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;Copy code to clipboard&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;Copy&lt;/span&gt;&#xA;&lt;/button&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;basic_auth {&#xA;username = env(&amp;#34;GRAFANA_CLOUD_USER_ID&amp;#34;)&#xA;password = env(&amp;#34;GRAFANA_CLOUD_API_KEY&amp;#34;)&#xA;}&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;p&gt;This configuration effectively sets up a pipeline for discovering Docker containers, collecting and processing their logs, and sending the processed logs to Grafana Cloud Logs, which is powered by Loki.&lt;/p&gt;&#xA;&lt;h2 id=&#34;set-up-and-run-okta-logs-collector&#34;&gt;Set up and run Okta logs collector&lt;/h2&gt;&#xA;&lt;p&gt;Having grasped the Alloy configuration, you&amp;rsquo;re ready to set up and run the Okta logs collector.&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;Sign in to Okta&lt;/strong&gt;. Log in to your Okta account as an administrator.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Create API Token&lt;/strong&gt;. Create a new &lt;a href=&#34;https://help.okta.com/en-us/content/topics/security/api.htm?cshid=ext-create-api-token#create-okta-api-token&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;API token&lt;/a&gt; for accessing the &lt;a href=&#34;https://developer.okta.com/docs/reference/api/system-log/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;System Logs API&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Set Environment Variables.&lt;/strong&gt; Configure the necessary environment variables in your shell:&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;button x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;Copy code to clipboard&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;Copy&lt;/span&gt;&#xA;&lt;/button&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;export OKTA_URL=&amp;#34;https://&amp;lt;account&amp;gt;.okta.com&amp;#34;&#xA;export OKTA_API_TOKEN=&amp;#34;your-api-token&amp;#34;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;ol start=&#34;4&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Run Okta logs collector&lt;/strong&gt;. Use Docker to run the Okta logs collector container. You can also run it in Kubernetes.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;button x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;Copy code to clipboard&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;Copy&lt;/span&gt;&#xA;&lt;/button&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;docker run --name okta-logs-collector \&#xA;-e OKTA_URL=${OKTA_URL} \&#xA;-e API_KEY=${OKTA_API_TOKEN} \&#xA;-e LOOKBACK_INTERVAL=24h \ # Defaults to 1h&#xA;-e POLL_INTERVAL=10s \&#xA;-e LOG_LEVEL=info \&#xA;grafana/okta-logs-collector:latest poll&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;ol start=&#34;5&#34;&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Download configuration files.&lt;/strong&gt; Obtain the &lt;a href=&#34;https://github.com/grafana/okta-logs-collector/tree/main/examples&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;example configuration files&lt;/a&gt; and place them in a convenient location. Note that the Alloy configuration sends all Docker logs to Loki, so you should consider &lt;a href=&#34;/docs/alloy/latest/reference/components/discovery.docker/?pg=blog&amp;amp;plcmt=body-txt#filter-block&#34;&gt;filtering the logs&lt;/a&gt; using the container name.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Use Loki on Grafana Cloud or run Loki&lt;/strong&gt; &lt;strong&gt;on-premises.&lt;/strong&gt; Locate your Grafana Cloud stack and &lt;a href=&#34;/docs/grafana-cloud/account-management/cloud-stacks/?pg=blog&amp;amp;plcmt=body-txt#find-instance-endpoints&#34;&gt;find your Loki instance endpoint&lt;/a&gt;. (If you don&amp;rsquo;t already use Grafana Cloud, you can sign up for a &lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;forever-free account&lt;/a&gt; today.) Alternatively, &lt;a href=&#34;https://github.com/grafana/okta-logs-collector/blob/main/examples/loki.yaml&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;an example configuration file&lt;/a&gt; is provided for Loki if you want to run Loki on-premises.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Configure Alloy&lt;/strong&gt;. If you’re using Grafana Cloud Logs, follow these steps.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Use the &lt;a href=&#34;https://github.com/grafana/okta-logs-collector/blob/main/examples/cloud-config.alloy&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;provided example configuration&lt;/a&gt; and replace these placeholders with actual values: &lt;code&gt;&amp;lt;subdomain&amp;gt;&lt;/code&gt;, &lt;code&gt;&amp;lt;Your Grafana.com User ID&amp;gt;&lt;/code&gt;, and &lt;code&gt;&amp;lt;Your Grafana.com API Token&amp;gt;&lt;/code&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Generate an &lt;a href=&#34;http://Grafana.com&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;API token&lt;/a&gt; to access and push logs to your Loki instance.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Run Alloy&lt;/strong&gt;. Download, unpack and run &lt;a href=&#34;https://github.com/grafana/alloy/releases/latest&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;the latest version of Alloy&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;If you’re using Grafana Cloud Logs, use &lt;code&gt;cloud-config.alloy&lt;/code&gt; instead. The details of how the example configuration files are structured are explained in the previous section.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;button x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;Copy code to clipboard&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;Copy&lt;/span&gt;&#xA;&lt;/button&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;./alloy-linux-amd64 run /absolute/path/to/config.alloy&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;h2 id=&#34;how-to-observe-logs-in-loki-and-grafana&#34;&gt;How to observe logs in Loki and Grafana&lt;/h2&gt;&#xA;&lt;p&gt;After a few moments, you should see logs appearing in Loki. Use the Loki LogCLI or its data source in Grafana to view and analyze the logs. If you are using Grafana Cloud, go to the Grafana Cloud portal and launch Grafana. From the right menu, navigate to &lt;strong&gt;Connections&lt;/strong&gt; &amp;gt; &lt;strong&gt;Data Sources,&lt;/strong&gt; where you will see that Loki is already added as a data source. Navigate to the &lt;strong&gt;Explore&lt;/strong&gt; page and start querying your Okta logs using the &lt;code&gt;{job=&amp;quot;okta-logs-collector&amp;quot;}&lt;/code&gt; stream selector. The &lt;code&gt;eventType&lt;/code&gt; field is indexed, allowing you to filter specific event types. A complete list of Okta event types (more than 930 as of now) can be found &lt;a href=&#34;https://developer.okta.com/docs/reference/api/event-types/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1999px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&#xA;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/okta-logs-collector/okta-logs-loki-monitor.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/okta-logs-collector/okta-logs-loki-monitor.png&#34;data-srcset=&#34;/media/blog/okta-logs-collector/okta-logs-loki-monitor.png?w=320 320w, /media/blog/okta-logs-collector/okta-logs-loki-monitor.png?w=550 550w, /media/blog/okta-logs-collector/okta-logs-loki-monitor.png?w=750 750w, /media/blog/okta-logs-collector/okta-logs-loki-monitor.png?w=900 900w, /media/blog/okta-logs-collector/okta-logs-loki-monitor.png?w=1040 1040w, /media/blog/okta-logs-collector/okta-logs-loki-monitor.png?w=1240 1240w, /media/blog/okta-logs-collector/okta-logs-loki-monitor.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;Log volume dashboard in Loki&#34;&#xA;width=&#34;1999&#34;&#xA;height=&#34;860&#34;&#xA;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/okta-logs-collector/okta-logs-loki-monitor.png&#34;&#xA;alt=&#34;Log volume dashboard in Loki&#34;&#xA;width=&#34;1999&#34;&#xA;height=&#34;860&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;/a&gt;&#xA;&lt;/figure&gt;&#xA;&lt;h2 id=&#34;how-to-use-sigma-rules-for-detecting-critical-log-lines&#34;&gt;How to use Sigma rules for detecting critical log lines&lt;/h2&gt;&#xA;&lt;p&gt;Ingesting logs into Loki is only half the equation; the other half is detecting critical log lines. These log lines provide crucial evidence, such as identifying whether corporate accounts have been compromised. While you can always write your own LogQL queries to detect specific issues, there are more efficient methods. One such method is leveraging the Sigma ecosystem, which offers an abundant set of declarative rules for discovering these pieces of evidence.&lt;/p&gt;&#xA;&lt;p&gt;Fortunately, the security operations team has developed a backend for &lt;a href=&#34;https://sigmahq.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Sigma&lt;/a&gt; that converts Sigma rules into Loki queries (LogQL queries). You can leverage &lt;a href=&#34;https://github.com/SigmaHQ/sigma/tree/master/rules/cloud/okta&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;existing Sigma rules for Okta&lt;/a&gt; to detect critical log lines and set alerts to monitor these events. Follow the instructions provided in &lt;a href=&#34;/blog/2022/12/15/a-guide-to-cyber-threat-hunting-with-promtail-grafana-loki-sigma-and-grafana-cloud/&#34;&gt;this blog post&lt;/a&gt; to install Sigma CLI and its plugins and to convert Sigma rules into LogQL queries.&lt;/p&gt;&#xA;&lt;p&gt;Also, you can continuously validate your Sigma rules against the &lt;a href=&#34;https://github.com/SigmaHQ/sigma-specification/blob/main/sigma-schema.json&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Sigma JSON Schema&lt;/a&gt; by utilizing the &lt;a href=&#34;https://github.com/SigmaHQ/sigma-rules-validator&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;sigma-rules-validator&lt;/a&gt; GitHub Action. Follow the instructions in &lt;a href=&#34;/blog/2024/03/25/how-to-validate-sigma-rules-with-github-actions-for-improved-security-monitoring/&#34;&gt;this blog post&lt;/a&gt; to learn more about the action and how to use it.&lt;/p&gt;&#xA;&lt;h2 id=&#34;whats-next&#34;&gt;What’s next&lt;/h2&gt;&#xA;&lt;p&gt;We hope this project can help you monitor your Okta logs more easily, but we&amp;rsquo;re not done yet. Stay tuned for version 2 of the Okta logs collector, which we&amp;rsquo;re developing as an Alloy component. This new version will offer advanced capabilities and seamless integration with Alloy components to better meet your logging needs.&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;/products/cloud/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Cloud &lt;/a&gt;is the easiest way to get started with metrics, logs, traces, dashboards, and more. We have a generous forever-free tier and plans for every use case. &lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Sign up for free now!&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;】&lt;p&gt;Okta 等身份提供商 (IdP) 通过为访问组织资源的用户提供无缝身份验证和授权体验，在企业环境中发挥着至关重要的作用。这些交互会生成大量事件日志，其中包含用户详细信息、地理位置、IP 地址等有价值的信息。&lt;/p&gt;&#xA;&lt;p&gt;这些日志对于安全团队至关重要，尤其是在运营中，因为它们用于有效检测和响应事件。然而，将这些日志集成到日志记录和 SIEM 平台可能具有挑战性。&lt;/p&gt;&#xA;&lt;p&gt;在这篇博文中，我们将向您展示如何有效设置和运行 Okta 日志收集器，以将日志发送到 &lt;a href=&#34;/oss/loki/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana Loki &lt;/a&gt; 本地或云中的实例。通过配置环境变量，运行 Okta 日志收集器 Docker 容器，并利用最新版本的 Loki 和 &lt;a href=&#34;/oss/alloy-opentelemetry-collector/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana Alloy&lt;/ a&gt;，您可以监控、分析 Okta 日志并设置警报，以获得更深入的见解并提高系统安全性和操作能力。&lt;/p&gt;&#xA;&lt;h2 id=&#34;why-we-development-the-okta-logs-collector&#34;&gt;我们为何开发 Okta 日志收集器&lt;/h2&gt;&#xA;&lt;p&gt;许多 IdP 提供用于获取事件日志的 REST API，其中 &lt;a href=&#34;https://developer.okta.com/docs/reference/api/system-log/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer &#34;&gt;Okta 的系统日志 API&lt;/a&gt; 提供 JSON 格式的日志，如下所示。然而，将这些日志集成到现有系统中通常涉及一个复杂且耗时的过程，通常需要使用 Go 等编程语言通过 HTTP 客户端库编写自定义代码来访问日志。&lt;/p&gt;&#xA;&lt;p&gt;为了简化和简化此过程，我们开发了&lt;a href=&#34;https://github.com/grafana/okta-logs-collector&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Okta 日志收集器&lt; /a&gt;.该工具可以自动从 Okta System Log API 检索日志，丰富数据，并将其发送到 STDOUT，从而可以使用 Alloy 或 Promtail 等代理轻松抓取日志并将其转发到 Loki 等可观察平台。&lt;/p&gt;&#xA;&lt;p&gt;为了进一步说明我们构建 Okta 日志收集器的原因，让我们简要了解一下开发人员在获取事件日志时面临的挑战以及我们如何尝试解决这些挑战。&lt;/p&gt;&#xA;&lt;h3 id=&#34;json-log-event-example&#34;&gt;JSON 日志事件示例&lt;/h3&gt;&#xA;&lt;p&gt;以下是 Okta 系统日志 API 生成的 JSON 格式日志事件的示例：&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet&#34;&gt;&lt;div class=&#34;lang-toolbar&#34;&gt;&#xA;&lt;span class=&#34;lang-toolbar__item&#34;&gt;JavaScript&lt;/span&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;按钮 x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;将代码复制到剪贴板&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;复制&lt;/span&gt;&#xA;&lt;/按钮&gt;&#xA;&lt;/span&gt;&#xA;&lt;div class=&#34;lang-toolbar__border&#34;&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;cod电子片段&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-javascript&#34;&gt;{&#xA;“版本”：“0”，&#xA;“严重性”：“信息”，&#xA;“客户”： {&#xA;“区域”：“OFF_NETWORK”，&#xA;“设备”：“未知”，&#xA;“用户代理”：{&#xA;&#34;os&#34;: &#34;未知&#34;,&#xA;“浏览器”：“未知”，&#xA;&#34;rawUserAgent&#34;: &#34;未知-下载&#34;&#xA;},&#xA;“ip地址”：“12.97.85.90”&#xA;},&#xA;“设备”： {&#xA;&#34;id&#34;: &#34;guob5wtu7rBggkg9G1d7&#34;,&#xA;“名称”：“MacBookPro16,1”，&#xA;“os_platform”：“OSX”，&#xA;&#34;os_version&#34;: &#34;14.3.0&#34;,&#xA;“托管”：假，&#xA;“已注册”：真实，&#xA;“device_integrator”：空，&#xA;&#34;disk_encryption_type&#34;: &#34;ALL_INTERNAL_VOLUMES&#34;,&#xA;&#34;screen_lock_type&#34;: &#34;生物识别&#34;,&#xA;“越狱”：空，&#xA;“secure_hardware_present”：true&#xA;},&#xA;“演员”：{&#xA;“id”：“00u1qw1mqitPHM8AJ0g7”，&#xA;“类型”：“用户”，&#xA;“alternateId”：“admin@example.com”，&#xA;“显示名称”：“约翰·多伊”&#xA;},&#xA;“结果”： {&#xA;“结果”：“成功”&#xA;},&#xA;“uuid”：“f790999f-fe87-467a-9880-6982a583986c”，&#xA;“已发布”：“2017-09-31T22：23：07.777Z”，&#xA;&#34;eventType&#34;: &#34;user.session.start&#34;,&#xA;&#34;displayMessage&#34;: &#34;用户登录 Okta&#34;,&#xA;“交易”： {&#xA;“类型”：“网络”，&#xA;“id”：“V04Oy4ubUOc5UuG6s9DyNQAABtc”&#xA;},&#xA;“调试上下文”：{&#xA;“调试数据”：{&#xA;&#34;requestUri&#34;: &#34;/登录/do-login&#34;&#xA;}&#xA;},&#xA;&#34;legacyEventType&#34;: &#34;core.user_auth.login_success&#34;,&#xA;“身份验证上下文”：{&#xA;“身份验证步骤”：0，&#xA;“externalSessionId”：“1013FfF-DKQSvCI4RVXChzX-w”&#xA;}&#xA;}&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;h3 id=&#34;challenges-with-log-retrieval&#34;&gt;日志检索的挑战&lt;/h3&gt;&#xA;&lt;p&gt;要检索这些日志，您需要 &lt;a href=&#34;https://help.okta.com/en-us/content/topics/security/api.htm?cshid=ext-create-api-token# create-okta-api-token&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;API 令牌&lt;/a&gt;。您可以使用 &lt;code&gt;curl&lt;/code&gt; 或类似的 HTTP 客户端测试 API：&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;按钮 x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;将代码复制到剪贴板&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;复制&lt;/span&gt;&#xA;&lt;/按钮&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;curl -v -X GET \&#xA;-H“接受：application/json”\&#xA;-H“内容类型：application/json”\&#xA;-H“授权：SSWS ${api_token}”\&#xA;“https://${yourOktaDomain}/api/v1/logs&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;p&gt;虽然 Okta 提供了 Go SDK 以便于集成，但开发人员仍然需要编写代码来获取和处理日志，这可能会很麻烦rsome并且容易出错。这就是 Okta 日志收集器通过自动化整个过程而大放异彩的地方。&lt;/p&gt;&#xA;&lt;h3 id=&#34;the-okta-logs-collector-solution&#34;&gt;Okta 日志收集器解决方案&lt;/h3&gt;&#xA;&lt;p&gt;我们的 &lt;code&gt;okta-logs-collector&lt;/code&gt; 应用程序定期从 Okta 的系统日志 API 获取日志并将其发送到 STDOUT。我们的解决方案在容器化环境中运行，Alloy 可以在其中发现 Docker 引擎、接收容器日志并将其转发给 Loki。或者，您可以将应用程序日志通过管道传输到磁盘上的文件，然后 Alloy 可以使用 &lt;code&gt;loki.source.file&lt;/code&gt; &lt;a href=&#34;/docs/alloy/latest/reference 来监视和读取该文件/components/loki.source.file/&#34;&gt;组件&lt;/a&gt; 并发送给 Loki。容器化方案如下图所示：&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1771px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&#xA;&lt;一&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/okta-logs-collector/okta-logs-collector-diagram.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/blog/okta-logs-collector/okta-logs-collector-diagram.png&#34;data-srcset=&#34;/media/blog/okta-logs-collector/okta-logs-collector-diagram. png?w=320 320w，/media/blog/okta-logs-collector/okta-logs-collector-diagram.png?w=550 550w，/media/blog/okta-logs-collector/okta-logs-collector-图.png?w=750 750w, /media/blog/okta-logs-collector/okta-logs-collector-diagram.png?w=900 900w, /media/blog/okta-logs-collector/okta-logs- Collector-diagram.png?w=1040 1040w, /media/blog/okta-logs-collector/okta-logs-collector-diagram.png?w=1240 1240w, /media/blog/okta-logs-collector/okta-日志收集器图.png?w=1920 1920w&#34;&#xA;data-size=&#34;auto&#34;alt=&#34;Okta 日志收集器图&#34;&#xA;宽度=“1771”&#xA;高度=“571”&#xA;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/okta-logs-collector/okta-logs-collector-diagram.png”&#xA;alt=&#34;Okta 日志收集器图&#34;&#xA;宽度=“1771”&#xA;高度=“571”&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;/a&gt;&#xA;&lt;/图&gt;&#xA;&lt;h2 id=&#34;how-to-use-okta-logs-collector-with-alloy&#34;&gt;如何将 Okta 日志收集器与 Alloy 结合使用&lt;/h2&gt;&#xA;&lt;p&gt;要有效地设置和运行应用程序，了解 &lt;a href=&#34;https://github.com/grafana/okta-logs-collector/blob/main/examples/cloud-config.alloy&#34; 非常重要target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Alloy 的示例配置文件&lt;/a&gt;。组件是 Alloy 的构建块，每个组件处理特定的任务，例如检索日志或将其发送给 Loki。每个组件的参考文档可以在&lt;a href=&#34;/docs/alloy/latest/reference/components/?pg=blog&amp;plcmt=body-txt&#34;&gt;此处&lt;/a&gt;找到。示例配置文件使用了多个组件，如下所述。&lt;/p&gt;&#xA;&lt;h3 id=&#34;component-1-discoverydocker&#34;&gt;组件 1：&lt;code&gt;discovery.docker&lt;/code&gt;&lt;/h3&gt;&#xA;&lt;p&gt;&lt;code&gt;discovery.docker&lt;/code&gt;&lt;a href=&#34;/docs/alloy/latest/reference/components/discovery.docker/?pg=blog&amp;plcmt=body-txt&#34;&gt;组件&lt;/a&gt;发现&lt;一个小时ref=&#34;https://docs.docker.com/engine/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Docker Engine&lt;/a&gt; 容器并将它们公开为目标。这假设您在本地运行 Docker 引擎，并且您可以访问 docker.sock Unix 域套接字，这意味着您是 Linux 上 docker 组的成员或者您以 root 身份运行。&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;按钮 x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;将代码复制到剪贴板&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;复制&lt;/span&gt;&#xA;&lt;/按钮&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;discovery.docker“容器”{&#xA;主机=“unix:///var/run/docker.sock”&#xA;}&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;h3 id=&#34;component-2-lokisourcedocker&#34;&gt;组件 2：&lt;code&gt;loki.source.docker&lt;/code&gt;&lt;/h3&gt;&#xA;&lt;p&gt;&lt;code&gt;loki.source.docker&lt;/code&gt; &lt;a href=&#34;/docs/alloy/latest/reference/components/loki.source.docker/?pg=blog&amp;plcmt=body-txt&#34;&gt;组件&lt; /a&gt; 从 Docker 容器读取日志条目并将其转发到其他 &lt;code&gt;loki.*&lt;/code&gt; 组件。每个组件都可以从单个 Docker 守护进程读取。在以下示例中，我们使用与组件 1 中使用的主机相同的 &lt;code&gt;docker.sock&lt;/code&gt;。&lt;code&gt;target&lt;/code&gt; 设置为从 Docker 容器发现并收集日志它们将被转发到链中的下一个组件（使用 &lt;code&gt;forward_to&lt;/code&gt; 参数）：&lt;code&gt;loki.process.grafanacloud.receiver&lt;/code&gt;。该组件将向其检索的所有日志应用单个标签，并且每 10 秒从容器收集一次日志（默认为 &lt;code&gt;60s&lt;/code&gt;）。&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;按钮 x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;将代码复制到剪贴板&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;复制&lt;/span&gt;&#xA;&lt;/按钮&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;loki.source.docker“默认”{&#xA;主机=“unix:///var/run/docker.sock”&#xA;目标= discovery.docker.containers.targets&#xA;forward_to = [loki.process.grafanacloud.receiver]&#xA;标签={&#xA;工作=“okta-logs-collector”，&#xA;}&#xA;刷新间隔=“10秒”&#xA;}&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;h3 id=&#34;component-3-lokiprocess&#34;&gt;组件 3：&lt;code&gt;loki.process&lt;/code&gt;&lt;/h3&gt;&#xA;&lt;p&gt;&lt;code&gt;loki.process&lt;/code&gt; &lt;a href=&#34;/docs/alloy/latest/reference/components/loki.process/?pg=blog&amp;plcmt=body-txt&#34;&gt;组件&lt;/a&gt;接收来自其他 Loki 组件的日志条目。然后，它通过各个“阶段”处理它们，并将处理后的日志转发到指定的接收者。每个阶段有&lt;code&gt;loki.process&lt;/code&gt; 块可以解析、转换和过滤日志条目。此管道中的阶段执行以下操作：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;过滤日志&lt;/strong&gt;以仅包含来自 &lt;code&gt;okta-logs-collector&lt;/code&gt; 作业的日志。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;从 JSON 格式的日志行中提取字段&lt;/strong&gt;（&lt;code&gt;eventType&lt;/code&gt;、&lt;code&gt;level&lt;/code&gt;、&lt;code&gt;timestamp&lt;/code&gt;）。&lt;/li &gt;&#xA;&lt;li&gt;&lt;strong&gt;使用提取的&lt;code&gt;timestamp&lt;/code&gt;字段设置日志时间戳&lt;/strong&gt;，格式为&lt;a href=&#34;https://www.rfc-editor.org/rfc/rfc3339。 html&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;RFC3339&lt;/a&gt;。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;将提取的字段&lt;/strong&gt;（&lt;code&gt;eventType&lt;/code&gt; 和 &lt;code&gt;level&lt;/code&gt;）分配为用于索引和查询的 Loki 标签。 &lt;code&gt;级别&lt;/code&gt;有效地取代了Loki日志级别。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;按钮 x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;将代码复制到剪贴板&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;复制&lt;/span&gt;&#xA;&lt;/按钮&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;loki.process &#34;grafanacloud&#34; {&#xA;forward_to = [loki.write.grafanacloud.receiver]&#xA;阶段.匹配{&#xA;// 仅匹配来自 okta-logs-collector 作业的日志&#xA;选择器 = &#34;{job=\&#34;okta-logs-collector\&#34;}&#34;&#xA;// 从日志行中提取重要标签和时间戳&#xA;// 并将它们映射到 Loki 标签&#xA;阶段.json {&#xA;表达式 = {&#xA;eventType = &#34;事件.eventType&#34;,&#xA;level = &#34;事件.严重性&#34;,&#xA;时间戳=“时间”，&#xA;}&#xA;}&#xA;// 使用日志行中的时间戳作为 Loki 时间戳&#xA;阶段.时间戳{&#xA;来源=“时间戳”&#xA;格式=“RFC3339”&#xA;}&#xA;// 使用提取的标签作为 Loki 标签进行索引。&#xA;// 这些标签可以用作 LogQL 中的流选择器。&#xA;阶段.标签{&#xA;值={&#xA;事件类型 = &#34;&#34;,&#xA;级别=“”，&#xA;}&#xA;}&#xA;}&#xA;}&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;h3 id=&#34;component-4-lokiwrite&#34;&gt;组件 4：&lt;code&gt;loki.write&lt;/code&gt;&lt;/h3&gt;&#xA;&lt;p&gt;&lt;code&gt;loki.write&lt;/code&gt; &lt;a href=&#34;/docs/alloy/latest/reference/components/loki.write/?pg=blog&amp;plcmt=body-txt&#34;&gt;组件&lt;/a&gt;接收来自其他 Loki 组件的日志条目（确切地说是我们刚刚讨论的最后三个组件），并使用 &lt;code&gt;logproto&lt;/code&gt; &lt;a href=&#34;https://github.com/grafana/loki/ 将它们发送到 Loki blob/main/pkg/logproto/logproto.proto&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;格式&lt;/a&gt;。该示例使用具有基本身份验证的 &lt;a href=&#34;/docs/grafana-cloud/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt; 端点。&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;按钮 x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;将代码复制到剪贴板“宽度=“14”高度=“13”&gt;&#xA;&lt;span&gt;复制&lt;/span&gt;&#xA;&lt;/按钮&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;loki.write &#34;grafanacloud&#34; {&#xA;端点{&#xA;url = &#34;https://&lt;子域名&gt;.grafana.net/loki/api/v1/push&#34;&#xA;基本身份验证{&#xA;username = &#34;&lt;您的 Grafana.com 用户 ID&gt;&#34;&#xA;密码 =“&lt;您的 Grafana.com API 令牌&gt;”&#xA;}&#xA;}&#xA;}&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;p&gt;环境变量还可以用于设置用户名和密码（甚至 URL）：&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;按钮 x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;将代码复制到剪贴板&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;复制&lt;/span&gt;&#xA;&lt;/按钮&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;basic_auth {&#xA;用户名 = env(&#34;GRAFANA_CLOUD_USER_ID&#34;)&#xA;密码 = env(&#34;GRAFANA_CLOUD_API_KEY&#34;)&#xA;}&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;p&gt;此配置有效地设置了一个管道，用于发现 Docker 容器、收集和处理其日志，并将处理后的日志发送到由 Loki 提供支持的 Grafana Cloud Logs。&lt;/p&gt;&#xA;&lt;h2 id=&#34;set-up-and-run-okta-logs-collector&#34;&gt;设置并运行 Okta 日志收集器&lt;/h2&gt;&#xA;&lt;p&gt;掌握 Alloy 配置后，您就可以设置并运行 Okta 日志收集器了。&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;登录 Okta&lt;/strong&gt;。以管理员身份登录您的 Okta 帐户。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;创建 API 令牌&lt;/strong&gt;。创建一个新的 &lt;a href=&#34;https://help.okta.com/en-us/content/topics/security/api.htm?cshid=ext-create-api-token#create-okta-api-token&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;API 令牌&lt;/a&gt;，用于访问 &lt;a href=&#34;https://developer.okta.com/docs/reference/api/system-log/&#34; target=&#34; _blank&#34; rel=&#34;noopener noreferrer&#34;&gt;系统日志 API&lt;/a&gt;。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;设置环境变量。&lt;/strong&gt;在 shell 中配置必要的环境变量：&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;按钮 x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;将代码复制到剪贴板&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;复制&lt;/span&gt;&#xA;&lt;/按钮&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;导出 OKTA_URL=&#34;https://&lt;account&gt;.okta.com&#34;&#xA;导出 OKTA_API_TOKEN=&#34;your-api-token&#34;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;ol开始=“4”&gt;&#xA;&lt;li&gt;&lt;strong&gt;运行 Okta 日志收集器&lt;/strong&gt;。使用 Docker 运行 Okta 日志收集器容器。您也可以在 Kubernetes 中运行它。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;按钮n x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;将代码复制到剪贴板&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;复制&lt;/span&gt;&#xA;&lt;/按钮&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;docker run --name okta-logs-collector \&#xA;-e OKTA_URL=${OKTA_URL} \&#xA;-e API_KEY=${OKTA_API_TOKEN} \&#xA;-e LOOKBACK_INTERVAL=24h \ # 默认为 1h&#xA;-e POLL_INTERVAL=10s \&#xA;-e LOG_LEVEL=信息 \&#xA;grafana/okta-logs-collector:最新民意调查&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;ol开始=“5”&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;下载配置文件。&lt;/strong&gt;获取&lt;a href=&#34;https://github.com/grafana/okta-logs-collector/tree/main/examples&#34; target=&#34;_blank&#34; rel= “noopener noreferrer&#34;&gt;示例配置文件&lt;/a&gt;并将它们放在方便的位置。请注意，Alloy 配置将所有 Docker 日志发送到 Loki，因此您应该考虑 &lt;a href=&#34;/docs/alloy/latest/reference/components/discovery.docker/?pg=blog&amp;plcmt=body-txt#filter-block&#34;&gt;使用容器名称过滤日志&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;在 Grafana Cloud 上使用 Loki 或在本地运行 Loki&lt;/strong&gt; &lt;strong&gt;本地部署。&lt;/strong&gt;找到您的 Grafana Cloud 堆栈并&lt;a href=&#34;/docs/grafana-cloud/account-management /cloud-stacks/?pg=blog&amp;plcmt=body-txt#find-instance-endpoints&#34;&gt;查找您的 Loki 实例端点&lt;/a&gt;。 （如果您尚未使用 Grafana Cloud，可以注册一个&lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;plcmt=body-txt&#34;&gt;永久免费帐户&lt;/a &gt; 今天。）或者，&lt;a href=&#34;https://github.com/grafana/okta-logs-collector/blob/main/examples/loki.yaml&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;an如果您想在本地运行 Loki，则为 Loki 提供示例配置文件&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;配置合金&lt;/strong&gt;。如果您使用 Grafana Cloud Logs，请按照以下步骤操作。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;使用&lt;a href=&#34;https://github.com/grafana/okta-logs-collector/blob/main/examples/cloud-config.alloy&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;提供的示例配置&lt;/a&gt;，并将这些占位符替换为实际值：&lt;code&gt;&lt;subdomain&gt;&lt;/code&gt;、&lt;code&gt;&lt;Your Grafana.com User ID&gt;&lt;/code&gt; 和 &lt;code&gt;&lt;Your Grafana.com User ID&gt;&lt;/code&gt;。 com API 令牌&gt;&lt;/code&gt;。&lt;/li&gt;&#xA;&lt;li&gt;生成 &lt;a href=&#34;http://Grafana.com&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;API 令牌&lt;/a&gt;以访问日志并将日志推送到您的 Loki 实例。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;运行合金&lt;/strong&gt;。下载、解压并运行&lt;a href=&#34;https://github.com/grafana/alloy/releases/latest&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;最新版本的 Alloy&lt;/a&gt;。&lt;/ p&gt;&#xA;&lt;p&gt;如果您使用 Grafana Cloud Logs，请改用 &lt;code&gt;cloud-config.alloy&lt;/code&gt;。上一节解释了示例配置文件的结构细节。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;按钮x-data =“app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;将代码复制到剪贴板&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;复制&lt;/span&gt;&#xA;&lt;/按钮&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;./alloy-linux-amd64 run /absolute/path/to/config.alloy&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;h2 id=&#34;how-to-observe-logs-in-loki-and-grafana&#34;&gt;如何在 Loki 和 Grafana 中观察日志&lt;/h2&gt;&#xA;&lt;p&gt;过了一会儿，您应该会看到 Loki 中出现日志。使用 Loki LogCLI 或其在 Grafana 中的数据源来查看和分析日志。如果您使用 Grafana Cloud，请转至 Grafana Cloud 门户并启动 Grafana。从右侧菜单中，导航至&lt;strong&gt;连接&lt;/strong&gt; &gt; &lt;strong&gt;数据源&lt;/strong&gt;，您将在其中看到 Loki 已添加为数据源。导航到&lt;strong&gt;探索&lt;/strong&gt;页面并开始使用&lt;code&gt;{job=&#34;okta-logs-collector&#34;}&lt;/code&gt;流选择器查询您的Okta日志。 &lt;code&gt;eventType&lt;/code&gt; 字段已建立索引，允许您过滤特定的事件类型。可以找到 Okta 事件类型的完整列表（截至目前超过 930 种） &lt;a href=&#34;https://developer.okta.com/docs/reference/api/event-types/&#34; target=&#34;_blank&#34; rel =&#34;noopener noreferrer&#34;&gt;这里&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1999px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&#xA;&lt;一&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/okta-logs-collector/okta-logs-loki-monitor.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/blog/okta-logs-collector/okta-logs-loki-monitor.png&#34;data-srcset=&#34;/media/blog/okta-logs-collector/okta-logs-loki-monitor.png png?w=320 320w，/media/blog/okta-logs-collector/okta-logs-loki-monitor.png?w=550 550w，/media/blog/okta-logs-collector/okta-logs-loki- Monitor.png?w=750 750w, /media/blog/okta-logs-collector/okta-logs-loki-monitor.png?w=900 900w, /media/blog/okta-logs-collector/okta-logs- loki-monitor.png?w=1040 1040w, /media/blog/okta-logs-collector/okta-logs-loki-monitor.png?w=1240 1240w, /media/blog/okta-logs-collector/okta-日志-loki-monitor.png?w=1920 1920w&#34;&#xA;data-size=&#34;auto&#34;alt=&#34;Loki 中的日志量仪表板&#34;&#xA;宽度=“1999”&#xA;高度=“860”&#xA;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src=&#34;/media/blog/okta-logs-collector/okta-logs-loki-monitor.png&#34;&#xA;alt=&#34;Loki 中的日志量仪表板&#34;&#xA;宽度=“1999”&#xA;高度=“860”&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;/a&gt;&#xA;&lt;/图&gt;&#xA;&lt;h2 id=&#34;how-to-use-sigma-rules-for-detecting-ritic-log-lines&#34;&gt;如何使用 Sigma 规则检测关键日志行&lt;/h2&gt;&#xA;&lt;p&gt;将日志摄取到 Loki 中只是成功的一半；另一半是检测关键日志行。这些日志行提供了重要的证据，例如确定公司帐户是否已被泄露。虽然您始终可以编写自己的 LogQL 查询来检测特定问题，但还有更有效的方法。一种这样的方法是 le评估 Sigma 生态系统，它提供了一套丰富的声明性规则来发现这些证据。&lt;/p&gt;&#xA;&lt;p&gt;幸运的是，安全运营团队为 &lt;a href=&#34;https://sigmahq.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Sigma&lt;/a&gt; 开发了一个后端，可以将 Sigma 规则转换为Loki 查询（LogQL 查询）。您可以利用&lt;a href=&#34;https://github.com/SigmaHQ/sigma/tree/master/rules/cloud/okta&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Okta 的现有 Sigma 规则&lt;/a &gt; 检测关键日志行并设置警报来监控这些事件。请按照&lt;a href=&#34;/blog/2022/12/15/a-guide-to-cyber-threat-hunting-with-promtail-grafana-loki-sigma-and-grafana-cloud/&#34;&gt;此中提供的说明进行操作博客文章&lt;/a&gt;安装 Sigma CLI 及其插件并将 Sigma 规则转换为 LogQL 查询。&lt;/p&gt;&#xA;&lt;p&gt;此外，您还可以根据 &lt;a href=&#34;https://github.com/SigmaHQ/sigma-specation/blob/main/sigma-schema.json&#34; target=&#34;_blank&#34; rel= 持续验证 Sigma 规则“noopener noreferrer&#34;&gt;Sigma JSON Schema&lt;/a&gt;，利用 &lt;a href=&#34;https://github.com/SigmaHQ/sigma-rules-validator&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;sigma-规则验证器&lt;/a&gt; GitHub Action。请按照&lt;a href=&#34;/blog/2024/03/25/how-to-validate-sigma-rules-with-github-actions-for-improved-security-monitoring/&#34;&gt;此博文&lt;/a中的说明进行操作&gt; 了解有关该操作及其使用方法的更多信息。&lt;/p&gt;&#xA;&lt;h2 id=&#34;whats-next&#34;&gt;下一步是什么&lt;/h2&gt;&#xA;&lt;p&gt;我们希望这个项目可以帮助您更轻松地监控 Okta 日志，但我们还没有完成。请继续关注 Okta 日志收集器的第 2 版，我们正在将其开发为 Alloy 组件。这个新版本将提供先进的功能以及与 Alloy 组件的无缝集成，以更好地满足您的日志记录需求。&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;/products/cloud/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt;是开始使用指标、日志、跟踪、仪表板等的最简单方法。我们为每个用例提供慷慨的永久免费套餐和计划。 &lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;plcmt=body-txt&#34;&gt;立即免费注册！&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 07 Aug 2024 00:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>