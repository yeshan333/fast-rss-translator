<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Grafana Labs blog on Grafana Labs</title>
    <link>/blog/index.xml</link>
    <description>Recent content in Grafana Labs blog on Grafana Labs</description>
    <item>
      <title>【Save the date: GrafanaCON 2025 is coming to Seattle in May!】保存日期：GrafanaCON 2025 将于 5 月在西雅图举行！</title>
      <link>https://grafana.com/blog/2024/12/10/save-the-date-grafanacon-2025-is-coming-to-seattle-in-may/</link>
      <description>【&lt;p&gt;We’re excited to share that &lt;a href=&#34;/events/grafanacon/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;GrafanaCON 2025&lt;/a&gt; will take place May 6-8 in Seattle! &lt;a href=&#34;/events/grafanacon/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;We hope you’ll join us at our biggest community event of the year for three days of technical sessions, live demos, user stories, our Ask-the-Experts booth, and more.&lt;/p&gt;&#xA;&lt;p&gt;In addition to covering all the latest and greatest features in Grafana, GrafanaCON 2025 will include more than 20 talks, deep dives, and hands-on sessions related to Prometheus, OpenTelemetry, Loki, Mimir, Tempo, and other open source projects. Plus, it’s a fantastic way to network with peers and hear about all the cool and inspiring ways they’re using Grafana and its extended OSS ecosystem.&lt;/p&gt;&#xA;&lt;p&gt;Registration for GrafanaCON 2025 will officially open in March, but you can &lt;a href=&#34;/events/grafanacon/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;sign up now&lt;/a&gt; to be notified about early access to tickets and special pricing.&lt;/p&gt;&#xA;&lt;div class=&#34;btn-row &#34;&gt;&lt;a class=&#34;btn btn--primary &#34; href=&#34;https://grafana.com/events/grafanacon/?pg=blog&amp;amp;plcmt=body-txt&#34; rel=&#34;noopener noreferrer&#34;&gt;Sign up to get notified&lt;/a&gt;&lt;/div&gt;&#xA;&lt;h2 id=&#34;present-a-talk-at-grafanacon-2025&#34;&gt;Present a talk at GrafanaCON 2025&lt;/h2&gt;&#xA;&lt;p&gt;Do you have a Grafana home lab setup you’re really proud of? Or maybe you’re using Grafana, Loki, and Prometheus at work to advance your observability strategy?&lt;/p&gt;&#xA;&lt;p&gt;If so, we’d love to see you on stage at GrafanaCON 2025. We’re looking for open source contributors and hands-on practitioners to share their stories with the wider community. Our &lt;a href=&#34;/events/grafanacon/2025/?pg=blog&amp;amp;plcmt=body-txt/#cfp&#34;&gt;call for presentations&lt;/a&gt; is open now until &lt;strong&gt;January 30, 2025.&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper w-100p &#34;&#xA;style=&#34;max-width: 1920px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/events/grafanacon/2025/?pg=blog&amp;amp;plcmt=body-txt/#cfp&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/grafanacon-2025-save-the-date/gcon_2025_CFP.png&#34;data-srcset=&#34;/media/blog/grafanacon-2025-save-the-date/gcon_2025_CFP.png?w=320 320w, /media/blog/grafanacon-2025-save-the-date/gcon_2025_CFP.png?w=550 550w, /media/blog/grafanacon-2025-save-the-date/gcon_2025_CFP.png?w=750 750w, /media/blog/grafanacon-2025-save-the-date/gcon_2025_CFP.png?w=900 900w, /media/blog/grafanacon-2025-save-the-date/gcon_2025_CFP.png?w=1040 1040w, /media/blog/grafanacon-2025-save-the-date/gcon_2025_CFP.png?w=1240 1240w, /media/blog/grafanacon-2025-save-the-date/gcon_2025_CFP.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;The session card for the GrafanaCON 2025 CFP.&#34;width=&#34;1920&#34;height=&#34;1080&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/grafanacon-2025-save-the-date/gcon_2025_CFP.png&#34;&#xA;alt=&#34;The session card for the GrafanaCON 2025 CFP.&#34;width=&#34;1920&#34;height=&#34;1080&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;We’re open to a wide range of topics, from beginner to advanced, and speakers from all backgrounds and industries. Need a little inspiration? &lt;a href=&#34;/events/grafanacon/2024/&#34;&gt;Check out the user stories&lt;/a&gt; from our last GrafanaCON event, which covered everything from monitoring moon landings to observing smart robots.&lt;/p&gt;&#xA;&lt;div class=&#34;btn-row &#34;&gt;&lt;a class=&#34;btn btn--primary &#34; href=&#34;https://pretalx.com/grafanacon-2025/&#34; rel=&#34;noopener noreferrer&#34;&gt;Submit a talk&lt;/a&gt;&lt;/div&gt;&#xA;&lt;h2 id=&#34;enter-your-dashboard-for-the-golden-grot-awards&#34;&gt;Enter your dashboard for the Golden Grot Awards&lt;/h2&gt;&#xA;&lt;p&gt;No GrafanaCON event would be complete without our &lt;a href=&#34;/golden-grot-awards/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Golden Grot Awards&lt;/a&gt;, which recognize all the amazing Grafana dashboards our community creates — whether they’re for monitoring your &lt;a href=&#34;/blog/2024/04/09/grafanacon-2024-a-guide-to-all-the-announcements-from-grafana-labs/#introducing-the-2024-golden-grot-award-winners&#34;&gt;morning commute or defects in steel alloys&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;The awards recognize the top dashboard in two categories: personal and professional. Community members can submit a maximum of one dashboard per category before &lt;strong&gt;February 21, 2025&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper w-100p &#34;&#xA;style=&#34;max-width: 1999px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/golden-grot-awards/?pg=blog&amp;amp;plcmt=body-txt&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/grafanacon-2025-save-the-date/gcon_2025_golden_grots.png&#34;data-srcset=&#34;/media/blog/grafanacon-2025-save-the-date/gcon_2025_golden_grots.png?w=320 320w, /media/blog/grafanacon-2025-save-the-date/gcon_2025_golden_grots.png?w=550 550w, /media/blog/grafanacon-2025-save-the-date/gcon_2025_golden_grots.png?w=750 750w, /media/blog/grafanacon-2025-save-the-date/gcon_2025_golden_grots.png?w=900 900w, /media/blog/grafanacon-2025-save-the-date/gcon_2025_golden_grots.png?w=1040 1040w, /media/blog/grafanacon-2025-save-the-date/gcon_2025_golden_grots.png?w=1240 1240w, /media/blog/grafanacon-2025-save-the-date/gcon_2025_golden_grots.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;The session card for the GrafanaCON 2025 Golden Grot Awards.&#34;width=&#34;1999&#34;height=&#34;1047&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/grafanacon-2025-save-the-date/gcon_2025_golden_grots.png&#34;&#xA;alt=&#34;The session card for the GrafanaCON 2025 Golden Grot Awards.&#34;width=&#34;1999&#34;height=&#34;1047&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;A panel of internal judges will narrow the submissions down to a short list, and then the entire Grafana community will also have a chance to vote for their favorites. The top dashboards in each category will be showcased during GrafanaCON 2025, and the grand prize winners will receive a trip to Seattle to be celebrated on stage during the big event.&lt;/p&gt;&#xA;&lt;div class=&#34;btn-row &#34;&gt;&lt;a class=&#34;btn btn--primary &#34; href=&#34;https://grafana.com/golden-grot-awards/?pg=blog&amp;amp;plcmt=body-txt&#34; rel=&#34;noopener noreferrer&#34;&gt;Enter the Golden Grot Awards&lt;/a&gt;&lt;/div&gt;&#xA;&lt;p&gt;The countdown to &lt;a href=&#34;/events/grafanacon/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;GrafanaCON 2025&lt;/a&gt; has officially begun. Can’t wait to see you there!&lt;/p&gt;】&lt;p&gt;我们很高兴与大家分享，&lt;a href=&#34;/events/grafanacon/?pg=blog&amp;plcmt=body-txt&#34;&gt;GrafanaCON 2025&lt;/a&gt; 将于 5 月 6 日至 8 日在西雅图举行！ &lt;a href=&#34;/events/grafanacon/?pg=blog&amp;plcmt=body-txt&#34;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;我们希望您能加入我们今年最大的社区活动，参加为期三天的技术会议、现场演示、用户故事、专家咨询展位等。&lt;/p&gt;&#xA;&lt;p&gt;除了涵盖 Grafana 的所有最新和最强大的功能之外，GrafanaCON 2025 还将包括与 Prometheus、OpenTelemetry、Loki、Mimir、Tempo 和其他开源项目相关的 20 多个演讲、深入探讨和实践会议。此外，这是与同行建立联系并了解他们使用 Grafana 及其扩展 OSS 生态系统的所有酷炫且鼓舞人心的方式的绝佳方式。&lt;/p&gt;&#xA;&lt;p&gt;GrafanaCON 2025 的注册将于 3 月正式开放，但您可以&lt;a href=&#34;/events/grafanacon/?pg=blog&amp;plcmt=body-txt&#34;&gt;立即注册&lt;/a&gt;以获得有关提前访问的通知门票和特价。&lt;/p&gt;&#xA;&lt;div class=&#34;btn-row &#34;&gt;&lt;a class=&#34;btn btn--primary&#34; href=&#34;https://grafana.com/events/grafanacon/?pg=blog&amp;plcmt=body-txt&#34; rel=&#34;noopener noreferrer &#34;&gt;注册以获得通知&lt;/a&gt;&lt;/div&gt;&#xA;&lt;h2 id=&#34;present-a-talk-at-grafanacon-2025&#34;&gt;在 GrafanaCON 2025 上发表演讲&lt;/h2&gt;&#xA;&lt;p&gt;您有真正引以为傲的 Grafana 家庭实验室设置吗？或者您可能在工作中使用 Grafana、Loki 和 Prometheus 来推进您的可观察性策略？&lt;/p&gt;&#xA;&lt;p&gt;如果是这样，我们很高兴在 GrafanaCON 2025 的舞台上看到您。我们正在寻找开源贡献者和实践者与更广泛的社区分享他们的故事。我们的&lt;a href=&#34;/events/grafanacon/2025/?pg=blog&amp;plcmt=body-txt/#cfp&#34;&gt;演示征集&lt;/a&gt;现已开放，直至&lt;strong&gt;2025 年 1 月 30 日&lt;/strong&gt;&lt; /p&gt;&#xA;&lt;图&#xA;类=“图形包装器w-100p”&#xA;样式=“最大宽度：1920px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接”&#xA;href=&#34;/events/grafanacon/2025/?pg=blog&amp;plcmt=body-txt/#cfp&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/blog/grafanacon-2025-save-the-date/gcon_2025_CFP.png&#34;data-srcset=&#34;/media/blog/grafanacon-2025-save-the-date/gcon_2025_CFP.png?w= 320 320瓦， /media/blog/grafanacon-2025-save-the-date/gcon_2025_CFP.png?w=550 550w, /media/blog/grafanacon-2025-save-the-date/gcon_2025_CFP.png?w=750 750w, /media/blog/grafanacon-2025-save-the-date/gcon_2025_CFP.png?w=900 900w, /media/blog/grafanacon-2025-save-the-date/gcon_2025_CFP.png?w=1040 1040w, /media/blog/grafanacon-2025-save-the-date/gcon_2025_CFP.png?w=1240 1240w，/media/blog/grafanacon-2025-save-the-date/gcon_2025_CFP.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;GrafanaCON 2025 CFP 的会话卡。&#34;width=&#34;1920&#34;height=&#34;1080&#34;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src=&#34;/media/blog/grafanacon-2025-save-the-date/gcon_2025_CFP.png&#34;&#xA;alt=&#34;GrafanaCON 2025 CFP 的会议卡。&#34;width=&#34;1920&#34;height=&#34;1080&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;W我们对从初级到高级的各种主题持开放态度，演讲者来自各个背景和行业。需要一点灵感吗？ &lt;a href=&#34;/events/grafanacon/2024/&#34;&gt;查看我们上次 GrafanaCON 活动中的用户故事&lt;/a&gt;，其中涵盖了从监测登月到观察智能机器人的所有内容。&lt;/p&gt;&#xA;&lt;div class=&#34;btn-row &#34;&gt;&lt;a class=&#34;btn btn--primary &#34; href=&#34;https://pretalx.com/grafanacon-2025/&#34; rel=&#34;noopener noreferrer&#34;&gt;提交演讲&lt;/a &gt;&lt;/div&gt;&#xA;&lt;h2 id=&#34;enter-your-dashboard-for-the-golden-grot-awards&#34;&gt;输入 Golden Grot 奖信息中心&lt;/h2&gt;&#xA;&lt;p&gt;没有我们的&lt;a href=&#34;/golden-grot-awards/?pg=blog&amp;plcmt=body-txt&#34;&gt;Golden Grot Awards&lt;/a&gt;，任何 GrafanaCON 活动都是不完整的，该奖项表彰了我们社区中所有令人惊叹的 Grafana 仪表板创建 — 它们是否用于监视您的 &lt;a href=&#34;/blog/2024/04/09/grafanacon-2024-a-guide-to-all-the-announcements-from-grafana-labs/#introducing-the-2024-golden-grot-award-winners&#34;&gt;早上通勤或钢合金缺陷&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;该奖项表彰两个类别中的顶级仪表板：个人和专业。在 &lt;strong&gt;2025 年 2 月 21 日&lt;/strong&gt;之前，社区成员最多可为每个类别提交一个仪表板。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图形包装器w-100p”&#xA;样式=“最大宽度：1999px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接”&#xA;href=&#34;/golden-grot-awards/?pg=blog&amp;plcmt=body-txt&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/blog/grafanacon-2025-save-the-date/gcon_2025_golden_grots.png&#34;data-srcset=&#34;/media/blog/grafanacon-2025-save-the-date/gcon_2025_golden_grots.png?w= 320 320瓦， /media/blog/grafanacon-2025-save-the-date/gcon_2025_golden_grots.png?w=550 550w, /media/blog/grafanacon-2025-save-the-date/gcon_2025_golden_grots.png?w=750 750w, /media/blog/grafanacon-2025-save-the-date/gcon_2025_golden_grots.png?w=900 900w, /media/blog/grafanacon-2025-save-the-date/gcon_2025_golden_grots.png?w=1040 1040w, /media/blog/grafanacon-2025-save-the-date/gcon_2025_golden_grots.png?w=1240 1240w，/media/blog/grafanacon-2025-save-the-date/gcon_2025_golden_grots.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;GrafanaCON 2025 Golden Grot Awards 会议卡。&#34;width=&#34;1999&#34;height=&#34;1047&#34;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/grafanacon-2025-save-the-date/gcon_2025_golden_grots.png”&#xA;alt=&#34;GrafanaCON 2025 金格罗特奖会议卡。&#34;width=&#34;1999&#34;height=&#34;1047&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;内部评审小组会将提交的作品缩小到最终名单，然后整个 Grafana 社区也将有机会投票选出他们最喜欢的作品。每个类别的顶级仪表板将在 GrafanaCON 2025 期间展示，大奖获得者将获得西雅图之旅，并在大型活动期间登台庆祝。&lt;/p&gt;&#xA;&lt;div class=&#34;btn-row &#34;&gt;&lt;a class=&#34;btn btn--primary &#34; href=&#34;https://grafana.com/golden-grot-awards/?pg=blog&amp;amp;plcmt=body-txt&#34; rel=&#34;noopener noreferrer&#34;&gt;参加金格罗特奖&lt;/a&gt;&lt;/div&gt;&#xA;&lt;p&gt;&lt;a href=&#34;/events/grafanacon/?pg=blog&amp;plcmt=body-txt&#34;&gt;GrafanaCON 2025&lt;/a&gt; 倒计时已正式开始。迫不及待地想在那里见到你！&lt;/p&gt;</description>
      <pubDate>Tue, 10 Dec 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Grafana LLM plugin updates: choose the large language models and providers that work best for you】Grafana LLM 插件更新：选择最适合您的大型语言模型和提供商</title>
      <link>https://grafana.com/blog/2024/12/18/grafana-llm-plugin-updates-choose-the-large-language-models-and-providers-that-work-best-for-you/</link>
      <description>【&lt;p&gt;At Grafana Labs, our mission has always been to empower users with the tools they need to build their own observability solutions. Our big tent philosophy embodies this mission by allowing you to choose the tools and technologies that best suit your needs.&lt;/p&gt;&#xA;&lt;p&gt;In this post, we want to share an update to our &lt;a href=&#34;/docs/grafana-cloud/alerting-and-irm/machine-learning/llm/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;LLM plugin&lt;/a&gt; that reflects this philosophy in action. As of the &lt;a href=&#34;https://github.com/grafana/grafana-llm-app/releases/tag/0.10.0&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;0.10.0 release&lt;/a&gt; earlier this year, the Grafana LLM plugin, which provides centralized access to large language models across Grafana, now supports &lt;a href=&#34;https://promptmetheus.com/resources/llm-knowledge-base/open-weights-model&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;open-weights models&lt;/a&gt; and non-OpenAI providers. This offers you greater flexibility to choose the LLMs and providers that best meet your needs in terms of performance, privacy, and cost.&lt;/p&gt;&#xA;&lt;h2 id=&#34;an-overview-of-the-grafana-llm-plugin&#34;&gt;An overview of the Grafana LLM plugin&lt;/h2&gt;&#xA;&lt;p&gt;The Grafana LLM plugin — currently in public preview in Grafana OSS, Grafana Enterprise, and Grafana Cloud — leverages generative AI to simplify your workflows. More specifically, the plugin helps you leverage LLMs to:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Annotate your dashboards and panels with more descriptive titles&lt;/li&gt;&#xA;&lt;li&gt;Automatically generate incident summaries&lt;/li&gt;&#xA;&lt;li&gt;Explain log patterns in a more human-friendly way&lt;/li&gt;&#xA;&lt;li&gt;Analyze complex flame graph profiles with&lt;a href=&#34;/blog/2024/05/15/ai-powered-insights-for-continuous-profiling-introducing-flame-graph-ai-in-grafana-cloud/&#34;&gt; Flame graph AI&lt;/a&gt; (shown below)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 948px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/docs/grafana-cloud/profiles/pyorsope-flamegraph-ai-analysis.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/docs/grafana-cloud/profiles/pyorsope-flamegraph-ai-analysis.png&#34;data-srcset=&#34;/media/docs/grafana-cloud/profiles/pyorsope-flamegraph-ai-analysis.png?w=320 320w, /media/docs/grafana-cloud/profiles/pyorsope-flamegraph-ai-analysis.png?w=550 550w, /media/docs/grafana-cloud/profiles/pyorsope-flamegraph-ai-analysis.png?w=750 750w, /media/docs/grafana-cloud/profiles/pyorsope-flamegraph-ai-analysis.png?w=900 900w, /media/docs/grafana-cloud/profiles/pyorsope-flamegraph-ai-analysis.png?w=1040 1040w, /media/docs/grafana-cloud/profiles/pyorsope-flamegraph-ai-analysis.png?w=1240 1240w, /media/docs/grafana-cloud/profiles/pyorsope-flamegraph-ai-analysis.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A screenshot of Flame graph AI.&#34;width=&#34;948&#34;height=&#34;918&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/docs/grafana-cloud/profiles/pyorsope-flamegraph-ai-analysis.png&#34;&#xA;alt=&#34;A screenshot of Flame graph AI.&#34;width=&#34;948&#34;height=&#34;918&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;The update we made in the 0.10.0 release makes these capabilities more accessible, no matter which LLMs or LLM provider you prefer, by allowing you to choose what works best for you and to balance cost, performance, and privacy.&lt;/p&gt;&#xA;&lt;h2 id=&#34;unified-support-for-llms&#34;&gt;Unified support for LLMs&lt;/h2&gt;&#xA;&lt;p&gt;Initially, Grafana&amp;rsquo;s LLM features were exclusive to models from &lt;a href=&#34;https://openai.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;OpenAI&lt;/a&gt;, leveraging their powerful GPT models. While these models are remarkable, we recognized the need for flexibility. With the latest update, you now have the freedom to integrate any model you prefer, as long as it is behind an OpenAI-compatible API and supports a system prompt.&lt;/p&gt;&#xA;&lt;p&gt;This means you can now take advantage of:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Self-hosted models:&lt;/strong&gt; You can use powerful open source models like &lt;a href=&#34;https://www.llama.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Llama 3&lt;/a&gt; and deploy them independently to gain full control over your data and model management.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Support for alternative LLM providers:&lt;/strong&gt; Through OpenAI-compatible proxies, such as &lt;a href=&#34;https://www.litellm.ai/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;LiteLLM&lt;/a&gt;, you can tap into models from different providers such as &lt;a href=&#34;https://gemini.google.com/app&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Google&amp;rsquo;s Gemini&lt;/a&gt; or &lt;a href=&#34;https://www.anthropic.com/claude&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Anthropic&amp;rsquo;s Claude&lt;/a&gt;, no matter which cloud service you&amp;rsquo;re using.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;To make this transition as seamless as possible, we are presenting two simplified options: a Base model for cost-effective LLM completions (e.g., gpt-4o-mini) or a Large model for use cases that require more advanced capabilities or larger context windows (e.g., gpt-4o). Grafana administrators can override these defaults and pick custom models that balance cost, performance, and privacy.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1050px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/llm-plugin-updates/LLM-plugin-updates-model-mapping.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/llm-plugin-updates/LLM-plugin-updates-model-mapping.png&#34;data-srcset=&#34;/media/blog/llm-plugin-updates/LLM-plugin-updates-model-mapping.png?w=320 320w, /media/blog/llm-plugin-updates/LLM-plugin-updates-model-mapping.png?w=550 550w, /media/blog/llm-plugin-updates/LLM-plugin-updates-model-mapping.png?w=750 750w, /media/blog/llm-plugin-updates/LLM-plugin-updates-model-mapping.png?w=900 900w, /media/blog/llm-plugin-updates/LLM-plugin-updates-model-mapping.png?w=1040 1040w, /media/blog/llm-plugin-updates/LLM-plugin-updates-model-mapping.png?w=1240 1240w, /media/blog/llm-plugin-updates/LLM-plugin-updates-model-mapping.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A screenshot of the model mappings feature in the LLM plugin.&#34;width=&#34;1050&#34;height=&#34;530&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/llm-plugin-updates/LLM-plugin-updates-model-mapping.png&#34;&#xA;alt=&#34;A screenshot of the model mappings feature in the LLM plugin.&#34;width=&#34;1050&#34;height=&#34;530&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;Some OpenAI-compatible API proxies, such as LiteLLM, have additional routing capabilities, allowing you to use different models from different providers (including your own self-hosted provider) for either the Base or Large model, depending on your unique needs and requirements.&lt;/p&gt;&#xA;&lt;h2 id=&#34;getting-started-with-custom-llm-providers&#34;&gt;Getting started with custom LLM providers&lt;/h2&gt;&#xA;&lt;p&gt;To use an alternative provider or self-hosted LLM model, follow these simple steps:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;/grafana/plugins/grafana-llm-app/&#34;&gt;Install the plugin&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Set up your LLM API&lt;/strong&gt;: Make sure you have an OpenAI-compatible API server, such as &lt;a href=&#34;https://github.com/vllm-project/vllm&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;vLLM&lt;/a&gt;, &lt;a href=&#34;https://ollama.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Ollama&lt;/a&gt;, &lt;a href=&#34;https://lmstudio.ai/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;LM Studio&lt;/a&gt;, or &lt;a href=&#34;https://www.litellm.ai/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;LiteLLM&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Configure the plugin:&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;In the plugin settings, select &lt;strong&gt;Use your own OpenAI Account.&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;Set the OpenAI API URL to point to your self-hosted API (e.g. &lt;a href=&#34;http://vllm.internal.url:8000/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;http://vllm.internal.url:8000/&lt;/a&gt;).&lt;/li&gt;&#xA;&lt;li&gt;Map your custom models in &lt;strong&gt;Model Settings &amp;gt; Model mappings&lt;/strong&gt; by specifying the &lt;code&gt;Base&lt;/code&gt; and &lt;code&gt;Large&lt;/code&gt; model (e.g., &lt;code&gt;meta-llama/Meta-Llama-3-8B-Instruct&lt;/code&gt;).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;That&amp;rsquo;s it! You can now enjoy Grafana’s LLM-powered features with your chosen model. On top of that, you now have the option to change the default model used to Base or Large, depending on your needs.&lt;/p&gt;&#xA;&lt;h2 id=&#34;benchmarking-non-openai-llms-on-grafana&#34;&gt;Benchmarking non-OpenAI LLMs on Grafana&lt;/h2&gt;&#xA;&lt;p&gt;As we opened the doors to bringing your own LLMs, we wanted to ensure that Grafana’s AI features still work as expected when using non-OpenAI options. This is easier said than done, since it&amp;rsquo;s not easy to guarantee a prompt still works consistently across diverse providers and open LLM models.&lt;/p&gt;&#xA;&lt;p&gt;Part of our testing approach was to benchmark our AI features across some popular LLMs. We discovered that the current prompt structure wasn&amp;rsquo;t reliable for a subset of models (particularly llama3), since it was using multiple system prompts. By being able to test different approaches, we were able to improve it and make sure our features still work as best as they can, regardless of the model you choose.&lt;/p&gt;&#xA;&lt;h3 id=&#34;benchmark-results&#34;&gt;Benchmark results&lt;/h3&gt;&#xA;&lt;table&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;&lt;strong&gt;Model&lt;/strong&gt;&#xA;&lt;/td&gt;&#xA;&lt;td&gt;&lt;strong&gt;Panel description&lt;/strong&gt; &lt;br&#xA;&lt;/strong&gt;N=841&#xA;&lt;/td&gt;&#xA;&lt;td&gt;&lt;strong&gt;Panel title&lt;/strong&gt; &lt;br&#xA;&lt;/strong&gt;N=841&#xA;&lt;/td&gt;&#xA;&lt;td&gt;&lt;strong&gt;Dashboard title&lt;/strong&gt; &lt;br&#xA;&lt;/strong&gt;N=506&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;gemini-1.5-flash&#xA;&lt;/td&gt;&#xA;&lt;td&gt;78.1%&#xA;&lt;/td&gt;&#xA;&lt;td&gt;&lt;strong&gt;82.0%&lt;/strong&gt;&#xA;&lt;/td&gt;&#xA;&lt;td&gt;67.2%&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;claude-3.5-sonnet&#xA;&lt;/td&gt;&#xA;&lt;td&gt;&lt;strong&gt;78.4%&lt;/strong&gt;&#xA;&lt;/td&gt;&#xA;&lt;td&gt;80.5%&#xA;&lt;/td&gt;&#xA;&lt;td&gt;&lt;strong&gt;68.7%&lt;/strong&gt;&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;gpt-4o-2024-05-13&#xA;&lt;/td&gt;&#xA;&lt;td&gt;77.8%&#xA;&lt;/td&gt;&#xA;&lt;td&gt;81.3%&#xA;&lt;/td&gt;&#xA;&lt;td&gt;66.1%&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;gpt-4o-mini-2024-07-18&#xA;&lt;/td&gt;&#xA;&lt;td&gt;78.0%&#xA;&lt;/td&gt;&#xA;&lt;td&gt;80.7%&#xA;&lt;/td&gt;&#xA;&lt;td&gt;66.8%&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;gpt-4-turbo-2024-04-09&#xA;&lt;/td&gt;&#xA;&lt;td&gt;77.6%&#xA;&lt;/td&gt;&#xA;&lt;td&gt;79.4%&#xA;&lt;/td&gt;&#xA;&lt;td&gt;66.9%&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;gpt-3.5-turbo-0125&#xA;&lt;/td&gt;&#xA;&lt;td&gt;76.3%&#xA;&lt;/td&gt;&#xA;&lt;td&gt;77.8%&#xA;&lt;/td&gt;&#xA;&lt;td&gt;63.6%&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;llama3:8b-instruct&#xA;&lt;/td&gt;&#xA;&lt;td&gt;73.0%&#xA;&lt;/td&gt;&#xA;&lt;td&gt;73.1%&#xA;&lt;/td&gt;&#xA;&lt;td&gt;65.0%&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;llama3.1:8b-instruct (AWQ)&#xA;&lt;/td&gt;&#xA;&lt;td&gt;76.7%&#xA;&lt;/td&gt;&#xA;&lt;td&gt;70.9%&#xA;&lt;/td&gt;&#xA;&lt;td&gt;63.1%&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;llama3:8b-instruct (pre-fix)&#xA;&lt;/td&gt;&#xA;&lt;td&gt;59.2%&#xA;&lt;/td&gt;&#xA;&lt;td&gt;58.5%&#xA;&lt;/td&gt;&#xA;&lt;td&gt;64.1%&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/table&gt;&#xA;&lt;p&gt;As expected, larger models deliver better performance, and by supporting smaller models, as well, we provide more flexibility and options for trading off cost and performance.&lt;/p&gt;&#xA;&lt;h2 id=&#34;whats-next-for-llms-in-grafana&#34;&gt;What’s next for LLMs in Grafana?&lt;/h2&gt;&#xA;&lt;p&gt;As we’re looking ahead, we want to bring more LLM capabilities to Grafana developers and continue to embrace our big tent philosophy.&lt;/p&gt;&#xA;&lt;p&gt;One of the features we&amp;rsquo;re excited to explore is enabling function calling and tool integration. This would allow developers to use LLMs to interact with Grafana to, for example, create new incidents or update dashboards.&lt;/p&gt;&#xA;&lt;p&gt;A recent Grafana Labs &lt;a href=&#34;/blog/2024/03/01/grafana-labs-hackathon-projects-where-are-they-now/&#34;&gt;hackathon&lt;/a&gt; project experimented with the &lt;a href=&#34;https://modelcontextprotocol.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Model Context Protocol&lt;/a&gt; (MCP) and created a Grafana MCP server that offers this functionality and more. This lets users ask questions of their Grafana instance from any compatible MCP client, such as Claude Desktop or Zed. Furthermore, it paves the way to a more &lt;a href=&#34;https://hbr.org/2024/12/what-is-agentic-ai-and-how-will-it-change-work&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;agentic&lt;/a&gt; approach to interacting with Grafana: imagine being able to chat with your Grafana instance from Slack, with an assistant that can search for relevant dashboards, add comments to incidents, or start &lt;a href=&#34;/docs/grafana-cloud/alerting-and-irm/machine-learning/sift/&#34;&gt;Sift investigations&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Stay tuned to learn more, as we continue to build out LLM capabilities in Grafana.&lt;/p&gt;】&lt;p&gt;在 Grafana Labs，我们的使命始终是为用户提供构建自己的可观测性解决方案所需的工具。我们的大帐篷理念体现了这一使命，让您可以选择最适合您需求的工具和技术。&lt;/p&gt;&#xA;&lt;p&gt;在这篇文章中，我们想分享 &lt;a href=&#34;/docs/grafana-cloud/alerting-and-irm/machine-learning/llm/?pg=blog&amp;plcmt=body-txt&#34;&gt;LLM 的更新插件&lt;/a&gt;在行动中体现了这一理念。自 &lt;a href=&#34;https://github.com/grafana/grafana-llm-app/releases/tag/0.10.0&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;0.10.0 版本&lt;/ a&gt; 今年早些时候，Grafana LLM 插件提供了对 Grafana 大型语言模型的集中访问，现在支持 &lt;a href=&#34;https://promptmetheus.com/resources/llm-knowledge-base/open-weights-model&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;开放权重模型&lt;/a&gt;和非 OpenAI 提供商。这使您可以更加灵活地选择最能满足您在性能、隐私和成本方面的需求的法学硕士和提供商。&lt;/p&gt;&#xA;&lt;h2 id=&#34;an-overview-of-the-grafana-llm-plugin&#34;&gt;Grafana LLM 插件概述&lt;/h2&gt;&#xA;&lt;p&gt;Grafana LLM 插件目前在 Grafana OSS、Grafana Enterprise 和 Grafana Cloud 中提供公共预览版，利用生成式 AI 来简化您的工作流程。更具体地说，该插件可帮助您利用法学硕士来：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;使用更具描述性的标题来注释您的仪表板和面板&lt;/li&gt;&#xA;&lt;li&gt;自动生成事件摘要&lt;/li&gt;&#xA;&lt;li&gt;以更人性化的方式解释日志模式&lt;/li&gt;&#xA;&lt;li&gt;使用&lt;a href=&#34;/blog/2024/05/15/ai-powered-insights-for-continuous-profiling-introducing-flame-graph-ai-in-grafana-cloud/&#34;分析复杂的火焰图剖面&gt; 火焰图AI&lt;/a&gt;（如下图）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：948px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接”&#xA;href=&#34;/media/docs/grafana-cloud/profiles/pyorsope-flamegraph-ai-analysis.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src =“/media/docs/grafana-cloud/profiles/pyorsope-flamegraph-ai-analysis.png”data-srcset =“/media/docs/grafana-cloud/profiles/pyorsope-flamegraph-ai-analysis.png” png?w=320 320w，/media/docs/grafana-cloud/profiles/pyorsope-flamegraph-ai-analysis.png?w=550 550w， /media/docs/grafana-cloud/profiles/pyorsope-flamegraph-ai-analysis.png?w=750 750w，/media/docs/grafana-cloud/profiles/pyorsope-flamegraph-ai-analysis.png?w=900 900w，/media/docs/grafana-cloud/profiles/pyorsope-flamegraph-ai-analysis.png?w=1040 1040w、/media/docs/grafana-cloud/profiles/pyorsope-flamegraph-ai-analysis.png?w=1240 1240w、/media/docs/grafana-cloud/profiles/pyorsope-flamegraph-ai-analysis.png?w =1920 1920w&#34;&#xA;data-sizes =“auto”alt =“火焰图AI的屏幕截图。”width =“948”height =“918”/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/docs/grafana-cloud/profiles/pyorsope-flamegraph-ai-analysis.png”&#xA;alt=&#34;A sc火焰图 AI 重拍。&#34;width=&#34;948&#34;height=&#34;918&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;我们在 0.10.0 版本中进行的更新使您可以更轻松地使用这些功能，无论您喜欢哪个 LLM 或 LLM 提供商，您都可以选择最适合您的选项并平衡成本、性能和隐私。&lt; /p&gt;&#xA;&lt;h2 id=&#34;unified-support-for-llms&#34;&gt;对法学硕士的统一支持&lt;/h2&gt;&#xA;&lt;p&gt;最初，Grafana 的 LLM 功能是 &lt;a href=&#34;https://openai.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;OpenAI&lt;/a&gt; 的模型独有的，利用其强大的 GPT 模型。虽然这些模型非常出色，但我们认识到灵活性的必要性。通过最新的更新，您现在可以自由地集成您喜欢的任何模型，只要它位于兼容 OpenAI 的 API 后面并支持系统提示即可。&lt;/p&gt;&#xA;&lt;p&gt;这意味着您现在可以利用：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;自托管模型&lt;/strong&gt;：您可以使用强大的开源模型，例如 &lt;a href=&#34;https://www.llama.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34; &gt;Llama 3&lt;/a&gt; 并独立部署它们，以完全控制您的数据和模型管理。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;支持替代 LLM 提供商&lt;/strong&gt;：通过 OpenAI 兼容代理，例如 &lt;a href=&#34;https://www.litellm.ai/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer &#34;&gt;LiteLLM&lt;/a&gt;，您可以利用来自不同提供商的模型，例如 &lt;a href=&#34;https://gemini.google.com/app&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Google 的模型Gemini&lt;/a&gt; 或 &lt;a href=&#34;https://www.anthropic.com/claude&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Anthropic 的 Claude&lt;/a&gt;，无论您使用哪种云服务使用。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;为了使这一过渡尽可能无缝，我们提供了两个简化的选项：用于经济高效的 LLM 完成的基本模型（例如 gpt-4o-mini）或用于需要更高级功能或的用例的大型模型更大的上下文窗口（例如 gpt-4o）。 Grafana 管理员可以覆盖这些默认值并选择平衡成本、性能和隐私的自定义模型。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1050px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/llm-plugin-updates/LLM-plugin-updates-model-mapping.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/blog/llm-plugin-updates/LLM-plugin-updates-model-mapping.png&#34;data-srcset=&#34;/media/blog/llm-plugin-updates/LLM-plugin-updates- model-mapping.png?w=320 320w，/media/blog/llm-plugin-updates/LLM-plugin-updates-model-mapping.png?w=550 550w，/media/blog/llm-plugin-updates/LLM-plugin-updates-model-mapping.png?w=750 750w，/media/blog/llm-plugin-updates/LLM-plugin-updates-model-mapping .png?w=900 900w, /media/blog/llm-plugin-updates/LLM-plugin-updates-model-mapping.png?w=1040 1040w，/media/blog/llm-plugin-updates/LLM-plugin-updates-model-mapping.png ?w=1240 1240w，/media/blog/llm-plugin-updates/LLM-plugin-updates-model-mapping.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;LLM 插件中模型映射功能的屏幕截图。&#34;width=&#34;1050&#34;height=&#34;530&#34;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/llm-plugin-updates/LLM-plugin-updates-model-mapping.png”&#xA;alt=&#34;LLM 插件中模型映射功能的屏幕截图。&#34;width=&#34;1050&#34;height=&#34;530&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;一些与 OpenAI 兼容的 API 代理（例如 LiteLLM）具有额外的路由功能，允许您根据您的独特需求，针对基本模型或大型模型使用来自不同提供商（包括您自己的自托管提供商）的不同模型和要求。&lt;/p&gt;&#xA;&lt;h2 id=&#34;getting-started-with-custom-llm-providers&#34;&gt;自定义 LLM 提供商入门&lt;/h2&gt;&#xA;&lt;p&gt;要使用替代提供商或自托管 LLM 模型，请按照以下简单步骤操作：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;/grafana/plugins/grafana-llm-app/&#34;&gt;安装插件&lt;/a&gt;&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;设置您的 LLM API&lt;/strong&gt;：确保您拥有与 OpenAI 兼容的 API 服务器，例如 &lt;a href=&#34;https://github.com/vllm-project/vllm&#34; target= &#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;vLLM&lt;/a&gt;，&lt;a href=&#34;https://ollama.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Ollama&lt;/a&gt;，&lt;a href=&#34;https://lmstudio.ai/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;LM Studio&lt;/a&gt;，或 &lt;a href=&#34;https://www.litellm.ai/&#34; target= “_blank”rel =“noopener noreferrer”&gt;LiteLLM&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;配置插件：&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;在插件设置中，选择&lt;strong&gt;使用您自己的 OpenAI 帐户。&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;将 OpenAI API URL 设置为指向您的自托管 API（例如 &lt;a href=&#34;http://vllm.internal.url:8000/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;http: //vllm.internal.url:8000/&lt;/a&gt;)。&lt;/li&gt;&#xA;&lt;li&gt;通过指定 &lt;code&gt;Base&lt;/code&gt; 和 &lt;code&gt;Large&lt;/code&gt; 模型（例如 &lt;code&gt;meta-llama /Meta-Llama-3-8B-Instruct&lt;/code&gt;）。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;就是这样！现在，您可以通过您选择的型号享受 Grafana 的 LLM 支持的功能。最重要的是，您现在可以根据需要将默认模型更改为“基本”或“大”。&lt;/p&gt;&#xA;&lt;h2 id=&#34;benchmarking-non-openai-llms-on-grafana&#34;&gt;在 Grafana 上对非 OpenAI LLM 进行基准测试&lt;/h2&gt;&#xA;&lt;p&gt;当我们为您带来自己的法学硕士敞开大门时，我们希望确保 Grafana 的 AI 功能在使用非 OpenAI 选项时仍然按预期工作。这说起来容易做起来难，因为要保证提示在不同的提供商和开放的 LLM 模型中仍然一致地工作并不容易。&lt;/p&gt;&#xA;&lt;p&gt;我们测试方法的一部分是在一些流行的法学硕士中对我们的人工智能功能进行基准测试。我们发现当前的提示结构对于部分模型（特别是 llama3）来说并不可靠，因为它使用多个系统提示。通过测试不同的方法，我们能够改进它并确保我们的无论您选择哪种型号，功能仍然会尽其所能地发挥作用。&lt;/p&gt;&#xA;&lt;h3 id=&#34;benchmark-results&#34;&gt;基准测试结果&lt;/h3&gt;&#xA;&lt;表&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;&lt;strong&gt;型号&lt;/strong&gt;&#xA;&lt;/td&gt;&#xA;&lt;td&gt;&lt;strong&gt;面板说明&lt;/strong&gt; &lt;br&#xA;&lt;/strong&gt;N=841&#xA;&lt;/td&gt;&#xA;&lt;td&gt;&lt;strong&gt;面板标题&lt;/strong&gt; &lt;br&#xA;&lt;/strong&gt;N=841&#xA;&lt;/td&gt;&#xA;&lt;td&gt;&lt;strong&gt;仪表板标题&lt;/strong&gt; &lt;br&#xA;&lt;/strong&gt;N=506&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;gemini-1.5-flash&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;78.1%&#xA;&lt;/td&gt;&#xA;&lt;td&gt;&lt;strong&gt;82.0%&lt;/strong&gt;&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;67.2%&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;claude-3.5-十四行诗&#xA;&lt;/td&gt;&#xA;&lt;td&gt;&lt;strong&gt;78.4%&lt;/strong&gt;&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;80.5%&#xA;&lt;/td&gt;&#xA;&lt;td&gt;&lt;strong&gt;68.7%&lt;/strong&gt;&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;gpt-4o-2024-05-13&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;77.8%&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;81.3%&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;66.1%&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;gpt-4o-mini-2024-07-18&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;78.0%&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;80.7%&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;66.8%&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;gpt-4-turbo-2024-04-09&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;77.6%&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;79.4%&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;66.9%&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;gpt-3.5-turbo-0125&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;76.3%&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;77.8%&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;63.6%&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;llama3:8b-指令&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;73.0%&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;73.1%&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;65.0%&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;llama3.1:8b-指令 (AWQ)&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;76.7%&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;70.9%&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;63.1%&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;llama3:8b-指令（前缀）&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;59.2%&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;58.5%&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;64.1%&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/表&gt;&#xA;&lt;p&gt;正如预期的那样，较大的模型可提供更好的性能，并且通过支持较小的模型，我们提供了更多的灵活性和选项来权衡成本和性能。&lt;/p&gt;&#xA;&lt;h2 id=&#34;whats-next-for-llms-in-grafana&#34;&gt;Grafana 法学硕士的下一步是什么？&lt;/h2&gt;&#xA;&lt;p&gt;展望未来，我们希望为 Grafana 开发人员带来更多 LLM 功能，并继续秉承我们的大帐篷理念。&lt;/p&gt;&#xA;&lt;p&gt;我们很高兴探索的功能之一是支持函数调用和工具集成。这将允许开发人员使用 LLM 与 Grafana 进行交互，例如创建新事件或更新仪表板。&lt;/p&gt;&#xA;&lt;p&gt;最近的 Grafana Labs &lt;a href=&#34;/blog/2024/03/01/grafana-labs-hackathon-projects-where-are-they-now/&#34;&gt;黑客马拉松&lt;/a&gt; 项目试验了 &lt;a href=&#34;https://modelcontextprotocol.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;模型上下文协议&lt;/a&gt; (MCP) 并创建了 Grafana MCP 服务器它提供了此功能以及更多功能。这使用户可以从任何兼容的 MCP 客户端（例如 Claude Desktop 或 Zed）询问其 Grafana 实例的问题。此外，它为更多&lt;a href=&#34;https://hbr.org/2024/12/what-is-agentic-ai-and-how-will-it-change-work&#34; target=&#34;_blank &#34; rel=&#34;noopener noreferrer&#34;&gt;代理&lt;/a&gt; 与 Grafana 交互的方法：想象一下能够通过 Slack 与 Grafana 实例聊天，助手可以搜索相关仪表板、向事件添加评论或启动&lt;a href=&#34;/docs/grafana-cloud/alerting-and-irm/machine-learning/sift/&#34;&gt;筛选调查&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;请继续关注以了解更多信息，我们将继续在 Grafana 中构建 LLM 功能。&lt;/p&gt;</description>
      <pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【2025 observability predictions and trends from Grafana Labs】Grafana Labs 的 2025 年可观测性预测和趋势</title>
      <link>https://grafana.com/blog/2024/12/16/2025-observability-predictions-and-trends-from-grafana-labs/</link>
      <description>【&lt;p&gt;From AI to eBPF, 2024 reshaped the observability landscape. As we peer into 2025, Grafana Labs&amp;rsquo; experts predict another year of innovation that will redefine how teams understand and optimize their systems, from profiling to platform engineering.&lt;/p&gt;&#xA;&lt;p&gt;Their insights align with what the community is saying, according to early responses from our third annual Observability Survey. Do you agree or disagree with the trends our team believes will transform the world of observability next year? Let us know by &lt;a href=&#34;/observability-survey/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;making your voice heard before the survey closes on Dec. 31&lt;/a&gt;!&lt;/p&gt;&#xA;&lt;p&gt;And when you&amp;rsquo;re done, come back here to get an early look at the survey results and to find out what our own observability experts see on the horizon for 2025.&lt;/p&gt;&#xA;&lt;h2 id=&#34;profiles-and-traces-converge&#34;&gt;Profiles and traces converge&lt;/h2&gt;&#xA;&lt;p&gt;Profiling had a big year in 2024 with the &lt;a href=&#34;https://opentelemetry.io/blog/2024/profiling/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;addition of continuous profiling to OpenTelemetry&lt;/a&gt;. And despite being a fairly nascent technology, about 13% of our survey respondents are already using profiling tools in production. We expect that number to grow in 2025 as engineers realize the full potential of profiling when they use it in tandem with traces.&lt;/p&gt;&#xA;&lt;p&gt;Traces have unique benefits, but expect to see increased convergence with profiles as organizations seek deeper insights into application performance, said Ryan Perry, Principal Product Manager. That&amp;rsquo;s because traces excel at showing end-to-end request flows, while profiles reveal detailed system resource usage.&lt;/p&gt;&#xA;&lt;p&gt;&amp;ldquo;By combining these tools, teams gain visibility into their applications that manually added spans never could,&amp;rdquo; Perry said. &amp;ldquo;For example, when a trace shows a 400ms span, corresponding profile data can reveal exactly which code executed during that time period, down to the specific functions and their resource consumption. This allows teams to pinpoint performance bottlenecks with surgical precision, leading to more efficient optimization efforts and reduced operational costs.&amp;rdquo;&lt;/p&gt;&#xA;&lt;p&gt;As &lt;a href=&#34;https://opentelemetry.io/blog/2024/profiling/#a-community-in-motion&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;profiling becomes stable in OpenTelemetry&lt;/a&gt;, forward-thinking organizations will do more than simply collect traces and profiles. &amp;ldquo;They&amp;rsquo;ll be treating them as interconnected, contextual data streams that provide a holistic view of system performance and efficiency,” he added.&lt;/p&gt;&#xA;&lt;h2 id=&#34;aiml-wont-replace-engineers-but-give-them-superpowers&#34;&gt;AI/ML won’t replace engineers but give them superpowers&lt;/h2&gt;&#xA;&lt;p&gt;Despite the hype, AI/ML has not yet proven to be the silver bullet for observability challenges. While only 18% of surveyed participants consider AI/ML capabilities crucial when evaluating new observability solutions, those embracing AI technologies recognize its promise for things like accelerating root cause analysis and intelligent alerting.&lt;/p&gt;&#xA;&lt;p&gt;AI/ML continues to be an important emerging tool, but it should no longer be seen as a catch-all solution, said Quynton Johnson, Product Marketing Lead. Instead, expect AI/ML efforts to hone in on specific use cases that deliver tangible value.&lt;/p&gt;&#xA;&lt;p&gt;&amp;ldquo;AI/ML excels at pattern recognition, enabling the automation of time-consuming tasks and identifying cost-saving opportunities,&amp;rdquo; Johnson said. &amp;ldquo;Rather than replacing engineers, our solutions will augment their capabilities by reducing noise and providing well-reasoned recommendations. This frees up human experts to focus on complex decision-making where their expertise is most valuable.&amp;rdquo;&lt;/p&gt;&#xA;&lt;h2 id=&#34;cloud-repatriation-wont-be-the-key-to-cost-savings-for-most&#34;&gt;Cloud repatriation won’t be the key to cost savings (for most)&lt;/h2&gt;&#xA;&lt;p&gt;Year-over-year, cost continues to be one of the most important criteria when selecting a new observability tool and, according to our data, cost will still be top of mind for organizations of all sizes and across all industries in 2025. One approach to cutting costs that people are talking about — but not executing on — is moving workloads from cloud to on-premises. However, that won’t be feasible (or strategic) for most.&lt;/p&gt;&#xA;&lt;p&gt;Yes, certain organizations, like large-scale social media networks with predictable workloads, might benefit from hybrid or on-prem solutions. However, the time, money, resources, and overall complexity of full-scale cloud repatriation won’t offset cost for most organizations, said Richard “RichiH” Hartmann, Director of Community &amp;amp; Office of the CTO.&lt;/p&gt;&#xA;&lt;p&gt;&amp;ldquo;They should look into implementing a targeted optimization approach,&amp;rdquo; Hartmann said. &amp;ldquo;Instead of abandoning their cloud infrastructure, they can optimize it for cost, performance, and scalability.&amp;rdquo;&lt;/p&gt;&#xA;&lt;p&gt;&amp;ldquo;This requires a mix of FinOps, leveraging the right tools, and continuous monitoring of infrastructure economics,&amp;rdquo; he added, &amp;ldquo;but teams that lean into this approach will see meaningful cost savings without sacrificing the agility and scalability that drew them to cloud platforms in the first place.”&lt;/p&gt;&#xA;&lt;h2 id=&#34;platform-engineerings-next-frontier-ebpf&#34;&gt;Platform engineering&amp;rsquo;s next frontier: eBPF&lt;/h2&gt;&#xA;&lt;p&gt;Platform teams are experiencing significant growth, with nearly 25% of those surveyed working in this role. As the importance of platform teams increases, their responsibilities will expand to encompass emerging tools and technologies — like eBPF.&lt;/p&gt;&#xA;&lt;p&gt;What started as a trendy technology will become the backbone of modern platform engineering, fundamentally reshaping how organizations handle observability and security,&amp;rdquo; said Nikola Grcevski, Principal Software Engineer, adding that eBPF is on &amp;ldquo;the cusp of a major transformation.&amp;rdquo;&lt;/p&gt;&#xA;&lt;p&gt;&amp;ldquo;One significant shift will be the transition of instrumentation responsibility from application teams to platform teams. We’re already seeing OpenTelemetry integrate with eBPF, with updates like the &lt;a href=&#34;https://opentelemetry.io/blog/2024/elastic-contributes-continuous-profiling-agent/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;OpenTelemetry eBPF Profiling donation&lt;/a&gt;, which is already helping drive adoption of eBPF,&amp;rdquo; Grcevski said. &amp;ldquo;Moving forward we’ll see more opportunities for eBPF to create a seamless bridge between system-level data and application telemetry while standardizing how platforms collect and process observability data.“&lt;/p&gt;&#xA;&lt;h2 id=&#34;open-source-will-continue-to-be-the-cornerstone-of-observability&#34;&gt;Open source will continue to be the cornerstone of observability&lt;/h2&gt;&#xA;&lt;p&gt;OpenTelemetry and Prometheus continue to gain traction, with more than 50% of respondents reporting that they’ve increased their usage of both projects over the past year. With similar growth in &lt;a href=&#34;/observability-survey/2024/?pg=blog&amp;amp;plcmt=body-txt#oss-is-the-de-facto-approach-to-observability&#34;&gt;years past&lt;/a&gt;, open source observability shows no signs of slowing down.&lt;/p&gt;&#xA;&lt;p&gt;Open source isn&amp;rsquo;t just a cost-saving strategy; it&amp;rsquo;s becoming the primary vehicle for technological innovation in observability, according to Marylia Gutierrez, Staff Software Engineer. OpenTelemetry, in particular, is transforming how organizations approach instrumentation by providing a vendor-neutral, unified approach to collecting telemetry data across different systems and programming languages.&lt;/p&gt;&#xA;&lt;p&gt;&amp;ldquo;As more organizations recognize the strategic value of OTel, we&amp;rsquo;ll see continued investment, deeper integrations with tools like Prometheus and Grafana, and even wider spread adoption. There are a few promising areas that OTel is poised to impact in the coming months,&amp;rdquo; Gutierrez said.&lt;/p&gt;&#xA;&lt;p&gt;&amp;ldquo;One is streamlined troubleshooting — as OpenTelemetry enables teams to correlate metrics, logs, and traces seamlessly, we’ll see accelerated root cause analysis and improved system reliability,&amp;rdquo; Gutierrez added. &amp;ldquo;Another is developer productivity — as standardized instrumentation eliminates the overhead of maintaining custom telemetry solutions, teams will be free to focus on building features. And last is the creation of libraries that provide users with the observability they&amp;rsquo;ve been seeking, such as databases, mobile applications, profiling, among many others.&amp;rdquo;&lt;/p&gt;&#xA;&lt;h2 id=&#34;join-us-to-see-how-2025-plays-out&#34;&gt;Join us to see how 2025 plays out&lt;/h2&gt;&#xA;&lt;p&gt;What do you think of our predictions? Obviously no one knows what the future holds, but we&amp;rsquo;re excited to see what 2025 has in store for observability — for us and for you! If you want to join us on this journey, we&amp;rsquo;ll be covering these topics and more at &lt;a href=&#34;/events/grafanacon/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;GrafanaCON 2025&lt;/a&gt;, which will run from May 6 to May 8 in Seattle.&lt;/p&gt;&#xA;&lt;p&gt;And if you can&amp;rsquo;t make it to the Pacific Northwest, keep an eye out for one of our &lt;a href=&#34;/events/observabilitycon-on-the-road/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;ObservabilityCON on the Road&lt;/a&gt; events potentially coming to a city near you.&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;/products/cloud/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Cloud &lt;/a&gt;is the easiest way to get started with metrics, logs, traces, dashboards, and more. We have a generous forever-free tier and plans for every use case. &lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Sign up for free now!&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;】&lt;p&gt;从 AI 到 eBPF，2024 年重塑了可观测性格局。展望 2025 年，Grafana Labs 的专家预测又一个创新年，将重新定义团队如何理解和优化其系统，从分析到平台工程。&lt;/p&gt;&#xA;&lt;p&gt;根据我们第三次年度可观测性调查的早期回复，他们的见解与社区的说法一致。您是否同意我们团队认为明年将改变可观测世界的趋势？请&lt;a href=&#34;/observability-survey/?pg=blog&amp;plcmt=body-txt&#34;&gt;在 12 月 31 日调查结束之前表达您的意见&lt;/a&gt;，让我们知道！&lt;/p&gt;&#xA;&lt;p&gt;完成后，请返回此处尽早查看调查结果，并了解我们的可观测性专家对 2025 年的看法。&lt;/p&gt;&#xA;&lt;h2 id=&#34;profiles-and-traces-converge&#34;&gt;配置文件和痕迹汇聚&lt;/h2&gt;&#xA;&lt;p&gt;分析在 2024 年是重要的一年，&lt;a href=&#34;https://opentelemetry.io/blog/2024/profiling/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;在 OpenTelemetry 中添加了连续分析功能&lt;/a&gt;。尽管这是一项相当新兴的技术，但大约 13% 的受访者已经在生产中使用分析工具。我们预计这个数字将在 2025 年增长，因为工程师会意识到分析与跟踪结合使用时的全部潜力。&lt;/p&gt;&#xA;&lt;p&gt;首席产品经理 Ryan Perry 表示，跟踪具有独特的优势，但随着组织寻求更深入地了解应用程序性能，跟踪与配置文件的融合预计会有所加强。这是因为跟踪擅长显示端到端请求流，而配置文件则揭示详细的系统资源使用情况。&lt;/p&gt;&#xA;&lt;p&gt;“通过组合这些工具，团队可以了解其应用程序，这是手动添加的跨度永远无法实现的，”Perry 说。 “例如，当跟踪显示 400 毫秒的跨度时，相应的配置文件数据可以准确揭示该时间段内执行的代码，具体到特定功能及其资源消耗。这使得团队能够以外科手术般的精度查明性能瓶颈，从而实现更高效的优化工作并降低运营成本。”&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://opentelemetry.io/blog/2024/profiling/#a-community-in-motion&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;分析在 OpenTelemetry 中变得稳定&lt; /a&gt;，有远见的组织将做的不仅仅是收集痕迹和档案。 “他们将把它们视为相互关联的上下文数据流，提供系统性能和效率的整体视图，”他补充道。&lt;/p&gt;&#xA;&lt;h2 id=&#34;aiml-wont-replace-engineers-but-give-them-superpowers&#34;&gt;AI/ML 不会取代工程师，但会赋予他们超能力&lt;/h2&gt;&#xA;&lt;p&gt;尽管大肆宣传，人工智能/机器学习尚未被证明是应对可观测性挑战的灵丹妙药。虽然只有 18% 的受访者认为 AI/ML 能力在评估新的可观测性解决方案时至关重要，但那些采用 AI 技术的人认为 AI/ML 能力至关重要。我们认识到它在加速根本原因分析和智能警报等方面的前景。&lt;/p&gt;&#xA;&lt;p&gt;产品营销主管 Quynton Johnson 表示，AI/ML 仍然是一种重要的新兴工具，但不应再将其视为包罗万象的解决方案。相反，期望 AI/ML 努力专注于提供有形价值的特定用例。&lt;/p&gt;&#xA;&lt;p&gt;“人工智能/机器学习擅长模式识别，能够实现耗时任务的自动化并识别节省成本的机会，”约翰逊说。 “我们的解决方案不是取代工程师，而是通过降低噪音和提供合理的建议来增强他们的能力。这使得人类专家能够专注于他们的专业知识最有价值的复杂决策。”&lt;/p&gt;&#xA;&lt;h2 id=&#34;cloud-repatriation-wont-be-the-key-to-cost- savings-for-most&#34;&gt;云汇回不会成为节省成本的关键（对于大多数人来说）&lt;/h2&gt;&#xA;&lt;p&gt;与去年同期相比，成本仍然是选择新的可观察性工具时最重要的标准之一，并且根据我们的数据，到 2025 年，成本仍将是各种规模和所有行业的组织的首要考虑因素人们谈论但没有执行的一种削减成本的方法是将工作负载从云转移到本地。然而，这对大多数人来说是不可行的（或战略性的）。&lt;/p&gt;&#xA;&lt;p&gt;是的，某些组织（例如具有可预测工作负载的大型社交媒体网络）可能会从混合或本地解决方案中受益。然而，全面云迁移的时间、金钱、资源和整体复杂性无法抵消大多数组织的成本，社区兼 CTO 办公室总监 Richard“RichiH”Hartmann 表示。&lt;/p&gt;&#xA;&lt;p&gt;“他们应该考虑实施有针对性的优化方法，”哈特曼说。 “他们可以优化成本、性能和可扩展性，而不是放弃云基础设施。”&lt;/p&gt;&#xA;&lt;p&gt;“这需要结合使用 FinOps、利用正确的工具以及对基础设施经济性的持续监控，”他补充道，“但采用这种方法的团队将看到有意义的成本节省，而不会牺牲吸引他们的敏捷性和可扩展性。首先是云平台。”&lt;/p&gt;&#xA;&lt;h2 id=&#34;platform-engineerings-next-frontier-ebpf&#34;&gt;平台工程的下一个前沿：eBPF&lt;/h2&gt;&#xA;&lt;p&gt;平台团队正在经历显着增长，近 25% 的受访者担任此职位。随着平台团队重要性的增加，他们的职责将扩大到涵盖新兴工具和技术——例如 eBPF。&lt;/p&gt;&#xA;&lt;p&gt;最初作为一项流行技术将成为现代平台工程的支柱，从根本上重塑组织处理可观察性和安全性的方式，”首席软件工程师 Nikola Grcevski 说道，并补充说 eBPF 正处于“重大转型的风口浪尖”。 &lt;/p&gt;&#xA;&lt;p&gt;“一个重大转变将是 tr将仪表责任从应用程序团队转移到平台团队。我们已经看到 OpenTelemetry 与 eBPF 集成，并进行了诸如 &lt;a href=&#34;https://opentelemetry.io/blog/2024/elastic-contributes-continuous-profiling-agent/&#34; target=&#34;_blank&#34; rel=&#34; 之类的更新noopener noreferrer&#34;&gt;OpenTelemetry eBPF 分析捐赠&lt;/a&gt;，这已经有助于推动 eBPF 的采用，”Grcevski 说。 “展望未来，我们将看到 eBPF 有更多机会在系统级数据和应用程序遥测之间建立无缝桥梁，同时标准化平台收集和处理可观测性数据的方式。”&lt;/p&gt;&#xA;&lt;h2 id=&#34;open-source-will-continue-to-be-the-cornerstone-of-observability&#34;&gt;开源将继续成为可观察性的基石&lt;/h2&gt;&#xA;&lt;p&gt;OpenTelemetry 和 Prometheus 继续受到关注，超过 50% 的受访者表示，他们在过去一年中增加了对这两个项目的使用。 &lt;a href=&#34;/observability-survey/2024/?pg=blog&amp;plcmt=body-txt#oss-is-the-de-facto-approach-to-observability&#34;&gt;过去几年&lt;/a&gt;也有类似的增长，源可观测性没有放缓的迹象。&lt;/p&gt;&#xA;&lt;p&gt;开源不仅仅是一种节省成本的策略；高级软件工程师 Marylia Gutierrez 表示，它正在成为可观测性技术创新的主要工具。特别是，OpenTelemetry 正在改变组织处理仪器的方式，提供一种与供应商无关的统一方法来跨不同系统和编程语言收集遥测数据。&lt;/p&gt;&#xA;&lt;p&gt;“随着越来越多的组织认识到 OTel 的战略价值，我们将看到持续的投资、与 Prometheus 和 Grafana 等工具的更深入集成，以及更广泛的采用。 OTel 准备在未来几个月内影响一些有前景的领域。”Gutierrez 说道。&lt;/p&gt;&#xA;&lt;p&gt;“一个是简化故障排除 - 由于 OpenTelemetry 使团队能够无缝关联指标、日志和跟踪，我们将看到根本原因分析的加速和系统可靠性的提高，”Gutierrez 补充道。 “另一个是开发人员的生产力——随着标准化仪器消除了维护定制遥测解决方案的开销，团队将可以自由地专注于构建功能。最后是创建库，为用户提供他们一直在寻求的可观察性，例如数据库、移动应用程序、分析等。”&lt;/p&gt;&#xA;&lt;h2 id=&#34;join-us-to-see-how-2025-plays-out&#34;&gt;加入我们，看看 2025 年将如何发展&lt;/h2&gt;&#xA;&lt;p&gt;您对我们的预测有何看法？显然，没有人知道未来会怎样，但我们很高兴看到 2025 年可观察性的前景——对于我们和您来说！如果您想加入我们的旅程，我们将在 &lt;a href=&#34;/events/grafanacon/?pg=blog&amp;plcmt=body-txt&#34;&gt;GrafanaCON 2025&lt;/a&gt; 上介绍这些主题及更多内容，该会议将在5 月 6 日至 5 月 8 日在西雅图。&lt;/p&gt;&#xA;&lt;p&gt;如果您无法前往太平洋西北地区，请留意我们的&lt;a href=&#34;/events/observabilitycon-on-the-road/?pg=blog&amp;plcmt=body-txt&#34;&gt;之一ObservabilityCON on the Road&lt;/a&gt; 活动可能会在您附近的城市举办。&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;/products/cloud/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt;是开始使用指标、日志、跟踪、仪表板等的最简单方法。我们为每个用例提供慷慨的永久免费套餐和计划。 &lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;plcmt=body-txt&#34;&gt;立即免费注册！&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Inside Grafana Labs: how we foster a culture of continuous learning】Grafana Labs 内部：我们如何培养持续学习的文化</title>
      <link>https://grafana.com/blog/2024/12/19/inside-grafana-labs-how-we-foster-a-culture-of-continuous-learning/</link>
      <description>【&lt;p&gt;&lt;em&gt;&lt;strong&gt;“What did you learn today?”&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;It’s a question many of us heard as a child. Maybe a parent asked you on the way home from school, or a sibling around the dinner table, or even a curious aunt or uncle at a family gathering. But when was the last time someone asked you, as an adult, what you actually &lt;em&gt;learned&lt;/em&gt; at the end of a day?&lt;/p&gt;&#xA;&lt;p&gt;The truth is, as we grow older, the expectation to be constantly learning diminishes. It seems we’re simply too tired, or too busy with other responsibilities, to be learning all the time. As a member of the Learning and Development team here at Grafana Labs, I strive to reset that expectation.&lt;/p&gt;&#xA;&lt;p&gt;Since our early days as a company, we’ve fostered a culture of continuous learning. We start during an employee’s first few days as a Grafanista, beginning with our virtual onboarding sessions (Grafana Labs is a &lt;a href=&#34;/blog/2023/05/12/inside-grafana-labs-remote-first-is-relationship-first/&#34;&gt;remote-first company&lt;/a&gt;) and then through our week-long, in-person onboarding events, which are a great way to connect with other new employees and members of the Grafana Labs leadership team.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1999px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link captioned&#34;&#xA;href=&#34;/media/blog/continuous-learning/continuous-learning-onboarding.jpg&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload mb-0&#34;&#xA;data-src=&#34;/media/blog/continuous-learning/continuous-learning-onboarding.jpg&#34;data-srcset=&#34;/media/blog/continuous-learning/continuous-learning-onboarding.jpg?w=320 320w, /media/blog/continuous-learning/continuous-learning-onboarding.jpg?w=550 550w, /media/blog/continuous-learning/continuous-learning-onboarding.jpg?w=750 750w, /media/blog/continuous-learning/continuous-learning-onboarding.jpg?w=900 900w, /media/blog/continuous-learning/continuous-learning-onboarding.jpg?w=1040 1040w, /media/blog/continuous-learning/continuous-learning-onboarding.jpg?w=1240 1240w, /media/blog/continuous-learning/continuous-learning-onboarding.jpg?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A photo from a recent Grafana Labs onboarding event.&#34;width=&#34;1999&#34;height=&#34;1051&#34;title=&#34;*A photo from a 2024 Grafana Labs in-person onboarding event in Washington, DC.*&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/continuous-learning/continuous-learning-onboarding.jpg&#34;&#xA;alt=&#34;A photo from a recent Grafana Labs onboarding event.&#34;width=&#34;1999&#34;height=&#34;1051&#34;title=&#34;*A photo from a 2024 Grafana Labs in-person onboarding event in Washington, DC.*&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;figcaption class=&#34;w-100p caption text-gray-13 &#34;&gt;&lt;em&gt;A photo from a 2024 Grafana Labs in-person onboarding event in Washington, DC.&lt;/em&gt;&lt;/figcaption&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;Our goal is to inspire our employees to learn and grow right from the start by investing heavily in their initial onboarding experience. But we also encourage employees to continue learning throughout their careers at Grafana Labs.&lt;/p&gt;&#xA;&lt;p&gt;In this post, we share exactly how we do that. Read on to learn more about our learning management systems, professional development budgets, and other ways we ensure Grafanistas learn something each and every day.&lt;/p&gt;&#xA;&lt;h2 id=&#34;learning-on-demand&#34;&gt;Learning on demand&lt;/h2&gt;&#xA;&lt;p&gt;All Grafana Labs employees are respectfully empowered to work in the way that is best for them. Flexibility and autonomy are &lt;a href=&#34;/about/careers/&#34;&gt;cornerstones of our work&lt;/a&gt;, so it makes sense that those values also extend to our learning culture. Therefore, we provide a variety of on-demand resources for Grafanistas to learn what they want to learn, when and how they want to learn it.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.docebo.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Docebo&lt;/a&gt;, our learning management system (LMS), provides access to a variety of custom courses. These courses — created by Grafanistas, for Grafanistas — provide relevant content that accounts for our unique circumstances.&lt;/p&gt;&#xA;&lt;p&gt;For example, our Level-Up Toolkits contain curated resources to help people managers dive deeper into critical topics like delegation, change management, and feedback. These toolkits are part of a learning path that Grafana Labs employees are free to opt in or out of, based on their interests and availability.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1010px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link captioned&#34;&#xA;href=&#34;/media/blog/continuous-learning/continuous-learning-toolkit.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload mb-0&#34;&#xA;data-src=&#34;/media/blog/continuous-learning/continuous-learning-toolkit.png&#34;data-srcset=&#34;/media/blog/continuous-learning/continuous-learning-toolkit.png?w=320 320w, /media/blog/continuous-learning/continuous-learning-toolkit.png?w=550 550w, /media/blog/continuous-learning/continuous-learning-toolkit.png?w=750 750w, /media/blog/continuous-learning/continuous-learning-toolkit.png?w=900 900w, /media/blog/continuous-learning/continuous-learning-toolkit.png?w=1040 1040w, /media/blog/continuous-learning/continuous-learning-toolkit.png?w=1240 1240w, /media/blog/continuous-learning/continuous-learning-toolkit.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A screenshot of courses for Grafana Labs employees in Docebo.&#34;width=&#34;1010&#34;height=&#34;748&#34;title=&#34;*Custom toolkits on Docebo encourage continued learning about various topics.*&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/continuous-learning/continuous-learning-toolkit.png&#34;&#xA;alt=&#34;A screenshot of courses for Grafana Labs employees in Docebo.&#34;width=&#34;1010&#34;height=&#34;748&#34;title=&#34;*Custom toolkits on Docebo encourage continued learning about various topics.*&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;figcaption class=&#34;w-100p caption text-gray-13 &#34;&gt;&lt;em&gt;Custom toolkits on Docebo encourage continued learning about various topics.&lt;/em&gt;&lt;/figcaption&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;Additionally, our partnership with LinkedIn Learning allows our team members to browse thousands of additional courses directly from our LMS.&lt;/p&gt;&#xA;&lt;p&gt;We’re also working on a new Learning &amp;amp; Development Hub that will serve as a one-stop shop for employees to access process documentation, public speaking resources, new hire onboarding documentation, and other on-demand learning materials.&lt;/p&gt;&#xA;&lt;h2 id=&#34;learning-live-and-with-your-team&#34;&gt;Learning live (and with your team)&lt;/h2&gt;&#xA;&lt;p&gt;As a remote-first company, we want to help Grafanistas build connections with their peers, even when they live on different continents. One way we achieve this — while also encouraging continuous learning — is through our Concierge Services, a program that offers live learning opportunities in a group setting.&lt;/p&gt;&#xA;&lt;p&gt;Concierge Services brings learning directly to Grafana Labs employees. They simply choose from a menu of courses, let us know their preferred date and time, and that’s it! Our L&amp;amp;D team handles the coordination, preparation, and delivery of the training — either in person or virtually — by an experienced facilitator. Sessions can be run for as few or as many people as desired and span a variety of topics, including time management, career progression, and public speaking. If one of the existing sessions doesn’t quite hit the mark, Grafanistas can request custom sessions designed specifically for their unique interests.&lt;/p&gt;&#xA;&lt;h2 id=&#34;professional-development-budget&#34;&gt;Professional development budget&lt;/h2&gt;&#xA;&lt;p&gt;When Grafanistas want to branch out a bit further — maybe to obtain a professional certification, learn another language, or attend an industry conference — we offer our professional development budget.&lt;/p&gt;&#xA;&lt;p&gt;Each Grafana Labs employee is allocated $1500 USD per calendar year to invest in their professional development. Few limits exist on the program; everybody has the freedom to use their budget in a way that works for them.&lt;/p&gt;&#xA;&lt;p&gt;This year, I used my professional development budget to attend the &lt;a href=&#34;https://afrotechconference.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Afrotech Conference&lt;/a&gt; in Houston, Texas. It was so exciting to build out connections, network with other professionals, and learn valuable insights to bring back to Grafana Labs at the end of my trip!&lt;/p&gt;&#xA;&lt;p&gt;Other common ways to use the budget include spending on:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Books&lt;/strong&gt;: &lt;a href=&#34;https://brenebrown.com/hubs/dare-to-lead/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;“Dare to Lead”&lt;/a&gt; by Brene Brown is a popular one.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Industry certifications&lt;/strong&gt;: For our engineers, &lt;a href=&#34;https://kubernetes.io/training/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Kubernetes&lt;/a&gt; and &lt;a href=&#34;https://www.comptia.org/certifications&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;CompTIA&lt;/a&gt; certifications are especially common.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Subscriptions&lt;/strong&gt;: &lt;a href=&#34;https://www.shrm.org/home&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;SHRM memberships&lt;/a&gt;, as one example, are something our People Team recommends.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Conferences&lt;/strong&gt;: In the past, Grafanistas have attended the &lt;a href=&#34;https://www.gs1us.org/education-and-events/events/gs1-connect&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;GS1 Connect Summit&lt;/a&gt;, &lt;a href=&#34;https://latinasintech.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Latinas in Tech&lt;/a&gt;, and, of course, major events in the open source software space, such as &lt;a href=&#34;https://events.linuxfoundation.org/kubecon-cloudnativecon-north-america/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;KubeCon&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Other &lt;strong&gt;technical or professional development courses&lt;/strong&gt;, including those offered by &lt;a href=&#34;https://www.boot.dev/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Boot.dev&lt;/a&gt; and &lt;a href=&#34;https://www.udemy.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Udemy&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;learn-more-about-working-at-grafana-labs&#34;&gt;Learn more about working at Grafana Labs&lt;/h2&gt;&#xA;&lt;p&gt;At Grafana Labs, you never age out of discovering new things. By taking advantage of our on-demand and live learning opportunities, each Grafanista has the opportunity to expand their knowledge and lean into our value of helping ourselves, and others, thrive.&lt;/p&gt;&#xA;&lt;p&gt;If you’re interested in learning more about working at Grafana Labs — including some of our open positions right now — please refer to our &lt;a href=&#34;/about/careers/&#34;&gt;careers page&lt;/a&gt;. We’d love to hear from you!&lt;/p&gt;】&lt;p&gt;&lt;em&gt;&lt;strong&gt;“你今天学到了什么？”&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;这是我们很多人小时候都听过的问题。也许是家长在放学回家的路上问你，或者是餐桌旁的兄弟姐妹，甚至是家庭聚会上好奇的阿姨或叔叔。但是，最后一次有人问你，作为一个成年人，你在一天结束时实际上学到了什么？&lt;/p&gt;&#xA;&lt;p&gt;事实是，随着年龄的增长，不断学习的期望逐渐减弱。看来我们只是太累了，或者太忙于其他责任，无法一直学习。作为 Grafana Labs 学习和开发团队的一员，我努力重新设定这一期望。&lt;/p&gt;&#xA;&lt;p&gt;自公司成立之初起，我们就培养了持续学习的文化。我们从员工成为 Grafanista 的头几天开始，从我们的虚拟入职会议开始（Grafana Labs 是一个 &lt;a href=&#34;/blog/2023/05/12/inside-grafana-labs-remote-first-is-relationship -first/&#34;&gt;远程优先公司&lt;/a&gt;），然后通过我们为期一周的面对面入职活动，这是与其他新员工和成员建立联系的好方法Grafana Labs 领导团队。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1999px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接标题”&#xA;href=&#34;/media/blog/continuous-learning/continuous-learning-onboarding.jpg&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“lazyload mb-0”&#xA;数据-src =“/媒体/博客/连续学习/连续学习-onboarding.jpg”数据-srcset =“/媒体/博客/连续学习/连续学习-onboarding.jpg？w = 320 320w，/媒体/博客/持续学习/持续学习-onboarding.jpg？w=550 550w， /media/blog/持续学习/持续学习-onboarding.jpg？w=750 750w，/media/blog/持续学习/持续学习-onboarding.jpg？w=900 900w，/media/博客/连续-学习/持续学习-onboarding.jpg?w=1040 1040w, /media/blog/持续学习/持续学习-onboarding.jpg？w=1240 1240w，/媒体/博客/持续学习/持续学习-onboarding.jpg？w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;最近 Grafana Labs 入职活动的照片。&#34;width=&#34;1999&#34;height=&#34;1051&#34;title=&#34;*2024 年在华盛顿举行的 Grafana Labs 现场入职活动的照片，直流电。*&#34;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/Continous-learning/Continous-learning-onboarding.jpg”&#xA;alt=&#34;最近 Grafana Labs 入职活动的照片。&#34;width=&#34;1999&#34;height=&#34;1051&#34;title=&#34;*2024 年在华盛顿特区举办的 Grafana Labs 现场入职活动的照片。*&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;figcaption class=&#34;w-100p title text-gray-13 &#34;&gt;&lt;em&gt;2024 年在华盛顿特区举办的 Grafana Labs 现场入职活动照片。&lt;/em&gt;&lt;/em&gt;&lt;/noscript&gt;&lt;/div&gt;图标题&gt;&lt;/a&gt;&lt;/图&gt;&#xA;&lt;p&gt;我们的目标是通过大力投资于他们的初始入职体验，激励员工从一开始就学习和成长。但我们也鼓励让员工在整个职业生涯中都能在 Grafana Labs 继续学习。&lt;/p&gt;&#xA;&lt;p&gt;在这篇文章中，我们具体分享了我们是如何做到这一点的。请继续阅读，详细了解我们的学习管理系统、专业发展预算以及我们确保 Grafanista 每天都能学到东西的其他方法。&lt;/p&gt;&#xA;&lt;h2 id=&#34;learning-on-demand&#34;&gt;按需学习&lt;/h2&gt;&#xA;&lt;p&gt;所有 Grafana Labs 员工都被尊重地授权以最适合自己的方式工作。灵活性和自主性是&lt;a href=&#34;/about/careers/&#34;&gt;我们工作的基石&lt;/a&gt;，因此这些价值观也延伸到我们的学习文化中是有道理的。因此，我们为 Grafanista 提供各种点播资源，让他们了解他们想学什么、何时以及如何学习。&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.docebo.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Docebo&lt;/a&gt;，我们的学习管理系统 (LMS)，提供对各种内容的访问定制课程。这些课程由 Grafanistas 创建，为 Grafanistas 提供，提供了适合我们独特情况的相关内容。&lt;/p&gt;&#xA;&lt;p&gt;例如，我们的升级工具包包含精选资源，可帮助职能经理更深入地研究授权、变更管理和反馈等关键主题。这些工具包是学习路径的一部分，Grafana Labs 员工可以根据自己的兴趣和空闲时间自由选择加入或退出。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1010px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接标题”&#xA;href=&#34;/media/blog/continuous-learning/continuous-learning-toolkit.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“lazyload mb-0”&#xA;data-src =“/media/blog/Continous-learning/Continous-learning-toolkit.png”data-srcset =“/media/blog/Continous-learning/Continous-learning-toolkit.png？w = 320 320w，/媒体/博客/持续学习/持续学习工具包.png？w=550 550w， /media/blog/continuous-learning/continuous-learning-toolkit.png?w=750 750w, /media/blog/continuous-learning/continuous-learning-toolkit.png?w=900 900w, /media/blog/continuous -学习/持续学习工具包.png?w=1040 1040w, /media/blog/Continous-learning/Continous-learning-toolkit.png?w=1240 1240w，/media/blog/Continous-learning/Continous-learning-toolkit.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;Docebo 中为 Grafana Labs 员工提供的课程屏幕截图。&#34;width=&#34;1010&#34;height=&#34;748&#34;title=&#34;*Docebo 上的自定义工具包鼓励继续学习各种主题。*&#34;/ &gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/Continous-learning/Continous-learning-toolkit.png”&#xA;alt=&#34;Docebo 中为 Grafana Labs 员工提供的课程屏幕截图。&#34;width=&#34;1010&#34;height=&#34;748&#34;title=&#34;*Docebo 上的自定义工具包鼓励继续学习各种主题。*&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;figcaption class=&#34;w-100p title text-gray-13 &#34;&gt;&lt;em&gt;Docebo 上的自定义工具包鼓励继续学习各种主题。&lt;/em&gt;&lt;/figca选项&gt;&lt;/a&gt;&lt;/图&gt;&#xA;&lt;p&gt;此外，我们与 LinkedIn Learning 的合作伙伴关系使我们的团队成员可以直接从我们的 LMS 浏览数千个其他课程。&lt;/p&gt;&#xA;&lt;p&gt;我们还在开发一个新的学习与发展中心，该中心将作为员工访问流程文档、公开演讲资源、新员工入职文档和其他按需学习材料的一站式商店。&lt;/ p&gt;&#xA;&lt;h2 id=&#34;learning-live-and-with-your-team&#34;&gt;现场学习（并与您的团队一起）&lt;/h2&gt;&#xA;&lt;p&gt;作为一家远程优先的公司，我们希望帮助 Grafanista 与同行建立联系，即使他们生活在不同的大陆。我们实现这一目标的方法之一是通过我们的礼宾服务，同时也鼓励持续学习，这是一项在团体环境中提供现场学习机会的计划。&lt;/p&gt;&#xA;&lt;p&gt;礼宾服务直接为 Grafana Labs 员工带来学习。他们只需从课程菜单中进行选择，让我们知道他们喜欢的日期和时间，就这样！我们的学习与发展团队由经验丰富的辅导员负责亲自或虚拟培训的协调、准备和交付。会议可以根据需要为尽可能少的人或任意多的人举办，并且涵盖各种主题，包括时间管理、职业发展和公开演讲。如果现有会议之一不太符合要求，Grafanista 可以请求专门针对他们独特兴趣设计的自定义会议。&lt;/p&gt;&#xA;&lt;h2 id=&#34;professional-development-budget&#34;&gt;专业发展预算&lt;/h2&gt;&#xA;&lt;p&gt;当 Grafanista 想要进一步扩展时（也许是为了获得专业认证、学习另一种语言或参加行业会议），我们会提供专业发展预算。&lt;/p&gt;&#xA;&lt;p&gt;每个 Grafana Labs 员工每年都会获得 1500 美元的拨款，用于投资于他们的专业发展。该计划几乎没有限制；每个人都可以自由地以适合自己的方式使用预算。&lt;/p&gt;&#xA;&lt;p&gt;今年，我用我的专业发展预算参加了在休斯顿举行的&lt;a href=&#34;https://afrotechconference.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Afrotech 会议&lt;/a&gt;，德克萨斯州。与其他专业人士建立联系、建立联系并学习宝贵的见解并在旅行结束时带回 Grafana Labs 真是太令人兴奋了！&lt;/p&gt;&#xA;&lt;p&gt;使用预算的其他常见方式包括支出：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;书籍&lt;/strong&gt;：&lt;a href=&#34;https://brenebrown.com/hubs/dare-to-lead/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;“敢于领导”&lt;/a&gt; 布琳·布朗 (Brene Brown) 的作品很受欢迎。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;行业认证&lt;/strong&gt;：对于我们的工程师来说，&lt;a href=&#34;https://kubernetes.io/training/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Kubernetes&lt;/a&gt; &lt;a href=&#34;https://www.comptia.org/certifications&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;CompTIA&lt;/a&gt; 认证尤其常见。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;订阅&lt;/strong&gt;：&lt;a href=&#34;https://www.shrm.org/home&#34; target=&#34;_例如，我们的人员团队建议加入空白&#34; rel=&#34;noopener noreferrer&#34;&gt;SHRM 会员资格&lt;/a&gt;。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;会议&lt;/strong&gt;：过去，Grafanista 曾参加过&lt;a href=&#34;https://www.gs1us.org/education-and-events/events/gs1-connect&#34; target=&#34; _blank&#34; rel=&#34;noopener noreferrer&#34;&gt;GS1 Connect 峰会&lt;/a&gt;，&lt;a href=&#34;https://latinasintech.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;拉丁裔科技&lt;/a&gt;，当然还有开源软件领域的重大事件，例如 &lt;a href=&#34;https://events.linuxfoundation.org/kubecon-cloudnativecon-north-america/&#34; target=&#34; _blank&#34; rel=&#34;noopener noreferrer&#34;&gt;KubeCon&lt;/a&gt;。&lt;/li&gt;&#xA;&lt;li&gt;其他&lt;strong&gt;技术或专业发展课程&lt;/strong&gt;，包括 &lt;a href=&#34;https://www.boot.dev/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Boot 提供的课程.dev&lt;/a&gt; 和 &lt;a href=&#34;https://www.udemy.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Udemy&lt;/a&gt;。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;learn-more-about-working-at-grafana-labs&#34;&gt;了解有关在 Grafana Labs 工作的更多信息&lt;/h2&gt;&#xA;&lt;p&gt;在 Grafana Labs，您永远不会因发现新事物而变老。通过利用我们的点播和实时学习机会，每个 Grafanista 都有机会扩展他们的知识，并了解我们帮助自己和他人蓬勃发展的价值观。&lt;/p&gt;&#xA;&lt;p&gt;如果您有兴趣了解有关在 Grafana Labs 工作的更多信息（包括我们目前的一些空缺职位），请参阅我们的&lt;a href=&#34;/about/careers/&#34;&gt;职业页面&lt;/a&gt;。我们很乐意听取您的意见！&lt;/p&gt;</description>
      <pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【How to securely connect Grafana to Google BigQuery using Workload Identity Federation】如何使用工作负载身份联合安全地将 Grafana 连接到 Google BigQuery</title>
      <link>https://grafana.com/blog/2024/12/17/how-to-securely-connect-grafana-to-google-bigquery-using-workload-identity-federation/</link>
      <description>【&lt;p&gt;&lt;em&gt;Umesh Pawar is a Senior Cloud Engineer at Searce, and is also the co-organizer of the Grafana and Friends Delhi Group. Umesh has been focused on infrastructure and app modernization, as well as observability solutions including the Grafana LGTM Stack, for the past two years.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;With the &lt;a href=&#34;/grafana/plugins/grafana-bigquery-datasource/&#34;&gt;Google BigQuery data source plugin&lt;/a&gt; for Grafana, you can easily query and visualize data from BigQuery directly in Grafana. This enables a wide range of use cases, such as creating dashboards for log analysis, billing data, sales metrics, traffic analysis, and digital marketing campaign tracking.&lt;/p&gt;&#xA;&lt;p&gt;When running Grafana on Google Kubernetes Engine (GKE) and connecting to BigQuery as a data source, it&amp;rsquo;s essential to prioritize security. This blog explores how Workload Identity Federation can help you securely connect a Grafana instance running on GKE to the Google BigQuery service without exposing a service account key.&lt;/p&gt;&#xA;&lt;h2 id=&#34;authentication-with-gcp-using-workload-identity-federation&#34;&gt;Authentication with GCP using Workload Identity Federation&lt;/h2&gt;&#xA;&lt;p&gt;You can securely access Google Cloud APIs from your workloads running in GKE clusters by using &lt;a href=&#34;https://cloud.google.com/iam/docs/workload-identity-federation&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Workload Identity Federation&lt;/a&gt; for GKE.&lt;/p&gt;&#xA;&lt;p&gt;If you are running Grafana on GKE in &lt;a href=&#34;https://cloud.google.com/kubernetes-engine/docs/concepts/autopilot-overview&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Autopilot &lt;/a&gt;mode, Workload Identity Federation is enabled by default. When you are running in &lt;a href=&#34;https://cloud.google.com/kubernetes-engine/docs/concepts/choose-cluster-mode&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Standard&lt;/a&gt; mode, you enable Workload Identity Federation on clusters and node pools using the Google Cloud CLI or the Google Cloud console. Workload Identity Federation for GKE must be enabled at the cluster level before you can enable it for GKE on node pools.&lt;/p&gt;&#xA;&lt;p&gt;To enable on a new cluster:&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;button x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;Copy code to clipboard&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;Copy&lt;/span&gt;&#xA;&lt;/button&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;gcloud container clusters create CLUSTER_NAME \&#xA;--location=LOCATION \&#xA;--workload-pool=PROJECT_ID.svc.id.goog&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;p&gt;To enable on an existing cluster:&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;button x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;Copy code to clipboard&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;Copy&lt;/span&gt;&#xA;&lt;/button&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;gcloud container clusters update CLUSTER_NAME \&#xA;--location=LOCATION \&#xA;--workload-pool=PROJECT_ID.svc.id.goog&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;h2 id=&#34;configure-grafana-to-use-workload-identity-federation-for-gke&#34;&gt;Configure Grafana to use Workload Identity Federation for GKE&lt;/h2&gt;&#xA;&lt;p&gt;To let your GKE application — in our case, Grafana — authenticate to Google Cloud APIs using Workload Identity Federation for GKE, you need to create IAM policies for the specific APIs.&lt;/p&gt;&#xA;&lt;p&gt;If you are using a Helm chart, just edit this code to values.yaml.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1452px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/bigquery-grafana/bigquery-grafana-service-account-code.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/bigquery-grafana/bigquery-grafana-service-account-code.png&#34;data-srcset=&#34;/media/blog/bigquery-grafana/bigquery-grafana-service-account-code.png?w=320 320w, /media/blog/bigquery-grafana/bigquery-grafana-service-account-code.png?w=550 550w, /media/blog/bigquery-grafana/bigquery-grafana-service-account-code.png?w=750 750w, /media/blog/bigquery-grafana/bigquery-grafana-service-account-code.png?w=900 900w, /media/blog/bigquery-grafana/bigquery-grafana-service-account-code.png?w=1040 1040w, /media/blog/bigquery-grafana/bigquery-grafana-service-account-code.png?w=1240 1240w, /media/blog/bigquery-grafana/bigquery-grafana-service-account-code.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A screenshot of code for IAM policies.&#34;width=&#34;1452&#34;height=&#34;548&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/bigquery-grafana/bigquery-grafana-service-account-code.png&#34;&#xA;alt=&#34;A screenshot of code for IAM policies.&#34;width=&#34;1452&#34;height=&#34;548&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;If you are deploying as a &lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/deployment/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Kubernetes deployment&lt;/a&gt;, create a &lt;a href=&#34;https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Kubernetes service account&lt;/a&gt; for Grafana to use. You can also use any existing Kubernetes service account in any namespace. If you don&amp;rsquo;t assign a service account to your workload, Kubernetes assigns the default service account in the namespace.&lt;/p&gt;&#xA;&lt;p&gt;Grant your IAM service account the roles that it needs on specific Google Cloud APIs. In our case, Grafana wants to query the BigQuery API, so we will give it the &lt;a href=&#34;https://cloud.google.com/bigquery/docs/access-control#bigquery.admin&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;BigQuery Admin role&lt;/a&gt; (but, in general, always follow the principle of least privilege).&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;button x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;Copy code to clipboard&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;Copy&lt;/span&gt;&#xA;&lt;/button&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;gcloud projects add-iam-policy-binding IAM_SA_PROJECT_ID \&#xA;--member &amp;#34;serviceAccount:IAM_SA_NAME@IAM_SA_PROJECT_ID.iam.gserviceaccount.com&amp;#34; \&#xA;--role &amp;#34;ROLE_NAME&amp;#34;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;p&gt;Create an &lt;a href=&#34;https://cloud.google.com/iam/docs/policies&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;IAM allow policy&lt;/a&gt; that gives the Kubernetes service account access to impersonate the IAM service account. As a good practice, grant permissions to specific Google Cloud resources that your application needs to access. You must have relevant IAM permissions to create allow policies in your project.&lt;/p&gt;&#xA;&lt;p&gt;In the code block below, &lt;code&gt;KSA_NAME&lt;/code&gt; represents the Kubernetes service account name attached to the Grafana workload, and&lt;code&gt;NAMESPACE&lt;/code&gt; represents the namespace on which Grafana is deployed.&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;button x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;Copy code to clipboard&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;Copy&lt;/span&gt;&#xA;&lt;/button&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;gcloud iam service-accounts add-iam-policy-binding IAM_SA_NAME@IAM_SA_PROJECT_ID.iam.gserviceaccount.com \&#xA;--role roles/iam.workloadIdentityUser \&#xA;--member &amp;#34;serviceAccount:PROJECT_ID.svc.id.goog[NAMESPACE/KSA_NAME]&amp;#34;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;p&gt;Now we need to annotate the Kubernetes service account so GKE sees the link between the service accounts. &lt;em&gt;Note: if you are deploying through Helm, skip this step and instead annotate on your Helm chart, as seen on the above step.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;button x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;Copy code to clipboard&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;Copy&lt;/span&gt;&#xA;&lt;/button&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;kubectl annotate serviceaccount KSA_NAME \&#xA;--namespace NAMESPACE \&#xA;iam.gke.io/gcp-service-account=IAM_SA_NAME@IAM_SA_PROJECT_ID.iam.gserviceaccount.com&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;h2 id=&#34;configure-the-google-bigquery-data-source-for-grafana&#34;&gt;Configure the Google BigQuery data source for Grafana&lt;/h2&gt;&#xA;&lt;p&gt;As mentioned above, the &lt;a href=&#34;/grafana/plugins/grafana-bigquery-datasource/&#34;&gt;Google BigQuery data source plugin&lt;/a&gt; allows you to query and visualize Google BigQuery data from within Grafana.&lt;/p&gt;&#xA;&lt;h3 id=&#34;install-the-plugin&#34;&gt;Install the plugin&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Navigate to the BigQuery plugin homepage.&lt;/li&gt;&#xA;&lt;li&gt;On the right-hand side, click the &lt;strong&gt;Install&lt;/strong&gt; button.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1600px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/bigquery-grafana/bigquery-grafana-install-plugin-page.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/bigquery-grafana/bigquery-grafana-install-plugin-page.png&#34;data-srcset=&#34;/media/blog/bigquery-grafana/bigquery-grafana-install-plugin-page.png?w=320 320w, /media/blog/bigquery-grafana/bigquery-grafana-install-plugin-page.png?w=550 550w, /media/blog/bigquery-grafana/bigquery-grafana-install-plugin-page.png?w=750 750w, /media/blog/bigquery-grafana/bigquery-grafana-install-plugin-page.png?w=900 900w, /media/blog/bigquery-grafana/bigquery-grafana-install-plugin-page.png?w=1040 1040w, /media/blog/bigquery-grafana/bigquery-grafana-install-plugin-page.png?w=1240 1240w, /media/blog/bigquery-grafana/bigquery-grafana-install-plugin-page.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A screenshot of the the installation page for the BigQuery data source in Grafana.&#34;width=&#34;1600&#34;height=&#34;902&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/bigquery-grafana/bigquery-grafana-install-plugin-page.png&#34;&#xA;alt=&#34;A screenshot of the the installation page for the BigQuery data source in Grafana.&#34;width=&#34;1600&#34;height=&#34;902&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;h3 id=&#34;verify-that-the-plugin-is-installed&#34;&gt;Verify that the plugin is installed&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;In Grafana, navigate to &lt;strong&gt;Configuration &amp;gt; Data sources&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;From the top-right corner, click the &lt;strong&gt;Add data source&lt;/strong&gt; button.&lt;/li&gt;&#xA;&lt;li&gt;Search for Google BigQuery in the search field, and hover over the Google BigQuery search result.&lt;/li&gt;&#xA;&lt;li&gt;Click the &lt;strong&gt;Select&lt;/strong&gt; button for Google BigQuery. If you can click the &lt;strong&gt;Select&lt;/strong&gt; button, then it is installed.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1600px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/bigquery-grafana/bigquery-grafana-verify-the-data-source-works.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/bigquery-grafana/bigquery-grafana-verify-the-data-source-works.png&#34;data-srcset=&#34;/media/blog/bigquery-grafana/bigquery-grafana-verify-the-data-source-works.png?w=320 320w, /media/blog/bigquery-grafana/bigquery-grafana-verify-the-data-source-works.png?w=550 550w, /media/blog/bigquery-grafana/bigquery-grafana-verify-the-data-source-works.png?w=750 750w, /media/blog/bigquery-grafana/bigquery-grafana-verify-the-data-source-works.png?w=900 900w, /media/blog/bigquery-grafana/bigquery-grafana-verify-the-data-source-works.png?w=1040 1040w, /media/blog/bigquery-grafana/bigquery-grafana-verify-the-data-source-works.png?w=1240 1240w, /media/blog/bigquery-grafana/bigquery-grafana-verify-the-data-source-works.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A screenshot of the Settings tab for the BigQuery data source in Grafana.&#34;width=&#34;1600&#34;height=&#34;853&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/bigquery-grafana/bigquery-grafana-verify-the-data-source-works.png&#34;&#xA;alt=&#34;A screenshot of the Settings tab for the BigQuery data source in Grafana.&#34;width=&#34;1600&#34;height=&#34;853&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;h3 id=&#34;authentication&#34;&gt;Authentication&lt;/h3&gt;&#xA;&lt;p&gt;By automatically retrieving credentials using Workload Identity Federation (when running Grafana on GKE), make sure that the service account has been given read access to the BigQuery API.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1600px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/bigquery-grafana/bigquery-grafana-plugin-authentication.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/bigquery-grafana/bigquery-grafana-plugin-authentication.png&#34;data-srcset=&#34;/media/blog/bigquery-grafana/bigquery-grafana-plugin-authentication.png?w=320 320w, /media/blog/bigquery-grafana/bigquery-grafana-plugin-authentication.png?w=550 550w, /media/blog/bigquery-grafana/bigquery-grafana-plugin-authentication.png?w=750 750w, /media/blog/bigquery-grafana/bigquery-grafana-plugin-authentication.png?w=900 900w, /media/blog/bigquery-grafana/bigquery-grafana-plugin-authentication.png?w=1040 1040w, /media/blog/bigquery-grafana/bigquery-grafana-plugin-authentication.png?w=1240 1240w, /media/blog/bigquery-grafana/bigquery-grafana-plugin-authentication.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A screenshot of the Authentication page for the BigQuery data source plugin.&#34;width=&#34;1600&#34;height=&#34;904&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/bigquery-grafana/bigquery-grafana-plugin-authentication.png&#34;&#xA;alt=&#34;A screenshot of the Authentication page for the BigQuery data source plugin.&#34;width=&#34;1600&#34;height=&#34;904&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;h3 id=&#34;query-the-data-source&#34;&gt;Query the data source&lt;/h3&gt;&#xA;&lt;p&gt;The query editor allows you to query the Google BigQuery data source. Queries can contain &lt;a href=&#34;/docs/plugins/yesoreyeram-infinity-datasource/latest/query/macros/&#34;&gt;macros&lt;/a&gt;, which simplify syntax and allow your queries to be more dynamic. The SQL query editor comes with a rich support for standard SQL, as well as autocompletion for:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;BigQuery standard SQL language syntax&lt;/li&gt;&#xA;&lt;li&gt;BigQuery datasets, tables, and columns&lt;/li&gt;&#xA;&lt;li&gt;Macros and template variables&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1600px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/bigquery-grafana/bigquery-grafana-query-the-data-source.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/bigquery-grafana/bigquery-grafana-query-the-data-source.png&#34;data-srcset=&#34;/media/blog/bigquery-grafana/bigquery-grafana-query-the-data-source.png?w=320 320w, /media/blog/bigquery-grafana/bigquery-grafana-query-the-data-source.png?w=550 550w, /media/blog/bigquery-grafana/bigquery-grafana-query-the-data-source.png?w=750 750w, /media/blog/bigquery-grafana/bigquery-grafana-query-the-data-source.png?w=900 900w, /media/blog/bigquery-grafana/bigquery-grafana-query-the-data-source.png?w=1040 1040w, /media/blog/bigquery-grafana/bigquery-grafana-query-the-data-source.png?w=1240 1240w, /media/blog/bigquery-grafana/bigquery-grafana-query-the-data-source.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A screenshot of a query for the BigQuery data source.&#34;width=&#34;1600&#34;height=&#34;908&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/bigquery-grafana/bigquery-grafana-query-the-data-source.png&#34;&#xA;alt=&#34;A screenshot of a query for the BigQuery data source.&#34;width=&#34;1600&#34;height=&#34;908&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;h2 id=&#34;how-to-learn-more&#34;&gt;How to learn more&lt;/h2&gt;&#xA;&lt;p&gt;To explore more on this topic, you can check out &lt;a href=&#34;https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;these docs&lt;/a&gt; about Workload Identity Federation for GKE, as well as&lt;a href=&#34;/grafana/plugins/grafana-bigquery-datasource/&#34;&gt; this page&lt;/a&gt; dedicated to the BigQuery data source plugin for Grafana.&lt;/p&gt;】&lt;p&gt;&lt;em&gt;Umesh Pawar 是 Searce 的高级云工程师，也是 Grafana 和 Friends Delhi Group 的联合组织者。过去两年，Umesh 一直专注于基础设施和应用现代化，以及包括 Grafana LGTM Stack 在内的可观测性解决方案。&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;借助适用于 Grafana 的 &lt;a href=&#34;/grafana/plugins/grafana-bigquery-datasource/&#34;&gt;Google BigQuery 数据源插件&lt;/a&gt;，您可以直接在 Grafana 中轻松查询和可视化来自 BigQuery 的数据。这支持广泛的用例，例如创建用于日志分析、计费数据、销售指标、流量分析和数字营销活动跟踪的仪表板。&lt;/p&gt;&#xA;&lt;p&gt;在 Google Kubernetes Engine (GKE) 上运行 Grafana 并连接到 BigQuery 作为数据源时，必须优先考虑安全性。本博客探讨了 Workload Identity Federation 如何帮助您将 GKE 上运行的 Grafana 实例安全地连接到 Google BigQuery 服务，而无需暴露服务帐户密钥。&lt;/p&gt;&#xA;&lt;h2 id=&#34;authentication-with-gcp-using-workload-identity-federation&#34;&gt;使用工作负载联合身份验证通过 GCP 进行身份验证&lt;/h2&gt;&#xA;&lt;p&gt;您可以使用 &lt;a href=&#34;https://cloud.google.com/iam/docs/workload-identity-federation&#34; target=&#34;_blank&#34; rel 从 GKE 集群中运行的工作负载安全地访问 Google Cloud API =&#34;noopener noreferrer&#34;&gt;GKE 的工作负载身份联合&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;如果您在 &lt;a href=&#34;https://cloud.google.com/kubernetes-engine/docs/concepts/autopilot-overview&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt; 中的 GKE 上运行 Grafana Autopilot 模式，Workload Identity Federation 默认启用。当您以&lt;a href=&#34;https://cloud.google.com/kubernetes-engine/docs/concepts/choose-cluster-mode&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;标准&lt;/a运行时&gt; 模式下，您可以使用 Google Cloud CLI 或 Google Cloud 控制台在集群和节点池上启用工作负载联合身份验证。必须先在集群级别启用 GKE 的工作负载身份联合，然后才能在节点池上为 GKE 启用它。&lt;/p&gt;&#xA;&lt;p&gt;要在新集群上启用：&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;按钮 x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;将代码复制到剪贴板&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;复制&lt;/span&gt;&#xA;&lt;/按钮&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;gcloud 容器集群创建 CLUSTER_NAME \&#xA;--位置=位置\&#xA;--workload-pool=PROJECT_ID.svc.id.goog&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;p&gt;要在现有集群上启用：&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;按钮 x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;将代码复制到剪贴板”宽度=“14”高度=“13”&gt;&#xA;&lt;span&gt;复制&lt;/span&gt;&#xA;&lt;/按钮&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;gcloud 容器集群更新 CLUSTER_NAME \&#xA;--位置=位置\&#xA;--workload-pool=PROJECT_ID.svc.id.goog&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;h2 id=&#34;configure-grafana-to-use-workload-identity-federation-for-gke&#34;&gt;配置 Grafana 以使用适用于 GKE 的工作负载联合身份验证&lt;/h2&gt;&#xA;&lt;p&gt;要让您的 GKE 应用程序（在我们的示例中为 Grafana）使用 Workload Identity Federation for GKE 向 Google Cloud API 进行身份验证，您需要为特定 API 创建 IAM 政策。&lt;/p&gt;&#xA;&lt;p&gt;如果您使用的是 Helm 图表，只需将此代码编辑为values.yaml。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1452px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/bigquery-grafana/bigquery-grafana-service-account-code.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/blog/bigquery-grafana/bigquery-grafana-service-account-code.png&#34;data-srcset=&#34;/media/blog/bigquery-grafana/bigquery-grafana-service-account-code. png?w=320 320w，/media/blog/bigquery-grafana/bigquery-grafana-service-account-code.png?w=550 550w， /media/blog/bigquery-grafana/bigquery-grafana-service-account-code.png?w=750 750w，/media/blog/bigquery-grafana/bigquery-grafana-service-account-code.png?w=900 900w，/media/blog/bigquery-grafana/bigquery-grafana-service-account-code.png?w=1040 1040w、/media/blog/bigquery-grafana/bigquery-grafana-service-account-code.png?w=1240 1240w、/media/blog/bigquery-grafana/bigquery-grafana-service-account-code.png?w =1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;IAM 策略代码的屏幕截图。&#34;width=&#34;1452&#34;height=&#34;548&#34;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src=&#34;/media/blog/bigquery-grafana/bigquery-grafana-service-account-code.png&#34;&#xA;alt=&#34;IAM 策略代码的屏幕截图。&#34;width=&#34;1452&#34;height=&#34;548&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;如果您要部署为 &lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/deployment/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Kubernetes 部署&lt;/a &gt;，创建一个 &lt;a href=&#34;https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Kubernetes 服务帐户&lt;/a&gt;供 Grafana 使用。您还可以使用任何命名空间中的任何现有 Kubernetes 服务帐户。如果您没有为工作负载分配服务帐户，Kubernetes 会在命名空间中分配默认服务帐户。&lt;/p&gt;&#xA;&lt;p&gt;向您的 IAM 服务帐号授予其在特定 Google Cloud API 上所需的角色。在我们的例子中，Grafana 想要查询 BigQuery API，因此我们将为它提供 &lt;a href=&#34;https://cloud.google.com/bigquery/docs/access-control#bigquery.admin&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;BigQuery 管理员角色&lt;/a&gt;（但是，一般来说，始终遵循最小权限原则伊莱格）。&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;按钮 x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;将代码复制到剪贴板&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;复制&lt;/span&gt;&#xA;&lt;/按钮&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;gcloud 项目 add-iam-policy-binding IAM_SA_PROJECT_ID \&#xA;--member &#34;serviceAccount:IAM_SA_NAME@IAM_SA_PROJECT_ID.iam.gserviceaccount.com&#34; \&#xA;--角色“ROLE_NAME”&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;p&gt;创建一个 &lt;a href=&#34;https://cloud.google.com/iam/docs/policies&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;IAM 允许政策&lt;/a&gt;授予 Kubernetes 服务帐户访问权限来模拟 IAM 服务帐户。最佳做法是向您的应用程序需要访问的特定 Google Cloud 资源授予权限。您必须拥有相关的 IAM 权限才能在项目中创建允许策略。&lt;/p&gt;&#xA;&lt;p&gt;在下面的代码块中，&lt;code&gt;KSA_NAME&lt;/code&gt; 表示附加到 Grafana 工作负载的 Kubernetes 服务帐户名称，&lt;code&gt;NAMESPACE&lt;/code&gt; 表示部署 Grafana 的命名空间。&lt;/p &gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;按钮 x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;将代码复制到剪贴板&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;复制&lt;/span&gt;&#xA;&lt;/按钮&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;gcloud iam service-accounts add-iam-policy-binding IAM_SA_NAME@IAM_SA_PROJECT_ID.iam.gserviceaccount.com \&#xA;--角色角色/iam.workloadIdentityUser \&#xA;--member &#34;serviceAccount:PROJECT_ID.svc.id.goog[NAMESPACE/KSA_NAME]&#34;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;p&gt;现在我们需要注释 Kubernetes 服务帐户，以便 GKE 看到服务帐户之间的链接。 &lt;em&gt;注意：如果您通过 Helm 进行部署，请跳过此步骤，而是在 Helm 图表上进行注释，如上述步骤所示。&lt;/em&gt;&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;按钮 x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;将代码复制到剪贴板&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;复制&lt;/span&gt;&#xA;&lt;/按钮&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;kubectl 注释 serviceaccount KSA_NAME \&#xA;--命名空间 命名空间 \&#xA;iam.gke.io/gcp-service-account=IAM_SA_NAME@IAM_SA_PROJECT_ID.iam.gserviceaccount.com&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;h2 id=&#34;configure-the-google-bigquery-data-source-for-grafana&#34;&gt;为 G 配置 Google BigQuery 数据源拉法纳&lt;/h2&gt;&#xA;&lt;p&gt;如上所述，&lt;a href=&#34;/grafana/plugins/grafana-bigquery-datasource/&#34;&gt;Google BigQuery 数据源插件&lt;/a&gt;可让您在 Grafana 中查询和可视化 Google BigQuery 数据。&lt;/ p&gt;&#xA;&lt;h3 id=&#34;install-the-plugin&#34;&gt;安装插件&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;导航至 BigQuery 插件主页。&lt;/li&gt;&#xA;&lt;li&gt;点击右侧的&lt;strong&gt;安装&lt;/strong&gt;按钮。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1600px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/bigquery-grafana/bigquery-grafana-install-plugin-page.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/blog/bigquery-grafana/bigquery-grafana-install-plugin-page.png&#34;data-srcset=&#34;/media/blog/bigquery-grafana/bigquery-grafana-install-plugin-page. png?w=320 320w，/media/blog/bigquery-grafana/bigquery-grafana-install-plugin-page.png?w=550 550w， /media/blog/bigquery-grafana/bigquery-grafana-install-plugin-page.png?w=750 750w，/media/blog/bigquery-grafana/bigquery-grafana-install-plugin-page.png?w=900 900w，/media/blog/bigquery-grafana/bigquery-grafana-install-plugin-page.png?w=1040 1040w、/media/blog/bigquery-grafana/bigquery-grafana-install-plugin-page.png?w=1240 1240w、/media/blog/bigquery-grafana/bigquery-grafana-install-plugin-page.png?w =1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;Grafana 中 BigQuery 数据源的安装页面的屏幕截图。&#34;width=&#34;1600&#34;height=&#34;902&#34;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src=&#34;/media/blog/bigquery-grafana/bigquery-grafana-install-plugin-page.png&#34;&#xA;alt=&#34;Grafana 中 BigQuery 数据源安装页面的屏幕截图。&#34;width=&#34;1600&#34;height=&#34;902&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;h3 id=&#34;verify-that-the-plugin-is-installed&#34;&gt;验证插件是否已安装&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;在 Grafana 中，导航至&lt;strong&gt;配置 &gt; 数据源&lt;/strong&gt;。&lt;/li&gt;&#xA;&lt;li&gt;点击右上角的&lt;strong&gt;添加数据源&lt;/strong&gt;按钮。&lt;/li&gt;&#xA;&lt;li&gt;在搜索字段中搜索 Google BigQuery，并将鼠标悬停在 Google BigQuery 搜索结果上。&lt;/li&gt;&#xA;&lt;li&gt;点击 Google BigQuery 的&lt;strong&gt;选择&lt;/strong&gt;按钮。如果您可以单击&lt;strong&gt;选择&lt;/strong&gt;按钮，则表示已安装。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1600px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/bigquery-grafana/bigquery-grafana-verify-the-data-source-works.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/blog/bigquery-grafana/bigquery-grafana-verify-the-data-source-works.png&#34;data-srcset=&#34;/media/blog/bigquery-grafana/bigquery-grafana-verify- the-data-source-works.png?w=320 320w, /media/blog/bigquery-grafana/bigquery-grafana-verify-the-data-source-works.png?w=550 550w，/media/blog/bigquery-grafana/bigquery-grafana-verify-the-data-source-works.png?w=750 750w，/media/blog/bigquery-grafana/bigquery-grafana-verify-the-data-source-works.png?w =900 900w， /media/blog/bigquery-grafana/bigquery-grafana-verify-the-data-source-works.png?w=1040 1040w，/media/blog/bigquery-grafana/bigquery-grafana-verify-the-data-source -works.png?w=1240 1240w, /media/blog/bigquery-grafana/bigquery-grafana-verify-the-data-source-works.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;Grafana 中 BigQuery 数据源的“设置”选项卡的屏幕截图。&#34;width=&#34;1600&#34;height=&#34;853&#34;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src=&#34;/media/blog/bigquery-grafana/bigquery-grafana-verify-the-data-source-works.png&#34;&#xA;alt=&#34;Grafana 中 BigQuery 数据源的“设置”选项卡的屏幕截图。&#34;width=&#34;1600&#34;height=&#34;853&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;h3 id=&#34;authentication&#34;&gt;身份验证&lt;/h3&gt;&#xA;&lt;p&gt;通过使用 Workload Identity Federation 自动检索凭据（在 GKE 上运行 Grafana 时），请确保服务帐户已被授予对 BigQuery API 的读取权限。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1600px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/bigquery-grafana/bigquery-grafana-plugin-authentication.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/blog/bigquery-grafana/bigquery-grafana-plugin-authentication.png&#34;data-srcset=&#34;/media/blog/bigquery-grafana/bigquery-grafana-plugin-authentication.png?w= 320 320w，/media/blog/bigquery-grafana/bigquery-grafana-plugin-authentication.png?w=550 550w、/media/blog/bigquery-grafana/bigquery-grafana-plugin-authentication.png?w=750 750w、/media/blog/bigquery-grafana/bigquery-grafana-plugin-authentication.png?w=900 900w、 /media/blog/bigquery-grafana/bigquery-grafana-plugin-authentication.png?w=1040 1040w, /media/blog/bigquery-grafana/bigquery-grafana-plugin-authentication.png?w=1240 1240w, /media/blog/bigquery-grafana/bigquery-grafana-plugin-authentication.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;BigQuery 数据源插件的身份验证页面的屏幕截图。&#34;width=&#34;1600&#34;height=&#34;904&#34;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src=&#34;/media/blog/bigquery-grafana/bigquery-grafana-plugin-authentication.png&#34;&#xA;alt=&#34;BigQuery 数据源插件的身份验证页面的屏幕截图。&#34;width=&#34;1600&#34;height=&#34;904&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;h3 id=&#34;query-the-data-source&#34;&gt;查询数据源&lt;/h3&gt;&#xA;&lt;p&gt;查询编辑器允许您查询 Google BigQuery 数据源。查询可以包含&lt;a href=&#34;/docs/plugins/yesoreyeram-infinity-datasource/latest/query/macros/&#34;&gt;宏&lt;/a&gt;，它简化了语法并使您的查询更加动态。 SQL 查询编辑器提供了对标准 SQL 的丰富支持，以及以下自动完成功能：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;BigQuery 标准 SQL 语言语法&lt;/li&gt;&#xA;&lt;li&gt;BigQuery 数据集、表和列&lt;/li&gt;&#xA;&lt;li&gt;宏和模板变量&lt;/li&gt;&#xA;&lt;/u我&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1600px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/bigquery-grafana/bigquery-grafana-query-the-data-source.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/blog/bigquery-grafana/bigquery-grafana-query-the-data-source.png&#34;data-srcset=&#34;/media/blog/bigquery-grafana/bigquery-grafana-query-the-数据源.png?w=320 320w，/media/blog/bigquery-grafana/bigquery-grafana-query-the-data-source.png?w=550 550w，/media/blog/bigquery-grafana/bigquery-grafana-query-the-data-source.png?w=750 750w，/media/blog/bigquery-grafana/bigquery-grafana-query-the-data-source .png?w=900 900w, /media/blog/bigquery-grafana/bigquery-grafana-query-the-data-source.png?w=1040 1040w，/media/blog/bigquery-grafana/bigquery-grafana-query-the-data-source.png ?w=1240 1240w, /media/blog/bigquery-grafana/bigquery-grafana-query-the-data-source.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;BigQuery 数据源查询的屏幕截图。&#34;width=&#34;1600&#34;height=&#34;908&#34;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/bigquery-grafana/bigquery-grafana-query-the-data-source.png”&#xA;alt=&#34;BigQuery 数据源查询的屏幕截图。&#34;width=&#34;1600&#34;height=&#34;908&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;h2 id=&#34;how-to-learn-more&#34;&gt;如何了解更多信息&lt;/h2&gt;&#xA;&lt;p&gt;要了解有关此主题的更多信息，您可以查看&lt;a href=&#34;https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity&#34; target=&#34;_blank&#34; rel= &#34;noopener noreferrer&#34;&gt;有关 GKE 的工作负载身份联合的这些文档&lt;/a&gt;，以及专门介绍 BigQuery 数据的&lt;a href=&#34;/grafana/plugins/grafana-bigquery-datasource/&#34;&gt;此页面&lt;/a&gt;来源Grafana 插件。&lt;/p&gt;</description>
      <pubDate>Tue, 17 Dec 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Grafana Labs: Top 10 moments of 2024】Grafana 实验室：2024 年十大时刻</title>
      <link>https://grafana.com/blog/2024/12/13/grafana-labs-top-10-moments-of-2024/</link>
      <description>【&lt;p&gt;2024 was a year of making connections.&lt;/p&gt;&#xA;&lt;p&gt;The open source community gathered in person for GrafanaCON for the first time in five years — meeting in Amsterdam to celebrate Grafana 11, Loki 3.0, a new open source project (cue Grafana Alloy), and more. TailCtrl, an early-stage company that specializes in adaptive trace sampling, joined Grafana Labs to advance our Adaptive Telemetry story (welcome, founder Sean Porter!). And we found exciting ways to make it easier for users to connect with their data, from query-free data analysis to launching new tools to help monitor multiple collectors (hello, Fleet Management).&lt;/p&gt;&#xA;&lt;p&gt;Above all, we have loved finding new ways to reach the open source community this year — whether it&amp;rsquo;s through fresh discussions on &amp;ldquo;Grafana&amp;rsquo;s Big Tent&amp;rdquo; podcast, gauging the opinions of more than 300 practitioners in our second annual Observability Survey, or working with emerging observability companies through the Grafana Labs Startup Program.&lt;/p&gt;&#xA;&lt;p&gt;&amp;ldquo;We really believe in the big tent, bringing together other projects, other ecosystems, other vendors all underneath Grafana, and helping you analyze your data no matter where it lives,&amp;rdquo; said Grafana Labs Co-founder and CEO Raj Dutt at GrafanaCON 2024, &amp;ldquo;and we are so privileged to be at the center of this really vibrant community and ecosystem.&amp;rdquo;&lt;/p&gt;&#xA;&lt;p&gt;Here are some of the highlights of 2024 for Grafana Labs.&lt;/p&gt;&#xA;&lt;h2 id=&#34;1-grafanacon-in-person-in-amsterdam&#34;&gt;1. GrafanaCON in person, in Amsterdam&lt;/h2&gt;&#xA;&lt;p&gt;The last time the Grafana community gathered in person for GrafanaCON? 2019 in Los Angeles. &amp;ldquo;I gotta say, after three or four years of virtual GrafanaCONs, I&amp;rsquo;m kind of virtual-ed out,&amp;rdquo; said Grafana Labs CEO and co-founder Raj Dutt. But no matter if it&amp;rsquo;s in person or online, &amp;ldquo;my overwhelming emotion at every GrafanaCON is really excitement and gratitude.&amp;rdquo;&lt;/p&gt;&#xA;&lt;p&gt;Same, Raj, same. Which is why it was thrilling to bring together about 400 attendees at GrafanaCON 2024 in Amsterdam for two days of community-led sessions, live demos, and hands-on workshops. (&lt;a href=&#34;/events/grafanacon/2024/?pg=blog&amp;amp;plcmt=body-txt#sessions&#34;&gt;Sessions are available on demand today&lt;/a&gt;!) We also celebrated the &lt;a href=&#34;/blog/2024/04/09/grafana-11-release-all-the-new-features/&#34;&gt;release of Grafana 11&lt;/a&gt;, the winners of the second annual &lt;a href=&#34;/golden-grot-awards/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Golden Grot Awards&lt;/a&gt;, and the opportunity to reunite with the open source community.&lt;/p&gt;&#xA;&lt;div&#xA;class=&#34;youtube-lazyload responsive-video&#34;&#xA;data-embed=&#34;L_GHahMOWEY&#34;&#xA;data-url=&#34;https://www.youtube.com/embed/L_GHahMOWEY?autoplay=1&amp;amp;rel=0&#34;&#xA;data-title=&#34;YouTube Video&#34;&#xA;&gt;&#xA;&lt;div class=&#34;play-button&#34;&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;Want to take part next year? Join us at &lt;a href=&#34;/events/grafanacon/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;GrafanaCON 2025&lt;/a&gt; from May 6 - 8 in Seattle. The &lt;a href=&#34;/events/grafanacon/#cfp&#34;&gt;CFP is open&lt;/a&gt;, and we are accepting applications for the &lt;a href=&#34;/golden-grot-awards/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Golden Grot Awards&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;2-loki-30-release&#34;&gt;2. Loki 3.0 release&lt;/h2&gt;&#xA;&lt;p&gt;Welcome to the next chapter of Grafana Loki! On the heels of the Loki project &lt;a href=&#34;/blog/2023/12/11/open-source-log-monitoring-the-concise-guide-to-grafana-loki/&#34;&gt;celebrating five years&lt;/a&gt; of growth and development, we rolled out &lt;a href=&#34;https://github.com/grafana/loki&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Grafana Loki 3.0&lt;/a&gt; at GrafanaCON in April.&lt;/p&gt;&#xA;&lt;p&gt;The latest major release of our open source log aggregation system introduced:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Accelerated query results.&lt;/strong&gt; Bloom filters is an experimental feature intended to help return “needle in a haystack” queries faster. After working with early adopters and seeing how Bloom filters worked at scale, we decided to adjust our approach in Loki 3.3 to &lt;a href=&#34;/blog/2024/11/21/grafana-loki-3.3-release-faster-query-results-via-blooms-for-structured-metadata/#query-acceleration-via-bloom-filters&#34;&gt;leverage structured metadata&lt;/a&gt;, making it faster to build, download, and query.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Native OpenTelemetry support.&lt;/strong&gt; Say good-bye to the Loki Exporter! Now that Loki has &lt;a href=&#34;/blog/2024/04/09/grafana-loki-3.0-release-all-the-new-features/#native-opentelemetry-support&#34;&gt;native OTel support&lt;/a&gt;, you get a simpler ingestion pipeline and a better querying experience since you can interact with all the OpenTelemetry attributes and log event metadata at query time without having to do any deserialization.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div&#xA;class=&#34;youtube-lazyload responsive-video&#34;&#xA;data-embed=&#34;H_7yHut6hvw&#34;&#xA;data-url=&#34;https://www.youtube.com/embed/H_7yHut6hvw?autoplay=1&amp;amp;rel=0&#34;&#xA;data-title=&#34;YouTube Video&#34;&#xA;&gt;&#xA;&lt;div class=&#34;play-button&#34;&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;It was also a huge year of growing adoption for Loki, which saw installs climb from 64,000 in 2023 to 132,000 in 2024.&lt;/p&gt;&#xA;&lt;p&gt;P.S. There&amp;rsquo;s still a few more weeks to go in the year, if you want to &lt;a href=&#34;https://github.com/grafana/loki&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;install Loki yourself!&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;3-grafana-alloy-launch&#34;&gt;3. Grafana Alloy launch&lt;/h2&gt;&#xA;&lt;p&gt;We welcomed a new open source project into the family and we are proud to announce: It&amp;rsquo;s a collector!&lt;/p&gt;&#xA;&lt;p&gt;Wait, &lt;em&gt;another&lt;/em&gt; collector?&lt;/p&gt;&#xA;&lt;p&gt;Hear us out: Grafana Alloy is our open source distribution of the OpenTelemetry Collector. It&amp;rsquo;s 100% OTLP compatible and offers native pipelines for OpenTelemetry and Prometheus telemetry formats, supporting metrics, logs, traces, and profiles. (For those of you familiar with Grafana Agent Flow, Alloy will make you feel right at home because it uses the same components, code, and concepts.)&lt;/p&gt;&#xA;&lt;div&#xA;class=&#34;youtube-lazyload responsive-video&#34;&#xA;data-embed=&#34;NrnLyDXpfq0&#34;&#xA;data-url=&#34;https://www.youtube.com/embed/NrnLyDXpfq0?autoplay=1&amp;amp;rel=0&#34;&#xA;data-title=&#34;YouTube Video&#34;&#xA;&gt;&#xA;&lt;div class=&#34;play-button&#34;&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;This open source tool combines all the observability signals that are vital to run combined infrastructure and application monitoring workloads at scale. Plus, it includes enterprise-grade features — such as native clustering for production at scale and built-in Vault support for enhanced security — all out of the box.&lt;/p&gt;&#xA;&lt;p&gt;To learn more, check out our &lt;a href=&#34;/events/observabilitycon/2024/opentelemetry-grafana-alloy-beyla-demo-of-instrumentation-ingestion/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;GrafanaCON session all about Alloy&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;4-adaptive-telemetry-grows&#34;&gt;4. Adaptive Telemetry grows&lt;/h2&gt;&#xA;&lt;p&gt;Imagine an observability stack in which all the noise is pruned away and your team just retains the signal that matters, ensuring that every byte of data that you store is worth your money.&lt;/p&gt;&#xA;&lt;p&gt;That&amp;rsquo;s the goal of Adaptive Telemetry, a set of tools that uses AI/ML to identify the signals you really need and extract them from the fire hose of observability data that you are maintaining.&lt;/p&gt;&#xA;&lt;p&gt;This year we introduced &lt;a href=&#34;/blog/2024/09/24/introducing-adaptive-logs/&#34;&gt;Adaptive Logs&lt;/a&gt;, which analyzes your incoming data and compares it to your usage patterns to make a set of customized recommendations to help you reduce the volume of unnecessary logs to lower your observability costs. Our customers, our early adopters, and even our company have seen a decrease of 40% to 60% of total ingested log volume.&lt;/p&gt;&#xA;&lt;div&#xA;class=&#34;youtube-lazyload responsive-video&#34;&#xA;data-embed=&#34;ltkqkbY6Jao&#34;&#xA;data-url=&#34;https://www.youtube.com/embed/ltkqkbY6Jao?autoplay=1&amp;amp;rel=0&#34;&#xA;data-title=&#34;YouTube Video&#34;&#xA;&gt;&#xA;&lt;div class=&#34;play-button&#34;&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;Adaptive Logs joins&lt;a href=&#34;/blog/2024/08/12/why-companies-choose-adaptive-metrics-and-how-they-save-time-and-a-lot-of-money/&#34;&gt; Adaptive Metrics&lt;/a&gt;, which aggregates unused and partially used metrics into lower cardinality versions, in our growing Adaptive Telemetry suite of tools. Soon &lt;a href=&#34;/blog/2024/09/24/grafana-labs-acquires-tailctrl/&#34;&gt;Adaptive Traces&lt;/a&gt; will join the ranks thanks to Sean Porter, the founder of startups TailCtrl and Sensu, who joined Grafana Labs this year. TailCtrl specialized in adaptive trace sampling, which aligns with our Adaptive Traces goals. With Sean&amp;rsquo;s help, we hope to extend the Adaptive Telemetry functionality across the LGTM Stack, so you can more easily and cost-effectively analyze observability data at scale.&lt;/p&gt;&#xA;&lt;h2 id=&#34;5-celebrating-10-hackathons-and-counting&#34;&gt;5. Celebrating 10 hackathons and counting&lt;/h2&gt;&#xA;&lt;p&gt;At Grafana Labs, our company-wide hackathon rules are simple: Grafanistas are encouraged to work in cross-collaborative teams to build anything as long as it helps solve a problem for the company or benefits the community. And you have a week to do it. “These Hackathons are so important,” says Grafana Labs Co-founder Anthony Woods. “We want to make sure that there is always an avenue for talented people across the company, not just in R&amp;amp;D, to innovate.”&lt;/p&gt;&#xA;&lt;p&gt;The ideas sparked over 10 hackathons have been both inspiring and entertaining, with projects ranging from new Grafana visualizations like the &lt;a href=&#34;/blog/2021/12/01/grafana-8.3-released-recorded-queries-panel-suggestions-new-panels-added-security-and-more/#new-candlestick-panel-enterprise-and-oss&#34;&gt;candlestick panel&lt;/a&gt; to answering the pressing question of our time: &lt;a href=&#34;/blog/2022/03/31/can-grafana-run-doom/&#34;&gt;Can Grafana run Doom?&lt;/a&gt; (Spoiler alert: It can!)&lt;/p&gt;&#xA;&lt;p&gt;Almost 50% of our hackathon projects have either shipped, are on our roadmap, or are in progress. For example, Explore Logs, an app that lets you browse your logs without LogQL, started as a hackathon project and ended up being spotlighted at GrafanaCON. It now joins the &lt;a href=&#34;/blog/2024/10/22/from-multi-line-queries-to-no-code-investigations-meeting-grafana-users-where-they-are/&#34;&gt;powerful Explore apps suite&lt;/a&gt;, which is available in OSS and Grafana Cloud and includes Explore Metrics, Explore Traces, and Explore Profiles.&lt;/p&gt;&#xA;&lt;h2 id=&#34;6-season-2-of-grafanas-big-tent-podcast&#34;&gt;6. Season 2 of &amp;lsquo;Grafana&amp;rsquo;s Big Tent&amp;rsquo; podcast&lt;/h2&gt;&#xA;&lt;p&gt;Grafana Labs&amp;rsquo; award-winning podcast, &amp;ldquo;&lt;a href=&#34;https://bigtent.fm/episodes&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Grafana&amp;rsquo;s Big Tent&lt;/a&gt;,&amp;rdquo; which is all about the people, community, tools, and tech around observability, returned for another season with more special guests, more observability insights, and an extended metaphor about restaurant seating and resource utilization that you never knew you needed.&lt;/p&gt;&#xA;&lt;p&gt;With almost 6,000 downloads to date, season 2 has reached listeners around the world, from India to South Africa to Brazil and beyond, and touched on a wide array of topics, such as &lt;a href=&#34;/blog/2024/08/23/grafanas-big-tent-podcast-season-2-is-here/&#34;&gt;caching&lt;/a&gt;, &lt;a href=&#34;/blog/2024/12/06/kubernetes-kepler-and-carbon-footprints-the-latest-tools-and-strategies-to-optimize-observability/&#34;&gt;optimization&lt;/a&gt;, and &lt;a href=&#34;/blog/2024/09/20/ddos-protection-observability-automation-and-curiosity/&#34;&gt;DDoS protection&lt;/a&gt;. “At Grafana Labs, it’s way more than just about the technology we build,” said Grafana Labs CTO Tom Wilkie in the introductory episode. “Grafana is one of the few pieces of software in the world that touches hundreds of different projects. And we want to use this platform we’ve got as a way of shining a spotlight on some of those projects.”&lt;/p&gt;&#xA;&lt;h2 id=&#34;7-extending-the-grafana-cloud-stack&#34;&gt;7. Extending the Grafana Cloud stack&lt;/h2&gt;&#xA;&lt;p&gt;We are consistently shipping new features for &lt;a href=&#34;/products/cloud/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt; in an effort to make our cloud-hosted observability platform more efficient, more intelligent, and easier to use, especially for those just starting out on their observability journey.&lt;/p&gt;&#xA;&lt;p&gt;This year is no exception, as we introduced or updated the following tools to make it even easier to optimize and troubleshoot your infrastructure and applications:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;/blog/2024/12/02/the-evolution-of-grafana-cloud-synthetic-monitoring-new-features-pricing-updates-and-more/&#34;&gt;Synthetic Monitoring&lt;/a&gt; for managing APIs and web applications from the user’s perspective.&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;/blog/2024/08/22/multi-cloud-monitoring-made-easy-monitor-aws-microsoft-azure-and-google-cloud-services-all-in-one-app/&#34;&gt;Cloud Provider Observability&lt;/a&gt; for monitoring multi-cloud environments.&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;/blog/2024/11/20/easily-control-observability-collectors-at-scale-with-fleet-management-in-grafana-cloud/&#34;&gt;Fleet Management&lt;/a&gt; for monitoring collectors in your infrastructure.&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;/blog/2024/09/24/contextual-root-cause-analysis-grafana-cloud/&#34;&gt;Asserts and Application Observability&lt;/a&gt; for AI/ML-powered root cause analysis for your backend services.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;8-industry-recognition&#34;&gt;8. Industry recognition&lt;/h2&gt;&#xA;&lt;p&gt;It&amp;rsquo;s an honor just to be nominated, but we&amp;rsquo;re learning it feels great to be acknowledged as well. Grafana Labs was named a Leader in the &lt;a href=&#34;https://www.gartner.com/en/documents/5663323&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Gartner® Magic Quadrant™ for Observability Platforms&lt;/a&gt; — one in a string of recognitions that shows how our company and community is playing a vital role in the area of modern software development management.&lt;/p&gt;&#xA;&lt;p&gt;We were also thrilled to be included in:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The &lt;a href=&#34;https://www.forbes.com/lists/cloud100/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Forbes Cloud 100 list&lt;/a&gt;, which recognizes the best private cloud computing companies; Grafana Labs ranked 23rd in 2024.&lt;/li&gt;&#xA;&lt;li&gt;The Silicon Valley Defense Group’s NATSEC100, which &lt;a href=&#34;https://natsec100.org/#list&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;ranked Grafana Labs 23rd&lt;/a&gt; among “national security-focused and dual-use startups.”&lt;/li&gt;&#xA;&lt;li&gt;The &lt;a href=&#34;https://www.redpoint.com/infrared/100/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;InfraRed 100&lt;/a&gt;, an unranked list that honors transformative companies in cloud infrastructure.&lt;/li&gt;&#xA;&lt;li&gt;The &lt;a href=&#34;https://www.crn.com/news/software/2024/the-10-coolest-open-source-software-tools-of-2024-so-far?page=7&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;10 coolest open source software tools &lt;/a&gt;in 2024 and on the &lt;a href=&#34;https://www.crn.com/news/software/2024/the-coolest-data-observability-and-dataops-companies-of-the-2024-big-data-100?page=6&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Big Data 100&lt;/a&gt;, both produced by CRN.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;But even with all the shiny, new accolades, we still — and always will — consider your success to be the ultimate validation of our products. &amp;ldquo;We have customers big and small, from the largest top 10 companies in the world to startups and hobbyists using the free tier of Grafana Cloud,&amp;rdquo; Raj noted during GrafanaCON. &amp;ldquo;It&amp;rsquo;s great to see that growth.&amp;rdquo;&lt;/p&gt;&#xA;&lt;h2 id=&#34;9-observability-survey-2024&#34;&gt;9. Observability Survey 2024&lt;/h2&gt;&#xA;&lt;p&gt;Regardless of the industry they operate in or the number of people they employ, businesses with mature observability practices can respond to incidents faster — and save time and money in the process, according to the &lt;a href=&#34;/observability-survey/2024/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;second annual Observability Survey&lt;/a&gt; presented by Grafana Labs.&lt;/p&gt;&#xA;&lt;p&gt;More than 300 observability practitioners participated in the second annual Observability Survey presented by Grafana Labs. They shared their thoughts on a wide range of topics, including the varying degrees of maturity, the sheer volume of tools in use, the lingering concerns about expenses, and the ubiquity of open source tools in this still-emerging market. What results is an in-depth look at the state of the industry today — and what practitioners hope to see in the future.&lt;/p&gt;&#xA;&lt;p&gt;We&amp;rsquo;d love to hear from you! Take the &lt;a href=&#34;/observability-survey/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;3rd annual Observability Survey&lt;/a&gt; today. It takes about five minutes and all responses will be kept anonymous.&lt;/p&gt;&#xA;&lt;h2 id=&#34;10-grafana-labs-startup-program&#34;&gt;10. Grafana Labs Startup Program&lt;/h2&gt;&#xA;&lt;p&gt;Startups face a particular set of challenges, especially when they have to scale rapidly. To alleviate some of the pressure on founders who are trying to keep up with demand while also keeping the lights on, we launched the &lt;a href=&#34;https://grafana-labs.typeform.com/to/cSI7ohks/?pg=blog&amp;amp;plcmt=body-txt&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Grafana Labs Startup Program&lt;/a&gt;, which includes up to $100,000 in Grafana Cloud credits to eligible startups for 12 months or until their next round of funding.&lt;/p&gt;&#xA;&lt;p&gt;Thus far more than $1 million in Grafana Cloud credits have been provisioned to early stage startups with more to come. “Grafana Cloud’s solutions and open source approach gives us a ton of flexibility, and the startup program has allowed us to focus on execution without worrying about our monitoring stack,” said Julian Giuca, CEO of the telemetry management platform &lt;a href=&#34;https://www.datable.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Datable.io&lt;/a&gt;, which is one of the first companies accepted in the program.&lt;/p&gt;&#xA;&lt;p&gt;Interested in applying? Learn more about the &lt;a href=&#34;/blog/2024/09/24/grafana-labs-startup-program/&#34;&gt;Grafana Labs Startup Program&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Whew! All that and we still have two more weeks until the end of the year. All of our success wouldn&amp;rsquo;t be possible without the incredible open source community that we are so thankful to be part of day in and day out. We can&amp;rsquo;t wait to start the new year and find even &lt;em&gt;more&lt;/em&gt; ways to connect with all of you.&lt;/p&gt;】&lt;p&gt;2024 年是建立联系的一年。&lt;/p&gt;&#xA;&lt;p&gt;开源社区五年来首次亲自聚集在一起参加 GrafanaCON — 在阿姆斯特丹举行会议，庆祝 Grafana 11、Loki 3.0、新的开源项目（提示 Grafana Alloy）等。 TailCtrl 是一家专门从事自适应跟踪采样的早期公司，它加入了 Grafana Labs 来推进我们的自适应遥测故事（欢迎，创始人 Sean Porter！）。我们找到了令人兴奋的方法，使用户能够更轻松地连接他们的数据，从免查询数据分析到推出新工具来帮助监控多个收集器（您好，车队管理）。&lt;/p&gt;&#xA;&lt;p&gt;最重要的是，我们今年喜欢寻找新的方式来接触开源社区 - 无论是通过“Grafana&#39;s Big Tent”播客的新讨论，在我们的第二次年度可观察性调查中衡量 300 多名从业者的意见，还是通过通过 Grafana Labs 启动计划与新兴可观测性公司合作。&lt;/p&gt;&#xA;&lt;p&gt;“我们真的相信这个大帐篷，将 Grafana 下的其他项目、其他生态系统、其他供应商聚集在一起，并帮助您分析数据，无论数据位于何处，”Grafana Labs 联合创始人兼首席执行官 Raj Dutt 说道。 GrafanaCON 2024，“我们非常荣幸能够成为这个充满活力的社区和生态系统的中心。”&lt;/p&gt;&#xA;&lt;p&gt;以下是 Grafana Labs 2024 年的一些亮点。&lt;/p&gt;&#xA;&lt;h2 id=&#34;1-grafanacon-in-person-in-amsterdam&#34;&gt;1. GrafanaCON 亲自出席，在阿姆斯特丹&lt;/h2&gt;&#xA;&lt;p&gt;Grafana 社区上次亲自聚集在一起参加 GrafanaCON 是什么时候？ 2019 年在洛杉矶。 Grafana Labs 首席执行官兼联合创始人 Raj Dutt 表示：“我不得不说，在参加了三四年的虚拟 GrafanaCON 后，我有点被虚拟淘汰了。”但无论是现场还是在线，“每次 GrafanaCON 上我的压倒性情感都是兴奋和感激。”&lt;/p&gt;&#xA;&lt;p&gt;同样，拉杰，同样。这就是为什么在阿姆斯特丹举办的 GrafanaCON 2024 上，约 400 名与会者齐聚一堂，参加为期两天的社区主导会议、现场演示和实践研讨会，这是令人兴奋的原因。 （&lt;a href=&#34;/events/grafanacon/2024/?pg=blog&amp;plcmt=body-txt#sessions&#34;&gt;会议今天可按需提供&lt;/a&gt;！）我们还庆祝了&lt;a href=&#34;/blog/2024 /04/09/grafana-11-release-all-the-new-features/&#34;&gt;Grafana 11 发布&lt;/a&gt;，第二届年度获奖者&lt;a href=&#34;/golden-grot-awards/?pg=blog&amp;plcmt=body-txt&#34;&gt;Golden Grot 奖&lt;/a&gt;，以及与开源社区重聚的机会。&lt;/p&gt;&#xA;&lt;div&#xA;类 =“youtube-lazyload 响应视频”&#xA;数据嵌入=“L_GHahMOWEY”&#xA;data-url=&#34;https://www.youtube.com/embed/L_GHahMOWEY?autoplay=1&amp;rel=0&#34;&#xA;数据标题=“YouTube 视频”&#xA;&gt;&#xA;&lt;div class=&#34;play-button&#34;&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;明年想参加吗？欢迎参加 5 月 6 日至 8 日在西雅图举行的 &lt;a href=&#34;/events/grafanacon/?pg=blog&amp;plcmt=body-txt&#34;&gt;GrafanaCON 2025&lt;/a&gt;。 &lt;a href=&#34;/events/grafanacon/#cfp&#34;&gt;CFP 已开放&lt;/a&gt;，我们正在接受申请&lt;a href=&#34;/golden-grot-awards/?pg=blog&amp;plcmt=body-txt&#34;&gt;金格罗特奖&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;h2 id=&#34;2-loki-30-release&#34;&gt;2.洛基 3.0 发布&lt;/h2&gt;&#xA;&lt;p&gt;欢迎来到 Grafana Loki 的下一章！继 Loki 项目&lt;a href=&#34;/blog/2023/12/11/open-source-log-monitoring-the-concise-guide-to-grafana-loki/&#34;&gt;庆祝五周年&lt;/a&gt;为了促进成长和发展，我们推出了 &lt;a href=&#34;https://github.com/grafana/loki&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Grafana Loki 3.0&lt;/a&gt; 四月份在 GrafanaCON 上发布。&lt;/p&gt;&#xA;&lt;p&gt;我们推出了开源日志聚合系统的最新主要版本：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;加速查询结果。&lt;/strong&gt;布隆过滤器是一项实验性功能，旨在帮助更快地返回“大海捞针”查询。在与早期采用者合作并了解布隆过滤器如何大规模工作后，我们决定将 Loki 3.3 中的方法调整为 &lt;a href=&#34;/blog/2024/11/21/grafana-loki-3.3-release-faster-query- results-via-blooms-for-structed-metadata/#query-acceleration-via-bloom-filters&#34;&gt;利用结构化元数据&lt;/a&gt;，加快构建、下载、并查询。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;原生 OpenTelemetry 支持。&lt;/strong&gt;向 Loki Exporter 说再见！现在 Loki 拥有&lt;a href=&#34;/blog/2024/04/09/grafana-loki-3.0-release-all-the-new-features/#native-opentelemetry-support&#34;&gt;原生 OTel 支持&lt;/a&gt;，您可以获得更简单的摄取管道和更好的查询体验，因为您可以在查询时与所有 OpenTelemetry 属性和日志事件元数据进行交互，而无需进行任何反序列化。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div&#xA;类 =“youtube-lazyload 响应视频”&#xA;数据嵌入=“H_7yHut6hvw”&#xA;data-url=&#34;https://www.youtube.com/embed/H_7yHut6hvw?autoplay=1&amp;rel=0&#34;&#xA;数据标题=“YouTube 视频”&#xA;&gt;&#xA;&lt;div class=&#34;play-button&#34;&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;这也是 Loki 普及率不断提高的重要一年，安装量从 2023 年的 64,000 次攀升至 2024 年的 132,000 次。&lt;/p&gt;&#xA;&lt;p&gt;附注如果您想&lt;a href=&#34;https://github.com/grafana/loki&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;自己安装 Loki，今年还有几周时间！&lt; /a&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;3-grafana-alloy-launch&#34;&gt;3. Grafana合金推出&lt;/h2&gt;&#xA;&lt;p&gt;我们欢迎一个新的开源项目加入我们的家族，我们很自豪地宣布：它是一个收集器！&lt;/p&gt;&#xA;&lt;p&gt;等等，&lt;em&gt;另一个&lt;/em&gt;收藏家？&lt;/p&gt;&#xA;&lt;p&gt;听我们说：Grafana Alloy 是我们的 OpenTelemetry Collector 开源发行版。它 100% OTLP 兼容，并为 OpenTelemetry 和 Prometheus 遥测格式提供本机管道，支持指标、日志、跟踪和配置文件。 （对于那些熟悉 Grafana Agent Flow 的人来说，Alloy 会让您感到宾至如归，因为它使用相同的组件、代码和概念。）&lt;/p&gt;&#xA;&lt;div&#xA;类 =“youtube-lazyload 响应视频”&#xA;数据嵌入=“NrnLyDXpfq0”&#xA;data-url=&#34;https://www.youtube.com/embed/NrnLyDXpfq0?autoplay=1&amp;rel=0&#34;&#xA;数据标题=“YouTube 视频”&#xA;&gt;&#xA;&lt;div class=&#34;play-button&#34;&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;这个开源工具结合了所有可观测性信号对于大规模运行组合基础设施和应用程序监控工作负载至关重要。此外，它还包括企业级功能，例如用于大规模生产的本机集群和用于增强安全性的内置 Vault 支持，所有这些都是开箱即用的。&lt;/p&gt;&#xA;&lt;p&gt;要了解更多信息，请查看我们的 &lt;a href=&#34;/events/observabilitycon/2024/opentelemetry-grafana-alloy-beyla-demo-of-instrumentation-ingestion/?pg=blog&amp;plcmt=body-txt&#34;&gt;GrafanaCON 会议关于合金的一切&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;h2 id=&#34;4-adaptive-telemetry-grows&#34;&gt;4.自适应遥测增长&lt;/h2&gt;&#xA;&lt;p&gt;想象一个可观察性堆栈，其中所有噪音都被修剪掉，您的团队只保留重要的信号，确保您存储的每个字节的数据都物有所值。&lt;/p&gt;&#xA;&lt;p&gt;这就是自适应遥测的目标，它是一组工具，使用 AI/ML 来识别您真正需要的信号，并从您正在维护的可观测数据的消防水带中提取它们。&lt;/p&gt;&#xA;&lt;p&gt;今年，我们推出了&lt;a href=&#34;/blog/2024/09/24/introducing-adaptive-logs/&#34;&gt;自适应日志&lt;/a&gt;，它可以分析您的传入数据并将其与您的使用模式进行比较，以便一组定制建议可帮助您减少不必要的日志量，从而降低可观察性成本。我们的客户、我们的早期采用者，甚至我们公司的总摄取日志量减少了 40% 到 60%。&lt;/p&gt;&#xA;&lt;div&#xA;类 =“youtube-lazyload 响应视频”&#xA;数据嵌入=“ltkqkbY6Jao”&#xA;data-url=&#34;https://www.youtube.com/embed/ltkqkbY6Jao?autoplay=1&amp;rel=0&#34;&#xA;数据标题=“YouTube 视频”&#xA;&gt;&#xA;&lt;div class=&#34;play-button&#34;&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;自适应日志加入&lt;a href=&#34;/blog/2024/08/12/why-companies-choose-adaptive-metrics-and-how-they-save-time-and-a-lot-of-money/ &#34;&gt; 自适应指标&lt;/a&gt;，在我们不断发展的自适应遥测工具套件中，它将未使用和部分使用的指标聚合到较低基数版本中。很快 &lt;a href=&#34;/blog/2024/09/24/grafana-labs-acquires-tailctrl/&#34;&gt;Adaptive Traces&lt;/a&gt; 将加入这一行列，这要归功于初创公司 TailCtrl 和 Sensu 的创始人肖恩·波特 (Sean Porter) 的加入。今年的 Grafana 实验室。 TailCtrl 专门从事自适应跟踪采样，这与我们的自适应跟踪目标一致。在 Sean 的帮助下，我们希望将自适应遥测功能扩展到整个 LGTM Stack，以便您可以更轻松、更经济高效地大规模分析可观测性数据。&lt;/p&gt;&#xA;&lt;h2 id=&#34;5-celebating-10-hackathons-and-counting&#34;&gt;5.庆祝 10 场黑客马拉松并持续举办&lt;/h2&gt;&#xA;&lt;p&gt;在 Grafana Labs，我们公司范围内的黑客马拉松规则很简单：鼓励 Grafanista 在跨协作团队中工作来构建任何东西，只要它有助于解决公司问题或使社区受益。你有一周的时间来做这件事。 “这些黑客马拉松非常重要，”Grafana Labs 联合创始人 Anthony Woods 说。 “我们希望确保整个公司（而不仅仅是研发领域）的人才始终有创新的途径。”&lt;/p&gt;&#xA;&lt;p&gt;这些想法引发了 10 多个黑客攻击荣誉们的项目既鼓舞人心又有趣，包括新的 Grafana 可视化，例如 &lt;a href=&#34;/blog/2021/12/01/grafana-8.3​​-released-recorded-queries-panel-suggestions-new-panels-linked -security-and-more/#new-candlestick-panel-enterprise-and-oss&#34;&gt;烛台面板&lt;/a&gt;回答我们这个时代的紧迫问题：&lt;a href=&#34;/blog/2022/03/31/can-grafana-run-doom/&#34;&gt;Grafana 可以运行 Doom 吗？&lt;/a&gt;（剧透警告：可以！）&lt;/p&gt;&#xA;&lt;p&gt;我们近 50% 的黑客马拉松项目已经交付、已列入路线图或正在进行中。例如，Explore Logs 是一款无需 LogQL 即可浏览日志的应用程序，最初是一个黑客马拉松项目，最终在 GrafanaCON 上受到关注。它现在加入了&lt;a href=&#34;/blog/2024/10/22/from-multi-line-queries-to-no-code-investigations-meeting-grafana-users-where-they-are/&#34;&gt;强大的探索应用程序套件&lt;/a&gt;，可在 OSS 和 Grafana Cloud 中使用，包括探索指标、探索跟踪和探索配置文件。&lt;/p&gt;&#xA;&lt;h2 id=&#34;6-season-2-of-grafanas-big-tent-podcast&#34;&gt;6. “Grafana 的大帐篷”播客第 2 季&lt;/h2&gt;&#xA;&lt;p&gt;Grafana Labs 的获奖播客“&lt;a href=&#34;https://bigtent.fm/episodes&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Grafana 的大帐篷&lt;/a&gt;”，所有关于围绕可观察性的人、社区、工具和技术的内容，又一季回归，带来了更多特殊客人、更多可观察性见解，以及关于餐厅座位和资源利用的扩展隐喻，这些隐喻是你从未了解过的需要。&lt;/p&gt;&#xA;&lt;p&gt;迄今为止，第二季的下载量已接近 6,000 次，覆盖了从印度、南非到巴西等世界各地的听众，并涉及广泛的主题，例如 &lt;a href=&#34;/blog/2024/ 08/23/grafanas-big-tent-podcast-season-2-is-here/&#34;&gt;缓存&lt;/a&gt;，&lt;a href=&#34;/blog/2024/12/06/kubernetes-kepler-and-carbon-footprints-the-latest-tools-and-strategies-to-optimize-observability/&#34;&gt;优化&lt;/a&gt;，以及 &lt;a href =&#34;/blog/2024/09/20/ddos-protection-observability-automation-and-curiosity/&#34;&gt;DDoS 防护&lt;/a&gt;。 “在 Grafana Labs，这不仅仅是我们构建的技术，”Grafana Labs 首席技术官 Tom Wilkie 在介绍性节目中说道。 “Grafana 是世界上为数不多的涉及数百个不同项目的软件之一。我们希望利用我们拥有的这个平台来关注其中一些项目。”&lt;/p&gt;&#xA;&lt;h2 id=&#34;7-extending-the-grafana-cloud-stack&#34;&gt;7.扩展 Grafana 云堆栈&lt;/h2&gt;&#xA;&lt;p&gt;我们不断为 &lt;a href=&#34;/products/cloud/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt; 提供新功能，努力使我们的云托管可观测性平台更加高效，更智能，更易于使用，特别是对于那些刚刚开始观察之旅的人来说。&lt;/p&gt;&#xA;&lt;p&gt;今年也不例外，我们推出或更新了以下工具，使您的基础架构和应用程序的优化和故障排除变得更加轻松：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;/blog/2024/12/02/the-evolution-of-grafana-cloud-synthetic-monitoring-new-features-pricing-updates-and-more/&#34;&gt;综合监控&lt;/a&gt;用于从用户的角度管理 API 和 Web 应用程序。&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;/blog/2024/08/22/multi-cloud-monitoring-made-easy-monitor-aws-microsoft-azure-and-google-cloud-services-all-in-one-app /&#34;&gt;云提供商可观察性&lt;/a&gt;，用于监控多云环境。&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;/blog/2024/11/20/easily-control-observability-collectors-at-scale-with-fleet-management-in-grafana-cloud/&#34;&gt;队列管理&lt;/a&gt;监控基础设施中的收集器。&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;/blog/2024/09/24/contextual-root-cause-analysis-grafana-cloud/&#34;&gt;断言和应用程序可观察性&lt;/a&gt;，用于 AI/ML 支持的根本原因分析后端服务。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;8-industry-recognition&#34;&gt;8.行业认可&lt;/h2&gt;&#xA;&lt;p&gt;获得提名是一种荣幸，但我们了解到，获得认可的感觉也很棒。 Grafana Labs 被评为&lt;a href=&#34;https://www.gartner.com/en/documents/5663323&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Gartner® 可观测性平台魔力象限™ 的领导者&lt; /a&gt; — 一系列认可中的一个，表明我们的公司和社区如何在现代软件开发管理领域发挥着至关重要的作用。&lt;/p&gt;&#xA;&lt;p&gt;我们也很高兴能够参与：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.forbes.com/lists/cloud100/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;福布斯云 100 强榜单&lt;/a&gt;，旨在表彰最佳私有企业云计算公司； Grafana Labs 2024 年排名第 23 位。&lt;/li&gt;&#xA;&lt;li&gt;硅谷防御组织的 NATSEC100，&lt;a href=&#34;https://natsec100.org/#list&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;将 Grafana Labs 评为“国家级”第 23 位&lt;/a&gt;以安全为中心的军民两用初创公司。”&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.redpoint.com/infrared/100/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;InfraRed 100&lt;/a&gt;，这是一份旨在表彰变革型公司的未排名名单云基础设施。&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.crn.com/news/software/2024/the-10-coolest-open-source-software-tools-of-2024-so-far?page=7 &#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;2024 年和 &lt;a 上 10 个最酷的开源软件工具&lt;/a&gt; href=&#34;https://www.crn.com/news/software/2024/the-coolest-data-observability-and-dataops-companies-of-the-2024-big-data-100?page=6&#34;目标=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;大数据 100&lt;/a&gt;，均由 CRN 制作。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;但即使拥有所有闪亮的新荣誉，我们仍然（并且始终会）认为您的成功是对我们产品的最终验证。 Raj 在 GrafanaCON 期间指出：“我们拥有大大小小的客户，从世界上最大的 10 家公司到使用 Grafana Cloud 免费层的初创公司和爱好者。” “很高兴看到这种增长。”&lt;/p&gt;&#xA;&lt;h2 id=&#34;9-observability-survey-2024&#34;&gt;9. 2024 年可观测性调查&lt;/h2&gt;&#xA;&lt;p&gt;无论根据 &lt;a href=&#34;/observability-survey/2024/?pg= blog&amp;plcmt=body-txt&#34;&gt;Grafana Labs 提出的第二次年度可观测性调查&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;超过 300 名可观测性从业者参加了 Grafana Labs 举办的第二届年度可观测性调查。他们就广泛的主题分享了自己的想法，包括不同的成熟度、使用的工具的绝对数量、对费用挥之不去的担忧，以及开源工具在这个新兴市场中的普遍存在。结果是对当今行业状况的深入了解以及从业者希望在未来看到的结果。&lt;/p&gt;&#xA;&lt;p&gt;我们很乐意听取您的意见！今天参加&lt;a href=&#34;/observability-survey/?pg=blog&amp;plcmt=body-txt&#34;&gt;第三次年度可观测性调查&lt;/a&gt;。大约需要五分钟，所有回复都将保持匿名。&lt;/p&gt;&#xA;&lt;h2 id=&#34;10-grafana-labs-startup-program&#34;&gt;10. Grafana 实验室启动计划&lt;/h2&gt;&#xA;&lt;p&gt;初创公司面临着一系列特殊的挑战，尤其是当它们必须快速扩张时。为了减轻创始人在努力满足需求的同时保持正常运转的压力，我们推出了 &lt;a href=&#34;https://grafana-labs.typeform.com/to/cSI7ohks/?pg= blog&amp;plcmt=body-txt&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Grafana Labs 启动计划&lt;/a&gt;，其中包括高达 100,000 美元的 Grafana Cloud 积分符合条件的初创公司为期 12 个月或直到下一轮融资。&lt;/p&gt;&#xA;&lt;p&gt;到目前为止，已经向早期初创公司提供了超过 100 万美元的 Grafana Cloud 积分，而且未来还会有更多积分。遥测管理平台首席执行官 Julian Giuca 表示：“Grafana Cloud 的解决方案和开源方法为我们提供了极大的灵活性，启动计划使我们能够专注于执行，而不必担心我们的监控堆栈。” ://www.datable.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Datable.io&lt;/a&gt;，这是该计划首批接受的公司之一。&lt;/p&gt;&#xA;&lt;p&gt;有兴趣申请吗？详细了解 &lt;a href=&#34;/blog/2024/09/24/grafana-labs-startup-program/&#34;&gt;Grafana Labs 启动计划&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;哇！所有这些，距离年底我们还有两周的时间。如果没有令人难以置信的开源社区，我们所有的成功都是不可能的，我们非常感谢日复一日地参与其中。我们迫不及待地想开始新的一年并找到&lt;em&gt;更多&lt;/em&gt;方式与大家联系。&lt;/p&gt;</description>
      <pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【OpenTelemetry: past, present, and future】OpenTelemetry：过去、现在和未来</title>
      <link>https://grafana.com/blog/2024/12/20/opentelemetry-past-present-and-future/</link>
      <description>【&lt;p&gt;Here&amp;rsquo;s something most people probably didn&amp;rsquo;t have on their 2024 bingo cards: the terms &amp;ldquo;gossip&amp;rdquo; and &amp;ldquo;scandalous details&amp;rdquo; popping up on an episode of “Grafana’s Big Tent.&amp;quot; But if you did, congratulations!&lt;/p&gt;&#xA;&lt;p&gt;It happened during a conversation about &lt;a href=&#34;/oss/opentelemetry/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;OpenTelemetry&lt;/a&gt;, in which co-hosts Mat Ryer, Grafana Labs Engineering Director, and Matt Toback, Grafana Labs VP of Culture, playfully tried to get some scoop about the inner-workings of the OpenTelemetry Governance Committee from two of its members, podcast guests Juraci Paixão Kröhling, Grafana Principal Engineer, and Daniel Gomez Blanco, Principal Engineer at Skyscanner. (Truth be told, the most scandalous detail to come out of the episode might be that Matt still owns a zip drive cable . . .)&lt;/p&gt;&#xA;&lt;p&gt;You can read some of the show’s highlights below, but listen to the full episode to hear more about instrumentation and distributed tracing, as well as OTel history — including its early names — TBT (trace-based testing), ODD (observability-driven development), and Mat&amp;rsquo;s Broadway moment.&lt;/p&gt;&#xA;&lt;iframe width=&#34;100%&#34; height=&#34;180&#34; frameborder=&#34;no&#34; scrolling=&#34;no&#34; seamless=&#34;&#34; src=&#34;https://share.transistor.fm/e/e8c53636&#34;&gt;&lt;/iframe&gt;&#xA;&lt;p&gt;&lt;em&gt;Note: The following are highlights from episode 9, season 2 of “Grafana’s Big Tent” podcast. The transcript below has been edited for length and clarity.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;the-basics-of-opentelemetry&#34;&gt;The basics of OpenTelemetry&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Mat Ryer:&lt;/strong&gt; For anyone not familiar with OTel, what is it?&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Daniel Gomez Blanco:&lt;/strong&gt; OpenTelemetry is a framework that allows you to instrument, to collect, to process, and then to transport telemetry data. It&amp;rsquo;s focused on cloud native systems, and one of the major goals is that you can produce all that telemetry from any application, any library, any language, in a standard format and using a standard set of naming conventions as well, and then push that to any backend. It&amp;rsquo;s vendor-neutral, so you can do whatever you want with your telemetry. You&amp;rsquo;re not forced to use a particular solution or backend.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Mat:&lt;/strong&gt; Before that, we had all different systems, and they have different traditions, different names, different techniques. So this is a goal to unify it all and get everyone behind one set of standards.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Daniel:&lt;/strong&gt; Yeah, it&amp;rsquo;s one set of standards as well as something that is really, really important for observability, which is context. We&amp;rsquo;re no longer thinking about your metrics here, and your logs here, and your traces here. You have everything as part of one set of telemetry data that is correlated in order to allow you to get better insights from your applications.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Juraci Paixão Kröhling:&lt;/strong&gt; One of the nice things about OpenTelemetry is that it came to be when existing tools were very successful already, so we tried to make open telemetry play nicely with the things that came before us. Of course, not everything is 100% philosophically compatible, but we tried to make it so that people could use OpenTelemetry even if they don&amp;rsquo;t like every part of it, or even if they were already happy with other parts.&lt;/p&gt;&#xA;&lt;h2 id=&#34;learning-the-rules&#34;&gt;Learning the rules&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Mat:&lt;/strong&gt; You mentioned logs, metrics, and traces. As an everyday developer, how do you know which of these telemetry types we should use? Is there a set of rules, or is this intuition and experience that you have to learn over time?&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Daniel:&lt;/strong&gt; It depends so much on the system. The first question to ask is if you should be adding that telemetry yourself, or if you should be relying on telemetry that is emitted by instrumentation libraries or the libraries themselves? One of the things that OpenTelemetry enables is instrumentation authors to write that telemetry for you, as well library authors. So let&amp;rsquo;s say that you pick an open source library that comes already instrumented with the metrics that you need, or with the spans and the tracing instrumentation that you need — you don&amp;rsquo;t need to add that yourself.&lt;/p&gt;&#xA;&lt;p&gt;When we&amp;rsquo;re talking about instrumenting our own data, our own applications, I think it&amp;rsquo;s important to choose the telemetry that is right for your use case. So if you&amp;rsquo;re looking to drive, for example, alerts or dashboards or something that you&amp;rsquo;re looking at long-term, you&amp;rsquo;re probably looking at time series data so that you need your metrics. If you&amp;rsquo;re looking at really high granularity insights, and you&amp;rsquo;re interested in how it all fits together in a complex, distributed system, and you&amp;rsquo;re interested in context, then you want traces. And then if you want to integrate with some of the legacy systems that, perhaps, didn&amp;rsquo;t produce any spans or any metrics, then you want to rely on logs.&lt;/p&gt;&#xA;&lt;p&gt;But the important thing is that you get all those parts of the context, the same set of correlated data. And that&amp;rsquo;s something OTel helps with — to bridge that gap.&lt;/p&gt;&#xA;&lt;p&gt;Another way of thinking about it is going into multiple different levels of granularity. You may start from metrics, and then you want to correlate that to your traces, and then maybe keep going down in your level of abstraction and then going down into profiles.&lt;/p&gt;&#xA;&lt;p&gt;The story that we&amp;rsquo;re trying to tell is that you need all that data and you need it to be correlated.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Juraci:&lt;/strong&gt; The mental model I have is a little bit different. When I&amp;rsquo;m developing an application, I try to put myself in the future — like at 2 a.m. during an outage, looking at my code and thinking, What do I need to know to understand what&amp;rsquo;s going on? It&amp;rsquo;s very likely that I don&amp;rsquo;t need the individual log entries. When I need aggregate information, then I need metrics and I can think, What are the metrics that I need? Do I need a gauge for the size of the queue that I&amp;rsquo;m handling right now? Do I need a latency for the outgoing HTTP requests? Things like that.&lt;/p&gt;&#xA;&lt;p&gt;The second mode is, What do I need to understand the context of the transaction specifically? When I&amp;rsquo;m thinking about the transaction as a whole — microservices — then I know I need a span. I know I need distributed tracing. And when I&amp;rsquo;m thinking about the neighboring services, the one thing that I know that I need is one span representing my incoming HTTP request or my incoming RPC, and one span representing my outgoing RPC. So that&amp;rsquo;s all that I really need when it comes to distributed tracing, because then I see the whole chain in a trace. I feel like logs are mostly for the life cycle events of my application.&lt;/p&gt;&#xA;&lt;h2 id=&#34;making-a-game-out-of-learning&#34;&gt;Making a game out of learning&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Matt:&lt;/strong&gt; A lot of times, when we talk about how to instrument your application, there&amp;rsquo;s this feeling that you&amp;rsquo;re choosing instrumentation for your future self to troubleshoot. How often do you see differences in team approaches on the same application?&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Daniel:&lt;/strong&gt; It depends on what teams are used to. One of the things that I&amp;rsquo;ve been doing recently with some of the teams of Skyscanner is going through the OTel demo and doing a bit of a game. We put them in front of the demo, we inject some failures into that system, and then ask them to go and debug it. We try to have different teams compete against each other and see who gets to the root cause first.&lt;/p&gt;&#xA;&lt;p&gt;You get to the root cause a lot faster if you use context than if you start from, perhaps, an alert that we set up that&amp;rsquo;s driven from metrics. Just by looking at the metrics, you won&amp;rsquo;t be able to answer the questions &amp;ldquo;What is the root cause here? What made it fail?&amp;rdquo;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Matt:&lt;/strong&gt; Have you seen eureka moments when someone discovers that they&amp;rsquo;re able to see more than they were before?&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Daniel:&lt;/strong&gt; There was an engineer who was adamant that they were able to debug this through logs alone, because that&amp;rsquo;s what they were used to. And they didn&amp;rsquo;t win. People in another room were using tracing and were a lot further advanced in finding the root cause, so that was fun.&lt;/p&gt;&#xA;&lt;h2 id=&#34;why-some-people-still-dont-understand-observability&#34;&gt;Why some people still don&amp;rsquo;t understand observability&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Juraci:&lt;/strong&gt; I also think about telemetry when writing code, but I think there is some barrier to entry there. Out of curiosity, I was looking at the curriculum for some computer science classes in Brazil — but I think this applies elsewhere — and we teach people how to write operating systems, but we don&amp;rsquo;t tell people how to monitor them. We don&amp;rsquo;t teach them how to do observability, like how to understand what&amp;rsquo;s going on, and this is a real gap.&lt;/p&gt;&#xA;&lt;p&gt;People have a hard time understanding distributed tracing. It &lt;em&gt;is&lt;/em&gt; a hard topic. It is difficult to imagine that parts of that data are going directly to a collector somewhere, and parts of the data are being propagated down as part of the RPC. So which one is which? What is where? How does that actually work? Why do I need a trace context there with two types of IDs and flags? Those are things that we just assume that people know, and if they don&amp;rsquo;t, we provide the tools to them. But then they use them without knowing what&amp;rsquo;s in there, and it makes it very hard to debug when things go wrong with the telemetry systems they have.&lt;/p&gt;&#xA;&lt;p&gt;On one hand, I see that the tooling to develop instrumentation is necessary. On the other hand, I think we end up having a huge cost problem, which is already a reality in observability by having tools that are generating a lot of telemetry data that we don&amp;rsquo;t actually need. When we look at most traces that we&amp;rsquo;ve collected, we don&amp;rsquo;t use most of them. A few years ago, someone mentioned close to 90% of traces are created, transmitted, and stored, and never seen — all of that work for pretty much nothing.&lt;/p&gt;&#xA;&lt;p&gt;If we were to have only manual instrumentation, then we would have only high valuable data being stored, and way less data than what we have right now. But because it is so difficult to understand and to manually instrument, we end up using those very powerful tools that generate a lot of telemetry that we might not need in the hopes that they become useful sometime in the future.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Matt:&lt;/strong&gt; How often will you prune it?&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Juraci:&lt;/strong&gt; We never do. I think it&amp;rsquo;s in our nature to not delete something because of fear that that thing might be useful in the future. I think this is where academia is way more advanced than we are. There is some research going in this area of turning on and off instrumentation points based on the current state of the systems. I think the future is not that we are &lt;em&gt;not&lt;/em&gt; going to instrument things as much as what we are doing today, but I think the future is whether we collect and store and transmit that data in the first place.&lt;/p&gt;&#xA;&lt;h2 id=&#34;the-need-for-a-cultural-shift&#34;&gt;The need for a cultural shift&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Mat:&lt;/strong&gt; What is the biggest challenge to adoption, that people just don&amp;rsquo;t really know it, or are there other resistances?&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Daniel:&lt;/strong&gt; One of the challenges is that people don&amp;rsquo;t know it. You need to change years of culture and people within a distributed system operating them as if it were monoliths — like isolated entities — without thinking of your overall system. And I think that&amp;rsquo;s something that needs to change from an engineering perspective, or, like, how do we operate systems.&lt;/p&gt;&#xA;&lt;p&gt;There is, as well, another challenge for adoption, which tends to be cost-related, because we generate a lot of telemetry data from distributed systems. Before you perhaps had one big replica that was massive, now you&amp;rsquo;ve got little components that all produce telemetry. I think it&amp;rsquo;s important as well to understand that distributed tracing and that context allows you to make better decisions in what to keep and what not to keep.&lt;/p&gt;&#xA;&lt;p&gt;Cost is a challenge, but is not an insurmountable challenge.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Juraci:&lt;/strong&gt; I think there&amp;rsquo;s also the situation where people only see the value when they have experience. It takes a while for people to realize that they need observability, and they might not even realize it even after years of experience.&lt;/p&gt;&#xA;&lt;h2 id=&#34;weighing-the-trade-offs-of-using-otel&#34;&gt;Weighing the trade-offs of using OTel&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Mat:&lt;/strong&gt; Are there downsides to using OTel, or trade-offs that we have to be aware of?&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Daniel:&lt;/strong&gt; It depends where you are in your observability journey as an organization. So if you&amp;rsquo;ve got really stable processes, and there may be something in OTel that is not quite stable yet, there are parts that are very stable that you could adopt and try to simplify and consolidate on that. There are other parts that are less stable, for example, things related to profiles. So I think if you&amp;rsquo;ve got something that is currently working, it&amp;rsquo;s probably one of the things where you wait until things get a bit more stable.&lt;/p&gt;&#xA;&lt;p&gt;If you&amp;rsquo;re completely greenfield and you&amp;rsquo;re starting from scratch, your balance will probably tip towards innovation.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Juraci:&lt;/strong&gt; I think it&amp;rsquo;s all relative as well. The collector has not reached a v1 yet, so in theory, it is not stable. But it doesn&amp;rsquo;t stop people like Vijay [Samuel] from eBay from implementing a highly scalable collector pipeline there and giving talks at KubeCon.&lt;/p&gt;&#xA;&lt;p&gt;We think it&amp;rsquo;s fine for some things, but not so fine for other things.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Daniel:&lt;/strong&gt; It does require a little bit of due diligence from a platform engineering team. At Skyscanner, for example, we run collectors at scale as well, handling more than a million spans per second, and handling hundreds of thousands of data points per second. The collector is not v1, but the components that we rely on — OTLP, receive, and export — and the processors that we use are stable.&lt;/p&gt;&#xA;&lt;h2 id=&#34;governance-committee-scoop&#34;&gt;Governance Committee scoop&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Mat:&lt;/strong&gt; Tell us a little more about what you do on the Governance Committee, in particular if you&amp;rsquo;re working on anything interesting right now. Or I&amp;rsquo;d love to know any gossip about big places you disagreed, or something from behind-the-scenes.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Daniel:&lt;/strong&gt; I don&amp;rsquo;t think we disagree much. We&amp;rsquo;re all quite aligned.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Juraci:&lt;/strong&gt; All our calls are recorded, so the meeting notes are public and the recordings &lt;a href=&#34;https://github.com/open-telemetry/community?tab=readme-ov-file#governing-bodies&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;are available&lt;/a&gt; — it is an open source project after all. We do have private sessions for things that are really related to code of conduct or complaints from people from the community. It is a big community, so disagreement is bound to happen. Our group is there to balance that, and to make sure that we are moving forward as a community and that we are not ignoring problems that may cause even bigger problems in the future.&lt;/p&gt;&#xA;&lt;p&gt;But I think our biggest challenge is even though OpenTelemetry is full of people from vendors — most people there work for vendors — even though we have that commercial interest behind the project, we’re all, at the end of the day, volunteers. Most of us end up doing things during our working hours. We are being paid for that, but this is not something that we put on our OKRs.&lt;/p&gt;&#xA;&lt;p&gt;The difficult part as part of the GC, of the governance committee, is to agree on a roadmap, and convince other people that they have to pay attention to what we are saying, as “This is what we believe to be important. Not only listening to us, but also following the path that we are trying to go into.”&lt;/p&gt;&#xA;&lt;p&gt;We are software engineers, so we find new toys every single day, and we want to play with those toys. At this point, my candid opinion is that we have too many toys and we have to do some spring cleaning and see what is worth keeping and what is not, and what we should declare as something that is a good idea, but for the future.&lt;/p&gt;&#xA;&lt;h2 id=&#34;whats-coming-up-for-otel&#34;&gt;What&amp;rsquo;s coming up for OTel&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Mat:&lt;/strong&gt; Speaking of new toys, what is new? What&amp;rsquo;s the exciting thing that&amp;rsquo;s next for OTel?&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Daniel:&lt;/strong&gt; One of the things that&amp;rsquo;s got everyone excited is profiling as a new signal, and how you can get profiles correlated with your traces. That is just going to open such a new avenue to explore within your debugging practices.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Juraci:&lt;/strong&gt; I&amp;rsquo;m looking forward to so many things. I think one of them is the &lt;a href=&#34;https://github.com/open-telemetry/community?tab=readme-ov-file#specification-sigs&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Entity SIG&lt;/a&gt;. I like to think that is our first big refactoring in OpenTelemetry, and that is refactoring the idea of resource attributes. Resources is the context that Dan mentioned before. It ties all of the signals together.&lt;/p&gt;&#xA;&lt;p&gt;It turns out that not everything that we thought would be good values for resource attributes are actually good. They might be problematic for things that don&amp;rsquo;t deal very well with high cardinality, like &lt;a href=&#34;/oss/prometheus/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Prometheus&lt;/a&gt;, so we probably do not want to store the process ID as part of resource attributes. It&amp;rsquo;s nice metadata to have about the process, but we don&amp;rsquo;t actually need it there.&lt;/p&gt;&#xA;&lt;p&gt;The Entities SIG would break down the resource context into what is the identity resources and identity SIG — so what is the identity of my resource and what is the metadata for my resource, so that this linking context between the signals would be very thin, and I could use those in Prometheus and &lt;a href=&#34;/oss/loki/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Loki&lt;/a&gt; or in different data stores, and the metadata could be stored elsewhere. It doesn&amp;rsquo;t have to be indexed. It doesn&amp;rsquo;t have to be part of the identity of the object.&lt;/p&gt;&#xA;&lt;p&gt;It&amp;rsquo;s not as exciting as profiling, perhaps, but I think it is very necessary, and it&amp;rsquo;s a sign of maturity that we are doing a refactoring.&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;“Grafana’s Big Tent” podcast wants to hear from you. If you have a great story to share, want to join the conversation, or have any feedback, please contact the Big Tent team at &lt;a href=&#34;/blog/2024/08/23/grafanas-big-tent-podcast-season-2-is-here/bigtent@grafana.com&#34;&gt;bigtent@grafana.com&lt;/a&gt;. You can also catch up on the first and second season of “Grafana’s Big Tent” on &lt;a href=&#34;https://podcasts.apple.com/us/podcast/grafanas-big-tent/id1616725129&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Apple Podcasts&lt;/a&gt; and &lt;a href=&#34;https://open.spotify.com/show/3beQvS8to0rYs1gxOnPrfD?si=bf046f54fe214615&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Spotify&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;】&lt;p&gt;大多数人的 2024 年宾果卡上可能没有这样的内容：在“Grafana&#39;s Big Tent”的一集中突然出现的术语“八卦”和“丑闻细节”。但如果你这样做了，恭喜你！&lt;/p &gt;&#xA;&lt;p&gt;这件事发生在一次关于 &lt;a href=&#34;/oss/opentelemetry/?pg=blog&amp;plcmt=body-txt&#34;&gt;OpenTelemetry&lt;/a&gt; 的对话中，对话的共同主持人包括 Grafana Labs 工程总监 Mat Ryer 和 Matt Grafana Labs 文化副总裁 Toback 开玩笑地试图从两位成员、播客嘉宾 Juraci 那里了解 OpenTelemetry 治理委员会的内部运作情况Grafana 首席工程师 Paixão Kröhling 和 Skyscanner 首席工程师 Daniel Gomez Blanco。 （说实话，这一集中最令人震惊的细节可能是马特仍然拥有一根拉链驱动器电缆......）&lt;/p&gt;&#xA;&lt;p&gt;您可以阅读下面的一些节目亮点，但也可以收听完整剧集，了解有关仪器和分布式跟踪的更多信息，以及 OTel 的历史 - 包括其早期名称 - TBT（基于跟踪的测试）、ODD（可观测性） -驱动的发展），以及马特的百老汇时刻。&lt;/p&gt;&#xA;&lt;iframe width =“100％”height =“180”frameborder =“否”滚动=“否”无缝=“”src =“https://share.transistor.fm/e/e8c53636”&gt; &lt;/ iframe&gt;&#xA;&lt;p&gt;&lt;em&gt;注意：以下是“Grafana’s Big Tent”播客第二季第 9 集的精彩片段。为了长度和清晰度，下面的文字记录已经过编辑。&lt;/em&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;the-basics-of-opentelemetry&#34;&gt;OpenTelemetry 基础知识&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Mat Ryer：&lt;/strong&gt;对于不熟悉 OTel 的人来说，这是什么？&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Daniel Gomez Blanco&lt;/strong&gt;：OpenTelemetry 是一个框架，可让您检测、收集、处理并传输遥测数据。它专注于云原生系统，主要目标之一是您可以以标准格式并使用一组标准命名约定从任何应用程序、任何库、任何语言生成所有遥测数据，然后将其推送到任何后端。它与供应商无关，因此您可以通过遥测进行任何您想做的事情。您不必被迫使用特定的解决方案或后端。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Mat：&lt;/strong&gt;在此之前，我们有不同的系统，它们有不同的传统、不同的名称、不同的技术。因此，我们的目标是统一所有内容并让每个人都遵循一套标准。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;丹尼尔：&lt;/strong&gt;是的，这是一套标准，也是对可观察性非常非常重要的东西，即上下文。我们不再考虑您的指标、日志和痕迹。您拥有的所有内容都是一组相互关联的遥测数据的一部分，以便您从应用程序中获得更好的见解。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Juraci Paixão Kröhling：&lt;/strong&gt;OpenTelemetry 的优点之一是它是在现有工具非常成功的情况下出现的已经足够了，所以我们试图让开放遥测与我们之前的事情很好地配合。当然，并不是所有东西在哲学上都是 100% 兼容的，但我们试图让人们可以使用 OpenTelemetry，即使他们不喜欢它的每个部分，或者即使他们已经对其他部分感到满意​​。&lt;/p&gt;&#xA;&lt;h2 id=&#34;learning-the-rules&#34;&gt;学习规则&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Mat：&lt;/strong&gt;您提到了日志、指标和跟踪。作为一名日常开发人员，您如何知道我们应该使用哪些遥测类型？是否有一套规则，或者这种直觉和经验是你必须随着时间的推移而学习的？&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;丹尼尔：&lt;/strong&gt;这很大程度上取决于系统。要问的第一个问题是您是否应该自己添加遥测数据，或者是否应该依赖仪器库或库本身发出的遥测数据？ OpenTelemetry 的功能之一是仪器作者以及库作者为您编写遥测数据。因此，假设您选择了一个开源库，该库已经配备了您需要的指标，或者您需要的跨度和跟踪工具 - 您不需要自己添加。&lt;/p&gt;&#xA;&lt;p&gt;当我们谈论检测我们自己的数据、我们自己的应用程序时，我认为选择适合您的用例的遥测技术非常重要。因此，如果您希望驱动警报或仪表板或您长期关注的内容，您可能会查看时间序列数据，以便需要指标。如果您正在寻找真正高粒度的见解，并且您对它们如何在复杂的分布式系统中组合在一起感兴趣，并且您对上下文感兴趣，那么您需要跟踪。然后，如果您想与一些可能不会产生任何跨度或任何指标的遗留系统集成，那么您需要依赖日志。&lt;/p&gt;&#xA;&lt;p&gt;但重要的是您可以获得上下文的所有这些部分，即同一组相关数据。这正是 OTel 所提供的帮助——弥合这一差距。&lt;/p&gt;&#xA;&lt;p&gt;另一种思考方式是进入多个不同的粒度级别。您可能从指标开始，然后想要将其与您的跟踪相关联，然后可能继续降低抽象级别，然后深入到配置文件。&lt;/p&gt;&#xA;&lt;p&gt;我们想要讲述的故事是，您需要所有这些数据，并且需要将它们关联起来。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Juraci：&lt;/strong&gt;我的心理模型有点不同。当我开发应用程序时，我会尝试将自己置于未来——比如凌晨 2 点停电期间，查看我的代码并思考，我需要知道什么才能了解​​正在发生的情况？我很可能不需要单独的日志条目。当我需要汇总信息时，我需要指标，我可以想，W我需要哪些指标？我需要测量我现在正在处理的队列的大小吗？传出 HTTP 请求是否需要延迟？诸如此类的事情。&lt;/p&gt;&#xA;&lt;p&gt;第二种模式是，我具体需要了解交易的上下文是什么？当我将事务视为一个整体（微服务）时，我知道我需要一个跨度。我知道我需要分布式跟踪。当我考虑相邻服务时，我知道我需要的一件事是一个代表我的传入 HTTP 请求或我的传入 RPC 的跨度，以及一个代表我的传出 RPC 的跨度。这就是我在分布式跟踪方面真正需要的一切，因为这样我就可以在跟踪中看到整个链。我觉得日志主要是我的应用程序的生命周期事件。&lt;/p&gt;&#xA;&lt;h2 id=&#34;making-a-game-out-of-learning&#34;&gt;通过学习制作游戏&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Matt：&lt;/strong&gt;很多时候，当我们谈论如何检测您的应用程序时，您会感觉您正在为未来的自己选择检测来进行故障排除。您多久会发现同一应用程序上的团队方法存在差异？&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;丹尼尔：&lt;/strong&gt;这取决于团队的习惯。我最近与 Skyscanner 的一些团队一起做的事情之一是浏览 OTel 演示并制作一些游戏。我们把他们放在演示前面，我们向该系统注入一些故障，然后要求他们去调试它。我们尝试让不同的团队相互竞争，看看谁先找到根本原因。&lt;/p&gt;&#xA;&lt;p&gt;如果您使用上下文，您可以更快地找到根本原因，而不是从我们设置的由指标驱动的警报开始。仅通过查看指标，您将无法回答“根本原因是什么？是什么导致了它的失败？”&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;马特：&lt;/strong&gt;你是否见过有人发现自己比以前看得更多的恍然大悟的时刻？&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;丹尼尔：&lt;/strong&gt;有一位工程师坚信他们能够仅通过日志进行调试，因为这是他们习惯的。但他们没有赢。另一个房间里的人正在使用跟踪，并且在查找根本原因方面取得了很大的进展，所以这很有趣。&lt;/p&gt;&#xA;&lt;h2 id=&#34;why-some-people-still-dont-understand-observability&#34;&gt;为什么有些人仍然不理解可观察性&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Juraci：&lt;/strong&gt;我在编写代码时也会考虑遥测，但我认为进入那里存在一些障碍。出于好奇，我查看了巴西一些计算机科学课程的课程——但我认为这也适用于其他地方——我们教人们如何编写操作系统，但我们不告诉人们如何监控它们。我们没有教他们如何进行可观察性，比如如何理解正在发生的事情，这是一个真正的差距。&lt;/p&gt;&#xA;&lt;人们很难理解分布式追踪。这是一个很难的话题。很难想象部分数据会直接发送到某个地方的收集器，并且部分数据会作为 RPC 的一部分向下传播。那么哪一个是哪一个呢？什么是哪里？这实际上是如何运作的？为什么我需要一个具有两种类型的 ID 和标志的跟踪上下文？这些是我们假设人们知道的事情，如果他们不知道，我们会向他们提供工具。但随后他们在不知道里面有什么的情况下使用它们，当他们拥有的遥测系统出现问题时，这使得调试变得非常困难。&lt;/p&gt;&#xA;&lt;p&gt;一方面，我认为开发仪器的工具是必要的。另一方面，我认为我们最终会遇到一个巨大的成本问题，这在可观测性方面已经是一个现实，因为我们拥有生成大量我们实际上并不需要的遥测数据的工具。当我们查看收集到的大多数痕迹时，我们并没有使用其中的大部分。几年前，有人提到近 90% 的痕迹都是被创建、传输和存储的，但从未被看到过——所有这些几乎没有任何作用。&lt;/p&gt;&#xA;&lt;p&gt;如果我们只有手动仪器，那么我们将只存储高价值的数据，并且比我们现在拥有的数据少得多。但由于它很难理解和手动检测，我们最终使用了那些非常强大的工具来生成大量我们可能不需要的遥测数据，希望它们在未来的某个时候变得有用。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;马特：&lt;/strong&gt;你多久修剪一次？&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Juraci：&lt;/strong&gt;我们从来不这样做。我认为不删除某些东西是我们的本性，因为担心该东西将来可能有用。我认为这就是学术界比我们先进得多的地方。在这一领域正在进行一些研究，根据系统的当前状态打开和关闭仪表点。我认为未来并不是我们不再像今天所做的那样对事物进行仪器化，而是我们是否首先收集、存储和传输这些数据。 &lt;/p&gt;&#xA;&lt;h2 id=&#34;the-need-for-a-culture-shift&#34;&gt;文化转变的必要性&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Mat：&lt;/strong&gt;采用的最大挑战是什么，人们并不真正了解它，还是存在其他阻力？&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;丹尼尔：&lt;/strong&gt;挑战之一是人们不知道这一点。您需要改变多年来的文化和分布式系统中的人员，将其视为整体（如孤立的实体），而不考虑整个系统。我认为从工程角度来看，这需要改变，或者我们如何操作系统。&lt;/p&gt;&#xA;&lt;p&gt;采用还存在另一个挑战，这往往与成本相关，因为我们从分布式系统生成大量遥测数据。贝夫如果你之前可能有一个巨大的复制品，那么现在你只有很小的组件来产生遥测数据。我认为了解分布式跟踪和上下文可以让您更好地决定保留什么和不保留什么，这一点也很重要。&lt;/p&gt;&#xA;&lt;p&gt;成本是一个挑战，但并非不可克服的挑战。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Juraci：&lt;/strong&gt;我认为还有一种情况，人们只有在拥有经验时才能看到价值。人们需要一段时间才能意识到他们需要可观察性，即使经过多年的经验，他们甚至可能没有意识到这一点。&lt;/p&gt;&#xA;&lt;h2 id=&#34;weighing-the-trade-offs-of-using-otel&#34;&gt;权衡使用 OTel 的利弊&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Mat：&lt;/strong&gt;使用 OTel 是否有缺点，或者我们必须注意哪些权衡？&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;丹尼尔：&lt;/strong&gt;这取决于您作为一个组织在可观察性之旅中所处的阶段。因此，如果您拥有非常稳定的流程，并且 OTel 中可能有些东西还不太稳定，那么您可以采用非常稳定的部分，并尝试对其进行简化和整合。还有其他部分不太稳定，例如与配置文件相关的东西。所以我认为，如果你有一些目前正在发挥作用的东西，那么它可能是你需要等到事情变得更加稳定的事情之一。&lt;/p&gt;&#xA;&lt;p&gt;如果您完全是新手并且从头开始，您的天平可能会倾向于创新。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Juraci：&lt;/strong&gt;我认为这也是相对的。该收集器还没有达到 v1，所以理论上它还不稳定。但这并不能阻止像 eBay 的 Vijay [Samuel] 这样的人在那里实施高度可扩展的收集器管道并在 KubeCon 上发表演讲。&lt;/p&gt;&#xA;&lt;p&gt;我们认为这对于某些事情来说很好，但对于其他事情来说就不太好了。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;丹尼尔：&lt;/strong&gt;它确实需要平台工程团队进行一些尽职调查。例如，在 Skyscanner，我们也大规模运行收集器，每秒处理超过一百万个跨度，每秒处理数十万个数据点。收集器不是 v1，但我们依赖的组件（OTLP、接收和导出）以及我们使用的处理器是稳定的。&lt;/p&gt;&#xA;&lt;h2 id=&#34;governance-committee-scoop&#34;&gt;治理委员会独家报道&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Mat：&lt;/strong&gt;请告诉我们更多有关您在治理委员会所做的工作的信息，特别是如果您现在正在从事任何有趣的事情。或者我很想知道关于你不同意的大地方的八卦，或者幕后的事情。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;丹尼尔：&lt;/strong&gt;我认为我们没有太大分歧。我们都非常一致。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Juraci：&lt;/strong&gt;我们所有的通话都会被录音，因此会议记录是公开的，并且录音&lt;a href=&#34;https://github.com/open-telemetry/community?tab=readme- ov-file#governing-bodies&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;可用&lt;/a&gt; - 毕竟这是一个开源项目。我们确实有私人会议，讨论与行为准则真正相关的事情或来自社区的人们的投诉。这是一个很大的社区，所以分歧肯定会发生。我们的团队会平衡这一点，并确保我们作为一个社区不断前进，并且我们不会忽视可能在未来造成更大问题的问题。&lt;/p&gt;&#xA;&lt;p&gt;但我认为我们最大的挑战是，尽管 OpenTelemetry 充满了来自供应商的人员 - 那里的大多数人为供应商工作 - 尽管我们在该项目背后有商业利益，但归根结底，我们都是，志愿者。我们大多数人最终都会在工作时间做一些事情。我们为此获得报酬，但这不是我们纳入 OKR 的内容。&lt;/p&gt;&#xA;&lt;p&gt;作为 GC 治理委员会的一部分，困难的部分是就路线图达成一致，并说服其他人他们必须关注我们所说的内容，因为“这是我们认为重要的事情” 。不仅倾听我们的意见，而且遵循我们正在努力走的道路。”&lt;/p&gt;&#xA;&lt;p&gt;我们是软件工程师，所以我们每天都会发现新玩具，并且我们想玩这些玩具。在这一点上，我坦率的意见是，我们有太多玩具，我们必须进行一些春季大扫除，看看什么值得保留，什么不值得，以及我们应该宣布什么是好主意，但为了未来.&lt;/p&gt;&#xA;&lt;h2 id=&#34;whats-coming-up-for-otel&#34;&gt;OTel 即将推出的产品&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Mat：&lt;/strong&gt;说到新玩具，什么是新的？ OTel 接下来令人兴奋的事情是什么？&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Daniel&lt;/strong&gt;：让每个人都兴奋的事情之一是将分析作为新信号，以及如何获得与跟踪相关的分析。这将为您在调试实践中探索开辟一条新途径。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Juraci：&lt;/strong&gt;我期待很多事情。我认为其中之一是 &lt;a href=&#34;https://github.com/open-telemetry/community?tab=readme-ov-file#specification-sigs&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;实体 SIG&lt;/a&gt;。我认为这是我们在 OpenTelemetry 中的第一次重大重构，即重构资源属性的想法。资源就是 Dan 之前提到的上下文。它将所有信号连接在一起。&lt;/p&gt;&#xA;&lt;p&gt;事实证明，并非所有我们认为对资源属性具有良好价值的东西实际上都是好的。对于那些不能很好地处理高基数的事情，例如 &lt;a href=&#34;/oss/prometheus/?pg=blog&amp;plcmt=body-txt&#34;&gt;Prometheus&lt;/a&gt; ，它们可能会出现问题，所以我们可能不想要将进程 ID 存储为资源属性的一部分。关于流程的元数据是很好的，但我们实际上并不需要它。&lt;/p&gt;&#xA;&lt;p&gt;实体 SIG 将资源上下文分解为身份资源和身份 SIG ��� 那么我的资源的身份是什么，我的资源的元数据是什么，这样信号之间的链接上下文就会非常薄，我可以在 Prometheus 和 &lt;a href=&#34;/oss/loki/ 中使用它们?pg=blog&amp;plcmt=body-txt&#34;&gt;Loki&lt;/a&gt; 或不同的数据存储中，元数据可以存储在其他地方。它不必被索引。它不必是对象标识的一部分。&lt;/p&gt;&#xA;&lt;p&gt;也许它不像分析那么令人兴奋，但我认为这是非常必要的，而且这是我们正在进行重构的成熟标志。&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;“Grafana 的大帐篷”播客希望收到您的来信。如果您有精彩的故事要分享、想要加入对话或有任何反馈，请联系 Big Tent 团队：&lt;a href=&#34;/blog/2024/08/23/grafanas-big-tent-podcast-season -2-is-here/bigtent@grafana.com&#34;&gt;bigtent@grafana.com&lt;/a&gt;。您还可以在 &lt;a href=&#34;https://podcasts.apple.com/us/podcast/grafanas-big-tent/id1616725129&#34; target=&#34;_blank&#34; 上观看《Grafana&#39;s Big Tent》第一季和第二季rel=&#34;noopener noreferrer&#34;&gt;Apple 播客&lt;/a&gt; 和 &lt;a href=&#34;https://open.spotify.com/show/3beQvS8to0rYs1gxOnP​​rfD?si=bf046f54fe214615&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Spotify&lt;/a&gt;。&lt;/em&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 20 Dec 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【PromQL vector matching: what it is and how it affects your Prometheus queries】PromQL 向量匹配：它是什么以及它如何影响您的 Prometheus 查询</title>
      <link>https://grafana.com/blog/2024/12/13/promql-vector-matching-what-it-is-and-how-it-affects-your-prometheus-queries/</link>
      <description>【&lt;p&gt;&lt;em&gt;Dawid Dębowski is a software engineer at G2A.COM and a Grafana Champion. Holding an MS of Computer Science, Dawid’s main fields of interest related to observability are PromQL and data visualizations using Grafana.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;Have you ever created an awesome query in PromQL, expecting it to return the exact results you’re looking for, only to receive the &amp;ldquo;No data&amp;rdquo; response when you run it? If so, you might have fallen into the trap of PromQL vector matching.&lt;/p&gt;&#xA;&lt;p&gt;In this post, we will provide an overview of what vectors are in PromQL, including the different types and why they’re important. We will also explain the concept of vector matching and walk through an example of it, using Prometheus and Grafana.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;em&gt;Note: If you want to learn more about the overall mechanics of PromQL queries, you can also check out &lt;a href=&#34;/blog/2024/10/08/inside-promql-a-closer-look-at-the-mechanics-of-a-prometheus-query/&#34;&gt;this blog post&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h2 id=&#34;prometheus-vectors-an-overview&#34;&gt;Prometheus vectors: an overview&lt;/h2&gt;&#xA;&lt;p&gt;In Prometheus, almost every query returns a &lt;em&gt;vector,&lt;/em&gt; which is a collection of time series data points. These can either be an &lt;em&gt;instant vector&lt;/em&gt; or a &lt;em&gt;range vector&lt;/em&gt;.&lt;/p&gt;&#xA;&lt;p&gt;You can think of an &lt;a href=&#34;https://prometheus.io/docs/prometheus/latest/querying/basics/#instant-vector-selectors&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;instant vector&lt;/a&gt; as a pair &lt;code&gt;(v1, t1)&lt;/code&gt; with value and time, while a &lt;a href=&#34;https://prometheus.io/docs/prometheus/latest/querying/basics/#range-vector-selectors&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;range vector&lt;/a&gt; is an array &lt;code&gt;[(v1, t1), (v2, t2), (v3, t3), …]&lt;/code&gt;. Each vector can also have labels, and different labels mean different vectors.&lt;/p&gt;&#xA;&lt;p&gt;There’s also a &lt;em&gt;scalar&lt;/em&gt; type, which is a single floating point value without any time connotations — for example, &lt;code&gt;v1&lt;/code&gt;. These definitions of vectors and scalars are important because of binary operations. As you can imagine, dividing a scalar by a scalar is easy, and so is dividing a vector by a scalar (where the value of every element of the vector is divided by the scalar). But what about dividing a vector by a vector?&lt;/p&gt;&#xA;&lt;p&gt;In PromQL, arithmetic binary operations are defined only for instant vectors (trying to divide a range vector by another range vector will yield an error). &lt;a href=&#34;https://prometheus.io/docs/prometheus/latest/querying/operators/#arithmetic-binary-operators&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;According to Prometheus docs,&lt;/a&gt; applying binary operations between two instant vectors results in using the binary operator to each entry in the left-hand vector and its matching element in the right-hand vector.&lt;/p&gt;&#xA;&lt;p&gt;Seems complicated, right? Let’s clear things up with an example.&lt;/p&gt;&#xA;&lt;h2 id=&#34;setting-up-the-environment&#34;&gt;Setting up the environment&lt;/h2&gt;&#xA;&lt;p&gt;Let’s say we deployed a simple application for collecting Pokémons. The application exposes the &lt;code&gt;pokemon_caught_total&lt;/code&gt; metric (a simple counter) with a &lt;code&gt;type&lt;/code&gt; label, representing the Pokémon type. For scraping metrics, we’re using Prometheus and, for visualization, we’re using Grafana.&lt;/p&gt;&#xA;&lt;p&gt;Let’s start with a simple query: &lt;code&gt;pokemon_caught_total{type=&amp;quot;water&amp;quot;}&lt;/code&gt;, which displays the amount of &lt;code&gt;water&lt;/code&gt; type Pokémons the application gathered from the start of its lifecycle.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 850px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/promql-vector-matching/promql-vector-water-types1.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/promql-vector-matching/promql-vector-water-types1.png&#34;data-srcset=&#34;/media/blog/promql-vector-matching/promql-vector-water-types1.png?w=320 320w, /media/blog/promql-vector-matching/promql-vector-water-types1.png?w=550 550w, /media/blog/promql-vector-matching/promql-vector-water-types1.png?w=750 750w, /media/blog/promql-vector-matching/promql-vector-water-types1.png?w=900 900w, /media/blog/promql-vector-matching/promql-vector-water-types1.png?w=1040 1040w, /media/blog/promql-vector-matching/promql-vector-water-types1.png?w=1240 1240w, /media/blog/promql-vector-matching/promql-vector-water-types1.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A screenshot of an example PromQL query.&#34;width=&#34;850&#34;height=&#34;584&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/promql-vector-matching/promql-vector-water-types1.png&#34;&#xA;alt=&#34;A screenshot of an example PromQL query.&#34;width=&#34;850&#34;height=&#34;584&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;As you can see, it’s an instant vector — it is placed in time and has a value. Another quick query shows that, for now, we’ve caught 285 Pokémons. Water types caught by us are roughly &lt;code&gt;5.26%&lt;/code&gt; of our 285 total Pokémons.&lt;/p&gt;&#xA;&lt;p&gt;Let’s see what Prometheus will say:&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 850px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/promql-vector-matching/promql-vectors-water-types2.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/promql-vector-matching/promql-vectors-water-types2.png&#34;data-srcset=&#34;/media/blog/promql-vector-matching/promql-vectors-water-types2.png?w=320 320w, /media/blog/promql-vector-matching/promql-vectors-water-types2.png?w=550 550w, /media/blog/promql-vector-matching/promql-vectors-water-types2.png?w=750 750w, /media/blog/promql-vector-matching/promql-vectors-water-types2.png?w=900 900w, /media/blog/promql-vector-matching/promql-vectors-water-types2.png?w=1040 1040w, /media/blog/promql-vector-matching/promql-vectors-water-types2.png?w=1240 1240w, /media/blog/promql-vector-matching/promql-vectors-water-types2.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A screenshot of Prometheus results for a sample PromQL query.&#34;width=&#34;850&#34;height=&#34;584&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/promql-vector-matching/promql-vectors-water-types2.png&#34;&#xA;alt=&#34;A screenshot of Prometheus results for a sample PromQL query.&#34;width=&#34;850&#34;height=&#34;584&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;Well, that’s… unexpected. But wait, we forgot about the &lt;code&gt;sum&lt;/code&gt; around the divisor. That should do it!&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 850px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/promql-vector-matching/promql-vector-matching-no-data1.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/promql-vector-matching/promql-vector-matching-no-data1.png&#34;data-srcset=&#34;/media/blog/promql-vector-matching/promql-vector-matching-no-data1.png?w=320 320w, /media/blog/promql-vector-matching/promql-vector-matching-no-data1.png?w=550 550w, /media/blog/promql-vector-matching/promql-vector-matching-no-data1.png?w=750 750w, /media/blog/promql-vector-matching/promql-vector-matching-no-data1.png?w=900 900w, /media/blog/promql-vector-matching/promql-vector-matching-no-data1.png?w=1040 1040w, /media/blog/promql-vector-matching/promql-vector-matching-no-data1.png?w=1240 1240w, /media/blog/promql-vector-matching/promql-vector-matching-no-data1.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A screenshot of PromQL query returning a No data response.&#34;width=&#34;850&#34;height=&#34;584&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/promql-vector-matching/promql-vector-matching-no-data1.png&#34;&#xA;alt=&#34;A screenshot of PromQL query returning a No data response.&#34;width=&#34;850&#34;height=&#34;584&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;Still no results. So, what’s going on exactly?&lt;/p&gt;&#xA;&lt;h2 id=&#34;vector-matching&#34;&gt;Vector matching&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://prometheus.io/docs/prometheus/latest/querying/operators/#vector-matching&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Prometheus documentation&lt;/a&gt; includes information about matching elements. When there’s an arithmetic operation between two instant vectors, Prometheus will compare all the labels in the vectors and try to find matches between them. Unmatched vectors will be dropped from the result. That’s why the first example showed 100% — Prometheus found one match between vectors on both sides, and it was a vector with the &lt;code&gt;type=water&lt;/code&gt; label. The rest of the search results did not match, so they were dropped from the final results. This is the same reason why the second example returned &lt;code&gt;No data&lt;/code&gt;, even though both sides had some data: &lt;code&gt;sum&lt;/code&gt; results in a vector with no labels, so there was no way Prometheus could match something to nothing.&lt;/p&gt;&#xA;&lt;p&gt;This is why it’s important to pay attention when using binary operations between two vectors — sometimes, your result might look right, but it&amp;rsquo;s not, because Prometheus didn’t match all the vectors it should have.&lt;/p&gt;&#xA;&lt;h2 id=&#34;the-solution&#34;&gt;The solution&lt;/h2&gt;&#xA;&lt;p&gt;The easiest solution here is to have the same labels on the left-hand and right-hand vectors. In the example with the &lt;code&gt;water&lt;/code&gt; type Pokémon percentage calculation, all it takes is to strip the labels from the left side of the operation:&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 850px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/promql-vector-matching/promql-vector-matching-strip-the-labels.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/promql-vector-matching/promql-vector-matching-strip-the-labels.png&#34;data-srcset=&#34;/media/blog/promql-vector-matching/promql-vector-matching-strip-the-labels.png?w=320 320w, /media/blog/promql-vector-matching/promql-vector-matching-strip-the-labels.png?w=550 550w, /media/blog/promql-vector-matching/promql-vector-matching-strip-the-labels.png?w=750 750w, /media/blog/promql-vector-matching/promql-vector-matching-strip-the-labels.png?w=900 900w, /media/blog/promql-vector-matching/promql-vector-matching-strip-the-labels.png?w=1040 1040w, /media/blog/promql-vector-matching/promql-vector-matching-strip-the-labels.png?w=1240 1240w, /media/blog/promql-vector-matching/promql-vector-matching-strip-the-labels.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A screenshot showing a PromQL query with the labels stripped away from the left side of the operation.&#34;width=&#34;850&#34;height=&#34;366&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/promql-vector-matching/promql-vector-matching-strip-the-labels.png&#34;&#xA;alt=&#34;A screenshot showing a PromQL query with the labels stripped away from the left side of the operation.&#34;width=&#34;850&#34;height=&#34;366&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;Since we have queried all the interesting Pokémons on the left side, we can also use &lt;code&gt;sum&lt;/code&gt; to get the sum across the series. Now both sides have no labels, so Prometheus can match them. However, what if we wanted to create a chart of the percentages of Pokémon types we caught?&lt;/p&gt;&#xA;&lt;p&gt;Using grouping on the aggregation makes us go back to square one:&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 850px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/promql-vector-matching/promql-vectors-grouping-by-aggregations.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/promql-vector-matching/promql-vectors-grouping-by-aggregations.png&#34;data-srcset=&#34;/media/blog/promql-vector-matching/promql-vectors-grouping-by-aggregations.png?w=320 320w, /media/blog/promql-vector-matching/promql-vectors-grouping-by-aggregations.png?w=550 550w, /media/blog/promql-vector-matching/promql-vectors-grouping-by-aggregations.png?w=750 750w, /media/blog/promql-vector-matching/promql-vectors-grouping-by-aggregations.png?w=900 900w, /media/blog/promql-vector-matching/promql-vectors-grouping-by-aggregations.png?w=1040 1040w, /media/blog/promql-vector-matching/promql-vectors-grouping-by-aggregations.png?w=1240 1240w, /media/blog/promql-vector-matching/promql-vectors-grouping-by-aggregations.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;Another screenshot of a PromQL query returning a No data result.&#34;width=&#34;850&#34;height=&#34;591&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/promql-vector-matching/promql-vectors-grouping-by-aggregations.png&#34;&#xA;alt=&#34;Another screenshot of a PromQL query returning a No data result.&#34;width=&#34;850&#34;height=&#34;591&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;Creating multiple charts or using &lt;a href=&#34;/docs/grafana/latest/dashboards/variables/&#34;&gt;Grafana variables&lt;/a&gt; is also not an option if we want to, for example, compare that data on a single plot. Fortunately, PromQL provides a couple of keywords that allow us to match vectors with different label sets: &lt;code&gt;on&lt;/code&gt; and &lt;code&gt;ignoring&lt;/code&gt;. With those keywords, we show Prometheus the labels &lt;code&gt;on&lt;/code&gt; which the vector matching should be performed, or the labels Prometheus should be &lt;code&gt;ignoring&lt;/code&gt; while performing the match. If you’re using one-to-one matching (where each vector on one side has to exactly match one vector on the other side), all you need to do is use one of the keywords after the binary operator sign.&lt;/p&gt;&#xA;&lt;p&gt;Let’s go back to calculating the percentage of &lt;code&gt;water&lt;/code&gt; type Pokémons:&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 850px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/promql-vector-matching/promql-vector-matching-on-filter.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/promql-vector-matching/promql-vector-matching-on-filter.png&#34;data-srcset=&#34;/media/blog/promql-vector-matching/promql-vector-matching-on-filter.png?w=320 320w, /media/blog/promql-vector-matching/promql-vector-matching-on-filter.png?w=550 550w, /media/blog/promql-vector-matching/promql-vector-matching-on-filter.png?w=750 750w, /media/blog/promql-vector-matching/promql-vector-matching-on-filter.png?w=900 900w, /media/blog/promql-vector-matching/promql-vector-matching-on-filter.png?w=1040 1040w, /media/blog/promql-vector-matching/promql-vector-matching-on-filter.png?w=1240 1240w, /media/blog/promql-vector-matching/promql-vector-matching-on-filter.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A screenshot of a PromQL query using the on keyword.&#34;width=&#34;850&#34;height=&#34;380&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/promql-vector-matching/promql-vector-matching-on-filter.png&#34;&#xA;alt=&#34;A screenshot of a PromQL query using the on keyword.&#34;width=&#34;850&#34;height=&#34;380&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;As you can see, we told Prometheus to match &lt;code&gt;on&lt;/code&gt; an empty set of labels, since the common label set is empty. Also, as exactly one vector on the left side matches only one vector on the right side, we have one-to-one matching and the &lt;code&gt;on&lt;/code&gt; keyword is enough.&lt;/p&gt;&#xA;&lt;p&gt;But what about when we want to match multiple vectors on the left side to one vector on the right? As you can see, we have an error:&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 854px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/promql-vector-matching/promql-vector-matching-on-filter-no-date.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/promql-vector-matching/promql-vector-matching-on-filter-no-date.png&#34;data-srcset=&#34;/media/blog/promql-vector-matching/promql-vector-matching-on-filter-no-date.png?w=320 320w, /media/blog/promql-vector-matching/promql-vector-matching-on-filter-no-date.png?w=550 550w, /media/blog/promql-vector-matching/promql-vector-matching-on-filter-no-date.png?w=750 750w, /media/blog/promql-vector-matching/promql-vector-matching-on-filter-no-date.png?w=900 900w, /media/blog/promql-vector-matching/promql-vector-matching-on-filter-no-date.png?w=1040 1040w, /media/blog/promql-vector-matching/promql-vector-matching-on-filter-no-date.png?w=1240 1240w, /media/blog/promql-vector-matching/promql-vector-matching-on-filter-no-date.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A screenshot of a PromQL query returning a No data response.&#34;width=&#34;854&#34;height=&#34;498&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/promql-vector-matching/promql-vector-matching-on-filter-no-date.png&#34;&#xA;alt=&#34;A screenshot of a PromQL query returning a No data response.&#34;width=&#34;854&#34;height=&#34;498&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;We have many vectors on the left side that match one vector on the right side — that’s many-to-one matching. In this case, we have to show Prometheus from which side we want our labels (which side represents the “many”), using &lt;code&gt;group_left&lt;/code&gt; or &lt;code&gt;group_right&lt;/code&gt; keywords. When we want to preserve labels from the left side, we use &lt;code&gt;group_left,&lt;/code&gt; and when from the right side, we use &lt;code&gt;group_right&lt;/code&gt;:&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 850px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/promql-vector-matching/promql-vector-group-left.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/promql-vector-matching/promql-vector-group-left.png&#34;data-srcset=&#34;/media/blog/promql-vector-matching/promql-vector-group-left.png?w=320 320w, /media/blog/promql-vector-matching/promql-vector-group-left.png?w=550 550w, /media/blog/promql-vector-matching/promql-vector-group-left.png?w=750 750w, /media/blog/promql-vector-matching/promql-vector-group-left.png?w=900 900w, /media/blog/promql-vector-matching/promql-vector-group-left.png?w=1040 1040w, /media/blog/promql-vector-matching/promql-vector-group-left.png?w=1240 1240w, /media/blog/promql-vector-matching/promql-vector-group-left.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A screenshot of a PromQL query using the group left keyword.&#34;width=&#34;850&#34;height=&#34;505&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/promql-vector-matching/promql-vector-group-left.png&#34;&#xA;alt=&#34;A screenshot of a PromQL query using the group left keyword.&#34;width=&#34;850&#34;height=&#34;505&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;Now, we have all our Pokémon type percentages. To check, the &lt;code&gt;water&lt;/code&gt; type percentage is &lt;code&gt;5.26%&lt;/code&gt;, just as we calculated before.&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;Note: &lt;a href=&#34;https://prometheus.io/docs/prometheus/latest/querying/operators/#group-modifiers&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Prometheus documentation&lt;/a&gt; mentions that &lt;code&gt;group_.&lt;/em&gt;&lt;/code&gt; are advanced use cases that should be carefully considered.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;wrapping-up&#34;&gt;Wrapping up&lt;/h2&gt;&#xA;&lt;p&gt;Now you know that binary operations between vectors might not be as straightforward as they seem! You can visit this &lt;a href=&#34;https://github.com/Davenury/PromQL-Vector-Matching-Demo&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;GitHub repo&lt;/a&gt; if you’d like to play around with the metrics and sample Pokémon application more.&lt;/p&gt;&#xA;&lt;p&gt;You can also find more about vectors in these &lt;a href=&#34;https://prometheus.io/docs/prometheus/latest/querying/basics/#time-series-selectors&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;PromQL docs, &lt;/a&gt; and the logic of arithmetic operations is described in detail &lt;a href=&#34;https://prometheus.io/docs/prometheus/latest/querying/operators/#arithmetic-binary-operators&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;here&lt;/a&gt;. Examples we’ve discussed in this post can be easily carried over to real-life scenarios, like HTTP response times or HTTP status codes — for example, to find the percentage of error status codes within all traffic.&lt;/p&gt;&#xA;&lt;p&gt;That’s it for now, and thank you for following along!&lt;/p&gt;】&lt;p&gt;&lt;em&gt;Dawid Dębowski 是 G2A.COM 的软件工程师，也是 Grafana 冠军。 Dawid 拥有计算机科学硕士学位，与可观测性相关的主要兴趣领域是 PromQL 和使用 Grafana 的数据可视化。&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;您是否曾经在 PromQL 中创建过一个很棒的查询，期望它返回您正在寻找的确切结果，但在运行它时却收到“无数据”响应？如果是这样，您可能已经陷入了 PromQL 向量匹配的陷阱。&lt;/p&gt;&#xA;&lt;p&gt;在这篇文章中，我们将概述 PromQL 中的向量，包括不同的类型以及它们的重要性。我们还将解释矢量匹配的概念，并使用 Prometheus 和 Grafana 演示它的示例。&lt;/p&gt;&#xA;&lt;块引用&gt;&#xA;&lt;p&gt;&lt;em&gt;注意：如果您想了解有关 PromQL 查询的整体机制的更多信息，您还可以查看 &lt;a href=&#34;/blog/2024/10/08/inside-promql-a-closer-look -at-the-mechanics-of-a-prometheus-query/&#34;&gt;这篇博文&lt;/a&gt;。&lt;/em&gt;&lt;/p&gt;&#xA;&lt;/块引用&gt;&#xA;&lt;h2 id=&#34;prometheus-vectors-an-overview&#34;&gt;Prometheus 向量：概述&lt;/h2&gt;&#xA;&lt;p&gt;在 Prometheus 中，几乎每个查询都会返回一个向量，它是时间序列数据点的集合。这些可以是&lt;em&gt;即时向量&lt;/em&gt;或&lt;em&gt;范围向量&lt;/em&gt;。&lt;/p&gt;&#xA;&lt;p&gt;你可以想到一个 &lt;a href=&#34;https://prometheus.io/docs/prometheus/latest/querying/basics/#instant-vector-selectors&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;即时向量&lt;/a&gt;作为具有值和时间的一对&lt;code&gt;(v1, t1)&lt;/code&gt;，而&lt;a href=&#34;https://prometheus.io/docs/prometheus/latest/querying/basics/#range-vector-selectors&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;范围向量&lt;/a&gt;是一个数组&lt;代码&gt;[(v1,t1),(v2,t2),(v3,t3),...]&lt;/code&gt;。每个向量还可以有标签，不同的标签代表不同的向量。&lt;/p&gt;&#xA;&lt;p&gt;还有一个&lt;em&gt;标量&lt;/em&gt;类型，它是没有任何时间含义的单个浮点值 - 例如，&lt;code&gt;v1&lt;/code&gt;。由于二元运算，向量和标量的这些定义很重要。正如您可以想象的那样，将标量除以标量很容易，将向量除以标量也很容易（其中向量的每个元素的值除以标量）。但是用一个向量除以一个向量又如何呢？&lt;/p&gt;&#xA;&lt;p&gt;在 PromQL 中，算术二元运算仅为即时向量定义（尝试将范围向量除以另一个范围向量将产生错误）。 &lt;a href=&#34;https://prometheus.io/docs/prometheus/latest/querying/operators/#arithmetic-binary-operators&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;根据 Prometheus 文档，&lt;/a &gt; 在两个即时向量之间应用二元运算会导致对左侧向量中的每个条目及其右侧向量中的匹配元素使用二元运算符。&lt;/p&gt;&#xA;&lt;p&gt;看起来很复杂，对吧？让我们用一个例子来澄清问题。&lt;/p&gt;&#xA;&lt;h2 id=&#34;setting-up-the-environment&#34;&gt;设置环境&lt;/h2&gt;&#xA;&lt;p&gt;假设我们部署了一个简单的应用程序来收集神奇宝贝。该应用程序使用 &lt;code&gt;type&lt;/code&gt; 标签公开 &lt;code&gt;pokemon_caught_total&lt;/code&gt; 指标（一个简单的计数器），代表 Pokémon 类型。对于抓取指标，我们使用 Prometheus，对于可视化，我们使用 Grafana。&lt;/p&gt;&#xA;&lt;p&gt;让我们从一个简单的查询开始：&lt;code&gt;pokemon_caught_total{type=&#34;water&#34;}&lt;/code&gt;，它显示应用程序从其生命周期开始时收集的&lt;code&gt;water&lt;/code&gt;类型神奇宝贝的数量.&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：850px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/promql-vector-matching/promql-vector-water-types1.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/blog/promql-vector-matching/promql-vector-water-types1.png&#34;data-srcset=&#34;/media/blog/promql-vector-matching/promql-vector-water-types1. png?w=320 320w，/media/blog/promql-vector-matching/promql-vector-water-types1.png?w=550 550w，/media/blog/promql-vector-matching/promql-vector-water-types1.png?w=750 750w，/media/blog/promql-vector-matching/promql-vector-water-types1.png?w =900 900w， /media/blog/promql-vector-matching/promql-vector-water-types1.png?w=1040 1040w，/media/blog/promql-vector-matching/promql-vector-water-types1.png?w=1240 1240瓦， /media/blog/promql-vector-matching/promql-vector-water-types1.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;PromQL 查询示例的屏幕截图。&#34;width=&#34;850&#34;height=&#34;584&#34;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/promql-vector-matching/promql-vector-water-types1.png”&#xA;alt=&#34;PromQL 查询示例的屏幕截图。&#34;width=&#34;850&#34;height=&#34;584&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;正如你所看到的，它是一个即时向量——它被放置在时间中并且具有一个值。另一个快速查询显示，目前我们已经捕获了 285 只神奇宝贝。我们捕获的水系类型大约占 285 只神奇宝贝的&lt;code&gt;5.26%&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;让我们看看普罗米修斯会说什么：&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：850px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/promql-vector-matching/promql-vectors-water-types2.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/blog/promql-vector-matching/promql-vectors-water-types2.png&#34;data-srcset=&#34;/media/blog/promql-vector-matching/promql-vectors-water-types2. w=320 320w, /media/blog/promql-vector-matching/promql-vectors-water-types2.png?w=550 550w，/media/blog/promql-vector-matching/promql-vectors-water-types2.png?w=750 750瓦， /media/blog/promql-vector-matching/promql-vectors-water-types2.png?w=900 900w，/media/blog/promql-vector-matching/promql-vectors-water-types2.png?w=1040 1040瓦， /media/blog/promql-vector-matching/promql-vectors-water-types2.png?w=1240 1240w，/media/blog/promql-vector-匹配/promql-vectors-water-types2.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;示例 PromQL 查询的 Prometheus 结果的屏幕截图。&#34;width=&#34;850&#34;height=&#34;584&#34;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/promql-vector-matching/promql-vectors-water-types2.png”&#xA;alt=&#34;示例 PromQL 查询的 Prometheus 结果的屏幕截图。&#34;width=&#34;850&#34;height=&#34;584&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;嗯，这……出乎意料。但是等等，我们忘记了除数周围的&lt;code&gt;sum&lt;/code&gt;。应该可以了！&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：850px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/promql-vector-matching/promql-vector-matching-no-data1.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/blog/promql-vector-matching/promql-vector-matching-no-data1.png&#34;data-srcset=&#34;/media/blog/promql-vector-matching/promql-vector-matching-无数据1.png?w=320 320w, /media/blog/promql-vector-matching/promql-vector-matching-no-data1.png?w=550 550w，/media/blog/promql-vector-matching/promql-vector-matching-no-data1.png ?w=750 750w, /media/blog/promql-vector-matching/promql-vector-matching-no-data1.png?w=900 900w，/media/blog/promql-vector-matching/promql-vector-matching-no-data1.png ?w=1040 1040w, /media/blog/promql-vector-matching/promql-vector-matching-no-data1.png?w=1240 1240w，/media/blog/promql-vector-matching/promql-vector-matching-no-data1.png ?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;返回无数据响应的 PromQL 查询的屏幕截图。&#34;width=&#34;850&#34;height=&#34;584&#34;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/promql-vector-matching/promql-vector-matching-no-data1.png”&#xA;alt=&#34;返回无数据响应的 PromQL 查询的屏幕截图。&#34;width=&#34;850&#34;height=&#34;584&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;仍然没有结果。那么，到底发生了什么？&lt;/p&gt;&#xA;&lt;h2 id=&#34;vector-matching&#34;&gt;矢量匹配&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://prometheus.io/docs/prometheus/latest/querying/operators/#vector-matching&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Prometheus 文档&lt;/a&gt; 包括有关匹配元素的信息。当两个即时向量之间进行算术运算时，Prometheus 会比较向量中的所有标签，并尝试找到它们之间的匹配项。不匹配的向量将从结果中删除。这就是为什么第一个示例显示 100% — Prometheus 在两侧向量之间发现了一个匹配，并且它是带有 &lt;code&gt;type=water&lt;/code&gt; 标签的向量。其余搜索结果不匹配，因此从最终结果中删除。这与第二个示例返回 &lt;code&gt;No data&lt;/code&gt; 的原因相同，即使双方都有一些数据： &lt;code&gt;sum&lt;/code&gt; 结果得到一个没有标签的向量，因此 Prometheus 没有办法可以将某物与无物相匹配。&lt;/p&gt;&#xA;&lt;p&gt;这就是为什么在两个向量之间使用二元运算时要注意这一点很重要——有时，你的 r结果可能看起来正确，但事实并非如此，因为 Prometheus 没有匹配它应有的所有向量。&lt;/p&gt;&#xA;&lt;h2 id=&#34;the-solution&#34;&gt;解决方案&lt;/h2&gt;&#xA;&lt;p&gt;这里最简单的解决方案是在左侧和右侧向量上使用相同的标签。在&lt;code&gt;水&lt;/code&gt;类型神奇宝贝百分比计算的示例中，所需要做的就是从操作的左侧剥离标签：&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：850px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/promql-vector-matching/promql-vector-matching-strip-the-labels.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/blog/promql-vector-matching/promql-vector-matching-strip-the-labels.png&#34;data-srcset=&#34;/media/blog/promql-vector-matching/promql-vector-匹配条带标签.png?w=320 320w, /media/blog/promql-向量匹配/promql-向量匹配-strip-the-labels.png?w=550 550w，/media/blog/promql-向量匹配/promql-向量匹配-strip-the -labels.png?w=750 750w, /media/blog/promql-向量匹配/promql-向量匹配-strip-the-labels.png?w=900 900w，/media/blog/promql-向量匹配/promql-向量匹配-strip-the -labels.png?w=1040 1040w, /media/blog/promql-向量匹配/promql-向量匹配-strip-the-labels.png?w=1240 1240w，/media/blog/promql-向量匹配/promql-向量匹配-strip-the -labels.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;显示 PromQL 查询的屏幕截图，其中标签从操作的左侧剥离。&#34;width=&#34;850&#34;height=&#34;366&#34;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/promql-vector-matching/promql-vector-matching-strip-the-labels.png”&#xA;alt=&#34;显示 PromQL 查询的屏幕截图，其中标签从操作的左侧剥离。&#34;width=&#34;850&#34;height=&#34;366&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;由于我们已经查询了左侧所有有趣的神奇宝贝，因此我们还可以使用 &lt;code&gt;sum&lt;/code&gt; 来获取整个系列的总和。现在双方都没有标签了，所以普罗米修斯可以匹配它们。但是，如果我们想创建一个图表来显示我们捕获的神奇宝贝类型的百分比，该怎么办？&lt;/p&gt;&#xA;&lt;p&gt;在聚合上使用分组使我们回到第一个方向：&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：850px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/promql-vector-matching/promql-vectors-grouping-by-aggregations.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/blog/promql-vector-matching/promql-vectors-grouping-by-aggregations.png&#34;data-srcset=&#34;/media/blog/promql-vector-matching/promql-vectors-grouping- by-aggregations.png?w=320 320w, /media/blog/promql-vector-matching/promql-vectors-grouping-by-aggregations.png?w=550 550w，/media/blog/promql-vector-matching/promql-vectors-grouping-by-aggregations.png?w=750 750w, /media/blog/promql-vector-matching/promql-vectors-grouping-by-aggregations.png?w=900 900w, /media/blog/ promql-向量匹配/promql-vectors-grouping-by-aggregations.png?w=1040 1040w，/media/blog/promql-向量匹配/promql-向量分组按聚合.png?w=1240 1240w，/media/blog/promql-向量匹配/promql-向量分组按聚合.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;返回无数据结果的 PromQL 查询的另一个屏幕截图。&#34;width=&#34;850&#34;height=&#34;591&#34;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/promql-vector-matching/promql-vectors-grouping-by-aggregations.png”&#xA;alt=&#34;返回无数据结果的 PromQL 查询的另一个屏幕截图。&#34;width=&#34;850&#34;height=&#34;591&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;如果我们想要比较数据，那么创建多个图表或使用 &lt;a href=&#34;/docs/grafana/latest/dashboards/variables/&#34;&gt;Grafana 变量&lt;/a&gt; 也不是一个选择。单一情节。幸运的是，PromQL 提供了几个关键字，允许我们将向量与不同的标签集进行匹配：&lt;code&gt;on&lt;/code&gt; 和 &lt;code&gt;ignoring&lt;/code&gt;。通过这些关键字，我们向 Prometheus 展示应在其上执行向量匹配的标签，或者 Prometheus 在执行匹配时应&lt;code&gt;忽略&lt;/code&gt;的标签。如果您使用一对一匹配（其中一侧的每个向量必须与另一侧的一个向量完全匹配），您所需要做的就是在二元运算符号后面使用其中一个关键字。&lt;/p &gt;&#xA;&lt;p&gt;让我们回到计算&lt;code&gt;水&lt;/code&gt;类型神奇宝贝的百分比：&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：850px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/promql-vector-matching/promql-vector-matching-on-filter.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/blog/promql-vector-matching/promql-vector-matching-on-filter.png&#34;data-srcset=&#34;/media/blog/promql-vector-matching/promql-vector-matching- on-filter.png?w=320 320w, /media/blog/promql-vector-matching/promql-vector-matching-on-filter.png?w=550 550w，/media/blog/promql-vector-matching/promql-vector-matching-on-filter.png ?w=750 750w, /media/blog/promql-vector-matching/promql-vector-matching-on-filter.png?w=900 900w，/media/blog/promql-vector-matching/promql-vector-matching-on-filter.png ?w=1040 1040w, /media/blog/promql-vector-matching/promql-vector-matching-on-filter.png?w=1240 1240w，/media/blog/promql-vector-matching/promql-vector-matching-on-filter.png ?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;使用 on 关键字的 PromQL 查询的屏幕截图。&#34;width=&#34;850&#34;height=&#34;380&#34;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/promql-vector-matching/promql-vector-matching-on-filter.png”&#xA;alt=&#34;使用 on 关键字的 PromQL 查询的屏幕截图。&#34;width=&#34;850&#34;height=&#34;380&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;如你所见，我们告诉 Prometheus 匹配空标签集，因为公共标签集是空的。此外，由于左侧的一个向量仅与右侧的一个向量匹配，因此我们进行一对一匹配，并且 &lt;code&gt;on&lt;/code&gt; 关键字就足够了。&lt;/p&gt;&#xA;&lt;p&gt;但是当我们想要将左侧的多个向量与右侧的一个向量匹配时该怎么办呢？正如您所看到的，我们有一个错误：&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：854px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/promql-vector-matching/promql-vector-matching-on-filter-no-date.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/blog/promql-vector-matching/promql-vector-matching-on-filter-no-date.png&#34;data-srcset=&#34;/media/blog/promql-vector-matching/promql-矢量匹配过滤器无日期.png?w=320 320w, /media/blog/promql-向量匹配/promql-向量匹配-on-filter-no-date.png?w=550 550w，/media/blog/promql-向量匹配/promql-向量匹配-on -filter-no-date.png?w=750 750w, /media/blog/promql-向量匹配/promql-向量匹配-on-filter-no-date.png?w=900 900w，/media/blog/promql-向量匹配/promql-向量匹配-on -filter-no-date.png?w=1040 1040w, /media/blog/promql-向量匹配/promql-向量匹配-on-filter-no-date.png?w=1240 1240w，/media/blog/promql-向量匹配/promql-向量匹配-on -filter-no-date.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;返回无数据响应的 PromQL 查询的屏幕截图。&#34;width=&#34;854&#34;height=&#34;498&#34;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/promql-vector-matching/promql-vector-matching-on-filter-no-date.png”&#xA;alt=&#34;返回无数据响应的 PromQL 查询的屏幕截图。&#34;width=&#34;854&#34;height=&#34;498&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;左侧有许多向量与右侧的一个向量匹配 - 这是多对一匹配。在这种情况下，我们必须使用 &lt;code&gt;group_left&lt;/code&gt; 或 &lt;code&gt;group_right&lt;/code&gt; 关键字向 Prometheus 展示我们想要标签的哪一侧（哪一侧代表“许多”）。当我们想要保留左侧的标签时，我们使用 &lt;code&gt;group_left,&lt;/code&gt;；当我们想要保留右侧的标签时，我们使用 &lt;code&gt;group_right&lt;/code&gt;：&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：850px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/promql-vector-matching/promql-vector-group-left.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src =“/media/blog/promql-vector-matching/promql-vector-group-left.png”data-srcset =“/media/blog/promql-vector-matching/promql-vector-group-left.png” png?w=320 320w，/media/blog/promql-vector-matching/promql-vector-group-left.png?w=550 550w， /media/blog/promql-vector-matching/promql-vector-group-left.png?w=750 750w，/media/blog/promql-vector-matching/promql-vector-group-left.png?w=900 900w, /media/blog/promql-vector-matching/promql-vector-group-left.png?w=1040 1040w, /media/blog/promql-向量匹配/promql-vector-group-left.png?w=1240 1240w, /media/blog/promql-vector-matching/promql-vector-group-left.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;使用 group left 关键字的 PromQL 查询的屏幕截图。&#34;width=&#34;850&#34;height=&#34;505&#34;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/promql-vector-matching/promql-vector-group-left.png”&#xA;alt=&#34;使用 group left 关键字的 PromQL 查询的屏幕截图。&#34;width=&#34;850&#34;height=&#34;505&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;现在，我们有了所有神奇宝贝类型的百分比。经检查，&lt;code&gt;水&lt;/code&gt;类型百分比为&lt;code&gt;5.26%&lt;/code&gt;，正如我们之前计算的那样。&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;注意：&lt;a href=&#34;https://prometheus.io/docs/prometheus/latest/querying/operators/#group-modifiers&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Prometheus 文档&lt;/a&gt;提到&lt;code&gt;group_。&lt;/em&gt;&lt;/code&gt;是应该仔细考虑的高级用例。&lt;/em&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;wrapping-up&#34;&gt;总结&lt;/h2&gt;&#xA;&lt;p&gt;现在您知道向量之间的二元运算可能并不像看起来那么简单！如果您愿意，可以访问此 &lt;a href=&#34;https://github.com/Davenury/PromQL-Vector-Matching-Demo&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;GitHub 存储库&lt;/a&gt;尝试更多指标和示例 Pokémon 应用程序。&lt;/p&gt;&#xA;&lt;p&gt;您还可以在这些 &lt;a href=&#34;https://prometheus.io/docs/prometheus/latest/querying/basics/#time-series-selectors&#34; target=&#34;_blank&#34; rel=&#34; 中找到有关向量的更多信息noopener noreferrer&#34;&gt;PromQL docs，&lt;/a&gt;详细描述了算术运算的逻辑&lt;a href=&#34;https://prometheus.io/docs/prometheus/latest/querying/operators/#arithmetic-binary-operators&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;此处&lt;/a&gt;。我们在这篇文章中讨论的示例可以轻松地应用到现实生活场景中，例如 HTTP 响应时间或 HTTP 状态代码 - 例如，查找所有流量中错误状态代码的百分比。&lt;/p&gt;&#xA;&lt;p&gt;现在就这样，感谢您的关注！&lt;/p&gt;</description>
      <pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Open source at Grafana Labs: 2024 year in review】Grafana Labs 的开源：2024 年回顾</title>
      <link>https://grafana.com/blog/2024/12/11/open-source-at-grafana-labs-2024-year-in-review/</link>
      <description>【&lt;p&gt;Open source has always been the bedrock for everything we build here at Grafana Labs, going all the way back to Grafana creator Torkel Ödegaard&amp;rsquo;s &lt;a href=&#34;/story-of-grafana/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;first commit in December 2013&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Ten years after Grafana Labs was founded, open source continued to be our driving force as we worked to develop and evolve our core OSS tools and technologies in 2024. Combine that with our contributions to OpenTelemetry and Prometheus, as well as our new open source projects like &lt;a href=&#34;/docs/alloy/latest/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Alloy&lt;/a&gt;, and it all adds up to a whole lot of OSS goodness that aligns with our &amp;ldquo;big tent&amp;rdquo; philosophy.&lt;/p&gt;&#xA;&lt;p&gt;&amp;ldquo;We&amp;rsquo;re building bridges between different observability approaches, contributing upstream to multiple open source communities, and ensuring teams can use the right tool for the right job,&amp;rdquo; Grafana Labs CTO Tom Wilkie &lt;a href=&#34;https://www.businesswire.com/news/home/20241105009431/en/Grafana-Labs-Strengthens-Cloud-Native-Ecosystem-with-Major-OpenTelemetry-and-Kubernetes-Monitoring-Updates&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;recently said&lt;/a&gt;. &amp;ldquo;This is how open source should work – inclusive, interoperable, and focused on solving real user needs.&amp;rdquo;&lt;/p&gt;&#xA;&lt;p&gt;Let&amp;rsquo;s take a look at some of the biggest highlights from 2024.&lt;/p&gt;&#xA;&lt;h2 id=&#34;grafana-lgtm-stack-updates&#34;&gt;Grafana LGTM Stack updates&lt;/h2&gt;&#xA;&lt;h3 id=&#34;loki&#34;&gt;Loki&lt;/h3&gt;&#xA;&lt;p&gt;With the Grafana Loki 3.0 release, our &lt;a href=&#34;/docs/loki/latest/&#34;&gt;log aggregation system&lt;/a&gt; hit a major milestone in 2024. Six years in and more than 24,000 GitHub stars later, we continued to push the limits of what you can do with Loki.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Accelerated query results:&lt;/strong&gt; The 3.0 release introduced Bloom filters, an experimental feature intended to help return &amp;ldquo;needle in a haystack&amp;rdquo; queries faster. After working with early adopters and seeing how Bloom filters worked at scale, we decided to adjust our approach in Loki 3.3 to &lt;a href=&#34;/blog/2024/11/21/grafana-loki-3.3-release-faster-query-results-via-blooms-for-structured-metadata/#query-acceleration-via-bloom-filters&#34;&gt;leverage structured metadata&lt;/a&gt;, making it faster to build, download, and query.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Native OpenTelemetry support.&lt;/strong&gt; Say good-bye to the Loki Exporter! Now that Loki has &lt;a href=&#34;/blog/2024/04/09/grafana-loki-3.0-release-all-the-new-features/#native-opentelemetry-support&#34;&gt;native OTel support&lt;/a&gt;, you get a simpler ingestion pipeline by removing the Loki Exporter from the process. You also get a better querying experience since you can interact with all the OpenTelemetry attributes and log event metadata at query time without having to do any deserialization.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;grafana&#34;&gt;Grafana&lt;/h3&gt;&#xA;&lt;p&gt;Even with more than a decade of development and yet another major release under our belt, we still love to find new ways to improve Grafana for collecting, correlating, and visualizing data.&lt;/p&gt;&#xA;&lt;div&#xA;class=&#34;youtube-lazyload responsive-video&#34;&#xA;data-embed=&#34;8pPJ_X1xPfA&#34;&#xA;data-url=&#34;https://www.youtube.com/embed/8pPJ_X1xPfA?autoplay=1&amp;amp;rel=0&#34;&#xA;data-title=&#34;YouTube Video&#34;&#xA;&gt;&#xA;&lt;div class=&#34;play-button&#34;&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;Between the &lt;a href=&#34;/blog/2024/04/09/grafana-11-release-all-the-new-features/&#34;&gt;announcement of Grafana 11.0&lt;/a&gt; at GrafanaCON 2024 in April and the 11.4 release just this month, there were scads of upgrades big and small. Here are just a few of the noteworthy ones.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Custom visualizations.&lt;/strong&gt; Canvas panels have continued to grow in popularity since they were introduced in Grafana 9.x, and this year we made a number of improvements to them, including high-demand flowcharting features.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Easier management at scale.&lt;/strong&gt; With the addition of subfolders, user-based authentication with Azure Monitor, and an improved dashboard-to-PDF feature for large dashboards, we&amp;rsquo;re making it easier for large organizations to manage their environment and safely share insights across their orgs.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Scenes-powered dashboards.&lt;/strong&gt; The architecture for Grafana dashboards has &lt;a href=&#34;/blog/2024/10/31/grafana-dashboards-are-now-powered-by-scenes-big-changes-same-ui/&#34;&gt;migrated to the Scenes library&lt;/a&gt;, giving you more stable, dynamic, and flexible dashboards.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Text wrapping.&lt;/strong&gt; You asked for it, and we were happy to ship it. We’ve enabled text wrapping within cells for the&lt;a href=&#34;/docs/grafana/latest/panels-visualizations/visualizations/table/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt; table panel&lt;/a&gt;, making convoluted, long lines of text easier to read.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Grafana Alerting upgrades.&lt;/strong&gt; There has been a big focus on helping you simplify how you manage alerts in Grafana 11.x, from &lt;a href=&#34;/docs/grafana-cloud/whats-new/2024-03-15-keep-last-state-for-grafana-managed-alerting/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Keep last state&lt;/a&gt; to a holistic view of your alerts to alert templates. We also added role-based access control for notifications and &lt;a href=&#34;/blog/2024/12/03/grafana-alerting-save-time-and-effort-with-grafana-managed-recording-rules/&#34;&gt;Grafana-managed recording rules&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1342px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link captioned&#34;&#xA;href=&#34;/media/blog/oss-2024/Alerting-settings.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload mb-0&#34;&#xA;data-src=&#34;/media/blog/oss-2024/Alerting-settings.png&#34;data-srcset=&#34;/media/blog/oss-2024/Alerting-settings.png?w=320 320w, /media/blog/oss-2024/Alerting-settings.png?w=550 550w, /media/blog/oss-2024/Alerting-settings.png?w=750 750w, /media/blog/oss-2024/Alerting-settings.png?w=900 900w, /media/blog/oss-2024/Alerting-settings.png?w=1040 1040w, /media/blog/oss-2024/Alerting-settings.png?w=1240 1240w, /media/blog/oss-2024/Alerting-settings.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;The new Grafana Alerting settings page&#34;width=&#34;1342&#34;height=&#34;1106&#34;title=&#34;*The new Grafana Alerting settings page*&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/oss-2024/Alerting-settings.png&#34;&#xA;alt=&#34;The new Grafana Alerting settings page&#34;width=&#34;1342&#34;height=&#34;1106&#34;title=&#34;*The new Grafana Alerting settings page*&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;figcaption class=&#34;w-100p caption text-gray-13 &#34;&gt;&lt;em&gt;The new Grafana Alerting settings page&lt;/em&gt;&lt;/figcaption&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;h3 id=&#34;tempo&#34;&gt;Tempo&lt;/h3&gt;&#xA;&lt;p&gt;Grafana Tempo, our easy-to-use, and high-scale distributed tracing backend, had three minor releases in 2024, ushering in lots of performance and functionality improvements along the way.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;TraceQL metrics.&lt;/strong&gt; An experimental feature introduced in Tempo 2.4, &lt;a href=&#34;/docs/tempo/latest/operations/traceql-metrics/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;TraceQL metrics&lt;/a&gt; creates metrics from traces, much in the same way LogQL creates metrics from logs. Initially supporting the &lt;code&gt;rate()&lt;/code&gt; function, Tempo 2.5 added &lt;code&gt;quantile_over_time()&lt;/code&gt; and &lt;code&gt;histogram_over_time()&lt;/code&gt; so you can aggregate numerical values as well.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;More TraceQL features.&lt;/strong&gt; &lt;a href=&#34;/blog/2024/09/05/grafana-tempo-2.6-release-performance-improvements-and-new-traceql-features/#traceql-features&#34;&gt;Building on the vParquet4 backend&lt;/a&gt;, we&amp;rsquo;ve added support for querying events, span links, and arrays.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Better performance.&lt;/strong&gt; The Tempo 2.6 release included several &lt;a href=&#34;/docs/tempo/latest/release-notes/v2-6/?pg=blog&amp;amp;plcmt=body-txt#traceql-improvements&#34;&gt;performance improvements&lt;/a&gt; for TraceQL, and it also came with a notable reduction of memory usage due to polling improvements.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;gRPC streaming.&lt;/strong&gt; In Tempo 2.5 support for gRPC streaming was added to most Tempo HTTP endpoints including TraceQL search, tag name lookups, tag value lookups and TraceQL metrics.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1130px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link captioned&#34;&#xA;href=&#34;/media/blog/oss-2024/tempo-change.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload mb-0&#34;&#xA;data-src=&#34;/media/blog/oss-2024/tempo-change.png&#34;data-srcset=&#34;/media/blog/oss-2024/tempo-change.png?w=320 320w, /media/blog/oss-2024/tempo-change.png?w=550 550w, /media/blog/oss-2024/tempo-change.png?w=750 750w, /media/blog/oss-2024/tempo-change.png?w=900 900w, /media/blog/oss-2024/tempo-change.png?w=1040 1040w, /media/blog/oss-2024/tempo-change.png?w=1240 1240w, /media/blog/oss-2024/tempo-change.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A Grafana panel visualization of the memory usage reduction from polling improvements&#34;width=&#34;1130&#34;height=&#34;780&#34;title=&#34;*A Grafana panel visualization of the memory usage reduction from polling improvements*&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/oss-2024/tempo-change.png&#34;&#xA;alt=&#34;A Grafana panel visualization of the memory usage reduction from polling improvements&#34;width=&#34;1130&#34;height=&#34;780&#34;title=&#34;*A Grafana panel visualization of the memory usage reduction from polling improvements*&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;figcaption class=&#34;w-100p caption text-gray-13 &#34;&gt;&lt;em&gt;A Grafana panel visualization of the memory usage reduction from polling improvements&lt;/em&gt;&lt;/figcaption&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;h3 id=&#34;mimir&#34;&gt;Mimir&lt;/h3&gt;&#xA;&lt;p&gt;The four Grafana Mimir 2.1x minor releases represented another step forward for our Prometheus-compatible time series database for long-term storage:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;OTLP endpoint support.&lt;/strong&gt; By implementing native translation, we’ve improved OTLP ingestion performance significantly – cutting &lt;a href=&#34;/docs/mimir/latest/references/architecture/components/distributor/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;distributor&lt;/a&gt; memory usage by 30% and CPU usage by 8%.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;PromQL engine.&lt;/strong&gt; This experimental feature, currently a release candidate, decreases the peak memory consumption of Mimir’s querier component, so that queries over millions of time series no longer trigger out-of-memory errors or require users to massively over-resource their queriers.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Kafka-based ingest storage.&lt;/strong&gt; Kafka, the open source distributed event streaming system, is a critical tool for many large organizations. This &lt;a href=&#34;/docs/mimir/latest/configure/configuration-parameters/?pg=blog&amp;amp;plcmt=body-txt#ingest_storage&#34;&gt;experimental feature&lt;/a&gt; can help manage long-term costs associated with storing event streams.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Query scheduler routing optimization.&lt;/strong&gt; This update improves overall query execution latency, helping you get the answers you need faster.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;learn-more&#34;&gt;Learn more&lt;/h3&gt;&#xA;&lt;p&gt;You can check out our &lt;a href=&#34;/docs/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;documentation&lt;/a&gt; for details on all of the updates to the Grafana LGTM Stack and more, including valuable upgrades we&amp;rsquo;ve made to our other OSS projects such as &lt;a href=&#34;/docs/k6/latest/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana k6&lt;/a&gt; for performance testing and &lt;a href=&#34;/docs/pyroscope/latest/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Pyroscope&lt;/a&gt; for continuous profiling.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;h3 id=&#34;data-analysis-without-queries-explore-apps&#34;&gt;Data analysis without queries: Explore apps&lt;/h3&gt;&#xA;&lt;p&gt;The Explore apps suite, &lt;a href=&#34;/blog/2024/09/24/queryless-metrics-logs-traces-profiles/&#34;&gt;announced at ObservabilityCon 2024&lt;/a&gt;, provides an opinionated, intuitive, and queryless user experience for quickly answering questions about your metrics, logs, traces, and profiles through simple, point-and-click interactions. The suite of apps is designed for all users, whether you&amp;rsquo;re unfamiliar with querying languages or an expert just looking to simplify the process of finding the data you need.&lt;/p&gt;&#xA;&lt;p&gt;Available in Grafana OSS, Grafana Enterprise, and Grafana Cloud, the Explore apps include Explore Metrics, Explore Logs, Explore Traces, and Explore Profiles.&lt;/p&gt;&#xA;&lt;p&gt;Check out a &lt;a href=&#34;https://www.youtube.com/watch?v=YICcDk_ddC4&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;demo of how Explore apps work&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h2 id=&#34;introducing-grafana-alloy&#34;&gt;Introducing Grafana Alloy&lt;/h2&gt;&#xA;&lt;p&gt;The latest open source project from Grafana Labs, &lt;a href=&#34;/oss/alloy-opentelemetry-collector/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Alloy&lt;/a&gt; is our distribution of the OpenTelemetry Collector with built-in Prometheus pipelines and support for metrics, logs, traces, and profiles.&lt;/p&gt;&#xA;&lt;div&#xA;class=&#34;youtube-lazyload responsive-video&#34;&#xA;data-embed=&#34;aOnHS7qDgic&#34;&#xA;data-url=&#34;https://www.youtube.com/embed/aOnHS7qDgic?autoplay=1&amp;amp;rel=0&#34;&#xA;data-title=&#34;YouTube Video&#34;&#xA;&gt;&#xA;&lt;div class=&#34;play-button&#34;&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;Announced at &lt;a href=&#34;/blog/2024/04/09/grafana-alloy-opentelemetry-collector-with-prometheus-pipelines/?pg=oss-alloy&amp;amp;plcmt=hero-btn-2&#34;&gt;GrafanaCon 2024&lt;/a&gt;, Alloy uses the same components, code, and concepts that were first introduced in Grafana Agent Flow. Since then, we&amp;rsquo;ve rolled out new features, including &lt;a href=&#34;/docs/alloy/v1.3/troubleshoot/debug/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;live debugging&lt;/a&gt;, which supports real-time monitoring of data pipelines and more efficient troubleshooting.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Grafana Agent, the predecessor to Alloy, is expected to reach end-of-life phase on Nov. 1, 2025. For more information, read our &lt;a href=&#34;/blog/2024/04/09/grafana-agent-to-grafana-alloy-opentelemetry-collector-faq/&#34;&gt;FAQ blog&lt;/a&gt; about migration from Grafana Agent to Alloy.*&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h2 id=&#34;opentelemetry&#34;&gt;OpenTelemetry&lt;/h2&gt;&#xA;&lt;p&gt;OpenTelemetry stands out as one of the fastest growing open source projects in the cloud native arena, with 43% increase in code commits in GitHub and a 100% increase in search volume on Google in 2024 according to a &lt;a href=&#34;/opentelemetry-report/&#34;&gt;recent OpenTelemetry report&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Grafana Labs continues to be active in the OpenTelemetry community in an effort to help drive innovation and adoption. For example, in June, Grafana Labs engineers released &lt;a href=&#34;https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/receiver/datadogreceiver/README.md&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;new open source code&lt;/a&gt; that allows users to translate Datadog metric formats into native OTLP format. These metrics that are collected and translated by the OpenTelemetry Datadog receiver can be sent to any OpenTelemetry-compatible metrics system, whether it is Prometheus, Grafana Mimir, or another backend database. The receiver, marked as experimental, is available as both a Grafana Alloy and OpenTelemetry component.&lt;/p&gt;&#xA;&lt;p&gt;We&amp;rsquo;ve also worked to ensure our open source technology and tools can work seamlessly with OpenTelemetry:&lt;/p&gt;&#xA;&lt;h3 id=&#34;opentelemetry--metrics&#34;&gt;OpenTelemetry + metrics&lt;/h3&gt;&#xA;&lt;p&gt;In Grafana, Explore Metrics, which allows users to browse and analyze Prometheus-compatible metrics without writing PromQL queries, expanded to automatically handle OpenTelemetry metrics, eliminating the need for users to create separate queries for each system. This unified approach means users can access and visualize more types of metrics through a single, consistent interface regardless of whether the data is in Prometheus or OpenTelemetry format. This development represents Grafana Labs’ larger commitment to improving compatibility between OpenTelemetry and Prometheus while meeting users where they are no matter what formats they use.&lt;/p&gt;&#xA;&lt;h3 id=&#34;opentelemetry--profiles&#34;&gt;OpenTelemetry + profiles&lt;/h3&gt;&#xA;&lt;p&gt;This year, the OpenTelemetry community took significant steps towards establishing profiling as a &lt;a href=&#34;https://opentelemetry.io/blog/2024/profiling/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;core OTel signal&lt;/a&gt;. To align with those efforts, we rolled out experimental support for OpenTelemetry profiles in the Grafana Pyroscope 1.10.0 release last month.&lt;/p&gt;&#xA;&lt;h3 id=&#34;opentelemetry--ebpf&#34;&gt;OpenTelemetry + eBPF&lt;/h3&gt;&#xA;&lt;p&gt;In November 2023, we announced the&lt;a href=&#34;/blog/2023/11/14/grafana-beyla-1.0-release-zero-code-instrumentation-for-application-telemetry-using-ebpf/&#34;&gt; general availability of Grafana Beyla&lt;/a&gt;, our open source OpenTelemetry and Prometheus eBPF auto-instrumentation tool to help you easily get started with application observability. In the year since, we&amp;rsquo;ve been busy growing the community to help with important patches and other contributions, such as the &lt;a href=&#34;https://github.com/grafana/beyla/pull/642&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Beyla Helm chart&lt;/a&gt;. In fact, there is a 10:1 ratio of external contributors to Grafanistas contributing to Beyla today.&lt;/p&gt;&#xA;&lt;p&gt;Since our 1.0 release, which tracked the HTTP and gRPC protocols, we’ve added support for HTTP2, SQL, Redis, and Kafka. We also started tracking network and connection metrics, which allows users to build solutions for service graphs.&lt;/p&gt;&#xA;&lt;p&gt;We worked hard to pick the right defaults, balancing ease of use with generating too many metrics. As a result of all this work, we saw the full&lt;a href=&#34;/events/observabilitycon/2024/opentelemetry-grafana-alloy-beyla-demo-of-instrumentation-ingestion/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt; OpenTelemetry Demo instrumented with a single Beyla daemonset deployment&lt;/a&gt; earlier this year. The one Beyla instance produced service-level application metrics for all the different technologies and protocols used to implement the services in the&lt;a href=&#34;https://opentelemetry.io/ecosystem/demo/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt; OpenTelemetry Demo&lt;/a&gt;.services, while keeping the bare-bones uninstrumented applications talking to each other.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1999px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link captioned&#34;&#xA;href=&#34;/media/blog/oss-2024/beyla-demo.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload mb-0&#34;&#xA;data-src=&#34;/media/blog/oss-2024/beyla-demo.png&#34;data-srcset=&#34;/media/blog/oss-2024/beyla-demo.png?w=320 320w, /media/blog/oss-2024/beyla-demo.png?w=550 550w, /media/blog/oss-2024/beyla-demo.png?w=750 750w, /media/blog/oss-2024/beyla-demo.png?w=900 900w, /media/blog/oss-2024/beyla-demo.png?w=1040 1040w, /media/blog/oss-2024/beyla-demo.png?w=1240 1240w, /media/blog/oss-2024/beyla-demo.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;RED (rate, error, and duration) metrics, as well as service graph metrics, generated for the OpenTelemetry Demo Checkout service directly from Beyla&#34;width=&#34;1999&#34;height=&#34;1003&#34;title=&#34;*RED (rate, error, and duration) metrics, as well as service graph metrics, generated for the OpenTelemetry Demo Checkout service directly from Beyla*&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/oss-2024/beyla-demo.png&#34;&#xA;alt=&#34;RED (rate, error, and duration) metrics, as well as service graph metrics, generated for the OpenTelemetry Demo Checkout service directly from Beyla&#34;width=&#34;1999&#34;height=&#34;1003&#34;title=&#34;*RED (rate, error, and duration) metrics, as well as service graph metrics, generated for the OpenTelemetry Demo Checkout service directly from Beyla*&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;figcaption class=&#34;w-100p caption text-gray-13 &#34;&gt;&lt;em&gt;RED (rate, error, and duration) metrics, as well as service graph metrics, generated for the OpenTelemetry Demo Checkout service directly from Beyla&lt;/em&gt;&lt;/figcaption&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;h2 id=&#34;prometheus-30&#34;&gt;Prometheus 3.0&lt;/h2&gt;&#xA;&lt;p&gt;OpenTelemetry and Prometheus are staples of today&amp;rsquo;s observability landscape. In fact, according to our &lt;a href=&#34;/observability-survey/2024/?pg=blog&amp;amp;plcmt=body-txt#intro&#34;&gt;2024 Observability Survey&lt;/a&gt;, an overwhelming majority of industry practitioners are investing in Prometheus (89%) or OpenTelemetry (85%), and almost 40% are using both.&lt;/p&gt;&#xA;&lt;p&gt;Grafana Labs is deeply committed to both projects — and we are committed to making both projects work together. To that end, Grafana Labs is the No. 1 company contributor to Prometheus and a top 10 contributor to OpenTelemetry. Several Grafanistas even double as Prometheus maintainers, &lt;a href=&#34;/blog/2024/08/30/grafana-labs-at-promcon-prometheus-3.0-opentelemetry-native-histograms-and-more/&#34;&gt;helping to support the release of Prometheus 3.0&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;That 3.0 release marked a big step forward in Prometheus supporting OpenTelemetry, and it also mirrors our efforts to make our latest projects, Beyla and Alloy, support both projects from the outset.&lt;/p&gt;&#xA;&lt;p&gt;We look forward to working with the open source community even more in the new year!&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;We’d love to hear your thoughts on open source and the state of observability. Click the button below to take our annual Observability Survey today!&lt;/em&gt;&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper w-100p &#34;&#xA;style=&#34;max-width: 567px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;https://grafana.com/observability-survey/?pg=blog&amp;amp;plcmt=body-txt&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/survey-promo/take-the-survey.png&#34;data-srcset=&#34;/media/blog/survey-promo/take-the-survey.png?w=320 320w, /media/blog/survey-promo/take-the-survey.png?w=550 550w, /media/blog/survey-promo/take-the-survey.png?w=750 750w, /media/blog/survey-promo/take-the-survey.png?w=900 900w, /media/blog/survey-promo/take-the-survey.png?w=1040 1040w, /media/blog/survey-promo/take-the-survey.png?w=1240 1240w, /media/blog/survey-promo/take-the-survey.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;Link to the Observability Survey.&#34;width=&#34;567&#34;height=&#34;71&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/survey-promo/take-the-survey.png&#34;&#xA;alt=&#34;Link to the Observability Survey.&#34;width=&#34;567&#34;height=&#34;71&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;】&lt;p&gt;开源一直是我们在 Grafana Labs 构建的一切的基石，一直追溯到 Grafana 创建者 Torkel Ödegaard 的 &lt;a href=&#34;/story-of-grafana/?pg=blog&amp;plcmt=body-txt&#34; &gt;2013 年 12 月首次提交&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;Grafana Labs 成立十年后，开源仍然是我们的驱动力，我们致力于在 2024 年开发和发展我们的核心 OSS 工具和技术。将其与我们对 OpenTelemetry 和 Prometheus 的贡献以及我们的新像 &lt;a href=&#34;/docs/alloy/latest/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana Alloy&lt;/a&gt; 这样的开源项目，所有这些加起来就构成了一大堆 OSS善良符合我们的“大帐篷”理念。&lt;/p&gt;&#xA;&lt;p&gt;“我们正在不同的可观测性方法之间建立桥梁，为多个开源社区做出上游贡献，并确保团队能够使用正确的工具来完成正确的工作，”Grafana Labs 首席技术官 Tom Wilkie &lt;a href=&#34;https://www.businesswire.com/news/home/20241105009431/en/Grafana-Labs-Strengthens-Cloud-Native-Ecosystem-with-Major-OpenTelemetry-and-Kubernetes-Monitoring-Updates&#34; target=&#34; _blank&#34; rel=&#34;noopener noreferrer&#34;&gt;最近说过&lt;/a&gt;。 “这就是开源应该如何运作——包容、可互操作，并专注于解决真正的用户需求。”&lt;/p&gt;&#xA;&lt;p&gt;让我们来看看 2024 年的一些最大亮点。&lt;/p&gt;&#xA;&lt;h2 id=&#34;grafana-lgtm-stack-updates&#34;&gt;Grafana LGTM 堆栈更新&lt;/h2&gt;&#xA;&lt;h3 id=&#34;loki&#34;&gt;洛基&lt;/h3&gt;&#xA;&lt;p&gt;随着 Grafana Loki 3.0 的发布，我们的&lt;a href=&#34;/docs/loki/latest/&#34;&gt;日志聚合系统&lt;/a&gt;在 2024 年达到了一个重要的里程碑。六年过去了，在 GitHub 上获得了超过 24,000 颗星，我们不断突破 Loki 的极限。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;加速查询结果：&lt;/strong&gt;3.0 版本引入了 Bloom 过滤器，这是一项实验性功能，旨在帮助更快地返回“大海捞针”查询。在与早期采用者合作并了解布隆过滤器如何大规模工作后，我们决定将 Loki 3.3 中的方法调整为 &lt;a href=&#34;/blog/2024/11/21/grafana-loki-3.3-release-faster-query- results-via-blooms-for-structed-metadata/#query-acceleration-via-bloom-filters&#34;&gt;利用结构化元数据&lt;/a&gt;，加快构建、下载、并查询。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;原生 OpenTelemetry 支持。&lt;/strong&gt;向 Loki Exporter 说再见！现在 Loki 拥有&lt;a href=&#34;/blog/2024/04/09/grafana-loki-3.0-release-all-the-new-features/#native-opentelemetry-support&#34;&gt;原生 OTel 支持&lt;/a&gt;，通过从流程中删除 Loki Exporter，您可以获得更简单的摄取管道。您还可以获得更好的查询体验，因为您可以在查询时与所有 OpenTelemetry 属性和日志事件元数据进行交互，而无需进行任何反序列化。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;grafana&#34;&gt;格拉法纳&lt;/h3&gt;&#xA;&lt;p&gt;即使经过了十多年的发展，并且又发布了一个重大版本，我们仍然喜欢寻找新的方法来改进 Grafana 以进行收集、关联ng，以及可视化数据。&lt;/p&gt;&#xA;&lt;div&#xA;类 =“youtube-lazyload 响应视频”&#xA;数据嵌入=“8pPJ_X1xPfA”&#xA;data-url=&#34;https://www.youtube.com/embed/8pPJ_X1xPfA?autoplay=1&amp;rel=0&#34;&#xA;数据标题=“YouTube 视频”&#xA;&gt;&#xA;&lt;div class=&#34;play-button&#34;&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;在 4 月份的 GrafanaCON 2024 上&lt;a href=&#34;/blog/2024/04/09/grafana-11-release-all-the-new-features/&#34;&gt;Grafana 11.0 公告&lt;/a&gt;与11.4 本月刚刚发布，出现了大量大大小小的升级。以下只是其中一些值得注意的内容。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;自定义可视化。&lt;/strong&gt;自 Grafana 9.x 中引入以来，Canvas 面板不断流行，今年我们对其进行了多项改进，包括高要求的流程图功能。 &lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;更轻松地进行大规模管理。&lt;/strong&gt;通过添加子文件夹、使用 Azure Monitor 进行基于用户的身份验证以及针对大型仪表板改进的仪表板到 PDF 功能，我们使大型仪表板的管理变得更加容易组织管理其环境并在整个组织中安全地分享见解。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;场景驱动的仪表板。&lt;/strong&gt;Grafana 仪表板的架构具有&lt;a href=&#34;/blog/2024/10/31/grafana-dashboards-are-now-powered-by-scenes-big -changes-same-ui/&#34;&gt;迁移到场景库&lt;/a&gt;，为您提供更稳定、动态且灵活的仪表板。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;文本换行。&lt;/strong&gt;您提出要求，我们很乐意发货。我们为&lt;a href=&#34;/docs/grafana/latest/panels-visualizations/visualizations/table/?pg=blog&amp;plcmt=body-txt&#34;&gt;表格面板&lt;/a&gt;启用了单元格内的文本换行，长行文本更易于阅读。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Grafana 警报升级。&lt;/strong&gt;重点关注帮助您简化 Grafana 11.x 中的警报管理方式，来自 &lt;a href=&#34;/docs/grafana-cloud/whats-new /2024-03-15-keep-last-state-for-grafana-management-alerting/?pg=blog&amp;plcmt=body-txt&#34;&gt;保留最后状态&lt;/a&gt;以全面了解您的警报到警报模板。我们还为通知和 &lt;a href=&#34;/blog/2024/12/03/grafana-alerting-save-time-and-effort-with-grafana-management-recording-rules/&#34;&gt;Grafana 添加了基于角色的访问控制- 管理录制规则&lt;/a&gt;。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1342px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接标题”&#xA;href=&#34;/media/blog/oss-2024/Alerting-settings.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“lazyload mb-0”&#xA;data-src =“/media/blog/oss-2024/Alerting-settings.png”data-srcset =“/media/blog/oss-2024/Alerting-settings.png？w = 320 320w，/media/blog/ oss-2024/Alerting-settings.png?w=550 550w, /media/blog/oss-2024/Alerting-settings.png?w=750 750w, /media/blog/oss-2024/Alerting-settings.png?w=900 900w, /media/blog/oss-2024/Alerting -settings.png?w=1040 1040w, /media/blog/oss-2024/Alerting-settings.png?w=1240 1240w, /media/blog/oss-2024/Alerting-settings.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;新的 Grafana 警报设置页面&#34;width=&#34;1342&#34;height=&#34;1106&#34;title=&#34;*新的 Grafana 警报设置页面*&#34;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/oss-2024/Alerting-settings.png”&#xA;alt=&#34;新的 Grafana 警报设置页面&#34;width=&#34;1342&#34;height=&#34;1106&#34;title=&#34;*新的 Grafana 警报设置页面*&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;figcaption class=&#34;w-100p title text-gray-13 &#34;&gt;&lt;em&gt;新的 Grafana 警报设置页面&lt;/em&gt;&lt;/figcaption&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;h3 id=&#34;tempo&#34;&gt;节奏&lt;/h3&gt;&#xA;&lt;p&gt;Grafana Tempo 是我们易于使用的大规模分布式跟踪后端，于 2024 年发布了三个小版本，在此过程中带来了大量性能和功能改进。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;TraceQL 指标。&lt;/strong&gt;Tempo 2.4 中引入的一项实验性功能，&lt;a href=&#34;/docs/tempo/latest/operations/traceql-metrics/?pg=blog&amp;plcmt=body-txt&#34;&gt;TraceQL metrics&lt;/a&gt; 从跟踪中创建指标，这与 LogQL 从日志中创建指标的方式非常相似。 Tempo 2.5 最初支持 &lt;code&gt;rate()&lt;/code&gt; 函数，后来添加了 &lt;code&gt;quantile_over_time()&lt;/code&gt; 和 &lt;code&gt;histogram_over_time()&lt;/code&gt;，以便您也可以聚合数值。&lt;/code&gt;李&gt;&#xA;&lt;li&gt;&lt;strong&gt;更多 TraceQL 功能。&lt;/strong&gt; &lt;a href=&#34;/blog/2024/09/05/grafana-tempo-2.6-release-performance-improvements-and-new-traceql-features/#traceql -features&#34;&gt;在 vParquet4 后端的基础上构建&lt;/a&gt;，我们添加了对查询事件、跨度链接和数组的支持。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;性能更佳。&lt;/strong&gt;Tempo 2.6 版本包含多项&lt;a href=&#34;/docs/tempo/latest/release-notes/v2-6/?pg=blog&amp;plcmt=body-txt#traceql- TraceQL 的改进&#34;&gt;性能改进&lt;/a&gt;，并且由于轮询改进，内存使用量也显着减少。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;gRPC 流式传输。&lt;/strong&gt;在 Tempo 2.5 中，大多数 Tempo HTTP 端点都添加了对 gRPC 流式传输的支持，包括 TraceQL 搜索、标签名称查找、标签值查找和 TraceQL 指标。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1130px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接标题”&#xA;href=&#34;/media/blog/oss-2024/tempo-change.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“lazyload mb-0”&#xA;data-src =“/media/blog/oss-2024/tempo-change.png”data-srcset =“/media/blog/oss-2024/tempo-change.png？w = 320 320w，/media/blog/ oss-2024/tempo-change.png?w=550 550w, /media/blog/oss-2024/tempo-change.png?w=750 750w, /media/blog/oss-2024/tempo-change.png?w=900 900w, /media/blog/oss-2024/tempo -change.png?w=1040 1040w, /media/blog/oss-2024/tempo-change.png?w=1240 1240w, /media/blog/oss-2024/tempo-change.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;Grafana 面板可视化显示轮询改进带来的内存使用量减少&#34;width=&#34;1130&#34;height=&#34;780&#34;title=&#34;*Grafana 面板可视化显示轮询改进带来的内存使用量减少* ”/&gt;&#xA;&lt;诺斯克里普t&gt;&#xA;&lt;图片&#xA;src=&#34;/media/blog/oss-2024/tempo-change.png&#34;&#xA;alt=&#34;轮询改进带来的内存使用量减少的 Grafana 面板可视化&#34;width=&#34;1130&#34;height=&#34;780&#34;title=&#34;*轮询改进带来的内存使用量减少的 Grafana 面板可视化*&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;figcaption class=&#34;w-100p title text-gray-13 &#34;&gt;&lt;em&gt;轮询改进带来的内存使用量减少的 Grafana 面板可视化&lt;/em&gt;&lt;/figcaption&gt;&lt;/a &gt;&lt;/图&gt;&#xA;&lt;h3 id=&#34;mimir&#34;&gt;米米尔&lt;/h3&gt;&#xA;&lt;p&gt;四个 Grafana Mimir 2.1x 小版本代表了我们与 Prometheus 兼容的时间序列数据库在长期存储方面又向前迈出了一步：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;OTLP 端点支持。&lt;/strong&gt;通过实施原生翻译，我们显着提高了 OTLP 摄取性能 - 减少了 &lt;a href=&#34;/docs/mimir/latest/references/architecture/components/distributor/? pg=blog&amp;plcmt=body-txt&#34;&gt;分发器&lt;/a&gt;内存使用率降低 30%，CPU 使用率降低 8%。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;PromQL 引擎。&lt;/strong&gt;此实验性功能目前是候选版本，可降低 Mimir 查询器组件的峰值内存消耗，以便数百万个时间序列的查询不再触发内存不足错误或要求用户为他们的查询器提供大量的资源。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;基于 Kafka 的摄取存储。&lt;/strong&gt;Kafka 是开源分布式事件流系统，是许多大型组织的关键工具。此&lt;a href=&#34;/docs/mimir/latest/configure/configuration-parameters/?pg=blog&amp;plcmt=body-txt#ingest_storage&#34;&gt;实验功能&lt;/a&gt;可以帮助管理与存储事件流相关的长期成本。 &lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;查询调度程序路由优化。&lt;/strong&gt;此更新改善了整体查询执行延迟，帮助您更快地获得所需的答案。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;learn-more&#34;&gt;了解更多&lt;/h3&gt;&#xA;&lt;p&gt;您可以查看我们的&lt;a href=&#34;/docs/?pg=blog&amp;plcmt=body-txt&#34;&gt;文档&lt;/a&gt;，了解有关 Grafana LGTM Stack 等所有更新的详细信息，包括我们的宝贵升级我们已经对我们的其他 OSS 项目（例如 &lt;a href=&#34;/docs/k6/latest/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana k6&lt;/a&gt;）进行了性能测试，并&lt;a href=&#34;/docs/pyrscope/latest/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana Pyrscope&lt;/a&gt; 用于连续分析。&lt;/p&gt;&#xA;&lt;块引用&gt;&#xA;&lt;h3 id=&#34;data-analysis-without-queries-explore-apps&#34;&gt;无需查询的数据分析：探索应用&lt;/h3&gt;&#xA;&lt;p&gt;Explore 应用套件&lt;a href=&#34;/blog/2024/09/24/queryless-metrics-logs-traces-profiles/&#34;&gt;在 ObservabilityCon 2024 上发布&lt;/a&gt;，提供了固执己见、直观且无查询的用户体验，通过简单的点击式交互快速回答有关指标、日志、跟踪和配置文件的问题。该应用程序套件专为所有用户设计，无论您是不熟悉查询语言，还是只是希望简化查找所需数据的过程的专家。&lt;/p&gt;&#xA;&lt;p&gt;探索应用程序可在 Grafana OSS、Grafana Enterprise 和 Grafana Cloud 中使用包括探索指标、探索日志、探索跟踪和探索配置文件。&lt;/p&gt;&#xA;&lt;p&gt;查看&lt;a href=&#34;https://www.youtube.com/watch?v=YICcDk_ddC4&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;探索应用如何工作的演示&lt;​​/a&gt;。 &lt;/p&gt;&#xA;&lt;/块引用&gt;&#xA;&lt;h2 id=&#34;introducing-grafana-alloy&#34;&gt;Grafana 合金简介&lt;/h2&gt;&#xA;&lt;p&gt;Grafana Labs 的最新开源项目 &lt;a href=&#34;/oss/alloy-opentelemetry-collector/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana Alloy&lt;/a&gt; 是我们的 OpenTelemetry Collector 发行版内置 Prometheus 管道以及对指标、日志、跟踪和配置文件的支持。&lt;/p&gt;&#xA;&lt;div&#xA;类 =“youtube-lazyload 响应视频”&#xA;数据嵌入=“aOnHS7qDgic”&#xA;data-url=&#34;https://www.youtube.com/embed/aOnHS7qDgic?autoplay=1&amp;rel=0&#34;&#xA;数据标题=“YouTube 视频”&#xA;&gt;&#xA;&lt;div class=&#34;play-button&#34;&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;在 &lt;a href=&#34;/blog/2024/04/09/grafana-alloy-opentelemetry-collector-with-prometheus-pipelines/?pg=oss-alloy&amp;plcmt=hero-btn-2&#34;&gt;GrafanaCon 2024 上宣布&lt; /a&gt;，Alloy 使用与 Grafana Agent Flow 中首次引入的相同组件、代码和概念。从那时起，我们推出了新功能，包括&lt;a href=&#34;/docs/alloy/v1.3/troubleshoot/debug/?pg=blog&amp;plcmt=body-txt&#34;&gt;实时调试&lt;/a&gt;，它支持实时调试- 数据管道的实时监控和更高效的故障排除。&lt;/p&gt;&#xA;&lt;块引用&gt;&#xA;&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;：Alloy 的前身 Grafana Agent 预计将于 2025 年 11 月 1 日达到生命周期结束阶段。有关更多信息，请阅读我们的 &lt;a href=&#34;/blog /2024/04/09/grafana-agent-to-grafana-alloy-opentelemetry-collector-faq/&#34;&gt;有关从 Grafana Agent 迁移到 Alloy 的常见问题解答博客&lt;/a&gt;。*&lt;/p&gt;&#xA;&lt;/块引用&gt;&#xA;&lt;h2 id=&#34;opentelemetry&#34;&gt;OpenTelemetry&lt;/h2​​&gt;&#xA;&lt;p&gt;OpenTelemetry 脱颖而出，成为云原生领域增长最快的开源项目之一，根据 &lt;a href=&#34; 的数据，到 2024 年，GitHub 上的代码提交量将增加 43%，Google 上的搜索量将增加 100% /opentelemetry-report/&#34;&gt;最近的 OpenTelemetry 报告&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;Grafana Labs 继续积极参与 OpenTelemetry 社区，努力帮助推动创新和采用。例如，6 月份，Grafana Labs 工程师发布了 &lt;a href=&#34;https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/receiver/datadogreceiver/README.md&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;新的开源代码&lt;/a&gt;，允许用户将 Datadog 指标格式转换为本机 OTLP 格式。由 OpenTelemetry Datadog 接收器收集和转换的这些指标可以发送到任何 OpenTelemetry 兼容的指标系统，无论是 Prometheus、Grafana Mimir 还是其他后端数据库。该接收器标记为实验性的，可作为 Grafana Alloy 和 OpenTelemetry 组件使用。&lt;/p&gt;&#xA;&lt;p&gt;我们还努力确保我们的开源技术和工具能够与 OpenTelemetry 无缝协作：&lt;/p&gt;&#xA;&lt;h3 id=&#34;opentelemetry--metrics&#34;&gt;OpenTelemetry + 指标&lt;/h3&gt;&#xA;&lt;p&gt;在 Grafana 中，探索指标，允许用户浏览和分析yze Prometheus 兼容指标，无需编写 PromQL 查询，扩展为自动处理 OpenTelemetry 指标，无需用户为每个系统创建单独的查询。这种统一的方法意味着用户可以通过单个一致的界面访问和可视化更多类型的指标，无论数据是 Prometheus 还是 OpenTelemetry 格式。这一开发代表了 Grafana Labs 的更大承诺，即提高 OpenTelemetry 和 Prometheus 之间的兼容性，同时满足用户的需求，无论他们使用什么格式。&lt;/p&gt;&#xA;&lt;h3 id=&#34;opentelemetry--profiles&#34;&gt;OpenTelemetry + 配置文件&lt;/h3&gt;&#xA;&lt;p&gt;今年，OpenTelemetry 社区采取了重大步骤，将分析作为&lt;a href=&#34;https://opentelemetry.io/blog/2024/profiling/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;核心OTel信号&lt;/a&gt;。为了配合这些努力，我们在上个月发布的 Grafana Pyrscope 1.10.0 中推出了对 OpenTelemetry 配置文件的实验支持。&lt;/p&gt;&#xA;&lt;h3 id=&#34;opentelemetry--ebpf&#34;&gt;OpenTelemetry + eBPF&lt;/h3&gt;&#xA;&lt;p&gt;2023 年 11 月，我们宣布了&lt;a href=&#34;/blog/2023/11/14/grafana-beyla-1.0-release-zero-code-instrumentation-for-application-telemetry-using-ebpf/&#34;&gt; Grafana Beyla 正式上市&lt;/a&gt;，这是我们的开源 OpenTelemetry 和 Prometheus eBPF 自动检测工具，可帮助您轻松开始应用程序可观察性。从那以后的一年里，我们一直忙于发展社区，以帮助完成重要补丁和其他贡献，例如 &lt;a href=&#34;https://github.com/grafana/beyla/pull/642&#34; target=&#34;_blank “ rel=&#34;noopener noreferrer&#34;&gt;Beyla Helm 图表&lt;/a&gt;。事实上，今天为 Beyla 做出贡献的外部贡献者与 Grafanista 的比例为 10:1。&lt;/p&gt;&#xA;&lt;p&gt;自我们的 1.0 版本（跟踪 HTTP 和 gRPC 协议）以来，我们添加了对 HTTP2、SQL、Redis 和 Kafka 的支持。我们还开始跟踪网络和连接指标，这允许用户构建服务图解决方案。&lt;/p&gt;&#xA;&lt;p&gt;我们努力选择正确的默认值，在易用性与生成过多指标之间取得平衡。经过所有这些工作，我们看到了完整的&lt;a href=&#34;/events/observabilitycon/2024/opentelemetry-grafana-alloy-beyla-demo-of-instrumentation-ingestion/?pg=blog&amp;plcmt=body-txt&#34;&gt;今年早些时候，OpenTelemetry 演示使用了单个 Beyla 守护程序集部署&lt;/a&gt;。一个 Beyla 实例为用于实现 &lt;a href=&#34;https://opentelemetry.io/ecosystem/demo/&#34; target=&#34;_blank&#34; rel=&#34; 中的服务的所有不同技术和协议生成了服务级别应用程序指标noopener noreferrer&#34;&gt;OpenTelemetry Demo&lt;/a&gt;.services，同时保持未经检测的裸机应用程序相互通信。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1999px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接标题”&#xA;href=&#34;/media/blog/oss-2024/beyla-demo.png&#34;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“lazyload mb-0”&#xA;data-src=&#34;/media/blog/oss-2024/beyla-demo.png&#34;data-srcset=&#34;/media/blog/oss-2024/beyla-demo.png?w=320 320w，/media/blog/ oss-2024/beyla-demo.png?w=550 550w, /media/blog/oss-2024/beyla-demo.png?w=750 750w, /media/blog/oss-2024/beyla-demo.png?w=900 900w, /media/blog/oss-2024/beyla -demo.png?w=1040 1040w, /media/blog/oss-2024/beyla-demo.png?w=1240 1240w, /media/blog/oss-2024/beyla-demo.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;RED（速率、错误和持续时间）指标以及服务图指标，直接从 Beyla&#34;width=&#34;1999&#34;height=&#34;1003&#34;title 为 OpenTelemetry 演示 Checkout 服务生成=&#34;*RED（速率、错误和持续时间）指标以及服务图指标，直接从 Beyla 为 OpenTelemetry 演示 Checkout 服务生成*&#34;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src=&#34;/media/blog/oss-2024/beyla-demo.png&#34;&#xA;alt=&#34;RED（速率、错误和持续时间）指标以及服务图指标，直接从 Beyla 为 OpenTelemetry 演示 Checkout 服务生成&#34;width=&#34;1999&#34;height=&#34;1003&#34;title=&#34;*RED（速率、错误和持续时间）指标以及服务图指标，直接从 Beyla*&#34;/&gt; 为 OpenTelemetry 演示 Checkout 服务生成&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;figcaption class=&#34;w-100p title text-gray-13 &#34;&gt;&lt;em&gt;为 OpenTelemetry 演示生成的红色（速率、错误和持续时间）指标以及服务图指标直接从 Beyla 结帐服务&lt;/em&gt;&lt;/figcaption&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;h2 id=&#34;prometheus-30&#34;&gt;普罗米修斯 3.0&lt;/h2&gt;&#xA;&lt;p&gt;OpenTelemetry 和 Prometheus 是当今可观测性领域的主要内容。事实上，根据我们的&lt;a href=&#34;/observability-survey/2024/?pg=blog&amp;plcmt=body-txt#intro&#34;&gt;2024 年可观测性调查&lt;/a&gt;，绝大多数行业从业者都在投资 Prometheus (89 %) 或 OpenTelemetry (85%)，近 40% 的人同时使用两者。&lt;/p&gt;&#xA;&lt;p&gt;Grafana Labs 坚定地致力于这两个项目，并且我们致力于让这两个项目协同工作。为此，Grafana Labs 是 Prometheus 排名第一的公司贡献者，也是 OpenTelemetry 的前 10 名贡献者。一些 Grafanista 甚至兼任 Prometheus 维护者，&lt;a href=&#34;/blog/2024/08/30/grafana-labs-at-promcon-prometheus-3.0-opentelemetry-native-histograms-and-more/&#34;&gt;帮助支持Prometheus 3.0 发布&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;该 3.0 版本标志着 Prometheus 在支持 OpenTelemetry 方面向前迈出了一大步，它也反映了我们为使我们的最新项目 Beyla 和 Alloy 从一开始就支持这两个项目所做的努力。&lt;/p&gt;&#xA;&lt;p&gt;我们期待在新的一年里与开源社区更多地合作！&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;我们很想听听您对开源和可观察性状态的想法。单击下面的按钮立即参加我们的年度可观察性调查！&lt;/em&gt;&lt;/p&gt;&#xA;&lt;图&#xA;类=“图形包装器w-100p”&#xA;样式=“最大宽度：567px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接”&#xA;href=“ht”tps://grafana.com/observability-survey/?pg=blog&amp;plcmt=body-txt&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/blog/survey-promo/take-the-survey.png&#34;data-srcset=&#34;/media/blog/survey-promo/take-the-survey.png?w=320 320w, /媒体/博客/survey-promo/take-the-survey.png?w=550 550w, /media/blog/survey-promo/take-the-survey.png?w=750 750w, /media/blog/survey-promo/take-the-survey.png?w=900 900w, /media/blog/survey -promo/take-the-survey.png?w=1040 1040w, /media/blog/survey-promo/take-the-survey.png?w=1240 1240w, /media/blog/survey-promo/take-the-survey.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;可观测性调查链接。&#34;width=&#34;567&#34;height=&#34;71&#34;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/survey-promo/take-the-survey.png”&#xA;alt=&#34;可观测性调查的链接。&#34;width=&#34;567&#34;height=&#34;71&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;</description>
      <pubDate>Wed, 11 Dec 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Grafana Cloud in 2024: Year in review】2024 年 Grafana 云：年度回顾</title>
      <link>https://grafana.com/blog/2024/12/10/grafana-cloud-in-2024-year-in-review/</link>
      <description>【&lt;p&gt;Throughout 2024, we made a ton of updates to &lt;a href=&#34;/products/cloud/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt;, our fully managed, cloud-hosted observability platform powered by the Grafana LGTM (&lt;a href=&#34;/oss/loki/&#34;&gt;Loki&lt;/a&gt; for logs,&lt;a href=&#34;/oss/grafana?pg=blog&amp;amp;plcmt=body-txt&#34;&gt; Grafana&lt;/a&gt; for visualization,&lt;a href=&#34;/oss/tempo/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt; Tempo&lt;/a&gt; for traces,&lt;a href=&#34;/oss/mimir/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt; Mimir&lt;/a&gt; for metrics) Stack. And, looking back, most of those updates were made with the same three goals in mind: to make Grafana Cloud more efficient, more intelligent, and easier to use, including for those just starting out on their observability journey.&lt;/p&gt;&#xA;&lt;p&gt;“Grafana Cloud and the LGTM Stack have really appealed to the early adopters — to the kinds of people who want to get their hands dirty, learn the query languages, and build their own dashboards,” said Tom Wilkie, CTO of Grafana Labs, at &lt;a href=&#34;/events/observabilitycon/2024/keynote/&#34;&gt;ObservabilityCON 2024&lt;/a&gt;. “We grew with the rise of observability and with all of these practitioners learning how to build things and get value out of these tools. But what we found over the past few years is that we&amp;rsquo;ve been appealing more to a broader, more mainstream audience.”&lt;/p&gt;&#xA;&lt;p&gt;In this post, we recap some of the big updates we’ve made to Grafana Cloud this year, and how they can help advance, or kickstart, your team’s observability strategy.&lt;/p&gt;&#xA;&lt;h2 id=&#34;extending-adaptive-telemetry-to-logs--and-beyond&#34;&gt;Extending adaptive telemetry to logs — and beyond&lt;/h2&gt;&#xA;&lt;p&gt;In 2023, &lt;a href=&#34;/blog/2023/05/09/adaptive-metrics-grafana-cloud-announcement/&#34;&gt;we introduced Adaptive Metrics&lt;/a&gt;, a Grafana Cloud feature that enables teams to aggregate unused and partially used metrics into lower cardinality versions of themselves to reduce observability costs.&lt;/p&gt;&#xA;&lt;p&gt;Since then, &lt;a href=&#34;/blog/2024/08/12/why-companies-choose-adaptive-metrics-and-how-they-save-time-and-a-lot-of-money/&#34;&gt;Adaptive Metrics has delivered&lt;/a&gt; a 35% reduction in metrics costs, on average, for more than 1,200 organizations — a figure that speaks to how impactful the feature can be, in terms of benefitting an organization’s bottom line.&lt;/p&gt;&#xA;&lt;p&gt;Building on that momentum this year, we &lt;a href=&#34;/blog/2024/09/24/introducing-adaptive-logs/&#34;&gt;introduced Adaptive Logs&lt;/a&gt;. Now generally available in all Grafana Cloud tiers, Adaptive Logs identifies commonly ingested log patterns and creates a set of customized sampling recommendations based on how frequently those patterns are queried. The end result? You can reduce the volume of unnecessary logs to lower your observability costs.&lt;/p&gt;&#xA;&lt;div&#xA;class=&#34;youtube-lazyload responsive-video&#34;&#xA;data-embed=&#34;ltkqkbY6Jao&#34;&#xA;data-url=&#34;https://www.youtube.com/embed/ltkqkbY6Jao?autoplay=1&amp;amp;rel=0&#34;&#xA;data-title=&#34;YouTube Video&#34;&#xA;&gt;&#xA;&lt;div class=&#34;play-button&#34;&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;Through our &lt;a href=&#34;/blog/2024/09/24/grafana-labs-acquires-tailctrl/&#34;&gt;acquisition of TailCtrl&lt;/a&gt;, an early-stage company specializing in adaptive trace sampling, we’ve also started to accelerate our development of Adaptive Traces. The move represents our continued efforts to extend the adaptive telemetry concept across the LGTM Stack, so you can more easily and cost-effectively analyze observability data at scale.&lt;/p&gt;&#xA;&lt;h2 id=&#34;simplified-data-analysis-with-the-explore-apps-suite&#34;&gt;Simplified data analysis with the Explore apps suite&lt;/h2&gt;&#xA;&lt;p&gt;In September, we announced public previews of &lt;a href=&#34;/docs/grafana-cloud/visualizations/simplified-exploration/traces/&#34;&gt;Explore Traces&lt;/a&gt; and &lt;a href=&#34;/docs/grafana-cloud/visualizations/simplified-exploration/profiles/&#34;&gt;Explore Profiles&lt;/a&gt;, which joined &lt;a href=&#34;/docs/grafana/latest/explore/explore-metrics/&#34;&gt;Explore Metrics&lt;/a&gt; and &lt;a href=&#34;/docs/grafana-cloud/visualizations/simplified-exploration/logs/&#34;&gt;Explore Logs&lt;/a&gt; — now generally available — to create a full suite of Explore apps for Grafana and Grafana Cloud.&lt;/p&gt;&#xA;&lt;p&gt;These apps streamline data exploration and analysis through intuitive, point-and-click UIs, enabling you to drill down and visualize data without having to know query languages like PromQL, LogQL, or TraceQL. Together, &lt;a href=&#34;/blog/2024/10/22/from-multi-line-queries-to-no-code-investigations-meeting-grafana-users-where-they-are/&#34;&gt;the Explore apps ensure that everyone&lt;/a&gt; — from beginners to experts — can get value out of their telemetry data and realize the full potential of observability.&lt;/p&gt;&#xA;&lt;p&gt;With the release of our Explore apps for all four pillars of observability, users can now &lt;a href=&#34;/blog/2024/10/22/from-multi-line-queries-to-no-code-investigations-meeting-grafana-users-where-they-are/&#34;&gt;choose from three different options&lt;/a&gt; in Grafana Cloud to help them get insights from telemetry stored in Prometheus (or Mimir), Loki, Tempo, or Pyroscope:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;Code&lt;/strong&gt;: Use query languages like PromQL, LogQL, and TraceQL.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Low code&lt;/strong&gt;: Use &lt;a href=&#34;/docs/grafana/latest/datasources/prometheus/query-editor/?pg=blog&amp;amp;plcmt=body-txt#builder-mode&#34;&gt;builder mode&lt;/a&gt;, which provides more of a visual programming experience.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;No code&lt;/strong&gt;: Use the Explore apps suite to access screens that are already pre-populated with graphs.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;div&#xA;class=&#34;youtube-lazyload responsive-video&#34;&#xA;data-embed=&#34;YICcDk_ddC4&#34;&#xA;data-url=&#34;https://www.youtube.com/embed/YICcDk_ddC4?autoplay=1&amp;amp;rel=0&#34;&#xA;data-title=&#34;YouTube Video&#34;&#xA;&gt;&#xA;&lt;div class=&#34;play-button&#34;&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;h2 id=&#34;enhancements-to-synthetic-monitoring-and-application-observability&#34;&gt;Enhancements to Synthetic Monitoring and Application Observability&lt;/h2&gt;&#xA;&lt;h3 id=&#34;synthetic-monitoring&#34;&gt;Synthetic Monitoring&lt;/h3&gt;&#xA;&lt;p&gt;In 2024, we rolled out &lt;a href=&#34;/blog/2024/05/01/grafana-cloud-synthetic-monitoring-all-the-latest-features/&#34;&gt;a revamped version of Grafana Cloud Synthetic Monitoring&lt;/a&gt; to help you simulate even the most complex transactions and ensure the best possible end-user experience.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1504px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/synthetic-monitoring-updates-2024/synthetic-monitoring-updates_dashboard-screenshot.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/synthetic-monitoring-updates-2024/synthetic-monitoring-updates_dashboard-screenshot.png&#34;data-srcset=&#34;/media/blog/synthetic-monitoring-updates-2024/synthetic-monitoring-updates_dashboard-screenshot.png?w=320 320w, /media/blog/synthetic-monitoring-updates-2024/synthetic-monitoring-updates_dashboard-screenshot.png?w=550 550w, /media/blog/synthetic-monitoring-updates-2024/synthetic-monitoring-updates_dashboard-screenshot.png?w=750 750w, /media/blog/synthetic-monitoring-updates-2024/synthetic-monitoring-updates_dashboard-screenshot.png?w=900 900w, /media/blog/synthetic-monitoring-updates-2024/synthetic-monitoring-updates_dashboard-screenshot.png?w=1040 1040w, /media/blog/synthetic-monitoring-updates-2024/synthetic-monitoring-updates_dashboard-screenshot.png?w=1240 1240w, /media/blog/synthetic-monitoring-updates-2024/synthetic-monitoring-updates_dashboard-screenshot.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A screenshot of the Synthetic Monitoring home page.&#34;width=&#34;1504&#34;height=&#34;1020&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/synthetic-monitoring-updates-2024/synthetic-monitoring-updates_dashboard-screenshot.png&#34;&#xA;alt=&#34;A screenshot of the Synthetic Monitoring home page.&#34;width=&#34;1504&#34;height=&#34;1020&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;Powered by Grafana k6, Synthetic Monitoring now includes two new check types — multiHTTP and k6 scripted checks — to support more complex testing scenarios. We also introduced &lt;a href=&#34;/docs/grafana-cloud/testing/synthetic-monitoring/get-started/create-a-k6-browser-check/&#34;&gt;k6 browser checks&lt;/a&gt;, now in public preview, which let you collect frontend &lt;a href=&#34;https://developers.google.com/search/docs/appearance/core-web-vitals&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Web Vitals metrics&lt;/a&gt;, capture custom performance metrics, and perform user actions like clicking buttons or completing forms.&lt;/p&gt;&#xA;&lt;h3 id=&#34;application-observability&#34;&gt;Application Observability&lt;/h3&gt;&#xA;&lt;p&gt;We also continued to evolve &lt;a href=&#34;/products/cloud/application-observability/&#34;&gt;Grafana Cloud Application Observability&lt;/a&gt;, our opinionated, out-of-the-box solution designed to improve the reliability of modern applications. Featuring native support for both OpenTelemetry and Prometheus, Application Observability helps developers and SREs seamlessly unify application and infrastructure insights for faster root cause analysis.&lt;/p&gt;&#xA;&lt;p&gt;Some of the key additions we made to Application Observability this year include:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;/docs/grafana-cloud/monitor-applications/application-observability/manual/service/#time-frame-comparison&#34;&gt;Time frame comparison&lt;/a&gt; to analyze service performance over time&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;/docs/grafana-cloud/monitor-applications/application-observability/manual/automatic-baseline/&#34;&gt;Automatic baseline&lt;/a&gt; to compare RED metrics for services and operations against historic upper and lower thresholds.&lt;/li&gt;&#xA;&lt;li&gt;The &lt;a href=&#34;/docs/grafana-cloud/monitor-applications/application-observability/manual/group-filter/?pg=application-observability&amp;amp;plcmt=hero-btn-2#filter-by&#34;&gt;filter-by feature&lt;/a&gt; to manage which data is visible based on attribute values&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;/blog/2024/06/13/improved-anomaly-detection-and-faster-root-cause-analysis-the-latest-features-in-grafana-cloud-application-observability/#faster-root-cause-analysis-with-in-context-navigation&#34;&gt;In-context navigation&lt;/a&gt; for faster root cause analysis&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1024px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/app-observability-updates/application-observability-updates-incontext-nav.gif&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/app-observability-updates/application-observability-updates-incontext-nav.gif&#34;alt=&#34;A gif showing App Observability.&#34;width=&#34;1024&#34;height=&#34;541&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/app-observability-updates/application-observability-updates-incontext-nav.gif&#34;&#xA;alt=&#34;A gif showing App Observability.&#34;width=&#34;1024&#34;height=&#34;541&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;You can learn more in our technical docs for &lt;a href=&#34;/docs/grafana-cloud/testing/synthetic-monitoring/&#34;&gt;Synthetic Monitoring&lt;/a&gt; and &lt;a href=&#34;/docs/grafana-cloud/monitor-applications/application-observability/&#34;&gt;Application Observability&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;control-collectors-at-scale-with-fleet-management&#34;&gt;Control collectors at scale with Fleet Management&lt;/h2&gt;&#xA;&lt;p&gt;Managing observability workloads can quickly overwhelm even the most experienced admins — especially if they’re responsible for tracking hundreds of collectors across different environments. That’s why, last month, &lt;a href=&#34;/blog/2024/11/20/easily-control-observability-collectors-at-scale-with-fleet-management-in-grafana-cloud/&#34;&gt;we announced Fleet Management in Grafana Cloud&lt;/a&gt;, a powerful new way to monitor and manage observability collectors efficiently, regardless of scale.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;/docs/grafana-cloud/send-data/fleet-management/intro-fleet-mgmt/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Fleet Management&lt;/a&gt;, in public preview, helps you manage hundreds or thousands of collectors efficiently. It enables you to roll out configurations remotely, monitor collector health across all deployments, and control cost simply by activating or deactivating pipelines as needed.&lt;/p&gt;&#xA;&lt;div&#xA;class=&#34;youtube-lazyload responsive-video&#34;&#xA;data-embed=&#34;mKOLablQUxM&#34;&#xA;data-url=&#34;https://www.youtube.com/embed/mKOLablQUxM?autoplay=1&amp;amp;rel=0&#34;&#xA;data-title=&#34;YouTube Video&#34;&#xA;&gt;&#xA;&lt;div class=&#34;play-button&#34;&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;Currently, Fleet Management supports &lt;a href=&#34;/docs/alloy/latest/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Alloy&lt;/a&gt;, our open source distribution of the OpenTelemetry Collector, fully compatible with the OTLP protocol and featuring native pipelines for OTel and Prometheus. As leading contributors to the &lt;a href=&#34;https://opentelemetry.io/docs/specs/opamp/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Open Agent Management Protocol (OpAMP)&lt;/a&gt; project, we hope to extend support to traditional OTel Collectors in the future.&lt;/p&gt;&#xA;&lt;p&gt;You can learn more about Fleet Management in&lt;a href=&#34;/blog/2024/11/20/easily-control-observability-collectors-at-scale-with-fleet-management-in-grafana-cloud/&#34;&gt;&lt;/a&gt; our &lt;a href=&#34;/docs/grafana-cloud/send-data/fleet-management/&#34;&gt;technical docs&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;aiml-advancements&#34;&gt;AI/ML advancements&lt;/h2&gt;&#xA;&lt;p&gt;AI/ML continued to reshape the observability space throughout 2024 — and Grafana Cloud was no exception. In case you missed them, here are some of the major AI/ML announcements we made this year.&lt;/p&gt;&#xA;&lt;h3 id=&#34;contextualized-root-cause-analysis-workflows&#34;&gt;Contextualized root cause analysis workflows&lt;/h3&gt;&#xA;&lt;p&gt;At ObservabilityCON 2024, we &lt;a href=&#34;/blog/2024/09/24/contextual-root-cause-analysis-grafana-cloud/&#34;&gt;introduced a suite of unified workflows&lt;/a&gt; connecting &lt;a href=&#34;/blog/2023/11/14/grafana-labs-acquires-asserts/&#34;&gt;Asserts&lt;/a&gt; and Grafana Cloud solutions that helps automate the correlation of anomalies across infrastructure and application layers to provide a more cohesive troubleshooting experience. The workflows cover a wide range of monitoring needs, including application performance, Kubernetes workload monitoring, infrastructure monitoring, real user monitoring, and simplified SLO management. These AI-driven inferences enable even junior engineers to more effectively understand and diagnose issues in complex systems.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1999px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/asserts-obscon-2024/entity-explorer-asserts-grafana-cloud.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/asserts-obscon-2024/entity-explorer-asserts-grafana-cloud.png&#34;data-srcset=&#34;/media/blog/asserts-obscon-2024/entity-explorer-asserts-grafana-cloud.png?w=320 320w, /media/blog/asserts-obscon-2024/entity-explorer-asserts-grafana-cloud.png?w=550 550w, /media/blog/asserts-obscon-2024/entity-explorer-asserts-grafana-cloud.png?w=750 750w, /media/blog/asserts-obscon-2024/entity-explorer-asserts-grafana-cloud.png?w=900 900w, /media/blog/asserts-obscon-2024/entity-explorer-asserts-grafana-cloud.png?w=1040 1040w, /media/blog/asserts-obscon-2024/entity-explorer-asserts-grafana-cloud.png?w=1240 1240w, /media/blog/asserts-obscon-2024/entity-explorer-asserts-grafana-cloud.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A screenshot of Asserts in Grafana Cloud.&#34;width=&#34;1999&#34;height=&#34;1135&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/asserts-obscon-2024/entity-explorer-asserts-grafana-cloud.png&#34;&#xA;alt=&#34;A screenshot of Asserts in Grafana Cloud.&#34;width=&#34;1999&#34;height=&#34;1135&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;h3 id=&#34;observability-for-your-generative-ai-apps&#34;&gt;Observability for your generative AI apps&lt;/h3&gt;&#xA;&lt;p&gt;While generative AI has emerged as a powerful force for synthesizing new content, monitoring these complex AI systems can be a challenge. This is why we &lt;a href=&#34;/blog/2024/10/21/monitor-your-generative-ai-app-with-the-ai-observability-solution-in-grafana-cloud/&#34;&gt;rolled out our AI Observability solution&lt;/a&gt;, a Grafana Cloud integration designed to provide insights into gen AI use cases.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;/docs/grafana-cloud/monitor-applications/ai-observability/&#34;&gt;AI Observability&lt;/a&gt; leverages &lt;a href=&#34;https://openlit.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;OpenLIT&lt;/a&gt;, the open source SDK that has been engineered to monitor, diagnose, and optimize generative AI systems. This means you can now observe every nuance of your AI models, from performance bottlenecks to anomaly detection, all within the unified Grafana interface. Key features include performance monitoring, cost optimization, end-to-end tracing, and prompt and response tracking.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/ai-observability-solution/GenAI-panels.png?w=1240&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/ai-observability-solution/GenAI-panels.png?w=1240&#34;alt=&#34;A screenshot of the AI Observability solution in Grafana Cloud.&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/ai-observability-solution/GenAI-panels.png?w=1240&#34;&#xA;alt=&#34;A screenshot of the AI Observability solution in Grafana Cloud.&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;h3 id=&#34;more-flexible-and-powerful-diagnostics-with-sift&#34;&gt;More flexible and powerful diagnostics with Sift&lt;/h3&gt;&#xA;&lt;p&gt;&lt;a href=&#34;/docs/grafana-cloud/alerting-and-irm/machine-learning/manage/sift/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Sift&lt;/a&gt; is a machine-learning-powered diagnostic feature in Grafana Cloud that automates routine parts of incident investigation. Since we &lt;a href=&#34;/blog/2023/09/14/announcing-sift-automated-system-checks-for-faster-incident-response-times-in-grafana-cloud/&#34;&gt;launched Sift into public preview&lt;/a&gt; last year, we’ve been &lt;a href=&#34;/blog/2024/02/21/ai-powered-diagnostics-for-incident-response-new-sift-features-in-grafana-irm/&#34;&gt;working to expand its capabilities&lt;/a&gt;, including:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;A new homepage and &lt;strong&gt;Configuration&lt;/strong&gt; tab that allows you to customize the way Sift runs&lt;/li&gt;&#xA;&lt;li&gt;An HTTP Error Series check that helps detect an increase in HTTP errors within the investigation’s cluster and namespace&lt;/li&gt;&#xA;&lt;li&gt;An investigation timeline to help correlate events.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;infrastructure-observability-improvements&#34;&gt;Infrastructure observability improvements&lt;/h2&gt;&#xA;&lt;h3 id=&#34;kubernetes-monitoring&#34;&gt;Kubernetes Monitoring&lt;/h3&gt;&#xA;&lt;p&gt;We made a series of improvements to &lt;a href=&#34;/solutions/kubernetes/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Kubernetes Monitoring in Grafana Cloud&lt;/a&gt; in 2024, including new visualizations to help you monitor costs and new tools to streamline troubleshooting.&lt;/p&gt;&#xA;&lt;p&gt;For example, we introduced the &lt;a href=&#34;/docs/grafana-cloud/monitor-infrastructure/kubernetes-monitoring/manage-costs/#cost-overview&#34;&gt;Cost Overview&lt;/a&gt; tab, where you can quickly see a 90-day view of your total compute costs, average cost per pod, and average pod count.&lt;/p&gt;&#xA;&lt;p&gt;For faster and easier troubleshooting in Kubernetes Monitoring, it’s also now possible to:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Find deleted objects, such as clusters, nodes, pods, containers, workloads, and namespaces.&lt;/li&gt;&#xA;&lt;li&gt;Zoom into a specific area on a graph to narrow a time range.&lt;/li&gt;&#xA;&lt;li&gt;Jump directly to the list of clusters, nodes, workloads, and alerts from the home page.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;You can check out our &lt;a href=&#34;/docs/grafana-cloud/monitor-infrastructure/kubernetes-monitoring/&#34;&gt;Kubernetes Monitoring docs&lt;/a&gt; to learn more.&lt;/p&gt;&#xA;&lt;h3 id=&#34;multi-cloud-monitoring&#34;&gt;Multi-cloud monitoring&lt;/h3&gt;&#xA;&lt;p&gt;Managing multi-cloud environments often means juggling different monitoring tools for each provider, leading to increased complexity. &lt;a href=&#34;/blog/2024/08/22/multi-cloud-monitoring-made-easy-monitor-aws-microsoft-azure-and-google-cloud-services-all-in-one-app/&#34;&gt;Cloud Provider Observability&lt;/a&gt; — an application for monitoring AWS, Microsoft Azure, and Google Cloud services, all in Grafana Cloud — helps address this very challenge. Now generally available, Cloud Provider Observability provides comprehensive insights across cloud services with a single, out-of-the-box solution that is easy to set up and scale. Learn more in our &lt;a href=&#34;/docs/grafana-cloud/monitor-infrastructure/monitor-cloud-provider/&#34;&gt;documentation&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/cloud-provider-observability/cloud-provider-o11y-lambda-logging.png?w=1240&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/cloud-provider-observability/cloud-provider-o11y-lambda-logging.png?w=1240&#34;alt=&#34;A screenshot of AWS Lamda logging in Cloud Provider Observability.&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/cloud-provider-observability/cloud-provider-o11y-lambda-logging.png?w=1240&#34;&#xA;alt=&#34;A screenshot of AWS Lamda logging in Cloud Provider Observability.&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;h2 id=&#34;but-wait-theres-more&#34;&gt;But wait… there’s more!&lt;/h2&gt;&#xA;&lt;p&gt;Here are a couple other Grafana Cloud features and milestones we wanted to share before we wrap up 2024.&lt;/p&gt;&#xA;&lt;h3 id=&#34;ml-enhanced-guidance-in-grafana-slo&#34;&gt;ML-enhanced guidance in Grafana SLO&lt;/h3&gt;&#xA;&lt;p&gt;&lt;a href=&#34;/products/cloud/slo/&#34;&gt;Grafana SLO&lt;/a&gt; makes it easy to create, manage, and scale service level objectives, SLO dashboards, and error budget alerts in Grafana Cloud.&lt;/p&gt;&#xA;&lt;p&gt;That said, we’ve noticed teams struggle to set their initial &lt;a href=&#34;/docs/grafana-cloud/alerting-and-irm/slo/introduction/#service-level-indicators-slis&#34;&gt;Service Level Indicators (SLI)&lt;/a&gt; target percentage, or modify an existing target percentage on their SLOs. If you assume, for example, that you want to create an SLO to ensure 99.5% of HTTP requests return successfully in under 500 ms, how do you know that 99.5% is a realistic target for your service?&lt;/p&gt;&#xA;&lt;p&gt;To solve for this, we’ve made a major update to our guided wizard in Grafana SLO: the use of machine learning to predict the risk of hitting an SLI target percentage.&lt;/p&gt;&#xA;&lt;p&gt;After defining an SLO, the target selection page now offers ML-based guidance to select a target percentage that you’ll have confidence in your ability to meet. We query 90 days of history from the metrics used in the SLO definition, and run simulations to predict the likelihood of meeting a given target. You can also slide the target percentage to see an updated prediction of the likelihood of meeting that target.&lt;/p&gt;&#xA;&lt;p&gt;To learn more about Grafana SLO, please refer to our &lt;a href=&#34;/docs/grafana-cloud/alerting-and-irm/slo/&#34;&gt;technical docs&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h3 id=&#34;new-enterprise-data-sources-to-tap-into&#34;&gt;New Enterprise data sources to tap into&lt;/h3&gt;&#xA;&lt;p&gt;Throughout the year, we’ve been steadily building out our line-up of Enterprise data sources for Grafana Cloud. Today, we offer &lt;a href=&#34;/grafana/plugins/data-source-plugins/?enterprise=1&#34;&gt;more than 30 Enterprise data sources&lt;/a&gt; that help you query and visualize data from external systems using your existing Grafana Cloud dashboards. &lt;a href=&#34;/grafana/plugins/grafana-atlassianstatuspage-datasource/&#34;&gt;Atlassian Statuspage&lt;/a&gt;, &lt;a href=&#34;/grafana/plugins/grafana-pagerduty-datasource/&#34;&gt;PagerDuty&lt;/a&gt;, and &lt;a href=&#34;/grafana/plugins/grafana-catchpoint-datasource/&#34;&gt;Catchpoint&lt;/a&gt; are just a few of the many new data sources we rolled out this year.&lt;/p&gt;&#xA;&lt;p&gt;We also introduced a new &lt;a href=&#34;https://github.com/orgs/grafana/projects/619/views/1?pane=info&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;public roadmap&lt;/a&gt; for data source plugins being built by Grafana, our partners, and our community. You can use it to track our plans for plugin development, as well as &lt;a href=&#34;https://github.com/grafana/grafana/issues/new?assignees=&amp;amp;labels=area%2Fdatasource%2Ctype%2Fnew-plugin-request&amp;amp;projects=&amp;amp;template=3-data_source_request.yaml&amp;amp;title=%5BNew&amp;#43;Data&amp;#43;Source%5D%3A&amp;#43;%3Cname-of-service%3E&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;request new ones. &lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;/products/cloud/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt; is the easiest way to get started with metrics, logs, traces, and dashboards. We have a generous free forever tier and plans for every use case.&lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt; Sign up for free now&lt;/a&gt;!&lt;/em&gt;&lt;/p&gt;】&lt;p&gt;整个 2024 年，我们对 &lt;a href=&#34;/products/cloud/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt; 进行了大量更新，这是我们完全托管、云托管的可观测性平台由 Grafana LGTM（&lt;a href=&#34;/oss/loki/&#34;&gt;Loki&lt;/a&gt; 用于日志，&lt;a href=&#34;/oss/grafana?pg=blog&amp;plcmt=body-txt&#34;&gt; Grafana&lt;/a&gt; 用于可视化，&lt;a href=&#34;/oss/tempo/?pg=blog&amp;plcmt=body-txt&#34;&gt; Tempo&lt;/a&gt;对于跟踪，&lt;a href=&#34;/oss/mimir/?pg=blog&amp;plcmt=body-txt&#34;&gt; Mimir&lt;/a&gt; 对于指标）堆栈。而且，回顾过去，大多数更新都是出于同样的三个目标：使 Grafana Cloud 更高效、更智能、更易于使用，包括那些刚刚开始其可观测之旅的人。&lt;/p&gt;&#xA;&lt;p&gt;“Grafana Cloud 和 LGTM Stack 确实吸引了早期采用者，即那些想要亲自动手、学习查询语言并构建自己的仪表板的人，”Grafana 首席技术官 Tom Wilkie 说道实验室，位于 &lt;a href=&#34;/events/observabilitycon/2024/keynote/&#34;&gt;ObservabilityCON 2024&lt;/a&gt;。 “随着可观察性的兴起，以及所有这些从业者学习如何构建事物并从这些工具中获取价值，我们不断成长。但过去几年我们发现，我们对更广泛、更主流的受众的吸引力越来越大。”&lt;/p&gt;&#xA;&lt;p&gt;在这篇文章中，我们回顾了今年对 Grafana Cloud 所做的一些重大更新，以及它们如何帮助推进或启动您团队的可观察性策略。&lt;/p&gt;&#xA;&lt;h2 id=&#34;extending-adaptive-telemetry-to-logs--and-beyond&#34;&gt;将自适应遥测扩展到日志 - 甚至更远&lt;/h2&gt;&#xA;&lt;p&gt;2023 年，&lt;a href=&#34;/blog/2023/05/09/adaptive-metrics-grafana-cloud-announcement/&#34;&gt;我们推出了自适应指标&lt;/a&gt;，这是一项 Grafana Cloud 功能，使团队能够聚合未使用和部分使用的指标将其转化为较低基数版本，以降低可观测性成本。&lt;/p&gt;&#xA;&lt;p&gt;从那时起，&lt;a href=&#34;/blog/2024/08/12/why-companies-choose-adaptive-metrics-and-how-they-save-time-and-a-lot-of-money/ &#34;&gt;Adaptive Metrics 为 1,200 多个组织平均降低了 35% 的指标成本 — 这一数字说明了该功能的影响力有多大有利于组织的底线。&lt;/p&gt;&#xA;&lt;p&gt;在今年的势头基础上，我们&lt;a href=&#34;/blog/2024/09/24/introducing-adaptive-logs/&#34;&gt;推出了自适应日志&lt;/a&gt;。自适应日志现在在所有 Grafana Cloud 层中普遍可用，它可以识别常见的日志模式，并根据这些模式的查询频率创建一组定制的采样建议。最终结果？您可以减少不必要的日志量，以降低可观测性成本。&lt;/p&gt;&#xA;&lt;div&#xA;类 =“youtube-lazyload 响应视频”&#xA;数据嵌入=“ltkqkbY6Jao”&#xA;data-url=&#34;https://www.youtube.com/embed/ltkqkbY6Jao?autoplay=1&amp;rel=0&#34;&#xA;数据标题=“YouTube 视频”&#xA;&gt;&#xA;&lt;div class=&#34;play-button&#34;&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;通过我们&lt;a href=&#34;/blog/2024/09/24/grafana-labs-acquires-tailctrl/&#34;&gt;收购 TailCtrl&lt;/a&gt;是一家专注于自适应跟踪采样的早期公司，我们也开始加速自适应跟踪的开发。此举代表了我们在整个 LGTM Stack 中扩展自适应遥测概念的持续努力，以便您可以更轻松、更经济高效地大规模分析可观测性数据。&lt;/p&gt;&#xA;&lt;h2 id=&#34;simplified-data-analysis-with-the-explore-apps-suite&#34;&gt;使用探索应用套件简化数据分析&lt;/h2&gt;&#xA;&lt;p&gt;9 月份，我们宣布推出 &lt;a href=&#34;/docs/grafana-cloud/visualizations/simplified-exploration/traces/&#34;&gt;Explore Traces&lt;/a&gt; 和 &lt;a href=&#34;/docs/grafana- cloud/visualizations/simplified-exploration/profiles/&#34;&gt;探索配置文件&lt;/a&gt;，已加入 &lt;a href=&#34;/docs/grafana/latest/explore/explore-metrics/&#34;&gt;探索指标&lt;/a&gt;和&lt;a href=&#34;/docs/grafana-cloud/visualizations/simplified-exploration/logs/&#34;&gt;探索日志&lt; /a&gt; — 现已全面上市 — 为 Grafana 和 Grafana Cloud 创建全套 Explore 应用程序。&lt;/p&gt;&#xA;&lt;p&gt;这些应用程序通过直观的点击式 UI 简化了数据探索和分析，使您能够深入钻取和可视化数据，而无需了解 PromQL、LogQL 或 TraceQL 等查询语言。 &lt;a href=&#34;/blog/2024/10/22/from-multi-line-queries-to-no-code-investigations-meeting-grafana-users-where-ey-are/&#34;&gt;Explore 应用共同确保每个人&lt;/a&gt;（从初学者到专家）都可以从遥测数据中获取价值，并充分发挥可观测性的潜力。&lt;/p&gt;&#xA;&lt;p&gt;随着针对可观测性所有四大支柱的探索应用程序的发布，用户现在可以&lt;a href=&#34;/blog/2024/10/22/from-multi-line-queries-to-no-code-investigations- meet-grafana-users-where-they-are/&#34;&gt;从 Grafana Cloud 中的三个不同选项中进行选择&lt;/a&gt;，帮助他们从 Prometheus（或 Mimir）、Loki、节奏或热镜：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;代码&lt;/strong&gt;：使用 PromQL、LogQL 和 TraceQL 等查询语言。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;低代码&lt;/strong&gt;：使用&lt;a href=&#34;/docs/grafana/latest/datasources/prometheus/query-editor/?pg=blog&amp;plcmt=body-txt#builder-mode&#34;&gt;构建器模式&lt;/a&gt;，它提供了更多的可视化编程体验。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;无代码&lt;/strong&gt;：使用探索应用套件访问已预先填充图表的屏幕。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;div&#xA;类 =“youtube-lazyload 响应视频”&#xA;数据嵌入=“YICcDk_ddC4”&#xA;data-url=&#34;https://www.youtube.com/embed/YICcDk_ddC4?autoplay=1&amp;rel=0&#34;&#xA;数据标题=“YouTube 视频”&#xA;&gt;&#xA;&lt;div class=&#34;play-button&#34;&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;h2 id=&#34;enhancements-to-synthetic-monitoring-and-application-observability&#34;&gt;综合监控和应用程序可观察性的增强&lt;/h2&gt;&#xA;&lt;h3 id=&#34;synthetic-monitoring&#34;&gt;综合监控&lt;/h3&gt;&#xA;&lt;p&gt;2024 年，我们推出了&lt;a href=&#34;/blog/2024/05/01/grafana-cloud-synthetic-monitoring-all-the-latest-features/&#34;&gt;Grafana 云综合监控的改进版本&lt; /a&gt; 帮助您模拟最复杂的交易并确保为最终用户提供最佳服务经验。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1504px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/synthetic-monitoring-updates-2024/synthetic-monitoring-updates_dashboard-screenshot.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src =“/media/blog/synthetic-monitoring-updates-2024/synthetic-monitoring-updates_dashboard-screenshot.png”data-srcset =“/media/blog/synthetic-monitoring-updates-2024/synthetic-monitoring- update_dashboard-screenshot.png?w=320 320w, /media/blog/synthetic-monitoring-updates-2024/synthetic-monitoring-updates_dashboard-screenshot.png?w=550 550w，/media/blog/synthetic-monitoring-updates-2024/synthetic-monitoring-updates_dashboard-screenshot.png ?w=750 750w, /media/blog/synthetic-monitoring-updates-2024/synthetic-monitoring-updates_dashboard-screenshot.png?w=900 900w，/media/blog/synthetic-monitoring-updates-2024/synthetic-monitoring-updates_dashboard-screenshot.png ?w=1040 1040w, /media/blog/synthetic-monitoring-updates-2024/synthetic-monitoring-updates_dashboard-screenshot.png?w=1240 1240w，/media/blog/synthetic-monitoring-updates-2024/synthetic-monitoring-updates_dashboard-screenshot.png ?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;综合监控主页的屏幕截图。&#34;width=&#34;1504&#34;height=&#34;1020&#34;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/synthetic-monitoring-updates-2024/synthetic-monitoring-updates_dashboard-screenshot.png”&#xA;alt=&#34;综合监控主页的屏幕截图。&#34;width=&#34;1504&#34;height=&#34;1020&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;综合监控由 Grafana k6 提供支持，现在包括两种新的检查类型 - multiHTTP 和 k6 脚本检查 - 以支持更复杂的测试场景。我们还推出了 &lt;a href=&#34;/docs/grafana-cloud/testing/synthetic-monitoring/get-started/create-a-k6-browser-check/&#34;&gt;k6 浏览器检查&lt;/a&gt;，现已推出公共预览版，它可让您收集前端&lt;a href=&#34;https://developers.google.com/search/docs/appearance/core-web-vitals&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Web Vitals指标&lt;/a&gt;，捕获自定义性能指标，并执行用户操作，例如单击按钮或填写表单。&lt;/p&gt;&#xA;&lt;h3 id=&#34;application-observability&#34;&gt;应用程序可观察性&lt;/h3&gt;&#xA;&lt;p&gt;我们还继续发展 &lt;a href=&#34;/products/cloud/application-observability/&#34;&gt;Grafana Cloud Application Observability&lt;/a&gt;，这是我们固执己见的开箱即用解决方案，旨在提高现代应用程序。应用程序可观测性以对 OpenTelemetry 和 Prometheus 的本机支持为特色，可帮助开发人员和 SRE 无缝统一应用程序和基础设施洞察，从而更快地进行根本原因分析。&lt;/p&gt;&#xA;&lt;p&gt;我们今年对应用程序可观察性所做的一些关键补充包括：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;/docs/grafana-cloud/monitor-applications/application-observability/manual/service/#time-frame-comparison&#34;&gt;时间范围比较&lt;/a&gt;以分析一段时间内的服务性能&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;/docs/grafana-cloud/monitor-applications/application-observability/manual/automatic-baseline/&#34;&gt;自动基线&lt;/a&gt;，用于将服务和运营的 RED 指标与历史上限和下限进行比较阈值。&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;/docs/grafana-cloud/monitor-applications/application-observability/manual/group-filter/?pg=application-observability&amp;plcmt=hero-btn-2#filter-by&#34;&gt;过滤器-按功能&lt;/a&gt;根据属性值管理哪些数据可见&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;/blog/2024/06/13/improved-anomaly-detection-and-faster-root-cause-analysis-the-latest-features-in-grafana-cloud-application-observability/# fast-root-cause-analysis-with-in-context-navigation&#34;&gt;上下文导航&lt;/a&gt;可加快根本原因分析&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1024px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/app-observability-updates/application-observability-updates-incontext-nav.gif&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/blog/app-observability-updates/application-observability-updates-incontext-nav.gif&#34;alt=&#34;显示应用程序可观察性的 gif。&#34;width=&#34;1024&#34;height=&#34;541&#34;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/app-observability-updates/application-observability-updates-incontext-nav.gif”&#xA;alt=&#34;显示应用程序可观察性的 gif。&#34;width=&#34;1024&#34;height=&#34;541&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;您可以在我们的技术文档中了解有关&lt;a href=&#34;/docs/grafana-cloud/testing/synthetic-monitoring/&#34;&gt;综合监控&lt;/a&gt;和&lt;a href=&#34;/docs/grafana-cloud /monitor-applications/application-observability/&#34;&gt;应用程序可观察性&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;h2 id=&#34;control-collectors-at-scale-with-fleet-management&#34;&gt;通过队列管理大规模控制收集器&lt;/h2&gt;&#xA;&lt;p&gt;即使是最有经验的管理员，管理可观察性工作负载也会很快让他们不知所措——尤其是当他们负责跟踪不同环境中的数百个收集器时。这就是为什么上个月&lt;a href=&#34;/blog/2024/11/20/easily-control-observability-collectors-at-scale-with-fleet-management-in-grafana-cloud/&#34;&gt;我们宣布推出车队管理Grafana Cloud&lt;/a&gt; 是一种有效监控和管理可观测性收集器的强大新方法，无论规模大小。&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;/docs/grafana-cloud/send-data/fleet-management/intro-fleet-mgmt/?pg=blog&amp;plcmt=body-txt&#34;&gt;队列管理&lt;/a&gt;，公开预览版，帮助您有效管理数百或数千个收集器。它使您能够远程部署配置，监控所有部署中的收集器运行状况，并只需根据需要激活或停用管道来控制成本。&lt;/p&gt;&#xA;&lt;div&#xA;类 =“youtube-lazyload 响应视频”&#xA;数据嵌入=“mKOLablQUxM”&#xA;data-url=&#34;https://www.youtube.com/embed/mKOLablQUxM?autoplay=1&amp;rel=0&#34;&#xA;数据标题=“YouTube 视频”&#xA;&gt;&#xA;&lt;div 类=“播放按钮”&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;目前，Fleet Management 支持 &lt;a href=&#34;/docs/alloy/latest/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana Alloy&lt;/a&gt;，这是我们的 OpenTelemetry Collector 开源发行版，与OTLP 协议并具有适用于 OTel 和 Prometheus 的本机管道。作为&lt;a href=&#34;https://opentelemetry.io/docs/specs/opamp/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;开放代理管理协议 (OpAMP)&lt;/a&gt; 项目的主要贡献者，我们希望将来能够向传统 OTel 收集者提供支持。&lt;/p&gt;&#xA;&lt;p&gt;您可以在&lt;a href=&#34;/blog/2024/11/20/easily-control-observability-collectors-at-scale-with-fleet-management-in-grafana-cloud/&#34;中了解有关车队管理的更多信息&gt;&lt;/a&gt;我们的&lt;a href=&#34;/docs/grafana-cloud/send-data/fleet-management/&#34;&gt;技术文档&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;h2 id=&#34;aiml-advancements&#34;&gt;AI/ML 进步&lt;/h2&gt;&#xA;&lt;p&gt;人工智能/机器学习在 2024 年继续重塑可观察性空间，Grafana Cloud 也不例外。如果您错过了，以下是我们今年发布的一些主要人工智能/机器学习公告。&lt;/p&gt;&#xA;&lt;h3 id=&#34;contextualized-root-cause-analysis-workflows&#34;&gt;情景化根本原因分析工作流程&lt;/h3&gt;&#xA;&lt;p&gt;在 ObservabilityCON 2024 上，我们&lt;a href=&#34;/blog/2024/09/24/contextual-root-cause-analysis-grafana-cloud/&#34;&gt;推出了一套统一的工作流程&lt;/a&gt;，连接&lt;a href =&#34;/blog/2023/11/14/grafana-labs-acquires-asserts/&#34;&gt;断言&lt;/a&gt;和有助于自动化关联的 Grafana Cloud 解决方案跨基础设施和应用程序层的异常情况，以提供更具凝聚力的故障排除体验。这些工作流程涵盖了广泛的监控需求，包括应用程序性能、Kubernetes 工作负载监控、基础设施监控、真实用户监控和简化的 SLO 管理。这些人工智能驱动的推理甚至使初级工程师能够更有效地理解和诊断复杂系统中的问题。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1999px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/asserts-obscon-2024/entity-explorer-asserts-grafana-cloud.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/blog/asserts-obscon-2024/entity-explorer-asserts-grafana-cloud.png&#34;data-srcset=&#34;/media/blog/asserts-obscon-2024/entity-explorer-asserts- grafana-cloud.png?w=320 320w, /media/blog/asserts-obscon-2024/entity-explorer-asserts-grafana-cloud.png?w=550 550w，/media/blog/asserts-obscon-2024/entity-explorer-asserts-grafana-cloud.png ?w=750 750w, /media/blog/asserts-obscon-2024/entity-explorer-asserts-grafana-cloud.png?w=900 900w，/media/blog/asserts-obscon-2024/entity-explorer-asserts-grafana-cloud.png ?w=1040 1040w, /media/blog/asserts-obscon-2024/entity-explorer-asserts-grafana-cloud.png?w=1240 1240w，/media/blog/asserts-obscon-2024/entity-explorer-asserts-grafana-cloud.png ?w=1920 1920w&#34;&#xA;数据大小=“auto&#34;alt=&#34;Grafana Cloud 中断言的屏幕截图。&#34;width=&#34;1999&#34;height=&#34;1135&#34;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/asserts-obscon-2024/entity-explorer-asserts-grafana-cloud.png”&#xA;alt=&#34;Grafana Cloud 中断言的屏幕截图。&#34;width=&#34;1999&#34;height=&#34;1135&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;h3 id=&#34;observability-for-your-generative-ai-apps&#34;&gt;生成式 AI 应用的可观察性&lt;/h3&gt;&#xA;&lt;p&gt;虽然生成式人工智能已成为合成新内容的强大力量，但监控这些复杂的人工智能系统可能是一项挑战。这就是为什么我们&lt;a href=&#34;/blog/2024/10/21/monitor-your-generative-ai-app-with-the-ai-observability-solution-in-grafana-cloud/&#34;&gt;推出我们的人工智能可观测性解决方案&lt;/a&gt;，一个 Grafana Cloud 集成，旨在提供对 gen AI 使用案例的见解。&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;/docs/grafana-cloud/monitor-applications/ai-observability/&#34;&gt;人工智能可观测性&lt;/a&gt;利用&lt;a href=&#34;https://openlit.io/&#34; target=&#34;_blank “ rel=&#34;noopener noreferrer&#34;&gt;OpenLIT&lt;/a&gt;，开源 SDK，旨在监控、诊断和优化生成式 AI 系统。这意味着您现在可以在统一的 Grafana 界面中观察 AI 模型的每一个细微差别，从性能瓶颈到异常检测。主要功能包括性能监控、成本优化、端到端跟踪以及提示和响应跟踪。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/ai-observability-solution/GenAI-panels.png?w=1240&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/blog/ai-observability-solution/GenAI-panels.png?w=1240&#34;alt=&#34;Grafana Cloud 中 AI 可观测性解决方案的屏幕截图。&#34;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src=&#34;/media/blog/ai-observability-solution/GenAI-panels.png?w=1240&#34;&#xA;alt=&#34;Grafana Cloud 中 AI 可观测性解决方案的屏幕截图。&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;h3 id=&#34;more-flexible-and-powerful-diagnostics-with-sift&#34;&gt;使用 Sift 进行更灵活、更强大的诊断&lt;/h3&gt;&#xA;&lt;p&gt;&lt;a href=&#34;/docs/grafana-cloud/alerting-and-irm/machine-learning/manage/sift/?pg=blog&amp;plcmt=body-txt&#34;&gt;Sift&lt;/a&gt; 是一种机器学习- Grafana Cloud 中的强大诊断功能可自动执行事件调查的常规部分。自从我们&lt;a href=&#34;/blog/2023/09/14/announcing-sift-automated-system-checks-for-faster-incident-response-times-in-grafana-cloud/&#34;&gt;推出 Sift 公共预览版&lt; /a&gt; 去年，我们&lt;a href=&#34;/blog/2024/02/21/ai-powered-diagnostics-for-incident-response-new-sift-features-in-grafana-irm/&#34;&gt;努力扩展其功能&lt;/a&gt;，包括： &lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;新的主页和&lt;strong&gt;配置&lt;/strong&gt;选项卡，可让您自定义 Sift 的运行方式&lt;/li&gt;&#xA;&lt;li&gt;HTTP 错误系列检查，有助于检测调查集群和命名空间内 HTTP 错误的增加情况&lt;/li&gt;&#xA;&lt;li&gt;调查时间需要帮助关联事件。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;infrastruct-observability-improvements&#34;&gt;基础设施可观测性改进&lt;/h2&gt;&#xA;&lt;h3 id=&#34;kubernetes-monitoring&#34;&gt;Kubernetes 监控&lt;/h3&gt;&#xA;&lt;p&gt;我们在 2024 年对&lt;a href=&#34;/solutions/kubernetes/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana Cloud 中的 Kubernetes 监控&lt;/a&gt;进行了一系列改进，包括帮助您监控成本的新可视化效果以及简化故障排除的新工具。&lt;/p&gt;&#xA;&lt;p&gt;例如，我们引入了&lt;a href=&#34;/docs/grafana-cloud/monitor-infrastruct/kubernetes-monitoring/manage-costs/#cost-overview&#34;&gt;成本概览&lt;/a&gt;选项卡，您可以在其中快速查看 90 天的总计算成本、每个 Pod 的平均成本和平均 Pod 数量。&lt;/p&gt;&#xA;&lt;p&gt;为了更快、更轻松地在 Kubernetes 监控中进行故障排除，现在还可以：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;查找已删除的对象，例如集群、节点、pod、容器、工作负载和命名空间。&lt;/li&gt;&#xA;&lt;li&gt;放大图表上的特定区域以缩小时间范围。&lt;/li&gt;&#xA;&lt;li&gt;从主页直接跳转到集群、节点、工作负载和警报列表。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;您可以查看我们的&lt;a href=&#34;/docs/grafana-cloud/monitor-infrastruct/kubernetes-monitoring/&#34;&gt;Kubernetes 监控文档&lt;/a&gt;以了解更多信息。&lt;/p&gt;&#xA;&lt;h3 id=&#34;multi-cloud-monitoring&#34;&gt;多云监控&lt;/h3&gt;&#xA;&lt;p&gt;管理多云环境通常意味着为每个提供商使用不同的监控工具，从而导致复杂性增加。 &lt;a href=&#34;/blog/2024/08/22/multi-cloud-monitoring-made-easy-monitor-aws-microsoft-azure-and-google-cloud-services-all-in-one-app/&#34;&gt; Cloud Provider Observability&lt;/a&gt;——一个用于监控 AWS、Microsoft Azure 和 Google Cloud 服务的应用程序，所有这些服务都在 Grafana Cloud 中——有助于解决这一挑战。云提供商可观测性现已全面上市，通过易于设置和扩展的单一开箱即用解决方案提供跨云服务的全面见解。请参阅我们的&lt;a href=&#34;/docs/grafana-cloud/monitor-infrastruct/monitor-cloud-provider/&#34;&gt;文档&lt;/a&gt;了解更多信息。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/cloud-provider-observability/cloud-provider-o11y-lambda-logging.png?w=1240&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/blog/cloud-provider-observability/cloud-provider-o11y-lambda-logging.png?w=1240&#34;alt=&#34;AWS Lambda 在云提供商可观察性中日志记录的屏幕截图。&#34;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src=&#34;/media/blog/cloud-provider-observability/cloud-provider-o11y-lambda-logging.png?w=1240&#34;&#xA;alt=&#34;AWS Lamda 登录云提供商可观察性的屏幕截图。&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;h2 id=&#34;but-wait-theres-more&#34;&gt;但是等等……还有更多！&lt;/h2&gt;&#xA;&lt;p&gt;以下是我们想在 2024 年结束之前分享的其他一些 Grafana Cloud 功能和里程碑。&lt;/p&gt;&#xA;&lt;h3id=&#34;ml-enhanced-guidance-in-grafana-slo&#34;&gt;Grafana SLO 中的 ML 增强型指导&lt;/h3&gt;&#xA;&lt;p&gt;&lt;a href=&#34;/products/cloud/slo/&#34;&gt;Grafana SLO&lt;/a&gt; 让您可以在 Grafana Cloud 中轻松创建、管理和扩展服务级别目标、SLO 仪表板和错误预算警报。&lt;/ p&gt;&#xA;&lt;p&gt;也就是说，我们注意到团队很难设置其初始&lt;a href=&#34;/docs/grafana-cloud/alerting-and-irm/slo/introduction/#service-level-indicators-slis&#34;&gt;服务级别指标 (SLI)&lt;/a&gt; 目标百分比，或修改其 SLO 的现有目标百分比。例如，如果您假设要创建 SLO 以确保 99.5% 的 HTTP 请求在 500 毫秒内成功返回，那么您如何知道 99.5% 是您的服务的实际目标？&lt;/p&gt;&#xA;&lt;p&gt;为了解决这个问题，我们对 Grafana SLO 中的引导向导进行了重大更新：使用机器学习来预测达到 SLI 目标百分比的风险。&lt;/p&gt;&#xA;&lt;p&gt;定义 SLO 后，目标选择页面现在提供基于 ML 的指导来选择您对自己有能力达到目标的百分比。我们从 SLO 定义中使用的指标查询 90 天的历史记录，并运行模拟来预测满足给定目标的可能性。您还可以滑动目标百分比来查看实现该目标的可能性的更新预测。&lt;/p&gt;&#xA;&lt;p&gt;要了解有关 Grafana SLO 的更多信息，请参阅我们的&lt;a href=&#34;/docs/grafana-cloud/alerting-and-irm/slo/&#34;&gt;技术文档&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;h3 id=&#34;new-enterprise-data-sources-to-tap-into&#34;&gt;可供利用的新企业数据源&lt;/h3&gt;&#xA;&lt;p&gt;这一年来，我们一直在稳步构建 Grafana Cloud 的企业数据源阵容。今天，我们提供&lt;a href=&#34;/grafana/plugins/data-source-plugins/?enterprise=1&#34;&gt;超过 30 个企业数据源&lt;/a&gt;，帮助您使用现有的 Grafana 查询和可视化来自外部系统的数据云仪表板。 &lt;a href=&#34;/grafana/plugins/grafana-atlassianstatuspage-datasource/&#34;&gt;Atlassian Statuspage&lt;/a&gt;、&lt;a href=&#34;/grafana/plugins/grafana-pagerduty-datasource/&#34;&gt;PagerDuty&lt;/a&gt; 和&lt;a href=&#34;/grafana/plugins/grafana-catchpoint-datasource/&#34;&gt;Catchpoint&lt;/a&gt; 只是我们推出的众多新数据源中的一部分年。&lt;/p&gt;&#xA;&lt;p&gt;我们还引入了一个新的&lt;a href=&#34;https://github.com/orgs/grafana/projects/619/views/1?pane=info&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;公共Grafana、我们的合作伙伴和社区正在构建的数据源插件的路线图&lt;/a&gt;。您可以使用它来跟踪我们的插件开发计划，以及&lt;a href=&#34;https://github.com/grafana/grafana/issues/new?assignees=&amp;labels=area%2Fdatasource%2Ctype%2Fnew-plugin- request&amp;projects=&amp;template=3-data_source_request.yaml&amp;title=%5BNew+Data+Source%5D%3A+%3Cname-of-service%3E&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;请求新的。 &lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;/products/cloud/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt; 是开始使用指标、日志、跟踪和仪表板的最简单方法rds。我们为每个用例提供慷慨的永久免费套餐和计划。&lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;plcmt=body-txt&#34;&gt;立即免费注册&lt;/a&gt;！ &lt;/em&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 10 Dec 2024 00:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>