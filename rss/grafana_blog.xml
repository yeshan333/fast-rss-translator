<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Grafana Labs blog on Grafana Labs</title>
    <link>/blog/index.xml</link>
    <description>Recent content in Grafana Labs blog on Grafana Labs</description>
    <item>
      <title>【ObservabilityCON on the Road is coming to a city near you!】ObservabilityCON on the Road 即将来到您附近的城市！</title>
      <link>https://grafana.com/blog/2024/08/13/observabilitycon-on-the-road-is-coming-to-a-city-near-you/</link>
      <description>【&lt;p&gt;Each year, observability enthusiasts and experts come together for &lt;a href=&#34;/events/observabilitycon/&#34;&gt;ObservabilityCON&lt;/a&gt;, our flagship open source observability conference that showcases the latest updates to the Grafana LGTM Stack (&lt;a href=&#34;/docs/loki/latest/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Loki&lt;/a&gt; for logs, &lt;a href=&#34;/docs/grafana/latest/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana&lt;/a&gt; for visualization, &lt;a href=&#34;/docs/tempo/latest/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Tempo&lt;/a&gt; for traces, and &lt;a href=&#34;/docs/mimir/latest/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Mimir&lt;/a&gt; for metrics) as well as deep-dive demos, workshops, and user success stories.&lt;/p&gt;&#xA;&lt;p&gt;This year, ObservabilityCON 2024 will take place in New York City on Sept. 24-25 with sessions highlighting root cause analysis with unified application and infrastructure observability, synthetic monitoring, AI/ML, and more. We will also highlight community talks from Walmart, Novo Nordisk, IG Group, and more.&lt;/p&gt;&#xA;&lt;p&gt;But for those who can&amp;rsquo;t make it to New York, you&amp;rsquo;re in luck: We&amp;rsquo;re bringing all the goodness of ObservabilityCON 2024 to a city near you with &lt;a href=&#34;/events/observabilitycon-on-the-road/&#34;&gt;ObservabilityCON on the Road&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Right after the ObservabilityCON 2024 conference wraps in New York, ObservabilityCON on the Road will head to the following cities:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Berlin on Oct. 8 (&lt;a href=&#34;/events/observabilitycon-on-the-road/2024/berlin/&#34;&gt;Register now&lt;/a&gt;)&lt;/li&gt;&#xA;&lt;li&gt;London on Oct 22 (&lt;a href=&#34;/events/observabilitycon-on-the-road/2024/london/&#34;&gt;Register now&lt;/a&gt;)&lt;/li&gt;&#xA;&lt;li&gt;São Paulo on Nov. 6, presented in Portuguese (&lt;a href=&#34;/pt-br/events/observabilitycon-on-the-road/2024/sao-paulo/&#34;&gt;Save the date&lt;/a&gt;)&lt;/li&gt;&#xA;&lt;li&gt;Paris on Nov. 21, presented in French (&lt;a href=&#34;/fr/events/observabilitycon-on-the-road/2024/paris/&#34;&gt;Save the date&lt;/a&gt;)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;btn-row &#34;&gt;&lt;a class=&#34;btn btn--primary &#34; href=&#34;https://grafana.com/events/observabilitycon-on-the-road/?pg=blog&amp;amp;plcmt=body-txt&#34; rel=&#34;noopener noreferrer&#34;&gt;Register for ObservabilityCON on the Road&lt;/a&gt;&lt;/div&gt;&#xA;&lt;p&gt;Don&amp;rsquo;t see your postal code? Don&amp;rsquo;t worry — more cities and dates in North America and Australia will be announced later this year.&lt;/p&gt;&#xA;&lt;h2 id=&#34;what-to-expect-at-observability-on-the-road&#34;&gt;What to expect at Observability on the Road&lt;/h2&gt;&#xA;&lt;p&gt;All of the things &lt;a href=&#34;/blog/2023/02/09/inside-observabilitycon-i-picked-up-so-much-practical-information/&#34;&gt;the community loves most about ObservabilityCON&lt;/a&gt; — Technical deep dives! Live demos! Ask the Experts booth! — will be included in these special one-day events that are happening around the world.&lt;/p&gt;&#xA;&lt;p&gt;Along with presenting the original technical sessions from ObservabilityCON, Grafana Labs experts will share the stage in each city with local observability pros who will walk through their success stories and the lessons they learned along the way.&lt;/p&gt;&#xA;&lt;p&gt;Registration is now open for ObservabilityCON on the Road in Berlin and in London. For Paris and São Paulo, you can sign up to get notified when registration opens and early bird ticket pricing begins.&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;Please note: The ObservabilityCON on the Road event in Paris will be presented in French and the event in São Paulo will be presented in Portuguese.&lt;/em&gt;&lt;/p&gt;】&lt;p&gt;每年，可观测性爱好者和专家都会齐聚一堂，参加 &lt;a href=&#34;/events/observabilitycon/&#34;&gt;ObservabilityCON&lt;/a&gt;，这是我们的旗舰开源可观测性会议，展示 Grafana LGTM Stack 的最新更新（&lt;a href=&#34;/docs/loki/latest/?pg=blog&amp;plcmt=body-txt&#34;&gt;Loki&lt;/a&gt; 用于日志，&lt;a href=&#34;/docs/grafana/latest/?pg=blog&amp;plcmt=body-txt&#34;&gt; Grafana&lt;/a&gt; 用于可视化，&lt;a href=&#34;/docs/tempo/latest/?pg=blog&amp;plcmt=body-txt&#34;&gt;Tempo&lt;/a&gt; 用于跟踪，以及 &lt;a href=&#34;/docs/mimir/latest /?pg=blog&amp;plcmt=body-txt&#34;&gt;Mimir&lt;/a&gt; 了解指标）以及深入演示、研讨会和用户成功案例。&lt;/p&gt;&#xA;&lt;p&gt;今年，ObservabilityCON 2024 将于 9 月 24 日至 25 日在纽约举行，会议重点介绍统一应用程序和基础设施可观测性的根本原因分析、综合监控、AI/ML 等。我们还将重点介绍来自沃尔玛、诺和诺德、IG Group 等的社区演讲。&lt;/p&gt;&#xA;&lt;p&gt;但是对于那些无法前往纽约的人来说，您很幸运：我们将通过 &lt;a href=&#34;/events/observabilitycon-on- 将 ObservabilityCON 2024 的所有优点带到您附近的城市the-road/&#34;&gt;ObservabilityCON 路上&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;ObservabilityCON 2024 会议在纽约结束后，ObservabilityCON on the Road 将前往以下城市：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;10 月 8 日柏林（&lt;a href=&#34;/events/observabilitycon-on-the-road/2024/berlin/&#34;&gt;立即注册&lt;/a&gt;）&lt;/li&gt;&#xA;&lt;li&gt;10 月 22 日伦敦（&lt;a href=&#34;/events/observabilitycon-on-the-road/2024/london/&#34;&gt;立即注册&lt;/a&gt;）&lt;/li&gt;&#xA;&lt;li&gt;11 月 6 日在圣保罗举行，以葡萄牙语呈现（&lt;a href=&#34;/pt-br/events/observabilitycon-on-the-road/2024/sao-paulo/&#34;&gt;保存日期&lt;/a&gt;） &lt;/li&gt;&#xA;&lt;li&gt;11 月 21 日巴黎，以法语呈现（&lt;a href=&#34;/fr/events/observabilitycon-on-the-road/2024/paris/&#34;&gt;保存日期&lt;/a&gt;）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;btn-row &#34;&gt;&lt;a class=&#34;btn btn--primary &#34; href=&#34;https://grafana.com/events/observabilitycon-on-the-road/?pg=blog&amp;plcmt=body-txt &#34; rel=&#34;noopener noreferrer&#34;&gt;注册 ObservabilityCON on the Road&lt;/a&gt;&lt;/div&gt;&#xA;&lt;p&gt;没有看到您的邮政编码？别担心——北美和澳大利亚的更多城市和日期将于今年晚些时候公布。&lt;/p&gt;&#xA;&lt;h2 id=&#34;what-to-expect-at-observability-on-the-road&#34;&gt;Observability on the Road 的期望&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;/blog/2023/02/09/inside-observabilitycon-i-picked-up-so-much-practical-information/&#34;&gt;社区最喜欢 ObservabilityCON 的所有内容&lt;/a &gt; — 技术深入探讨！现场演示！到专家展位询问！ — 将包含在世界各地正在发生的这些特殊的一日活动中。&lt;/p&gt;&#xA;&lt;p&gt;除了介绍 ObservabilityCON 的原创技术会议外，Grafana Labs 专家还将在每个城市与当地可观测性专业人士分享舞台，他们将讲述他们的成功故事以及一路上学到的经验教训。&lt;/p&gt;&#xA;&lt;p&gt;柏林和伦敦的 ObservabilityCON on the Road 现已开放注册。前往巴黎和圣保罗，您可以注册以便在注册开始和早鸟票定价开始时收到通知。&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;请注意：巴黎的 ObservabilityCON on the Road 活动将以法语进行，圣保罗的活动将以葡萄牙语进行。&lt;/em&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 13 Aug 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Grafana security release: Medium severity security fix for CVE-2024-6837】Grafana 安全版本：针对 CVE-2024-6837 的中等严重性安全修复</title>
      <link>https://grafana.com/blog/2024/08/14/grafana-security-release-medium-severity-security-fix-for-cve-2024-6837/</link>
      <description>【&lt;p&gt;We’ve recently released Grafana 11.1.4 along with Grafana 11.0.3 and 10.4.7. The latest version of Grafana and these patch releases contain a fix for CVE-2024-6837, a medium severity security vulnerability exploitable through Grafana’s embedded Swagger API documentation.&lt;/p&gt;&#xA;&lt;p&gt;Release 11.1.4, latest release with the security patch:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Download &lt;a href=&#34;/grafana/download/11.1.4/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana 11.1.4&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Release 11.0.3 with the security patch:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Download &lt;a href=&#34;/grafana/download/11.0.3/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana 11.0.3&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Release 10.4.7 with the security patch:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Download &lt;a href=&#34;/grafana/download/10.4.7/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana 10.4.7&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Appropriate patches have been applied to Grafana Cloud and as always, we closely coordinated with all cloud providers licensed to offer Grafana Cloud Pro. They have received early notification under embargo and confirmed that their offerings are secure at the time of this announcement. This is applicable to Amazon Managed Grafana and Azure Managed Grafana.&lt;/p&gt;&#xA;&lt;h2 id=&#34;data-source-permission-escalation-cve-2024-6837&#34;&gt;Data source permission escalation (CVE-2024-6837)&lt;/h2&gt;&#xA;&lt;h3 id=&#34;summary&#34;&gt;Summary&lt;/h3&gt;&#xA;&lt;p&gt;Grafana ships with a &lt;code&gt;/swagger&lt;/code&gt; endpoint that allows visitors to explore the Grafana API. Through a querystring parameter, it is possible to inject arbitrary HTML content into the page, which in turn allows for the possibility of an XSS exploit.&lt;/p&gt;&#xA;&lt;p&gt;The CVSS score for this vulnerability is &lt;a href=&#34;https://nvd.nist.gov/vuln-metrics/cvss/v3-calculator?vector=AV:N/AC:L/PR:N/UI:R/S:U/C:L/I:L/A:N&amp;amp;version=3.1&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;5.4 Medium&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h3 id=&#34;impact&#34;&gt;Impact&lt;/h3&gt;&#xA;&lt;p&gt;An attacker who can successfully exploit this vulnerability may be able to steal session cookies or interact with the Grafana API on behalf of the logged in user who is visiting the page.&lt;/p&gt;&#xA;&lt;h3 id=&#34;impacted-versions&#34;&gt;Impacted versions&lt;/h3&gt;&#xA;&lt;p&gt;The vulnerability impacts Grafana OSS and Grafana Enterprise running on the following versions:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Grafana 10.4.0 to Grafana 10.4.6&lt;/li&gt;&#xA;&lt;li&gt;Grafana 11.0.0 to Grafana 11.0.2&lt;/li&gt;&#xA;&lt;li&gt;Grafana 11.1.0 to Grafana 11.1.3&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Appropriate patches have been applied to Grafana Cloud.&lt;/p&gt;&#xA;&lt;h3 id=&#34;solutions-and-mitigations&#34;&gt;Solutions and mitigations&lt;/h3&gt;&#xA;&lt;p&gt;If your instance is vulnerable, we strongly recommend upgrading to one of the patched versions as soon as possible.&lt;/p&gt;&#xA;&lt;p&gt;As a mitigation, make sure that a Content Security Policy that blocks script execution coming from sources outside of the domains you control. For example:&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;button x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;Copy code to clipboard&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;Copy&lt;/span&gt;&#xA;&lt;/button&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;Content-Security-Policy: script-src &amp;#39;self&amp;#39;;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;h3 id=&#34;timeline-and-post-incident-review&#34;&gt;Timeline and post-incident review&lt;/h3&gt;&#xA;&lt;p&gt;Here is a detailed incident timeline starting from when we originally introduced the issue. All times are in UTC.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;2024-01-31 10:17 A &lt;a href=&#34;https://github.com/grafana/grafana/commit/2ffd56c23b7f734a09627df835b327bf93d5001f&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;commit enabled&lt;/a&gt; the &lt;code&gt;queryConfigEnabled&lt;/code&gt; Swagger flag, introducing the vulnerability.&lt;/li&gt;&#xA;&lt;li&gt;2024-03-06 14:20 - The vulnerability is &lt;a href=&#34;https://github.com/grafana/grafana/releases/tag/v10.4.0&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;released in Grafana version 10.4.0.&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;2024-07-10 14:28 - The vulnerability is discovered through our Security Bounty program&lt;/li&gt;&#xA;&lt;li&gt;2024-07-22 07:36 - The impact of the vulnerability is assessed, and a fix is merged.&lt;/li&gt;&#xA;&lt;li&gt;2024-07-31 17:05 Private release.&lt;/li&gt;&#xA;&lt;li&gt;2024-08-14 20:30 - Public release.&lt;/li&gt;&#xA;&lt;li&gt;2024-08-14 20:45 Blog published.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;reporting-security-issues&#34;&gt;Reporting security issues&lt;/h2&gt;&#xA;&lt;p&gt;If you think you have found a security vulnerability, please go to our &lt;a href=&#34;/legal/report-a-security-issue/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Report a security issue page&lt;/a&gt; to learn how to send a security report.&lt;/p&gt;&#xA;&lt;p&gt;Grafana Labs will send you a response indicating the next steps in handling your report. After the initial reply to your report, the security team will keep you informed of the progress towards a fix and full announcement, and may ask for additional information or guidance.&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;Important: We ask you to not disclose the vulnerability before it has been fixed and announced, unless you received a response from the Grafana Labs security team that you can do so.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;security-announcements&#34;&gt;Security announcements&lt;/h2&gt;&#xA;&lt;p&gt;We maintain a &lt;a href=&#34;/tags/security/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;security category&lt;/a&gt; on our blog where we will always post a summary, remediation, and mitigation details for any patch containing security fixes. You can also subscribe to our &lt;a href=&#34;/tags/security/index.xml&#34;&gt;RSS feed&lt;/a&gt;.&lt;/p&gt;】&lt;p&gt;我们最近发布了 Grafana 11.1.4 以及 Grafana 11.0.3 和 10.4.7。 Grafana 的最新版本和这些补丁版本包含 CVE-2024-6837 的修复程序，这是一个可通过 Grafana 的嵌入式 Swagger API 文档利用的中等严重性安全漏洞。&lt;/p&gt;&#xA;&lt;p&gt;版本 11.1.4，带有安全补丁的最新版本：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;下载&lt;a href=&#34;/grafana/download/11.1.4/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana 11.1.4&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;发布 11.0.3 并添加安全补丁：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;下载&lt;a href=&#34;/grafana/download/11.0.3/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana 11.0.3&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;发布带有安全补丁的 10.4.7：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;下载&lt;a href=&#34;/grafana/download/10.4.7/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana 10.4.7&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;适当的补丁已应用于 Grafana Cloud，并且一如既往，我们与所有获得许可提供 Grafana Cloud Pro 的云提供商密切协调。他们已收到禁运的早期通知，并确认他们的产品在本公告发布时是安全的。这适用于 Amazon Managed Grafana 和 Azure Managed Grafana。&lt;/p&gt;&#xA;&lt;h2 id=&#34;data-source-permission-escalation-cve-2024-6837&#34;&gt;数据源权限升级 (CVE-2024-6837)&lt;/h2&gt;&#xA;&lt;h3 id=&#34;summary&#34;&gt;摘要&lt;/h3&gt;&#xA;&lt;p&gt;Grafana 附带一个 &lt;code&gt;/swagger&lt;/code&gt; 端点，允许访问者探索 Grafana API。通过查询字符串参数，可以将任意 HTML 内容注入到页面中，从而导致 XSS 漏洞利用的可能性。&lt;/p&gt;&#xA;&lt;p&gt;此漏洞的 CVSS 评分为 &lt;a href=&#34;https://nvd.nist.gov/vuln-metrics/cvss/v3-calculator?vector=AV:N/AC:L/PR:N/UI :R/S:U/C:L/I:L/A:N&amp;version=3.1&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;5.4 中&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;h3 id=&#34;impact&#34;&gt;影响&lt;/h3&gt;&#xA;&lt;p&gt;能够成功利用此漏洞的攻击者可能能够窃取会话 cookie 或代表正在访问该页面的登录用户与 Grafana API 进行交互。&lt;/p&gt;&#xA;&lt;h3 id=&#34;impacted-versions&#34;&gt;受影响的版本&lt;/h3&gt;&#xA;&lt;p&gt;该漏洞影响在以下版本上运行的 Grafana OSS 和 Grafana Enterprise：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Grafana 10.4.0 至 Grafana 10.4.6&lt;/li&gt;&#xA;&lt;li&gt;Grafana 11.0.0 至 Grafana 11.0.2&lt;/li&gt;&#xA;&lt;li&gt;Grafana 11.1.0 至 Grafana 11.1.3&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;已对 Grafana Cloud 应用适当的补丁。&lt;/p&gt;&#xA;&lt;h3 id=&#34;solutions-and-mitigations&#34;&gt;解决方案和缓解措施&lt;/h3&gt;&#xA;&lt;p&gt;如果您的实例存在漏洞，我们强烈建议您尽快升级到已修补的版本之一。&lt;/p&gt;&#xA;&lt;p&gt;作为缓解措施，请确保内容安全策略阻止来自您控制的域之外的源的脚本执行。例如：&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;按钮 x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;将代码复制到剪贴板&#34; width=&#34;14&#34;高度=“13”&gt;&#xA;&lt;span&gt;复制&lt;/span&gt;&#xA;&lt;/按钮&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;内容安全策略：script-src &#39;self&#39;;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;h3 id=&#34;timeline-and-post-incident-review&#34;&gt;时间表和事件后审核&lt;/h3&gt;&#xA;&lt;p&gt;以下是从我们最初提出该问题时开始的详细事件时间表。所有时间均采用 UTC 时间。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;2024-01-31 10:17 A &lt;a href=&#34;https://github.com/grafana/grafana/commit/2ffd56c23b7f734a09627df835b327bf93d5001f&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;已启用提交&lt;/a &gt; &lt;code&gt;queryConfigEnabled&lt;/code&gt; Swagger 标志，引入漏洞。&lt;/li&gt;&#xA;&lt;li&gt;2024-03-06 14:20 - 该漏洞为&lt;a href=&#34;https://github.com/grafana/grafana/releases/tag/v10.4.0&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer &#34;&gt;在 Grafana 版本 10.4.0 中发布。&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;2024-07-10 14:28 - 该漏洞是通过我们的安全赏金计划发现的&lt;/li&gt;&#xA;&lt;li&gt;2024-07-22 07:36 - 评估了漏洞的影响，并合并了修复程序。&lt;/li&gt;&#xA;&lt;li&gt;2024-07-31 17:05 私人发布。&lt;/li&gt;&#xA;&lt;li&gt;2024-08-14 20:30 - 公开发布。&lt;/li&gt;&#xA;&lt;li&gt;2024-08-14 20:45 博客已发布。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;reporting-security-issues&#34;&gt;报告安全问题&lt;/h2&gt;&#xA;&lt;p&gt;如果您认为发现了安全漏洞，请访问我们的&lt;a href=&#34;/legal/report-a-security-issue/?pg=blog&amp;plcmt=body-txt&#34;&gt;报告安全问题页面&lt;/ a&gt; 了解如何发送安全报告。&lt;/p&gt;&#xA;&lt;p&gt;Grafana Labs 将向您发送回复，指示处理您的报告的后续步骤。在对您的报告进行初步回复后，安全团队将随时向您通报修复进度和完整公告，并可能要求您提供其他信息或指导。&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;重要提示：我们要求您在漏洞修复和公布之前不要披露该漏洞，除非您收到 Grafana Labs 安全团队的回复表明您可以这样做。&lt;/em&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;security-announcements&#34;&gt;安全公告&lt;/h2&gt;&#xA;&lt;p&gt;我们在博客上维护一个&lt;a href=&#34;/tags/security/?pg=blog&amp;plcmt=body-txt&#34;&gt;安全类别&lt;/a&gt;，我们将始终在其中发布任何问题的摘要、补救措施和缓解详细信息包含安全修复程序的补丁。您还可以订阅我们的 &lt;a href=&#34;/tags/security/index.xml&#34;&gt;RSS 源&lt;/a&gt;。&lt;/p&gt;</description>
      <pubDate>Wed, 14 Aug 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Prometheus data source update: Redefining our big tent philosophy】Prometheus 数据源更新：重新定义我们的大帐篷理念</title>
      <link>https://grafana.com/blog/2024/08/06/prometheus-data-source-update-redefining-our-big-tent-philosophy/</link>
      <description>【&lt;p&gt;As we continue adding to our growing catalog of more than 100 plugins for Grafana, we have been focused on developing data sources for Grafana that are more purpose-built for the respective technologies.&lt;/p&gt;&#xA;&lt;p&gt;One example has been the recent update to our core Prometheus data source. We have deprecated AWS authentication from the original Prometheus data source, and we created a new dedicated &lt;a href=&#34;/grafana/plugins/grafana-amazonprometheus-datasource/?tab=overview&#34;&gt;Amazon Managed Service for Prometheus plugin&lt;/a&gt; that will specifically cater to the AWS use case. If you are a Grafana user who uses Amazon Managed Prometheus (AMP), you can learn more about how to install or migrate to the new plugin in &lt;a href=&#34;/grafana/plugins/grafana-amazonprometheus-datasource/?tab=installation&#34;&gt;our Amazon Managed Service for Prometheus documentation&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;We plan to do the same update in regards to Prometheus and Microsoft Azure, and we will continue to explore how to make other data sources in the Grafana ecosystem more purpose-built over time.&lt;/p&gt;&#xA;&lt;h2 id=&#34;a-bigger-big-tent&#34;&gt;A bigger &amp;ldquo;big tent&amp;rdquo;&lt;/h2&gt;&#xA;&lt;p&gt;This refined focus on our data sources is a reflection of our commitment to meet our users where they are.&lt;/p&gt;&#xA;&lt;p&gt;Observability today is a complicated space. Companies of all sizes have adopted numerous open source and commercial tools to monitor an ever expanding sprawl of infrastructure, applications, and even physical devices. In our recent &lt;a href=&#34;/observability-survey/?pg=blog&amp;amp;plcmt=body-txt#so.-many.-tools.&#34;&gt;2024 Observability Survey&lt;/a&gt;, 72% of the active Grafana users polled had at least four data sources configured in Grafana. Not to mention, one in 10 Grafana users said they pull in data from &lt;em&gt;more than 50 data sources&lt;/em&gt;.&lt;/p&gt;&#xA;&lt;p&gt;It shouldn&amp;rsquo;t come as a surprise to anyone reading this, that this explosion in observability tools has been a pretty great wave for Grafana Labs to ride thanks to our commitment to our &amp;ldquo;big tent&amp;rdquo; philosophy. We believe that organizations should own their observability strategy, have the freedom to choose their own tools, and have the ability to bring all their data together in one view, no matter where it lives. As a result, Grafana has quickly become the de facto visualization tool for centralized observability.&lt;/p&gt;&#xA;&lt;p&gt;But over the years, we have evolved our understanding of what &amp;ldquo;big tent&amp;rdquo; stands for. While we still prioritize software interoperability, &amp;ldquo;big tent&amp;rdquo; also means surfacing the meaningful differences between data sources so users can form clear expectations and avoid solving for the lowest common denominator. These differences are in the values of each upstream project as much as they are in APIs.&lt;/p&gt;&#xA;&lt;p&gt;In our opinion, data sources with open source and foundation-run projects should be exclusively compatible with the upstream APIs and reflect the project’s vendor neutrality. Vendors adjacent to these open source projects, with their own API and differences, are also invited into the big tent: You can build data sources that are tailored to your specific technology and still reach the Grafana community. (Potential partners can enquire about working directly with us on commercial data source publishing options at &lt;a href=&#34;mailto:integrations@grafana.com&#34;&gt;integrations@grafana.com&lt;/a&gt;.) But whether it comes from a commercial partner or the community, we believe that each data source should have a clear purpose and lean into that goal.&lt;/p&gt;&#xA;&lt;p&gt;Prometheus is a standout example. Throughout a decade of development, this open source project has grown into a gold standard for time series metrics data and is critical infrastructure for businesses across the industry. It remains a vibrant and independent project under the governance of the &lt;a href=&#34;https://www.cncf.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Cloud Native Computing Foundation&lt;/a&gt; (CNCF), with countless open source contributors continuing to evolve the code to support challenges, and a thriving community providing a colossal support apparatus.&lt;/p&gt;&#xA;&lt;p&gt;Users of our core Prometheus data source should expect this data source to closely mirror the functionality developed and supported within this community. The data source itself should not be overcomplicated or otherwise confuse users with proprietary functionality that branches off of the Prometheus project.&lt;/p&gt;&#xA;&lt;p&gt;Meanwhile, the proprietary projects in Prometheus’s orbit should be built and welcomed into the community as separate data sources. This is why we have provided Grafana users who use Amazon Managed Prometheus (AMP) with access to the Amazon Managed Service for Prometheus plugin, which supports platform-specific AWS Signature Version 4 authentication.&lt;/p&gt;&#xA;&lt;h2 id=&#34;whats-next&#34;&gt;What&amp;rsquo;s next&lt;/h2&gt;&#xA;&lt;p&gt;We feel this new &amp;ldquo;big tent&amp;rdquo; approach has been a natural evolution we&amp;rsquo;ve seen in the industry as we continue to field requests for new data sources that span a wide range of licensing models and that support every flavor of platform-specific auth, query language, feature, and more.&lt;/p&gt;&#xA;&lt;p&gt;But interoperability continues to be one of the primary drivers of our roadmap. We maintain &lt;a href=&#34;/grafana/plugins/all-plugins/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;100+ plugins&lt;/a&gt; for Grafana and &lt;a href=&#34;/docs/grafana-cloud/data-configuration/integrations/integration-reference/&#34;&gt;65+ Grafana Cloud integrations&lt;/a&gt; for monitoring third-party tools. Our open source projects, including the core technology behind the Grafana LGTM Stack (&lt;a href=&#34;/oss/loki/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Loki&lt;/a&gt; for logs, &lt;a href=&#34;/oss/grafana?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana&lt;/a&gt; for visualization, &lt;a href=&#34;/oss/tempo/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Tempo&lt;/a&gt; for traces, and &lt;a href=&#34;/oss/mimir/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Mimir&lt;/a&gt; for metrics), are built on &amp;ldquo;big tent&amp;rdquo; principles. We also contribute to OSS projects such as Prometheus (we are the No. 1 company contributor) and OpenTelemetry, with a focus on making the &lt;a href=&#34;/blog/2023/07/20/a-practical-guide-to-data-collection-with-opentelemetry-and-prometheus/&#34;&gt;two projects more interoperable&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;While this is our current thinking on &amp;ldquo;big tent&amp;rdquo; and interoperability, we want to continue to listen to our community, partners, and users to better refine our approach. Please reach out to the team at &lt;a href=&#34;mailto:integrations@grafana.com&#34;&gt;integrations@grafana.com&lt;/a&gt; if you have any feedback, questions, or concerns.&lt;/p&gt;&#xA;&lt;p&gt;We are also delighted to share that we are creating a new &lt;a href=&#34;/docs/grafana-cloud/whats-new/2024-07-24-roadmap-for-new-data-sources/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;public roadmap&lt;/a&gt; that shows all of the date source plugins being built by Grafana Labs, our partners, and our community. Grafana Cloud users can now see our current plans and request new plugins, upvote existing requests, or comment with ideas and requirements. Grafana OSS and Grafana Enterprise users will soon have access to the public roadmap as well.&lt;/p&gt;&#xA;&lt;p&gt;No matter how you engage with our community, we want to hear from you and learn how we can make Grafana&amp;rsquo;s &amp;ldquo;big tent&amp;rdquo; bigger and better.&lt;/p&gt;】&lt;p&gt;随着我们不断向 Grafana 的 100 多个插件添加目录，我们一直专注于为 Grafana 开发更适合各自技术的数据源。&lt;/p&gt;&#xA;&lt;p&gt;一个例子是我们的核心 Prometheus 数据源的最近更新。我们已弃用原始 Prometheus 数据源的 AWS 身份验证，并创建了一个新的专用 &lt;a href=&#34;/grafana/plugins/grafana-amazonprometheus-datasource/?tab=overview&#34;&gt;Amazon Managed Service for Prometheus 插件&lt;/a&gt;这将专门满足 AWS 用例。如果您是使用 Amazon Managed Prometheus (AMP) 的 Grafana 用户，您可以在 &lt;a href=&#34;/grafana/plugins/grafana-amazonprometheus-datasource/?tab=installation 中了解有关如何安装或迁移到新插件的更多信息&#34;&gt;我们的 Amazon Managed Service for Prometheus 文档&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;我们计划对 Prometheus 和 Microsoft Azure 进行相同的更新，并且随着时间的推移，我们将继续探索如何使 Grafana 生态系统中的其他数据源更加专用。&lt;/p&gt;&#xA;&lt;h2 id=&#34;a-bigger-big-tent&#34;&gt;更大的“大帐篷”&lt;/h2&gt;&#xA;&lt;p&gt;对数据源的高度关注体现了我们满足用户需求的承诺。&lt;/p&gt;&#xA;&lt;p&gt;当今的可观察性是一个复杂的空间。各种规模的公司都采用了大量的开源和商业工具来监控不断扩大的基础设施、应用程序甚至物理设备。在我们最近的&lt;a href=&#34;/observability-survey/?pg=blog&amp;plcmt=body-txt#so.-many.-tools.&#34;&gt;2024 年可观测性调查&lt;/a&gt;中，接受调查的活跃 Grafana 用户中有 72% Grafana 中至少配置了四个数据源。更不用说，十分之一的 Grafana 用户表示他们从&lt;em&gt;超过 50 个数据源&lt;/em&gt;提取数据。&lt;/p&gt;&#xA;&lt;p&gt;读到这篇文章的人应该不会感到惊讶，由于我们对“大帐篷”理念的承诺，可观察性工具的爆炸式增长对 Grafana Labs 来说是一个相当大的浪潮。我们认为，组织应该拥有自己的可观察性策略，可以自由选择自己的工具，并且有能力将所有数据整合到一个视图中，无论数据位于何处。因此，Grafana 迅速成为事实上的集中式可观测可视化工具。&lt;/p&gt;&#xA;&lt;p&gt;但多年来，我们对“大帐篷”的含义有了更深的理解。虽然我们仍然优先考虑软件互操作性，但“大帐篷”也意味着暴露数据源之间有意义的差异，以便用户可以形成明确的期望，并避免解决最低公分母。这些差异既存在于每个上游项目的价值中，也存在于 API 中。&lt;/p&gt;&#xA;&lt;p&gt;我们认为，开源和基金会运行的项目的数据源应该与上游 API 完全兼容，并体现项目的供应商中立性。与这些开源项目相邻的供应商都有自己的API 和差异也被邀请进入大帐篷：您可以构建适合您的特定技术的数据源，并且仍然可以到达 Grafana 社区。 （潜在合作伙伴可以通过 &lt;a href=&#34;mailto:integrations@grafana.com&#34;&gt;integrations@grafana.com&lt;/a&gt; 询问是否直接与我们就商业数据源发布选项进行合作。）但它是否来自商业合作伙伴或社区，我们认为每个数据源都应该有明确的目的并倾向于该目标。&lt;/p&gt;&#xA;&lt;p&gt;普罗米修斯是一个突出的例子。经过十年的发展，这个开源项目已经发展成为时间序列指标数据的黄金标准，并且是整个行业企业的关键基础设施。在&lt;a href=&#34;https://www.cncf.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;云原生计算基金会&lt;/a&gt; (CNCF ），无数开源贡献者不断改进代码以支持挑战，并且蓬勃发展的社区提供了巨大的支持工具。&lt;/p&gt;&#xA;&lt;p&gt;我们核心 Prometheus 数据源的用户应该期望该数据源能够密切反映该社区内开发和支持的功能。数据源本身不应过于复杂，否则会使用户对 Prometheus 项目分支的专有功能感到困惑。&lt;/p&gt;&#xA;&lt;p&gt;与此同时，普罗米修斯轨道上的专有项目应该作为单独的数据源构建并欢迎进入社区。因此，我们为使用 Amazon Managed Prometheus (AMP) 的 Grafana 用户提供了对 Amazon Managed Service for Prometheus 插件的访问权限，该插件支持特定于平台的 AWS 签名版本 4 身份验证。&lt;/p&gt;&#xA;&lt;h2 id=&#34;whats-next&#34;&gt;下一步是什么&lt;/h2&gt;&#xA;&lt;p&gt;我们认为，这种新的“大帐篷”方法是我们在行业中看到的自然演变，因为我们不断满足对新数据源的请求，这些数据源涵盖广泛的许可模型并支持各种平台 -特定的身份验证、查询语言、功能等等。&lt;/p&gt;&#xA;&lt;p&gt;但互操作性仍然是我们路线图的主要驱动因素之一。我们为 Grafana 和 &lt;a href=&#34;/docs/grafana-cloud/data- 维护&lt;a href=&#34;/grafana/plugins/all-plugins/?pg=blog&amp;plcmt=body-txt&#34;&gt;100 多个插件&lt;/a&gt; configuration/integrations/integration-reference/&#34;&gt;65 多个 Grafana Cloud 集成&lt;/a&gt;，用于监控第三方工具。我们的开源项目，包括 Grafana LGTM Stack 背后的核心技术（&lt;a href=&#34;/oss/loki/?pg=blog&amp;plcmt=body-txt&#34;&gt;Loki&lt;/a&gt; 用于日志、&lt;a href=&#34;/oss /grafana?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana&lt;/a&gt; 用于可视化，&lt;a href=&#34;/oss/tempo/?pg=blog&amp;plcmt=body-txt&#34;&gt;Tempo&lt;/a&gt; 用于跟踪，以及 &lt; a href=&#34;/oss/mimir/?pg=blog&amp;plcmt=body-txt&#34;&gt;Mimir&lt;/a&gt; 用于指标），是建立在“大帐篷”原则之上的。我们还为 Prometheus（我们是排名第一的公司贡献者）和 OpenT 等 OSS 项目做出贡献elemetry，重点是使&lt;a href=&#34;/blog/2023/07/20/a-practical-guide-to-data-collection-with-opentelemetry-and-prometheus/&#34;&gt;两个项目更具互操作性&lt;/一个&gt;.&lt;/p&gt;&#xA;&lt;p&gt;虽然这是我们目前对“大帐篷”和互操作性的想法，但我们希望继续倾听社区、合作伙伴和用户的意见，以更好地完善我们的方法。如果您有任何反馈、问题或疑虑，请通过 &lt;a href=&#34;mailto:integrations@grafana.com&#34;&gt;integrations@grafana.com&lt;/a&gt; 与团队联系。&lt;/p&gt;&#xA;&lt;p&gt;我们还很高兴地告诉大家，我们正在创建一个新的&lt;a href=&#34;/docs/grafana-cloud/whats-new/2024-07-24-roadmap-for-new-data-sources/?pg= blog&amp;plcmt=body-txt&#34;&gt;公共路线图&lt;/a&gt;显示了 Grafana Labs、我们的合作伙伴和我们的社区正在构建的所有日期源插件。 Grafana Cloud 用户现在可以查看我们当前的计划并请求新插件、对现有请求进行投票或评论想法和要求。 Grafana OSS 和 Grafana Enterprise 用户很快也将可以访问公共路线图。&lt;/p&gt;&#xA;&lt;p&gt;无论您如何与我们的社区互动，我们都希望听到您的意见并了解如何使 Grafana 的“大帐篷”变得更大更好。&lt;/p&gt;</description>
      <pubDate>Tue, 06 Aug 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Behind the scenes of the OpenTelemetry Governance Committee】OpenTelemetry 治理委员会的幕后故事</title>
      <link>https://grafana.com/blog/2024/08/16/behind-the-scenes-of-the-opentelemetry-governance-committee/</link>
      <description>【&lt;p&gt;As a principal engineer at Grafana Labs, my focus is on &lt;a href=&#34;https://opentelemetry.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;OpenTelemetry&lt;/a&gt;: writing code or maintaining OTel Collector components and tooling, helping out with our recent security audit, and building bridges between people with similar ideas — all with the ultimate goal of helping the OTel community, as a whole, succeed.&lt;/p&gt;&#xA;&lt;p&gt;For nearly three years now, I’ve also been a member of the &lt;a href=&#34;https://github.com/open-telemetry/community/blob/main/community-members.md#governance-committee&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;OpenTelemetry Governance Committee (GC)&lt;/a&gt;. I was first elected in October 2021, and then re-elected in October 2023 for another two-year term. OpenTelemetry’s GC members, along with the &lt;a href=&#34;https://github.com/open-telemetry/community/blob/main/community-members.md#technical-committee&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Technical Committee (TC)&lt;/a&gt;, serve as the official maintainers of the project from the perspective of the CNCF.&lt;/p&gt;&#xA;&lt;p&gt;While the TC &lt;a href=&#34;https://github.com/open-telemetry/community/blob/main/tech-committee-charter.md&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;focuses on technical matters&lt;/a&gt; — such as determining acceptable changes to the specifications, deciding on code donations, and resolving technical disagreements — the GC &lt;a href=&#34;https://github.com/open-telemetry/community/blob/main/governance-charter.md&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;takes on a more strategic role&lt;/a&gt;. This involves defining the project’s overall roadmap and ensuring its continued success from all perspectives, including our original goal of providing a vendor-neutral instrumentation and collection framework.&lt;/p&gt;&#xA;&lt;p&gt;I thought it would be useful to share a glimpse into the role and responsibilities of a GC member, based on my personal experience. My hope is this can help serve as a guide to select candidates in upcoming elections — and to provide prospective candidates with more insight into the role. That said, it&amp;rsquo;s important to note that other GC members have different experiences and responsibilities. While not every task or responsibility listed here happens daily, each has occurred at least once over the past three years for me.&lt;/p&gt;&#xA;&lt;h2 id=&#34;representing-the-opentelemetry-project&#34;&gt;Representing the OpenTelemetry project&lt;/h2&gt;&#xA;&lt;p&gt;I frequently attend and &lt;a href=&#34;https://github.com/jpkrohling/talks&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;speak at conferences&lt;/a&gt;, participate in podcasts, review blog posts, and engage with individuals from various companies. This helps me understand OpenTelemetry from different perspectives — users, library developers, potential contributors, and proponents of new project areas. Representing the project requires a good grasp of its direction and helping others while considering the project&amp;rsquo;s best interests.&lt;/p&gt;&#xA;&lt;p&gt;Being a representative is a multifaceted role. It involves not just public speaking and writing, but also engaging in one-on-one conversations to understand the needs and concerns of our community. This role has given me the opportunity to network with industry leaders, learn about emerging trends, and advocate for the adoption and advancement of OpenTelemetry.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;h4 id=&#34;being-a-representative-is-a-multifaceted-role-it-involves-not-just-public-speaking-and-writing-but-also-engaging-in-one-on-one-conversations-to-understand-the-needs-and-concerns-of-our-community&#34;&gt;&lt;em&gt;&amp;ldquo;Being a representative is a multifaceted role. It involves not just public speaking and writing, but also engaging in one-on-one conversations to understand the needs and concerns of our community.&amp;rdquo;&lt;/em&gt;&lt;/h4&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;There have been moments where I need to pause and reflect on the interests I could be representing on a specific matter. I must make it clear in conversations whether I am speaking as a Grafana Labs employee, an OpenTelemetry Collector leader, a representative of the wider open source observability ecosystem, or a GC member. It’s natural to have different perspectives depending on the role I’m embodying, but it’s crucial to identify which &amp;ldquo;hat&amp;rdquo; I am wearing during any given discussion, and to ensure that my opinions are appropriately aligned with that role.&lt;/p&gt;&#xA;&lt;h2 id=&#34;reviewing-project-policies&#34;&gt;Reviewing project policies&lt;/h2&gt;&#xA;&lt;p&gt;The OpenTelemetry project is like a living being, growing every day. As a GC member, one of my responsibilities is to review and update our project policies to ensure they remain relevant and effective. This involves identifying gaps in our current policies, drafting new ones when necessary, and updating existing ones to reflect the evolving needs of the project.&lt;/p&gt;&#xA;&lt;p&gt;Two key areas I’ve worked on are our &lt;a href=&#34;https://github.com/open-telemetry/community/blob/main/mission-vision-values.md&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;community values&lt;/a&gt; and naming policy recommendations for external projects and components. Reviewing our values ensures we promote desired behaviors and discourage negative ones, fostering a collaborative and respectful environment. Additionally, we establish naming policy recommendations for projects and components in our ecosystem to prevent confusion among our end users and ensure our terminology is clear and distinct. This helps maintain the integrity and coherence of the OpenTelemetry project.&lt;/p&gt;&#xA;&lt;h2 id=&#34;sponsoring-sigs&#34;&gt;Sponsoring SIGs&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/open-telemetry/community/blob/main/project-management.md&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Anyone can propose&lt;/a&gt; a new &lt;a href=&#34;https://github.com/open-telemetry/community/blob/main/README.md#special-interest-groups&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;SIG (Special Interest Group)&lt;/a&gt; in OpenTelemetry. These groups are dedicated to advancing a specific part of the OTel project, such as new signals, language SDKs/APIs, or semantic conventions. Proposals need two sponsors: one from the TC and one from the GC. Being a GC member means staying informed about current and proposed SIGs and sponsoring initiatives that are essential to the project&amp;rsquo;s future. Sponsorship isn’t just a formality; it involves active participation in SIG meetings and discussions, and, ideally, contributing through coding, documentation, or issue triaging.&lt;/p&gt;&#xA;&lt;p&gt;Sponsoring a SIG is a rewarding experience. It has allowed me to nurture innovative ideas and help them grow into integral parts of the OTel project. Being involved from the inception of SIGs like Profiling, Security, and Contributor Experience has also given me a unique perspective on the challenges and triumphs of new initiatives. Some SIGs need only a few reviews and ideas about how to best navigate the community, while others require more active work in recruiting team members or implementation.&lt;/p&gt;&#xA;&lt;h2 id=&#34;check-ins-with-sig-maintainers&#34;&gt;Check-ins with SIG maintainers&lt;/h2&gt;&#xA;&lt;p&gt;A relatively new process in the OpenTelemetry community is the &lt;a href=&#34;https://github.com/open-telemetry/community/blob/main/gc-check-ins.md&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;GC monthly check-in&lt;/a&gt; with SIG maintainers. Each GC member was asked to pick about 4 SIGs, and then act as a liaison between those SIGs and the GC. Once a month, I ask SIG maintainers from Collector, Operator, Security, and Go Auto-Instrumentation questions, such as:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Do you have any specific issues within your SIG that would require GC intervention?&lt;/li&gt;&#xA;&lt;li&gt;Are you happy with the current balance of contributors/triagers/approvers/maintainers?&lt;/li&gt;&#xA;&lt;li&gt;What’s one thing the GC can help with to make your life easier?&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;These responses are confidential, and maintainers know they can approach me with any problems, like when there’s a conflict between community members. While I can’t promise to solve every issue, I am committed to working towards resolutions. These check-ins provide a structured way to ensure every SIG is heard and supported. They also help identify patterns or recurring issues that might need broader GC attention.&lt;/p&gt;&#xA;&lt;h2 id=&#34;gc-meetings&#34;&gt;GC meetings&lt;/h2&gt;&#xA;&lt;p&gt;GC members attend a &lt;a href=&#34;https://docs.google.com/document/d/1-23Sf7-xZK3OL5Ogv2pK0NP9YotlSa0PKU9bvvtQwp8&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;weekly call&lt;/a&gt;, and also have the option to attend an annual in-person leadership summit. We hold specification and project triage sessions at different times to accommodate various time zones.&lt;/p&gt;&#xA;&lt;p&gt;These meetings are essential to align our efforts and make strategic decisions. Despite the challenges posed by time zones, the dedication of GC members ensures we maintain a cohesive and effective governance structure. The annual leadership summit, though optional, provides a valuable opportunity for in-depth discussions and team building.&lt;/p&gt;&#xA;&lt;h2 id=&#34;conflict-mediation&#34;&gt;Conflict mediation&lt;/h2&gt;&#xA;&lt;p&gt;Every community has its challenges, and OpenTelemetry is no exception. With people from diverse backgrounds and varying personal and professional interests working together, conflicts are inevitable. As a GC member, I actively mediate community conflicts, listen to multiple perspectives, take notes during meetings, and draft documents summarizing my understanding of the situations.&lt;/p&gt;&#xA;&lt;p&gt;While conflict mediation isn’t my favorite task, addressing these issues is crucial for the project&amp;rsquo;s future. Ignoring conflicts in the hope they will disappear is not an option. Mediation involves not only resolving disputes, but fostering a culture of open communication and mutual respect. By doing so, we ensure that our community remains a welcoming and productive environment for all contributors.&lt;/p&gt;&#xA;&lt;h2 id=&#34;reflections-on-the-role&#34;&gt;Reflections on the role&lt;/h2&gt;&#xA;&lt;p&gt;Over the past three years, I’ve had the privilege of serving on the OpenTelemetry GC. I’m fortunate to work for a company that supports this role (&lt;a href=&#34;/about/careers/open-positions/&#34;&gt;we&amp;rsquo;re hiring, by the way!&lt;/a&gt;), allowing me to dedicate my full-time efforts to OpenTelemetry. This enables me to carry out these tasks as part of my regular workday.&lt;/p&gt;&#xA;&lt;p&gt;I have had some personal conflicts, however. A few times, I considered not running for re-election so I could focus more on my engineering contributions to the project. I have to admit that I still struggle to find the right balance between my GC responsibilities and my engineering work. However, one thing has become very clear to me over these past three years: more important than my individual contributions is ensuring that my efforts can scale. This means mentoring the next generation of potential leaders in the OpenTelemetry community, and thoroughly documenting my activities so others can take over those tasks.&lt;/p&gt;&#xA;&lt;p&gt;By sharing my experience, I hope prospective candidates will better understand the GC role and be able to answer a crucial question posed by a former GC colleague: &amp;ldquo;What do you expect to do on the GC that you can’t do as a regular contributor?&amp;rdquo; While this role might seem demanding, we need individuals from diverse areas of the ecosystem who are committed to the success of the project, even if they can only dedicate a few hours per week. I do believe that being part of the GC should be part of your day job, but it certainly doesn’t need to be your full-time job.&lt;/p&gt;&#xA;&lt;p&gt;I also hope this post provides voters with insights into which qualities to look for in candidates during the next GC elections. Choosing the right candidates is vital for the continued success and growth of OpenTelemetry. Look for individuals who are not only technically competent, but demonstrate leadership, empathy, and a commitment to the community.&lt;/p&gt;】&lt;p&gt;作为 Grafana Labs 的首席工程师，我的重点是 &lt;a href=&#34;https://opentelemetry.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;OpenTelemetry&lt;/a&gt;：编写代码或维护 OTel Collector 组件和工具，帮助我们最近的安全审核，并在具有相似想法的人们之间建立桥梁 - 所有这些的最终目标是帮助整个 OTel 社区取得成功。&lt;/p&gt;&#xA;&lt;p&gt;近三年来，我一直是 &lt;a href=&#34;https://github.com/open-telemetry/community/blob/main/community-members.md#governance-committee 的成员&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;OpenTelemetry 治理委员会 (GC)&lt;/a&gt;。我于 2021 年 10 月首次当选，并于 2023 年 10 月再次当选，任期两年。 OpenTelemetry 的 GC 成员，以及 &lt;a href=&#34;https://github.com/open-telemetry/community/blob/main/community-members.md#technical-committee&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer &#34;&gt;技术委员会（TC）&lt;/a&gt;，从CNCF的角度作为项目的官方维护者。&lt;/p&gt;&#xA;&lt;p&gt;虽然 TC &lt;a href=&#34;https://github.com/open-telemetry/community/blob/main/tech-committee-charter.md&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;重点关注技术问题&lt;/a&gt; - 例如确定可接受的规范更改、决定代码捐赠以及解决技术分歧 - GC &lt;a href=&#34;https://github.com/open-telemetry/community/blob/ main/governance-charter.md&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;承担更具战略性的角色&lt;/a&gt;。这涉及定义项目的总体路线图并确保其从各个角度持续取得成功，包括我们提供供应商中立的仪器和收集框架的最初目标。&lt;/p&gt;&#xA;&lt;p&gt;我认为根据我的个人经验，分享一下 GC 成员的角色和职责会很有用。我希望这可以作为在即将举行的选举中选择候选人的指南，并让潜在候选人更深入地了解这一角色。尽管如此，值得注意的是，其他 GC 成员也有不同的经验和职责。虽然并非此处列出的每项任务或责任每天都会发生，但对我来说，每项任务或责任在过去三年中至少发生过一次。&lt;/p&gt;&#xA;&lt;h2 id=&#34;representing-the-opentelemetry-project&#34;&gt;代表 OpenTelemetry 项目&lt;/h2&gt;&#xA;&lt;p&gt;我经常参加&lt;a href=&#34;https://github.com/jpkrohling/talks&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;会议发言&lt;/a&gt;、参与播客、评论博客发布帖子，并与来自不同公司的个人进行交流。这有助于我从不同的角度理解 OpenTelemetry——用户、库开发人员、潜在贡献者和新项目领域的支持者。代表项目需要很好地把握项目的方向并帮助他人，同时考虑项目的最大利益。&lt;/p&gt;&#xA;&lt;p&gt;作为代表是一个多方面的角色。它不仅涉及公开演讲和写作，还涉及进行一对一的对话以了解我们社区的需求和担忧。这一职位使我有机会与行业领导者建立联系，了解新兴趋势，并倡导 OpenTelemetry 的采用和进步。&lt;/p&gt;&#xA;&lt;块引用&gt;&#xA;&lt;h4 id=&#34;being-a-representative-is-a-multifaceted-role-it-involves-not-just-public-speaking-and-writing-but-also-engaging-in-one-on-one-conversations -了解我们社区的需求和担忧&#34;&gt;&lt;em&gt;“作为代表是一个多方面的角色。它不仅涉及公开演讲和写作，还涉及进行一对一的对话，以了解我们社区的需求和担忧。”&lt;/em&gt;&lt;/h4&gt;&#xA;&lt;/块引用&gt;&#xA;&lt;p&gt;有时我需要停下来思考我在特定问题上可以代表的利益。我必须在对话中明确表明我是作为 Grafana Labs 员工、OpenTelemetry Collector 领导者、更广泛的开源可观测性生态系统的代表还是 GC 成员来发言。根据我所扮演的角色，有不同的观点是很自然的，但在任何特定的讨论中确定我戴的“帽子”并确保我的观点与该角色适当一致是至关重要的。&lt;/p&gt;&#xA;&lt;h2 id=&#34;reviewing-project-policies&#34;&gt;审核项目政策&lt;/h2&gt;&#xA;&lt;p&gt;OpenTelemetry 项目就像一个生命体，每天都在成长。作为 GC 成员，我的职责之一是审查和更新我们的项目政策，以确保它们保持相关性和有效性。这包括找出我们当前政策中的差距，在必要时起草新政策，以及更新现有政策以反映项目不断变化的需求。&lt;/p&gt;&#xA;&lt;p&gt;我工作过的两个关键领域是我们的 &lt;a href=&#34;https://github.com/open-telemetry/community/blob/main/mission-vision-values.md&#34; target=&#34;_blank&#34; rel =&#34;noopener noreferrer&#34;&gt;社区价值观&lt;/a&gt;以及外部项目和组件的命名政策建议。审视我们的价值观可以确保我们促进理想的行为并阻止消极的行为，从而营造一个协作和尊重的环境。此外，我们还为生态系统中的项目和组件制定命名政策建议，以防止最终用户之间产生混淆，并确保我们的术语清晰明确。这有助于保持 OpenTelemetry 项目的完整性和连贯性。&lt;/p&gt;&#xA;&lt;h2 id=&#34;sponsoring-sigs&#34;&gt;赞助 SIG&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/open-telemetry/community/blob/main/project-management.md&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;任何人都可以提议&lt;/a &gt; 一个新的 &lt;a href=&#34;https://github.com/open-telemetry/community/blob/main/README.md#special-interest-groups&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;SIG ( OpenTelemetry 中的特别兴趣小组）&lt;/a&gt;。这些小组致力于推进 OTel 项目的特定部分，例如新信号、语言 SDK/API，或语义约定。提案需要两名发起人：一名来自 TC，一名来自 GC。成为 GC 成员意味着随时了解当前和拟议的 SIG 以及对项目未来至关重要的赞助计划。赞助不仅仅是一种形式；而是一种形式。它涉及积极参与 SIG 会议和讨论，并且最好通过编码、文档或问题分类做出贡献。&lt;/p&gt;&#xA;&lt;p&gt;赞助 SIG 是一次有益的经历。它让我能够培育创新想法，并帮助它们成长为 OTel 项目不可或缺的一部分。从分析、安全和贡献者体验等 SIG 一开始就参与其中，也让我对新举措的挑战和成功有了独特的视角。一些 SIG 只需要一些关于如何最好地驾驭社区的评论和想法，而另一些 SIG 则需要在招募团队成员或实施方面进行更积极的工作。&lt;/p&gt;&#xA;&lt;h2 id=&#34;check-ins-with-sig-maintainers&#34;&gt;与 SIG 维护者联系&lt;/h2&gt;&#xA;&lt;p&gt;OpenTelemetry 社区中一个相对较新的流程是 &lt;a href=&#34;https://github.com/open-telemetry/community/blob/main/gc-check-ins.md&#34; target=&#34;_blank&#34; rel =&#34;noopener noreferrer&#34;&gt;GC 每月与 SIG 维护者签到&lt;/a&gt;。每个 GC 成员都被要求挑选大约 4 个 SIG，然后充当这些 SIG 和 GC 之间的联络人。我每月一次向 Collector、Operator、Security 和 Go Auto-Instrumentation 的 SIG 维护人员询问一次问题，例如：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;您的 SIG 中是否存在需要 GC 干预的具体问题？&lt;/li&gt;&#xA;&lt;li&gt;您对当前贡献者/分类者/批准者/维护者的平衡感到满意吗？&lt;/li&gt;&#xA;&lt;li&gt;GC 可以帮助您让生活变得更轻松的一件事是什么？&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;这些回复是保密的，维护人员知道他们可以向我提出任何问题，例如当社区成员之间存在冲突时。虽然我不能保证解决所有问题，但我致力于努力解决问题。这些签到提供了一种结构化的方式，以确保每个 SIG 都能得到倾听和支持。它们还有助于识别可能需要更广泛的 GC 关注的模式或重复出现的问题。&lt;/p&gt;&#xA;&lt;h2 id=&#34;gc-meetings&#34;&gt;GC 会议&lt;/h2&gt;&#xA;&lt;p&gt;GC 成员参加&lt;a href=&#34;https://docs.google.com/document/d/1-23Sf7-xZK3OL5Ogv2pK0NP9YotlSa0PKU9bvvtQwp8&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;每周电话会议&lt;/a&gt; ，并且还可以选择参加年度领导力峰会。我们在不同时间举行规范和项目分类会议，以适应不同时区。&lt;/p&gt;&#xA;&lt;p&gt;这些会议对于协调我们的努力和做出战略决策至关重要。尽管存在时区带来的挑战，GC 成员的奉献精神确保我们保持有凝聚力和有效的治理结构。年度领导力峰会虽然是可选的，但却为深入讨论和团队建设提供了宝贵的机会。&lt;/p&gt;&#xA;&lt;h2 id=&#34;conflict-mediation&#34;&gt;冲突调解&lt;/h2&gt;&#xA;&lt;p&gt;每个社区有其挑战，OpenTelemetry 也不例外。当来自不同背景、具有不同个人和职业兴趣的人们一起工作时，冲突是不可避免的。作为GC成员，我积极调解社区冲突，倾听多种观点，在会议期间做笔记，并起草文件总结我对情况的理解。&lt;/p&gt;&#xA;&lt;p&gt;虽然冲突调解不是我最喜欢的任务，但解决这些问题对于项目的未来至关重要。忽视冲突并希望它们会消失是不可行的。调解不仅涉及解决争端，还涉及培育开放沟通和相互尊重的文化。通过这样做，我们确保我们的社区仍然为所有贡献者提供一个热情且富有成效的环境。&lt;/p&gt;&#xA;&lt;h2 id=&#34;reflections-on-the-role&#34;&gt;对角色的思考&lt;/h2&gt;&#xA;&lt;p&gt;在过去的三年里，我有幸在 OpenTelemetry GC 上工作。我很幸运能够在一家支持这一职位的公司工作（&lt;a href=&#34;/about/careers/open-positions/&#34;&gt;顺便说一下，我们正在招聘！&lt;/a&gt;），让我能够奉献自己的全职致力于 OpenTelemetry。这使我能够将这些任务作为日常工作的一部分来执行。&lt;/p&gt;&#xA;&lt;p&gt;但是，我遇到了一些个人冲突。有几次，我考虑不竞选连任，这样我就可以更多地关注我对项目的工程贡献。我必须承认，我仍然在努力在 GC 职责和工程工作之间找到适当的平衡。然而，在过去的三年里，我变得非常清楚一件事：比我个人的贡献更重要的是确保我的努力能够扩大规模。这意味着指导 OpenTelemetry 社区的下一代潜在领导者，并彻底记录我的活动，以便其他人可以接管这些任务。&lt;/p&gt;&#xA;&lt;p&gt;通过分享我的经验，我希望未来的候选人能够更好地理解 GC 的角色，并能够回答前 GC 同事提出的一个关键问题：“您希望在 GC 上做什么，而您无法做到这一点？”定期贡献者？”虽然这个角色似乎要求很高，但我们需要来自生态系统不同领域的个人致力于项目的成功，即使他们每周只能投入几个小时。我确实认为，成为 GC 的一员应该成为您日常工作的一部分，但它当然不需要成为您的全职工作。&lt;/p&gt;&#xA;&lt;p&gt;我还希望这篇文章能让选民深入了解在下一次地方选区选举中应寻找候选人的哪些品质。选择合适的候选人对于 OpenTelemetry 的持续成功和发展至关重要。寻找不仅具有技术能力，而且表现出领导能力、同理心和对社区的承诺的个人。&lt;/p&gt;</description>
      <pubDate>Fri, 16 Aug 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Grafana Alloy 1.3 release: Debug pipelines in real time】Grafana Alloy 1.3 版本：实时调试管道</title>
      <link>https://grafana.com/blog/2024/08/05/grafana-alloy-1.3-release-debug-pipelines-in-real-time/</link>
      <description>【&lt;p&gt;&lt;a href=&#34;https://github.com/grafana/alloy/releases/tag/v1.3.0&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Grafana Alloy 1.3&lt;/a&gt; is here!&lt;/p&gt;&#xA;&lt;p&gt;First introduced &lt;a href=&#34;/blog/2024/04/09/grafana-alloy-opentelemetry-collector-with-prometheus-pipelines/&#34;&gt;earlier this year&lt;/a&gt;, Alloy is our open source distribution of the OpenTelemetry Collector. It has native pipelines for OpenTelemetry and Prometheus telemetry formats, and it uses the same components, code, and concepts that were previously introduced in Grafana Agent Flow.&lt;/p&gt;&#xA;&lt;p&gt;This new release introduces &lt;a href=&#34;/docs/alloy/v1.3/troubleshoot/debug/&#34;&gt;live debugging&lt;/a&gt;, enhancing debugging capabilities across key &lt;a href=&#34;/docs/alloy/latest/get-started/components/&#34;&gt;components&lt;/a&gt;, which are the building blocks of Alloy. This feature allows for real-time monitoring of your data pipelines so you can quickly:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Visualize data transformations&lt;/li&gt;&#xA;&lt;li&gt;Identify and isolate errors&lt;/li&gt;&#xA;&lt;li&gt;Analyze pipeline behavior&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Live debugging makes troubleshooting more efficient and provides deeper insights into data flow so you can streamline your development and optimization processes.&lt;/p&gt;&#xA;&lt;h2 id=&#34;configure-live-debugging&#34;&gt;Configure live debugging&lt;/h2&gt;&#xA;&lt;p&gt;Live debugging is disabled by default to avoid accidentally displaying sensitive telemetry data. You can enable it by adding the &lt;a href=&#34;/docs/alloy/v1.3/reference/config-blocks/livedebugging/&#34;&gt;live debugging&lt;/a&gt; block to your config:&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet &#34;&gt;&lt;div class=&#34;lang-toolbar&#34;&gt;&#xA;&lt;span class=&#34;lang-toolbar__item&#34;&gt;alloy&lt;/span&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;button x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;Copy code to clipboard&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;Copy&lt;/span&gt;&#xA;&lt;/button&gt;&#xA;&lt;/span&gt;&#xA;&lt;div class=&#34;lang-toolbar__border&#34;&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet &#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-alloy&#34;&gt;livedebugging {&#xA;enabled = true&#xA;}&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;p&gt;Since this feature is experimental, you will need to set the stability level to &lt;code&gt;experimental&lt;/code&gt;:&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet &#34;&gt;&lt;div class=&#34;lang-toolbar&#34;&gt;&#xA;&lt;span class=&#34;lang-toolbar__item&#34;&gt;bash&lt;/span&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;button x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;Copy code to clipboard&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;Copy&lt;/span&gt;&#xA;&lt;/button&gt;&#xA;&lt;/span&gt;&#xA;&lt;div class=&#34;lang-toolbar__border&#34;&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet &#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-bash&#34;&gt;alloy run config.alloy --stability.level experimental&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;p&gt;Visit http://localhost:12345/ to open the UI. Press the &lt;strong&gt;Live Debugging&lt;/strong&gt; button on a component page to start a session for that component.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1791px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&#xA;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/alloy-1-3/live-debugging-in-ui.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/alloy-1-3/live-debugging-in-ui.png&#34;data-srcset=&#34;/media/blog/alloy-1-3/live-debugging-in-ui.png?w=320 320w, /media/blog/alloy-1-3/live-debugging-in-ui.png?w=550 550w, /media/blog/alloy-1-3/live-debugging-in-ui.png?w=750 750w, /media/blog/alloy-1-3/live-debugging-in-ui.png?w=900 900w, /media/blog/alloy-1-3/live-debugging-in-ui.png?w=1040 1040w, /media/blog/alloy-1-3/live-debugging-in-ui.png?w=1240 1240w, /media/blog/alloy-1-3/live-debugging-in-ui.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;&#34;&#xA;width=&#34;1791&#34;&#xA;height=&#34;1190&#34;&#xA;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/alloy-1-3/live-debugging-in-ui.png&#34;&#xA;alt=&#34;&#34;&#xA;width=&#34;1791&#34;&#xA;height=&#34;1190&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;/a&gt;&#xA;&lt;/figure&gt;&#xA;&lt;p&gt;You can scroll through, filter, and sample the data. You can also manage the flow using the pause/unpause feature and the &lt;strong&gt;Clear&lt;/strong&gt; button.&lt;/p&gt;&#xA;&lt;p&gt;The following components support live debugging in this version:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;loki.process&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;loki.relabel&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;otelcol.processor&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;otelcol.receiver&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;prometheus.relabel&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Both &lt;code&gt;otelcol.processor&lt;/code&gt; and &lt;code&gt;otelcol.receiver&lt;/code&gt; include all corresponding components.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h2 id=&#34;build-your-pipelines-step-by-step&#34;&gt;Build your pipelines step by step&lt;/h2&gt;&#xA;&lt;p&gt;In the previous version of Alloy, you had to build your entire pipeline and check your databases in the hope that the telemetry data was delivered in the expected format. But with live debugging, you can add components incrementally and verify that the data meets your expectations before sending it to the cloud.&lt;/p&gt;&#xA;&lt;p&gt;Watch the following videos to learn more about how to build pipelines with live debugging. In the first one, you&amp;rsquo;ll see how to send Prometheus metrics to Grafana Cloud using Alloy.&lt;/p&gt;&#xA;&lt;div class=&#34;shortcode youtube&#34;&gt;&#xA;&lt;iframe src=&#34;https://www.youtube.com/embed/_MbB8IVKMfw?rel=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;And if you&amp;rsquo;re using OpenTelemetry, this second video will show you how to receive OpenTelemetry Protocol (OTLP) metrics from your application and send them to Grafana Cloud with the help of live debugging.&lt;/p&gt;&#xA;&lt;div class=&#34;shortcode youtube&#34;&gt;&#xA;&lt;iframe src=&#34;https://www.youtube.com/embed/IRqQEzc0kvA?rel=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&#xA;&lt;h2 id=&#34;learn-more-about-grafana-alloy&#34;&gt;Learn more about Grafana Alloy&lt;/h2&gt;&#xA;&lt;p&gt;To learn more about other features in the latest release, please refer to our &lt;a href=&#34;/docs/alloy/v1.3/&#34;&gt;Grafana Alloy documentation&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;As always, we’d love to hear from you, so feel free to drop by our &lt;a href=&#34;https://slack.grafana.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Grafana Labs community Slack&lt;/a&gt; or check out the &lt;a href=&#34;https://github.com/grafana/alloy&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Alloy repo&lt;/a&gt; directly. We look forward to your comments and feedback!&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;/products/cloud/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Cloud &lt;/a&gt;is the easiest way to get started with metrics, logs, traces, dashboards, and more. We have a generous forever-free tier and plans for every use case. &lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Sign up for free now!&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;】&lt;p&gt;&lt;a href=&#34;https://github.com/grafana/alloy/releases/tag/v1.3.0&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Grafana Alloy 1.3&lt;/a&gt; 就在这里！ &lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;/blog/2024/04/09/grafana-alloy-opentelemetry-collector-with-prometheus-pipelines/&#34;&gt;今年早些时候&lt;/a&gt;首次推出，Alloy 是我们OpenTelemetry 收集器。它具有适用于 OpenTelemetry 和 Prometheus 遥测格式的本机管道，并且使用之前在 Grafana Agent Flow 中引入的相同组件、代码和概念。&lt;/p&gt;&#xA;&lt;p&gt;此新版本引入了&lt;a href=&#34;/docs/alloy/v1.3/troubleshoot/debug/&#34;&gt;实时调试&lt;/a&gt;，增强了关键&lt;a href=&#34;/docs/alloy/latest 的调试功能/get-started/components/&#34;&gt;组件&lt;/a&gt;，它们是 Alloy 的构建块。此功能允许实时监控您的数据管道，以便您可以快速：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;可视化数据转换&lt;/li&gt;&#xA;&lt;li&gt;识别并隔离错误&lt;/li&gt;&#xA;&lt;li&gt;分析管道行为&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;实时调试使故障排除更加高效，并提供对数据流的更深入洞察，以便您可以简化开发和优化流程。&lt;/p&gt;&#xA;&lt;h2 id=&#34;configure-live-debugging&#34;&gt;配置实时调试&lt;/h2&gt;&#xA;&lt;p&gt;默认情况下禁用实时调试，以避免意外显示敏感遥测数据。您可以通过将&lt;a href=&#34;/docs/alloy/v1.3/reference/config-blocks/livedebugging/&#34;&gt;实时调试&lt;/a&gt;块添加到您的配置中来启用它：&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet&#34;&gt;&lt;div class=&#34;lang-toolbar&#34;&gt;&#xA;&lt;span class=&#34;lang-toolbar__item&#34;&gt;合金&lt;/span&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;按钮 x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;将代码复制到剪贴板&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;复制&lt;/span&gt;&#xA;&lt;/按钮&gt;&#xA;&lt;/span&gt;&#xA;&lt;div class=&#34;lang-toolbar__border&#34;&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-alloy&#34;&gt;实时调试 {&#xA;启用=真&#xA;}&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;p&gt;由于此功能是实验性的，因此您需要将稳定性级别设置为&lt;code&gt;实验性&lt;/code&gt;：&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet&#34;&gt;&lt;div class=&#34;lang-toolbar&#34;&gt;&#xA;&lt;span class=&#34;lang-toolbar__item&#34;&gt;bash&lt;/span&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;按钮 x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;将代码复制到剪贴板&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;复制&lt;/span&gt;&#xA;&lt;/按钮&gt;&#xA;&lt;/span&gt;&#xA;&lt;div class=&#34;lang-toolbar__border&#34;&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-bash&#34;&gt;合金运行 config.alloy --stability.level 实验性&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;p&gt;访问http://localhost:12345/打开UI。按组件页面上的&lt;strong&gt;实时调试&lt;/strong&gt;按钮启动该组件的会话。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1791px；”&#xA;itemprop =“关联”泰德媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&#xA;&lt;一&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/alloy-1-3/live-debugging-in-ui.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src =“/media/blog/alloy-1-3/live-debugging-in-ui.png”data-srcset =“/media/blog/alloy-1-3/live-debugging-in-ui.png” png?w=320 320w，/media/blog/alloy-1-3/live-debugging-in-ui.png?w=550 550w，/media/blog/alloy-1-3/live-debugging-in- ui.png?w=750 750w, /media/blog/alloy-1-3/live-debugging-in-ui.png?w=900 900w, /media/blog/alloy-1-3/live-debugging- in-ui.png?w=1040 1040w，/media/blog/alloy-1-3/live-debugging-in-ui.png?w=1240 1240w，/media/blog/alloy-1-3/live-调试-in-ui.png?w=1920 1920w&#34;&#xA;数据大小=“自动”alt=“”&#xA;宽度=“1791”&#xA;高度=“1190”&#xA;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/alloy-1-3/live-debugging-in-ui.png”&#xA;替代=“”&#xA;宽度=“1791”&#xA;高度=“1190”&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;/a&gt;&#xA;&lt;/图&gt;&#xA;&lt;p&gt;您可以滚动、过滤和采样数据。您还可以使用暂停/取消暂停功能和&lt;strong&gt;清除&lt;/strong&gt;按钮来管理流程。&lt;/p&gt;&#xA;&lt;p&gt;此版本中以下组件支持实时调试：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;loki.process&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;loki.relabel&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;otelcol.processor&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;otelcol.receiver&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;prometheus.relabel&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;块引用&gt;&#xA;&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;&lt;code&gt;otelcol.processor&lt;/code&gt; 和 &lt;code&gt;otelcol.receiver&lt;/code&gt; 都包含所有相应的组件。&lt;/p&gt;&#xA;&lt;/块引用&gt;&#xA;&lt;h2 id=&#34;build-your-pipelines-step-by-step&#34;&gt;逐步构建您的管道&lt;/h2&gt;&#xA;&lt;p&gt;在 Alloy 的早期版本中，您必须构建整个管道并检查数据库，希望遥测数据以预期的格式交付。但通过实时调试，您可以增量添加组件并在将数据发送到云之前验证数据是否满足您的期望。&lt;/p&gt;&#xA;&lt;p&gt;观看以下视频，详细了解如何通过实时调试构建管道。在第一个中，您将了解如何使用 Alloy 将 Prometheus 指标发送到 Grafana Cloud。&lt;/p&gt;&#xA;&lt;div class=&#34;shortcode youtube&#34;&gt;&#xA;&lt;iframe src=&#34;https://www.youtube.com/embed/_MbB8IVKMfw?rel=0&#34; style=&#34;位置：绝对；顶部：0；左侧：0；宽度：100%；高度：100%；边框： 0;” allowedfullscreen title=&#34;YouTube 视频&#34;&gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;如果您使用 OpenTelemetry，第二个视频将向您展示如何从应用程序接收 OpenTelemetry Protocol (OTLP) 指标，并借助实时调试将它们发送到 Grafana Cloud。&lt;/p&gt;&#xA;&lt;div class=&#34;shortcode youtube&#34;&gt;&#xA;&lt;iframe src=&#34;https://www.youtube.com/embed/IRqQEzc0kvA?rel=0&#34; style=&#34;位置：绝对；顶部：0；左侧：0；宽度：100%；高度：100%；边框： 0;” allowedfullscreen title=&#34;YouTube 视频&#34;&gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&#xA;&lt;h2 id=&#34;learn-more-about-grafana-alloy&#34;&gt;了解有关 Grafana 合金的更多信息&lt;/h2&gt;&#xA;&lt;p&gt;要了解有关最新版本中其他功能的更多信息，请参阅我们的 &lt;a href=&#34;/docs/alloy/v1.3/&#34;&gt;Grafana Alloy 文档n&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;一如既往，我们很乐意听取您的意见，因此请随时访问我们的 &lt;a href=&#34;https://slack.grafana.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt; Grafana Labs 社区 Slack&lt;/a&gt; 或直接查看 &lt;a href=&#34;https://github.com/grafana/alloy&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Alloy 存储库&lt;/a&gt;。我们期待您的意见和反馈！&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;/products/cloud/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt;是开始使用指标、日志、跟踪、仪表板等的最简单方法。我们为每个用例提供慷慨的永久免费套餐和计划。 &lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;plcmt=body-txt&#34;&gt;立即免费注册！&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 05 Aug 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Observe deleted Kubernetes components in Grafana Cloud to boost troubleshooting and resource management】观察 Grafana Cloud 中已删除的 Kubernetes 组件，以促进故障排除和资源管理</title>
      <link>https://grafana.com/blog/2024/08/08/observe-deleted-kubernetes-components-in-grafana-cloud-to-boost-troubleshooting-and-resource-management/</link>
      <description>【&lt;p&gt;As a site reliability engineer, you need constant vigilance and a keen eye for detail if you want to manage your Kubernetes infrastructure effectively.&lt;/p&gt;&#xA;&lt;p&gt;As part of that effort, you need to see the historical data from your pods, nodes, and clusters — even after they&amp;rsquo;ve been deleted or recreated. Many SREs rely on kubectl for this, and while it&amp;rsquo;s indispensable for real-time Kubernetes management, it presents some significant challenges with historical data:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Manual effort:&lt;/strong&gt; You have to continuously intervene to capture and retain the necessary data.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Complexity:&lt;/strong&gt; You have to orchestrate multiple commands and tools to get a complete historical view.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Data retention:&lt;/strong&gt; You have to set up and maintain additional infrastructure to ensure the data is available long-term.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Not only is this time-consuming and expensive, it can also open the door to mistakes and missing data. And those errors can lead to a lack of visibility that hinders effective troubleshooting, resource management, and compliance. But with &lt;a href=&#34;/solutions/kubernetes/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Kubernetes Monitoring in Grafana Cloud&lt;/a&gt;, you can quickly overcome these challenges. To illustrate this, let&amp;rsquo;s follow the journey of a SRE facing multiple issues and see how historical visibility in Kubernetes Monitoring can help.&lt;/p&gt;&#xA;&lt;h3 id=&#34;scenario-1-debugging-post-deployment-application-issues&#34;&gt;&lt;strong&gt;Scenario 1: Debugging post-deployment application issues&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;p&gt;Let&amp;rsquo;s say you’re working at a bustling tech company, and you&amp;rsquo;ve just overseen the deployment of a new version of your application. Everything seems fine until users start reporting intermittent failures. Panic sets in as you realize the issue might be with the pods that were created and deleted during the deployment.&lt;/p&gt;&#xA;&lt;p&gt;Initially, you frantically run &lt;code&gt;kubectl get pods --all-namespaces&lt;/code&gt; to capture pod states, but the problematic pods were deleted. You then try to find logs using &lt;code&gt;kubectl logs &amp;lt;pod-name&amp;gt;&lt;/code&gt;, but the pods no longer exist. Desperate, you look for events with &lt;code&gt;kubectl describe pod&lt;/code&gt;, hoping to piece together the puzzle. This process is time consuming and error prone, causing further delays and frustration.&lt;/p&gt;&#xA;&lt;p&gt;But with Grafana Cloud, you get &lt;a href=&#34;/docs/grafana-cloud/monitor-infrastructure/kubernetes-monitoring/navigate-k8s-monitoring/?pg=blog&amp;amp;plcmt=body-txt#analyze-historical-data&#34;&gt;historical visibility out of the box&lt;/a&gt;. You can easily view the state and logs of those deleted pods. Instead of scrambling through ephemeral logs, you’re able to calmly access a timeline that shows exactly what happened before the deployment went awry. This not only helps you pinpoint the issue but also reduces downtime and user frustration.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 2446px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&#xA;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/docs/grafana-cloud/k8s/find-deletd-node.gif&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/docs/grafana-cloud/k8s/find-deletd-node.gif&#34;alt=&#34;Analyzing &amp;#39;No data&amp;#39; status on a node in Kubernetes Monitoring&#34;&#xA;width=&#34;2446&#34;&#xA;height=&#34;1806&#34;&#xA;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/docs/grafana-cloud/k8s/find-deletd-node.gif&#34;&#xA;alt=&#34;Analyzing &amp;#39;No data&amp;#39; status on a node in Kubernetes Monitoring&#34;&#xA;width=&#34;2446&#34;&#xA;height=&#34;1806&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;/a&gt;&#xA;&lt;/figure&gt;&#xA;&lt;p&gt;There are other times where historical data comes in handy for debugging. For example, maybe you&amp;rsquo;re working with an Azure Kubernetes Service cluster and you mistakenly delete all nodes, thinking the cluster would self-heal. This leads to all pods being in a pending state with no nodes available. The immediate impact is severe: applications become unavailable, user requests fail, and the overall system stability is compromised. You then decide to upgrade the cluster to bring it back to a functional state. After upgrading the cluster, nodes come back online, and pods move from pending to running state.&lt;/p&gt;&#xA;&lt;p&gt;With Kubernetes Monitoring in Grafana Cloud, you can access historical visibility to understand the sequence of events leading to the issue. You can see when the &lt;a href=&#34;/docs/grafana-cloud/monitor-infrastructure/kubernetes-monitoring/navigate-k8s-monitoring/?pg=blog&amp;amp;plcmt=body-txt#find-deleted-kubernetes-objects&#34;&gt;nodes were deleted&lt;/a&gt;, the exact state changes of the pods, and how the system responded over time.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1512px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&#xA;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/docs/grafana-cloud/k8s/nodata-on-node.gif&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/docs/grafana-cloud/k8s/nodata-on-node.gif&#34;alt=&#34;Analyzing &amp;#39;No date&amp;#39; status on a node in Kubernetes Monitoring&#34;&#xA;width=&#34;1512&#34;&#xA;height=&#34;824&#34;&#xA;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/docs/grafana-cloud/k8s/nodata-on-node.gif&#34;&#xA;alt=&#34;Analyzing &amp;#39;No date&amp;#39; status on a node in Kubernetes Monitoring&#34;&#xA;width=&#34;1512&#34;&#xA;height=&#34;824&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;/a&gt;&#xA;&lt;/figure&gt;&#xA;&lt;p&gt;This detailed historical data allows you to identify the root cause quickly and implement preventive measures to avoid such disruptions in the future. The ability to review the entire timeline in Grafana Cloud not only helps to resolve the current issue; it also provides insights for improving the overall system resilience.&lt;/p&gt;&#xA;&lt;h3 id=&#34;scenario-2-optimizing-resource-usage&#34;&gt;&lt;strong&gt;Scenario 2: Optimizing resource usage&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;p&gt;With the deployment issues resolved, your next task is optimizing the resource usage of your Kubernetes nodes. You’ve noticed some nodes are consistently running hot, while others are underutilized. Using kubectl, you can check current usage with commands like &lt;code&gt;kubectl top nodes&lt;/code&gt; and &lt;code&gt;kubectl top pods&lt;/code&gt;. But it requires more effort to understand past usage trends.&lt;/p&gt;&#xA;&lt;p&gt;To achieve this with kubectl, you must:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Set up persistent logging solutions to capture metrics over time.&lt;/li&gt;&#xA;&lt;li&gt;Periodically export and store these metrics manually.&lt;/li&gt;&#xA;&lt;li&gt;Painstakingly combine data from various sources to get a historical view.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;Kubernetes Monitoring in Grafana Cloud replaces this tedious process. Historical data on &lt;a href=&#34;/docs/grafana-cloud/monitor-infrastructure/kubernetes-monitoring/optimize-resource-usage/?pg=blog&amp;amp;plcmt=body-txt#discover-usage-over-time&#34;&gt;node and pod resource usage&lt;/a&gt; is readily available, which allows you to analyze trends and make informed decisions about resource allocation. This level of visibility helps you optimize your infrastructure for a more efficient and cost-effective operation.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1512px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&#xA;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/docs/grafana-cloud/k8s/pod-last-30-days.gif&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/docs/grafana-cloud/k8s/pod-last-30-days.gif&#34;alt=&#34;Analyzing the last 30 days in Kubernetes Monitoring&#34;&#xA;width=&#34;1512&#34;&#xA;height=&#34;824&#34;&#xA;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/docs/grafana-cloud/k8s/pod-last-30-days.gif&#34;&#xA;alt=&#34;Analyzing the last 30 days in Kubernetes Monitoring&#34;&#xA;width=&#34;1512&#34;&#xA;height=&#34;824&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;/a&gt;&#xA;&lt;/figure&gt;&#xA;&lt;p&gt;So, there you are in the middle of a resource optimization task, when you remember the cumbersome, manual approach you used to perform to export metrics periodically and store them for historical analysis. But with Grafana Cloud, your historical data can be viewed directly, so you can make quicker and more accurate decisions about resource allocation.&lt;/p&gt;&#xA;&lt;h3 id=&#34;scenario-3-analyzing-past-incidents-for-better-future-planning&#34;&gt;&lt;strong&gt;Scenario 3: Analyzing past incidents for better future planning&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;p&gt;Just when things seem to be running smoothly, a major outage occurs. As an SRE, it&amp;rsquo;s your job to analyze the incident and ensure it doesn&amp;rsquo;t happen again. You need to look back at the state of your Kubernetes infrastructure before, during, and after the outage.&lt;/p&gt;&#xA;&lt;p&gt;If you were to use kubectl to complete this task, you would have to follow a series of steps that presents the same challenges we&amp;rsquo;ve been discussing throughout this blog:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Manually record the state of pods and nodes at regular intervals.&lt;/li&gt;&#xA;&lt;li&gt;Correlate logs from various sources to reconstruct the sequence of events.&lt;/li&gt;&#xA;&lt;li&gt;Piece together data from different tools to get a comprehensive view.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;This can lead to incomplete analysis and overlooked root causes. For example, let&amp;rsquo;s say you discover the outage happened because a particular node was lost after an upgrade, causing significant disruption. It would be difficult to piece together the event logs and states of the nodes manually.&lt;/p&gt;&#xA;&lt;p&gt;Instead, you could use Grafana Cloud to quickly access historical data and understand the sequence of events that led to the outage. With the Kubernetes Monitoring, you can identify patterns and root causes of the incident with ease. And with a few clicks, you can visualize the state of your clusters over time, correlate metrics and &lt;a href=&#34;/docs/grafana-cloud/monitor-infrastructure/kubernetes-monitoring/navigate-k8s-monitoring/?pg=blog&amp;amp;plcmt=body-txt#view-logs-and-events&#34;&gt;logs&lt;/a&gt;, and derive actionable insights that translate to more effective incident analysis and better planning for the future.&lt;/p&gt;&#xA;&lt;h2 id=&#34;start-using-kubernetes-monitoring-today&#34;&gt;Start using Kubernetes Monitoring today&lt;/h2&gt;&#xA;&lt;p&gt;There are good reasons to delete pods and nodes in Kubernetes, including:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Application updates:&lt;/strong&gt; Deploying new versions of applications that may require deleting old pods.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Scaling operations:&lt;/strong&gt; Adjusting the number of pods or nodes to handle varying loads.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Security concerns:&lt;/strong&gt; Addressing vulnerabilities by removing compromised or outdated pods.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;But as we&amp;rsquo;ve shown here, it can lead to significant problems when it isn&amp;rsquo;t handled properly. Kubernetes Monitoring in Grafana Cloud turns potential nightmares into manageable tasks, making it an essential tool for any SRE, cloud infrastructure admin, or developer. For more information, visit the &lt;a href=&#34;/docs/grafana-cloud/monitor-infrastructure/kubernetes-monitoring/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Kubernetes Monitoring documentation&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;/products/cloud/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt; is the easiest way to get started with metrics, logs, traces, dashboards, and more. We have a generous forever-free tier and plans for every use case.&lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt; Sign up for free now&lt;/a&gt;!&lt;/em&gt;&lt;/p&gt;】&lt;p&gt;作为一名站点可靠性工程师，如果您想有效管理 Kubernetes 基础设施，您需要时刻保持警惕并敏锐地关注细节。&lt;/p&gt;&#xA;&lt;p&gt;作为这项工作的一部分，您需要查看 Pod、节点和集群的历史数据 - 即使它们已被删除或重新创建。许多 SRE 都依赖 kubectl 来实现这一点，虽然它对于实时 Kubernetes 管理是不可或缺的，但它对历史数据提出了一些重大挑战：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;手动操作：&lt;/strong&gt;您必须持续干预以捕获和保留必要的数据。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;复杂性：&lt;/strong&gt;您必须协调多个命令和工具才能获得完整的历史视图。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;数据保留&lt;/strong&gt;：您必须设置和维护额外的基础设施，以确保数据长期可用。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;这不仅耗时且昂贵，而且还可能导致错误和数据丢失。这些错误可能会导致缺乏可见性，从而阻碍有效的故障排除、资源管理和合规性。但借助 &lt;a href=&#34;/solutions/kubernetes/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana Cloud 中的 Kubernetes 监控&lt;/a&gt;，您可以快速克服这些挑战。为了说明这一点，让我们跟随一个面临多个问题的 SRE 的旅程，看看 Kubernetes 监控中的历史可见性如何提供帮助。&lt;/p&gt;&#xA;&lt;h3 id=&#34;scenario-1-debugging-post-deployment-application-issues&#34;&gt;&lt;strong&gt;场景 1：调试部署后应用程序问题&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;p&gt;假设您在一家繁忙的科技公司工作，并且您刚刚监督了应用程序新版本的部署。一切看起来都很好，直到用户开始报告间歇性故障。当您意识到问题可能出在部署期间创建和删除的 Pod 时，恐慌就开始了。&lt;/p&gt;&#xA;&lt;p&gt;最初，您疯狂地运行 &lt;code&gt;kubectl get pods --all-namespaces&lt;/code&gt; 来捕获 Pod 状态，但有问题的 Pod 被删除了。然后，您尝试使用 kubectl logs &lt;pod-name&gt; 查找日志，但 Pod 不再存在。绝望之下，您使用 &lt;code&gt;kubectl describe pod&lt;/code&gt; 寻找事件，希望能够拼凑出这个谜题。此过程非常耗时且容易出错，从而导致进一步的延迟和挫败感。&lt;/p&gt;&#xA;&lt;p&gt;但是使用 Grafana Cloud，您可以获得 &lt;a href=&#34;/docs/grafana-cloud/monitor-infrastruct/kubernetes-monitoring/navigate-k8s-monitoring/?pg=blog&amp;plcmt=body-txt#analyze-historical-data ”开箱即用的历史可见性&lt;/a&gt;。您可以轻松查看那些已删除 Pod 的状态和日志。您不必费力地浏览临时日志，而是可以平静地访问时间线，该时间线准确显示部署出错之前发生的情况。这不仅可以帮助您查明问题，还可以减少停机时间和用户的挫败感。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：2446px；”&#xA;项目专业p =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&#xA;&lt;一&#xA;类=“灯箱链接”&#xA;href=&#34;/media/docs/grafana-cloud/k8s/find-deletd-node.gif&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/docs/grafana-cloud/k8s/find-deletd-node.gif&#34;alt=&#34;在 Kubernetes 监控中分析节点上的“无数据”状态&#34;&#xA;宽度=“2446”&#xA;高度=“1806”&#xA;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/docs/grafana-cloud/k8s/find-deletd-node.gif”&#xA;alt=&#34;在 Kubernetes 监控中分析节点上的“无数据”状态&#34;&#xA;宽度=“2446”&#xA;高度=“1806”&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;/a&gt;&#xA;&lt;/图&gt;&#xA;&lt;p&gt;在其他时候，历史数据对于调试也很有用。例如，也许您正在使用 Azure Kubernetes 服务集群，并且您错误地删除了所有节点，认为集群会自我修复。这会导致所有 pod 都处于挂起状态，没有可用的节点。直接影响是严重的：应用程序不可用、用户请求失败、整体系统稳定性受到损害。然后，您决定升级集群以使其恢复到功能状态。升级集群后，节点重新上线，Pod 从挂起状态变为运行状态。&lt;/p&gt;&#xA;&lt;p&gt;借助 Grafana Cloud 中的 Kubernetes 监控，您可以访问历史可见性，以了解导致问题的事件顺序。您可以看到&lt;a href=&#34;/docs/grafana-cloud/monitor-infrastruct/kubernetes-monitoring/navigate-k8s-monitoring/?pg=blog&amp;plcmt=body-txt#find-deleted-kubernetes-objects&#34;&gt;节点何时被删除&lt;/a&gt;、Pod 的确切状态变化以及系统随时间的响应方式。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1512px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&#xA;&lt;一&#xA;类=“灯箱链接”&#xA;href=&#34;/media/docs/grafana-cloud/k8s/nodata-on-node.gif&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/docs/grafana-cloud/k8s/nodata-on-node.gif&#34;alt=&#34;在 Kubernetes 监控中分析节点上的“无日期”状态”&#xA;宽度=“1512”&#xA;高度=“824”&#xA;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/docs/grafana-cloud/k8s/nodata-on-node.gif”&#xA;alt=&#34;在 Kubernetes 监控中分析节点上的“无日期”状态”&#xA;宽度=“1512”&#xA;高度=“824”&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;/a&gt;&#xA;&lt;/图&gt;&#xA;&lt;p&gt;这些详细的历史数据使您能够快速确定根本原因并采取预防措施以避免将来出现此类中断。在 Grafana Cloud 中查看整个时间线的能力不仅有助于解决当前问题；它还提供了提高整体系统弹性的见解。&lt;/p&gt;&#xA;&lt;h3 id=&#34;scenario-2-optimizing-resource-usage&#34;&gt;&lt;strong&gt;场景 2：优化资源使用&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;p&gt;解决了部署问题后，您的下一个任务是优化 Kubernetes 节点的资源使用。您已经注意到一些节点一直运行得很热，w而其他的则未得到充分利用。使用 kubectl，您可以使用 &lt;code&gt;kubectl top Nodes&lt;/code&gt; 和 &lt;code&gt;kubectl top pods&lt;/code&gt; 等命令检查当前使用情况。但了解过去的使用趋势需要付出更多努力。&lt;/p&gt;&#xA;&lt;p&gt;要使用 kubectl 实现此目的，您必须：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;设置持久日志记录解决方案以捕获一段时间内的指标。&lt;/li&gt;&#xA;&lt;li&gt;定期手动导出并存储这些指标。&lt;/li&gt;&#xA;&lt;li&gt;精心组合来自不同来源的数据以获得历史视图。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;Grafana Cloud 中的 Kubernetes 监控取代了这个繁琐的过程。 &lt;a href=&#34;/docs/grafana-cloud/monitor-infrastruct/kubernetes-monitoring/optimize-resource-usage/?pg=blog&amp;plcmt=body-txt#discover-usage-over-time&#34;&gt;节点和 pod 上的历史数据资源使用情况&lt;/a&gt;随时可用，使您能够分析趋势并就资源分配做出明智的决策。这种级别的可见性可帮助您优化基础架构，实现更高效、更具成本效益的运营。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1512px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&#xA;&lt;一&#xA;类=“灯箱链接”&#xA;href=&#34;/media/docs/grafana-cloud/k8s/pod-last-30-days.gif&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/docs/grafana-cloud/k8s/pod-last-30-days.gif&#34;alt=&#34;分析 Kubernetes 监控中的过去 30 天&#34;&#xA;宽度=“1512”&#xA;高度=“824”&#xA;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/docs/grafana-cloud/k8s/pod-last-30-days.gif”&#xA;alt=&#34;在 Kubernetes 监控中分析最近 30 天&#34;&#xA;宽度=“1512”&#xA;高度=“824”&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;/a&gt;&#xA;&lt;/图&gt;&#xA;&lt;p&gt;因此，您正处于资源优化任务的中间，您还记得您用来定期导出指标并将其存储以进行历史分析的繁琐的手动方法。但借助 Grafana Cloud，您可以直接查看您的历史数据，因此您可以更快、更准确地做出资源分配决策。&lt;/p&gt;&#xA;&lt;h3 id=&#34;scenario-3-analyzing-past-incidents-for-better-future-planning&#34;&gt;&lt;strong&gt;场景 3：分析过去的事件以更好地规划未来&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;p&gt;就在事情看起来进展顺利时，却发生了严重的停电。作为 SRE，您的工作是分析事件并确保不再发生。您需要回顾 Kubernetes 基础设施在中断之前、期间和之后的状态。&lt;/p&gt;&#xA;&lt;p&gt;如果您要使用 kubectl 来完成此任务，则必须执行一系列步骤，这些步骤提出了我们在本博客中讨论的相同挑战：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;定期手动记录 Pod 和节点的状态。&lt;/li&gt;&#xA;&lt;li&gt;关联不同来源的日志以重建事件顺序。&lt;/li&gt;&#xA;&lt;li&gt;将来自不同工具的数据拼凑起来以获得全面的视图。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;这可能会导致分析不完整并忽视根本原因。对于前例如，假设您发现由于升级后某个特定节点丢失而发生中断，导致严重中断。手动拼凑事件日志和节点状态是很困难的。&lt;/p&gt;&#xA;&lt;p&gt;相反，您可以使用 Grafana Cloud 快速访问历史数据并了解导致中断的事件顺序。通过 Kubernetes 监控，您可以轻松识别事件的模式和根本原因。只需点击几下，您就可以可视化集群随时间的状态、关联指标和=body-txt#view-logs-and-events&#34;&gt;日志&lt;/a&gt;，并得出可操作的见解，转化为更有效的事件分析和更好的未来规划。&lt;/p&gt;&#xA;&lt;h2 id=&#34;start-using-kubernetes-monitoring-today&#34;&gt;立即开始使用 Kubernetes 监控&lt;/h2&gt;&#xA;&lt;p&gt;删除 Kubernetes 中的 Pod 和节点有充分的理由，包括：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;应用更新&lt;/strong&gt;：部署可能需要删除旧 Pod 的新版本应用。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;扩展操作&lt;/strong&gt;：调整 Pod 或节点的数量以处理不同的负载。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;安全问题&lt;/strong&gt;：通过删除受损或过时的 pod 来解决漏洞。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;但正如我们在此所示，如果处理不当，可能会导致严重问题。 Grafana Cloud 中的 Kubernetes 监控将潜在的噩梦变成可管理的任务，使其成为任何 SRE、云基础设施管理员或开发人员的必备工具。如需了解更多信息，请访问 &lt;a href=&#34;/docs/grafana-cloud/monitor-infrastruct/kubernetes-monitoring/?pg=blog&amp;plcmt=body-txt&#34;&gt;Kubernetes 监控文档&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;/products/cloud/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt; 是开始使用指标、日志、跟踪、仪表板等的最简单方法。我们为每个用例提供慷慨的永久免费套餐和计划。&lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;plcmt=body-txt&#34;&gt;立即免费注册&lt;/a&gt; ！&lt;/em&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 08 Aug 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Empowering every user: How Schwarz IT harnesses Grafana Enterprise for their diverse observability needs】赋能每位用户：Schwarz IT 如何利用 Grafana Enterprise 满足其多样化的可观察性需求</title>
      <link>https://grafana.com/blog/2024/08/09/empowering-every-user-how-schwarz-it-harnesses-grafana-enterprise-for-their-diverse-observability-needs/</link>
      <description>【&lt;p&gt;At Schwarz IT, they have a mission statement: deliver the right information to all employees, at the right time, and through the right channels. And to achieve that goal, they use Grafana.&lt;/p&gt;&#xA;&lt;p&gt;“Grafana is an interface for everyone,” says Felix Spitzer, Monitoring Specialist at Schwarz IT, the internal IT service provider for multinational retailer the Schwarz Group. “We have teams that are working closely with Grafana that are very technical, but we also have teams using it that are not technical users. With Grafana, we reach more customers — a bigger variety of users — than ever before.”&lt;/p&gt;&#xA;&lt;p&gt;In fact, this versatility was one of the biggest reasons Schwarz IT chose to implement &lt;a href=&#34;/oss/&#34;&gt;Grafana OSS&lt;/a&gt; in 2014, and then later move to &lt;a href=&#34;/products/enterprise/&#34;&gt;Grafana Enterprise&lt;/a&gt; in 2022. Yes, the team found significant value in being able to centralize and streamline their overall monitoring strategy with Grafana, but the “biggest selling point” for the platform, they say, is its ability to empower such a wide variety of users — both business and technical — to visualize the data that’s most important to them.&lt;/p&gt;&#xA;&lt;p&gt;“Our internal customers know best what they need to see and how to interpret it,” says Michael Dallmann, team lead for Monitoring and Observability Solutions at Schwarz IT. “With Grafana, we provide a tool where the customer can build their own view.”&lt;/p&gt;&#xA;&lt;p&gt;Schwarz IT, headquartered in Germany, is responsible for the IT infrastructure and software solutions that support the various divisions of the Schwarz Group. These include the Lidl and Kaufland food retailers; food production firm Schwarz Produktion; environmental services provider PreZero; and digital innovation firm Schwarz Digits. All in all, Schwarz IT ensures IT operations run smoothly for roughly 575,00 employees across 32 different countries.&lt;/p&gt;&#xA;&lt;p&gt;Today, Grafana Enterprise is used by more than 100 organizations within Schwarz IT. They have more than 6,000 dashboards and close to 1,500 active users. In addition, Schwarz IT supports the open source Grafana instances used by Lidl and Kaufland.&lt;/p&gt;&#xA;&lt;p&gt;But the monitoring team has done so much more than enable users to visualize data in Grafana. With a commitment to knowledge-sharing and dedicated time for innovation (hackathons, anyone?), they’ve fostered an active and thriving Grafana community that today spans nearly all facets of the Schwarz Group.&lt;/p&gt;&#xA;&lt;p&gt;“We don&amp;rsquo;t have a community around other tools like we have with Grafana,” says Spitzer. “I would say a big part of that community is because you can use Grafana in so many different ways.”&lt;/p&gt;&#xA;&lt;p&gt;Grafana Labs recently sat down with Spitzer to talk about the variety of ways Schwarz Group employees use Grafana, how his team has supported such large-scale adoption, and the unique culture and community Schwarz IT has created around the observability platform.&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;Note: The below interview has been edited for brevity and clarity.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;can-you-tell-us-more-about-the-team-youre-on-at-schwarz-it&#34;&gt;Can you tell us more about the team you’re on at Schwarz IT?&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Felix&lt;/strong&gt;: On the monitoring solutions team – we are about 18 people at the moment — we are supporting the Lidl and Kaufland countries, mostly, and the internal IT colleagues when they have monitoring questions. We maintain the monitoring environment. We have different products including Splunk, Dynatrace, our own Open Monitoring Distribution appliance with the NAGIOS fork Naemon, Prometheus, and Grafana, which is a very, very big part of it at the moment. We use Grafana Enterprise to monitor the health of systems, including our network, website and Windows Server.&lt;/p&gt;&#xA;&lt;p&gt;We use Grafana Enterprise as the foundation for all the raw monitoring data we have, and then we provide and administer open source Grafana instances, so other teams can also use it for themselves.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1999px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&#xA;&lt;a&#xA;class=&#34;lightbox-link captioned&#34;&#xA;href=&#34;/media/blog/schwarz-IT-spotlight/schwarz-IT-SPACE-dashboard.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload mb-0&#34;&#xA;data-src=&#34;/media/blog/schwarz-IT-spotlight/schwarz-IT-SPACE-dashboard.png&#34;data-srcset=&#34;/media/blog/schwarz-IT-spotlight/schwarz-IT-SPACE-dashboard.png?w=320 320w, /media/blog/schwarz-IT-spotlight/schwarz-IT-SPACE-dashboard.png?w=550 550w, /media/blog/schwarz-IT-spotlight/schwarz-IT-SPACE-dashboard.png?w=750 750w, /media/blog/schwarz-IT-spotlight/schwarz-IT-SPACE-dashboard.png?w=900 900w, /media/blog/schwarz-IT-spotlight/schwarz-IT-SPACE-dashboard.png?w=1040 1040w, /media/blog/schwarz-IT-spotlight/schwarz-IT-SPACE-dashboard.png?w=1240 1240w, /media/blog/schwarz-IT-spotlight/schwarz-IT-SPACE-dashboard.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A screenshot of the Schwarz IT SPACE Grafana dashboard.&#34;&#xA;width=&#34;1999&#34;&#xA;height=&#34;1061&#34;&#xA;title=&#34;*A Grafana dashboard for Schwarz IT’s end-to-end website monitoring product S.P.A.C.E. (Schwarz Playwright automatic check execution).*&#34;&#xA;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/schwarz-IT-spotlight/schwarz-IT-SPACE-dashboard.png&#34;&#xA;alt=&#34;A screenshot of the Schwarz IT SPACE Grafana dashboard.&#34;&#xA;width=&#34;1999&#34;&#xA;height=&#34;1061&#34;&#xA;title=&#34;*A Grafana dashboard for Schwarz IT’s end-to-end website monitoring product S.P.A.C.E. (Schwarz Playwright automatic check execution).*&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;figcaption class=&#34;w-100p caption text-gray-13 &#34;&gt;&lt;em&gt;A Grafana dashboard for Schwarz IT’s end-to-end website monitoring product S.P.A.C.E. (Schwarz Playwright automatic check execution).&lt;/em&gt;&lt;/figcaption&gt;&#xA;&lt;/a&gt;&#xA;&lt;/figure&gt;&#xA;&lt;h2 id=&#34;what-are-some-of-the-other-grafana-use-cases-you-see-across--schwarz-it-or-the-schwarz-group-more-broadly&#34;&gt;What are some of the other Grafana use cases you see across Schwarz IT or the Schwarz Group, more broadly?&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Felix&lt;/strong&gt;: So, the website teams use Grafana for an overview of JavaScript errors. We also have a team that created their own end-to-end website monitoring program that simulates user input and then uses Grafana as an endpoint to display results related to response time and latency.&lt;/p&gt;&#xA;&lt;p&gt;We have a team using Grafana to track orders and check the resources and warehouses for Lidl food retailers. They have big data in Oracle and MongoDB, and then get the data into Grafana, where they can track, for example, the stock of a product across different stores in the German division.&lt;/p&gt;&#xA;&lt;p&gt;The countries have different use cases because they want to monitor things that are specific to their retail stores.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1999px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&#xA;&lt;a&#xA;class=&#34;lightbox-link captioned&#34;&#xA;href=&#34;/media/blog/schwarz-IT-spotlight/schwarz-IT-IoT-dashboard.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload mb-0&#34;&#xA;data-src=&#34;/media/blog/schwarz-IT-spotlight/schwarz-IT-IoT-dashboard.png&#34;data-srcset=&#34;/media/blog/schwarz-IT-spotlight/schwarz-IT-IoT-dashboard.png?w=320 320w, /media/blog/schwarz-IT-spotlight/schwarz-IT-IoT-dashboard.png?w=550 550w, /media/blog/schwarz-IT-spotlight/schwarz-IT-IoT-dashboard.png?w=750 750w, /media/blog/schwarz-IT-spotlight/schwarz-IT-IoT-dashboard.png?w=900 900w, /media/blog/schwarz-IT-spotlight/schwarz-IT-IoT-dashboard.png?w=1040 1040w, /media/blog/schwarz-IT-spotlight/schwarz-IT-IoT-dashboard.png?w=1240 1240w, /media/blog/schwarz-IT-spotlight/schwarz-IT-IoT-dashboard.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A screenshot of an IoT dashboard in Grafana.&#34;&#xA;width=&#34;1999&#34;&#xA;height=&#34;875&#34;&#xA;title=&#34;*A Grafana dashboard providing an overview of IoT devices, inventory, and the uninterrupted power supply (UPS) for Kaufland stores in Germany.*&#34;&#xA;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/schwarz-IT-spotlight/schwarz-IT-IoT-dashboard.png&#34;&#xA;alt=&#34;A screenshot of an IoT dashboard in Grafana.&#34;&#xA;width=&#34;1999&#34;&#xA;height=&#34;875&#34;&#xA;title=&#34;*A Grafana dashboard providing an overview of IoT devices, inventory, and the uninterrupted power supply (UPS) for Kaufland stores in Germany.*&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;figcaption class=&#34;w-100p caption text-gray-13 &#34;&gt;&lt;em&gt;A Grafana dashboard providing an overview of IoT devices, inventory, and the uninterrupted power supply (UPS) for Kaufland stores in Germany.&lt;/em&gt;&lt;/figcaption&gt;&#xA;&lt;/a&gt;&#xA;&lt;/figure&gt;&#xA;&lt;h2 id=&#34;how-did-you-help-facilitate-grafana-adoption-at-such-large-scale&#34;&gt;How did you help facilitate Grafana adoption at such large scale?&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Felix&lt;/strong&gt;: We started to get specific questions about how to do things in Grafana. Grafana Labs has very good &lt;a href=&#34;/videos/&#34;&gt;webinars and videos&lt;/a&gt; on their site, but they aren’t customized for our environment.&lt;/p&gt;&#xA;&lt;p&gt;So we started our own internal Grafana training. We created this big Teams channel where we share dashboard ideas, the next big thing we’re going to try, success stories — and everyday somebody new would join. We would look for customers using Grafana and ask them about their use case and dashboards, and ask them to share a blog post about it on our Teams channel.&lt;/p&gt;&#xA;&lt;p&gt;We also hold a training session every three to four months. We are doing a basic one and are starting an advanced one this year. But every training is around 100 users. It’s very big, and we need even more.&lt;/p&gt;&#xA;&lt;h2 id=&#34;what-inspired-you-to-host-your-internal-grafana-hackathon-and-what-has-the-impact-been&#34;&gt;What inspired you to host your internal Grafana hackathon and what has the impact been?&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Felix&lt;/strong&gt;: The idea for the first hackathon in March 2023 stemmed from wanting to help drive Grafana use within the countries. In person, you can do little team workshops and be face-to-face — we wanted knowledge transfer. The Schwarz Group is so big and the Lidl countries are like their own companies, so there isn’t much knowledge transfer or communication between them. So we thought, okay, we are like the connection point for them. Let’s create a hackathon.&lt;/p&gt;&#xA;&lt;p&gt;We had an agenda where we showed them our goals. Then we asked about their goals with Grafana and what problems they wanted to solve. We were brainstorming with the different countries, and then we broke off into groups to build a dashboard for their particular problem. Everybody then shared their dashboard and was really excited; people were sharing the JSON because everybody was like, “yeah, I need that.”&lt;/p&gt;&#xA;&lt;p&gt;After the hackathon, we had a very big increase in Grafana usage throughout the countries. In a few weeks, there was an increase of more than 100 dashboards. And that was one of our main goals.&lt;/p&gt;&#xA;&lt;h2 id=&#34;you-use-a-number-of-products-in-your-monitoring-stack-why-focus-only-on-grafana-for-these-hackathons&#34;&gt;You use a number of products in your monitoring stack. Why focus only on Grafana for these hackathons?&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Felix&lt;/strong&gt;: Because you can use Grafana in so many different ways; we are using it as a visualization layer for everything. That’s created this sense of community, and it’s why the hackathons work so well. We’re really trying to push all the data we have to Grafana, making it possible for the end user who’s not technical, and the one who is technical, to use the same interface.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;h3 id=&#34;whats-next-for-schwarz-it&#34;&gt;What’s next for Schwarz IT&lt;/h3&gt;&#xA;&lt;p&gt;Schwarz IT recently held a second Grafana hackathon for their IT hub in Sofia to further expand Grafana usage.&lt;/p&gt;&#xA;&lt;p&gt;“We will also push standard dashboards for the countries to use predefined views and include business process monitoring visualizations,” said Michael Dallman, team lead for Monitoring and Observability Solutions. “For the countries, we will also set up a deep dive for all our monitoring tools, which will include, of course, Grafana.”&lt;/p&gt;&#xA;&lt;/blockquote&gt;】&lt;p&gt;在 Schwarz IT，他们有一个使命宣言：在正确的时间通过正确的渠道向所有员工提供正确的信息。为了实现这一目标，他们使用 Grafana。&lt;/p&gt;&#xA;&lt;p&gt;“Grafana 是适合所有人的界面，”跨国零售商 Schwarz Group 的内部 IT 服务提供商 Schwarz IT 的监控专家 Felix Spitzer 说道。 “我们有一些与 Grafana 密切合作的技术性很强的团队，但我们也有一些使用它的团队不是技术用户。借助 Grafana，我们比以往接触到了更多的客户——更多种类的用户。”&lt;/p&gt;&#xA;&lt;p&gt;事实上，这种多功能性是 Schwarz IT 选择在 2014 年实施 &lt;a href=&#34;/oss/&#34;&gt;Grafana OSS&lt;/a&gt; 并随后转向 &lt;a href=&#34;/products /enterprise/&#34;&gt;Grafana Enterprise&lt;/a&gt; 于 2022 年推出。是的，该团队发现能够通过 Grafana 集中和简化其整体监控策略具有重大价值，但他们表示，该平台的“最大卖点”是它能够让各种各样的用户（包括业务用户和技术用户）可视化对他们来说最重要的数据。&lt;/p&gt;&#xA;&lt;p&gt;“我们的内部客户最了解他们需要看到什么以及如何解释它，”Schwarz IT 监控和可观测性解决方案团队负责人 Michael Dallmann 说道。 “通过 Grafana，我们提供了一个工具，客户可以在其中构建自己的视图。”&lt;/p&gt;&#xA;&lt;p&gt;Schwarz IT 总部位于德国，负责支持 Schwarz 集团各个部门的 IT 基础设施和软件解决方案。其中包括 Lidl 和 Kaufland 食品零售商；食品生产公司 Schwarz Produktion；环境服务提供商PreZero；以及数字创新公司 Schwarz Digits。总而言之，Schwarz IT 确保 32 个不同国家/地区约 575,00 名员工的 IT 运营平稳运行。&lt;/p&gt;&#xA;&lt;p&gt;如今，Grafana Enterprise 已被 Schwarz IT 内的 100 多个组织使用。他们拥有 6,000 多个仪表板和近 1,500 名活跃用户。此外，Schwarz IT 支持 Lidl 和 Kaufland 使用的开源 Grafana 实例。&lt;/p&gt;&#xA;&lt;p&gt;但是监控团队所做的不仅仅是让用户在 Grafana 中可视化数据。通过致力于知识共享和投入创新时间（黑客马拉松，有人吗？），他们培育了一个活跃且蓬勃发展的 Grafana 社区，如今该社区几乎涵盖了 Schwarz Group 的各个方面。&lt;/p&gt;&#xA;&lt;p&gt;“我们没有像 Grafana 那样围绕其他工具建立社区，”Spitzer 说。 “我想说这个社区的一个重要部分是因为你可以通过多种不同的方式使用 Grafana。”&lt;/p&gt;&#xA;&lt;p&gt;Grafana Labs 最近与 Spitzer 坐下来讨论了 Schwarz Group 员工使用 Grafana 的各种方式、他的团队如何支持如此大规模的采用，以及 Schwarz IT 围绕可观察性平台创建的独特文化和社区。&lt; /p&gt;&#xA;&lt;p&gt;&lt;em&gt;注：以下采访已为简洁明了而进行了编辑。&lt;/em&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;can-you-tell-us-more-about-the-team-youre-on-at-schwarz-it&#34;&gt;您能告诉我们更多有关您在 Schwarz IT 团队的信息吗？&lt;/ H2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Felix&lt;/strong&gt;：在监控解决方案团队中，我们目前大约有 18 人，我们主要为 Lidl 和 Kaufland 国家提供支持，并在内部 IT 同事遇到监控问题时提供支持。我们维护监控环境。我们有不同的产品，包括 Splunk、Dynatrace、我们自己的开放式监控分发设备以及 NAGIOS 分支 Naemon、Prometheus 和 Grafana，目前这是其中非常非常重要的一部分。我们使用 Grafana Enterprise 来监控系统的运行状况，包括我们的网络、网站和 Windows Server。&lt;/p&gt;&#xA;&lt;p&gt;我们使用 Grafana Enterprise 作为我们拥有的所有原始监控数据的基础，然后我们提供和管理开源 Grafana 实例，以便其他团队也可以自己使用它。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1999px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&#xA;&lt;一&#xA;类=“灯箱链接标题”&#xA;href=&#34;/media/blog/schwarz-IT-spotlight/schwarz-IT-SPACE-dashboard.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“lazyload mb-0”&#xA;data-src=&#34;/media/blog/schwarz-IT-spotlight/schwarz-IT-SPACE-dashboard.png&#34;data-srcset=&#34;/media/blog/schwarz-IT-spotlight/schwarz-IT-SPACE-仪表板。 png?w=320 320w，/media/blog/schwarz-IT-spotlight/schwarz-IT-SPACE-dashboard.png?w=550 550w，/media/blog/schwarz-IT-spotlight/schwarz-IT-SPACE-仪表板.png?w=750 750w, /media/blog/schwarz-IT-spotlight/schwarz-IT-SPACE-dashboard.png?w=900 900w, /media/blog/schwarz-IT-spotlight/schwarz-IT-空间-dashboard.png?w=1040 1040w，/media/blog/schwarz-IT-spotlight/schwarz-IT-SPACE-dashboard.png?w=1240 1240w，/media/blog/schwarz-IT-spotlight/schwarz- IT-SPACE-dashboard.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;Schwarz IT SPACE Grafana 仪表板的屏幕截图。&#34;&#xA;宽度=“1999”&#xA;高度=“1061”&#xA;title=&#34;*Schwarz IT 端到端网站监控产品 S.P.A.C.E.（Schwarz Playwright 自动检查执行）的 Grafana 仪表板。*&#34;&#xA;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src=&#34;/media/blog/schwarz-IT-spotlight/schwarz-IT-SPACE-dashboard.png&#34;&#xA;alt=&#34;Schwarz IT SPACE Grafana 仪表板的屏幕截图。&#34;&#xA;宽度=“1999”&#xA;高度=“1061”&#xA;title=&#34;*Schwarz IT 端到端网站监控产品 S.P.A.C.E.（Schwarz Playwright 自动检查执行）的 Grafana 仪表板。*&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;figcaption class=&#34;w-100p title text-gray-13 &#34;&gt;&lt;em&gt;用于 Schwarz IT 端到端网站监控产品 S.P.A.C.E. 的 Grafana 仪表板。 （施瓦茨剧作家自动检查执行）。&lt;/em&gt;&lt;/figcaption&gt;&#xA;&lt;/a&gt;&#xA;&lt;/图&gt;&#xA;&lt;h2 id=&#34;what-are-some-of-the-other-grafana-use-cases-you-see-across--schwarz-it-or-the-schwarz-group-more-broadly&#34;&gt;有哪些您在 Schwarz IT 或 Schwarz Group 看到的其他 Grafana 用例，更广泛？&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Felix&lt;/strong&gt;：因此，网站团队使用 Grafana 来概述 JavaScript 错误。我们还有一个团队创建了自己的端到端网站监控程序，该程序模拟用户输入，然后使用 Grafana 作为端点来显示与响应时间和延迟相关的结果。&lt;/p&gt;&#xA;&lt;p&gt;我们有一个团队使用 Grafana 来跟踪 Lidl 食品零售商的订单并检查资源和仓库。他们在 Oracle 和 MongoDB 中拥有大数据，然后将数据输入 Grafana，在那里他们可以跟踪德国分部不同商店中产品的库存等情况。&lt;/p&gt;&#xA;&lt;p&gt;这些国家/地区有不同的用例，因为他们想要监控其零售店特有的事物。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1999px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&#xA;&lt;一&#xA;类=“灯箱链接标题”&#xA;href=&#34;/media/blog/schwarz-IT-spotlight/schwarz-IT-IoT-dashboard.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“lazyload mb-0”&#xA;data-src=&#34;/media/blog/schwarz-IT-spotlight/schwarz-IT-IoT-dashboard.png&#34;data-srcset=&#34;/media/blog/schwarz-IT-spotlight/schwarz-IT-IoT-dashboard. png?w=320 320w，/media/blog/schwarz-IT-spotlight/schwarz-IT-IoT-dashboard.png?w=550 550w，/media/blog/schwarz-IT-spotlight/schwarz-IT-IoT-仪表板.png?w=750 750w，/media/blog/schwarz-IT-spotlight/schwarz-IT-IoT-dashboard.png?w=900 900w，/media/blog/schwarz-IT-spotlight/schwarz-IT- IoT-dashboard.png?w=1040 1040w，/media/blog/schwarz-IT-spotlight/schwarz-IT-IoT-dashboard.png?w=1240 1240w，/media/blog/schwarz-IT-spotlight/schwarz- IT-IoT-dashboard.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;Grafana 中 IoT 仪表板的屏幕截图。&#34;&#xA;宽度=“1999”&#xA;高度=“875”&#xA;title=&#34;*Grafana 仪表板提供德国 Kaufland 商店的物联网设备、库存和不间断电源 (UPS) 的概述。*&#34;&#xA;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src=&#34;/media/blog/schwarz-IT-spotlight/schwarz-IT-IoT-dashboard.png&#34;&#xA;alt=&#34;Grafana 中 IoT 仪表板的屏幕截图。&#34;&#xA;宽度=“1999”&#xA;高度=“875”&#xA;title=&#34;*Grafana 仪表板提供德国 Kaufland 商店的物联网设备、库存和不间断电源 (UPS) 的概述。*&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;figcaption class=&#34;w-100p title text-gray-13 &#34;&gt;&lt;em&gt;Grafana 仪表板，提供德国 Kaufland 商店的 IoT 设备、库存和不间断电源 (UPS) 的概览。&lt;/em&gt;&lt; /图标题&gt;&#xA;&lt;/a&gt;&#xA;&lt;/图&gt;&#xA;&lt;h2 id=&#34;how-did-you-help-facilitate-grafana-adoption-at-such-large-scale&#34;&gt;您如何帮助促进 Grafana 如此大规模的采用？&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Felix&lt;/strong&gt;：我们开始收到有关如何在 Grafana 中执行操作的具体问题。 Grafana Labs 的网站上有非常好的&lt;a href=&#34;/videos/&#34;&gt;网络研讨会和视频&lt;/a&gt;，但它们并未针对我们的环境进行定制。&lt;/p&gt;&#xA;&lt;p&gt;因此我们开始了自己的内部 Grafana 培训。我们创建了这个大团队陈我们在其中分享仪表板创意、我们要尝试的下一件大事、成功故事——每天都会有新人加入。我们会寻找使用 Grafana 的客户，询问他们的用例和仪表板，并要求他们在我们的 Teams 频道上分享有关它的博客文章。&lt;/p&gt;&#xA;&lt;p&gt;我们还每三到四个月举办一次培训课程。我们正在做一个基础的，今年将开始一个高级的。但每次培训大约有 100 名用户。它非常大，我们需要更多。&lt;/p&gt;&#xA;&lt;h2 id=&#34;what-inspired-you-to-host-your-internal-grafana-hackathon-and-what-has-the-impact-been&#34;&gt;是什么促使您举办内部 Grafana 黑客马拉松以及产生了什么影响去过吗？&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Felix&lt;/strong&gt;：2023 年 3 月举办首届黑客马拉松的想法源于希望帮助推动 Grafana 在各国的使用。面对面地，你可以举办小型团队研讨会并进行面对面的交流——我们想要知识转移。施瓦茨集团太大了，Lidl国家就像他们自己的公司一样，所以他们之间没有太多的知识转移或交流。所以我们想，好吧，我们就像他们的连接点。让我们创建一个黑客马拉松。&lt;/p&gt;&#xA;&lt;p&gt;我们制定了一个议程，向他们展示了我们的目标。然后我们询问了他们使用 Grafana 的目标以及他们想要解决的问题。我们与不同的国家进行集思广益，然后分成小组，为他们的特定问题构建一个仪表板。然后每个人都分享了他们的仪表板，并且非常兴奋；人们共享 JSON 是因为每个人都说，“是的，我需要它。”&lt;/p&gt;&#xA;&lt;p&gt;黑客马拉松之后，我们在各个国家/地区的 Grafana 使用量有了很大的增加。几周之内，增加了 100 多个仪表板。这是我们的主要目标之一。&lt;/p&gt;&#xA;&lt;h2 id=&#34;you-use-a-number-of-products-in-your-monitoring-stack-why-focus-only-on-grafana-for-these-hackathons&#34;&gt;您在您的监控中使用了多种产品监控堆栈。为什么这些黑客马拉松只关注 Grafana？&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Felix&lt;/strong&gt;：因为您可以通过多种不同方式使用 Grafana；我们将它用作一切的可视化层。这创造了这种社区意识，也是黑客马拉松如此成功的原因。我们确实在努力将所有数据推送到 Grafana，使非技术人员和技术人员都可以使用相同的界面。&lt;/p&gt;&#xA;&lt;块引用&gt;&#xA;&lt;h3 id=&#34;whats-next-for-schwarz-it&#34;&gt;Schwarz IT 的下一步发展&lt;/h3&gt;&#xA;&lt;p&gt;Schwarz IT 最近为其位于索非亚的 IT 中心举办了第二届 Grafana 黑客马拉松，以进一步扩大 Grafana 的使用。&lt;/p&gt;&#xA;&lt;p&gt;“我们还将为各国推出标准仪表板，以使用预定义视图并包括业务流程监控可视化，”监控和可观察性解决方案团队负责人 Michael Dallman 说道。 “对于这些国家，我们还将深入研究我们所有的监控工具，当然包括 Grafana。”&lt;/p&gt;&#xA;&lt;/块q评级&gt;</description>
      <pubDate>Fri, 09 Aug 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【All about span events: what they are and how to query them】关于跨度事件的所有信息：它们是什么以及如何查询它们</title>
      <link>https://grafana.com/blog/2024/08/15/all-about-span-events-what-they-are-and-how-to-query-them/</link>
      <description>【&lt;p&gt;If you&amp;rsquo;re already familiar with distributed tracing, you know that spans are the building blocks of traces. But are you sleeping on what &lt;a href=&#34;https://opentelemetry.io/docs/concepts/signals/traces/#span-events&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;span events&lt;/a&gt; can do for you?&lt;/p&gt;&#xA;&lt;p&gt;First, you may need a wake-up call as to what a span event even is. While spans represent units of work or operation within a trace, &lt;strong&gt;a span event is a unique point in time during the span&amp;rsquo;s duration&lt;/strong&gt;. While spans help build the structural hierarchy of your services, span events can provide a deeper level of granularity to help debug your application faster and maintain optimal performance.&lt;/p&gt;&#xA;&lt;div class=&#34;shortcode youtube&#34;&gt;&#xA;&lt;iframe src=&#34;https://www.youtube.com/embed/bgQblHktS78?rel=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;Why use span events instead of just adding more spans or span attributes? While you can always add more spans, span events are much more lightweight and won&amp;rsquo;t significantly increase the size of your traces. Span attributes are also lightweight, but they lack the ability to store timestamps, which is where events really shine.&lt;/p&gt;&#xA;&lt;p&gt;In this blog post, we&amp;rsquo;ll cover when to add span events to gain different insights and how to query span events using TraceQL in Grafana Cloud Traces.&lt;/p&gt;&#xA;&lt;h2 id=&#34;when-to-add-span-events&#34;&gt;When to add span events&lt;/h2&gt;&#xA;&lt;p&gt;Now that we understand the benefits of span events, here are some ways you can leverage events into your tracing strategy to help you gain more valuable insights from your tracing data.&lt;/p&gt;&#xA;&lt;h3 id=&#34;error-tracking&#34;&gt;Error tracking&lt;/h3&gt;&#xA;&lt;p&gt;Let’s be honest: People don&amp;rsquo;t typically check dashboards, logs, or traces when everything is running smoothly. But more eyes will pay attention when there is an alert that one of your pods is crashlooping because of an error in a function that is shared across multiple services with various entry points.&lt;/p&gt;&#xA;&lt;p&gt;While traditional logs can capture errors, they sometimes lack the necessary context to help you fully chase down the issue. With tracing, however, you can record an &lt;a href=&#34;https://opentelemetry.io/docs/specs/otel/trace/exceptions/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;exception event&lt;/a&gt;. This event becomes part of a span, which in turn is part of a comprehensive trace, allowing you to track the exact flow and sequence of actions leading up to the error.&lt;/p&gt;&#xA;&lt;h3 id=&#34;performance-monitoring&#34;&gt;Performance monitoring&lt;/h3&gt;&#xA;&lt;p&gt;A major benefit of using span events is their ability to capture precise timestamps. This allows us to measure the performance of specific steps within a span.&lt;/p&gt;&#xA;&lt;p&gt;For instance, if a request is taking longer than expected, we can log all intermediate steps as span events. We can track the time to establish a connection with an external service, the time to acquire a read lock, or even the time to execute a database query. This detailed information can help us pinpoint whether the delay is due to network latency, a data locking issue, or the need for database query optimization.&lt;/p&gt;&#xA;&lt;h3 id=&#34;sampled-structured-logging&#34;&gt;Sampled structured logging&lt;/h3&gt;&#xA;&lt;p&gt;Unlike span attributes, span events can be viewed as structured logs. One advantage of using span events over traditional logs is that, because they are part of a trace, they allow us to easily follow the flow of execution.&lt;/p&gt;&#xA;&lt;p&gt;Another often overlooked benefit is that tracing has richer sampling capabilities than logs. Let’s say you want to monitor the inputs and outputs of a function that is executed across multiple entry points. But in this scenario, you don’t need the information about all the entry points; you only need to know about one or two specific entry points. With tracing, we can control &lt;a href=&#34;https://opentelemetry.io/docs/concepts/sampling/#head-sampling&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;head sampling&lt;/a&gt; rates for different entry points, so that we can isolate the data for the entry points we want and at the rate in which we need.&lt;/p&gt;&#xA;&lt;h2 id=&#34;how-to-query-span-events-with-traceql&#34;&gt;How to query span events with TraceQL&lt;/h2&gt;&#xA;&lt;p&gt;The initial versions of &lt;a href=&#34;/docs/tempo/latest/traceql/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;TraceQL&lt;/a&gt; — the query language designed for selecting traces in &lt;a href=&#34;/oss/tempo/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Tempo&lt;/a&gt;, which also powers &lt;a href=&#34;/products/cloud/traces/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Cloud Traces&lt;/a&gt; — brought in the concept of scopes, supporting span, resource, and trace scopes. With the latest iteration, we&amp;rsquo;ve added support for event scope, allowing Tempo users to query for span events. More specifically, TraceQL now offers support for span event names and attributes.&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;Note: This new feature is currently available in Grafana Cloud Traces and will soon be available in the next Grafana Tempo OSS release, which we will announce soon.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;event-name&#34;&gt;Event name&lt;/h3&gt;&#xA;&lt;p&gt;To query for event names, simply use the syntax &lt;code&gt;event:name&lt;/code&gt;. Below is an example query for spansets where there is at least one event with &lt;code&gt;name&lt;/code&gt; value of &lt;code&gt;updated database&lt;/code&gt;.&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;button x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;Copy code to clipboard&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;Copy&lt;/span&gt;&#xA;&lt;/button&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;{ event:name = &amp;#34;updated database&amp;#34; }&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 918px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&#xA;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/span-events/span-events-query-traceql.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/span-events/span-events-query-traceql.png&#34;data-srcset=&#34;/media/blog/span-events/span-events-query-traceql.png?w=320 320w, /media/blog/span-events/span-events-query-traceql.png?w=550 550w, /media/blog/span-events/span-events-query-traceql.png?w=750 750w, /media/blog/span-events/span-events-query-traceql.png?w=900 900w, /media/blog/span-events/span-events-query-traceql.png?w=1040 1040w, /media/blog/span-events/span-events-query-traceql.png?w=1240 1240w, /media/blog/span-events/span-events-query-traceql.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;TraceQL query for span event&#34;&#xA;width=&#34;918&#34;&#xA;height=&#34;554&#34;&#xA;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/span-events/span-events-query-traceql.png&#34;&#xA;alt=&#34;TraceQL query for span event&#34;&#xA;width=&#34;918&#34;&#xA;height=&#34;554&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;/a&gt;&#xA;&lt;/figure&gt;&#xA;&lt;p&gt;The query returned this matching trace where there is one span with one event matching the name &lt;code&gt;updated database&lt;/code&gt;. By clicking on the span id, we can see more information about this event.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 931px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&#xA;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/span-events/span-events-span-id.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/span-events/span-events-span-id.png&#34;data-srcset=&#34;/media/blog/span-events/span-events-span-id.png?w=320 320w, /media/blog/span-events/span-events-span-id.png?w=550 550w, /media/blog/span-events/span-events-span-id.png?w=750 750w, /media/blog/span-events/span-events-span-id.png?w=900 900w, /media/blog/span-events/span-events-span-id.png?w=1040 1040w, /media/blog/span-events/span-events-span-id.png?w=1240 1240w, /media/blog/span-events/span-events-span-id.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;TraceQL query results for a span event&#34;&#xA;width=&#34;931&#34;&#xA;height=&#34;723&#34;&#xA;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/span-events/span-events-span-id.png&#34;&#xA;alt=&#34;TraceQL query results for a span event&#34;&#xA;width=&#34;931&#34;&#xA;height=&#34;723&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;/a&gt;&#xA;&lt;/figure&gt;&#xA;&lt;p&gt;Here we can see that there were actually two events within this span. One event with the name &lt;code&gt;updating database&lt;/code&gt; and another with the name &lt;code&gt;updated database&lt;/code&gt;, which is the one we searched for. Based on the two events’ timestamps, we can see that it took about 60ms for the database operation to finish.&lt;/p&gt;&#xA;&lt;h3 id=&#34;event-attribute&#34;&gt;Event attribute&lt;/h3&gt;&#xA;&lt;p&gt;To query for event attributes, simply use the &lt;code&gt;event.&lt;/code&gt; syntax. Below is an example of a query for an event attribute key called &lt;code&gt;exception.message&lt;/code&gt; with the value partially matching &lt;code&gt;index out of range&lt;/code&gt;.&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;button x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;Copy code to clipboard&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;Copy&lt;/span&gt;&#xA;&lt;/button&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;{ event.exception.message =~ “.*index out of range.*” }&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 935px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&#xA;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/span-events/span-events-event-attribute.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/span-events/span-events-event-attribute.png&#34;data-srcset=&#34;/media/blog/span-events/span-events-event-attribute.png?w=320 320w, /media/blog/span-events/span-events-event-attribute.png?w=550 550w, /media/blog/span-events/span-events-event-attribute.png?w=750 750w, /media/blog/span-events/span-events-event-attribute.png?w=900 900w, /media/blog/span-events/span-events-event-attribute.png?w=1040 1040w, /media/blog/span-events/span-events-event-attribute.png?w=1240 1240w, /media/blog/span-events/span-events-event-attribute.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;Event attribute query in TraceQL using span events&#34;&#xA;width=&#34;935&#34;&#xA;height=&#34;555&#34;&#xA;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/span-events/span-events-event-attribute.png&#34;&#xA;alt=&#34;Event attribute query in TraceQL using span events&#34;&#xA;width=&#34;935&#34;&#xA;height=&#34;555&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;/a&gt;&#xA;&lt;/figure&gt;&#xA;&lt;p&gt;Here, we were able to find a matching trace with spans containing an event where the attribute &lt;code&gt;exception.message&lt;/code&gt; partially matched &lt;code&gt;index out of range&lt;/code&gt;. By clicking on the corresponding span id, we can see a detailed view of the trace.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 929px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&#xA;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/span-events/span-events-span-details.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/span-events/span-events-span-details.png&#34;data-srcset=&#34;/media/blog/span-events/span-events-span-details.png?w=320 320w, /media/blog/span-events/span-events-span-details.png?w=550 550w, /media/blog/span-events/span-events-span-details.png?w=750 750w, /media/blog/span-events/span-events-span-details.png?w=900 900w, /media/blog/span-events/span-events-span-details.png?w=1040 1040w, /media/blog/span-events/span-events-span-details.png?w=1240 1240w, /media/blog/span-events/span-events-span-details.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;Detailed view of trace after TraceQL query for event attributes&#34;&#xA;width=&#34;929&#34;&#xA;height=&#34;691&#34;&#xA;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/span-events/span-events-span-details.png&#34;&#xA;alt=&#34;Detailed view of trace after TraceQL query for event attributes&#34;&#xA;width=&#34;929&#34;&#xA;height=&#34;691&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;/a&gt;&#xA;&lt;/figure&gt;&#xA;&lt;p&gt;With the trace view open, we can see the sequence of steps that took place up until the error.&lt;/p&gt;&#xA;&lt;h2 id=&#34;learn-more-about-span-events-and-traceql&#34;&gt;Learn more about span events and TraceQL&lt;/h2&gt;&#xA;&lt;p&gt;Integrating span events into your tracing strategy can help you improve your debugging and application performance. They add an extra layer of granularity without blowing up your trace size. Additionally, tracing offers richer sampling capabilities compared to traditional logs, allowing you to selectively capture relevant data within span events. With the latest updates to TraceQL, you can now query these events to help you monitor performance and troubleshoot issues. So, what are you waiting for?&lt;/p&gt;&#xA;&lt;p&gt;To learn more about tracing and TraceQL, check out our on-demand webinar &amp;ldquo;&lt;a href=&#34;/go/webinar/getting-started-with-tracing-and-grafana-tempo/&#34;&gt;Getting started with tracing and Grafana Tempo&lt;/a&gt;.&amp;rdquo;&lt;/p&gt;&#xA;&lt;p&gt;You can also reach out to the Grafana Tempo team on the &lt;a href=&#34;https://grafana.slack.com/archives/C01D981PEE5&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Grafana Labs Community Slack channel&lt;/a&gt; or find Grafana Tempo in &lt;a href=&#34;https://github.com/grafana/tempo&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;*The easiest way to get started with tracing and TraceQL is with &lt;a href=&#34;/products/cloud/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt;. We have a generous forever-free tier and plans for every use case. &lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Sign up&lt;/a&gt; for free now!&lt;/p&gt;】&lt;p&gt;如果您已经熟悉分布式跟踪，您就会知道跨度是跟踪的构建块。但是您是否在考虑 &lt;a href=&#34;https://opentelemetry.io/docs/concepts/signals/traces/#span-events&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;span 事件&lt;/a&gt;能为您做什么？&lt;/p&gt;&#xA;&lt;p&gt;首先，您可能需要了解一下跨度事件是什么。虽然跨度代表跟踪内的工作或操作单元，但&lt;strong&gt;跨度事件是跨度持续时间内的唯一时间点&lt;/strong&gt;。虽然跨度有助于构建服务的结构层次结构，但跨度事件可以提供更深层次的粒度，以帮助更快地调试应用程序并保持最佳性能。&lt;/p&gt;&#xA;&lt;div class=&#34;shortcode youtube&#34;&gt;&#xA;&lt;iframe src=&#34;https://www.youtube.com/embed/bgQblHktS78?rel=0&#34; style=&#34;位置：绝对；顶部：0；左侧：0；宽度：100%；高度：100%；边框： 0;” allowedfullscreen title=&#34;YouTube 视频&#34;&gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;为什么使用跨度事件而不是仅仅添加更多跨度或跨度属性？虽然您始终可以添加更多跨度，但跨度事件更加轻量级，并且不会显着增加跟踪的大小。 Span 属性也是轻量级的，但它们缺乏存储时间戳的能力，而这正是事件真正的亮点。&lt;/p&gt;&#xA;&lt;p&gt;在这篇博文中，我们将介绍何时添加跨度事件以获得不同的见解，以及如何在 Grafana Cloud Traces 中使用 TraceQL 查询跨度事件。&lt;/p&gt;&#xA;&lt;h2 id=&#34;when-to-add-span-events&#34;&gt;何时添加跨度事件&lt;/h2&gt;&#xA;&lt;p&gt;现在我们了解了跨度事件的好处，您可以通过以下一些方法将事件纳入您的跟踪策略，以帮助您从跟踪数据中获得更有价值的见解。&lt;/p&gt;&#xA;&lt;h3 id=&#34;error-tracking&#34;&gt;错误跟踪&lt;/h3&gt;&#xA;&lt;p&gt;说实话：当一切顺利运行时，人们通常不会检查仪表板、日志或跟踪。但是，当出现警报称您的一个 pod 由于具有不同入口点的多个服务共享的函数出现错误而导致崩溃循环时，更多的目光会注意到。&lt;/p&gt;&#xA;&lt;p&gt;虽然传统日志可以捕获错误，但它们有时缺乏必要的上下文来帮助您完全追查问题。但是，通过跟踪，您可以记录&lt;a href=&#34;https://opentelemetry.io/docs/specs/otel/trace/exceptions/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;异常事件&lt;/a &gt;。此事件成为跨度的一部分，而跨度又是综合跟踪的一部分，使您能够跟踪导致错误的确切流程和操作顺序。&lt;/p&gt;&#xA;&lt;h3 id=&#34;performance-monitoring&#34;&gt;性能监控&lt;/h3&gt;&#xA;&lt;p&gt;使用跨度事件的一个主要好处是它们能够捕获精确的时间戳。这使我们能够衡量一个跨度内特定步骤的性能。&lt;/p&gt;&#xA;&lt;p&gt;例如，如果请求花费的时间比预期长，我们可以将所有中间步骤记录为跨度事件。我们可以跟踪与外部服务建立连接的时间、获取读锁的时间，或者甚至是执行数据库查询的时间。这些详细信息可以帮助我们确定延迟是否是由于网络延迟、数据锁定问题或数据库查询优化的需要造成的。&lt;/p&gt;&#xA;&lt;h3 id=&#34;sampled-structed-logging&#34;&gt;结构化日志记录示例&lt;/h3&gt;&#xA;&lt;p&gt;与span属性不同，span事件可以被视为结构化日志。与传统日志相比，使用跨度事件的优点之一是，因为它们是跟踪的一部分，所以它们使我们能够轻松跟踪执行流程。&lt;/p&gt;&#xA;&lt;p&gt;另一个经常被忽视的好处是跟踪比日志具有更丰富的采样功能。假设您想要监视跨多个入口点执行的函数的输入和输出。但在这种情况下，您不需要所有入口点的信息；您只需要了解一两个特定的切入点。通过跟踪，我们可以控制&lt;a href=&#34;https://opentelemetry.io/docs/concepts/sampling/#head-sampling&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;头部采样&lt;/a&gt;率不同的入口点，以便我们可以按照我们需要的速率隔离我们想要的入口点的数据。&lt;/p&gt;&#xA;&lt;h2 id=&#34;how-to-query-span-events-with-traceql&#34;&gt;如何使用 TraceQL 查询 Span 事件&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;/docs/tempo/latest/traceql/?pg=blog&amp;plcmt=body-txt&#34;&gt;TraceQL&lt;/a&gt; 的初始版本 — 用于在 &lt;a href=&#34; 中选择跟踪的查询语言/oss/tempo/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana Tempo&lt;/a&gt;，它还支持 &lt;a href=&#34;/products/cloud/traces/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana Cloud Traces &lt;/a&gt; — 引入了范围的概念，支持跨度、资源和跟踪范围。在最新的迭代中，我们添加了对事件范围的支持，允许 Tempo 用户查询跨度事件。更具体地说，TraceQL 现在提供对跨度事件名称和属性的支持。&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;注意：这项新功能目前已在 Grafana Cloud Traces 中提供，并将很快在我们即将发布的下一个 Grafana Tempo OSS 版本中提供。&lt;/em&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;event-name&#34;&gt;活动名称&lt;/h3&gt;&#xA;&lt;p&gt;要查询事件名称，只需使用语法&lt;code&gt;event:name&lt;/code&gt;。下面是一个跨集查询示例，其中至少有一个 &lt;code&gt;name&lt;/code&gt; 值为 &lt;code&gt;updated database&lt;/code&gt; 的事件。&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;按钮 x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;将代码复制到剪贴板&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;复制&lt;/span&gt;&#xA;&lt;/按钮&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;{ event:name = &#34;更新的数据库&#34; }&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：918px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/span-events/span-events-query-traceql.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/blog/span-events/span-events-query-traceql.png&#34;data-srcset=&#34;/media/blog/span-events/span-events-query-traceql.png?w= 320 320w，/media/blog/span-events/span-events-query-traceql.png?w=550 550w，/media/blog/span-events/span-events-query-traceql.png?w=750 750w , /media/blog/span-events/span-events-query-traceql.png?w=900 900w, /media/blog/span-events/span-events-query-traceql.png?w=1040 1040w, /媒体/博客/span-events/span-events-query-traceql.png？w=1240 1240w，/media/blog/span-events/span-events-query-traceql.png？w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;跨度事件的 TraceQL 查询&#34;&#xA;宽度=“918”&#xA;高度=“554”&#xA;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/span-events/span-events-query-traceql.png”&#xA;alt=&#34;TraceQL 查询跨度事件&#34;&#xA;宽度=“918”&#xA;高度=“554”&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;/a&gt;&#xA;&lt;/图&gt;&#xA;&lt;p&gt;查询返回了这一匹配跟踪，其中有一个范围包含一个与名称&lt;code&gt;更新的数据库&lt;/code&gt;匹配的事件。通过点击span id，我们可以看到有关此事件的更多信息。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：931px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&#xA;&lt;一&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/span-events/span-events-span-id.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/blog/span-events/span-events-span-id.png&#34;data-srcset=&#34;/media/blog/span-events/span-events-span-id.png?w= 320 320w，/media/blog/span-events/span-events-span-id.png?w=550 550w，/media/blog/span-events/span-events-span-id.png?w=750 750w , /media/blog/span-events/span-events-span-id.png?w=900 900w, /media/blog/span-events/span-events-span-id.png?w=1040 1040w, /媒体/博客/span-events/span-events-span-id.png？w=1240 1240w，/media/blog/span-events/span-events-span-id.png？w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;跨度事件的 TraceQL 查询结果&#34;&#xA;宽度=“931”&#xA;高度=“723”&#xA;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/span-events/span-events-span-id.png”&#xA;alt=&#34;跨度事件的 TraceQL 查询结果&#34;&#xA;宽度=“931”&#xA;高度=“723”&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;/a&gt;&#xA;&lt;/图&gt;&#xA;&lt;p&gt;在这里我们可以看到这个跨度内实际上有两个事件。一个事件的名称为“更新数据库”，另一个事件的名称为“更新数据库”，这就是我们搜索的事件。根据两个事件的时间戳，我们可以看到数据库操作大约需要 60ms 才能完成。&lt;/p&gt;&#xA;&lt;h3 id=&#34;event-attribute&#34;&gt;事件属性&lt;/h3&gt;&#xA;&lt;p&gt;要查询事件属性，只需使用 &lt;code&gt;event.&lt;/code&gt; 语法。下面是查询名为 &lt;code&gt;exception.message&lt;/code&gt; 的事件属性键的示例，其值部分匹配 &lt;code&gt;index out of range&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;跨度类=“代码-剪贴板&#34;&gt;&#xA;&lt;按钮 x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;将代码复制到剪贴板&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;复制&lt;/span&gt;&#xA;&lt;/按钮&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;{ event.exception.message =~ “.*索引超出范围。*” }&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：935px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&#xA;&lt;一&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/span-events/span-events-event-attribute.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/blog/span-events/span-events-event-attribute.png&#34;data-srcset=&#34;/media/blog/span-events/span-events-event-attribute.png?w= 320 320w、/media/blog/span-events/span-events-event-attribute.png?w=550 550w、/media/blog/span-events/span-events-event-attribute.png?w=750 750w , /media/blog/span-events/span-events-event-attribute.png?w=900 900w, /media/blog/span-events/span-events-event-attribute.png?w=1040 1040w, /媒体/博客/span-events/span-events-event-attribute.png？w=1240 1240w，/media/blog/span-events/span-events-event-attribute.png？w=1920 1920w”&#xA;data-size=&#34;auto&#34;alt=&#34;使用跨度事件在 TraceQL 中查询事件属性&#34;&#xA;宽度=“935”&#xA;高度=“555”&#xA;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/span-events/span-events-event-attribute.png”&#xA;alt=&#34;使用跨度事件在 TraceQL 中查询事件属性&#34;&#xA;宽度=“935”&#xA;高度=“555”&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;/a&gt;&#xA;&lt;/图&gt;&#xA;&lt;p&gt;在这里，我们能够找到一个匹配的跟踪，其跨度包含一个事件，其中属性&lt;code&gt;exception.message&lt;/code&gt;部分匹配&lt;code&gt;索引超出范围&lt;/code&gt;。通过点击相应的span id，我们可以看到跟踪的详细视图。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：929px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&#xA;&lt;一&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/span-events/span-events-span-details.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/blog/span-events/span-events-span-details.png&#34;data-srcset=&#34;/media/blog/span-events/span-events-span-details.png?w= 320 320w，/media/blog/span-events/span-events-span-details.png?w=550 550w，/media/blog/span-events/span-events-span-details.png?w=750 750w , /media/blog/span-events/span-events-span-details.png?w=900 900w, /media/blog/span-events/span-events-span-details.png?w=1040 1040w, /媒体/博客/span-events/span-events-span-details.png？w=1240 1240w，/media/blog/span-events/span-events-span-details.png？w=1920 1920w&#34;&#xA;data-size=&#34;auto&#34;alt=&#34;TraceQL 查询事件属性后跟踪的详细视图&#34;&#xA;宽度=“929”&#xA;高度=“691”&#xA;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/span-events/span-events-span-details.png”&#xA;alt=&#34;德TraceQL 查询事件属性后跟踪的尾部视图&#34;&#xA;宽度=“929”&#xA;高度=“691”&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;/a&gt;&#xA;&lt;/图&gt;&#xA;&lt;p&gt;打开跟踪视图后，我们可以看到发生错误之前发生的步骤顺序。&lt;/p&gt;&#xA;&lt;h2 id=&#34;learn-more-about-span-events-and-traceql&#34;&gt;了解有关跨度事件和 TraceQL 的更多信息&lt;/h2&gt;&#xA;&lt;p&gt;将跨度事件集成到跟踪策略中可以帮助您提高调试和应用程序性能。它们添加了额外的粒度层，而不会放大您的迹线大小。此外，与传统日志相比，跟踪提供了更丰富的采样功能，允许您有选择地捕获跨度事件中的相关数据。通过 TraceQL 的最新更新，您现在可以查询这些事件以帮助您监控性能并解决问题。那么，你还在等什么？&lt;/p&gt;&#xA;&lt;p&gt;要了解有关跟踪和 TraceQL 的更多信息，请观看我们的点播网络研讨会“&lt;a href=&#34;/go/webinar/getting-started-with-tracing-and-grafana-tempo/&#34;&gt;跟踪和跟踪入门Grafana 节奏&lt;/a&gt;。”&lt;/p&gt;&#xA;&lt;p&gt;您还可以通过 &lt;a href=&#34;https://grafana.slack.com/archives/C01D981PEE5&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Grafana Labs Community Slack 联系 Grafana Tempo 团队频道&lt;/a&gt; 或在 &lt;a href=&#34;https://github.com/grafana/tempo&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;GitHub&lt;/a&gt; 中找到 Grafana Tempo。&lt;/p&gt;&#xA;&lt;p&gt;*开始使用跟踪和 TraceQL 的最简单方法是使用 &lt;a href=&#34;/products/cloud/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt;。我们为每个用例提供慷慨的永久免费套餐和计划。 &lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;plcmt=body-txt&#34;&gt;立即免费注册&lt;/a&gt;！&lt;/p&gt;</description>
      <pubDate>Thu, 15 Aug 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Why companies choose Adaptive Metrics and how they save time and (a lot of) money】为什么公司选择自适应指标以及它们如何节省时间和（大量）金钱</title>
      <link>https://grafana.com/blog/2024/08/12/why-companies-choose-adaptive-metrics-and-how-they-save-time-and-a-lot-of-money/</link>
      <description>【&lt;p&gt;Let&amp;rsquo;s cut to the chase: Managing metric volumes at scale is hard. In fact, when we asked the open source observability community about their biggest concerns in this year&amp;rsquo;s &lt;a href=&#34;/observability-survey/?pg=blog&amp;amp;plcmt=body-txt#whats-next-addressing-gaps-and-driving-innovation&#34;&gt;Grafana Labs Observability Survey&lt;/a&gt;, the top four responses — cost, complexity, cardinality, and signal-to-noise ratio — can all be tied back to exponential growth in telemetry data.&lt;/p&gt;&#xA;&lt;p&gt;To help ease those problem areas, we built &lt;a href=&#34;/products/cloud/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Adaptive Metrics&lt;/a&gt;, a feature in Grafana Cloud that helps cut costs by aggregating unused and partially used metrics into lower cardinality versions.&lt;/p&gt;&#xA;&lt;p&gt;Adaptive Metrics has delivered a &lt;strong&gt;35% reduction in metrics costs on average for more than 1,200 organizations&lt;/strong&gt;. With 1,400 stacks performing aggregations and 350 million total aggregated series, the results are substantial, impactful, and can directly benefit your bottom line.&lt;/p&gt;&#xA;&lt;p&gt;But for the most successful observability teams, these savings aren&amp;rsquo;t the endgame—they&amp;rsquo;re just the beginning. In this blog, we&amp;rsquo;ll show you how four Grafana Cloud customers are taking advantage of Adaptive Metrics and the savings it affords them to:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Improve and further invest in their observability stack&lt;/li&gt;&#xA;&lt;li&gt;Focus more on areas that help drive business value&lt;/li&gt;&#xA;&lt;li&gt;Help developers act faster and more effectively&lt;/li&gt;&#xA;&lt;li&gt;Take a more proactive approach to incident management&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;invest-savings-into-improving-observability-insights&#34;&gt;Invest savings into improving observability insights&lt;/h2&gt;&#xA;&lt;p&gt;With an astounding 75 million active series, SailPoint needed to find a way to reduce their metrics volume without disrupting their developers&amp;rsquo; experience. Thankfully, the identity security company was able to do just that with Adaptive Metrics, &lt;strong&gt;reducing their metrics volume by 33%&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;p&gt;“The great thing with Adaptive Metrics is … it just tells me exactly what I’m looking for. If I want the metrics that we’re not seeing usage on, the tool gives me that information a lot quicker than having to go dig for it,” said Lydia Clarke, a DevOps engineer at SailPoint.&lt;/p&gt;&#xA;&lt;p&gt;But SailPoint didn&amp;rsquo;t just see the savings as a way to reduce their bottom line. Instead, they used that money to invest deeper into observability, adopting more Grafana Cloud offerings and enhancing their overall monitoring capabilities.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1999px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&#xA;&lt;a&#xA;class=&#34;lightbox-link captioned&#34;&#xA;href=&#34;/media/blog/high-value-metrics/sailpoint-dashboard.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload mb-0&#34;&#xA;data-src=&#34;/media/blog/high-value-metrics/sailpoint-dashboard.png&#34;data-srcset=&#34;/media/blog/high-value-metrics/sailpoint-dashboard.png?w=320 320w, /media/blog/high-value-metrics/sailpoint-dashboard.png?w=550 550w, /media/blog/high-value-metrics/sailpoint-dashboard.png?w=750 750w, /media/blog/high-value-metrics/sailpoint-dashboard.png?w=900 900w, /media/blog/high-value-metrics/sailpoint-dashboard.png?w=1040 1040w, /media/blog/high-value-metrics/sailpoint-dashboard.png?w=1240 1240w, /media/blog/high-value-metrics/sailpoint-dashboard.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A look at how Sailpoint tracks their active series limits&#34;&#xA;width=&#34;1999&#34;&#xA;height=&#34;1249&#34;&#xA;title=&#34;*A look at how Sailpoint tracks their active series limits*&#34;&#xA;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/high-value-metrics/sailpoint-dashboard.png&#34;&#xA;alt=&#34;A look at how Sailpoint tracks their active series limits&#34;&#xA;width=&#34;1999&#34;&#xA;height=&#34;1249&#34;&#xA;title=&#34;*A look at how Sailpoint tracks their active series limits*&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;figcaption class=&#34;w-100p caption text-gray-13 text-left &#34;&gt;&lt;em&gt;A look at how Sailpoint tracks their active series limits&lt;/em&gt;&lt;/figcaption&gt;&#xA;&lt;/a&gt;&#xA;&lt;/figure&gt;&#xA;&lt;p&gt;In addition to using Grafana for visualizations and Grafana Cloud Metrics for storage and management, SailPoint is looking to extend their stack to include Grafana Cloud Frontend Observability for real user monitoring.&lt;/p&gt;&#xA;&lt;p&gt;“We’re in the middle of our observability journey, but we’re just at the beginning of the relationship with Grafana Labs,” says Omar Lopez, head of the observability team. “We’re exploring more and more of the features and services in Grafana Cloud. It’s like being a kid in a candy store — we’re looking at everything.”&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;Read more about how &lt;a href=&#34;/success/sailpoint/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;SailPoint&amp;rsquo;s prioritization of high-value metrics&lt;/a&gt; has translated to investments in a broader and more comprehensive observability stack.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;spend-time-and-effort-on-areas-that-drive-value&#34;&gt;Spend time and effort on areas that drive value&lt;/h2&gt;&#xA;&lt;p&gt;When you understand which metrics are essential to your operations, you&amp;rsquo;re better equipped to allocate your resources. Grafana Cloud provides clear insights into metric usage, helping you distinguish between high-value metrics that drive business decisions and low-value metrics that inflate costs without adding significant value.&lt;/p&gt;&#xA;&lt;p&gt;That makes a lot of sense in theory, but it can lead to plenty of trepidation in reality. For example, engineers at TeleTracking, an integrated healthcare operations platform provider, were skeptical when the observability team broached the idea of eliminating unused metrics. The fear was that removing or aggregating metrics might disrupt critical services or lead to blind spots in their observability. Those concerns were quickly dispelled when they saw the results of the Adaptive Metrics recommendations.&lt;/p&gt;&#xA;&lt;p&gt;&amp;ldquo;Some engineers balked at the idea at first, but once they started using the key labels and standing up dashboards and easily writing alerts, they were quick to see the value,&amp;rdquo; says Oren Lion, Director of Software Engineering, Productivity Engineering at TeleTracking. They used Adaptive Metrics to revert to less verbose metrics by using aggregations, &lt;strong&gt;reducing their spend on Grafana Cloud Metrics by 50%&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1538px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&#xA;&lt;a&#xA;class=&#34;lightbox-link captioned&#34;&#xA;href=&#34;/media/blog/high-value-metrics/teletracking-dashboard.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload mb-0&#34;&#xA;data-src=&#34;/media/blog/high-value-metrics/teletracking-dashboard.png&#34;data-srcset=&#34;/media/blog/high-value-metrics/teletracking-dashboard.png?w=320 320w, /media/blog/high-value-metrics/teletracking-dashboard.png?w=550 550w, /media/blog/high-value-metrics/teletracking-dashboard.png?w=750 750w, /media/blog/high-value-metrics/teletracking-dashboard.png?w=900 900w, /media/blog/high-value-metrics/teletracking-dashboard.png?w=1040 1040w, /media/blog/high-value-metrics/teletracking-dashboard.png?w=1240 1240w, /media/blog/high-value-metrics/teletracking-dashboard.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A view of the volume of tenants TeleTracking processed in cycle &#34;&#xA;width=&#34;1538&#34;&#xA;height=&#34;910&#34;&#xA;title=&#34;*A view of the volume of tenants TeleTracking processed in cycle*&#34;&#xA;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/high-value-metrics/teletracking-dashboard.png&#34;&#xA;alt=&#34;A view of the volume of tenants TeleTracking processed in cycle &#34;&#xA;width=&#34;1538&#34;&#xA;height=&#34;910&#34;&#xA;title=&#34;*A view of the volume of tenants TeleTracking processed in cycle*&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;figcaption class=&#34;w-100p caption text-gray-13 text-left &#34;&gt;&lt;em&gt;A view of the volume of tenants TeleTracking processed in cycle&lt;/em&gt;&lt;/figcaption&gt;&#xA;&lt;/a&gt;&#xA;&lt;/figure&gt;&#xA;&lt;p&gt;These savings have been instrumental in helping TeleTracking grow efficiently without blowing up their metrics and costs.&lt;/p&gt;&#xA;&lt;p&gt;&amp;ldquo;We’re no longer just keeping the lights on and putting out fires,&amp;rdquo; Lion says. &amp;ldquo;Today, we’re being proactive, finding new ways to support the business, and helping our developers do their jobs easier, faster, and better.&amp;rdquo;&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;Read more about how &lt;a href=&#34;/blog/2024/01/26/inside-teletrackings-journey-to-build-a-better-observability-platform-with-grafana-cloud&#34;&gt;TeleTracking built a better observability platform&lt;/a&gt; with Grafana Cloud.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;empower-engineers-to-make-smarter-quicker-decisions&#34;&gt;Empower engineers to make smarter, quicker decisions&lt;/h2&gt;&#xA;&lt;p&gt;Dell Technologies faced significant challenges with its legacy observability tool, which led to alert fatigue and a burden on its infrastructure. After migrating to Grafana Cloud, they leveraged Adaptive Metrics to tackle their SNMP data.&lt;/p&gt;&#xA;&lt;p&gt;&amp;ldquo;Adaptive Metrics takes those metrics that you never look at, that you have no alerts on, and no dashboards related to, and says, &amp;lsquo;Why are you sending these to us? You don&amp;rsquo;t use them. Save yourself some money.&amp;rsquo; So that&amp;rsquo;s what we did,&amp;rdquo; says Brian Murphy, Technical Staff SRE at Dell Technologies.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1584px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&#xA;&lt;a&#xA;class=&#34;lightbox-link captioned&#34;&#xA;href=&#34;/media/blog/high-value-metrics/dell-dashboard.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload mb-0&#34;&#xA;data-src=&#34;/media/blog/high-value-metrics/dell-dashboard.png&#34;data-srcset=&#34;/media/blog/high-value-metrics/dell-dashboard.png?w=320 320w, /media/blog/high-value-metrics/dell-dashboard.png?w=550 550w, /media/blog/high-value-metrics/dell-dashboard.png?w=750 750w, /media/blog/high-value-metrics/dell-dashboard.png?w=900 900w, /media/blog/high-value-metrics/dell-dashboard.png?w=1040 1040w, /media/blog/high-value-metrics/dell-dashboard.png?w=1240 1240w, /media/blog/high-value-metrics/dell-dashboard.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;An example of Dell&amp;#39;s persona-based dashboard tailored to the needs of specific users&#34;&#xA;width=&#34;1584&#34;&#xA;height=&#34;906&#34;&#xA;title=&#34;*An example of Dell&amp;#39;s persona-based dashboard tailored to the needs of specific users*&#34;&#xA;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/high-value-metrics/dell-dashboard.png&#34;&#xA;alt=&#34;An example of Dell&amp;#39;s persona-based dashboard tailored to the needs of specific users&#34;&#xA;width=&#34;1584&#34;&#xA;height=&#34;906&#34;&#xA;title=&#34;*An example of Dell&amp;#39;s persona-based dashboard tailored to the needs of specific users*&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;figcaption class=&#34;w-100p caption text-gray-13 &#34;&gt;&lt;em&gt;An example of Dell&amp;rsquo;s persona-based dashboard tailored to the needs of specific users&lt;/em&gt;&lt;/figcaption&gt;&#xA;&lt;/a&gt;&#xA;&lt;/figure&gt;&#xA;&lt;p&gt;Dell&amp;rsquo;s SREs wrote rules to stop shipping unused metrics, which resulted in substantial savings, but it also led to greater efficiency for engineers. Instead of focusing on the metrics that are not working for them, they could focus on the ones that &lt;em&gt;do&lt;/em&gt;, which improved their decision-making processes and overall productivity.&lt;/p&gt;&#xA;&lt;p&gt;&amp;ldquo;For the engineering side, it&amp;rsquo;s great, too, because you don&amp;rsquo;t have to look at junk that&amp;rsquo;s not useful. If we can get rid of it, hide it away, and not even have to look at it, then it&amp;rsquo;s so much better and easier to work through,&amp;rdquo; Murphy says.&lt;/p&gt;&#xA;&lt;p&gt;W&lt;em&gt;atch Murphy&amp;rsquo;s &lt;a href=&#34;https://www.youtube.com/watch?v=Wz2a4hxt2c4&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;presentation at ObservabilityCon on the Road&lt;/a&gt; to learn more about how Dell focused on higher-priority areas with Grafana Cloud.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;cut-out-noise-automatically-to-focus-on-incident-response&#34;&gt;Cut out noise automatically to focus on incident response&lt;/h2&gt;&#xA;&lt;p&gt;For Mux, which operates an API-first video platform, the burden of managing their own observability stack meant that engineers were mostly spending their time reacting to alerts and keeping everything up and running.&lt;/p&gt;&#xA;&lt;p&gt;“Grafana Cloud probably saves us hundreds of engineering hours a year. Our platform engineers don’t have to manage the stack any more, and our product engineers don’t have to work through multiple observability tools, which used to really slow down our response times,” said Ryan Grothouse, VP, Engineering at Mux.&lt;/p&gt;&#xA;&lt;p&gt;Since moving to Grafana Cloud, &lt;strong&gt;they&amp;rsquo;ve reduced their metrics volume by 60%&lt;/strong&gt; and they have been able to expand their metrics retention time from 14 days to 13 months. This has helped Mux reduce noise, improve long-term analysis, and take a more proactive approach to incident management.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1089px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&#xA;&lt;a&#xA;class=&#34;lightbox-link captioned&#34;&#xA;href=&#34;/media/blog/high-value-metrics/mux-dashboard.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload mb-0&#34;&#xA;data-src=&#34;/media/blog/high-value-metrics/mux-dashboard.png&#34;data-srcset=&#34;/media/blog/high-value-metrics/mux-dashboard.png?w=320 320w, /media/blog/high-value-metrics/mux-dashboard.png?w=550 550w, /media/blog/high-value-metrics/mux-dashboard.png?w=750 750w, /media/blog/high-value-metrics/mux-dashboard.png?w=900 900w, /media/blog/high-value-metrics/mux-dashboard.png?w=1040 1040w, /media/blog/high-value-metrics/mux-dashboard.png?w=1240 1240w, /media/blog/high-value-metrics/mux-dashboard.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;Mux dashboard&#34;&#xA;width=&#34;1089&#34;&#xA;height=&#34;505&#34;&#xA;title=&#34;*Mux uses Grafana dashboards to monitor video quality across environments*&#34;&#xA;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/high-value-metrics/mux-dashboard.png&#34;&#xA;alt=&#34;Mux dashboard&#34;&#xA;width=&#34;1089&#34;&#xA;height=&#34;505&#34;&#xA;title=&#34;*Mux uses Grafana dashboards to monitor video quality across environments*&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;figcaption class=&#34;w-100p caption text-gray-13 &#34;&gt;&lt;em&gt;Mux uses Grafana dashboards to monitor video quality across environments&lt;/em&gt;&lt;/figcaption&gt;&#xA;&lt;/a&gt;&#xA;&lt;/figure&gt;&#xA;&lt;p&gt;Moreover, they&amp;rsquo;re relying on the automated functionality of Adaptive Metrics to help identify new areas of improvements over time.&lt;/p&gt;&#xA;&lt;blockquote class=&#34;pullquote en &#34;&gt;&#xA;&lt;div class=&#34;pullquote__content&#34;&gt;&#xA;&lt;p&gt;Adaptive Metrics is an amazing feature. It not only saves us hundreds of thousands of dollars a year, but it’s also a forcing function for us to look closely at our metrics to find additional opportunities for time series reduction and cardinality improvements.&amp;quot;&lt;/p&gt;&#xA;&lt;p&gt;— Kyle Weaver, Mux Staff Software Engineer&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;&lt;em&gt;Learn more about how &lt;a href=&#34;/blog/2024/07/22/how-mux-cut-metrics-volume-by-60-increased-retention-times-and-improved-developer-productivity-with-grafana-cloud/&#34;&gt;Mux is using Grafana Cloud and Adaptive Metrics&lt;/a&gt; to improve incident response and productivity.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;/products/cloud/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt; is the easiest way to get started with metrics, logs, traces, dashboards, and more. We have a generous forever-free tier and plans for every use case. &lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Sign up for free now&lt;/a&gt;!&lt;/em&gt;&lt;/p&gt;】&lt;p&gt;让我们切入正题：大规模管理指标量是很困难的。事实上，当我们向开源可观测性社区询问他们在今年的 &lt;a href=&#34;/observability-survey/?pg=blog&amp;plcmt=body-txt#whats-next-addressing-gaps-and-driven-innovation 中最关心的问题时&#34;&gt;Grafana Labs 可观测性调查&lt;/a&gt;中，排名前四的响应——成本、复杂性、基数和信噪比——都可以与遥测数据的指数增长联系起来。&lt;/p&gt;&#xA;&lt;p&gt;为了帮助缓解这些问题领域，我们构建了&lt;a href=&#34;/products/cloud/?pg=blog&amp;plcmt=body-txt&#34;&gt;自适应指标&lt;/a&gt;，这是 Grafana Cloud 中的一项功能，可通过聚合来帮助降低成本未使用和部分使用的指标转换为较低基数版本。&lt;/p&gt;&#xA;&lt;p&gt;Adaptive Metrics 为超过 1,200 个组织带来了&lt;strong&gt;指标成本平均降低 35%&lt;/strong&gt;。 1,400 个堆栈执行聚合，总计 3.5 亿个聚合系列，结果是巨大的、有影响力的，可以直接使您的利润受益。&lt;/p&gt;&#xA;&lt;p&gt;但对于最成功的可观察性团队来说，这些节省并不是最终结果，而只是开始。在本博客中，我们将向您展示四位 Grafana Cloud 客户如何利用 Adaptive Metrics 以及它为他们带来的节省：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;改进并进一步投资可观测性堆栈&lt;/li&gt;&#xA;&lt;li&gt;更多地关注有助于提升业务价值的领域&lt;/li&gt;&#xA;&lt;li&gt;帮助开发者更快、更有效地采取行动&lt;/li&gt;&#xA;&lt;li&gt;采取更主动的事件管理方法&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;invest- savings-into-improving-observability-insights&#34;&gt;将节省的资金投入到提高可观察性洞察力&lt;/h2&gt;&#xA;&lt;p&gt;拥有惊人的 7500 万个活跃系列，SailPoint 需要找到一种方法来减少指标量，同时又不影响开发人员的体验。值得庆幸的是，身份安全公司能够通过自适应指标来做到这一点，&lt;strong&gt;将指标量减少了 33%&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;p&gt;“自适应指标的伟大之处在于......它只是准确地告诉我我正在寻找什么。如果我想要我们没有看到使用情况的指标，该工具会比亲自去挖掘要快得多，”SailPoint 的 DevOps 工程师 Lydia Clarke 说道。&lt;/p&gt;&#xA;&lt;p&gt;但 SailPoint 不仅仅将节省成本视为降低利润的一种方式。相反，他们利用这笔资金对可观察性进行了更深入的投资，采用更多 Grafana Cloud 产品并增强了整体监控能力。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1999px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&#xA;&lt;一&#xA;类=“灯箱链接标题”&#xA;href=&#34;/media/blog/high-value-metrics/sailpoint-dashboard.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“lazyload mb-0”&#xA;data-src=&#34;/media/blog/high-value-metrics/sailpoint-dashboard.png&#34;data-srcset=&#34;/media/blog/high-value-metrics/sailpoint-dashboard.png?w=320 320w, /media/blog/high-value-metrics/sailpoint-dashboard.png?w=550 550w, /media/blog/high- value-metrics/sailpoint-dashboard.png?w=750 750w, /media/blog/high-value-metrics/sailpoint-dashboard.png?w=900 900w, /media/blog/high-value-metrics/sailpoint-仪表板.png?w=1040 1040w，/media/blog/high-value-metrics/sailpoint-dashboard.png?w=1240 1240w，/media/blog/high-value-metrics/sailpoint-dashboard.png?w= 1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;看看 Sailpoint 如何跟踪其活跃系列限制&#34;&#xA;宽度=“1999”&#xA;高度=“1249”&#xA;title=&#34;*看看 Sailpoint 如何跟踪其活跃系列限制*&#34;&#xA;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/high-value-metrics/sailpoint-dashboard.png”&#xA;alt=&#34;看看 Sailpoint 如何跟踪其活跃系列限制&#34;&#xA;宽度=“1999”&#xA;高度=“1249”&#xA;title=&#34;*看看 Sailpoint 如何跟踪其活跃系列限制*&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;figcaption class=&#34;w-100p title text-gray-13 text-left &#34;&gt;&lt;em&gt;看看 Sailpoint 如何跟踪其活跃系列限制&lt;/em&gt;&lt;/figcaption&gt;&#xA;&lt;/a&gt;&#xA;&lt;/图&gt;&#xA;&lt;p&gt;除了使用 Grafana 进行可视化和使用 Grafana Cloud Metrics 进行存储和管理之外，SailPoint 还希望扩展其堆栈，以包含 Grafana Cloud 前端可观察性以进行真实用户监控。&lt;/p&gt;&#xA;&lt;p&gt;“我们正处于可观测性之旅的中间，但我们与 Grafana Labs 的关系才刚刚开始，”可观测性团队负责人 Omar Lopez 说道。 “我们正在探索 Grafana Cloud 中越来越多的功能和服务。这就像一个在糖果店里的孩子——我们正在观察一切。”&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;详细了解&lt;a href=&#34;/success/sailpoint/?pg=blog&amp;plcmt=body-txt&#34;&gt;SailPoint 对高价值指标的优先考虑&lt;/a&gt;如何转化为更广泛、更广泛的投资全面的可观测性堆栈。&lt;/em&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;spend-time-and-effort-on-areas-that-drive-value&#34;&gt;将时间和精力花在能带来价值的领域&lt;/h2&gt;&#xA;&lt;p&gt;当您了解哪些指标对您的运营至关重要时，您就可以更好地分配资源。 Grafana Cloud 提供有关指标使用情况的清晰见解，帮助您区分推动业务决策的高价值指标和会增加成本而不增加显着价值的低价值指标。&lt;/p&gt;&#xA;&lt;p&gt;这在理论上很有道理，但在现实中可能会导致很多恐惧。例如，当可观测性团队提出消除未使用的指标的想法时，集成医疗保健运营平台提供商 TeleTracking 的工程师表示怀疑。人们担心删除或聚合指标可能会破坏关键服务或导致其可观察性出现盲点。当他们看到自适应指标建议的结果时，这些担忧很快就消失了。&lt;/p&gt;&#xA;&lt;p&gt;“一些工程师起初对这个想法犹豫不决，但一旦他们开始使用关键标签、站立仪表板并轻松编写警报，他们就会发现他们很快就看到了其中的价值。”TeleTracking 生产力工程软件工程总监 Oren Lion 说道。他们使用自适应指标通过聚合恢复为不太详细的指标，&lt;strong&gt;将 Grafana Cloud Metrics 的支出减少了 50%&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1538px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&#xA;&lt;一&#xA;类=“灯箱链接标题”&#xA;href=&#34;/media/blog/high-value-metrics/teletracking-dashboard.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“lazyload mb-0”&#xA;data-src =“/media/blog/high-value-metrics/teletracking-dashboard.png”data-srcset =“/media/blog/high-value-metrics/teletracking-dashboard.png？w = 320 320w，/媒体/博客/high-value-metrics/teletracking-dashboard.png?w=550 550w，/media/blog/high-value-metrics/teletracking-dashboard.png?w=750 750w，/media/blog/high- value-metrics/teletracking-dashboard.png?w=900 900w，/media/blog/high-value-metrics/teletracking-dashboard.png?w=1040 1040w，/media/blog/high-value-metrics/teletracking-仪表板.png?w=1240 1240w，/media/blog/high-value-metrics/teletracking-dashboard.png?w=1920 1920w&#34;&#xA;data-sizes=“auto”alt=“TeleTracking 周期内处理的租户数量视图”&#xA;宽度=“1538”&#xA;高度=“910”&#xA;title=&#34;*TeleTracking 周期内处理的租户数量视图*&#34;&#xA;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/high-value-metrics/teletracking-dashboard.png”&#xA;alt=&#34;TeleTracking 周期内处理的租户数量视图&#34;&#xA;宽度=“1538”&#xA;高度=“910”&#xA;title=&#34;*TeleTracking 周期内处理的租户数量视图*&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;figcaption class=&#34;w-100p title text-gray-13 text-left &#34;&gt;&lt;em&gt;TeleTracking 周期内处理的租户数量视图&lt;/em&gt;&lt;/figcaption&gt;&#xA;&lt;/a&gt;&#xA;&lt;/图&gt;&#xA;&lt;p&gt;这些节省的费用有助于帮助 TeleTracking 高效发展，同时又不会增加指标和成本。&lt;/p&gt;&#xA;&lt;p&gt;“我们不再只是维持照明和灭火，”莱恩说。 “今天，我们积极主动地寻找支持业务的新方法，并帮助我们的开发人员更轻松、更快、更好地完成工作。”&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;详细了解如何&lt;a href=&#34;/blog/2024/01/26/inside-teletrackings-journey-to-build-a-better-observability-platform-with-grafana-cloud&#34;&gt;TeleTracking使用 Grafana Cloud 构建了更好的可观察性平台&lt;/a&gt;。&lt;/em&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;empower-engineers-to-make-smarter-quicker-decisions&#34;&gt;帮助工程师做出更明智、更快速的决策&lt;/h2&gt;&#xA;&lt;p&gt;戴尔科技集团的旧版可观测性工具面临重大挑战，导致警报疲劳并给基础设施带来负担。迁移到 Grafana Cloud 后，他们利用自适应指标来处理 SNMP 数据。&lt;/p&gt;&#xA;&lt;p&gt;“自适应指标采用那些您从未查看过的指标，您没有警报，也没有与之相关的仪表板，并说，‘您为什么要发送这些指标？对我们来说是啥？你不使用它们。为自己省点钱。’这就是我们所做的。”戴尔科技集团 SRE 技术人员 Brian Murphy 说道。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1584px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&#xA;&lt;一&#xA;类=“灯箱链接标题”&#xA;href=&#34;/media/blog/high-value-metrics/dell-dashboard.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“lazyload mb-0”&#xA;data-src=&#34;/media/blog/high-value-metrics/dell-dashboard.png&#34;data-srcset=&#34;/media/blog/high-value-metrics/dell-dashboard.png?w=320 320w, /媒体/博客/high-value-metrics/dell-dashboard.png?w=550 550w，/media/blog/high-value-metrics/dell-dashboard.png?w=750 750w，/media/blog/high- value-metrics/dell-dashboard.png?w=900 900w，/media/blog/high-value-metrics/dell-dashboard.png?w=1040 1040w，/media/blog/high-value-metrics/dell-仪表板.png?w=1240 1240w，/media/blog/high-value-metrics/dell-dashboard.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;根据特定用户需求定制的戴尔基于角色的仪表板示例&#34;&#xA;宽度=“1584”&#xA;高度=“906”&#xA;title=&#34;*戴尔根据特定用户需求量身定制的基于角色的仪表板示例*&#34;&#xA;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src=&#34;/media/blog/high-value-metrics/dell-dashboard.png&#34;&#xA;alt=&#34;戴尔根据特定用户需求量身定制的基于角色的仪表板示例&#34;&#xA;宽度=“1584”&#xA;高度=“906”&#xA;title=&#34;*戴尔根据特定用户需求量身定制的基于角色的仪表板示例*&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;figcaption class=&#34;w-100p title text-gray-13 &#34;&gt;&lt;em&gt;戴尔根据特定用户需求量身定制的基于角色的仪表板示例&lt;/em&gt;&lt;/figcaption&gt;&#xA;&lt;/a&gt;&#xA;&lt;/图&gt;&#xA;&lt;p&gt;戴尔的 SRE 编写了规则来停止交付未使用的指标，这不仅节省了大量成本，而且还提高了工程师的效率。他们可以专注于那些对他们不起作用的指标，而不是关注对他们不起作用的指标，从而改善他们的决策流程和整体生产力。&lt;/p&gt;&#xA;&lt;p&gt;“对于工程方面来说，这也很棒，因为您不必查看无用的垃圾。如果我们能够摆脱它，把它藏起来，甚至不用看它，那么解决起来就会更好、更容易。”墨菲说。&lt;/p&gt;&#xA;&lt;p&gt;观看 Murphy &lt;a href=&#34;https://www.youtube.com/watch?v=Wz2a4hxt2c4&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;在 ObservabilityCon on the Road 上的演讲&lt;/ a&gt; 详细了解戴尔如何通过 Grafana Cloud 专注于更高优先级的领域。&lt;/em&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;cut-out-noise-automatically-to-focus-on-incident-response&#34;&gt;自动消除噪音以专注于事件响应&lt;/h2&gt;&#xA;&lt;p&gt;对于运营 API 优先视频平台的 Mux 来说，管理自己的可观察性堆栈的负担意味着工程师大部分时间都花在对警报做出反应并保留所有内容上启动并运行。&lt;/p&gt;&#xA;&lt;p&gt;“Grafana Cloud 每年可能为我们节省数百个工程时间。我们的平台工程师不必再管理堆栈，我们的产品工程师也不必使用多种可观察性工具，这在过去确实会减慢我们的响应时间。”Mux 工程副总裁 Ryan Grothouse 说道。 &lt;/p&gt;&#xA;&lt;p&gt;自从迁移到 Grafana Cloud 以来，&lt;strong&gt;他们的指标量减少了 60%&lt;/strong&gt;，并且能够将指标保留时间从 14 天延长到 13 个月。这有助于 Mux 减少噪音、改进长期分析并采取更主动的方法进行事件管理。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1089px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&#xA;&lt;一&#xA;类=“灯箱链接标题”&#xA;href=&#34;/media/blog/high-value-metrics/mux-dashboard.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“lazyload mb-0”&#xA;data-src =“/media/blog/high-value-metrics/mux-dashboard.png”data-srcset =“/media/blog/high-value-metrics/mux-dashboard.png？w = 320 320w，/媒体/博客/高值-指标/mux-dashboard.png？w = 550 550w，/媒体/博客/高值-指标/mux-dashboard.png？w = 750 750w，/媒体/博客/高- value-metrics/mux-dashboard.png?w=900 900w，/media/blog/high-value-metrics/mux-dashboard.png?w=1040 1040w，/media/blog/high-value-metrics/mux-仪表板.png?w=1240 1240w，/media/blog/high-value-metrics/mux-dashboard.png?w=1920 1920w&#34;&#xA;data-size=&#34;auto&#34;alt=&#34;Mux 仪表板&#34;&#xA;宽度=“1089”&#xA;高度=“505”&#xA;title=&#34;*Mux 使用 Grafana 仪表板监控跨环境的视频质量*&#34;&#xA;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/high-value-metrics/mux-dashboard.png”&#xA;alt=&#34;Mux 仪表板&#34;&#xA;宽度=“1089”&#xA;高度=“505”&#xA;title=&#34;*Mux 使用 Grafana 仪表板监控跨环境的视频质量*&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;figcaption class=&#34;w-100p title text-gray-13 &#34;&gt;&lt;em&gt;Mux 使用 Grafana 仪表板监控跨环境的视频质量&lt;/em&gt;&lt;/figcaption&gt;&#xA;&lt;/a&gt;&#xA;&lt;/图&gt;&#xA;&lt;p&gt;此外，他们依靠自适应指标的自动化功能来帮助确定随着时间的推移需要改进的新领域。&lt;/p&gt;&#xA;&lt;blockquote class=&#34;pullquote &#34;&gt;&#xA;&lt;div class=&#34;pullquote__content&#34;&gt;&#xA;&lt;p&gt;自适应指标是一项令人惊叹的功能。它不仅每年为我们节省数十万美元，而且还迫使我们仔细研究我们的指标，以寻找时间序列缩减和基数改进的其他机会。”&lt;/p&gt;&#xA;&lt;p&gt;— Kyle Weaver，Mux 高级软件工程师&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;/块引用&gt;&#xA;&lt;p&gt;&lt;em&gt;详细了解&lt;a href=&#34;/blog/2024/07/22/how-mux-cut-metrics-volume-by-60-increased-retention-times-and-improved-developer- Productivity-with-grafana-cloud/&#34;&gt;Mux 正在使用 Grafana Cloud 和自适应指标&lt;/a&gt;来提高事件响应和生产力。&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;/products/cloud/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt; 是最简单的获取方式从指标、日志、跟踪、仪表板等开始。我们为每个用例提供慷慨的永久免费套餐和计划。 &lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;plcmt=body-txt&#34;&gt;立即免费注册&lt;/a&gt;！&lt;/em&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 12 Aug 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【How to integrate Okta logs with Grafana Loki for enhanced SIEM capabilities】如何将 Okta 日志与 Grafana Loki 集成以增强 SIEM 功能</title>
      <link>https://grafana.com/blog/2024/08/07/how-to-integrate-okta-logs-with-grafana-loki-for-enhanced-siem-capabilities/</link>
      <description>【&lt;p&gt;Identity providers (IdPs) such as Okta play a crucial role in enterprise environments by providing seamless authentication and authorization experiences for users accessing organizational resources. These interactions generate a massive volume of event logs, containing valuable information like user details, geographical locations, IP addresses, and more.&lt;/p&gt;&#xA;&lt;p&gt;These logs are essential for security teams, especially in operations, because they&amp;rsquo;re used to detect and respond to incidents effectively. However, integrating these logs into logging and SIEM platforms can be challenging.&lt;/p&gt;&#xA;&lt;p&gt;In this blog post, we&amp;rsquo;ll show you how to effectively set up and run our Okta logs collector to send logs to &lt;a href=&#34;/oss/loki/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Loki&lt;/a&gt; instances on-premises or in the cloud. By configuring your environment variables, running the Okta logs collector Docker container, and utilizing the latest versions of Loki and &lt;a href=&#34;/oss/alloy-opentelemetry-collector/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Alloy&lt;/a&gt;, you can monitor, analyze, and set alerts on your Okta logs for deeper insights and improved system security and operational capabilities.&lt;/p&gt;&#xA;&lt;h2 id=&#34;why-we-developed-the-okta-logs-collector&#34;&gt;Why we developed the Okta logs collector&lt;/h2&gt;&#xA;&lt;p&gt;Many IdPs offer REST APIs for fetching event logs, with &lt;a href=&#34;https://developer.okta.com/docs/reference/api/system-log/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Okta&amp;rsquo;s System Log API&lt;/a&gt; providing logs in JSON format, as shown below. However, integrating these logs into existing systems often involves a complex and time-consuming process, typically requiring custom code to access the logs via an HTTP client library in programming languages like Go.&lt;/p&gt;&#xA;&lt;p&gt;To simplify and streamline this process, we developed the &lt;a href=&#34;https://github.com/grafana/okta-logs-collector&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Okta logs collector&lt;/a&gt;. This tool automates the retrieval of logs from the Okta System Log API, enriches the data, and sends it to STDOUT, making it easy to scrape and forward the logs to observability platforms like Loki using agents such as Alloy or Promtail.&lt;/p&gt;&#xA;&lt;p&gt;To further illustrate why we built the Okta logs collector, let&amp;rsquo;s briefly look at the challenge developers face with fetching event logs and how we&amp;rsquo;re attempting to address those challenges.&lt;/p&gt;&#xA;&lt;h3 id=&#34;json-log-event-example&#34;&gt;JSON log event example&lt;/h3&gt;&#xA;&lt;p&gt;Here&amp;rsquo;s an example of a JSON-formatted log event generated by Okta&amp;rsquo;s System Log API:&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet &#34;&gt;&lt;div class=&#34;lang-toolbar&#34;&gt;&#xA;&lt;span class=&#34;lang-toolbar__item&#34;&gt;JavaScript&lt;/span&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;button x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;Copy code to clipboard&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;Copy&lt;/span&gt;&#xA;&lt;/button&gt;&#xA;&lt;/span&gt;&#xA;&lt;div class=&#34;lang-toolbar__border&#34;&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet &#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-javascript&#34;&gt;{&#xA;&amp;#34;version&amp;#34;: &amp;#34;0&amp;#34;,&#xA;&amp;#34;severity&amp;#34;: &amp;#34;INFO&amp;#34;,&#xA;&amp;#34;client&amp;#34;: {&#xA;&amp;#34;zone&amp;#34;: &amp;#34;OFF_NETWORK&amp;#34;,&#xA;&amp;#34;device&amp;#34;: &amp;#34;Unknown&amp;#34;,&#xA;&amp;#34;userAgent&amp;#34;: {&#xA;&amp;#34;os&amp;#34;: &amp;#34;Unknown&amp;#34;,&#xA;&amp;#34;browser&amp;#34;: &amp;#34;UNKNOWN&amp;#34;,&#xA;&amp;#34;rawUserAgent&amp;#34;: &amp;#34;UNKNOWN-DOWNLOAD&amp;#34;&#xA;},&#xA;&amp;#34;ipAddress&amp;#34;: &amp;#34;12.97.85.90&amp;#34;&#xA;},&#xA;&amp;#34;device&amp;#34;: {&#xA;&amp;#34;id&amp;#34;: &amp;#34;guob5wtu7rBggkg9G1d7&amp;#34;,&#xA;&amp;#34;name&amp;#34;: &amp;#34;MacBookPro16,1&amp;#34;,&#xA;&amp;#34;os_platform&amp;#34;: &amp;#34;OSX&amp;#34;,&#xA;&amp;#34;os_version&amp;#34;: &amp;#34;14.3.0&amp;#34;,&#xA;&amp;#34;managed&amp;#34;: false,&#xA;&amp;#34;registered&amp;#34;: true,&#xA;&amp;#34;device_integrator&amp;#34;: null,&#xA;&amp;#34;disk_encryption_type&amp;#34;: &amp;#34;ALL_INTERNAL_VOLUMES&amp;#34;,&#xA;&amp;#34;screen_lock_type&amp;#34;: &amp;#34;BIOMETRIC&amp;#34;,&#xA;&amp;#34;jailbreak&amp;#34;: null,&#xA;&amp;#34;secure_hardware_present&amp;#34;: true&#xA;},&#xA;&amp;#34;actor&amp;#34;: {&#xA;&amp;#34;id&amp;#34;: &amp;#34;00u1qw1mqitPHM8AJ0g7&amp;#34;,&#xA;&amp;#34;type&amp;#34;: &amp;#34;User&amp;#34;,&#xA;&amp;#34;alternateId&amp;#34;: &amp;#34;admin@example.com&amp;#34;,&#xA;&amp;#34;displayName&amp;#34;: &amp;#34;John Doe&amp;#34;&#xA;},&#xA;&amp;#34;outcome&amp;#34;: {&#xA;&amp;#34;result&amp;#34;: &amp;#34;SUCCESS&amp;#34;&#xA;},&#xA;&amp;#34;uuid&amp;#34;: &amp;#34;f790999f-fe87-467a-9880-6982a583986c&amp;#34;,&#xA;&amp;#34;published&amp;#34;: &amp;#34;2017-09-31T22:23:07.777Z&amp;#34;,&#xA;&amp;#34;eventType&amp;#34;: &amp;#34;user.session.start&amp;#34;,&#xA;&amp;#34;displayMessage&amp;#34;: &amp;#34;User login to Okta&amp;#34;,&#xA;&amp;#34;transaction&amp;#34;: {&#xA;&amp;#34;type&amp;#34;: &amp;#34;WEB&amp;#34;,&#xA;&amp;#34;id&amp;#34;: &amp;#34;V04Oy4ubUOc5UuG6s9DyNQAABtc&amp;#34;&#xA;},&#xA;&amp;#34;debugContext&amp;#34;: {&#xA;&amp;#34;debugData&amp;#34;: {&#xA;&amp;#34;requestUri&amp;#34;: &amp;#34;/login/do-login&amp;#34;&#xA;}&#xA;},&#xA;&amp;#34;legacyEventType&amp;#34;: &amp;#34;core.user_auth.login_success&amp;#34;,&#xA;&amp;#34;authenticationContext&amp;#34;: {&#xA;&amp;#34;authenticationStep&amp;#34;: 0,&#xA;&amp;#34;externalSessionId&amp;#34;: &amp;#34;1013FfF-DKQSvCI4RVXChzX-w&amp;#34;&#xA;}&#xA;}&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;h3 id=&#34;challenges-with-log-retrieval&#34;&gt;Challenges with log retrieval&lt;/h3&gt;&#xA;&lt;p&gt;To retrieve these logs, you need an &lt;a href=&#34;https://help.okta.com/en-us/content/topics/security/api.htm?cshid=ext-create-api-token#create-okta-api-token&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;API token&lt;/a&gt;. You can test the API using &lt;code&gt;curl&lt;/code&gt; or similar HTTP clients:&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;button x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;Copy code to clipboard&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;Copy&lt;/span&gt;&#xA;&lt;/button&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;curl -v -X GET \&#xA;-H &amp;#34;Accept: application/json&amp;#34; \&#xA;-H &amp;#34;Content-Type: application/json&amp;#34; \&#xA;-H &amp;#34;Authorization: SSWS ${api_token}&amp;#34; \&#xA;&amp;#34;https://${yourOktaDomain}/api/v1/logs&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;p&gt;Although Okta provides a Go SDK for easier integration, developers still need to write code to fetch and handle the logs, which can be cumbersome and prone to errors. This is where the Okta logs collector shines by automating the entire process.&lt;/p&gt;&#xA;&lt;h3 id=&#34;the-okta-logs-collector-solution&#34;&gt;The Okta logs collector solution&lt;/h3&gt;&#xA;&lt;p&gt;Our &lt;code&gt;okta-logs-collector&lt;/code&gt; application periodically fetches logs from Okta’s System Logs API and sends them to the STDOUT. Our solution works in a containerized environment, in which Alloy can discover Docker Engine, receive container logs, and forward them to Loki. Alternatively, you can pipe the application logs to a file on disk, which can then be monitored and read by Alloy using the &lt;code&gt;loki.source.file&lt;/code&gt; &lt;a href=&#34;/docs/alloy/latest/reference/components/loki.source.file/&#34;&gt;component&lt;/a&gt; and sent to Loki. The containerized solution is shown in the diagram below:&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1771px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&#xA;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/okta-logs-collector/okta-logs-collector-diagram.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/okta-logs-collector/okta-logs-collector-diagram.png&#34;data-srcset=&#34;/media/blog/okta-logs-collector/okta-logs-collector-diagram.png?w=320 320w, /media/blog/okta-logs-collector/okta-logs-collector-diagram.png?w=550 550w, /media/blog/okta-logs-collector/okta-logs-collector-diagram.png?w=750 750w, /media/blog/okta-logs-collector/okta-logs-collector-diagram.png?w=900 900w, /media/blog/okta-logs-collector/okta-logs-collector-diagram.png?w=1040 1040w, /media/blog/okta-logs-collector/okta-logs-collector-diagram.png?w=1240 1240w, /media/blog/okta-logs-collector/okta-logs-collector-diagram.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;Okta logs collector diagram&#34;&#xA;width=&#34;1771&#34;&#xA;height=&#34;571&#34;&#xA;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/okta-logs-collector/okta-logs-collector-diagram.png&#34;&#xA;alt=&#34;Okta logs collector diagram&#34;&#xA;width=&#34;1771&#34;&#xA;height=&#34;571&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;/a&gt;&#xA;&lt;/figure&gt;&#xA;&lt;h2 id=&#34;how-to-use-okta-logs-collector-with-alloy&#34;&gt;How to Use Okta Logs Collector with Alloy&lt;/h2&gt;&#xA;&lt;p&gt;To effectively set up and run the application, it&amp;rsquo;s important to understand the &lt;a href=&#34;https://github.com/grafana/okta-logs-collector/blob/main/examples/cloud-config.alloy&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;example configuration file for Alloy&lt;/a&gt;. Components are the building blocks of Alloy, each handling a specific task such as retrieving logs or sending them to Loki. Reference documentation for each component can be found &lt;a href=&#34;/docs/alloy/latest/reference/components/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;here&lt;/a&gt;. The example configuration file utilizes several components, which are explained below.&lt;/p&gt;&#xA;&lt;h3 id=&#34;component-1-discoverydocker&#34;&gt;Component 1: &lt;code&gt;discovery.docker&lt;/code&gt;&lt;/h3&gt;&#xA;&lt;p&gt;The &lt;code&gt;discovery.docker&lt;/code&gt; &lt;a href=&#34;/docs/alloy/latest/reference/components/discovery.docker/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;component&lt;/a&gt; discovers&lt;a href=&#34;https://docs.docker.com/engine/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt; Docker Engine&lt;/a&gt; containers and exposes them as targets. This assumes that you’re running Docker Engine locally and you have access to the &lt;code&gt;docker.sock&lt;/code&gt; Unix domain socket, which means that you are a member of the &lt;code&gt;docker&lt;/code&gt; group on Linux or you’re running as root.&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;button x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;Copy code to clipboard&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;Copy&lt;/span&gt;&#xA;&lt;/button&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;discovery.docker &amp;#34;containers&amp;#34; {&#xA;host = &amp;#34;unix:///var/run/docker.sock&amp;#34;&#xA;}&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;h3 id=&#34;component-2-lokisourcedocker&#34;&gt;Component 2: &lt;code&gt;loki.source.docker&lt;/code&gt;&lt;/h3&gt;&#xA;&lt;p&gt;The &lt;code&gt;loki.source.docker&lt;/code&gt; &lt;a href=&#34;/docs/alloy/latest/reference/components/loki.source.docker/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;component&lt;/a&gt; reads log entries from Docker containers and forwards them to other &lt;code&gt;loki.*&lt;/code&gt; components. Each component can read from a single Docker daemon. In the following example, we’re using the same &lt;code&gt;docker.sock&lt;/code&gt; as the host that we used in Component 1. The &lt;code&gt;target&lt;/code&gt; is set to discover and collect logs from Docker containers and they will be forwarded to the next component in the chain (using the &lt;code&gt;forward_to&lt;/code&gt; argument): &lt;code&gt;loki.process.grafanacloud.receiver&lt;/code&gt;. This component will apply a single label to all the logs it retrieves and it will collect logs from containers every 10 seconds (default is &lt;code&gt;60s&lt;/code&gt;).&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;button x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;Copy code to clipboard&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;Copy&lt;/span&gt;&#xA;&lt;/button&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;loki.source.docker &amp;#34;default&amp;#34; {&#xA;host = &amp;#34;unix:///var/run/docker.sock&amp;#34;&#xA;targets = discovery.docker.containers.targets&#xA;forward_to = [loki.process.grafanacloud.receiver]&#xA;labels = {&#xA;job = &amp;#34;okta-logs-collector&amp;#34;,&#xA;}&#xA;refresh_interval = &amp;#34;10s&amp;#34;&#xA;}&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;h3 id=&#34;component-3-lokiprocess&#34;&gt;Component 3: &lt;code&gt;loki.process&lt;/code&gt;&lt;/h3&gt;&#xA;&lt;p&gt;The &lt;code&gt;loki.process&lt;/code&gt; &lt;a href=&#34;/docs/alloy/latest/reference/components/loki.process/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;component&lt;/a&gt; receives log entries from other Loki components. It then processes them through various &amp;ldquo;stages&amp;rdquo; and forwards the processed logs to specified receivers. Each stage within a &lt;code&gt;loki.process&lt;/code&gt; block can parse, transform, and filter log entries. The stages in this pipeline perform the following actions:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;Filter logs&lt;/strong&gt; to only include those from the &lt;code&gt;okta-logs-collector&lt;/code&gt; job.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Extract fields&lt;/strong&gt; (&lt;code&gt;eventType&lt;/code&gt;, &lt;code&gt;level&lt;/code&gt;, &lt;code&gt;timestamp&lt;/code&gt;) from JSON-formatted log lines.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Set the log timestamp&lt;/strong&gt; using the extracted &lt;code&gt;timestamp&lt;/code&gt; field, formatted in &lt;a href=&#34;https://www.rfc-editor.org/rfc/rfc3339.html&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;RFC3339&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Assign extracted fields&lt;/strong&gt; (&lt;code&gt;eventType&lt;/code&gt; and &lt;code&gt;level&lt;/code&gt;) as Loki labels for indexing and querying. The &lt;code&gt;level&lt;/code&gt; effectively replaces Loki log level.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;button x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;Copy code to clipboard&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;Copy&lt;/span&gt;&#xA;&lt;/button&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;loki.process &amp;#34;grafanacloud&amp;#34; {&#xA;forward_to = [loki.write.grafanacloud.receiver]&#xA;stage.match {&#xA;// Match only logs from the okta-logs-collector job&#xA;selector = &amp;#34;{job=\&amp;#34;okta-logs-collector\&amp;#34;}&amp;#34;&#xA;// Extract important labels and the timestamp from the log line&#xA;// and map them to Loki labels&#xA;stage.json {&#xA;expressions = {&#xA;eventType = &amp;#34;event.eventType&amp;#34;,&#xA;level = &amp;#34;event.severity&amp;#34;,&#xA;timestamp = &amp;#34;time&amp;#34;,&#xA;}&#xA;}&#xA;// Use the timestamp from the log line as the Loki timestamp&#xA;stage.timestamp {&#xA;source = &amp;#34;timestamp&amp;#34;&#xA;format = &amp;#34;RFC3339&amp;#34;&#xA;}&#xA;// Use the extracted labels as the Loki labels for indexing.&#xA;// These labels can be used as stream selectors in LogQL.&#xA;stage.labels {&#xA;values = {&#xA;eventType = &amp;#34;&amp;#34;,&#xA;level = &amp;#34;&amp;#34;,&#xA;}&#xA;}&#xA;}&#xA;}&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;h3 id=&#34;component-4-lokiwrite&#34;&gt;Component 4: &lt;code&gt;loki.write&lt;/code&gt;&lt;/h3&gt;&#xA;&lt;p&gt;The &lt;code&gt;loki.write&lt;/code&gt; &lt;a href=&#34;/docs/alloy/latest/reference/components/loki.write/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;component&lt;/a&gt; receives log entries from other loki components — the last three we just discussed, to be exact — and sends them to Loki using the &lt;code&gt;logproto&lt;/code&gt; &lt;a href=&#34;https://github.com/grafana/loki/blob/main/pkg/logproto/logproto.proto&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;format&lt;/a&gt;. The example uses a &lt;a href=&#34;/docs/grafana-cloud/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt; endpoint with basic authentication.&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;button x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;Copy code to clipboard&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;Copy&lt;/span&gt;&#xA;&lt;/button&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;loki.write &amp;#34;grafanacloud&amp;#34; {&#xA;endpoint {&#xA;url = &amp;#34;https://&amp;lt;subdomain&amp;gt;.grafana.net/loki/api/v1/push&amp;#34;&#xA;basic_auth {&#xA;username = &amp;#34;&amp;lt;Your Grafana.com User ID&amp;gt;&amp;#34;&#xA;password = &amp;#34;&amp;lt;Your Grafana.com API Token&amp;gt;&amp;#34;&#xA;}&#xA;}&#xA;}&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;p&gt;Environment variables can also be used to set the username and password (or even the URL):&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;button x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;Copy code to clipboard&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;Copy&lt;/span&gt;&#xA;&lt;/button&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;basic_auth {&#xA;username = env(&amp;#34;GRAFANA_CLOUD_USER_ID&amp;#34;)&#xA;password = env(&amp;#34;GRAFANA_CLOUD_API_KEY&amp;#34;)&#xA;}&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;p&gt;This configuration effectively sets up a pipeline for discovering Docker containers, collecting and processing their logs, and sending the processed logs to Grafana Cloud Logs, which is powered by Loki.&lt;/p&gt;&#xA;&lt;h2 id=&#34;set-up-and-run-okta-logs-collector&#34;&gt;Set up and run Okta logs collector&lt;/h2&gt;&#xA;&lt;p&gt;Having grasped the Alloy configuration, you&amp;rsquo;re ready to set up and run the Okta logs collector.&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;Sign in to Okta&lt;/strong&gt;. Log in to your Okta account as an administrator.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Create API Token&lt;/strong&gt;. Create a new &lt;a href=&#34;https://help.okta.com/en-us/content/topics/security/api.htm?cshid=ext-create-api-token#create-okta-api-token&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;API token&lt;/a&gt; for accessing the &lt;a href=&#34;https://developer.okta.com/docs/reference/api/system-log/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;System Logs API&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Set Environment Variables.&lt;/strong&gt; Configure the necessary environment variables in your shell:&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;button x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;Copy code to clipboard&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;Copy&lt;/span&gt;&#xA;&lt;/button&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;export OKTA_URL=&amp;#34;https://&amp;lt;account&amp;gt;.okta.com&amp;#34;&#xA;export OKTA_API_TOKEN=&amp;#34;your-api-token&amp;#34;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;ol start=&#34;4&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Run Okta logs collector&lt;/strong&gt;. Use Docker to run the Okta logs collector container. You can also run it in Kubernetes.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;button x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;Copy code to clipboard&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;Copy&lt;/span&gt;&#xA;&lt;/button&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;docker run --name okta-logs-collector \&#xA;-e OKTA_URL=${OKTA_URL} \&#xA;-e API_KEY=${OKTA_API_TOKEN} \&#xA;-e LOOKBACK_INTERVAL=24h \ # Defaults to 1h&#xA;-e POLL_INTERVAL=10s \&#xA;-e LOG_LEVEL=info \&#xA;grafana/okta-logs-collector:latest poll&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;ol start=&#34;5&#34;&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Download configuration files.&lt;/strong&gt; Obtain the &lt;a href=&#34;https://github.com/grafana/okta-logs-collector/tree/main/examples&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;example configuration files&lt;/a&gt; and place them in a convenient location. Note that the Alloy configuration sends all Docker logs to Loki, so you should consider &lt;a href=&#34;/docs/alloy/latest/reference/components/discovery.docker/?pg=blog&amp;amp;plcmt=body-txt#filter-block&#34;&gt;filtering the logs&lt;/a&gt; using the container name.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Use Loki on Grafana Cloud or run Loki&lt;/strong&gt; &lt;strong&gt;on-premises.&lt;/strong&gt; Locate your Grafana Cloud stack and &lt;a href=&#34;/docs/grafana-cloud/account-management/cloud-stacks/?pg=blog&amp;amp;plcmt=body-txt#find-instance-endpoints&#34;&gt;find your Loki instance endpoint&lt;/a&gt;. (If you don&amp;rsquo;t already use Grafana Cloud, you can sign up for a &lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;forever-free account&lt;/a&gt; today.) Alternatively, &lt;a href=&#34;https://github.com/grafana/okta-logs-collector/blob/main/examples/loki.yaml&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;an example configuration file&lt;/a&gt; is provided for Loki if you want to run Loki on-premises.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Configure Alloy&lt;/strong&gt;. If you’re using Grafana Cloud Logs, follow these steps.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Use the &lt;a href=&#34;https://github.com/grafana/okta-logs-collector/blob/main/examples/cloud-config.alloy&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;provided example configuration&lt;/a&gt; and replace these placeholders with actual values: &lt;code&gt;&amp;lt;subdomain&amp;gt;&lt;/code&gt;, &lt;code&gt;&amp;lt;Your Grafana.com User ID&amp;gt;&lt;/code&gt;, and &lt;code&gt;&amp;lt;Your Grafana.com API Token&amp;gt;&lt;/code&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Generate an &lt;a href=&#34;http://Grafana.com&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;API token&lt;/a&gt; to access and push logs to your Loki instance.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Run Alloy&lt;/strong&gt;. Download, unpack and run &lt;a href=&#34;https://github.com/grafana/alloy/releases/latest&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;the latest version of Alloy&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;If you’re using Grafana Cloud Logs, use &lt;code&gt;cloud-config.alloy&lt;/code&gt; instead. The details of how the example configuration files are structured are explained in the previous section.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;button x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;Copy code to clipboard&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;Copy&lt;/span&gt;&#xA;&lt;/button&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;./alloy-linux-amd64 run /absolute/path/to/config.alloy&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;h2 id=&#34;how-to-observe-logs-in-loki-and-grafana&#34;&gt;How to observe logs in Loki and Grafana&lt;/h2&gt;&#xA;&lt;p&gt;After a few moments, you should see logs appearing in Loki. Use the Loki LogCLI or its data source in Grafana to view and analyze the logs. If you are using Grafana Cloud, go to the Grafana Cloud portal and launch Grafana. From the right menu, navigate to &lt;strong&gt;Connections&lt;/strong&gt; &amp;gt; &lt;strong&gt;Data Sources,&lt;/strong&gt; where you will see that Loki is already added as a data source. Navigate to the &lt;strong&gt;Explore&lt;/strong&gt; page and start querying your Okta logs using the &lt;code&gt;{job=&amp;quot;okta-logs-collector&amp;quot;}&lt;/code&gt; stream selector. The &lt;code&gt;eventType&lt;/code&gt; field is indexed, allowing you to filter specific event types. A complete list of Okta event types (more than 930 as of now) can be found &lt;a href=&#34;https://developer.okta.com/docs/reference/api/event-types/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1999px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&#xA;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/okta-logs-collector/okta-logs-loki-monitor.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/okta-logs-collector/okta-logs-loki-monitor.png&#34;data-srcset=&#34;/media/blog/okta-logs-collector/okta-logs-loki-monitor.png?w=320 320w, /media/blog/okta-logs-collector/okta-logs-loki-monitor.png?w=550 550w, /media/blog/okta-logs-collector/okta-logs-loki-monitor.png?w=750 750w, /media/blog/okta-logs-collector/okta-logs-loki-monitor.png?w=900 900w, /media/blog/okta-logs-collector/okta-logs-loki-monitor.png?w=1040 1040w, /media/blog/okta-logs-collector/okta-logs-loki-monitor.png?w=1240 1240w, /media/blog/okta-logs-collector/okta-logs-loki-monitor.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;Log volume dashboard in Loki&#34;&#xA;width=&#34;1999&#34;&#xA;height=&#34;860&#34;&#xA;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/okta-logs-collector/okta-logs-loki-monitor.png&#34;&#xA;alt=&#34;Log volume dashboard in Loki&#34;&#xA;width=&#34;1999&#34;&#xA;height=&#34;860&#34;&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;/a&gt;&#xA;&lt;/figure&gt;&#xA;&lt;h2 id=&#34;how-to-use-sigma-rules-for-detecting-critical-log-lines&#34;&gt;How to use Sigma rules for detecting critical log lines&lt;/h2&gt;&#xA;&lt;p&gt;Ingesting logs into Loki is only half the equation; the other half is detecting critical log lines. These log lines provide crucial evidence, such as identifying whether corporate accounts have been compromised. While you can always write your own LogQL queries to detect specific issues, there are more efficient methods. One such method is leveraging the Sigma ecosystem, which offers an abundant set of declarative rules for discovering these pieces of evidence.&lt;/p&gt;&#xA;&lt;p&gt;Fortunately, the security operations team has developed a backend for &lt;a href=&#34;https://sigmahq.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Sigma&lt;/a&gt; that converts Sigma rules into Loki queries (LogQL queries). You can leverage &lt;a href=&#34;https://github.com/SigmaHQ/sigma/tree/master/rules/cloud/okta&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;existing Sigma rules for Okta&lt;/a&gt; to detect critical log lines and set alerts to monitor these events. Follow the instructions provided in &lt;a href=&#34;/blog/2022/12/15/a-guide-to-cyber-threat-hunting-with-promtail-grafana-loki-sigma-and-grafana-cloud/&#34;&gt;this blog post&lt;/a&gt; to install Sigma CLI and its plugins and to convert Sigma rules into LogQL queries.&lt;/p&gt;&#xA;&lt;p&gt;Also, you can continuously validate your Sigma rules against the &lt;a href=&#34;https://github.com/SigmaHQ/sigma-specification/blob/main/sigma-schema.json&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Sigma JSON Schema&lt;/a&gt; by utilizing the &lt;a href=&#34;https://github.com/SigmaHQ/sigma-rules-validator&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;sigma-rules-validator&lt;/a&gt; GitHub Action. Follow the instructions in &lt;a href=&#34;/blog/2024/03/25/how-to-validate-sigma-rules-with-github-actions-for-improved-security-monitoring/&#34;&gt;this blog post&lt;/a&gt; to learn more about the action and how to use it.&lt;/p&gt;&#xA;&lt;h2 id=&#34;whats-next&#34;&gt;What’s next&lt;/h2&gt;&#xA;&lt;p&gt;We hope this project can help you monitor your Okta logs more easily, but we&amp;rsquo;re not done yet. Stay tuned for version 2 of the Okta logs collector, which we&amp;rsquo;re developing as an Alloy component. This new version will offer advanced capabilities and seamless integration with Alloy components to better meet your logging needs.&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;/products/cloud/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Cloud &lt;/a&gt;is the easiest way to get started with metrics, logs, traces, dashboards, and more. We have a generous forever-free tier and plans for every use case. &lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Sign up for free now!&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;】&lt;p&gt;Okta 等身份提供商 (IdP) 通过为访问组织资源的用户提供无缝身份验证和授权体验，在企业环境中发挥着至关重要的作用。这些交互会生成大量事件日志，其中包含用户详细信息、地理位置、IP 地址等有价值的信息。&lt;/p&gt;&#xA;&lt;p&gt;这些日志对于安全团队至关重要，尤其是在运营中，因为它们用于有效检测和响应事件。然而，将这些日志集成到日志记录和 SIEM 平台可能具有挑战性。&lt;/p&gt;&#xA;&lt;p&gt;在这篇博文中，我们将向您展示如何有效设置和运行 Okta 日志收集器，以将日志发送到 &lt;a href=&#34;/oss/loki/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana Loki &lt;/a&gt; 本地或云中的实例。通过配置环境变量，运行 Okta 日志收集器 Docker 容器，并利用最新版本的 Loki 和 &lt;a href=&#34;/oss/alloy-opentelemetry-collector/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana Alloy&lt;/ a&gt;，您可以监控、分析 Okta 日志并设置警报，以获得更深入的见解并提高系统安全性和操作能力。&lt;/p&gt;&#xA;&lt;h2 id=&#34;why-we-development-the-okta-logs-collector&#34;&gt;我们为何开发 Okta 日志收集器&lt;/h2&gt;&#xA;&lt;p&gt;许多 IdP 提供用于获取事件日志的 REST API，其中 &lt;a href=&#34;https://developer.okta.com/docs/reference/api/system-log/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer &#34;&gt;Okta 的系统日志 API&lt;/a&gt; 提供 JSON 格式的日志，如下所示。然而，将这些日志集成到现有系统中通常涉及一个复杂且耗时的过程，通常需要使用 Go 等编程语言通过 HTTP 客户端库编写自定义代码来访问日志。&lt;/p&gt;&#xA;&lt;p&gt;为了简化和简化此过程，我们开发了&lt;a href=&#34;https://github.com/grafana/okta-logs-collector&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Okta 日志收集器&lt; /a&gt;.该工具可以自动从 Okta System Log API 检索日志，丰富数据，并将其发送到 STDOUT，从而可以使用 Alloy 或 Promtail 等代理轻松抓取日志并将其转发到 Loki 等可观察平台。&lt;/p&gt;&#xA;&lt;p&gt;为了进一步说明我们构建 Okta 日志收集器的原因，让我们简要了解一下开发人员在获取事件日志时面临的挑战以及我们如何尝试解决这些挑战。&lt;/p&gt;&#xA;&lt;h3 id=&#34;json-log-event-example&#34;&gt;JSON 日志事件示例&lt;/h3&gt;&#xA;&lt;p&gt;以下是 Okta 系统日志 API 生成的 JSON 格式日志事件的示例：&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet&#34;&gt;&lt;div class=&#34;lang-toolbar&#34;&gt;&#xA;&lt;span class=&#34;lang-toolbar__item&#34;&gt;JavaScript&lt;/span&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;按钮 x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;将代码复制到剪贴板&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;复制&lt;/span&gt;&#xA;&lt;/按钮&gt;&#xA;&lt;/span&gt;&#xA;&lt;div class=&#34;lang-toolbar__border&#34;&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;cod电子片段&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-javascript&#34;&gt;{&#xA;“版本”：“0”，&#xA;“严重性”：“信息”，&#xA;“客户”： {&#xA;“区域”：“OFF_NETWORK”，&#xA;“设备”：“未知”，&#xA;“用户代理”：{&#xA;&#34;os&#34;: &#34;未知&#34;,&#xA;“浏览器”：“未知”，&#xA;&#34;rawUserAgent&#34;: &#34;未知-下载&#34;&#xA;},&#xA;“ip地址”：“12.97.85.90”&#xA;},&#xA;“设备”： {&#xA;&#34;id&#34;: &#34;guob5wtu7rBggkg9G1d7&#34;,&#xA;“名称”：“MacBookPro16,1”，&#xA;“os_platform”：“OSX”，&#xA;&#34;os_version&#34;: &#34;14.3.0&#34;,&#xA;“托管”：假，&#xA;“已注册”：真实，&#xA;“device_integrator”：空，&#xA;&#34;disk_encryption_type&#34;: &#34;ALL_INTERNAL_VOLUMES&#34;,&#xA;&#34;screen_lock_type&#34;: &#34;生物识别&#34;,&#xA;“越狱”：空，&#xA;“secure_hardware_present”：true&#xA;},&#xA;“演员”：{&#xA;“id”：“00u1qw1mqitPHM8AJ0g7”，&#xA;“类型”：“用户”，&#xA;“alternateId”：“admin@example.com”，&#xA;“显示名称”：“约翰·多伊”&#xA;},&#xA;“结果”： {&#xA;“结果”：“成功”&#xA;},&#xA;“uuid”：“f790999f-fe87-467a-9880-6982a583986c”，&#xA;“已发布”：“2017-09-31T22：23：07.777Z”，&#xA;&#34;eventType&#34;: &#34;user.session.start&#34;,&#xA;&#34;displayMessage&#34;: &#34;用户登录 Okta&#34;,&#xA;“交易”： {&#xA;“类型”：“网络”，&#xA;“id”：“V04Oy4ubUOc5UuG6s9DyNQAABtc”&#xA;},&#xA;“调试上下文”：{&#xA;“调试数据”：{&#xA;&#34;requestUri&#34;: &#34;/登录/do-login&#34;&#xA;}&#xA;},&#xA;&#34;legacyEventType&#34;: &#34;core.user_auth.login_success&#34;,&#xA;“身份验证上下文”：{&#xA;“身份验证步骤”：0，&#xA;“externalSessionId”：“1013FfF-DKQSvCI4RVXChzX-w”&#xA;}&#xA;}&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;h3 id=&#34;challenges-with-log-retrieval&#34;&gt;日志检索的挑战&lt;/h3&gt;&#xA;&lt;p&gt;要检索这些日志，您需要 &lt;a href=&#34;https://help.okta.com/en-us/content/topics/security/api.htm?cshid=ext-create-api-token# create-okta-api-token&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;API 令牌&lt;/a&gt;。您可以使用 &lt;code&gt;curl&lt;/code&gt; 或类似的 HTTP 客户端测试 API：&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;按钮 x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;将代码复制到剪贴板&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;复制&lt;/span&gt;&#xA;&lt;/按钮&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;curl -v -X GET \&#xA;-H“接受：application/json”\&#xA;-H“内容类型：application/json”\&#xA;-H“授权：SSWS ${api_token}”\&#xA;“https://${yourOktaDomain}/api/v1/logs&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;p&gt;虽然 Okta 提供了 Go SDK 以便于集成，但开发人员仍然需要编写代码来获取和处理日志，这可能会很麻烦rsome并且容易出错。这就是 Okta 日志收集器通过自动化整个过程而大放异彩的地方。&lt;/p&gt;&#xA;&lt;h3 id=&#34;the-okta-logs-collector-solution&#34;&gt;Okta 日志收集器解决方案&lt;/h3&gt;&#xA;&lt;p&gt;我们的 &lt;code&gt;okta-logs-collector&lt;/code&gt; 应用程序定期从 Okta 的系统日志 API 获取日志并将其发送到 STDOUT。我们的解决方案在容器化环境中运行，Alloy 可以在其中发现 Docker 引擎、接收容器日志并将其转发给 Loki。或者，您可以将应用程序日志通过管道传输到磁盘上的文件，然后 Alloy 可以使用 &lt;code&gt;loki.source.file&lt;/code&gt; &lt;a href=&#34;/docs/alloy/latest/reference 来监视和读取该文件/components/loki.source.file/&#34;&gt;组件&lt;/a&gt; 并发送给 Loki。容器化方案如下图所示：&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1771px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&#xA;&lt;一&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/okta-logs-collector/okta-logs-collector-diagram.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/blog/okta-logs-collector/okta-logs-collector-diagram.png&#34;data-srcset=&#34;/media/blog/okta-logs-collector/okta-logs-collector-diagram. png?w=320 320w，/media/blog/okta-logs-collector/okta-logs-collector-diagram.png?w=550 550w，/media/blog/okta-logs-collector/okta-logs-collector-图.png?w=750 750w, /media/blog/okta-logs-collector/okta-logs-collector-diagram.png?w=900 900w, /media/blog/okta-logs-collector/okta-logs- Collector-diagram.png?w=1040 1040w, /media/blog/okta-logs-collector/okta-logs-collector-diagram.png?w=1240 1240w, /media/blog/okta-logs-collector/okta-日志收集器图.png?w=1920 1920w&#34;&#xA;data-size=&#34;auto&#34;alt=&#34;Okta 日志收集器图&#34;&#xA;宽度=“1771”&#xA;高度=“571”&#xA;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/okta-logs-collector/okta-logs-collector-diagram.png”&#xA;alt=&#34;Okta 日志收集器图&#34;&#xA;宽度=“1771”&#xA;高度=“571”&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;/a&gt;&#xA;&lt;/图&gt;&#xA;&lt;h2 id=&#34;how-to-use-okta-logs-collector-with-alloy&#34;&gt;如何将 Okta 日志收集器与 Alloy 结合使用&lt;/h2&gt;&#xA;&lt;p&gt;要有效地设置和运行应用程序，了解 &lt;a href=&#34;https://github.com/grafana/okta-logs-collector/blob/main/examples/cloud-config.alloy&#34; 非常重要target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Alloy 的示例配置文件&lt;/a&gt;。组件是 Alloy 的构建块，每个组件处理特定的任务，例如检索日志或将其发送给 Loki。每个组件的参考文档可以在&lt;a href=&#34;/docs/alloy/latest/reference/components/?pg=blog&amp;plcmt=body-txt&#34;&gt;此处&lt;/a&gt;找到。示例配置文件使用了多个组件，如下所述。&lt;/p&gt;&#xA;&lt;h3 id=&#34;component-1-discoverydocker&#34;&gt;组件 1：&lt;code&gt;discovery.docker&lt;/code&gt;&lt;/h3&gt;&#xA;&lt;p&gt;&lt;code&gt;discovery.docker&lt;/code&gt;&lt;a href=&#34;/docs/alloy/latest/reference/components/discovery.docker/?pg=blog&amp;plcmt=body-txt&#34;&gt;组件&lt;/a&gt;发现&lt;一个小时ref=&#34;https://docs.docker.com/engine/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Docker Engine&lt;/a&gt; 容器并将它们公开为目标。这假设您在本地运行 Docker 引擎，并且您可以访问 docker.sock Unix 域套接字，这意味着您是 Linux 上 docker 组的成员或者您以 root 身份运行。&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;按钮 x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;将代码复制到剪贴板&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;复制&lt;/span&gt;&#xA;&lt;/按钮&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;discovery.docker“容器”{&#xA;主机=“unix:///var/run/docker.sock”&#xA;}&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;h3 id=&#34;component-2-lokisourcedocker&#34;&gt;组件 2：&lt;code&gt;loki.source.docker&lt;/code&gt;&lt;/h3&gt;&#xA;&lt;p&gt;&lt;code&gt;loki.source.docker&lt;/code&gt; &lt;a href=&#34;/docs/alloy/latest/reference/components/loki.source.docker/?pg=blog&amp;plcmt=body-txt&#34;&gt;组件&lt; /a&gt; 从 Docker 容器读取日志条目并将其转发到其他 &lt;code&gt;loki.*&lt;/code&gt; 组件。每个组件都可以从单个 Docker 守护进程读取。在以下示例中，我们使用与组件 1 中使用的主机相同的 &lt;code&gt;docker.sock&lt;/code&gt;。&lt;code&gt;target&lt;/code&gt; 设置为从 Docker 容器发现并收集日志它们将被转发到链中的下一个组件（使用 &lt;code&gt;forward_to&lt;/code&gt; 参数）：&lt;code&gt;loki.process.grafanacloud.receiver&lt;/code&gt;。该组件将向其检索的所有日志应用单个标签，并且每 10 秒从容器收集一次日志（默认为 &lt;code&gt;60s&lt;/code&gt;）。&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;按钮 x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;将代码复制到剪贴板&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;复制&lt;/span&gt;&#xA;&lt;/按钮&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;loki.source.docker“默认”{&#xA;主机=“unix:///var/run/docker.sock”&#xA;目标= discovery.docker.containers.targets&#xA;forward_to = [loki.process.grafanacloud.receiver]&#xA;标签={&#xA;工作=“okta-logs-collector”，&#xA;}&#xA;刷新间隔=“10秒”&#xA;}&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;h3 id=&#34;component-3-lokiprocess&#34;&gt;组件 3：&lt;code&gt;loki.process&lt;/code&gt;&lt;/h3&gt;&#xA;&lt;p&gt;&lt;code&gt;loki.process&lt;/code&gt; &lt;a href=&#34;/docs/alloy/latest/reference/components/loki.process/?pg=blog&amp;plcmt=body-txt&#34;&gt;组件&lt;/a&gt;接收来自其他 Loki 组件的日志条目。然后，它通过各个“阶段”处理它们，并将处理后的日志转发到指定的接收者。每个阶段有&lt;code&gt;loki.process&lt;/code&gt; 块可以解析、转换和过滤日志条目。此管道中的阶段执行以下操作：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;过滤日志&lt;/strong&gt;以仅包含来自 &lt;code&gt;okta-logs-collector&lt;/code&gt; 作业的日志。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;从 JSON 格式的日志行中提取字段&lt;/strong&gt;（&lt;code&gt;eventType&lt;/code&gt;、&lt;code&gt;level&lt;/code&gt;、&lt;code&gt;timestamp&lt;/code&gt;）。&lt;/li &gt;&#xA;&lt;li&gt;&lt;strong&gt;使用提取的&lt;code&gt;timestamp&lt;/code&gt;字段设置日志时间戳&lt;/strong&gt;，格式为&lt;a href=&#34;https://www.rfc-editor.org/rfc/rfc3339。 html&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;RFC3339&lt;/a&gt;。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;将提取的字段&lt;/strong&gt;（&lt;code&gt;eventType&lt;/code&gt; 和 &lt;code&gt;level&lt;/code&gt;）分配为用于索引和查询的 Loki 标签。 &lt;code&gt;级别&lt;/code&gt;有效地取代了Loki日志级别。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;按钮 x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;将代码复制到剪贴板&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;复制&lt;/span&gt;&#xA;&lt;/按钮&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;loki.process &#34;grafanacloud&#34; {&#xA;forward_to = [loki.write.grafanacloud.receiver]&#xA;阶段.匹配{&#xA;// 仅匹配来自 okta-logs-collector 作业的日志&#xA;选择器 = &#34;{job=\&#34;okta-logs-collector\&#34;}&#34;&#xA;// 从日志行中提取重要标签和时间戳&#xA;// 并将它们映射到 Loki 标签&#xA;阶段.json {&#xA;表达式 = {&#xA;eventType = &#34;事件.eventType&#34;,&#xA;level = &#34;事件.严重性&#34;,&#xA;时间戳=“时间”，&#xA;}&#xA;}&#xA;// 使用日志行中的时间戳作为 Loki 时间戳&#xA;阶段.时间戳{&#xA;来源=“时间戳”&#xA;格式=“RFC3339”&#xA;}&#xA;// 使用提取的标签作为 Loki 标签进行索引。&#xA;// 这些标签可以用作 LogQL 中的流选择器。&#xA;阶段.标签{&#xA;值={&#xA;事件类型 = &#34;&#34;,&#xA;级别=“”，&#xA;}&#xA;}&#xA;}&#xA;}&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;h3 id=&#34;component-4-lokiwrite&#34;&gt;组件 4：&lt;code&gt;loki.write&lt;/code&gt;&lt;/h3&gt;&#xA;&lt;p&gt;&lt;code&gt;loki.write&lt;/code&gt; &lt;a href=&#34;/docs/alloy/latest/reference/components/loki.write/?pg=blog&amp;plcmt=body-txt&#34;&gt;组件&lt;/a&gt;接收来自其他 Loki 组件的日志条目（确切地说是我们刚刚讨论的最后三个组件），并使用 &lt;code&gt;logproto&lt;/code&gt; &lt;a href=&#34;https://github.com/grafana/loki/ 将它们发送到 Loki blob/main/pkg/logproto/logproto.proto&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;格式&lt;/a&gt;。该示例使用具有基本身份验证的 &lt;a href=&#34;/docs/grafana-cloud/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt; 端点。&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;按钮 x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;将代码复制到剪贴板“宽度=“14”高度=“13”&gt;&#xA;&lt;span&gt;复制&lt;/span&gt;&#xA;&lt;/按钮&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;loki.write &#34;grafanacloud&#34; {&#xA;端点{&#xA;url = &#34;https://&lt;子域名&gt;.grafana.net/loki/api/v1/push&#34;&#xA;基本身份验证{&#xA;username = &#34;&lt;您的 Grafana.com 用户 ID&gt;&#34;&#xA;密码 =“&lt;您的 Grafana.com API 令牌&gt;”&#xA;}&#xA;}&#xA;}&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;p&gt;环境变量还可以用于设置用户名和密码（甚至 URL）：&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;按钮 x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;将代码复制到剪贴板&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;复制&lt;/span&gt;&#xA;&lt;/按钮&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;basic_auth {&#xA;用户名 = env(&#34;GRAFANA_CLOUD_USER_ID&#34;)&#xA;密码 = env(&#34;GRAFANA_CLOUD_API_KEY&#34;)&#xA;}&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;p&gt;此配置有效地设置了一个管道，用于发现 Docker 容器、收集和处理其日志，并将处理后的日志发送到由 Loki 提供支持的 Grafana Cloud Logs。&lt;/p&gt;&#xA;&lt;h2 id=&#34;set-up-and-run-okta-logs-collector&#34;&gt;设置并运行 Okta 日志收集器&lt;/h2&gt;&#xA;&lt;p&gt;掌握 Alloy 配置后，您就可以设置并运行 Okta 日志收集器了。&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;登录 Okta&lt;/strong&gt;。以管理员身份登录您的 Okta 帐户。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;创建 API 令牌&lt;/strong&gt;。创建一个新的 &lt;a href=&#34;https://help.okta.com/en-us/content/topics/security/api.htm?cshid=ext-create-api-token#create-okta-api-token&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;API 令牌&lt;/a&gt;，用于访问 &lt;a href=&#34;https://developer.okta.com/docs/reference/api/system-log/&#34; target=&#34; _blank&#34; rel=&#34;noopener noreferrer&#34;&gt;系统日志 API&lt;/a&gt;。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;设置环境变量。&lt;/strong&gt;在 shell 中配置必要的环境变量：&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;按钮 x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;将代码复制到剪贴板&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;复制&lt;/span&gt;&#xA;&lt;/按钮&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;导出 OKTA_URL=&#34;https://&lt;account&gt;.okta.com&#34;&#xA;导出 OKTA_API_TOKEN=&#34;your-api-token&#34;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;ol开始=“4”&gt;&#xA;&lt;li&gt;&lt;strong&gt;运行 Okta 日志收集器&lt;/strong&gt;。使用 Docker 运行 Okta 日志收集器容器。您也可以在 Kubernetes 中运行它。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;按钮n x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;将代码复制到剪贴板&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;复制&lt;/span&gt;&#xA;&lt;/按钮&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;docker run --name okta-logs-collector \&#xA;-e OKTA_URL=${OKTA_URL} \&#xA;-e API_KEY=${OKTA_API_TOKEN} \&#xA;-e LOOKBACK_INTERVAL=24h \ # 默认为 1h&#xA;-e POLL_INTERVAL=10s \&#xA;-e LOG_LEVEL=信息 \&#xA;grafana/okta-logs-collector:最新民意调查&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;ol开始=“5”&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;下载配置文件。&lt;/strong&gt;获取&lt;a href=&#34;https://github.com/grafana/okta-logs-collector/tree/main/examples&#34; target=&#34;_blank&#34; rel= “noopener noreferrer&#34;&gt;示例配置文件&lt;/a&gt;并将它们放在方便的位置。请注意，Alloy 配置将所有 Docker 日志发送到 Loki，因此您应该考虑 &lt;a href=&#34;/docs/alloy/latest/reference/components/discovery.docker/?pg=blog&amp;plcmt=body-txt#filter-block&#34;&gt;使用容器名称过滤日志&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;在 Grafana Cloud 上使用 Loki 或在本地运行 Loki&lt;/strong&gt; &lt;strong&gt;本地部署。&lt;/strong&gt;找到您的 Grafana Cloud 堆栈并&lt;a href=&#34;/docs/grafana-cloud/account-management /cloud-stacks/?pg=blog&amp;plcmt=body-txt#find-instance-endpoints&#34;&gt;查找您的 Loki 实例端点&lt;/a&gt;。 （如果您尚未使用 Grafana Cloud，可以注册一个&lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;plcmt=body-txt&#34;&gt;永久免费帐户&lt;/a &gt; 今天。）或者，&lt;a href=&#34;https://github.com/grafana/okta-logs-collector/blob/main/examples/loki.yaml&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;an如果您想在本地运行 Loki，可以为 Loki 提供示例配置文件&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;配置合金&lt;/strong&gt;。如果您使用 Grafana Cloud Logs，请按照以下步骤操作。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;使用&lt;a href=&#34;https://github.com/grafana/okta-logs-collector/blob/main/examples/cloud-config.alloy&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;提供的示例配置&lt;/a&gt;，并将这些占位符替换为实际值：&lt;code&gt;&lt;subdomain&gt;&lt;/code&gt;、&lt;code&gt;&lt;Your Grafana.com User ID&gt;&lt;/code&gt; 和 &lt;code&gt;&lt;Your Grafana.com User ID&gt;&lt;/code&gt;。 com API 令牌&gt;&lt;/code&gt;。&lt;/li&gt;&#xA;&lt;li&gt;生成 &lt;a href=&#34;http://Grafana.com&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;API 令牌&lt;/a&gt;以访问日志并将日志推送到您的 Loki 实例。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;运行合金&lt;/strong&gt;。下载、解压并运行&lt;a href=&#34;https://github.com/grafana/alloy/releases/latest&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;最新版本的 Alloy&lt;/a&gt;。&lt;/ p&gt;&#xA;&lt;p&gt;如果您使用 Grafana Cloud Logs，请改用 &lt;code&gt;cloud-config.alloy&lt;/code&gt;。上一节解释了示例配置文件的结构细节。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;按钮x-data =“app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;将代码复制到剪贴板&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;复制&lt;/span&gt;&#xA;&lt;/按钮&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;./alloy-linux-amd64 run /absolute/path/to/config.alloy&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;h2 id=&#34;how-to-observe-logs-in-loki-and-grafana&#34;&gt;如何在 Loki 和 Grafana 中观察日志&lt;/h2&gt;&#xA;&lt;p&gt;过了一会儿，您应该会看到 Loki 中出现日志。使用 Loki LogCLI 或其在 Grafana 中的数据源来查看和分析日志。如果您使用 Grafana Cloud，请转至 Grafana Cloud 门户并启动 Grafana。从右侧菜单中，导航至&lt;strong&gt;连接&lt;/strong&gt; &gt; &lt;strong&gt;数据源&lt;/strong&gt;，您将在其中看到 Loki 已添加为数据源。导航到&lt;strong&gt;探索&lt;/strong&gt;页面并开始使用&lt;code&gt;{job=&#34;okta-logs-collector&#34;}&lt;/code&gt;流选择器查询您的Okta日志。 &lt;code&gt;eventType&lt;/code&gt; 字段已建立索引，允许您过滤特定的事件类型。可以找到 Okta 事件类型的完整列表（截至目前超过 930 种） &lt;a href=&#34;https://developer.okta.com/docs/reference/api/event-types/&#34; target=&#34;_blank&#34; rel =&#34;noopener noreferrer&#34;&gt;这里&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1999px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&#xA;&lt;一&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/okta-logs-collector/okta-logs-loki-monitor.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&#xA;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/blog/okta-logs-collector/okta-logs-loki-monitor.png&#34;data-srcset=&#34;/media/blog/okta-logs-collector/okta-logs-loki-monitor.png png?w=320 320w，/media/blog/okta-logs-collector/okta-logs-loki-monitor.png?w=550 550w，/media/blog/okta-logs-collector/okta-logs-loki- Monitor.png?w=750 750w, /media/blog/okta-logs-collector/okta-logs-loki-monitor.png?w=900 900w, /media/blog/okta-logs-collector/okta-logs- loki-monitor.png?w=1040 1040w, /media/blog/okta-logs-collector/okta-logs-loki-monitor.png?w=1240 1240w, /media/blog/okta-logs-collector/okta-日志-loki-monitor.png?w=1920 1920w&#34;&#xA;data-size=&#34;auto&#34;alt=&#34;Loki 中的日志量仪表板&#34;&#xA;宽度=“1999”&#xA;高度=“860”&#xA;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src=&#34;/media/blog/okta-logs-collector/okta-logs-loki-monitor.png&#34;&#xA;alt=&#34;Loki 中的日志量仪表板&#34;&#xA;宽度=“1999”&#xA;高度=“860”&#xA;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&#xA;&lt;/a&gt;&#xA;&lt;/图&gt;&#xA;&lt;h2 id=&#34;how-to-use-sigma-rules-for-detecting-ritic-log-lines&#34;&gt;如何使用 Sigma 规则检测关键日志行&lt;/h2&gt;&#xA;&lt;p&gt;将日志摄取到 Loki 中只是成功的一半；另一半是检测关键日志行。这些日志行提供了重要的证据，例如确定公司帐户是否已被泄露。虽然您始终可以编写自己的 LogQL 查询来检测特定问题，但还有更有效的方法。其中一种方法是 le评估 Sigma 生态系统，它提供了一套丰富的声明性规则来发现这些证据。&lt;/p&gt;&#xA;&lt;p&gt;幸运的是，安全运营团队为 &lt;a href=&#34;https://sigmahq.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Sigma&lt;/a&gt; 开发了一个后端，可以将 Sigma 规则转换为Loki 查询（LogQL 查询）。您可以利用&lt;a href=&#34;https://github.com/SigmaHQ/sigma/tree/master/rules/cloud/okta&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Okta 的现有 Sigma 规则&lt;/a &gt; 检测关键日志行并设置警报来监控这些事件。请按照&lt;a href=&#34;/blog/2022/12/15/a-guide-to-cyber-threat-hunting-with-promtail-grafana-loki-sigma-and-grafana-cloud/&#34;&gt;此中提供的说明进行操作博客文章&lt;/a&gt;安装 Sigma CLI 及其插件并将 Sigma 规则转换为 LogQL 查询。&lt;/p&gt;&#xA;&lt;p&gt;此外，您还可以根据 &lt;a href=&#34;https://github.com/SigmaHQ/sigma-specation/blob/main/sigma-schema.json&#34; target=&#34;_blank&#34; rel= 持续验证 Sigma 规则“noopener noreferrer&#34;&gt;Sigma JSON Schema&lt;/a&gt;，利用 &lt;a href=&#34;https://github.com/SigmaHQ/sigma-rules-validator&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;sigma-规则验证器&lt;/a&gt; GitHub Action。请按照&lt;a href=&#34;/blog/2024/03/25/how-to-validate-sigma-rules-with-github-actions-for-improved-security-monitoring/&#34;&gt;此博文&lt;/a中的说明进行操作&gt; 了解有关该操作及其使用方法的更多信息。&lt;/p&gt;&#xA;&lt;h2 id=&#34;whats-next&#34;&gt;下一步是什么&lt;/h2&gt;&#xA;&lt;p&gt;我们希望这个项目可以帮助您更轻松地监控 Okta 日志，但我们还没有完成。请继续关注 Okta 日志收集器的第 2 版，我们正在将其开发为 Alloy 组件。这个新版本将提供先进的功能以及与 Alloy 组件的无缝集成，以更好地满足您的日志记录需求。&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;/products/cloud/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt;是开始使用指标、日志、跟踪、仪表板等的最简单方法。我们为每个用例提供慷慨的永久免费套餐和计划。 &lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;plcmt=body-txt&#34;&gt;立即免费注册！&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 07 Aug 2024 00:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>