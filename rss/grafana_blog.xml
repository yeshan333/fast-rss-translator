<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Grafana Labs blog on Grafana Labs</title>
    <link>/blog/index.xml</link>
    <description>Recent content in Grafana Labs blog on Grafana Labs</description>
    <item>
      <title>【Tiger teams: How we tackle urgent, cross-functional challenges at Grafana Labs】老虎队：我们如何应对Grafana Labs的紧急，跨职能挑战</title>
      <link>https://grafana.com/blog/2025/09/05/tiger-teams-how-we-tackle-urgent-cross-functional-challenges-at-grafana-labs/</link>
      <description>【&lt;p&gt;A year ago, we hit a wall. &lt;/p&gt;&#xA;&lt;p&gt;Our Grafana OSS releases were excruciating to execute. The process was confusing and hard to follow, security patches were non-trivial, and many engineering hours were lost to an overly manual process. We needed to move fast, cut through ambiguity, and pull in just the right people without waiting on roadmaps or org charts. That’s when I pitched the idea of forming the first ever &amp;ldquo;tiger team&amp;rdquo; at Grafana Labs, a small and focused group designed to tackle high-priority, cross-functional problems with speed and clarity.&lt;/p&gt;&#xA;&lt;p&gt;A year later, tiger teams have greatly improved the release cycle process, and they&amp;rsquo;ve quickly become our go-to model for tackling urgent, high-impact issues that don’t fit neatly into a single team’s backlog. In this post, I’ll share what tiger teams are, examples of how we’ve used this model at Grafana Labs, hard lessons learned along the way, and my recommended best practices.&lt;/p&gt;&#xA;&lt;p&gt;Whether you&amp;rsquo;re facing a deep technical challenge, landing a major deal, or just need a way to unblock cross-functional work, I hope our approach gives you a few ideas to take back to your own organization.&lt;/p&gt;&#xA;&lt;h3 id=&#34;what-is-a-tiger-team&#34;&gt;What is a tiger team?&lt;/h3&gt;&#xA;&lt;p&gt;The term &amp;ldquo;tiger team&amp;rdquo; &lt;a href=&#34;https://en.wikipedia.org/wiki/Tiger_team#Origin_of_the_term&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;originated at NASA&lt;/a&gt; in the 1960s during the Apollo 13 mission. In Walter C. Williams’ paper, &amp;ldquo;Program Management in Design and Development,&amp;rdquo; the NASA Manned Spacecraft Center engineer defined a tiger team as a &amp;ldquo;team of undomesticated and uninhibited technical specialists, selected for their experience, energy, and imagination, and assigned to track down relentlessly every possible source of failure in a spacecraft subsystem or simulation.&amp;ldquo;​&lt;/p&gt;&#xA;&lt;p&gt;This approach was put to the test when an explosion in the spacecraft&amp;rsquo;s service module put the lives of the Apollo 13 astronauts in jeopardy. NASA&amp;rsquo;s flight director Gene Kranz assembled a group of specialists, later dubbed the tiger team, to find a way to safely return the astronauts to Earth. The success of this effort proved how powerful a temporary cross-functional team of experts can be when united by urgency and a singular focus.&lt;/p&gt;&#xA;&lt;p&gt;At Grafana Labs, we use the tiger team model to tackle complex, time-sensitive challenges that our org structure is not currently set up to handle. Unlike traditional engineering teams, which are often organized around long-term product areas or services, tiger teams are temporary, goal-oriented groups formed to address specific issues. They are typically composed of three to five specialized engineers, and they last for one to two quarters, or until the targeted goal is reached. &lt;/p&gt;&#xA;&lt;h3 id=&#34;a-grafana-labs-example-the-release-tiger-team&#34;&gt;A Grafana Labs example: The Release Tiger Team&lt;/h3&gt;&#xA;&lt;p&gt;Looking back at that wall we hit a year ago with releasing Grafana, the formation of the Release Tiger Team marked a turning point. At the time the challenges we faced didn’t fall neatly within the scope of any single team. Ownership was ambiguous, and the expertise needed to fix our build and release pipelines was scattered across the org. &lt;/p&gt;&#xA;&lt;p&gt;We brought together engineers from different teams who had the right mix of experience in CI/CD, and deep familiarity with our systems. These were the engineers that had been vocal about the problems, already hacking at them on the side, and were best positioned to drive real change. We banded together, blatantly ignoring our current organizational structures to focus solely on the one unified goal of fixing our build and release pipelines. &lt;/p&gt;&#xA;&lt;p&gt;Our company had put trust in us that we could deliver on this goal in a single quarter. We were a team of just three senior engineers, with myself as lead. I soon realized we needed laser focus to achieve this on such a short timescale. I drafted a roadmap with three major milestones: simplify the release process, add the ability to patch our Grafana Cloud release channels directly, and fully automate our builds. With this plan in place, we got to work.&lt;/p&gt;&#xA;&lt;h3 id=&#34;tiger-team-take-2&#34;&gt;Tiger team, take 2&lt;/h3&gt;&#xA;&lt;p&gt;Of course, the problem with the best laid plans is that they never go exactly as expected. &lt;/p&gt;&#xA;&lt;p&gt;We tried our best to stay singularly focused on our goals, but there were still releases that needed our immediate attention. This included unexpected security releases that quarter, and those releases had their own unique issues that needed our expertise to fix. This took valuable time away from our project, but also served as a real-world user test that highlighted our most critical issues, and what was most urgent for us to address. &lt;/p&gt;&#xA;&lt;p&gt;We reorganized and rallied behind our first milestone to simplify our release process by reducing the amount of manual, and thus error prone, steps involved. Originally responsibilities were too fragmented, and no single team had clear ownership of the release process. &lt;/p&gt;&#xA;&lt;p&gt;Taking a critical look at who was actually doing the work, who understood the system best, and who had the drive to fix it, we restructured engineers from various teams into this singularly focused tiger team, cutting across squads and reporting lines while doing so. &lt;/p&gt;&#xA;&lt;p&gt;These engineers knew how the current release process worked, where steps could be combined, what documentation was missing, how we built and packaged the release artifacts, and where the pipelines most commonly failed. With this, we had the momentum we needed to move quickly and make meaningful progress.&lt;/p&gt;&#xA;&lt;p&gt;As the quarter came to a close we had drastically reduced the manual steps involved in our release process. The engineers running the releases did so effectively and independently, and suddenly security releases were not so intimidating. We even made good progress on our other milestones, such as Grafana Cloud version patching. &lt;/p&gt;&#xA;&lt;p&gt;But then what? Our tiger team was set to dissolve at the end of the quarter, so what did that mean for the work still outstanding, or the tooling we had built? Who would own this moving forward? Thankfully, due to the success of the Release Tiger Team, we were able to advocate for a full-time dedicated team that would continue to iterate on our release issues and take full ownership in this area.&lt;/p&gt;&#xA;&lt;p&gt;However, this is not always possible—or even advisable. Our team fit a specific, long-term need, so it made sense to keep it around. But if your tiger team has achieved its goal and no longer serves a purpose, then it can be dissolved and everyone can return to their normal responsibilities.&lt;/p&gt;&#xA;&lt;h3 id=&#34;how-can-you-run-effective-tiger-teams&#34;&gt;How can you run effective tiger teams?&lt;/h3&gt;&#xA;&lt;p&gt;Running effective tiger teams is a delicate act, and it requires some forethought. I can only speak from my experience with the Release Tiger Team, and other tiger teams we have since created. However, I did learn some valuable lessons in the process.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Be strategic.&lt;/strong&gt; Be more strategic than you even think you need to be. Prioritize, and reprioritize, and reduce your ambitions down to a single laser-focused goal. With this goal you should be able to say: If this is all we achieved, our mission was still successful.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Get the right people.&lt;/strong&gt; The power of tiger teams is that you can pull people to your cause regardless of the constraints of existing organizational and team structures. You have high priority needs, ambitious goals, and a short amount of time to execute on them. None of this is possible without the right people by your side.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Define the end state at the beginning.&lt;/strong&gt; When is the tiger team complete? When can the people involved go back to their original teams? What happens to the code, tooling, features, or processes that were created? Who will own these long-term? Don’t wait for the project to end to find this out. The sooner these can be laid out in the process the better. No one wants their project suddenly dropped or thrown over the wall at someone else.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;In closing, I hope my own journey in this space has offered you some insight. Tiger teams are a powerful tool for rallying to solve critical failures, or land big deals, or address systemic issues that otherwise cannot be solved within the existing organizational structure of the company. &lt;/p&gt;&#xA;&lt;p&gt;We at Grafana have continued to lean into the power of tiger teams. Another of our tiger teams successfully landed a big Fortune 500 technology partner, and yet another is trailblazing greenfield opportunities that could expand our offerings. What can a tiger team accomplish at your company?&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;/products/cloud/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt;&lt;/em&gt; &lt;em&gt;is the easiest way to get started with metrics, logs, traces, dashboards, and more. We have a generous forever-free tier and plans for every use case.&lt;/em&gt; &lt;em&gt;&lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Sign up for free now!&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;】&lt;p&gt;一年前，我们撞墙了。 &lt;/p&gt;&#xA;&lt;p&gt;我们的Grafana OSS版本令人难以置信。该过程令人困惑，很难遵循，安全补丁是非平凡的，并且许多工程时间都因手动过度流程而丢失了。我们需要快速移动，削减歧义，并吸引恰到好处的人，而无需等待路线图或组织图表。那时，我提出了在Grafana Labs组成有史以来第一个“老虎团队”的想法，Grafana Labs是一个小型而专注的小组，旨在解决高优先级，跨功能问题的速度和清晰度。&lt;/p&gt;&#xA;&lt;p&gt;一年后，老虎团队大大改善了发行周期的过程，并且很快就成为我们解决紧急，高影响力问题的首选模式，这些问题并不完全适合单个团队的积压。在这篇文章中，我将分享什么是老虎团队，示例我们如何在Grafana Labs使用此模型，一路上学到了艰难的教训，以及我推荐的最佳实践。&lt;/p&gt;&#xA;&lt;p&gt;无论您是面临着深厚的技术挑战，达成重大交易，还是只需要一种解开跨职能工作的方法，我希望我们的方法能给您一些想法，可以带回自己的组织。&lt;/p&gt;&#xA;&lt;h3 id =“什么是老虎队”&gt;什么是老虎队？&lt;/h3&gt;&#xA;&lt;p&gt;术语“老虎团队” &lt;a href =“ https://en.wikipedia.org/wiki/wiki/tiger_team/team/team/team#origin_of_term_term“ target =” _ black“ rel =” noopener noreferrer“&gt;在1​​960年代在NASA &lt;/a&gt;中，在1960年代的Apollo 13 Mission。在沃尔特·C·威廉姆斯（Walter C. Williams）的论文中，“设计与开发计划管理”，NASA载有航天器中心工程师将一支老虎团队定义为“一支由未营造的和不受欢迎的技术专家组成的团队，他们为他们的经验，精力和想象力而被选中，并分配了无与伦比的所有可能的失败来源，以无限地跟踪Spacececraft Supsedystem或Simulation of Spacececraft Supsedem或Simpulation of Sypleulation或Simulation。&#xA;&lt;p&gt;当航天器的服务模块中的爆炸使阿波罗13宇航员的生命陷入困境时，这种方法进行了测试。美国宇航局的飞行总监吉恩·克兰兹（Gene Kranz）组建了一群专家，后来被称为老虎队，以找到一种安全将宇航员归还地球的方法。这项努力的成功证明了一个临时的跨职能专家团队在紧迫感和一个单一的重点时会多么强大。&lt;/p&gt;&#xA;&lt;p&gt;在Grafana Labs，我们使用Tiger Team模型来应对目前尚未设置组织的组织结构的复杂，时间敏感的挑战。与通常围绕长期产品区域或服务组织的传统工程团队不同，老虎团队是临时的，面向目标的小组，以解决特定问题。它们通常由三到五名专业工程师组成，并且持续一到两个季度，或者直到达到目标目标为止。 &lt;/p&gt;&#xA;&lt;h3 id =“ a-grafana-labs-示例 - 释放 - 老虎队”&gt; grafana Labs示例：发行Tiger Team &lt;/h3&gt;&#xA;&lt;p&gt;回头看那堵墙，我们一年前打了释放Grafana的释放Tiger Team的形成标志着一个转折点。当时，我们面临的挑战并没有整齐地落在任何一支球队的范围之内。所有权是模棱两可的，修复我们的构建和释放管道所需的专业知识散布在组织中。 &lt;/p&gt;&#xA;&lt;p&gt;我们将来自不同团队的工程师汇集在一起​​，他们在CI/CD方面具有正确的经验，并且对我们的系统非常熟悉。这些工程师一直在发声问题，已经在侧面攻击了他们，并且最好是推动真正的变化。我们团结起来，公然忽略了当前的组织结构，只专注于修复我们的构建和释放管道的一个统一目标。 &lt;/p&gt;&#xA;&lt;p&gt;我们的公司对我们可以在一个季度内实现这一目标信任。我们是一支由三名高级工程师组成的团队，我自己是领导者。我很快意识到，我们需要激光专注于如此短的时间表。我起草了一个具有三个主要里程碑的路线图：简化发布过程，添加直接修补Grafana Cloud释放频道的能力，并完全自动化我们的构建。有了这个计划，我们开始工作。&lt;/p&gt;&#xA;&lt;H3 ID =“ Tiger-Team-Take-2”&gt; Tiger Team，取2 &lt;/h3&gt;&#xA;&lt;p&gt;当然，最佳计划的问题是它们永远不会完全按预期进行。 &lt;/p&gt;&#xA;&lt;p&gt;我们尽力保持专注于我们的目标，但仍然有一些释放需要我们立即关注。这包括该季度的意外安全性发布，这些发行版具有自己的独特问题，需要我们的专业知识来解决。这花费了宝贵的时间，但也充当了现实世界中的用户测试，突出了我们最关键的问题，以及最迫切需要解决的问题。 &lt;/p&gt;&#xA;&lt;p&gt;我们通过减少涉及的步骤，重新组织并集结了第一个里程碑，以减少手动数量，从而简化释放过程，从而简化我们的释放过程。最初的责任太分散了，没有一支团队对发行过程有明确的所有权。 &lt;/p&gt;&#xA;&lt;p&gt;批判性地看着谁实际上正在做这项工作，谁最了解系统，谁有修复该系统的人，我们将各个团队的工程师重组为这个奇特的小型老虎团队，在这样做的同时跨越了小队和报告线路。 &lt;/p&gt;&#xA;&lt;p&gt;这些工程师知道当前发布过程如何工作，可以将步骤组合起来，缺少哪些文档，我们如何构建和打包释放工件以及最常见的管道中最常见的地方。这样，我们拥有需要快速行动并取得有意义进步的动力。&lt;/p&gt;&#xA;&lt;p&gt;当季度结束时，我们大大减少了发行过程中涉及的手动步骤。运行发行版的工程师如此有效，独立地做到了，突然安全版本并没有那么令人生畏。我们甚至在其他里程碑上取得了良好的进步，例如Grafana C大声版本修补。 &lt;/p&gt;&#xA;&lt;p&gt;但是那是什么？我们的老虎团队将在本季度结束时解散，那么这对于仍然出色的工作或我们建造的工具意味着什么？谁能拥有这个前进？值得庆幸的是，由于发行老虎团队的成功，我们能够为一个全职专用团队倡导，该团队将继续迭代我们的发行问题并在该领域获得全部所有权。&lt;/p&gt;&#xA;&lt;p&gt;但是，这并不总是可能的，甚至不可能。我们的团队满足了特定的长期需求，因此保持围绕它是有意义的。但是，如果您的老虎团队实现了目标，并且不再有目的，那么它可以解散，每个人都可以恢复正常的责任。&lt;/p&gt;&#xA;&lt;h3 id =“如何运行您运行的老虎队”&gt;您如何运行有效的老虎队？&lt;/h3&gt;&#xA;&lt;p&gt;运行有效的老虎团队是一种微妙的举动，它需要一些前瞻性。我只能根据发行老虎团队以及我们创建的其他老虎团队的经验。但是，我确实在此过程中学习了一些有价值的教训。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt; &lt;strong&gt;具有战略性。&lt;/strong&gt;比您认为您需要的更具战略意义。优先考虑，重新定位，并将您的野心降低到一个以激光为中心的目标。有了这个目标，您应该能够说：如果这是我们所取得的全部成就，我们的使命仍然成功。&lt;/li&gt;&#xA;&lt;li&gt; &lt;strong&gt;得到合适的人。&lt;/strong&gt;老虎团队的力量是，无论现有组织和团队结构的限制如何，您都可以将人们拉到您的事业上。您有很高的优先级需求，雄心勃勃的目标以及对他们执行的时间很短的时间。如果没有合适的人，这是不可能的。&lt;/li&gt;&#xA;&lt;li&gt; &lt;strong&gt;在开始时定义终端状态。&lt;/strong&gt;老虎队何时完成？涉及的人什么时候可以回到他们的原始团队？创建的代码，工具，功能或过程会发生什么？谁将拥有这些长期？不要等待该项目结束才能找到这个问题。这些过程越早可以在此过程中布置越好。没有人希望他们的项目突然掉落或扔在别人的墙上。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;结束时，我希望我自己在这个领域的旅程为您提供了一些见识。老虎团队是解决重大失败或大量交易的强大工具，或解决否则在公司现有组织结构中无法解决的系统性问题。 &lt;/p&gt;&#xA;&lt;p&gt;我们在格拉法纳（Grafana）继续依靠老虎队的力量。我们的另一个老虎团队成功地建立了一个大型财富500技术合作伙伴，而另一个是开拓性的绿地机会，可以扩大我们的产品。老虎团队可以在贵公司完成什么？&lt;/p&gt;&#xA;&lt;p&gt; &lt;em&gt; &lt;a href =“/products/cloud/？pg = blog＆plcmt = body-txt”&gt; grafana cloud &lt;/a&gt; &lt;/em&gt; &lt;em&gt;是开始使用指标，日志，痕迹，仪表，仪表板等最简单的方法。我们有一个慷慨的每种用例的越来越级别和计划。&lt;/em&gt; &lt;em&gt; &lt;a href =“/auth/auth/nig-up/create-user/？pg = blog＆plcmt = body-txt = body-txt”&gt;现在免费注册！&lt;/a&gt; &lt;/a&gt; &lt;/em&gt; &lt;/p&gt;</description>
      <pubDate>Fri, 05 Sep 2025 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【What’s new in the Infinity data source for Grafana: support for JQ parser, additional HTTP methods, and more】Grafana的Infinity数据源中有什么新功能：支持JQ Parser，其他HTTP方法等等</title>
      <link>https://grafana.com/blog/2025/09/04/whats-new-in-the-infinity-data-source-for-grafana-support-for-jq-parser-additional-http-methods-and-more/</link>
      <description>【&lt;p&gt;Since its launch in 2020, the &lt;a href=&#34;/docs/plugins/yesoreyeram-infinity-datasource/latest/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Infinity data source for Grafana&lt;/a&gt; has become the go-to solution to seamlessly query and visualize data from JSON, CSV, XML, and GraphQL endpoints within Grafana. &lt;/p&gt;&#xA;&lt;p&gt;Allowing users to integrate diverse data formats via HTTP-based APIs, the Infinity data source has enabled a wide range of use cases within our community over the years — from visualizing cloud computing costs to popular Pokémon games.&lt;/p&gt;&#xA;&lt;p&gt;Recently, we’ve made several updates to improve the functionality, performance, and ease of use of this universal data source. Read on to learn more about the latest features in our Infinity data source for Grafana, and check out the video below for a general overview. &lt;/p&gt;&#xA;&lt;div&#xA;class=&#34;youtube-lazyload responsive-video&#34;&#xA;data-embed=&#34;OR5pJR7jb8g&#34;&#xA;data-url=&#34;https://www.youtube.com/embed/OR5pJR7jb8g?autoplay=1&#34;&#xA;data-title=&#34;YouTube Video&#34;&#xA;&gt;&#xA;&lt;div class=&#34;play-button&#34;&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;&lt;em&gt;Note: In August 2025, a Server-Side Request Forgery (SSRF) vulnerability (&lt;strong&gt;&lt;a href=&#34;/security/security-advisories/cve-2025-8341/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;CVE-2025-8341&lt;/a&gt;&lt;/strong&gt;) was discovered in older versions of the Infinity data source.&lt;/em&gt; &lt;em&gt;This vulnerability was fixed in version 3.4.1.&lt;/em&gt; &lt;em&gt;For Grafana Cloud users, we have automatically updated older versions of the data source to the patched version. For all on-premises users, we strongly recommend upgrading to&lt;/em&gt; &lt;em&gt;&lt;a href=&#34;https://github.com/grafana/grafana-infinity-datasource/releases/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;the latest version&lt;/a&gt;&lt;/em&gt; &lt;em&gt;of the data source.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;powerful-json-transformation-support-for-the-jq-backend-parser&#34;&gt;Powerful JSON transformation: support for the JQ backend parser &lt;/h2&gt;&#xA;&lt;p&gt;One of the most requested features from the community is finally here: support for JQ parsing! 🎉&lt;/p&gt;&#xA;&lt;p&gt;Until now, the only backend parser available in the Infinity data source was &lt;a href=&#34;https://jsonata.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;JSONata&lt;/a&gt;. While powerful, its syntax is unfamiliar to many users. &lt;a href=&#34;https://jqlang.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;JQ&lt;/a&gt;, on the other hand, is widely known, well-documented, and already familiar to many developers. This makes it a much more approachable option for advanced JSON transformations.&lt;/p&gt;&#xA;&lt;p&gt;To use it:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;In the query editor, set the &lt;strong&gt;Parser&lt;/strong&gt; option to JQ.&lt;/li&gt;&#xA;&lt;li&gt;In the &lt;strong&gt;Root Selector&lt;/strong&gt;, write your &lt;strong&gt;JQ expression&lt;/strong&gt; (e.g. &lt;code&gt;.[]&lt;/code&gt;, &lt;code&gt;.data[]&lt;/code&gt;, or any valid JQ filter).&lt;/li&gt;&#xA;&lt;li&gt;Run the query to transform and visualize your JSON response.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: none;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;https://a-us.storyblok.com/f/1022730/1999x1271/eb3eeaf6fd/infinity-jq-parser.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;https://a-us.storyblok.com/f/1022730/1999x1271/eb3eeaf6fd/infinity-jq-parser.png&#34;alt=&#34;A screenshot of a query setup for the Infinity data source, displaying JSON data parsing and error message about non-portable GNU extension.&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;https://a-us.storyblok.com/f/1022730/1999x1271/eb3eeaf6fd/infinity-jq-parser.png&#34;&#xA;alt=&#34;A screenshot of a query setup for the Infinity data source, displaying JSON data parsing and error message about non-portable GNU extension.&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt; The JQ backend parser also supports computed fields, filtering, and summarization. For examples and syntax help, check out the &lt;a href=&#34;/docs/plugins/yesoreyeram-infinity-datasource/latest/query/jq-backend/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;JQ parser documentation&lt;/a&gt;. And If you want to try it out, check out &lt;a href=&#34;https://play.grafana.org/explore?schemaVersion=1&amp;amp;panes=%7B%226qu%22%3A%7B%22datasource%22%3A%22infinity%22%2C%22queries%22%3A%5B%7B%22refId%22%3A%22A%22%2C%22datasource%22%3A%7B%22type%22%3A%22yesoreyeram-infinity-datasource%22%2C%22uid%22%3A%22infinity%22%7D%2C%22type%22%3A%22json%22%2C%22source%22%3A%22url%22%2C%22format%22%3A%22table%22%2C%22url%22%3A%22https%3A%2F%2Frestcountries.com%2Fv3.1%2Fall%3Ffields%3Dname%2Cpopulation%2Cregion%2Csubregion%2Clanguages%2Carea%2Cstatus%2Ccar%2Clatlng%2Cborders%22%2C%22url_options%22%3A%7B%22method%22%3A%22GET%22%2C%22data%22%3A%22%22%7D%2C%22root_selector%22%3A%22.%5B%5D&amp;#43;%7C&amp;#43;&amp;#43;%7B&amp;#43;name&amp;#43;%3A&amp;#43;.name&amp;#43;.common&amp;#43;%7D%22%2C%22columns%22%3A%5B%5D%2C%22filters%22%3A%5B%5D%2C%22global_query_id%22%3A%22%22%2C%22parser%22%3A%22jq-backend%22%7D%5D%2C%22range%22%3A%7B%22from%22%3A%22now-1h%22%2C%22to%22%3A%22now%22%7D%7D%7D&amp;amp;orgId=1&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Grafana Play&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;Note: With the addition of the JQ parser, the existing backend parser has been renamed to JSONata to better reflect its underlying syntax and capabilities.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;increased-flexibility-when-working-with-different-apis&#34;&gt;Increased flexibility when working with different APIs&lt;/h2&gt;&#xA;&lt;p&gt;The latest version of the Infinity data source delivers a number of new features that provide greater flexibility and control when interacting with APIs. &lt;/p&gt;&#xA;&lt;h3 id=&#34;customizing-oauth2-tokens&#34;&gt;Customizing OAuth2 tokens&lt;/h3&gt;&#xA;&lt;p&gt;Infinity now supports customization for &lt;a href=&#34;https://oauth.net/2/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;OAuth2.0&lt;/a&gt; client credentials/&lt;a href=&#34;https://www.jwt.io/introduction&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;JWT&lt;/a&gt; authentication. This is especially useful when interacting with APIs that expect non-standard token headers or formats.&lt;/p&gt;&#xA;&lt;p&gt;You can now:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Use custom header names such as &lt;code&gt;X-API-Key&lt;/code&gt; instead of the default &lt;code&gt;Authorization&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;Customize token value format (e.g., &lt;code&gt;Token ${__oauth2.access_token}&lt;/code&gt; instead of &lt;code&gt;Bearer ${__oauth2.access_token}&lt;/code&gt;)&lt;/li&gt;&#xA;&lt;li&gt;Leverage multiple token properties like access token, refresh token, and token type&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;These settings are available in the data source configuration under &lt;code&gt;authHeader&lt;/code&gt; and &lt;code&gt;tokenTemplate&lt;/code&gt;. They give you more control over how tokens are passed in requests and allow you to integrate with APIs that don’t follow standard OAuth2 conventions. For detailed setup instructions and examples, see the &lt;a href=&#34;/docs/plugins/yesoreyeram-infinity-datasource/latest/setup/oauth2-token-customization/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;OAuth2 custom tokens documentation&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h3 id=&#34;passing-metadata-to-apis-via-headers-or-query-parameters&#34;&gt;Passing metadata to APIs via headers or query parameters&lt;/h3&gt;&#xA;&lt;p&gt;The Infinity data source plugin now allows passing Grafana metadata, such as the user ID and data source UID, to underlying APIs as headers or query parameters. This feature gives admins more control over how metadata is passed to external APIs, ensuring consistency and security.&lt;/p&gt;&#xA;&lt;p&gt;With this update, admins can configure these settings at the data source level, preventing users from overriding metadata values in individual queries. This adds flexibility, as different APIs may require metadata in different formats (headers or query parameters). It’s also important to note that metadata is handled securely at the backend and is not automatically forwarded in headers.&lt;/p&gt;&#xA;&lt;p&gt;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: none;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;https://a-us.storyblok.com/f/1022730/1999x787/d49bfda633/infinity-headers-and-parameters.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;https://a-us.storyblok.com/f/1022730/1999x787/d49bfda633/infinity-headers-and-parameters.png&#34;alt=&#34;A screenshot of a settings page for configuring the Infinity data source, showing options for HTTP headers and query parameters with &amp;#39;configured&amp;#39; status and reset buttons.&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;https://a-us.storyblok.com/f/1022730/1999x787/d49bfda633/infinity-headers-and-parameters.png&#34;&#xA;alt=&#34;A screenshot of a settings page for configuring the Infinity data source, showing options for HTTP headers and query parameters with &amp;#39;configured&amp;#39; status and reset buttons.&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt; For more information and examples, check out our &lt;a href=&#34;/docs/plugins/yesoreyeram-infinity-datasource/latest/references/url/?pg=blog&amp;amp;plcmt=body-txt/#forwarding-grafana-meta-data-as-headers--query-params&#34;&gt;documentation&lt;/a&gt;. &lt;/p&gt;&#xA;&lt;h3 id=&#34;proxy-username-and-password-for-individual-data-source-instances&#34;&gt;Proxy username and password for individual data source instances&lt;/h3&gt;&#xA;&lt;p&gt;The Infinity data source always sends API requests from Grafana server to the underlying downstream server. In some cases, these requests need to be routed through a proxy server. To support this and help with authentication needs, we’ve added an option to configure proxy settings directly in the data source configuration. When using a custom proxy for an individual data source instance, you can now also provide a username and password for the proxy authentication. You’ll find this option in the &lt;a href=&#34;/docs/plugins/yesoreyeram-infinity-datasource/latest/setup/configuration/network/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Network&lt;/a&gt; section of the data source settings.&lt;/p&gt;&#xA;&lt;h3 id=&#34;support-for-patch-put-and-delete-http-methods&#34;&gt;Support for PATCH, PUT, and DELETE HTTP methods&lt;/h3&gt;&#xA;&lt;p&gt;Infinity now supports additional HTTP methods—PATCH, PUT, and DELETE—via the &lt;code&gt;allowDangerousHTTPMethods&lt;/code&gt; configuration. Previously, only GET and POST methods were supported, which were sufficient for read-only queries. However, some use cases require modifying data, such as updating, creating, or deleting records.&lt;/p&gt;&#xA;&lt;p&gt;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: none;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;https://a-us.storyblok.com/f/1022730/1999x777/bf5454f212/infinity-http-methods.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;https://a-us.storyblok.com/f/1022730/1999x777/bf5454f212/infinity-http-methods.png&#34;alt=&#34;A screenshot of a dropdown menu with HTTP methods: GET, POST, PUT, PATCH, DELETE.&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;https://a-us.storyblok.com/f/1022730/1999x777/bf5454f212/infinity-http-methods.png&#34;&#xA;alt=&#34;A screenshot of a dropdown menu with HTTP methods: GET, POST, PUT, PATCH, DELETE.&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&lt;br /&gt;&#xA;These new methods provide greater flexibility when interacting with APIs that require these actions. Since these methods can perform potentially destructive actions, they are disabled by default. To enable them, simply toggle the &lt;code&gt;allowDangerousHTTPMethods&lt;/code&gt; setting in your data source configuration.&lt;/p&gt;&#xA;&lt;p&gt;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: none;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;https://a-us.storyblok.com/f/1022730/1730x1156/83287fa85d/infinity-allow-dangerous-methods.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;https://a-us.storyblok.com/f/1022730/1730x1156/83287fa85d/infinity-allow-dangerous-methods.png&#34;alt=&#34;A screenshot of the toggle button for allowing dangerous HTTP methods.&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;https://a-us.storyblok.com/f/1022730/1730x1156/83287fa85d/infinity-allow-dangerous-methods.png&#34;&#xA;alt=&#34;A screenshot of the toggle button for allowing dangerous HTTP methods.&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt; Once enabled, these methods will appear in the query editor UI. These methods support request bodies similar to POST.&lt;/p&gt;&#xA;&lt;h2 id=&#34;enhanced-dashboard-performance-with-gzip-compression&#34;&gt;Enhanced dashboard performance with gzip compression &lt;/h2&gt;&#xA;&lt;p&gt;The Infinity data source now automatically supports &lt;a href=&#34;https://en.wikipedia.org/wiki/Gzip&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;gzip&lt;/a&gt; compression for outgoing requests. This reduces payload size and improves data transfer efficiency, which is particularly beneficial for users working with large datasets or real-time dashboards.&lt;/p&gt;&#xA;&lt;p&gt;With this new update, the &lt;code&gt;Accept-Encoding: gzip&lt;/code&gt; header is included by default. This improves dashboard performance and reduces network strain, making it easier to work with large amounts of data.&lt;/p&gt;&#xA;&lt;h2 id=&#34;improved-compatibility-with-grafana-backend-features&#34;&gt;Improved compatibility with Grafana backend features&lt;/h2&gt;&#xA;&lt;p&gt;Infinity now defaults to the backend parser when creating new queries in dashboards or Explore. Previously, the frontend parser was the default, which limited access to backend features like &lt;a href=&#34;/docs/grafana/latest/alerting/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;alerts&lt;/a&gt;, &lt;a href=&#34;/docs/grafana/latest/panels-visualizations/query-transform-data/sql-expressions/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;SQL expressions&lt;/a&gt;, and &lt;a href=&#34;/docs/grafana/latest/dashboards/share-dashboards-panels/shared-dashboards/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;shared dashboards&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;With this update, new queries will automatically be set to use the backend parser, improving compatibility with Grafana’s backend features from the start. Existing queries using the frontend parser will continue to work as before, and users can manually switch the parser if needed.&lt;/p&gt;&#xA;&lt;h2 id=&#34;try-these-new-features-today&#34;&gt;Try these new features today&lt;/h2&gt;&#xA;&lt;p&gt;These new updates to the Infinity data source significantly enhance its flexibility, performance, and compatibility with Grafana’s backend features. &lt;/p&gt;&#xA;&lt;p&gt;To start using these new features, please make sure to &lt;a href=&#34;/docs/grafana/latest/administration/plugin-management/?pg=blog&amp;amp;plcmt=body-txt/#update-a-plugin&#34;&gt;update the Infinity data source&lt;/a&gt;. You can also learn more about the data source in our &lt;a href=&#34;/docs/plugins/yesoreyeram-infinity-datasource/latest/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;technical docs&lt;/a&gt;, &lt;a href=&#34;/grafana/plugins/yesoreyeram-infinity-datasource/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;plugin catalog&lt;/a&gt; and &lt;a href=&#34;https://github.com/grafana/grafana-infinity-datasource/releases/?pg=blog&amp;amp;plcmt=body-txt&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;release notes&lt;/a&gt;.&lt;/p&gt;】&lt;p&gt;自2020年推出以来，&lt;a href =“/doc/plugins/yesoreyeryeram-infinity-datasource/最终/？ &lt;/p&gt;&#xA;&lt;p&gt;允许用户通过基于HTTP的API集成了不同的数据格式，Infinity Data Source多年来启用了我们社区中广泛的用例 - 从可视化云计算成本到流行的Pokémon游戏。&lt;/p&gt; &lt;/p&gt;&#xA;&lt;p&gt;最近，我们进行了多次更新，以提高此通用数据源的功能，性能和易用性。请继续阅读以了解有关Grafana的Infinity数据源中最新功能的更多信息，并查看下面的视频以获取一般概述。 &lt;/p&gt;&#xA;&lt;div&#xA;class =“ youtube-lazyload响应式video”&#xA;data-embed =“ OR5PJR7JB8G”&#xA;data-url =“ https://www.youtube.com/embed/or5pjr7jb8g？autoplay = 1”&#xA;数据标题=“ YouTube视频”&#xA;&gt;&#xA;&lt;div class =“ play-button”&gt; &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt; &lt;em&gt;注意：2025年8月，服务器端请求伪造（SSRF）脆弱性（&lt;strong&gt; &lt;a href =“/security/security/security/security-advisories/cve-2025-8341/？pg = blog＆plcmt = bogl＆plcmt = body-txt = body-txt“&gt; cve-2025-8341 &lt;/forth empers of infor nife of emerd &lt;/strong&gt;） &lt;em&gt;此漏洞是在Grafana Cloud用户的3.4.1。&lt;/em&gt; &lt;em&gt;中修复的，我们已自动将数据源的旧版本更新为修补版本。对于所有本地用户，我们强烈建议您升级到&lt;/em&gt; &lt;a href =“ https://github.com/grafana/grafana/grafana/grafana-infinity-datasource/releases/” target =“ _ black” rel =“ rel =” noopener noreferrer nooreNoreferrer&#39;noopener noreferrer“ noopener noreferrer”&gt;最新版本&lt;/em em em&gt;&#xA;&lt;h2 id =“强大的json-transformation-support for-jq-backend-parser”&gt;强大的JSON变换：支持JQ Backend Parser &lt;/h2&gt;&#xA;&lt;p&gt;社区最要求的功能之一终于在这里：​​支持JQ解析！ 🎉&lt;/p&gt;&#xA;&lt;p&gt;到目前为止，Infinity数据源中唯一可用的后端解析器是&lt;a href =“ https://jsonata.org/” target =“ _ blank” rel =“ noopener noreferrer”&gt; jsonata &lt;/a&gt;。虽然强大，但其语法对许多用户不熟悉。 &lt;a href =“ https://jqlang.org/” target =“ _ blank” rel =“ noopener noreferrer”&gt; jq &lt;/a&gt;，另一方面，已广为人知，有据可查，并且已经对许多开发人员熟悉。这使其成为高级JSON转换的更平易近人的选择。&lt;/p&gt;&#xA;&lt;p&gt;使用它：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;在查询编辑器中，将&lt;strong&gt; Parser &lt;/strong&gt;选项设置为jq。&lt;/li&gt;&#xA;&lt;li&gt;在&lt;strong&gt; root选择器&lt;/strong&gt;中，写下您的&lt;strong&gt; jq expression &lt;/strong&gt;（例如&lt;code&gt;。&#xA;&lt;li&gt;运行查询以转换和可视化您的JSON响应。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt; &lt;图&#xA;class =“ figup-wrapper figuper-wrapper__lightbox W-100P”&#xA;样式=“最大宽度：无;”&#xA;itemprop =“ iSsectedmedia”&#xA;itemScope =“”&#xA;itemType =“ http://schema.org/imageObject”&#xA;&gt; &lt;a&#xA;class =“ Lightbox-link”&#xA;href =“ https：//a-us.storyblok.com/f/1022730/1999x1271/eb3eeaf6fd/infinity-jq-parser.png“&#xA;itemprop =“ contenturl”&#xA;&gt; &lt;div class =“ img-wrapper W-100P H-auto”&gt; &lt;img&#xA;class =“ Lazyload”&#xA;data-src =“ https://a-us.storyblok.com/f/1022730/19999x1271/eb3eeaf6fd/infinity-jq-parser.png” alt =“ Alt =” Alt =“ a a alt =” conenshot a screenShot a screenshot a cool setup of Infinity Data source in Infinity Data source，显示json数据源，显示不可能的数据，并显示不可能的信息gn。&#xA;&lt;NoScript&gt;&#xA;&lt;img&#xA;src =“ https://a-us.storyblok.com/f/1022730/1999x1271/eb3eeaf6fd/infinity-jq-parser.png”&#xA;alt =“无限数据源的查询设置的屏幕截图，显示JSON数据解析和有关不可存储GNU扩展的错误消息。”/&gt;&#xA;&lt;/noscript&gt; &lt;/div&gt; &lt;/a&gt; &lt;/figue&gt; JQ后端解析器还支持计算的字段，过滤和摘要。有关示例和语法帮助，请查看&lt;a href =“/doc/plugins/yes oryeryeram-infinity-datasource/lestest/query/query/jq-backend/？pg = blog＆plcmt = body-txt = body-txt”&gt; jq parser document &lt;/a&gt;。如果您想尝试一下，请查看&lt;a href =“ https://play.grafana.org/explore?schemaversion=1&amp;panes=%7B%226QU%22%3A%7B%22datasource%22%3A%2222222Infinity ％22％2C％22 Queries％22％3A％5B％7B％22 Refid％22％3A％22A％22％2C％2C％22Datasource％22％22％3A％7B％22 type％22％22％3A％22yesoreyeram-Infinit y-datasource％22％2C％22UID％22％3A％22 infinity％22％7d％2C％22 type％22％22％3A％22JSON％22％2C％2C％22source％22％22％3A％22url％22url％22％22％2C％2C％22 for MAT％22％3A％22Table％22％2C％22url％22％3A％22HTTPS％3A％2F％2FESTCOUNTRIES.com％2FV3.1％2FALL％3DFIELDS％3DNAME％2cpopulati在％2Cleion％2CSUBRIGION％2CLANGUAGES％2CAREA％2CSTATUS％2CCAR％2CLATLNG％2CBorders％2CBorders％2C％2C％2C％22url_options％22％22％3A％7B％22m ETHOD％22％3A％22Get％22％2C％22DATA％22％3A％22％22％2C％2C％22ROOT_SELECTOR％22％3A％22.％5B％5D+％7C+％7B+％7b+％+％3A+％3A+.name+.name+.com MON+％7D％22％2C％22 Columns％22％3A％5B％5D％2C％22滤光片％22％22％3A％5D％5D％2C％22 Global_query_id％22％22％3A％22％22％22％22％22％2C％22Parser％22Parser％22Parser％22％22％22％ 3A％22JQ-BAKEND％22％7D％5D％2C％22 range％22 range％22％3A％7b％22 FROM％22％3A％22NOW-1H％22％2C％2C％22％22％22％22％3A％22 now％22％22％22％7D％7D％7d％7D＆ORGID＆ORGID＆ORGID＆ORGID＆ORGID＆ORGID = 1” target =“ _空白” rel =“ noopener noreferrer”&gt; grafana play &lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt; &lt;em&gt;注意：随着JQ解析器的添加，现有的后端解析器已重命名为JSONATA，以更好地反映其基本语法和功能。&lt;/em&gt; &lt;/p&gt;&#xA;&lt;h2 id =“与不同的差异差异时的工作时提高了效率 - 使用不同的API &lt;/h2&gt;时提高了灵活性&#xA;&lt;p&gt;无限数据源的最新版本提供了许多新功能，可在与API交互时提供更大的灵活性和控制。 &lt;/p&gt;&#xA;在&#xA;&lt;p&gt; Infinity现在支持&lt;a href =“ https://oauth.net/2/”的自定义化noreferrer“&gt; jwt &lt;/a&gt;身份验证。当与期望非标准令牌标头或格式的API相互作用时，这特别有用。&lt;/p&gt;&#xA;&lt;p&gt;您现在可以：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;使用自定义标题名称，例如&lt;code&gt; x-api-key &lt;/code&gt;而不是默认&lt;code&gt;授权&lt;/code&gt; &lt;/li&gt;&#xA;&lt;li&gt;自定义ize令牌值格式（例如&lt;code&gt;令牌$ {__ oauth2.access_token} &lt;/code&gt;而不是&lt;code&gt; bearer $ {__ oauth2.access_token} &lt;/code&gt;）&lt;/code&gt;）&lt;/li&gt;&#xA;&lt;li&gt;利用多个令牌属性，例如访问令牌，刷新令牌和令牌类型&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;这些设置可在&lt;code&gt; authheader &lt;/code&gt;和&lt;code&gt; tokentemplate &lt;/code&gt;下的数据源配置中可用。它们可以使您更多地控制令牌如何通过请求传递的方式，并允许您与不遵循标准OAUTH2约定的API集成。有关详细的设置说明和示例，请参见&lt;a href =“/docs/plugins/yes oryeryeram-infinity-datasource/festment/setup/oauth2-token-customization/？pg = blog＆plcmt = bogl＆plcmt = body-txt = oauth2”&#xA;&lt;h3 id =“通过 - 米达塔（Metadata-to-apis-apis-via-via-headers-or-query-parameters”&gt;通过标头或查询参数将元数据传递到API &lt;/h3&gt;&#xA;&lt;p&gt; Infinity Data Source插件现在允许将Grafana元数据（例如用户ID和数据源UID）传递给基础API作为标题或查询参数。此功能使管理员更多地控制了元数据如何传递给外部API，从而确保了一致性和安全性。&lt;/p&gt;&#xA;&lt;p&gt;通过此更新，管理员可以在数据源级别配置这些设置，从而阻止用户在各个查询中覆盖元数据值。这增加了灵活性，因为不同的API可能需要不同格式（标题或查询参数）的元数据。同样重要的是要注意，元数据是在后端安全处理的，并且不会在标题中自动转发。&lt;/p&gt;&#xA;&lt;p&gt; &lt;图&#xA;class =“ figup-wrapper figuper-wrapper__lightbox W-100P”&#xA;样式=“最大宽度：无;”&#xA;itemprop =“ iSsectedmedia”&#xA;itemScope =“”&#xA;itemType =“ http://schema.org/imageObject”&#xA;&gt; &lt;a&#xA;class =“ Lightbox-link”&#xA;href =“ https://a-us.storyblok.com/f/1022730/19999x787/d49bfda6333/infinity-headers-headers-and-parameters.png”&#xA;itemprop =“ contenturl”&#xA;&gt; &lt;div class =“ img-wrapper W-100P H-auto”&gt; &lt;img&#xA;class =“ Lazyload”&#xA;data-src =“ https://a-us.storyblok.com/f/1022730/19999x787/d49bfda633/infinity-headers-headers-and-parameters.png” alt =“ Alt =”设置的屏幕截图，用于配置Infinity Data source和RESET参数，以配置Infinity Data soption and for Http and&#39;按钮。”/&gt;&#xA;&lt;NoScript&gt;&#xA;&lt;img&#xA;src =“ https://a-us.storyblok.com/f/1022730/1999x787/d49bfda6333/infinity-headers-headers-and-parameters.png”&#xA;Alt =“用于配置Infinity数据源的设置页面的屏幕截图，显示HTTP标头的选项以及具有&#39;配置&#39;&#39;状态和重置按钮的查询参数。”/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt; For more information and examples, check out our &lt;a href=&#34;/docs/plugins/yesoreyeram-infinity-datasource/latest/references/url/?pg=blog&amp;plcmt=body-txt/#forwarding-grafana-meta-data-as-headers--query-params&#34;&gt;documentation&lt;/a&gt;. &lt;/p&gt;&#xA;&lt;h3 id =“ perxy-username and-password-for-individual-data-source-instances”&gt;“单个数据源实例”的代理用户名和密码&lt;/h3&gt;&#xA;&lt;p&gt;无限数据源总是从GR发送API请求Afana服务器到下游服务器。在某些情况下，这些请求需要通过代理服务器进行路由。为了支持这一点并帮助您满足身份验证需求，我们添加了一个选项，可以直接在数据源配置中配置代理设置。在为单个数据源实例使用自定义代理时，您现在还可以为代理身份验证提供用户名和密码。您将在&lt;a href =“/docs/plugins/yesoreyeram-infinity-datasource/最终/setup/configuration/network/？pg = blog＆plcmt = body-txt = network &lt;/a&gt;数据源设置部分。&lt;/p&gt;&#xA;&lt;h3 id =“支持patch-putch-put-delete-http-methods”&gt;支持补丁，put和删除http方法&lt;/h3&gt;&#xA;&lt;p&gt; Infinity现在支持其他HTTP方法（patch，put和delete -via）&lt;code&gt; allowdangerdangerehttpmethods &lt;/code&gt;配置。以前，仅支持Get和Post方法，这足以用于仅阅读查询。但是，某些用例需要修改数据，例如更新，创建或删除记录。&lt;/p&gt;&#xA;&lt;p&gt; &lt;图&#xA;class =“ figup-wrapper figuper-wrapper__lightbox W-100P”&#xA;样式=“最大宽度：无;”&#xA;itemprop =“ iSsectedmedia”&#xA;itemScope =“”&#xA;itemType =“ http://schema.org/imageObject”&#xA;&gt; &lt;a&#xA;class =“ Lightbox-link”&#xA;href =“ https://a-us.storyblok.com/f/1022730/19999x7777/bf5454f2121212121212/infinity-http-methods.png”&#xA;itemprop =“ contenturl”&#xA;&gt; &lt;div class =“ img-wrapper W-100P H-auto”&gt; &lt;img&#xA;class =“ Lazyload”&#xA;data-src =“ https://a-us.storyblok.com/f/1022730/19999x7777/bf5454f212/infinity-http-methods.png” alt =“ Alt =” aLT =“用HTTP方法的下拉菜单的筛选：&#xA;&lt;NoScript&gt;&#xA;&lt;img&#xA;src =“ https://a-us.storyblok.com/f/1022730/1999x7777/bf5454f21212/infinity-http-methods.png”&#xA;alt =“带有HTTP方法的下拉菜单的屏幕截图：获取，发布，put，补丁，删除。”/&gt;&#xA;&lt;/noscript&gt; &lt;/div&gt; &lt;/a&gt; &lt;/fige&gt; &lt;br/&gt;&#xA;这些新方法在与需要这些动作的API交互时提供了更大的灵活性。由于这些方法可以执行潜在的破坏性动作，因此默认情况下是禁用的。要启用它们，只需在数据源配置中切换&lt;code&gt; allowdangerdangerdangerhttpmethods &lt;/code&gt;设置。&lt;/p&gt;&#xA;&lt;p&gt; &lt;图&#xA;class =“ figup-wrapper figuper-wrapper__lightbox W-100P”&#xA;样式=“最大宽度：无;”&#xA;itemprop =“ iSsectedmedia”&#xA;itemScope =“”&#xA;itemType =“ http://schema.org/imageObject”&#xA;&gt; &lt;a&#xA;class =“ Lightbox-link”&#xA;href =“ https://a-us.storyblok.com/f/1022730/1730x1156/83287fa85d/infinity-anfinity-allafity-allawal-allawal-dallosel-danger-dangeric-methods.png”&#xA;itemprop =“ contenturl”&#xA;&gt; &lt;div class =“ img-wrapper W-100P H-auto”&gt; &lt;img&#xA;class =“ Lazyload”&#xA;data-src =“ https://a-us.storyblok.com/f/1022730/1730x1156/83287fa85d/infinity-allfinity-allafity-allowal-dallo-danger-danger-danger-danger-methods.png” alt =“ alt =“ toggle buttom of toggle buttom of toggle stuct&#xA;&lt;NoScript&gt;&#xA;&lt;img&#xA;src =“ https://a-us.storyblok.com/f/1022730/1730x1156/83287fa85d/infinity-anfinity-allafity-allawal-allawal-dalloal-danger-dangercor-dangeric-methods.png”&#xA;alt =“用于允许危险http方法的切换按钮的屏幕截图。”/&gt;&#xA;&lt;/noscript&gt; &lt;/div&gt; &lt;/a&gt; &lt;/fige&gt;启用后，这些方法将出现在查询编辑ui中。这些方法支持类似于发布的请求机构。&lt;/p&gt;&#xA;&lt;h2 id =“增强仪表板 - 绩效 -  with-gzip-compression”&gt;带有GZIP压缩的增强仪表板性能&lt;/h2&gt;&#xA;&lt;p&gt; Infinity数据源现在自动支持&lt;a href =“ https://en.wikipedia.org/wiki/gzip/gzip” target =“ _ black” rel =“ noopener noreferrer”&gt; gzip &lt;/a&gt;用于即将进行的请求的压缩。这降低了有效载荷的大小并提高数据传输效率，这对于使用大型数据集或实时仪表板的用户特别有益。&lt;/p&gt;&#xA;&lt;p&gt;使用此新更新，&lt;code&gt;接受编码：gzip &lt;/code&gt;标题默认包含。这可以改善仪表板性能并减少网络应变，从而更容易使用大量数据。&lt;/p&gt;&#xA;&lt;H2 ID =“改善兼容性与Grafana-Backend-Features”&gt;改进了与Grafana后端功能的兼容性&lt;/h2&gt;&#xA;&lt;p&gt;无穷大现在在在仪表板上创建新的查询或探索时默认为后端解析器。以前，前端解析器是默认值，默认值有限访问后端功能，例如&lt;a href =“/docs/grafana/最新/altert/altering/？pg = blog＆plcmt = body-txt”&gt;警报&lt;/a&gt;，&lt;a&gt; &lt;a href =“/docs/grafana/最终/面板-Visualizations/query-transform-data/sql-expressions/？pg = blog＆plcmt = body-txt = sql表达href =“/docs/grafana/最终/dashboards/share-dashboards-panels/shared-dashboards/？pg = blog＆plcmt = body-txt”&gt;共享仪表板&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;通过此更新，将自动设置新的查询以使用后端解析器，从一开始就提高了与Grafana的后端功能的兼容性。使用前端解析器的现有查询将继续像以前一样继续工作，用户可以在需要时手动切换解析器。&lt;/p&gt;&#xA;&lt;H2 ID =“ Try-try-thew-features-today”&gt;今天尝试这些新功能&lt;/h2&gt;&#xA;&lt;p&gt;这些新的无限数据源的新更新显着增强了其灵活性，性能和与Grafana的后端功能的兼容性。 &lt;/p&gt;&#xA;&lt;p&gt;要开始使用这些新功能，请确保&lt;a href =“/docs/grafana/最终/prinission/plugin-managements/？pg = blog＆plcmt = body-txt/＃update-a-a-plugin”&gt;更新Infinity Data Source &lt;/a&gt;。您还可以在我们的&lt;a a href =“/doc/plugins/yes oreyeryeram-infinity-datasource/最终/？目录&lt;/a&gt;和&lt;a href =“ https://github.com/grafana/grafana/grafana-infinity-datasource/releases/?pg=blog&amp;plog&amp;plcmt=body-txt =” target =“ _ _ _ black”</description>
      <pubDate>Thu, 04 Sep 2025 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【AWS metric ingestion for less: Save money and get near real-time stream into Grafana Cloud】AWS度量摄入少量摄入：省钱并接近实时流入Grafana Cloud</title>
      <link>https://grafana.com/blog/2025/09/03/aws-metric-ingestion-for-less-save-money-and-get-near-real-time-stream-into-grafana-cloud/</link>
      <description>【&lt;p&gt;There&amp;rsquo;s a new way to ingest AWS metrics into Grafana Cloud that makes observing your AWS resources more cost-effective, easier to operate, and more accurate.&lt;/p&gt;&#xA;&lt;p&gt;You can now stream metrics into the &lt;a href=&#34;/solutions/cloud-monitoring-aws/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;AWS Observability app&lt;/a&gt; in Grafana Cloud in near real-time thanks to &lt;a href=&#34;/docs/grafana-cloud/monitor-infrastructure/monitor-cloud-provider/aws/cloudwatch-metrics/config-cw-metric-streams/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;our new integration&lt;/a&gt; with Amazon CloudWatch and Amazon Data Firehose. We&amp;rsquo;re already using it internally, and we&amp;rsquo;re finding that it&amp;rsquo;s not only easier to operate—it&amp;rsquo;s at least five times more cost-effective. &lt;/p&gt;&#xA;&lt;p&gt;In this blog post, we&amp;rsquo;ll explain how this new integration works and how you can start putting it to use today.&lt;/p&gt;&#xA;&lt;h2 id=&#34;pushnot-pullfor-peace-of-mind&#34;&gt;Push—not pull—for peace of mind&lt;/h2&gt;&#xA;&lt;p&gt;Our solution is based on &lt;a href=&#34;https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch-Metric-Streams.html&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;CloudWatch Metric Streams&lt;/a&gt;, which pipes metrics through a Data Firehose delivery stream to our custom HTTP endpoint. For most use cases, this is an upgrade from our other collection method in the AWS Observability app, which pulls metrics from AWS intervals.&lt;/p&gt;&#xA;&lt;p&gt;The advantage of this design is that it only requires resource definitions in AWS and credentials from Grafana Cloud. And since everything is managed infrastructure, the operational burden is minimal compared to running your own &lt;a href=&#34;/docs/alloy/latest/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Alloy&lt;/a&gt; instance.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: none;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;https://a-us.storyblok.com/f/1022730/1999x797/71e2b7dae5/metric-streaming-workflow.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;https://a-us.storyblok.com/f/1022730/1999x797/71e2b7dae5/metric-streaming-workflow.png&#34;alt=&#34;Workflow showing show metrics are streamed from AWS to Grafana Cloud&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;https://a-us.storyblok.com/f/1022730/1999x797/71e2b7dae5/metric-streaming-workflow.png&#34;&#xA;alt=&#34;Workflow showing show metrics are streamed from AWS to Grafana Cloud&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;The diagram above illustrates how the process works:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;AWS CloudWatch streams metrics to Data Firehose&lt;/li&gt;&#xA;&lt;li&gt;Metric events are backed up on S3 in case of a write failure.&lt;/li&gt;&#xA;&lt;li&gt;Metrics are forwarded to Grafana Cloud’s Data Firehose receiver endpoint and translated for Grafana Cloud Metrics.&lt;/li&gt;&#xA;&lt;li&gt;Users can then query and alert on AWS metrics.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;at-least-5-times-more-cost-effective&#34;&gt;At least 5 times more cost-effective&lt;/h3&gt;&#xA;&lt;p&gt;For the past two months we’ve been using CloudWatch Metric Streams internally to observe our own AWS resources, and we&amp;rsquo;ve found it to be at least five times as cost-effective as the old scrape jobs. This is due to Amazon Data Firehose operations costing less than Amazon CloudWatch API calls.&lt;/p&gt;&#xA;&lt;p&gt;We are using the same Terraform scripts as described in our &lt;a href=&#34;/docs/grafana-cloud/monitor-infrastructure/monitor-cloud-provider/aws/cloudwatch-metrics/config-cw-metric-streams/?pg=blog&amp;amp;plcmt=body-txt#configure-metric-streams-with-terraform&#34;&gt;configuration guide&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;The scripts:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Create an access policy and authentication token in Grafana Cloud&lt;/li&gt;&#xA;&lt;li&gt;Create an Amazon CloudWatch metric stream and Data Firehose resources pointing to our new endpoint.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;The only manual step is to verify that your metrics actually arrive.&lt;/p&gt;&#xA;&lt;h2 id=&#34;metrics-in-near-real-time&#34;&gt;Metrics in near real-time&lt;/h2&gt;&#xA;&lt;p&gt;The pull-style scrape jobs query CloudWatch for new metrics every five minutes, by default. This delay can impact alerts that are fired with the same delay.  By using the new push-based approach we avoid this lag. &lt;/p&gt;&#xA;&lt;p&gt;We process metrics as they arrive and alert in time. Furthermore, the metrics are more granular due to a higher data points per minute (DPM) number.&lt;/p&gt;&#xA;&lt;h3 id=&#34;enriching-your-streamed-metrics-with-resource-metadata&#34;&gt;Enriching your streamed metrics with resource metadata&lt;/h3&gt;&#xA;&lt;p&gt;So far we’ve omitted another new component offered as part of our integration with CloudWatch Metric Streams: AWS resource metadata scrape jobs.&lt;/p&gt;&#xA;&lt;p&gt;AWS resource metadata scrape jobs are configured and run in Grafana Cloud, and they generate info metrics containing metadata as labels for your AWS resources. These labels can then be used to enrich your streamed AWS metrics at ingestion time with the associated resource’s ARN and tags.&lt;/p&gt;&#xA;&lt;p&gt;Follow our &lt;a href=&#34;/docs/grafana-cloud/monitor-infrastructure/monitor-cloud-provider/aws/cloudwatch-metrics/config-cw-metric-streams/?pg=blog&amp;amp;plcmt=body-txt#configure-an-aws-resource-metadata-scrape-job-in-terraform&#34;&gt;configuration guide&lt;/a&gt; to set up one AWS resource metadata scrape job for each AWS account you’re streaming metrics from for all the regions that you need. We recommend configuring the scrape job with the same set of AWS namespaces that you configured your metric stream to push metrics for. That way you can get the most out of your streamed metrics.&lt;/p&gt;&#xA;&lt;h3 id=&#34;migrating-and-when-to-stick-with-scape-jobs&#34;&gt;Migrating and when to stick with scape jobs&lt;/h3&gt;&#xA;&lt;p&gt;Some Amazon CloudWatch metrics have a very low DPM rate. For instance, we only see one S3 update once per day, which might be difficult to handle for some queries. In these cases we advise you to stick with the old scrape job setup. The good news is that the old pull-based and the new push-based approaches can work hand-in-hand alongside each other. One set of metrics can be pushed while the other set is still being pulled.&lt;/p&gt;&#xA;&lt;p&gt;This leads us to the migration strategy. If you are already importing metrics via CloudWatch scrape jobs, you can enable push-based metrics for selected namespace. There is no need to migrate all AWS namespaces at once. The dashboards and alerts will continue to work across your different metric sources.&lt;/p&gt;&#xA;&lt;h2 id=&#34;whats-next&#34;&gt;What’s next&lt;/h2&gt;&#xA;&lt;p&gt;With this latest update,  we’ve reached feature parity with the CloudWatch scrape jobs, but we are already planning beyond that. In the future, we plan to offer ways to configure your metrics ingest experience. One such feature will be the ability to select which tags from resource metadata get attached to the streamed metrics. Another feature will be the ability to apply Prometheus relabel rules to labels on your streamed metrics.&lt;/p&gt;&#xA;&lt;p&gt;In the meantime, check out some of the other improvements we&amp;rsquo;ve made since launching the AWS Observability app last year, including &lt;a href=&#34;/blog/2024/05/07/logs-with-firehose-cost-effective-aws-log-streaming-to-grafana-cloud/&#34;&gt;support for streaming logs&lt;/a&gt; and the ability to &lt;a href=&#34;/blog/2025/06/24/grafana-cloud-manage-the-aws-observability-app-as-code-with-terraform/&#34;&gt;manage the app as code&lt;/a&gt;. We&amp;rsquo;ve also expanded our observability solutions to &lt;a href=&#34;/blog/2025/02/11/monitor-google-cloud-simplify-and-centralize-your-cloud-provider-observability-with-grafana-cloud/&#34;&gt;Google Cloud&lt;/a&gt; and &lt;a href=&#34;/blog/2025/02/26/monitor-microsoft-azure-in-grafana-cloud-simplify-and-centralize-your-cloud-provider-observability/&#34;&gt;Microsoft Azure&lt;/a&gt;, giving you one hub to monitor all your cloud provider resources. &lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;/products/cloud/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt;&lt;/em&gt; &lt;em&gt;is the easiest way to get started with metrics, logs, traces, dashboards, and more. We have a generous forever-free tier and plans for every use case.&lt;/em&gt; &lt;em&gt;&lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Sign up for free now!&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;】&lt;p&gt;有一种新的方法来将AWS指标摄入Grafana Cloud，这使观察您的AWS资源更具成本效益，更易于操作和更准确。&lt;/p&gt;&#xA;&lt;p&gt;您现在可以将指标流式传输到&lt;a href =“/solutions/cloud-monitoring-aws/？pg = blog＆plcmt = body-txt”&gt; aws observability应用程序&lt;/a&gt;在近乎实时的Grafana Cloud中，在近乎实时的&lt;a &lt;a中， href =“/docs/grafana-cloud/Monitor-Infrasture/monitor-cloud-provider/aws/cloudwatch-metrics/config-cw-metric-streams/？pg = blog＆plcmt = body-txt = body-txt“&gt;我们的新集成&lt;/a&gt;与Amazon CloudWatch和Amazon Data Firehose一起使用。我们已经在内部使用它，并且我们发现它不仅可以更容易操作，而且具有成本效益的五倍。 &lt;/p&gt;&#xA;&lt;p&gt;在这篇博客文章中，我们将解释这种新集成如何工作以及如何开始使用它。&lt;/p&gt;&#xA;&lt;h2 id =“ pushnot-pullfor-for-ind-ind”&gt;推动 - 而不是拉动 - 为了安心&lt;/h2&gt;&#xA;&lt;p&gt;我们的解决方案基于&lt;a href =“ https://docs.aws.amazon.com/amazoncloudwatch/latest/latest/monitoring/cloudwatch-metric-streams.html” target =“ _ black”端点。对于大多数用例，这是我们在AWS可观察性应用程序中的其他收集方法的升级，该应用程序从AWS间隔中提取指标。&lt;/p&gt;&#xA;&lt;p&gt;此设计的优点是它仅需要AWS中的资源定义和Grafana Cloud的凭据。而且，由于所有内容都是管理基础架构，因此与运行自己的&lt;a href =“/docs/ylay/最终/？pg = blog＆plcmt = body-txt”&gt; grafana合金&lt;/a&gt;实例。&lt;/p&gt;&#xA;&lt;图&#xA;class =“ figup-wrapper figuper-wrapper__lightbox W-100P”&#xA;样式=“最大宽度：无;”&#xA;itemprop =“ iSsectedmedia”&#xA;itemScope =“”&#xA;itemType =“ http://schema.org/imageObject”&#xA;&gt; &lt;a&#xA;class =“ Lightbox-link”&#xA;href =“ https://a-us.storyblok.com/f/1022730/199999797/71e2b7dae5/metric-streaming-workflow.png”&#xA;itemprop =“ contenturl”&#xA;&gt; &lt;div class =“ img-wrapper W-100P H-auto”&gt; &lt;img&#xA;class =“ Lazyload”&#xA;data-src =“ https://a-us.storyblok.com/f/1022730/199999X797/71E2B7DAE5/Metric-Streaming-workflow.png” alt =” alt =”工作流程显示显示量表从AWS流到grafana cloud”/&gt; grafana cloud&#39;&gt;&gt;&#xA;&lt;NoScript&gt;&#xA;&lt;img&#xA;src =“ https://a-us.storyblok.com/f/1022730/199999797/71e2b7dae5/metric-streaming-workflow.png”&#xA;alt =“工作流显示显示指标是从AWS流到Grafana Cloud的”/&gt;&#xA;&lt;/noscript&gt; &lt;/div&gt; &lt;/a&gt; &lt;/figie&gt;&#xA;&lt;p&gt;上图说明了过程的工作方式：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt; AWS CloudWatch流到Data FireHose &lt;/li&gt;&#xA;&lt;li&gt;在写作失败的情况下，在S3上备份度量事件。&lt;/li&gt;&#xA;&lt;li&gt;指标被转发到Grafana Cloud的数据FireHose接收器端点，并为Grafana Cloud指标进行了翻译。&lt;/li&gt;&#xA;&lt;li&gt;然后，用户可以查询和警报AWS指标。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;H3 ID =“至少5倍的成本效果”&gt;至少成本效益&lt;/h3&gt;至少增加5倍&#xA;&lt;p&gt;在过去的两个月中，我们一直在使用CloudWatch公制流在内部观察我们自己的AWS资源，我们发现它的成本效益至少是旧的刮擦工作的五倍。这是由于亚马逊数据消防操作的成本低于Amazon CloudWatch API调用。&lt;/p&gt;&#xA;&lt;p&gt;我们使用的是与我们&lt;a href =“/docs/docs/grafana-cloud/Monitor-infrastructure/monitor-cloud-provider/aws/cloudwatch-metrics/config-cw-metric-treams/？pg = bobl＆plcmt = bobl＆plcmt = configure-streams-streams-preams-with/prcem &lt;/conform &lt;/configure-streams-premetration-prea &lt;/conformiric-streams-premetration-preake-preake-prifation &lt;&#xA;&lt;p&gt;脚本：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;在Grafana Cloud中创建访问策略和身份验证令牌&lt;/li&gt;&#xA;&lt;li&gt;创建一个指向我们新端点的Amazon CloudWatch公制和数据FireHose资源。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;唯一的手动步骤是验证您的指标实际上到达。&lt;/p&gt;&#xA;&lt;h2 id =“ near-seal-eal-time”&gt;近实时的指标&lt;/h2&gt;&#xA;&lt;p&gt;默认情况下，每五分钟的拉力刮擦作业查询新指标的CloudWatch。此延迟会影响以相同延迟发射的警报。  通过使用新的基于推动的方法，我们避免了此滞后。 &lt;/p&gt;&#xA;&lt;p&gt;我们在及时处理时处理指标。此外，由于每分钟较高的数据点（DPM）数字，指标更具粒度。&lt;/p&gt;&#xA;&lt;h3 id =“丰富自己的流程 - 含有资源 - 库 - 米达塔”&gt;用资源元数据丰富您的流量指标&lt;/h3&gt;&#xA;&lt;p&gt;到目前为止，我们已经省略了与CloudWatch Metric Streams集成的一部分提供的另一个新组件：AWS资源元数据scrape作业。&lt;/p&gt;&#xA;&lt;p&gt; AWS资源元数据刮擦作业是在Grafana Cloud中配置和运行的，它们生成了包含元数据作为AWS资源标签的信息指标。然后，这些标签可用于使用相关资源的ARN和标签在摄入时间丰富您的流aws指标。&lt;/p&gt;&#xA;&lt;p&gt;请按照我们的&lt;a href =“/docs/docs/grafana-cloud/Monitor-infrasture/monitor-cloud-provider/aws/cloudwatch-metrics/config-cw-metrics/？pg = pg = blog＆plcmt = bogl＆plcmt = body-txt＃configure-an-aws-aws-resource-resource-resource-resource-metadata-scrape-in​​ aw/aw/priogation aw/aw/aw/您所需的所有区域的元数据刮擦工作是您流式传输指标的每个AWS帐户。我们建议使用与您配置的度量流相同的AWS名称空间配置刮擦作业，以推动指标。这样，您可以从流式的指标中获得最大收益。&lt;/p&gt;&#xA;&lt;h3 id =“迁移到粘合 - 与scape-jobs”&gt;迁移，何时坚持使用Scape Jobs &lt;/h3&gt;&#xA;&lt;p&gt;一些Amazon CloudWatch指标的DPM速率非常低。例如，我们每天只看到一次S3更新一次，对于某些查询可能很难处理。在这些情况下，我们建议您坚持旧的刮擦工作设置。好消息是，基于拉动的旧方法和新的基于推动的方法可以彼此并肩作用。一组指标可以推动，而另一组仍在拉动。&lt;/p&gt;&#xA;&lt;p&gt;这将我们带到了迁移离子策略。如果您已经通过CloudWatch Scrape作业导入指标，则可以为选定的名称空间启用基于推动的指标。无需一次迁移所有AWS名称空间。仪表板和警报将继续跨您的不同度量来源工作。&lt;/p&gt;&#xA;&lt;H2 ID =“ Whats-Next”&gt;下一步是什么&#xA;&lt;p&gt;通过此最新更新，我们与CloudWatch Scrape作业达到了奇偶校验，但是我们已经计划了。将来，我们计划提供配置您的指标摄入体验的方法。这样的功能之一将是能够选择来自资源元数据的哪些标签已连接到流式指标上。另一个功能将是能够将Prometheus Relabel规则应用于流式指标上的标签。&lt;/p&gt;&#xA;&lt;p&gt;与此同时，查看自去年启动AWS可观察性应用程序以来我们进行的其他一些改进，包括&lt;a href =“/blog/2024/2024/05/07/logs-with-with-with-firehose-cost-cost-ags-aws-aws-aws-ags-ags-ags-log-streaming-to to-grafana-to-grafana-cloud/to-grafana-cloud/“&gt;支持流媒体logs”&gt;支持流logs和&lt;/a&gt;和&lt;/a a的能力&lt;/a&gt;和&lt;a a&gt; &lt;/a&gt; &lt;/a&gt; href =“/blog/2025/06/24/grafana-cloud-the-the-aws-observibility-app-as-as-as-code-with-terraform/”&gt;将应用程序作为代码&lt;/a&gt;管理。我们还将可观察性解决方案扩展到&lt;a href =“/blog/2025/02/11/monitor-google-cloud-cloud-simplify and-centralize your-cloud-provider-ropservider-robservibility-with-grafana-cloud/with-groafana-cloud/”&gt; href =“/blog/2025/02/26/Monitor-microsoft-in-in-grafana-cloud-simplify and-centralize-inour-cloud-provider-robservidability/“&gt; Microsoft azure &lt;/a&gt; &lt;/a&gt; &lt;/p&gt;&#xA;&lt;p&gt; &lt;em&gt; &lt;a href =“/products/cloud/？pg = blog＆plcmt = body-txt”&gt; grafana cloud &lt;/a&gt; &lt;/em&gt; &lt;em&gt;是开始使用指标，日志，痕迹，仪表，仪表板等最简单的方法。我们有一个宽敞的永远的层次和计划。&lt;/em&gt; &lt;em&gt; &lt;a href =“/auth/auth/insip/create-user/？pg = blog＆plcmt = body-txt = body-txt”&gt;现在免费注册！&lt;/a&gt; &lt;/a&gt; &lt;/em&gt; &lt;/em&gt; &lt;/p&gt; &lt;/em&gt; &lt;/p&gt;</description>
      <pubDate>Wed, 03 Sep 2025 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Actionable insights into the end-user experience: an overview of Grafana Cloud Frontend Observability dashboards】对最终用户体验的可行见解：Grafana Cloud Frontend可观察性仪表板的概述</title>
      <link>https://grafana.com/blog/2025/09/02/actionable-insights-into-the-end-user-experience-an-overview-of-grafana-cloud-frontend-observability-dashboards/</link>
      <description>【&lt;p&gt;One of the biggest challenges in frontend development is identifying when and why users encounter performance issues, whether it’s slow page loads, JavaScript errors, or failed HTTP requests.&lt;/p&gt;&#xA;&lt;p&gt;With &lt;a href=&#34;/products/cloud/frontend-observability/&#34;&gt;Grafana Cloud Frontend Observability&lt;/a&gt; — a hosted service for real user monitoring (RUM) — you get immediate, clear, and actionable insights into the end-user experience of your web applications. Frontend Observability leverages performance data collected by the &lt;a href=&#34;/oss/faro/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Faro Web SDK&lt;/a&gt;, and presents it through pre-built dashboards and analytics tools, so you can quickly gain the insights you need. &lt;/p&gt;&#xA;&lt;p&gt;In a &lt;a href=&#34;/blog/2025/07/14/how-to-analyze-core-web-vitals-in-grafana-cloud-frontend-observability/&#34;&gt;previous blog post&lt;/a&gt;, we discussed how to analyze Core Web Vitals in Frontend Observability dashboards. In this post, we’ll walk through other key sections of the pre-built Frontend Observability dashboards, including those for page loads, page performance, sessions, errors, and HTTP requests. You can also learn more and follow along visually by watching the YouTube video below.&lt;/p&gt;&#xA;&lt;div&#xA;class=&#34;youtube-lazyload responsive-video&#34;&#xA;data-embed=&#34;K7rFF-k7GSk&#34;&#xA;data-url=&#34;https://www.youtube.com/embed/K7rFF-k7GSk?autoplay=1&#34;&#xA;data-title=&#34;YouTube Video&#34;&#xA;&gt;&#xA;&lt;div class=&#34;play-button&#34;&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;h2 id=&#34;key-components-of-a-grafana-cloud-frontend-observability-dashboard&#34;&gt;Key components of a Grafana Cloud Frontend Observability dashboard&lt;/h2&gt;&#xA;&lt;p&gt;Frontend Observability dashboards allow developers to gain real-time insight into how users experience their applications. Each dashboard section works together to provide a complete picture of frontend performance. &lt;/p&gt;&#xA;&lt;h3 id=&#34;page-loads&#34;&gt;Page Loads&lt;/h3&gt;&#xA;&lt;p&gt;The &lt;strong&gt;Page Loads&lt;/strong&gt; section provides insights into the user experience by measuring how long it takes entire pages to load within your application. You&amp;rsquo;ll see the total number of page loads within your selected timeframe, along with a distribution chart that separates successful loads (blue) from error encounters (red).&lt;/p&gt;&#xA;&lt;p&gt;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: none;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;https://a-us.storyblok.com/f/1022730/1788x1004/880d746c08/page-loads-frontent-o11y-dashboards.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;https://a-us.storyblok.com/f/1022730/1788x1004/880d746c08/page-loads-frontent-o11y-dashboards.png&#34;alt=&#34;A Grafana Cloud Frontend Observability dashboard displaying metrics related to page loads and page load errors.&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;https://a-us.storyblok.com/f/1022730/1788x1004/880d746c08/page-loads-frontent-o11y-dashboards.png&#34;&#xA;alt=&#34;A Grafana Cloud Frontend Observability dashboard displaying metrics related to page loads and page load errors.&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt; You can use this information to gauge how well a page is loading and what JavaScript errors may be occurring. Page loads can also help you understand the time intervals during which your users are most and least active.&lt;/p&gt;&#xA;&lt;h3 id=&#34;page-performance&#34;&gt;Page Performance&lt;/h3&gt;&#xA;&lt;p&gt;The &lt;strong&gt;Page Performance&lt;/strong&gt; section breaks down performance by individual page IDs, which are auto-generated by the Grafana Faro Cloud receiver — a component in the Grafana Cloud architecture that accepts telemetry data from the Grafana Faro Web SDK. You also have the option to override page IDs when you instrument your app. &lt;/p&gt;&#xA;&lt;p&gt;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: none;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;https://a-us.storyblok.com/f/1022730/1776x514/c1213203fe/page-performance-frontend-o11y-dashboards.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;https://a-us.storyblok.com/f/1022730/1776x514/c1213203fe/page-performance-frontend-o11y-dashboards.png&#34;alt=&#34;A Grafana Cloud Frontend Observability dashboard showing page performance metrics for various pages, including TTFB, FCP, LCP, CLS, FID, INP, and Errors.&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;https://a-us.storyblok.com/f/1022730/1776x514/c1213203fe/page-performance-frontend-o11y-dashboards.png&#34;&#xA;alt=&#34;A Grafana Cloud Frontend Observability dashboard showing page performance metrics for various pages, including TTFB, FCP, LCP, CLS, FID, INP, and Errors.&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt; Each page displays its own Core Web Vitals and error metrics using an intuitive color system: red indicates poor performance, yellow suggests areas needing improvement, and green represents good performance.&lt;/p&gt;&#xA;&lt;p&gt;Clicking into specific pages reveals detailed information, including associated session IDs and comprehensive logs. This granular approach helps you prioritize optimization efforts by identifying which pages most urgently need attention.&lt;/p&gt;&#xA;&lt;h3 id=&#34;errors&#34;&gt;Errors&lt;/h3&gt;&#xA;&lt;p&gt;The &lt;strong&gt;Errors&lt;/strong&gt; section provides a distribution of errors over time, as well as an aggregated list of top errors, top errors by page ID, and top errors by browser. When you drill into specific errors, you&amp;rsquo;ll find stack traces, detailed error messages, and metadata that helps streamline the debugging process. &lt;/p&gt;&#xA;&lt;p&gt;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: none;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;https://a-us.storyblok.com/f/1022730/1810x994/84f721c7a7/errors-frontend-o11y-dashboards.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;https://a-us.storyblok.com/f/1022730/1810x994/84f721c7a7/errors-frontend-o11y-dashboards.png&#34;alt=&#34;A Grafana Cloud Frontend Observability dashboard showing error analytics with bar graphs, top errors list, and error count by browser.&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;https://a-us.storyblok.com/f/1022730/1810x994/84f721c7a7/errors-frontend-o11y-dashboards.png&#34;&#xA;alt=&#34;A Grafana Cloud Frontend Observability dashboard showing error analytics with bar graphs, top errors list, and error count by browser.&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt; You can also access session data directly from error details to create a direct path from the identified problem to the user impact, making root cause analysis more efficient and thorough.&lt;/p&gt;&#xA;&lt;h3 id=&#34;sessions&#34;&gt;Sessions&lt;/h3&gt;&#xA;&lt;p&gt;Every user visit to your application generates a unique session ID that tracks the complete user journey from entry to exit or timeout. The &lt;strong&gt;Sessions&lt;/strong&gt; section displays session amount over time, segmented by page ID, along with a comprehensive table showing timestamps, errors, browser information, and session lifecycle data.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: none;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;https://a-us.storyblok.com/f/1022730/1802x1084/8bc7aaca9b/sessions-frontend-o11y-dashboards.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;https://a-us.storyblok.com/f/1022730/1802x1084/8bc7aaca9b/sessions-frontend-o11y-dashboards.png&#34;alt=&#34;A Grafana Cloud Frontend Observability dashboard displaying session data with colored bars and a table below showing session details, including IDs, pages, browsers, and platforms.&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;https://a-us.storyblok.com/f/1022730/1802x1084/8bc7aaca9b/sessions-frontend-o11y-dashboards.png&#34;&#xA;alt=&#34;A Grafana Cloud Frontend Observability dashboard displaying session data with colored bars and a table below showing session details, including IDs, pages, browsers, and platforms.&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;h3 id=&#34;http-performance-insights&#34;&gt;HTTP Performance Insights&lt;/h3&gt;&#xA;&lt;p&gt;The &lt;strong&gt;HTTP&lt;/strong&gt; section — also known as &lt;a href=&#34;/blog/2025/08/27/optimize-application-performance-at-the-network-layer-introducing-http-performance-insights-in-frontend-observability/&#34;&gt;HTTP Performance Insights&lt;/a&gt; — focuses on the health and performance of your application&amp;rsquo;s HTTP requests. You&amp;rsquo;ll see total requests, error rates, error percentages, average Time to First Byte (TTFB), and other request-related metrics that impact overall application performance. This feature is currently in public preview. &lt;/p&gt;&#xA;&lt;h3 id=&#34;hahahugoshortcode1958s5hbhb&#34;&gt;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: none;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;https://a-us.storyblok.com/f/1022730/1806x1644/f3f1cd5a97/http-insights-frontend-o11y-dashboards.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;https://a-us.storyblok.com/f/1022730/1806x1644/f3f1cd5a97/http-insights-frontend-o11y-dashboards.png&#34;alt=&#34;A Grafana Cloud Frontend Observability dashboard displaying HTTP request metrics, including errors, TTFB, duration, status codes, and resource timings.&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;https://a-us.storyblok.com/f/1022730/1806x1644/f3f1cd5a97/http-insights-frontend-o11y-dashboards.png&#34;&#xA;alt=&#34;A Grafana Cloud Frontend Observability dashboard displaying HTTP request metrics, including errors, TTFB, duration, status codes, and resource timings.&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&lt;/h3&gt;&#xA;&lt;h3 id=&#34;filters-customizable-data-analysis&#34;&gt;Filters: customizable data analysis&lt;/h3&gt;&#xA;&lt;p&gt;Available across all sections of Frontend Observability dashboards, filters allow you to slice and dice your data using both custom tags created during Faro instrumentation and preconfigured options.&lt;/p&gt;&#xA;&lt;p&gt;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: none;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;https://a-us.storyblok.com/f/1022730/1999x426/b0ade85599/filters-frontend-o11y-dashboards.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;https://a-us.storyblok.com/f/1022730/1999x426/b0ade85599/filters-frontend-o11y-dashboards.png&#34;alt=&#34;A Grafana Cloud Frontend Observability dashboard with a filter applied for a production environment.&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;https://a-us.storyblok.com/f/1022730/1999x426/b0ade85599/filters-frontend-o11y-dashboards.png&#34;&#xA;alt=&#34;A Grafana Cloud Frontend Observability dashboard with a filter applied for a production environment.&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt; Whether you need to analyze specific app environments, compare different versions, or focus on particular user segments, filters provide the granularity needed for targeted analysis.&lt;/p&gt;&#xA;&lt;h2 id=&#34;learn-more&#34;&gt;Learn more&lt;/h2&gt;&#xA;&lt;p&gt;These metrics and visualizations in Frontend Observability are designed to help you monitor the health of your web applications and ensure the best possible end-user experience. To learn more, please refer to our &lt;a href=&#34;/docs/grafana-cloud/monitor-applications/frontend-observability/performance/&#34;&gt;documentation&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;And to see a live, interactive example of Grafana Cloud Frontend Observability, please check out &lt;a href=&#34;https://play.grafana.org/a/grafana-kowalski-app&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Grafana Play&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;/products/cloud/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt;&lt;/em&gt; &lt;em&gt;is the easiest way to get started with metrics, logs, traces, dashboards, and more. We have a generous forever-free tier and plans for every use case.&lt;/em&gt; &lt;em&gt;&lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Sign up for free now!&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;】&lt;p&gt;前端开发中最大的挑战之一是确定用户何时以及为什么遇到性能问题，无论是页面慢，JavaScript错误还是失败的HTTP请求。&lt;/p&gt;&#xA;&lt;p&gt;使用&lt;a href =“/products/cloud/cloud/frontend-observability/”&gt; grafana云前端可观察性&lt;/a&gt;  - 一种用于真实用户监视的托管服务（朗姆酒） - 您可以立即，清晰，可行的洞察力，可对Web应用程序的最终用户体验进行深入了解。前端可观察性利用&lt;a href =“/oss/faro/？pg = blog＆plcmt = body-txt”&gt; grafaana faro web sdk &lt;/a&gt;，并通过预建的仪表板和分析工具进行展示，因此您可以快速获得洞察力。 &lt;/p&gt;&#xA;&lt;p&gt;在&lt;a &lt;a href =“/blog/2025/07/14/how-to-to-to-to-to-to-to-core-web-vitals-in-grafana-cloud-cloud-frontend-observability/”&gt;上一个博客文章&lt;/a&gt;，我们讨论了如何分析前端可观察性仪表板中的核心网络核心范围。在这篇文章中，我们将浏览前构建的前端可观察性仪表板的其他关键部分，包括有关页面加载，页面性能，会话，错误和HTTP请求的关键部分。您还可以通过观看下面的YouTube视频来了解更多信息，并以视觉关注。&lt;/p&gt;&#xA;&lt;div&#xA;class =“ youtube-lazyload响应式video”&#xA;data-embed =“ k7rff-k7gsk”&#xA;data-url =“ https://www.youtube.com/embed/k7rff-k7gsk?autoplay=1”&#xA;数据标题=“ YouTube视频”&#xA;&gt;&#xA;&lt;div class =“ play-button”&gt; &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;h2 id =“ grafana-cloud-cloud-frontend-observability-dashboard”&gt; grafana云前端可观察性仪表板&lt;/h2&gt;的键组件&lt;/h2&gt;&#xA;&lt;p&gt;前端可观察性仪表板使开发人员可以实时了解用户如何体验其应用程序。每个仪表板部分一起工作，提供前端性能的完整图片。 &lt;/p&gt;&#xA;&lt;H3 ID =“ Page-Loads”&gt; PAGE LOADS &lt;/H3&gt;&#xA;&lt;p&gt; &lt;strong&gt;页面加载&lt;/strong&gt;部分通过测量整个页面在应用程序中加载多长时间来提供对用户体验的见解。您将看到所选时间范围内的页面加载总数，以及将成功的负载（蓝色）与错误遇到的分配图表（红色）。&lt;/p&gt;&#xA;&lt;p&gt; &lt;图&#xA;class =“ figup-wrapper figuper-wrapper__lightbox W-100P”&#xA;样式=“最大宽度：无;”&#xA;itemprop =“ iSsectedmedia”&#xA;itemScope =“”&#xA;itemType =“ http://schema.org/imageObject”&#xA;&gt; &lt;a&#xA;class =“ Lightbox-link”&#xA;href =“ https://a-us.storyblok.com/f/1022730/1788x1004/880d746c08/page-loads-loads-frontent-o11y-dashboards.png”&#xA;itemprop =“ contenturl”&#xA;&gt; &lt;div class =“ img-wrapper W-100P H-auto”&gt; &lt;img&#xA;class =“ Lazyload”&#xA;data-src=&#34;https://a-us.storyblok.com/f/1022730/1788x1004/880d746c08/page-loads-frontent-o11y-dashboards.png&#34;alt=&#34;A Grafana Cloud Frontend Observability dashboard displaying metrics related to page loads and page load errors.&#34;/&gt;&#xA;&lt;NoScript&gt;&#xA;&lt;img&#xA;src =“ https://a-us.storyblok.com/f/1022730/1788x1004/880d746c08/page-loads-loads-frontent-o11y-dashboards.png”&#xA;alt =“ grafana云前端可观察性仪表板显示与p相关的指标年龄负载和页面加载错误。”/&gt;&#xA;&lt;/noscript&gt; &lt;/div&gt; &lt;/a&gt; &lt;/figue&gt;您可以使用此信息来衡量页面加载程度以及可能发生什么JavaScript错误。页面负载还可以帮助您了解用户最不活跃的时间间隔。&lt;/p&gt;&#xA;&lt;H3 ID =“页面绩效”&gt;页面性能&lt;/h3&gt;&#xA;&lt;p&gt; &lt;strong&gt;页面性能&lt;/strong&gt;部分通过单个页面ID分解性能，该页面ID由Grafana Faro Cloud接收器自动生成，这是Grafana Cloud Architecture中的一个组件，该组件接受Grafana Faro Web SDK的遥测数据。在启动应用程序时，您还可以选择覆盖页面ID。 &lt;/p&gt;&#xA;&lt;p&gt; &lt;图&#xA;class =“ figup-wrapper figuper-wrapper__lightbox W-100P”&#xA;样式=“最大宽度：无;”&#xA;itemprop =“ iSsectedmedia”&#xA;itemScope =“”&#xA;itemType =“ http://schema.org/imageObject”&#xA;&gt; &lt;a&#xA;class =“ Lightbox-link”&#xA;href =“ https://a-us.storyblok.com/f/1022730/1776x514/c1213203fe/page-performance-frontance-frontend-o11y-dashboards.png”&#xA;itemprop =“ contenturl”&#xA;&gt; &lt;div class =“ img-wrapper W-100P H-auto”&gt; &lt;img&#xA;class =“ Lazyload”&#xA;data-src=&#34;https://a-us.storyblok.com/f/1022730/1776x514/c1213203fe/page-performance-frontend-o11y-dashboards.png&#34;alt=&#34;A Grafana Cloud Frontend Observability dashboard showing page performance metrics for various pages, including TTFB, FCP, LCP, CLS, FID, INP和错误。”/&gt;&#xA;&lt;NoScript&gt;&#xA;&lt;img&#xA;src =“ https://a-us.storyblok.com/f/1022730/1776x514/c1213203fe/page-performance-frentance-frontend-o11y-dashboards.png”&#xA;alt =“ grafana cloud前端可观察性仪表板显示各个页面的页面性能指标，包括TTFB，FCP，LCP，CLS，FID，INP和错误。”/&gt;&#xA;&lt;/noscript&gt; &lt;/div&gt; &lt;/a&gt; &lt;/figud&gt;每个页面都使用直觉颜色系统显示自己的核心网络生命力和错误指标：红色表示性能差，黄色表明需要改进的区域，绿色代表良好的性能。&lt;/p&gt; &lt;/p&gt;&#xA;&lt;p&gt;单击特定页面揭示详细信息，包括关联的会话ID和全面日志。这种颗粒状方法可以通过确定最迫切需要关注的页面来帮助您确定优化工作的优先级。&lt;/p&gt;。&lt;/p&gt;&#xA;&lt;H3 ID =“错误”&gt;错误&lt;/h3&gt;&#xA;&lt;p&gt; &lt;strong&gt;错误&lt;/strong&gt;部分提供了随着时间的流逝分布错误的分布，以及最高错误的汇总列表，按页面ID划分的最高错误以及浏览器的最高错误。当您钻入特定错误时，您会发现堆栈跟踪，详细的错误消息和元数据有助于简化调试过程。 &lt;/p&gt;&#xA;&lt;p&gt; &lt;图&#xA;class =“ figup-wrapper figuper-wrapper__lightbox W-100P”&#xA;样式=“最大宽度：无;”&#xA;itemprop =“ iSsectedmedia”&#xA;itemScope =“”&#xA;itemType =“ http://schema.org/imageObject”&#xA;&gt; &lt;a&#xA;class =“ Lightbox-link”&#xA;href =“ https://a-us.storyblok.com/f/1022730/1810x994/84f721c7a7a/errors-frontend-o11y-dashboards.png”&#xA;itemprop =“ contenturl”&#xA;&gt; &lt;div class =“ img-wrapper W-100P H-auto”&gt; &lt;img&#xA;class =“ Lazyload”&#xA;data-src =“ https://a-us.storyblok.com/f/1022730/1810x994/84f721c7a7/errors-frontend-o11y-dashboards.png” Alt =“ grafana clo”UD前端可观察性仪表板显示带有条形图，最高错误列表和错误计数的错误分析。”/&gt;&#xA;&lt;NoScript&gt;&#xA;&lt;img&#xA;src =“ https://a-us.storyblok.com/f/1022730/1810x994/84f721c7a7a/errors-frontend-o11y-dashboards.png”&#xA;alt =“ grafana cloud前端可观察性仪表板显示带有条形图的错误分析，最高错误列表和浏览器的错误计数。”/&gt;&#xA;&lt;/noscript&gt; &lt;/div&gt; &lt;/a&gt; &lt;/figue&gt;您还可以直接从错误详细信息访问会话数据，以创建从确定的问题到用户影响的直接路径，从而使根本原因分析更加有效，更彻底。&lt;/p&gt;&#xA;&lt;H3 ID =“ Sessions”&gt; Sessions &lt;/h3&gt;&#xA;&lt;p&gt;每个用户访问您的应用程序都会生成一个唯一的会话ID，该ID跟踪从进入到退出或超时的完整用户旅程。 &lt;strong&gt;会话&lt;/strong&gt;部分显示会话数量随时间时间，按页面ID进行了分割，以及一个全面的表，显示时间戳，错误，浏览器信息和会话生命周期数据。&lt;/p&gt;&#xA;&lt;图&#xA;class =“ figup-wrapper figuper-wrapper__lightbox W-100P”&#xA;样式=“最大宽度：无;”&#xA;itemprop =“ iSsectedmedia”&#xA;itemScope =“”&#xA;itemType =“ http://schema.org/imageObject”&#xA;&gt; &lt;a&#xA;class =“ Lightbox-link”&#xA;href =“ https://a-us.storyblok.com/f/1022730/1802x1084/8bc7aaca9b/sessions-frontend-o11y-dashboards.png”&#xA;itemprop =“ contenturl”&#xA;&gt; &lt;div class =“ img-wrapper W-100P H-auto”&gt; &lt;img&#xA;class =“ Lazyload”&#xA;data-src =“ https://a-us.storyblok.com/f/1022730/1802x1084/8bc7aaca9b/sessions-frontend-o11y-dashboards.png” Alt =“ Alt =” Grafana Cloud Cloud cound countents观察性仪表板显示彩色仪表板，并在下面显示详细信息，并在下面显示详细信息，并在下面显示详细信息，并在下图平台。”/&gt;&#xA;&lt;NoScript&gt;&#xA;&lt;img&#xA;src =“ https://a-us.storyblok.com/f/1022730/1802x1084/8bc7aaca9b/sessions-frontend-o11y-dashboards.png”&#xA;Alt =“ Grafana Cloud前端可观察性仪表板显示带有彩色条的会话数据，下面的表显示了会话详细信息，包括ID，页面，浏览器和平台。”/&gt;&#xA;&lt;/noscript&gt; &lt;/div&gt; &lt;/a&gt; &lt;/figie&gt;&#xA;&lt;h3 id =“ http-performance-Insights”&gt; http绩效见解&#xA;&lt;p&gt; &lt;strong&gt; http &lt;/strong&gt;部分 - 也称为&lt;a href =“//blog/2025/08/27/opportize-application-performance-porformance-porformance-the-network-layer-indroducing-indroducing-http-performance-performs-performs-performs-performs-performs-rontends-infrontend-bobserv-in-frontend-bobserv---请求。您会看到总请求，错误率，错误百分比，第一个字节的平均时间（TTFB）以及其他影响总体应用程序性能的与请求相关的指标。此功能当前在公共预览中。 &lt;/p&gt;&#xA;&lt;H3 ID =“ HahahugoshortCode1958S5HBHB”&gt; &lt;fige&#xA;class =“ figup-wrapper figuper-wrapper__lightbox W-100P”&#xA;样式=“最大宽度：无;”&#xA;itemprop =“ iSsectedmedia”&#xA;itemScope =“”&#xA;itemType =“ http://schema.org/imageObject”&#xA;&gt; &lt;a&#xA;class =“ Lightbox-link”&#xA;href =“ https://a-us.storyblok.com/f/1022730/1806x16444/f3f1cd5a97/http-insights-fronts-frontend-o11y-dashboards.png”&#xA;itemprop =“ contenturl”&#xA;&gt; &lt;div class =“ img-wrap每w-100p h-auto“&gt; &lt;img&#xA;class =“ Lazyload”&#xA;data-src =“ https://a-us.storyblok.com/f/1022730/1806x16444/f3f1cd5a97/http-insights-fronts-frontend-o11y-dashboards.png”代码和资源时间。”/&gt;&#xA;&lt;NoScript&gt;&#xA;&lt;img&#xA;src =“ https://a-us.storyblok.com/f/1022730/1806x1644/f3f1cd5a97/http-insights-fronts-frontend-o11y-dashboards.png”&#xA;alt =“ Grafana云前端可观察性仪表板显示HTTP请求指标，包括错误，TTFB，持续时间，状态代码和资源时间。”/&gt;&#xA;&lt;/noscript&gt; &lt;/div&gt; &lt;/a&gt; &lt;/fige&gt; &lt;/h3&gt;&#xA;&lt;h3 id =“滤波器可限制的数据 - 分析”&gt;过滤器：可自定义数据分析&lt;/h3&gt;&#xA;&lt;p&gt;可在前端可观察性仪表板的所有部分可用，过滤器允许您使用在FARO仪器和预配置选项中创建的自定义标签切片和切成数据。&lt;/p&gt;&#xA;&lt;p&gt; &lt;图&#xA;class =“ figup-wrapper figuper-wrapper__lightbox W-100P”&#xA;样式=“最大宽度：无;”&#xA;itemprop =“ iSsectedmedia”&#xA;itemScope =“”&#xA;itemType =“ http://schema.org/imageObject”&#xA;&gt; &lt;a&#xA;class =“ Lightbox-link”&#xA;href =“ https://a-us.storyblok.com/f/1022730/19999x426/b0ade85599/filters-filters-frontend-o11y-dashboards.png”&#xA;itemprop =“ contenturl”&#xA;&gt; &lt;div class =“ img-wrapper W-100P H-auto”&gt; &lt;img&#xA;class =“ Lazyload”&#xA;data-src =“ https://a-us.storyblok.com/f/1022730/19999X426/B085599/filters-filters-frontend-frontend-o11y-dashboards.png” alt =“ Alt =” Grafana Cloud Frontend可观察性仪表板，适用于生产环境，&#xA;&lt;NoScript&gt;&#xA;&lt;img&#xA;src =“ https://a-us.storyblok.com/f/1022730/1999x426/b0ade85599/filters-filters-frontend-o11y-dashboards.png”&#xA;alt =“ grafana云前端可观察性仪表板，该仪表板带有过滤器用于生产环境。”/&gt;&#xA;&lt;/noscript&gt; &lt;/div&gt; &lt;/a&gt; &lt;/figud&gt;您是否需要分析特定的应用程序环境，比较不同的版本或专注于特定的用户段，过滤器提供了目标分析所需的粒度。&lt;/p&gt;&#xA;&lt;H2 ID =“ Learn-More”&gt;了解更多&lt;/h2&gt;&#xA;&lt;p&gt;这些指标和前端可观察性中的可视化旨在帮助您监视Web应用程序的健康状况，并确保最佳的最终用户体验。要了解更多信息，请参阅我们的&lt;a href =“/docs/docs/grafana-cloud/monitor-applications/frontend-observipity/performance/performance/”&gt;文档&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;，要查看Grafana Cloud前端可观察性的现场，交互式示例，请查看&lt;a href =“ https://play.gray.grafana.org/a/grafana-kowalski-app” target =“ _ _ _空白”&#xA;&lt;p&gt; &lt;em&gt; &lt;a href =“/products/cloud/？pg = blog＆plcmt = body-txt”&gt; grafana cloud &lt;/a&gt; &lt;/em&gt; &lt;em&gt;是开始使用指标，日志，痕迹，仪表，仪表板等最简单的方法。我们有一个宽敞的永远的层次和计划。&lt;/em&gt; &lt;em&gt; &lt;a href =“/auth/auth/insip/create-user/？pg = blog＆plcmt = body-txt = body-txt”&gt;现在免费注册！&lt;/a&gt; &lt;/a&gt; &lt;/em&gt; &lt;/em&gt; &lt;/p&gt; &lt;/em&gt; &lt;/p&gt;</description>
      <pubDate>Tue, 02 Sep 2025 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Project Bob: The autonomous boat attempting to circle the globe with open source and Grafana】鲍勃项目：试图用开源和格拉法那绕全球绕全球的自主船</title>
      <link>https://grafana.com/blog/2025/08/29/project-bob-the-open-source-boat-attempting-to-circle-the-globe/</link>
      <description>【&lt;p&gt;Andrew McCalip works with satellites and spacecraft, so he’s no stranger to ambitious engineering challenges. His latest side project may be his boldest yet.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.projectbob.xyz/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Project Bob&lt;/a&gt; aims to be the first autonomous boat to circumnavigate the globe. Open source tools will monitor every detail on the 14-foot, solar-powered vessel, from power levels to location and heading, in real time. And it will use onboard cameras, sensors and a Starlink antenna to stream live video and telemetry data to the public via a custom Grafana Cloud dashboard.&lt;/p&gt;&#xA;&lt;p&gt;McCalip shared the story of Project Bob at his recent &lt;a href=&#34;/events/grafanacon/2025/monitor-project-bob-droneship-with-grafana-and-tailscale/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;GrafanaCON 2025 talk&lt;/a&gt;, demonstrating the power of today’s open source software in tackling real-world engineering challenges.&lt;/p&gt;&#xA;&lt;p&gt;“I haven’t really done software in 10 years,” he said. “So I come back, and there’s this whole sprawling ecosystem of wonderful tools that wasn’t there the first time.”&lt;/p&gt;&#xA;&lt;div&#xA;class=&#34;youtube-lazyload responsive-video&#34;&#xA;data-embed=&#34;uUmXbG3Y4iU&#34;&#xA;data-url=&#34;https://www.youtube.com/embed/uUmXbG3Y4iU?autoplay=1&#34;&#xA;data-title=&#34;YouTube Video&#34;&#xA;&gt;&#xA;&lt;div class=&#34;play-button&#34;&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;h2 id=&#34;from-furnace-door-to-open-ocean&#34;&gt;From furnace door to open ocean&lt;/h2&gt;&#xA;&lt;p&gt;McCalip is head of research and development at &lt;a href=&#34;https://www.varda.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Varda Space Industries&lt;/a&gt;, but he may be better known for the self-proclaimed “weird hobbies” he documents for his 69,000 followers &lt;a href=&#34;https://x.com/andrewmccalip&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;on X&lt;/a&gt;. During his most famous project—attempting to recreate LK-99, a purported room-temperature superconductor—about 15,000 people were glued to a live stream of a furnace door with a Grafana Labs temperature plot.&lt;/p&gt;&#xA;&lt;p&gt;“They gave me the idea, like, ‘Hey, can we do more really boring live streams?’” McCalip recalled. “And so that was kind of the genesis of this idea. Can we do an orbit? Can we do a really boring live stream? And can we engage the public as we build with these cool tools?”&lt;/p&gt;&#xA;&lt;p&gt;He launched a Kickstarter campaign for Project Bob, which met its funding goal in one day. Then he and a group of engineers got to designing a small, rugged drone boat capable of staying at sea for months on its own. That meant it had to be energy efficient, self-sustaining, and able to recover from failure with no human intervention.&lt;/p&gt;&#xA;&lt;p&gt;“Once we send this thing off, there’s no way to ever get to it again,” McCalip said. “We’ve got one chance.”&lt;/p&gt;&#xA;&lt;h2 id=&#34;one-goal-dont-sink&#34;&gt;One goal: ‘Don’t sink’&lt;/h2&gt;&#xA;&lt;p&gt;The team tested two designs—an aerodynamic, fiberglass hull and a rugged (but slow) modified kayak stuffed with batteries and foam—and built them on nights and weekends.&lt;/p&gt;&#xA;&lt;p&gt;“It’s a little bit of a race between the two designs,” McCalip said. “We’re launching number two first, and then one will catch up later.”&lt;/p&gt;&#xA;&lt;p&gt;As with past projects, he documented the process in public. He installed solar panels on the roof of his workplace, experimented in a makeshift dev environment, and put the vessels out on the water at a local marina.&lt;/p&gt;&#xA;&lt;p&gt;“The number-one goal was don’t sink, and we did not sink,” McCalip said. “We did hit a few boats. There was some lag, and once we got out of range of the Wi-Fi, we lost Wi-Fi connection to the boat, and it ran away from us. But other than that, it’s been good.”&lt;/p&gt;&#xA;&lt;p&gt;To test the boat’s GPS capabilities, he even monitored a Grafana dashboard from the passenger seat of a truck en route to the marina.&lt;/p&gt;&#xA;&lt;p&gt;“I am sitting in the truck, we’ve got Grafana open, we’re streaming video through Starlink, through Tailscale, back down to the laptop as we drive down the 405 in Los Angeles,” he said. “That was kind of fun. We got a couple strange looks.”&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: none;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;https://a-us.storyblok.com/f/1022730/1938x826/d4cdb68f4b/project-bob-dashboard.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;https://a-us.storyblok.com/f/1022730/1938x826/d4cdb68f4b/project-bob-dashboard.png&#34;alt=&#34;Dashboard with boat data: speed, power, heading, graphs, and video of a harbor scene with palm trees. Various gauges and metrics displayed.&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;https://a-us.storyblok.com/f/1022730/1938x826/d4cdb68f4b/project-bob-dashboard.png&#34;&#xA;alt=&#34;Dashboard with boat data: speed, power, heading, graphs, and video of a harbor scene with palm trees. Various gauges and metrics displayed.&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;h2 id=&#34;grafana-at-the-helm&#34;&gt;Grafana at the helm&lt;/h2&gt;&#xA;&lt;p&gt;Project Bob runs on a Raspberry Pi 4 with 14 Docker containers controlling the propulsion system, motors, GPS, accelerometers, magnetometers, IP cameras and more. Each container communicates through Redis, the open source in-memory data store, and collects data with Telegraf, the open source server agent. That data is stored in an onboard InfluxDB instance, and it syncs daily over a Tailscale-secured Starlink connection to a cloud replica hosted on Google Cloud Platform. From there, the team pushes metrics to Grafana Cloud for visualization.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: none;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;https://a-us.storyblok.com/f/1022730/1938x1086/1d64c2f515/project-bob-pipeline-architecture.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;https://a-us.storyblok.com/f/1022730/1938x1086/1d64c2f515/project-bob-pipeline-architecture.png&#34;alt=&#34;Flowchart showing a data pipeline from boat to land. Components include Pi4, Redis, Docker, ESP32, Starlink, GCP, InfluxDB, Grafana, and more.&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;https://a-us.storyblok.com/f/1022730/1938x1086/1d64c2f515/project-bob-pipeline-architecture.png&#34;&#xA;alt=&#34;Flowchart showing a data pipeline from boat to land. Components include Pi4, Redis, Docker, ESP32, Starlink, GCP, InfluxDB, Grafana, and more.&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;Those visualizations play a key role in the monitoring and operating of the boat. In particular, a first-person-view dashboard with video and embedded controls allows the team to steer and change speed when needed. Backed by a robust, near-real-time data pipeline, the team is also able to use Open Broadcaster software to create a single streaming video with Grafana dashboards overlaid on top of the boat’s camera footage. This allows viewers on YouTube to see what the boat sees and how it’s performing.&lt;/p&gt;&#xA;&lt;h2 id=&#34;25000-miles-to-go&#34;&gt;25,000 miles to go&lt;/h2&gt;&#xA;&lt;p&gt;To officially circumnavigate the globe, Project Bob must take a route that crosses the equator twice, passes through the point on Earth directly opposite Los Angeles (a spot in the Indian Ocean off the southern coast of Madagascar) and avoids all canals. If all goes well, the 25,000-mile voyage will see the boat pass around South America, Africa, and Australia before returning home.&lt;/p&gt;&#xA;&lt;p&gt;McCalip acknowledged that’s a big if. But he and his team are up for the challenge.&lt;/p&gt;&#xA;&lt;p&gt;“I don’t think that we’re going to make it the first time, but we’re going to keep trying until we get it,” he said. “This would be a world record if we can pull it off.”&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;/products/cloud/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt;&lt;/em&gt; &lt;em&gt;is the easiest way to get started with metrics, logs, traces, dashboards, and more. We have a generous forever-free tier and plans for every use case.&lt;/em&gt; &lt;em&gt;&lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Sign up for free now!&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;】&lt;p&gt;安德鲁·麦卡利普（Andrew McCalip）与卫星和航天器一起工作，因此他对雄心勃勃的工程挑战并不陌生。他的最新侧面项目可能是他最大胆的。&lt;/p&gt;&#xA;&lt;p&gt; &lt;a href =“ https://www.projectbob.xyz/” target =“ _ blank” rel =“ noopener noreferrer”&gt; bob bob &lt;/a&gt;旨在成为第一艘自主船，以绕过全球。开源工具将监视14英尺太阳能驱动的容器上的每个细节，从电源水平到位置和朝向，并实时进行。它将使用自定义Grafana Cloud仪表板将现场视频和遥测数据传输给公众。&lt;/p&gt;&#xA;&lt;p&gt; McCalip在他最近的&lt;a href =“/events/grafanacon/2025/Monitor-project-bob-Roneship-with-grafana and-tailscale/？pg = blog＆plcmt = body-txt = grafanacon 2025 Talk Talking &lt;/a&gt;上，挑战&lt;/a&gt;，挑战&lt;/a&gt;，&lt;p&gt; McCalip分享了鲍勃项目的故事。&#xA;&lt;p&gt;“我十年来还没有真正完成软件，”他说。 “所以我回来了，这是第一次没有的整个庞大的奇妙工具生态系统。” &lt;/p&gt;&#xA;&lt;div&#xA;class =“ youtube-lazyload响应式video”&#xA;data-embed =“ uumxbg3y4iu”&#xA;data-url =“ https://www.youtube.com/embed/uumxbg3y4iu?autoplay = 1”&#xA;数据标题=“ YouTube视频”&#xA;&gt;&#xA;&lt;div class =“ play-button”&gt; &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;h2 id =“从炉门到开放式海洋&lt;/h2&gt;&#xA;&lt;p&gt; McCalip是研究与开发的主管，&lt;a href =“ https://www.varda.com/” target =“ _ blank” rel =“ noopener noreferrer”&gt; varda space Industries &lt;/a&gt;，但他可能以自称为“怪异的Hebbies”的自称为69,000 clasters &lt; href =“ https://x.com/andrewmccalip” target =“ _ blank” rel =“ noopener noreferrer”&gt; on x &lt;/a&gt;。在他最著名的项目中 - 挑战LK-99，是一个声称的室温超导体 - 大约有15,000人被粘在带有Grafana Labs温度图的炉门的现场直播中。&lt;/p&gt; &lt;/p&gt;&#xA;&lt;p&gt;“他们给了我这个主意，例如，‘嘿，我们能做更多真正无聊的直播吗？’”麦卡利普回忆道。 “这就是这个想法的起源。我们可以做一个轨道吗？我们可以做一个真正无聊的现场直播吗？我们可以在使用这些酷工具时吸引公众吗？” &lt;/p&gt;&gt;&#xA;&lt;p&gt;他为鲍勃计划发起了一项Kickstarter运动，该活动在一天之内达到了其资金目标。然后，他和一群工程师必须设计一艘崎rug的无人机船，能够独自待在海上几个月。这意味着它必须是节能，自我维持的，并且能够在没有人类干预的情况下从失败中恢复过来。&lt;/p&gt;&#xA;&lt;p&gt;“一旦我们把这东西寄出，就再也无法再解决了，”麦卡利普说。 “我们有机会。” &lt;/p&gt;&#xA;&lt;h2 id =“一球插入”&gt;一个目标：&#39;不要下沉&#39;&lt;/h2&gt;&#xA;&lt;p&gt;该团队测试了两种设计 - 空气动力学，玻璃纤维船体和一个崎and的（但缓慢）的皮划艇，里面装有电池和泡沫 - 并在夜间和周末建造了它们。&lt;/p&gt;。&lt;/p&gt;&#xA;&lt;p&gt;“它麦卡利普说：``两种设计之间有点竞赛。我们首先推出第二名，然后再赶上。” &lt;/p&gt;&#xA;&lt;p&gt;与过去的项目一样，他在公开场合记录了这一过程。他在工作场所的屋顶上安装了太阳能电池板，在临时开发环境中进行了试验，并将船只放在当地码头的水上。&lt;/p&gt;&#xA;&lt;p&gt;“第一目标不是下沉，我们没有下沉，”麦卡利普说。 “我们确实撞上了几艘船。有一些滞后，一旦我们离开了Wi-Fi范围，我们就失去了Wi-Fi连接到船上，它逃离了我们。但是除此之外，这很好。”​​ &lt;/p&gt;&gt;&gt; &lt;/p&gt;&#xA;&lt;p&gt;为了测试船的GPS功能，他甚至从卡车的乘客座椅上监视了前往码头的乘客座椅。&lt;/p&gt;&#xA;&lt;p&gt;“我坐在卡车上，我们已经开放了Grafana，我们正在通过Starlink，通过Tailscale播放视频，当我们驶向洛杉矶的405时，回到笔记本电脑，”他说。 “那很有趣。我们有几个奇怪的外观。” &lt;/p&gt;&#xA;&lt;图&#xA;class =“ figup-wrapper figuper-wrapper__lightbox W-100P”&#xA;样式=“最大宽度：无;”&#xA;itemprop =“ iSsectedmedia”&#xA;itemScope =“”&#xA;itemType =“ http://schema.org/imageObject”&#xA;&gt; &lt;a&#xA;class =“ Lightbox-link”&#xA;href =“ https://a-us.storyblok.com/f/1022730/1938x826/d4cdb68f4b/project-bob-dashboard.png”&#xA;itemprop =“ contenturl”&#xA;&gt; &lt;div class =“ img-wrapper W-100P H-auto”&gt; &lt;img&#xA;class =“ Lazyload”&#xA;data-src =“ https://a-us.storyblok.com/f/1022730/1938x826/d4cdb68f4b/project-bob-dashboard.png” alt =“ dashboard with Boat data with Boat data：speed，speed，power，power，power，power，power，power，heading and thrage and the harbor a the harbor a the harbor abore a harbour coble a there toble a the harbor abore coble a the harbor abore coble。&#xA;&lt;NoScript&gt;&#xA;&lt;img&#xA;src =“ https://a-us.storyblok.com/f/1022730/1938x826/d4cdb68f4b/project-bob-dashboard.png”&#xA;alt =“带有船只数据的仪表板：速度，电源，标题，图形和带有棕榈树的港口场景的视频。显示了各种规模和指标。”/&gt;&#xA;&lt;/noscript&gt; &lt;/div&gt; &lt;/a&gt; &lt;/figie&gt;&#xA;&lt;H2 ID =“ grafana-at-the-helm”&gt; Grafana in Helm &lt;/h2&gt;&#xA;&lt;p&gt;项目BOB在Raspberry Pi 4上运行，该Raspberry Pi 4带有14个Docker容器，可控制推进系统，电动机，GPS，加速度计，磁力计，IP摄像机等。每个容器通过开源中内存数据存储Redis进行通信，并使用开源服务器代理Telegraf收集数据。该数据存储在板载InfluxDB实例中，并且每天通过尾部安全的Starlink连接将其同步到Google Cloud Platform上托管的云复制品。从那里开始，团队将指标推向Grafana Cloud以进行可视化。&lt;/p&gt;&#xA;&lt;图&#xA;class =“ figup-wrapper figuper-wrapper__lightbox W-100P”&#xA;样式=“最大宽度：无;”&#xA;itemprop =“ iSsectedmedia”&#xA;itemScope =“”&#xA;itemType =“ http://schema.org/imageObject”&#xA;&gt; &lt;a&#xA;class =“ Lightbox-link”&#xA;href =“ https://a-us.storyblok.com/f/1022730/1938x1086/1d64c2f515/project-bob-pipeline-architecture.png”&#xA;itemprop =“ contenturl”&#xA;&gt; &lt;div class =“ img-wrapper W-100P H-auto”&gt; &lt;img&#xA;class =“ Lazyload”&#xA;data-src =“ https://a-us.storyblok.com/f/1022730/1938x1086/1D64C2F515/Project-Bob-Pipeline-Architecture.png“ Alt =”流程图显示了从船到土地的数据管道。组件包括PI4，Redis，Docker，ESP32，Starlink，GCP，InfruxDB，Grafana等。”/&gt;&#xA;&lt;NoScript&gt;&#xA;&lt;img&#xA;src =“ https://a-us.storyblok.com/f/1022730/1938x1086/1d64c2f515/project-bob-pipeline-archituction.png”&#xA;alt =“流程图显示了从船到土地的数据管道。组件包括PI4，Redis，Docker，ESP32，Starlink，GCP，GCP，InfluxdB，Grafana等。”/&gt;&#xA;&lt;/noscript&gt; &lt;/div&gt; &lt;/a&gt; &lt;/figie&gt;&#xA;&lt;p&gt;这些可视化在船的监视和操作中起着关键作用。特别是，带有视频和嵌入式控件的第一人视仪表板使团队可以在需要时进行转向和更改速度。在坚固的，近实时的数据管道的支持下，该团队还可以使用开放的广播软件来创建一个单个流媒体视频，其中横跨船的摄像机镜头的Grafana仪表板。这使YouTube上的观众可以查看船的表现以及表现方式。&lt;/p&gt;&#xA;&lt;h2 id =“ 25000英里到go”&gt; 25,000英里&lt;/h2&gt;&#xA;&lt;p&gt;为了正式绕过地球，鲍勃必须采取两次越过赤道的路线，穿过洛杉矶对面（马达加斯加南部海岸附近的印度洋）对面的地球上的地上，并避免了所有运河。如果一切顺利，那么25,000英里的航行将在返回家园之前在南美，非洲和澳大利亚附近通过。&lt;/p&gt;。&lt;/p&gt;&#xA;&lt;p&gt;麦卡利普承认这是一个很大的话。但是他和他的团队正在挑战。&lt;/p&gt;&#xA;&lt;p&gt;“我认为我们不会第一次做到这一点，但是我们将继续尝试，直到我们得到它为止。” “如果我们能实现这一目标，这将是世界纪录。” &lt;/p&gt;&#xA;&lt;p&gt; &lt;em&gt; &lt;a href =“/products/cloud/？pg = blog＆plcmt = body-txt”&gt; grafana cloud &lt;/a&gt; &lt;/em&gt; &lt;em&gt;是开始使用指标，日志，痕迹，仪表，仪表板等最简单的方法。我们有一个宽敞的永远的层次和计划。&lt;/em&gt; &lt;em&gt; &lt;a href =“/auth/auth/insip/create-user/？pg = blog＆plcmt = body-txt = body-txt”&gt;现在免费注册！&lt;/a&gt; &lt;/a&gt; &lt;/em&gt; &lt;/em&gt; &lt;/p&gt; &lt;/em&gt; &lt;/p&gt;</description>
      <pubDate>Fri, 29 Aug 2025 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【How should Prometheus handle OpenTelemetry resource attributes?】Prometheus应该如何处理OpenTelemetry资源属性？</title>
      <link>https://grafana.com/blog/2025/08/28/how-should-prometheus-handle-opentelemetry-resource-attributes-a-ux-research-report/</link>
      <description>【&lt;p&gt;&lt;em&gt;Note: A version of this post originally appeared on the&lt;/em&gt; &lt;em&gt;&lt;a href=&#34;https://opentelemetry.io/blog/2025/ux-research-prometheus-otel/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;OpenTelemetry blog.&lt;/a&gt;&lt;/em&gt; &lt;em&gt;Victoria Nduka is user experience designer and open source contributor making her way into the cloud native space. She writes about design, accessibility, and open source with the same curiosity she brings to her work.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;On May 29, I wrapped up my mentorship with Prometheus through the &lt;a href=&#34;https://mentorship.lfx.linuxfoundation.org/project/36e3f336-ce78-4074-b833-012015eb59be&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Linux Foundation mentorship program&lt;/a&gt;. My project focused on understanding how Prometheus handles OpenTelemetry resource attributes and how that experience could be improved for users. My job was to conduct research to get the user perspective on this challenge. Over three months, I conducted user and stakeholder interviews, ran a survey, and analyzed the findings.&lt;/p&gt;&#xA;&lt;p&gt;In this article, I&amp;rsquo;ll share how we conducted the research, what we uncovered, and where the communities involved could go from here.&lt;/p&gt;&#xA;&lt;h2 id=&#34;the-project-background&#34;&gt;&lt;strong&gt;The project background&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;p&gt;OpenTelemetry (OTel) has something called &lt;a href=&#34;https://opentelemetry.io/docs/concepts/resources/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;resource attributes&lt;/a&gt;, which are extra information about the source of a metric, such as the service, host, or environment that generated it. &lt;/p&gt;&#xA;&lt;p&gt;Prometheus, being a time-series database, uses labels to identify and query metrics. If resource attributes are converted to labels, they can cause what&amp;rsquo;s known as a &amp;ldquo;cardinality explosion,&amp;rdquo; essentially creating too many unique combinations that overwhelm the system. This usually happens if the attributes change often or include a lot of unique values, such as user IDs or pod names.&lt;/p&gt;&#xA;&lt;p&gt;Currently, there are three main approaches to handling this challenge:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;Map all resource attributes to labels&lt;/strong&gt;: This was the original implementation made by the Prometheus community. However, it actually creates cardinality explosion problems, especially for applications with large numbers of attributes or frequently changing attribute values.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Selective promotion&lt;/strong&gt;: Users manually choose which resource attributes are important enough to be converted to labels in Prometheus.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Target info pattern&lt;/strong&gt;: Put all resource attributes in a separate metric called &lt;code&gt;target_info&lt;/code&gt;. When users need to query metrics involving specific resource attributes, they have to perform a &amp;ldquo;join&amp;rdquo; between the target info and their actual metrics.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;These aren&amp;rsquo;t bad solutions technically, but they don&amp;rsquo;t make for the best user experience. So, we conducted this research to understand what the Prometheus maintainers might be missing about the user experience.&lt;/p&gt;&#xA;&lt;p&gt;The research objectives were:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Understand how engineers currently use OpenTelemetry resource attributes with Prometheus&lt;/li&gt;&#xA;&lt;li&gt;Identify pain points in the current integration&lt;/li&gt;&#xA;&lt;li&gt;Discover user expectations for how resource attributes should be represented&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;research-approach&#34;&gt;&lt;strong&gt;Research approach&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;p&gt;My research approach was a mix of qualitative and quantitative research. I started with stakeholder interviews to understand the historical context and assess how open stakeholders were to changes that might result from my research. The stakeholders we spoke to represented a range of roles, from project founders and co-founders to long-time maintainers with historical context, as well as others more directly involved in the ongoing challenges around resource attribute handling.&lt;/p&gt;&#xA;&lt;p&gt;Next, I conducted user interviews to hear directly from people actually using these tools. After that, I followed up with a survey to reach a broader audience and validate what we heard in interviews.&lt;/p&gt;&#xA;&lt;h3 id=&#34;stakeholder-interviews-insights&#34;&gt;&lt;strong&gt;Stakeholder interviews insights&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;p&gt;We spoke to six stakeholders—three from each project:&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Prometheus stakeholders:&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Julius Volz (&lt;a href=&#34;https://github.com/juliusv&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;https://github.com/juliusv&lt;/a&gt;): Prometheus co-founder&lt;/li&gt;&#xA;&lt;li&gt;Beorn Rabenstein (&lt;a href=&#34;https://github.com/beorn7&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;https://github.com/beorn7&lt;/a&gt;): Long-time Prometheus maintainer&lt;/li&gt;&#xA;&lt;li&gt;Richard Hartmann (&lt;a href=&#34;https://github.com/RichiH&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;https://github.com/RichiH&lt;/a&gt;):  OpenMetrics co-founder and Prometheus maintainer.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;OpenTelemetry stakeholders:&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Juraci Paixão Khröhling (&lt;a href=&#34;https://github.com/jpkrohling&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;https://github.com/jpkrohling&lt;/a&gt;): OpenTelemetry Governance Committee member&lt;/li&gt;&#xA;&lt;li&gt;Josh Suereth (&lt;a href=&#34;https://github.com/jsuereth&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;https://github.com/jsuereth&lt;/a&gt;): OpenTelemetry Technical Committee member &lt;/li&gt;&#xA;&lt;li&gt;Austin Parker (&lt;a href=&#34;https://github.com/austinlparker&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;https://github.com/austinlparker&lt;/a&gt;): OpenTelemetry Governance Committee member and co-founder.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Our conversations with stakeholders brought several interesting discoveries to light:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;The Prometheus and OpenTelemetry communities hadn&amp;rsquo;t always communicated well and that prevented them from collaborating early on.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Much of the interoperability issues that exist now stem from the different philosophical and technical foundations on which each of the projects is built. &lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&amp;ldquo;If we think about exploratory situations or use cases, then we can justify a lot of the design decisions behind OpenTelemetry. And if we think about metrics and scaling, monitoring, for huge infra, then the design decisions for Prometheus are justified as well. So both have very good arguments.&amp;rdquo; - Juraci Paixão Kröhling&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;“I think one of the biggest [interoperability issues] is the difference between push and pull.” - Julius Volz&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;Julius later elaborated that his concern goes beyond the delivery mechanism itself. In his words:&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;“One of the biggest downsides of using OTLP to push metrics to Prometheus is that you end up throwing away one of the core features of Prometheus as a monitoring system: its pull-based metrics collection model that is based on dynamic service discovery information (so Prometheus always knows which targets should currently exist), and the resulting automatic target health monitoring via the synthetic ‘up’ metric that is generated for each target scrape.”&lt;/em&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;There’s a shared recognition of the importance of putting user needs first, even while maintaining some non-negotiables (e.g., Prometheus keeping its pull model and not alienating existing users).&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;One key takeaway from the interviews for me was realizing that the current interoperability problems are not failures, but natural consequences of different communities solving different problems at different times. And it’s good to see both projects are working together now to make user experience better.&lt;/p&gt;&#xA;&lt;h3 id=&#34;user-interviews-insights&#34;&gt;&lt;strong&gt;User interviews insights&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;p&gt;The user interviews were just as revealing as the stakeholder conversations. We aimed to speak with about 10 users (admittedly ambitious) but managed to interview seven, and they all shared incredibly helpful perspectives.&lt;/p&gt;&#xA;&lt;p&gt;The most prominent pain point users shared was the complexity of performing joins with the current integration. Another issue mentioned was the mismatch in metric names caused by character set limitations, but I understand that has since been addressed, as recent Prometheus releases &lt;a href=&#34;/blog/2024/11/06/prometheus-3.0-and-opentelemetry-a-practical-guide-to-storing-and-querying-otel-data/#utf-8&#34;&gt;now support UTF-8 characters&lt;/a&gt; (though this introduces the need for the more cumbersome quoted selector syntax in PromQL).&lt;/p&gt;&#xA;&lt;p&gt;Regarding mental models, many users (both interviewees and survey respondents) don’t distinguish between resource attributes and Prometheus labels. They tend to think of them as the same thing.&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&amp;ldquo;I would expect resource attributes as a rule to be treated exactly the same way as the attributes attached to the tracer, the metric&amp;hellip; I wouldn&amp;rsquo;t draw a boundary between them.&amp;rdquo; - Interview participant 1&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;I also learned about the various workarounds people use to handle resource attribute issues in their specific use cases. Some promote selected resource attributes to labels; others handle the conversion at the OpenTelemetry level to avoid dealing with it in Prometheus; and a few convert all attributes, though usually only when the number of attributes is small.&lt;/p&gt;&#xA;&lt;h3 id=&#34;survey-insights&#34;&gt;&lt;strong&gt;Survey insights&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;p&gt;The survey helped me quantify what I was hearing in interviews and reach a broader audience. At the time of writing, we’ve had 134 responses, with 61 from our target group—people who use OTel and Prometheus together.&lt;/p&gt;&#xA;&lt;p&gt;Here are the key findings:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Users don&amp;rsquo;t conceptualize resource attributes as different from regular labels, yet current implementation treats them as separate metadata.&lt;/li&gt;&#xA;&lt;li&gt;Complex join syntax is a big barrier to adoption, with average developers unable to write basic queries accessing resource attributes.&lt;/li&gt;&#xA;&lt;li&gt;Manual attribute promotion creates operational overhead that scales poorly with team size and complexity.&lt;/li&gt;&#xA;&lt;li&gt;78% of respondents find documentation gaps a challenge in their use of resource attributes.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: none;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;https://a-us.storyblok.com/f/1022730/622x494/f6be735f5a/prometheus-research-stats.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;https://a-us.storyblok.com/f/1022730/622x494/f6be735f5a/prometheus-research-stats.png&#34;alt=&#34;Bar chart showing challenges with OpenTelemetry in Prometheus. Highlighted: &amp;#39;Documentation gaps&amp;#39; rated as very challenging by 25 respondents.&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;https://a-us.storyblok.com/f/1022730/622x494/f6be735f5a/prometheus-research-stats.png&#34;&#xA;alt=&#34;Bar chart showing challenges with OpenTelemetry in Prometheus. Highlighted: &amp;#39;Documentation gaps&amp;#39; rated as very challenging by 25 respondents.&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;The survey patterns were consistent with what emerged from my qualitative research. &lt;/p&gt;&#xA;&lt;h2 id=&#34;what-we-didnt-expect-to-learn-but-did&#34;&gt;&lt;strong&gt;What we didn’t expect to learn (but did)&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;p&gt;We began this research to understand user pain points with resource attribute handling, but we uncovered some unexpected and important findings. One of the most surprising was the realization that &lt;a href=&#34;https://github.com/open-telemetry/opentelemetry-specification/tree/main/specification/resource#telescoping&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;OpenTelemetry’s resource detection feature&lt;/a&gt; allows users to selectively retain or drop resource attributes based on relevance via a conceptual pattern sometimes referred to as “telescoping.” &lt;/p&gt;&#xA;&lt;p&gt;Despite its potential, many users and even some members of the Prometheus community seem unaware of it. This lack of awareness may have contributed to the adoption of the &amp;ldquo;join&amp;rdquo; pattern, which has since proven to be problematic.&lt;/p&gt;&#xA;&lt;p&gt;This also highlights a broader issue: &lt;strong&gt;documentation and education gaps&lt;/strong&gt; are a major barrier. In our survey, 78% of respondents cited documentation gaps as a challenge.&lt;/p&gt;&#xA;&lt;p&gt;Another key realization is that earlier integration decisions, like the reliance on joins, were made without a full understanding of each tool’s capabilities. This is an unavoidable consequence of the lack of early collaboration and communication between the Prometheus and OpenTelemetry communities.&lt;/p&gt;&#xA;&lt;h2 id=&#34;recommended-solutions&#34;&gt;&lt;strong&gt;Recommended solutions&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;p&gt;Based on conversations with stakeholders and end users, here are some of the proposed solutions, grouped by what&amp;rsquo;s feasible in the short term vs. what&amp;rsquo;s part of a longer-term vision.&lt;/p&gt;&#xA;&lt;h3 id=&#34;short-term-solutions&#34;&gt;&lt;strong&gt;Short-term solutions&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Improved documentation for attribute handling.&lt;/strong&gt; Since users find it easier to promote attributes than to join on target info, it may be worth de-emphasizing (or even sunsetting) documentation around joins, while making &lt;a href=&#34;https://prometheus.io/docs/guides/opentelemetry/#promoting-resource-attributes&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;attribute promotion docs&lt;/a&gt; more prominent for those not yet aware of the option. The telescoping pattern of resource detection in OpenTelemetry also deserves more visibility and proper documentation. Additionally, users have suggested creating consolidated Prometheus-OpenTelemetry documentation that clearly explains how both systems handle resource attributes.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;long-term-vision&#34;&gt;&lt;strong&gt;Long-Term Vision&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Entity framework.&lt;/strong&gt; OpenTelemetry’s developing concept of &lt;em&gt;entities&lt;/em&gt; could help Prometheus distinguish between identifying vs. descriptive attributes. This would guide which attributes become labels, and which are stored or filtered out.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Metadata storage.&lt;/strong&gt; Stakeholders also discussed the idea of adding first-class metadata support to Prometheus itself. This would allow certain resource attributes to be stored as metadata (not labels), avoiding cardinality costs while keeping the information available for queries or joins.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Expanding for exploratory telemetry.&lt;/strong&gt; This might be a stretch, but Prometheus could consider expanding its scope to better support exploratory telemetry use cases. Stakeholders showed openness to change, as long as Prometheus’ core architecture remains intact and existing users aren’t alienated. That suggests there may be room for evolution, especially if new capabilities can complement, rather than replace, current behavior.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Cross-signal correlation.&lt;/strong&gt; Users mention using platforms that can ingest all telemetry types and correlate metrics, traces, and logs within a single system. While Prometheus will likely remain focused on just metrics, it could enable tooling that correlates metrics with telemetry stored in other databases. Prometheus currently supports &lt;a href=&#34;https://prometheus.io/docs/specs/om/open_metrics_spec/#exemplars&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;exemplars&lt;/a&gt;, which allow linking metrics to traces, but that’s about the extent of their scope. They rely on tracing being present, which makes them less useful in environments where traces aren’t available or instrumented.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;This cross-signal correlation is an opportunity for Prometheus to expand its usefulness in modern observability workflows without changing its core focus on metrics storage. &lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;“One of the key innovative things in OpenCensus was… you could divide CPU usage by which requests were using CPU and get a metric that would say, ‘here&amp;rsquo;s CPU usage by request.’ That’s a thing you could accomplish in OpenCensus because it was all contextual-based metrics.” - Josh Suereth&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;There&amp;rsquo;s still work to be done. The communities will need time to develop and test solutions. But I&amp;rsquo;m proud that this research has provided a user-centered foundation for that work.&lt;/p&gt;&#xA;&lt;p&gt;If you&amp;rsquo;re interested in the ongoing discussions, proposals, and feedback around these ideas, you can check out the GitHub repository where everything is being documented: &lt;a href=&#34;https://github.com/prometheus-community/ux-research/tree/main/prom-otel-research&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;OpenTelemetry resource attributes in Prometheus UX research&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;acknowledgments&#34;&gt;&lt;strong&gt;Acknowledgments&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;p&gt;This post would be incomplete if I didn’t acknowledge my incredible mentors from Grafana Labs: Amy Super, Andrej Kiripolsky, and Arthur Silva Sens. Thanks for trusting me to take on this challenging project and for caring so deeply about my professional journey. You’re the real superstars.&lt;/p&gt;&#xA;&lt;p&gt;To all the stakeholders and users who shared their time and perspectives, thank you for engaging with the research and trusting me with your honest feedback. Your stories and frustrations are what made this research meaningful.&lt;/p&gt;&#xA;&lt;p&gt;And a few words from the Grafanistas:&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;“Thank&lt;/em&gt; &lt;em&gt;&lt;strong&gt;you,&lt;/strong&gt;&lt;/em&gt; &lt;em&gt;Victoria, for getting this research to the finish line. You&amp;rsquo;ve shown courage to face your fears and incredible dedication throughout the whole mentorship.&amp;quot;&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;We&amp;rsquo;d also like to thank Grafana Labs’ culture, which always encourages us to make meaningful contributions to OpenTelemetry, Prometheus, and other open-source communities!”&lt;/em&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;em&gt;Andrej, Amy, and Arthur&lt;/em&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;what&#34;&gt;&lt;strong&gt;What&amp;rsquo;s next for me&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;p&gt;I&amp;rsquo;m excited to continue working at the intersection of UX and cloud native systems. If you have opportunities in this area similar to this mentorship, please reach out to me on &lt;a href=&#34;https://www.linkedin.com/in/victorianduka/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;LinkedIn&lt;/a&gt; or by &lt;a href=&#34;mailto:ndukavictoria7@gmail.com&#34;&gt;email&lt;/a&gt;. I&amp;rsquo;m a hard worker—just ask my mentors.&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;/products/cloud/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt;&lt;/em&gt; &lt;em&gt;is the easiest way to get started with metrics, logs, traces, dashboards, and more. We have a generous forever-free tier and plans for every use case.&lt;/em&gt; &lt;em&gt;&lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Sign up for free now!&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;】&lt;p&gt; &lt;em&gt;注意：本文的一个版本最初出现在&lt;/em&gt; &lt;em&gt; &lt;a href =“ https://opentlemetry.io.io/blog/2025/2025/ux-research-prometheus-otel/” target =“ _ rell =” rel =“ rel =” noopener noreferrer&#39;&gt;用户体验设计师和开源贡献者进入云本地空间。她以与她的作品相同的好奇心写了关于设计，可访问性和开源的文章。&lt;/em&gt; &lt;/p&gt;&#xA;&lt;p&gt; 5月29日，我通过&lt;a href =“ https://mentorship.lfx.linuxfoundation.org/project/project/36e3f336-ce78-4074-4074-b833-012012015eb59be targitor =” no ninux Founterrer =“ sllien nin nlinub ninub ninubs nline nliniunl ninubn linirer nin nliniunl ninuber nin verroferer，程序&lt;/a&gt;。我的项目专注于了解Prometheus如何处理OpenTelemetry资源属性以及如何改善用户的体验。我的工作是进行研究，以了解用户对这一挑战的看法。在三个月的时间里，我进行了用户和利益相关者访谈，进行了调查，并分析了调查结果。&lt;/p&gt;。&#xA;&lt;p&gt;在本文中，我将分享我们如何进行研究，发现的内容以及所涉及的社区可以从这里去的地方。&lt;/p&gt;&#xA;&lt;h2 id =“ the-project-background”&gt; &lt;strong&gt;项目背景&lt;/strong&gt; &lt;/h2&gt;&#xA;&lt;p&gt;OpenTelemetry (OTel) has something called &lt;a href=&#34;https://opentelemetry.io/docs/concepts/resources/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;resource attributes&lt;/a&gt;, which are extra information about the source of a metric, such as the service, host, or environment that generated it. &lt;/p&gt;&#xA;&lt;p&gt; Prometheus是一个时间序列数据库，使用标签来识别和查询指标。如果将资源属性转换为标签，它们可能会导致所谓的“基数爆炸”，从本质上产生了太多的独特组合，使系统不堪重负。如果属性经常更改或包含许多唯一值，例如用户ID或POD名称，通常会发生这种情况。&lt;/p&gt;&#xA;&lt;p&gt;目前，处理这一挑战的主要方法：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt; &lt;strong&gt;将所有资源属性映射到标签&lt;/strong&gt;：这是普罗米修斯社区的原始实现。但是，它实际上会产生基数爆炸问题，尤其是对于具有大量属性或经常更改属性值的应用程序。&lt;/li&gt;&#xA;&lt;li&gt; &lt;strong&gt;选择性促销&lt;/strong&gt;：用户手动选择哪些资源属性很重要，可以转换为Prometheus中的标签。&lt;/li&gt;&#xA;&lt;li&gt; &lt;strong&gt;目标信息模式&lt;/strong&gt;：将所有资源属性放在一个单独的度量标准中，称为&lt;code&gt; target_info &lt;/code&gt;。当用户需要查询涉及特定资源属性的指标时，他们必须在目标信息和实际指标之间执行“加入”。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;从技术上讲，这些解决方案不是不良的解决方案，但是它们并不是最佳的用户体验。因此，我们进行了这项研究，以了解普罗米修斯维护者可能缺少什么关于用户体验。&lt;/p&gt;&#xA;&lt;p&gt;研究目标是：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;了解工程师当前如何使用Prometheus &lt;/li&gt;使用OpenTelemetry资源属性&lt;/li&gt;&#xA;&lt;li&gt;确定当前整合中的疼痛点&lt;/li&gt;&#xA;&lt;li&gt;发现用户对应如何表示资源属性的期望&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id =“研究 - 接触”&gt; &lt;strong&gt;研究方法&lt;/strong&gt; &lt;/h2&gt;&#xA;&lt;p&gt;我的研究方法是定性和定量研究的结合。我从利益相关者的访谈开始，以了解历史环境，并评估利益相关者对我研究可能导致的变化的开放式。我们交谈的利益相关者代表了一系列角色，从项目创始人和联合创始人到具有历史背景的长期维护者，以及其他更直接地参与围绕资源属性处理的挑战。&lt;/p&gt;&#xA;&lt;p&gt;接下来，我进行了用户访谈，直接听取实际使用这些工具的人的意见。之后，我进行了一项调查，以吸引更广泛的受众并验证我们在采访中听到的信息。&lt;/p&gt;&#xA;&lt;H3 ID =“利益相关者 - 访问 -  i-Insights”&gt; &lt;strong&gt;利益相关者采访见解&lt;/strong&gt; &lt;/h3&gt;&#xA;&lt;p&gt;我们与六个利益相关者进行了交谈 - 每个项目中的三个：&lt;/p&gt;&#xA;&lt;p&gt; &lt;strong&gt;普罗米修斯利益相关者：&lt;/strong&gt; &lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt; julius volz（&lt;a href =“ https://github.com/juliusv” target =“ _ blank” rel =“ noopener noreferrer”&gt; https：//github.com/julius.com/juliusv &lt;/a&gt;）&#xA;&lt;li&gt; beorn rabenstein（&lt;a href =“ https://github.com/beorn7” target =“ _ blank” rel =“ noopener noreferrer”&gt; https://github.com/beorn7 &lt;/a&gt;）：&#xA;&lt;li&gt; RICHARD HARTMANN（&lt;a href =“ https://github.com/richih” target =“ _ blank” rel =“ noopener noreferrer”&gt; https://github.com/richih &lt;/a&gt;）&#xA;&lt;/ul&gt;&#xA;&lt;p&gt; &lt;strong&gt; OpentElemetry利益相关者：&lt;/strong&gt; &lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt; juracipaixãoKhröhling（&lt;a href =“ https://github.com/jpkrohling” target =“ _ black” rel =“ noopener noreferrer”&gt; https://github.com/jpkrohling &lt;/a&gt;）&#xA;&lt;li&gt; Josh Suereth（&lt;a href =“ https://github.com/jsuereth” target =“ _ blank” rel =“ noopener noreferrer”&gt; https://github.com/jsuereth &lt;/a&gt;）&#xA;&lt;li&gt; Austin Parker（&lt;A href =“ https://github.com/austinlparker” target =“ _ blank” rel =“ noopener noreferrer”&gt; https://github.com/austinlparker &lt;/a&gt;）&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;我们与利益相关者的对话带来了一些有趣的发现：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt; Prometheus和Opentelemetry社区并不总是很好地交流，这阻止了他们早期合作。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;现在存在的许多互操作性问题源于每个项目的建立的不同哲学和技术基础。 &lt;/p&gt;&#xA;&lt;p&gt; &lt;em&gt;“如果我们考虑探索性情况或用例ns在Opentelemetry后面。而且，如果我们考虑庞大的下属的指标和扩展，监视，那么普罗米修斯的设计决策也是合理的。所以两者都有很好的论点。” -JuraciPaixãoKröhling&lt;/em&gt; &lt;/p&gt;&#xA;&lt;p&gt; &lt;em&gt;“我认为最大的[互操作性问题]之一是推动和拉力之间的区别。” -Julius volz &lt;/em&gt; &lt;/p&gt;&#xA;&lt;p&gt;朱利叶斯后来阐述了他的关注超出了交付机制本身。用他的话：&lt;/p&gt;&#xA;&lt;p&gt; &lt;em&gt;“使用OTLP将指标推向Prometheus的最大弊端之一是，您最终将Prometheus作为监控系统的核心特征之一丢弃：其基于拉动的指标收集模型基于动态服务发现信息，因此，Prometheus始终知道当前的目标是自动监控的目标，并且可以通过“自动监控”目标来启动，并通过“启用”目标，并且可以通过“合成”来指示。刮擦。” &lt;/em&gt; &lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;即使维持某些非商品（例如，Prometheus保留其拉力模型而不疏远现有用户），也可以共同认识到将用户放在首位的重要性。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;对我的采访中的一个关键要点是，意识到当前的互操作性问题不是失败，而是在不同时间解决不同社区的自然后果。很高兴看到这两个项目现在正在共同努力以使用户体验更好。&lt;/p&gt;&#xA;在&#xA;&lt;p&gt;用户访谈与利益相关者对话一样揭示。我们的目的是与大约10位用户交谈（肯定是雄心勃勃），但设法采访了七个，他们都分享了令人难以置信的有用观点。&lt;/p&gt;&#xA;&lt;p&gt;用户分享的最突出的疼痛点是与当前集成一起执行连接的复杂性。提到的另一个问题是由字符集限制引起的公制名称的不匹配，但我知道此后已经解决了，因为最近的Prometheus发行&lt;a href =“/blog/blog/2024/2024/11/11/prometheus-3.0--3.0-and-opentelemetry-apentelemetry-a-a-a-a-a-a-a-a-practical to-practical-a-practical to-practor-to-stoperd-and-querying-querying-querying-portsuts-underted-inding-undert-utff-in/now and ut/ut utf-8介绍了Promql中更繁琐的选择器语法的需求）。&lt;/p&gt;&#xA;&lt;p&gt;关于心理模型，许多用户（受访者和调查受访者）都没有区分资源属性和普罗米修斯标签。他们倾向于将它们视为同一件事。&lt;/p&gt;&#xA;&lt;p&gt; &lt;em&gt;“我希望将资源属性通常与示踪剂，度量标准的属性完全相同的方式进行处理。我不会在它们之间划界。” - 面试参与者1 &lt;/em&gt; &lt;/p&gt;&#xA;&lt;p&gt;我还了解了人们用来处理特定用例中资源属性问题的各种解决方法。一些将选定的资源属性推向标签；其他人处理转换t opentelemetry级别避免在普罗米修斯（Prometheus）处理它；还有一些转换所有属性，尽管通常仅在属性数很小时才。&lt;/p&gt;&#xA;&lt;H3 ID =“ Survey-Insights”&gt; &lt;strong&gt;调查见解&lt;/strong&gt; &lt;/h3&gt;&#xA;&lt;p&gt;这项调查帮助我量化了在采访中听到的内容，并吸引了更广泛的受众。在撰写本文时，我们有134个回复，我们的目标人群有61个 - 将Otel和Prometheus一起使用的人。&lt;/p&gt;。&lt;/p&gt;&#xA;&lt;p&gt;这是关键发现：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;用户不会将资源属性概念化为与常规标签不同，但是当前的实现将它们视为单独的元数据。&lt;/li&gt;&#xA;&lt;li&gt;复杂的加入语法是采用的巨大障碍，普通的开发人员无法编写基本查询来访问资源属性。&lt;/li&gt;&#xA;&lt;li&gt;手动属性促销创建的操作开销，随着团队规模和复杂性的缩小范围很差。&lt;/li&gt;&#xA;&lt;li&gt; 78％的受访者发现文档差距是他们使用资源属性的挑战。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;图&#xA;class =“ figup-wrapper figuper-wrapper__lightbox W-100P”&#xA;样式=“最大宽度：无;”&#xA;itemprop =“ iSsectedmedia”&#xA;itemScope =“”&#xA;itemType =“ http://schema.org/imageObject”&#xA;&gt; &lt;a&#xA;class =“ Lightbox-link”&#xA;href =“ https://a-us.storyblok.com/f/1022730/622x494/f6be735f5a/prometheus-research-search-stats.png”&#xA;itemprop =“ contenturl”&#xA;&gt; &lt;div class =“ img-wrapper W-100P H-auto”&gt; &lt;img&#xA;class =“ Lazyload”&#xA;data-src =“ https://a-us.storyblok.com/f/10222730/6222x494/f6be735f5a/prometheus-research-stats.png” alt =“ Alt =” bar Chart显示出挑战，在Prometheus中与OpenTelemetry中的OpenTelemetry挑战。&#xA;&lt;NoScript&gt;&#xA;&lt;img&#xA;src =“ https://a-us.storyblok.com/f/1022730/622x494/f6be735f5a/prometheus-research-search-stats.png”&#xA;Alt =“条形图显示Prometheus中的OpenTelemetry的挑战。突出显示：“文档差距”被25位受访者评为非常具有挑战性。”/&gt;&#xA;&lt;/noscript&gt; &lt;/div&gt; &lt;/a&gt; &lt;/figie&gt;&#xA;&lt;p&gt;调查模式与我的定性研究中出现的结果一致。 &lt;/p&gt;&#xA;&lt;h2 id =“ What What We Whe-We-didnt-to-to-bearn but-did”&gt; &lt;strong&gt;我们没想到（但做过）&lt;/strong&gt; &lt;/h2&gt;&#xA;&lt;p&gt;我们开始了这项研究，以通过资源属性处理来了解用户痛点，但我们发现了一些意外而重要的发现。最令人惊讶的之一是意识到，&lt;a href =“ https://github.com/open-telemetry/opentelemetry/opentelemetry-specification/tree/main/main/specification/mmain/specification/Resource#telescoping/Resource#telescoping” target =“ _ _ vramp =” real =“ relopener noreferrer”&gt; noopener noreFerrer“ propertiber resource resource resource resoutder resouttion tocription”基于通过概念模式的相关性，有时被称为“望远镜”。 &lt;/p&gt;&#xA;&lt;p&gt;尽管有潜力，但许多用户甚至普罗米修斯社区的某些成员似乎都没有意识到这一点。缺乏意识可能有助于采用“联接”模式，此后事实证明这是有问题的。&lt;/p&gt;&#xA;&lt;p&gt;这也突出了一个更广泛的问题：&lt;strong&gt;文档和教育差距&lt;/strong&gt;是一个主要障碍。在我们的调查中，有78％的受访者将文件差距作为挑战。&lt;/p&gt;&#xA;&lt;p&gt;另一个关键的认识是，早期的集成决策，例如对加入的依赖，在没有完全了解每个工具的功能的情况下做出了。这是普罗米修斯和Opentelemetry社区之间缺乏早期合作和交流的不可避免的结果。&lt;/p&gt;&#xA;&lt;H2 ID =“推荐溶液”&gt; &lt;strong&gt;推荐解决方案&lt;/strong&gt; &lt;/h2&gt;&#xA;&lt;p&gt;基于与利益相关者和最终用户的对话，以下是一些拟议的解决方案，由短期中可行的与长期愿景的一部分进行分组。&lt;/p&gt;&#xA;&lt;H3 ID =“短期溶液”&gt; &lt;strong&gt;短期解决方案&lt;/strong&gt; &lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt; &lt;strong&gt;改进了属性处理的文档。&lt;/strong&gt;由于用户发现促进属性比加入目标信息更容易促进属性，因此在加入围绕JOIN的同时，它可能值得强调（甚至是日落）文档，同时进行&lt;a href =“ https：///prometheus.io.io.io/docs/guides/guides/guides/guides/guides/guides/guide-prometry-prometry-promomoting-promomoting-promoting-romoting-romoting-romoting-romoting-romoting-rimoting-risting&#39; target =“ _ blank” rel =“ noopener noreferrer”&gt;属性促销文档&lt;/a&gt;对于尚未知道该选项的人来说，更为突出。 Opentelemetry中资源检测的望远镜模式也值得更多可见性和适当的文档。此外，用户建议创建合并的Prometheus-opentelemetry文档，该文档清楚地说明了两个系统如何处理资源属性。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;H3 ID =“长期视觉”&gt; &lt;strong&gt;长期视觉&lt;/strong&gt; &lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt; &lt;strong&gt;实体框架。&lt;/strong&gt; opentelemetry的开发&lt;em&gt;实体概念&lt;/em&gt;可以帮助普罗米修斯（Prometheus）区分识别与描述性属性。这将指导哪些属性成为标签，哪些被存储或过滤出来。&lt;/li&gt;&#xA;&lt;li&gt; &lt;strong&gt;元数据存储。&lt;/strong&gt;利益相关者还讨论了在普罗米修斯本身中添加一流元数据支持的想法。这将允许某些资源属性作为元数据（不是标签）存储，避免了基数成本，同时保持信息可用于查询或加入。&lt;/li&gt;&#xA;&lt;li&gt; &lt;strong&gt;扩大探索性遥测。&lt;/strong&gt;这可能是一个伸展的范围，但是普罗米修斯可以考虑扩大其范围以更好地支持探索性遥测用例。只要普罗米修斯的核心架构完好无损并且现有用户没有疏远，利益相关者就会表现出开放的变化。这表明可能存在进化的空间，尤其是如果新功能可以补充而不是取代当前行为。&lt;/li&gt;&#xA;&lt;li&gt; &lt;strong&gt;交叉信号相关性。&lt;/strong&gt;用户提到的是使用可以摄取所有遥测类型并在单个系统中摄入所有遥测类型并将日志相关的平台。虽然普罗米修斯可能只专注于指标，但它可以启用与存储在其他数据库中的遥测相关的工具es。 Prometheus currently supports &lt;a href=&#34;https://prometheus.io/docs/specs/om/open_metrics_spec/#exemplars&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;exemplars&lt;/a&gt;, which allow linking metrics to traces, but that’s about the extent of their scope.他们依靠跟踪存在，这使得它们在没有痕迹或没有仪器的环境中有用。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;这种跨信号相关性是普罗米修斯在现代可观察性工作流程中扩大其实用性的机会，而不会改变其对指标存储的核心关注。 &lt;/p&gt;&#xA;&lt;p&gt; &lt;em&gt;“ OpenCensus中的关键创新性事物之一是……您可以通过请求使用CPU并获得一个指标的CPU用法，并获得‘这是‘这是通过请求使用的CPU用法。’这是您可以在OpenCensus中完成的事情，因为这都是基于上下文的基于上下文的指标。” -Josh Suereth &lt;/em&gt; &lt;/p&gt;&#xA;&lt;p&gt;仍然有工作要做。社区将需要时间来开发和测试解决方案。但是我为这项研究提供了以用户为中心的基础，我感到自豪。&lt;/p&gt;&#xA;&lt;p&gt;如果您对这些想法的正在进行的讨论，建议和反馈感兴趣，则可以查看所有内容都在记录的GitHub存储库中：&lt;a href =“ https://prometheus/prometheus/prometheus-community/ux-community/ux-research/ux-research/tree/tree/tree/main/main/main/prom-prom-prom-prom-prom-prom-prom-prom-prom-prom-otel-research noore =” Prometheus UX研究中的资源属性&lt;/a&gt; &lt;/p&gt;&#xA;&lt;H2 ID =“确认”&gt; &lt;strong&gt; bengrygments &lt;/strong&gt; &lt;/h2&gt;&#xA;&lt;p&gt;，如果我不承认Grafana Labs的令人难以置信的导师：Amy Super，Andrej Kiripolsky和Arthur Silva Sens。您是真正的超级巨星。&lt;/p&gt;&#xA;&lt;p&gt;对分享时间和观点的所有利益相关者和用户，感谢您参与研究并以诚实的反馈来信任我。您的故事和挫败感使这项研究有意义。&lt;/p&gt;&#xA;&lt;p&gt;和grafanistas的几个单词：&lt;/p&gt;&#xA;&lt;p&gt; &lt;em&gt;“感谢&lt;/em&gt; &lt;em&gt; &lt;strong&gt;您，&lt;/strong&gt; &lt;/em&gt; &lt;em&gt; victoria，将这项研究登上了终点线。您已经勇于面对恐惧和令人难以置信的奉献精神。&#xA;&lt;p&gt; &lt;em&gt;我们还要感谢Grafana Labs的文化，这总是鼓励我们为Opentelemetry，Prometheus和其他开源社区做出有意义的贡献！” &lt;/em&gt; &lt;/em&gt; &lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt; &lt;em&gt; Andrej，Amy和Arthur &lt;/em&gt; &lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;H2 ID =“ What&#39;&gt; &lt;strong&gt;我接下来是什么&lt;/strong&gt; &lt;/h2&gt;&#xA;&lt;p&gt;我很高兴能继续在UX和云本机系统的交叉点工作。如果您在此领域有与该指导相似的机会，请通过&lt;a href =“ https://www.linkedin.com/in/victorianduka/” target =“ _ _ black” rel =“ noopener noreferrer” noopener noreferrer“&gt;mail.com”&gt;电子邮件&lt;/a&gt;。我是一个勤奋的人 - 只是问我的导师。&lt;/p&gt;&#xA;&lt;p&gt; &lt;em&gt; &lt;a href =“/products/cloud/？pg = blog＆plcmt = body-txt”&gt; grafana cloud &lt;/a&gt; &lt;/em&gt; &lt;em&gt;是开始使用指标，日志，痕迹，仪表，仪表板等最简单的方法。我们有一个宽敞的永远的层次和计划。&lt;/em&gt; &lt;em&gt; &lt;a href =“/auth/auth/insip/create-user/？pg = blog＆plcmt = body-txt = body-txt”&gt;现在免费注册！&lt;/a&gt; &lt;/a&gt; &lt;/em&gt; &lt;/em&gt; &lt;/p&gt; &lt;/em&gt; &lt;/p&gt;</description>
      <pubDate>Thu, 28 Aug 2025 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Optimize application performance at the network layer: introducing HTTP Performance Insights in Frontend Observability】优化网络层的应用程序性能：在前端可观察性中引入HTTP性能见解</title>
      <link>https://grafana.com/blog/2025/08/27/optimize-application-performance-at-the-network-layer-introducing-http-performance-insights-in-frontend-observability/</link>
      <description>【&lt;p&gt;Imagine you’re a frontend engineer monitoring the user experience for an e-commerce app. You notice your checkout flow has a 15% abandonment rate. Your API responses are inconsistent. Your users are frustrated, and you&amp;rsquo;re drowning in data and complex queries trying to figure out why. Sound familiar? &lt;/p&gt;&#xA;&lt;p&gt;You can use real user monitoring (RUM) to determine &lt;em&gt;what&lt;/em&gt; has happened, looking at page load times, error counts, user sessions, etc. But when performance issues strike, you also need to know &lt;em&gt;why&lt;/em&gt; they happened and &lt;em&gt;where&lt;/em&gt; to focus your optimization efforts. &lt;/p&gt;&#xA;&lt;p&gt;This is exactly where &lt;a href=&#34;/whats-new/2025-07-21-http-performance-insights/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;HTTP Performance Insights&lt;/a&gt;, a new feature in &lt;a href=&#34;/products/cloud/frontend-observability/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Cloud Frontend Observability&lt;/a&gt;, comes in. With HTTP Performance Insights, you can go beyond basic metrics with aggregated views that surface actionable signals, so you can quickly identify and resolve application performance issues at the network layer.&lt;/p&gt;&#xA;&lt;p&gt;Here, we’ll explore the key features of HTTP Performance Insights, and offer an early look at the broader performance intelligence platform we’re building out in Frontend Observability. &lt;/p&gt;&#xA;&lt;h2 id=&#34;http-performance-insights-clear-actionable-data-to-drive-results&#34;&gt;HTTP Performance Insights: clear, actionable data to drive results &lt;/h2&gt;&#xA;&lt;p&gt;HTTP Performance Insights offers a comprehensive view into your application’s HTTP requests, allowing you to monitor request quality and detect bottlenecks in real time. Instead of reactive firefighting, teams can use HTTP Performance Insights to proactively identify performance issues and address them before they impact the user experience. &lt;/p&gt;&#xA;&lt;h3 id=&#34;performance-dashboards-that-highlight-the-network-layer&#34;&gt;Performance dashboards that highlight the network layer&lt;/h3&gt;&#xA;&lt;p&gt;The HTTP Performance Insights interface shows not just raw numbers, but health indicators, color-coding, and other trend analysis features to guide your attention to what matters most. &lt;/p&gt;&#xA;&lt;p&gt;To start your investigation, navigate to the &lt;strong&gt;HTTP&lt;/strong&gt; tab in Frontend Observability. You can use the metrics across the top of the dashboard — including &lt;strong&gt;total requests&lt;/strong&gt;, &lt;strong&gt;error totals&lt;/strong&gt;, and &lt;strong&gt;error rate&lt;/strong&gt; — to evaluate backend responsiveness, and protectively identify and address issues affecting frontend performance. You can also reference &lt;strong&gt;time to first byte&lt;/strong&gt; and &lt;strong&gt;transfer size&lt;/strong&gt; to identify further opportunities for optimization. &lt;/p&gt;&#xA;&lt;p&gt;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: none;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;https://a-us.storyblok.com/f/1022730/1565x784/5cd33a02f1/http-performance-insights-dashboard-1.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;https://a-us.storyblok.com/f/1022730/1565x784/5cd33a02f1/http-performance-insights-dashboard-1.png&#34;alt=&#34;A Grafana Cloud dashboard displaying performance metrics, including response times, requests per second, and error rates.&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;https://a-us.storyblok.com/f/1022730/1565x784/5cd33a02f1/http-performance-insights-dashboard-1.png&#34;&#xA;alt=&#34;A Grafana Cloud dashboard displaying performance metrics, including response times, requests per second, and error rates.&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt; The actionable breakdowns below those top-level metrics help you identify your biggest problems first. Sortable tables pinpoint your slowest endpoints, largest requests, and most error-prone calls. With this data, you can quickly answer questions like:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Are image assets causing performance bottlenecks?&lt;/li&gt;&#xA;&lt;li&gt;Is a specific API endpoint generating most user errors?&lt;/li&gt;&#xA;&lt;li&gt;Which domains are consuming the most bandwidth?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;The time series visualization lets you track trends and quickly correlate issues with potential causes. You can also look for clusters of errors to correlate issues against deployments, traffic spikes, or external dependencies.  &lt;/p&gt;&#xA;&lt;h3 id=&#34;deep-dives-into-problematic-endpoints&#34;&gt;Deep dives into problematic endpoints &lt;/h3&gt;&#xA;&lt;p&gt;When you identify a problematic endpoint with a high error rate, you can drill down for granular analysis. The &lt;strong&gt;single endpoint&lt;/strong&gt; view provides request-level granularity, showing individual requests, their performance characteristics, and timing breakdowns.&lt;/p&gt;&#xA;&lt;p&gt;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: none;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;https://a-us.storyblok.com/f/1022730/1568x599/bf0008c664/https-performance-insights-dashboard-2.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;https://a-us.storyblok.com/f/1022730/1568x599/bf0008c664/https-performance-insights-dashboard-2.png&#34;alt=&#34;A Grafana Cloud dashboard displaying metrics like response time and data usage for a specific endpoint.&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;https://a-us.storyblok.com/f/1022730/1568x599/bf0008c664/https-performance-insights-dashboard-2.png&#34;&#xA;alt=&#34;A Grafana Cloud dashboard displaying metrics like response time and data usage for a specific endpoint.&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt; This level of detail enables precise troubleshooting. You can see exactly which requests are outliers, understand request size patterns, and correlate performance with specific user sessions or geographic regions. The same rich visualization suite applies at this focused level, giving you consistent analytical capabilities whether you&amp;rsquo;re looking at the big picture or investigating a specific issue.&lt;/p&gt;&#xA;&lt;h2 id=&#34;get-started-with-http-performance-insights&#34;&gt;Get started with HTTP Performance Insights&lt;/h2&gt;&#xA;&lt;p&gt;HTTP Performance Insights is available now in public preview. You can access it in Grafana Cloud Frontend Observability by navigating to the &lt;strong&gt;HTTP&lt;/strong&gt; tab. The feature automatically analyzes your existing HTTP request data, so there&amp;rsquo;s no additional instrumentation required.&lt;/p&gt;&#xA;&lt;p&gt;We recommend first exploring the HTTP overview to identify performance patterns and problematic endpoints. Then, you can use the drill-down capabilities to investigate specific issues and correlate them with user impact.&lt;/p&gt;&#xA;&lt;h2 id=&#34;whats-next&#34;&gt;What&amp;rsquo;s next&lt;/h2&gt;&#xA;&lt;p&gt;HTTP Performance Insights represents our first step towards building out a broader set of performance intelligence capabilities within Grafana Cloud Frontend Observability. We’re currently working to add the following features, which will also offer actionable views to help you correlate performance metrics to the user experience:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Page Performance Insights&lt;/strong&gt;: Comprehensive analysis of loading, rendering, and Web Vitals with resource utilization breakdowns&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Resource Loading Intelligence&lt;/strong&gt;: Deep visibility into static assets, their impact on performance, and optimization opportunities&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Integrated User Experience Views&lt;/strong&gt;: Timeline-based analysis showing how performance issues affect real user journeys&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;We are building with user needs in mind — so we welcome your feedback! &lt;/p&gt;&#xA;&lt;p&gt;To learn more about HTTP Performance Insights, please visit our &lt;a href=&#34;/docs/grafana-cloud/monitor-applications/frontend-observability/http-insights/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;docs.&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;/products/cloud/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt;&lt;/em&gt; &lt;em&gt;is the easiest way to get started with metrics, logs, traces, dashboards, and more. We have a generous forever-free tier and plans for every use case.&lt;/em&gt; &lt;em&gt;&lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Sign up for free now!&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;】&lt;p&gt;想象您是一名前端工程师，监视电子商务应用程序的用户体验。您会注意到您的结帐流量的放弃率为15％。您的API响应不一致。您的用户感到沮丧，您正在淹没数据和复杂的查询，试图弄清楚原因。听起来很熟悉吗？ &lt;/p&gt;&#xA;&lt;p&gt;您可以使用真实的用户监视（朗姆酒）来确定&lt;em&gt;发生了什么，查看页面加载时间，错误计数，用户会话等。但是，当绩效问题爆发时，您还需要知道&lt;em&gt;为什么会发生&lt;/em&gt;他们会发生&lt;/em&gt; &lt;/em&gt; &lt;/em&gt; &lt;/em&gt;才能集中优化工作。 &lt;/p&gt;&#xA;&lt;p&gt;这到底是&lt;a href =“/Whats-new/2025-07-21-HTTP-Performance-Insights/？pg = blog＆plcmt = body-txt = http绩效见解&lt;/a&gt;可观察性&lt;/a&gt;，进来。使用HTTP性能洞察，您可以超越基本指标，具有表面可操作的信号的汇总视图，因此您可以快速识别并解决网络层的应用程序性能问题。&lt;/p&gt; &lt;/p&gt;&#xA;&lt;p&gt;在这里，我们将探讨HTTP性能见解的关键特征，并尽早查看我们在前端可观察性中构建的更广泛的性能智能平台。 &lt;/p&gt;&#xA;&lt;h2 id =“ http-performance-ignights-clear-callable-data-to-data-to-drive-results”&gt; http performance Insights：清晰，可行的数据以驱动结果&lt;/h2&gt;&#xA;&lt;p&gt; HTTP Performance Insights对应用程序的HTTP请求提供了全面的视图，从而可以监视请求质量并实时检测瓶颈。团队可以使用HTTP绩效见解来主动识别性能问题并在影响用户体验之前解决这些问题，而不是反应性的消防。 &lt;/p&gt;&#xA;&lt;h3 id =“ performance-dashboards-that-that-the-the-the-network-layer”&gt;性能仪表板，突出显示网络层&lt;/h3&gt;&#xA;&lt;p&gt; HTTP性能见解界面不仅显示原始数字，还显示健康指标，颜色编码和其他趋势分析功能，以指导您对最重要的关注。 &lt;/p&gt;&#xA;&lt;p&gt;要开始调查，请在前端可观察性中导航到&lt;strong&gt; http &lt;/strong&gt;选项卡。您可以使用仪表板顶部的指标 - 包括&lt;strong&gt;总请求&lt;/strong&gt;，&lt;strong&gt;错误总计&lt;/strong&gt;和&lt;strong&gt;错误率&lt;/strong&gt;  - 评估后端响应性，并保护并解决影响前端性能的问题。您还可以参考第一个字节&lt;/strong&gt;和&lt;strong&gt;转移大小&lt;/strong&gt;的时间&lt;/strong&gt;，以确定进一步的优化机会。 &lt;/p&gt;&#xA;&lt;p&gt; &lt;图&#xA;class =“ figup-wrapper figuper-wrapper__lightbox W-100P”&#xA;样式=“最大宽度：无;”&#xA;itemprop =“ iSsectedmedia”&#xA;itemScope =“”&#xA;itemType =“ http://schema.org/imageObject”&#xA;&gt; &lt;a&#xA;class =“ Lightbox-link”&#xA;href =“ https://a-us.storyblok.com/f/1022730/1565x784/5cd33a02f1/http-performance-intformance-intformance-inlights-intights-dashboards-dashboard-1.png-1.png”&#xA;itemprop =“ contenturl”&#xA;&gt; &lt;div class =“ img-wrapper w-100p h-auto”&gt; &lt;img&#xA;class =“ Lazyload”&#xA;data-src =“ https://a-us.storyblok.com/f/10222730/1565x784/5cd33a02f1/http-performance-performance-intights-intights-ingights-dashboards-dashboard-dashboard-1.png” alt =“ Alt =” Alt =“ Grafana Cloud cloud cloud cloud cloud dashboard显示响应仪表，包括响应时间，包括响应时间，请求时间，每个要求，每秒，第二个/&gt;&#xA;&lt;NoScript&gt;&#xA;&lt;img&#xA;src =“ https://a-us.storyblok.com/f/1022730/1565x784/5cd33a02f1/http-performance-intformance-intformance-interformance-inlights-ingights-dashboard-dashboard-1.png-1.png”&#xA;Alt =“ Grafana Cloud仪表板显示性能指标，包括响应时间，每秒请求和错误率。”/&gt;&#xA;&lt;/noscript&gt; &lt;/div&gt; &lt;/a&gt; &lt;/figue&gt;在这些顶级指标下方可行的分解可帮助您首先确定最大的问题。可排序表查明您最慢的端点，最大请求和最容易出错的调用。有了这些数据，您可以快速回答以下问题：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;图像资产是否导致性能瓶颈？&lt;/li&gt;&#xA;&lt;li&gt;是生成大多数用户错误的特定API端点吗？&lt;/li&gt;&#xA;&lt;li&gt;哪些域消耗最多的带宽？&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;时间序列可视化使您可以跟踪趋势并迅速将问题与潜在原因相关联。您还可以寻找错误群，以将问题与部署，流量尖峰或外部依赖关系相关联。  &lt;/p&gt;&#xA;在&#xA;&lt;p&gt;当您以高错误率确定有问题的端点时，您可以向下钻取颗粒状分析。 &lt;strong&gt;单端点&lt;/strong&gt;视图提供了请求级粒度，显示单个请求，其性能特征和时机崩溃。&lt;/p&gt;&#xA;&lt;p&gt; &lt;图&#xA;class =“ figup-wrapper figuper-wrapper__lightbox W-100P”&#xA;样式=“最大宽度：无;”&#xA;itemprop =“ iSsectedmedia”&#xA;itemScope =“”&#xA;itemType =“ http://schema.org/imageObject”&#xA;&gt; &lt;a&#xA;class =“ Lightbox-link”&#xA;href =“ https://a-us.storyblok.com/f/1022730/1568x599/bf0008c664/https-performance-istermance-insights-dashboard-dashboard-2.png”&#xA;itemprop =“ contenturl”&#xA;&gt; &lt;div class =“ img-wrapper W-100P H-auto”&gt; &lt;img&#xA;class =“ Lazyload”&#xA;data-src =“ https://a-us.storyblok.com/f/1022730/1568x599/bf0008c664/https-performance-insights-insights-dashboards-dashboard-dashboard-2.png“ alt =” Alt =“ Grafana cloud云仪表板显示响应时间和数据的指标，例如特定的端点，&#xA;&lt;NoScript&gt;&#xA;&lt;img&#xA;src =“ https://a-us.storyblok.com/f/1022730/1568x599/bf0008c664/https-performance-insights-insights-dashboard-2.png”&#xA;alt =“ grafana云仪表板显示指标，例如响应时间和特定端点的数据使用。”/&gt;&#xA;&lt;/noscript&gt; &lt;/div&gt; &lt;/a&gt; &lt;/figue&gt;此详细信息可以进行精确的故障排除。您可以准确查看哪些请求是异常值，了解请求大小模式，并将绩效与特定的用户会话或地理区域相关联。相同的丰富可视化套件适用于此重点级别，无论您是查看大局还是调查特定问题，都可以使您保持一致的分析能力。&lt;/p&gt;&#xA;&lt;h2 id =“与http-performance-Insights一起启动”&gt;开始HTTP性能见解&lt;/h2&gt;&#xA;&lt;p&gt; HTTP性能见解现已在公共预览中获得。您可以通过导航到&lt;strong&gt; http &lt;/strong&gt;选项卡中的Grafana Cloud Frontend可观察性访问它。该功能会自动分析您现有的HTTP请求数据，因此无需其他仪器。&lt;/p&gt;&#xA;&lt;p&gt;我们建议首先探索HTTP概述，以识别性能模式和有问题的终点。然后，您可以使用钻取功能来研究特定问题并将其与用户影响相关联。&lt;/p&gt;&#xA;&lt;H2 ID =“ Whats-Next”&gt;下一步是什么&#xA;&lt;p&gt; HTTP性能见解是我们在Grafana Cloud前端可观察性中建立更广泛的性能智能功能的第一步。我们目前正在努力添加以下功能，该功能还将提供可行的视图，以帮助您将性能指标与用户体验相关联：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt; &lt;strong&gt;页面绩效见解&lt;/strong&gt;：对负载，渲染和Web生命的全面分析，并具有资源利用分解&lt;/li&gt;&#xA;&lt;li&gt; &lt;strong&gt;资源加载智能&lt;/strong&gt;：对静态资产的可见性，对绩效的影响和优化机会&lt;/li&gt;&#xA;&lt;li&gt; &lt;strong&gt;集成的用户体验视图&lt;/strong&gt;：基于时间表的分析，显示绩效问题如何影响真正的用户旅程&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;我们正在牢记用户需求，因此我们欢迎您的反馈！ &lt;/p&gt;&#xA;&lt;p&gt;要了解有关HTTP性能见解的更多信息，请访问我们的&lt;a href =“/docs/docs/grafana-cloud/monitor-applications/frontend-observability/http-insights/？pg = blog＆plcmt＆plcmt＆plcmt = body-txt = body-txt = docs。&#xA;&lt;p&gt; &lt;em&gt; &lt;a href =“/products/cloud/？pg = blog＆plcmt = body-txt”&gt; grafana cloud &lt;/a&gt; &lt;/em&gt; &lt;em&gt;是开始使用指标，日志，痕迹，仪表，仪表板等最简单的方法。我们有一个宽敞的永远的层次和计划。&lt;/em&gt; &lt;em&gt; &lt;a href =“/auth/auth/insip/create-user/？pg = blog＆plcmt = body-txt = body-txt”&gt;现在免费注册！&lt;/a&gt; &lt;/a&gt; &lt;/em&gt; &lt;/em&gt; &lt;/p&gt; &lt;/em&gt; &lt;/p&gt;</description>
      <pubDate>Wed, 27 Aug 2025 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Inside Grafana Labs’ Voice of Customer program: what’s new and what’s next】内部Grafana Labs的客户计划：什么是新事物和下一步</title>
      <link>https://grafana.com/blog/2025/08/26/inside-grafana-labs-voice-of-customer-program-whats-new-and-whats-next/</link>
      <description>【&lt;p&gt;At Grafana Labs, &lt;em&gt;openness&lt;/em&gt; isn’t just our approach to building software — it’s a core company value that reflects how we engage with our community. This includes being transparent about how we collect product feedback, how it’s reviewed, and how it informs what we build.&lt;/p&gt;&#xA;&lt;p&gt;We’re always striving to tighten the loop between what our users ask for and what we prioritize in R&amp;amp;D. Our Voice of Customer (VoC) program — a centralized effort to collect, triage, and share product feedback from our user base — is one of the key ways we achieve this. &lt;/p&gt;&#xA;&lt;p&gt;In this post, we’ll unpack what the VoC program is, share real examples of how it’s shaped product direction here at Grafana Labs, and highlight recent updates like our new customer-facing portal.&lt;/p&gt;&#xA;&lt;h2 id=&#34;voc-program-what-it-is-and-why-it-matters&#34;&gt;VoC program: what it is and why it matters&lt;/h2&gt;&#xA;&lt;p&gt;Our VoC program began as a simple spreadsheet that helped us log incoming requests from &lt;a href=&#34;/products/cloud/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt; users. But as feedback grew, so did the need for structure. &lt;/p&gt;&#xA;&lt;p&gt;We introduced reporting, analysis, regular reviews, and tighter alignment with product and engineering. Today, VoC acts as a structured, reliable signal that helps teams spot patterns, validate use cases, and build with more context.&lt;/p&gt;&#xA;&lt;p&gt;We have a dedicated team focused on this work, with individual team members aligned to specific product areas. This dedicated team reviews and triages every request for our product and engineering teams, and themes and trends are regularly analyzed and shared.&lt;/p&gt;&#xA;&lt;p&gt;Having a dedicated team means we can keep this process consistent and scalable. It also helps us spot and connect related requests across different areas of our product portfolio — something that’s easy to miss in more fragmented setups.&lt;/p&gt;&#xA;&lt;p&gt;About 35% of the requests submitted through our Voice of Customer program have been &lt;em&gt;actioned&lt;/em&gt; — meaning they’ve either been accepted and are in progress, or have already resulted in new features or initiatives. While we’ve anecdotally heard estimates like 10–15% from other product teams, we haven’t found any reliable industry benchmarks to compare against. For now, 35% is our current baseline, and we’re focused on improving it as the program grows.&lt;/p&gt;&#xA;&lt;h3 id=&#34;examples-of-voc-impact&#34;&gt;Examples of VoC impact &lt;/h3&gt;&#xA;&lt;p&gt;Running Grafana Cloud at scale internally gives us a unique perspective, but we know our needs aren’t always the same as our customers’. We strive to meet a broad range of use cases, environments, and operational realities.&lt;/p&gt;&#xA;&lt;p&gt;Voice of the Customer plays a key role in ensuring that we’re not only optimizing for our own experience. It helps us identify patterns across users and build for the widest possible impact.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;“As our products evolve, we always want to ensure we are building features that align with our customer use cases,” said Ryan Kehoe, Staff Product Manager at Grafana Labs. “VoC has been critical in providing my teams with direct customer feedback through all phases of the software delivery lifecycle so we can build with confidence and pivot if we miss the mark.”&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;Here’s a look at some recent product updates — and on-going initiatives — that have been shaped heavily by VoC user feedback:&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Expanding RBAC across products&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;One of the most consistently requested capabilities across VoC feedback is fine-grained access control — not just in one area, but across our stack. Thanks to this signal, we&amp;rsquo;ve shipped RBAC capabilities and improvements across multiple Grafana Cloud features, including &lt;a href=&#34;/docs/grafana-cloud/monitor-applications/frontend-observability/rbac/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Frontend Observability&lt;/a&gt;, Alerting (&lt;a href=&#34;/whats-new/2024-06-06-rule-specific-silences-with-rbac/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;silences&lt;/a&gt;, &lt;a href=&#34;/whats-new/2025-01-22-rbac-for-alerting-notifications/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;contact points&lt;/a&gt;, &lt;a href=&#34;/docs/grafana/latest/alerting/set-up/configure-rbac/access-folders/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;subfolders&lt;/a&gt;, &lt;a href=&#34;/docs/grafana-cloud/machine-learning/dynamic-alerting/rbac/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Dynamic alerting&lt;/a&gt;, and &lt;a href=&#34;/whats-new/2025-01-22-rbac-for-notification-policies/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;notification policies&lt;/a&gt;), &lt;a href=&#34;/whats-new/2025-05-20-rbac-for-synthetic-monitoring-is-generally-available/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Synthetic Monitoring&lt;/a&gt;, and &lt;a href=&#34;/docs/grafana-cloud/alerting-and-irm/irm/manage/users-and-teams/?pg=blog&amp;amp;plcmt=body-txt/#role-based-access-control-rbac&#34;&gt;IRM&lt;/a&gt;. This continues to be a major theme for us and we are committed to expanding and refining RBAC support over time.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Improving cost visibility and control&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;Cost control and attribution have been a significant theme in user feedback, especially from teams managing multiple environments or stakeholders. In response, we’ve launched several foundational improvements, including updates to our billing dashboards and usage APIs, to help teams understand where the spend is going. We’ve also introduced &lt;a href=&#34;/blog/2025/01/14/what-is-adaptive-telemetry-and-how-can-it-reduce-mttr-noise-and-cost/&#34;&gt;Adaptive Telemetry&lt;/a&gt; to help reduce noise and manage cost without losing critical observability signals. &lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;“It was crucial for our organization to have an in-depth volume and cost breakdown of telemetry for monthly internal chargebacks, and to ensure compliance of cost centers against set budgets. To our delight, Grafana was able to deliver the necessary component,” said Peter Vernigorov, Principal Engineer at Delivery Hero. “They took the time to understand our needs by collaborating with our observability and FinOps engineers, and we really appreciated their quick iterative approach.” &lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;Programmatic workflows: Terraform, APIs, and Git Sync&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;Another recurring theme in user feedback has been the need to manage Grafana programmatically. This shows up across products: requests for more Terraform coverage, better APIs, and Git-based workflows for dashboards and configurations. In response, we continue to &lt;a href=&#34;/blog/2025/05/07/observability-as-code-grafana-12/#new-terraform-resource&#34;&gt;expand our Terraform provider&lt;/a&gt; to cover more resources, and &lt;a href=&#34;/blog/2025/05/07/grafana-12-release-all-the-new-features/#git-sync&#34;&gt;introduced Git Sync&lt;/a&gt; — an observability as code tool that brings Git workflows directly into the Grafana UI — in the &lt;a href=&#34;/blog/2025/05/07/grafana-12-release-all-the-new-features/&#34;&gt;Grafana 12 release&lt;/a&gt;. &lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Secrets management for Grafana Cloud Synthetic Monitoring&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;A top request from users running synthetic checks in production environments has been the ability to securely store and inject sensitive values without hardcoding them in scripts. Today, that’s difficult to do safely, which introduces risk and complicates compliance. We’re actively building a secure secrets management flow that allows sensitive data to be stored in a backend secrets store, injected into scripts as environment variables, and fully hidden from the UI and logs. &lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;“Secrets management kept coming up again and again in our Voice of the Customer feedback. It was one of the biggest pain points for Synthetic Monitoring users and a real blocker for adoption,” said Mark Meier, Staff Product Manager at Grafana Labs. “Having that VoC data made a huge difference, helping turn user feedback into real momentum.”&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;Stay tuned for more updates. &lt;/p&gt;&#xA;&lt;h2 id=&#34;whats-new-the-voc-customer-facing-portal&#34;&gt;What’s new: the VoC customer-facing portal&lt;/h2&gt;&#xA;&lt;p&gt;We’ve rolled out a customer-facing Feature Request Portal to make our feedback process more efficient and transparent. &lt;/p&gt;&#xA;&lt;p&gt;Previously, all feedback would be filtered manually through Grafana Labs account teams. Now, with the new VoC portal, users can see what’s already been requested, vote or comment on those requests with additional context, and track ideas across their organization.&lt;/p&gt;&#xA;&lt;p&gt;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: none;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;https://a-us.storyblok.com/f/1022730/1999x800/c005e08f65/voc-portal-screenshot.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;https://a-us.storyblok.com/f/1022730/1999x800/c005e08f65/voc-portal-screenshot.png&#34;alt=&#34;A screenshot of the new Voice of Customer portal.&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;https://a-us.storyblok.com/f/1022730/1999x800/c005e08f65/voc-portal-screenshot.png&#34;&#xA;alt=&#34;A screenshot of the new Voice of Customer portal.&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt; Customers can now:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Submit and view all Grafana Labs feature requests&lt;/li&gt;&#xA;&lt;li&gt;Upvote existing feature requests&lt;/li&gt;&#xA;&lt;li&gt;Comment to clarify use cases&lt;/li&gt;&#xA;&lt;li&gt;Track requests their org has submitted or supported&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;When users can easily see and engage with existing ideas, we get a clearer view of which requests are shared and gaining traction. It also allows people to gauge the popularity of something they are interested in compared to other ideas.&lt;/p&gt;&#xA;&lt;p&gt;If you&amp;rsquo;re a Grafana Cloud user, you can log in to the &lt;a href=&#34;https://grafana.ideas.aha.io/?pg=blog&amp;amp;plcmt=body-txt&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Feature Request Portal&lt;/a&gt; today to view, vote on, and submit ideas directly to Grafana Labs.&lt;/p&gt;&#xA;&lt;h2 id=&#34;whats-next-extending-the-reach-of-voc&#34;&gt;What’s next: extending the reach of VoC&lt;/h2&gt;&#xA;&lt;p&gt;The Voice of Customer program started by focusing on all Grafana Cloud customers. These customers often run our products in complex environments, rely on tightly integrated features, and generate high-signal feedback that’s directly tied to day-to-day workflows. This was a natural starting point as we built out our structure, scale, and process for the VoC program.&lt;/p&gt;&#xA;&lt;p&gt;But our roots are in open source, and we know that some of our most thoughtful feedback comes from our OSS community. Community input has always been part of the picture — through GitHub issues, forums, Slack, and direct conversations — but it’s often reached teams informally and inconsistently.&lt;/p&gt;&#xA;&lt;p&gt;Now, we’re working to integrate that feedback more systematically. The next phase of the VoC program involves partnering with teams across Grafana Labs to ensure that input from our open source users is captured, distilled, and represented alongside our cloud customer signals. This isn’t about replacing those processes for collecting feedback, but expanding the scope. &lt;/p&gt;&#xA;&lt;p&gt;Lastly, we want to thank everyone who’s taken the time to share feedback — whether it’s through the feature request portal, GitHub issues, Slack threads, Technical Support, or hallway conversations at an event. You’ve helped shape the products we’re building, and we’re so grateful for your input. &lt;/p&gt;&#xA;&lt;h2 id=&#34;voice-of-customer-program-faqs&#34;&gt;Voice of Customer program FAQs&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;What is the Voice of the Customer program at Grafana Labs?&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;The Voice of Customer (VoC) program is our structured approach to collecting, analyzing, and actioning on product feedback from our users. It serves as a centralized, reliable signal that helps our team spot patterns, validate use cases, and build with more context. While running Grafana Cloud internally gives us deep insight, VoC ensures we are not just building for our own needs, but for the broad range of environments, challenges, and realities our users face.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;How does Grafana Labs prioritize VoC feature requests?&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;We prioritize feature requests based on the number of organizations asking for the same thing — not individual votes. A single vote from 10 different companies carries more weight than 10 votes from the same company. This approach helps us ensure that we&amp;rsquo;re investing in features that solve widespread problems. &lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;When will my feature request be reviewed?&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;In most cases, feature requests are prioritized for review once we see interest from multiple organizations. We look for themes and patterns across our customer base so we can focus on building solutions that have broad impact. That said, there are cases where requests get reviewed earlier, especially if they align with something already on the roadmap or support a strategic initiative. While multi-org interest is the most common trigger, it&amp;rsquo;s not the only one. Every request is captured and visible to our Product team.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;How long does it take from submission &amp;gt; review &amp;gt; launch?&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;There’s no guaranteed timeline from submission to review to launch. It depends on several factors: how many customers are asking, how the request aligns with our current strategy and roadmap, and what other work is already in motion. Even if a request is prioritized for review, that doesn’t always mean it will be built. We aim to solve the right problems in the most scalable way, sometimes finding alternate paths or grouping similar feedback.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;What about community feedback?&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;Community feedback has always been valuable to our product improvement. We hear from users through GitHub issues, forums, community Slack, and direct conversations, and that input has shaped many features over the years.&lt;/p&gt;&#xA;&lt;p&gt;Those channels aren’t going away. If you&amp;rsquo;re already sharing feedback through GitHub or other public forums, please keep doing what you&amp;rsquo;re doing. That signal is important, and it’s not being replaced.&lt;/p&gt;&#xA;&lt;p&gt;We’re working to better connect that feedback to the broader Voice of Customer program so that insights from open source users are captured more consistently and represented alongside what we hear from cloud customers. This will help us spot shared patterns across all users, regardless of how or where they run Grafana.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;How can I learn more about Voice of Customer?&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;You can visit the &lt;a href=&#34;https://grafana.ideas.aha.io/sections/7518058178676519123&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Resources tab&lt;/a&gt; in the VoC portal to find information on using the portal, answers to common questions, and more details on our processes. For any other questions, contact &lt;a href=&#34;mailto:voc-shared-inbox@grafana.com&#34;&gt;voc-shared-inbox@grafana.com&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;/products/cloud/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt;&lt;/em&gt; &lt;em&gt;is the easiest way to get started with metrics, logs, traces, dashboards, and more. We have a generous forever-free tier and plans for every use case.&lt;/em&gt; &lt;em&gt;&lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Sign up for free now!&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;】&lt;p&gt;在Grafana Labs，&lt;em&gt;开放性&lt;/em&gt;不仅是我们构建软件的方法，而且是反映我们与社区互动的核心公司价值。这包括关于我们如何收集产品反馈，如何审查以及如何告知我们构建的内容的透明度。&lt;/p&gt;&#xA;&lt;p&gt;我们一直在努力收紧用户要求的循环以及在研发中优先考虑的循环。我们的客户（VOC）计划的声音是从用户群中收集，分类和分享产品反馈的集中式努力 - 是我们实现这一目标的关键方法之一。 &lt;/p&gt;&#xA;&lt;p&gt;在这篇文章中，我们将解开VOC程序是什么，分享Grafana Labs的形状指导方式的真实示例，并重点介绍了诸如我们的新客户门户网站之类的最新更新。&lt;/p&gt;&#xA;在&#xA;&lt;p&gt;我们的VOC程序始于一个简单的电子表格，它帮助我们从&lt;a href =“/products/cloud/cloud/？pg = blog＆plcmt = body-txt”&gt; grafana cloud cloud &lt;/a&gt;用户记录了传入请求。但是随着反馈的增长，对结构的需求也随之增加。 &lt;/p&gt;&#xA;&lt;p&gt;我们介绍了报告，分析，定期审查以及与产品和工程的更严格的一致性。如今，VOC充当一个结构化的，可靠的信号，可帮助团队发现模式，验证用例并使用更多上下文构建。&lt;/p&gt;&#xA;&lt;p&gt;我们有一个专门的团队专注于这项工作，单个团队成员与特定的产品领域保持一致。定期分析和共享这个专门的团队评论和三叶草的每个请求，以及主题和趋势。&lt;/p&gt;。&lt;/p&gt;&#xA;&lt;p&gt;拥有一个专门的团队意味着我们可以保持这一过程一致且可扩展。它还可以帮助我们在产品组合的不同领域发现并连接相关请求 - 在更零散的设置中很容易错过。&lt;/p&gt;&#xA;&lt;p&gt;通过我们的客户计划提交的请求中约有35％是&lt;em&gt;行动&lt;/em&gt;的 - 这意味着他们要么被接受并且正在进行中，要么已经产生了新功能或计划。虽然我们听到其他产品团队的估计值大约为10-15％，但我们尚未发现任何可靠的行业基准可以与之相比。目前，我们目前的基准是35％，随着程序的增长，我们专注于改进它。&lt;/p&gt;&#xA;&lt;H3 ID =“ voc-Impact的示例”&gt;&#xA;&lt;p&gt;在内部大规模运行Grafana Cloud为我们提供了独特的视角，但我们知道我们的需求与客户的需求并不总是相同的。我们努力满足广泛的用例，环境和操作现实。&lt;/p&gt;&#xA;&lt;p&gt;客户的声音在确保我们不仅为自己的经验优化时发挥着关键作用。它可以帮助我们识别用户之间的模式，并为可能的影响带来最广泛的影响。&lt;/p&gt;&#xA;&lt;BlockQuote&gt;&#xA;&lt;p&gt;“随着我们产品的发展，我们始终希望确保我们建立与客户用例保持一致的功能。”Grafana Labs的员工产品经理N Kehoe。 “ VOC对于通过软件交付生命周期的所有阶段为我的团队提供直接客户反馈至关重要，因此，如果我们错过了商标，我们可以充满信心地构建。” &lt;/p&gt; &lt;/blockquote&gt;&#xA;&lt;p&gt;这是一些最近的产品更新（以及正在进行的计划），这些更新是由VOC用户反馈大量塑造的：&lt;/p&gt;&#xA;&lt;p&gt; &lt;strong&gt;扩展RBAC跨产品&lt;/strong&gt; &lt;/p&gt;&#xA;&lt;p&gt;跨VOC反馈最一致的功能之一是细粒度的访问控制 - 不仅在一个区域，而且在我们的堆栈中。多亏了这个信号，我们已经发货了RBAC功能和改进，包括&lt;a href =“/docs/docs/grafana-cloud/monitor-applications/frontend-observility/rbac/？pg = blog＆plcmt＆plcmt = body＆plcmt = body-txt = body-txt = body-txt“ href=&#34;/whats-new/2024-06-06-rule-specific-silences-with-rbac/?pg=blog&amp;plcmt=body-txt&#34;&gt;silences&lt;/a&gt;, &lt;a href=&#34;/whats-new/2025-01-22-rbac-for-alerting-notifications/?pg=blog&amp;plcmt=body-txt&#34;&gt;contact points&lt;/a&gt;, &lt;a href=&#34;/docs/grafana/latest/alerting/set-up/configure-rbac/access-folders/?pg=blog&amp;plcmt=body-txt&#34;&gt;subfolders&lt;/a&gt;, &lt;a href=&#34;/docs/grafana-cloud/machine-learning/dynamic-alerting/rbac/?pg=blog&amp;plcmt=body-txt&#34;&gt;Dynamic alerting&lt;/a&gt;, and &lt;a href =“/whats-new/2025-01-22-rbac-for-notification-policies/？pg = blog＆plcmt = body-txt”&gt;通知策略&lt;/a&gt;），&lt;a href =“/whats-new/2025-05-20-rbac-for synththetic-monitoring-is-generally-ableable-abailable/？pg = blog＆plcmt = body-txt = body-txt&#39;&gt;综合监视&lt;/a&gt;和&lt;a &lt;a href =“/docs/grafana-cloud/nervering-mirm/irm/andm/manage/user-and-teams/？pg = blog＆plcmt = body-txt/＃基于角色的access-access-control-rbac”&gt; irm &lt;/a&gt;。这对我们来说仍然是一个主要主题，我们致力于随着时间的推移扩展和完善RBAC支持。&lt;/p&gt;&#xA;&lt;p&gt; &lt;strong&gt;提高成本可见性和控制&lt;/strong&gt; &lt;/p&gt;&#xA;&lt;p&gt;成本控制和归因是用户反馈中的重要主题，尤其是管理多个环境或利益相关者的团队。作为回应，我们启动了几个基本改进，包括对我们的计费仪表板和使用API​​的更新，以帮助团队了解支出的去向。我们还引入了&lt;a href =“/blog/2025/01/14/what-is-is-aptive-telemetry and-how-can-it-it-it-it-it-it-mttr-mttr-noise-and-cost/”&gt;自适应遥测&lt;/a&gt; &lt;/a&gt;有助于降低噪音并管理噪音而不失去关键可观察性信号而管理噪音并管理成本。 &lt;/p&gt;&#xA;&lt;BlockQuote&gt;&#xA;&lt;p&gt;“对于我们的组织来说，要对遥测进行深入销售和成本分解，以确保每月内部拒绝，并确保成本中心符合固定的预算。令我们高兴的是，Grafana能够提供必要的组成部分。 “他们花了一些时间通过与我们的可观察性和Finops工程师合作来了解我们的需求，我们真的很感谢他们快速的迭代方法。” &lt;/p&gt; &lt;/blockquote&gt;&#xA;&lt;p&gt; &lt;strong&gt;编程工作流程：Terraform，API和Git Sync &lt;/strong&gt; &lt;/p&gt;&#xA;&lt;p&gt;用户反馈中的另一个反复出现的主题是需要以编程方式管理格拉法纳。这跨产品显示：要求更多地Terraform覆盖范围，更好的API和用于仪表板和配置的基于GIT的工作流程。作为回应，我们继续&lt;a href =“/blog/2025/05/07/可观察性-scode-as-as-code-grafana-12/＃new-terraform-resource”&gt;扩展我们的Terraform提供商&lt;/a&gt;涵盖更多资源，&lt;a href =“同步&lt;/a&gt;  - 将GIT工作流直接带入Grafana UI的代码工具的可观察性 - 在&lt;a a href =“/blog/2025/05/05/05/07/grafana-12-rease-allease-all lease-all-the-theew-features/”&gt; grafana&gt; grafana 12版本&lt;/a&gt;中。 &lt;/p&gt;&#xA;&lt;p&gt; &lt;strong&gt; grafana云合成监控的秘密管理&lt;/strong&gt; &lt;/p&gt;&#xA;&lt;p&gt;在生产环境中运行合成检查的用户的最高请求是能够在无需硬编码脚本中安全地存储和注入敏感值的能力。今天，这很难安全，这会引入风险并使合规性复杂化。我们正在积极建立一个安全的秘密管理流，该流程允许将敏感数据存储在后端秘密商店中，并将其注入脚本为环境变量，并完全隐藏在UI和日志中。 &lt;/p&gt;&#xA;&lt;BlockQuote&gt;&#xA;&lt;p&gt;“秘密管理人员不断地以我们对客户反馈的声音进行一次又一次地出现。这是合成监控用户的最大痛苦点之一，也是采用真正的阻止者，” Grafana Labs的员工产品经理Mark Meier说。 “拥有这些VOC数据产生了巨大的不同，有助于将用户的反馈转化为真实动力。” &lt;/p&gt; &lt;/blockquote&gt;&#xA;&lt;p&gt;请继续关注更多更新。 &lt;/p&gt;&#xA;&lt;H2 ID =“ Whats-New-New-the-the-the-the-customer-Facemer-portal”&gt;新事物：面向VOC客户的门户网站&lt;/h2&gt;&#xA;&lt;p&gt;我们已经推出了面向客户的功能请求门户，以使我们的反馈流程更加高效和透明。 &lt;/p&gt;&#xA;&lt;p&gt;以前，所有反馈将通过Grafana Labs帐户团队手动过滤。现在，借助新的VOC门户网站，用户可以看到已经要求，对这些请求进行了投票或评论，并在其组织中跟踪想法。&lt;/p&gt;&#xA;&lt;p&gt; &lt;图&#xA;class =“ figup-wrapper figuper-wrapper__lightbox W-100P”&#xA;样式=“最大宽度：无;”&#xA;itemprop =“ iSsectedmedia”&#xA;itemScope =“”&#xA;itemType =“ http://schema.org/imageObject”&#xA;&gt; &lt;a&#xA;class =“ Lightbox-link”&#xA;href =“ https://a-us.storyblok.com/f/1022730/19999x800/c005e08f65/voc-portal-screenshot.png”&#xA;itemprop =“ contenturl”&#xA;&gt; &lt;div class =“ img-wrapper W-100P H-auto”&gt; &lt;img&#xA;class =“ Lazyload”&#xA;data-src =“ https://a-us.storyblok.com/f/1022730/19999x800/c005e08f65/voc-portal-screenshot.png” alt =“ Alt =” ALT =“新声音&#xA;&lt;NoScript&gt;&#xA;&lt;img&#xA;src =“ https://a-us.storyblok.com/f/1022730/19999x800/c005e08f65/voc-portal-screenshot.png”&#xA;alt =“客户门户新声音的屏幕截图。”/&gt;&lt;/noscript&gt; &lt;/div&gt; &lt;/a&gt; &lt;/fige&gt;客户现在可以：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;提交并查看所有Grafana Labs功能请求&lt;/li&gt;&#xA;&lt;li&gt; upvote现有功能请求&lt;/li&gt;&#xA;&lt;li&gt;评论要澄清用例&lt;/li&gt;&#xA;&lt;li&gt;轨道请求他们的组织已提交或支持&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;当用户可以轻松地看到并与现有想法互动时，我们可以更清楚地了解哪些请求并获得吸引力。与其他想法相比，它还允许人们评估他们感兴趣的事物的普及。&lt;/p&gt;&#xA;&lt;p&gt;If you’re a Grafana Cloud user, you can log in to the &lt;a href=&#34;https://grafana.ideas.aha.io/?pg=blog&amp;plcmt=body-txt&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Feature Request Portal&lt;/a&gt; today to view, vote on, and submit ideas directly to Grafana Labs.&lt;/p&gt;&#xA;&lt;h2 id =“ whats-next-扩展 -  voc”&gt;下一&#xA;&lt;p&gt;客户计划的声音首先关注所有Grafana Cloud客户。这些客户经常在复杂的环境中运行我们的产品，依靠紧密集成的功能，并产生与日常工作流程直接相关的高信号反馈。当我们为VOC程序构建结构，规模和过程时，这是一个自然的起点。&lt;/p&gt;&#xA;&lt;p&gt;，但我们的根源是开源的，我们知道我们最周到的反馈来自OSS社区。通过GitHub问题，论坛，松弛和直接对话，社区的投入一直是图片的一部分 - 但通常会非正式地与团队联系。&lt;/p&gt; &lt;/p&gt;&#xA;&lt;p&gt;现在，我们正在努力更系统地整合该反馈。 VOC计划的下一个阶段涉及与Grafana Labs的团队合作，以确保我们的开源用户的输入被捕获，蒸馏和与我们的云客户信号一起捕获。这不是要替换收集反馈的过程，而是要扩大范围。 &lt;/p&gt;&#xA;&lt;p&gt;最后，我们要感谢所有花时间分享反馈的人 - 无论是通过功能请求门户，GitHub问题，Slack Threads，Slack Threads，技术支持还是在活动中进行的对话。您已经帮助塑造了我们正在构建的产品，我们非常感谢您的投入。 &lt;/p&gt;&#xA;&lt;h2 id =“客户语音式 - 绘制式 -  faqs”&gt;客户程序的语音常见问题&lt;/h2&gt;&#xA;&lt;p&gt; &lt;strong&gt; Grafana Labs的客户计划的声音是什么？&lt;/strong&gt; &lt;/p&gt;&#xA;&lt;p&gt;客户（VOC）程序的声音是我们收集，分析和对用户的产品反馈采取措施的结构化方法。它是一个集中式，可靠的信号，可帮助我们的团队发现模式，验证用例并使用更多上下文构建。在内部运行Grafana Cloud的同时，VOC确保我们不仅为自己的需求而建立，而且还为我们用户所面临的各种环境，挑战和现实。&lt;/p&gt;&#xA;&lt;p&gt; &lt;strong&gt; Grafana Labs如何优先考虑VOC功能请求？&lt;/strong&gt; &lt;/p&gt;&#xA;&lt;p&gt;我们优先考虑功能e根据要求同一件事的组织数量的要求，而不是个人投票。来自10个不同公司的一次投票比同一公司的10票更重。这种方法有助于我们确保我们投资于解决广泛问题的功能。 &lt;/p&gt;&#xA;&lt;p&gt; &lt;strong&gt;什么时候可以审查我的功能请求？&lt;/strong&gt; &lt;/p&gt;&#xA;&lt;p&gt;在大多数情况下，一旦我们看到多个组织的兴趣，就可以将功能请求优先审核。我们在客户群中寻找主题和模式，因此我们可以专注于建立具有广泛影响的解决方案。也就是说，在某些情况下，请求较早地进行了审查，尤其是当它们与路线图上的某些内容保持一致或支持战略计划时。虽然多ORG的兴趣是最常见的触发因素，但这并不是唯一的触发因素。我们的产品团队都会捕获和可见每个请求。&lt;/p&gt;&#xA;&lt;p&gt; &lt;strong&gt;从提交&gt;评论&gt;启动需要多长时间？&lt;/strong&gt; &lt;/p&gt;&#xA;&lt;p&gt;从提交到审核到启动的时间表没有保证的时间表。这取决于几个因素：有多少客户要求，请求与我们当前的策略和路线图如何保持一致，以及其他工作已经在进行中。即使优先审核请求，也并不总是意味着它将建立。我们旨在以最可扩展的方式解决正确的问题，有时会找到其他路径或分组类似的反馈。&lt;/p&gt;&#xA;&lt;p&gt; &lt;strong&gt;社区反馈呢？&lt;/strong&gt; &lt;/p&gt;&#xA;&lt;p&gt;社区反馈始终对我们的产品改进很有价值。我们通过GITHUB问题，论坛，社区懈怠和直接对话从用户那里听到，多年来，该输入已塑造了许多功能。&lt;/p&gt;&#xA;&lt;p&gt;这些频道不会消失。如果您已经通过GitHub或其他公共论坛分享反馈，请继续做您的工作。该信号很重要，并且没有被替换。&lt;/p&gt;&#xA;&lt;p&gt;我们正在努力更好地将这些反馈与客户程序的更广泛的声音联系起来，以便更加一致地捕获开源用户的见解，并与我们从云客户那里听到的内容一起表示。这将有助于我们在所有用户中发现共享模式，而不管他们如何运行Grafana。&lt;/p&gt;&#xA;&lt;p&gt; &lt;strong&gt;我如何了解有关客户声音的更多信息？&lt;/strong&gt; &lt;/p&gt;&#xA;&lt;p&gt;You can visit the &lt;a href=&#34;https://grafana.ideas.aha.io/sections/7518058178676519123&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Resources tab&lt;/a&gt; in the VoC portal to find information on using the portal, answers to common questions, and more details on our processes.有关其他任何问题，请联系&lt;a href =“ mailto：voc-shared-inbox@grafana.com”&gt; voc-shared inbox@grafana.com &lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt; &lt;em&gt; &lt;a href =“/products/cloud/？pg = blog＆plcmt = body-txt”&gt; grafana cloud &lt;/a&gt; &lt;/em&gt; &lt;em&gt;是开始使用指标，日志，痕迹，仪表，仪表板等最简单的方法。我们有一个宽敞的永远的层次，并为每个用例都有计划。&lt;/em&gt; &lt;em&gt; &lt;ahref =“/auth/imp-up/create-user/？pg = blog＆plcmt = body-txt”&gt;现在免费注册！&lt;/a&gt; &lt;/a&gt; &lt;/em&gt; &lt;/p&gt;</description>
      <pubDate>Tue, 26 Aug 2025 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Canary tokens: Learn all about the unsung heroes of security at Grafana Labs】金丝雀令牌：在Grafana Labs了解所有有关安全英雄的信息</title>
      <link>https://grafana.com/blog/2025/08/25/canary-tokens-learn-all-about-the-unsung-heroes-of-security-at-grafana-labs/</link>
      <description>【&lt;p&gt;We&amp;rsquo;ve written at length about a recent security incident tied to a GitHub action, but what we haven&amp;rsquo;t publicized yet is how we found the trail left by the attacker: canary tokens. &lt;/p&gt;&#xA;&lt;p&gt;To quickly recap the &lt;a href=&#34;/blog/2025/05/15/grafana-security-update-post-incident-review-for-github-workflow-vulnerability-and-whats-next/&#34;&gt;security incident&lt;/a&gt; in question, on April 26 a vulnerable GitHub Action workflow allowed an unauthorized user access to a limited number of tokens.&lt;/p&gt;&#xA;&lt;p&gt;Our &lt;a href=&#34;/blog/2025/05/15/grafana-security-update-post-incident-review-for-github-workflow-vulnerability-and-whats-next/&#34;&gt;investigation&lt;/a&gt; into the incident concluded May 12, and we confirmed that &lt;strong&gt;there were no code modifications, unauthorized access to production systems, exposure of customer data, or access to personal information.&lt;/strong&gt; &lt;/p&gt;&#xA;&lt;p&gt;After the initial incident was triggered (but before our investigation concluded), the attacker deleted their fork, PRs, and workflow runs in an attempt to cover their tracks. This led to unauthorized access to secrets across five public repositories, though this did not impact production systems or customer data either. We disabled affected workflows, rotated all exposed credentials, and audited our repositories with Trufflehog, &lt;a href=&#34;/blog/2025/06/26/how-to-detect-vulnerable-github-actions-at-scale-with-zizmor/&#34;&gt;Zizmor&lt;/a&gt;, and Gato-X. We also conducted a full access log review in Grafana Loki and other data sources. You can read the initial announcement &lt;a href=&#34;/blog/2025/04/27/grafana-security-update-no-customer-impact-from-github-workflow-vulnerability/&#34;&gt;here&lt;/a&gt; and the PIR &lt;a href=&#34;/blog/2025/05/15/grafana-security-update-post-incident-review-for-github-workflow-vulnerability-and-whats-next/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Without canary tokens and our watchful team, it would have taken longer to detect the attack. In this blog, we&amp;rsquo;ll explain what canary tokens are and show you how they&amp;rsquo;ve helped us. We&amp;rsquo;ll also tell you how they can help you detect intrusions before they become serious security incidents. &lt;/p&gt;&#xA;&lt;h2 id=&#34;what-are-canary-tokens-and-how-do-we-use-them-at-grafana-labs&#34;&gt;What are canary tokens? And how do we use them at Grafana Labs?&lt;/h2&gt;&#xA;&lt;p&gt;Canary tokens are digital tripwires or decoys that look valuable to an intruder but have no legitimate use. If someone finds and uses one you&amp;rsquo;ve deployed, you&amp;rsquo;ll receive an immediate alert. &lt;/p&gt;&#xA;&lt;p&gt;Named after coal-mining canaries (early warning for toxic gas), these tokens are far lighter than honeypots. They can take many simple forms, such as API keys, files, URLs, or DNS entries, making them fast and easy to deploy across your environment.&lt;/p&gt;&#xA;&lt;p&gt;In our case, canary tokens weren’t just an experiment, they were the primary signal that told us an attacker was inside: An AWS API key was validated by the attacker; we got a real-time alert; teams swarmed; and the intrusion was contained within minutes.&lt;/p&gt;&#xA;&lt;p&gt;Here are the actionable lessons from that detection and why placement and deployment matter more than the token itself:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Speed wins:&lt;/strong&gt; Canary tokens turn hours of triage into minutes of containment.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Placement matters:&lt;/strong&gt; Choose the right token types and place them where attackers actually look.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Precision in pinpointing:&lt;/strong&gt; Utilize organization-level tokens for broad compromise detection and repository-level tokens to identify specific entry points.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Metadata is gold:&lt;/strong&gt; Comprehensive reminder text, token names, and locations are crucial for efficient triage.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Integration is key:&lt;/strong&gt; Canary tokens only shine when paired with clear naming, automated alerting, and integrated response workflows.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Iterative scaling:&lt;/strong&gt; Begin with a small-scale placement in high-risk areas. Only then, by refining your response strategy, can you scale use of canary tokens.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;how-we-built-our-canary-token-infrastructure&#34;&gt;How we built our canary token infrastructure&lt;/h3&gt;&#xA;&lt;p&gt;There are two options for deploying canary tokens:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;DIY setup:&lt;/strong&gt; Generate tokens (API keys, fake files, custom URLs) yourself and build or plug into your existing monitoring system to catch any token use. This gives you full control over token behavior and alert handling, making it ideal for custom platforms.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Automated platforms:&lt;/strong&gt; Solutions like &lt;a href=&#34;https://canary.tools/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Thinkst&lt;/a&gt; or &lt;a href=&#34;https://tracebit.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;TraceBit&lt;/a&gt; offer out-of-the-box token creation, monitoring, and notifications across major cloud providers and apps. For any bespoke tokens or corner-case scenarios, you’ll still need to handle monitoring yourself to ensure complete coverage.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;While a DIY approach could be sufficient for a relatively small environment, we needed something that could scale without manual intervention. So, after experimenting with Thinkst’s &lt;a href=&#34;https://github.com/thinkst/canarytokens&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;OSS&lt;/a&gt; and &lt;a href=&#34;https://canarytokens.org/nest/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;free&lt;/a&gt; editions, we switched to their &lt;a href=&#34;https://canary.tools/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;cloud&lt;/a&gt; version for features missing in OSS, such as undetectable tokens, a robust API, audit-trail logging, and a full authentication/authorization system.&lt;/p&gt;&#xA;&lt;p&gt;To make the most out of our setup, we connected the notifications of the Thinkst platform to Grafana Cloud IRM &lt;a href=&#34;/docs/grafana-cloud/alerting-and-irm/irm/configure/integrations/webhooks/incoming-webhooks/oncall-webhooks/&#34;&gt;webhooks&lt;/a&gt;, as shown below:&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: none;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;https://a-us.storyblok.com/f/1022730/1159x439/562ee4a70e/webhook-feed.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;https://a-us.storyblok.com/f/1022730/1159x439/562ee4a70e/webhook-feed.png&#34;alt=&#34;Screenshot of a web page showing a Global Webhooks Feed section with options for managing flocks and installed webhooks.&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;https://a-us.storyblok.com/f/1022730/1159x439/562ee4a70e/webhook-feed.png&#34;&#xA;alt=&#34;Screenshot of a web page showing a Global Webhooks Feed section with options for managing flocks and installed webhooks.&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;The webhook is then being listened to by the Grafana Cloud IRM integration:&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: none;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;https://a-us.storyblok.com/f/1022730/1693x1009/ae9bb0e4c2/canary-tokens-integration.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;https://a-us.storyblok.com/f/1022730/1693x1009/ae9bb0e4c2/canary-tokens-integration.png&#34;alt=&#34;Screenshot of a Canary Tokens configuration page showing HTTP Endpoint, labels schema, templates, and routes options for security alerts.&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;https://a-us.storyblok.com/f/1022730/1693x1009/ae9bb0e4c2/canary-tokens-integration.png&#34;&#xA;alt=&#34;Screenshot of a Canary Tokens configuration page showing HTTP Endpoint, labels schema, templates, and routes options for security alerts.&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;This setup allows us to route canary tokens’ notifications to Slack (as you can see in the Routes section above) and automate escalation chains (as you can see in the screenshot below). If you&amp;rsquo;d like to do something similar, further details on Grafana Cloud IRM integrations are available &lt;a href=&#34;/docs/grafana-cloud/alerting-and-irm/irm/configure/integrations/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: none;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;https://a-us.storyblok.com/f/1022730/1999x424/6cb322bee6/security-oncall.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;https://a-us.storyblok.com/f/1022730/1999x424/6cb322bee6/security-oncall.png&#34;alt=&#34;A schedule interface showing five steps with start, wait, and import actions for &amp;#39;Security Oncall&amp;#39; and &amp;#39;Security Managers&amp;#39; notifications.&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;https://a-us.storyblok.com/f/1022730/1999x424/6cb322bee6/security-oncall.png&#34;&#xA;alt=&#34;A schedule interface showing five steps with start, wait, and import actions for &amp;#39;Security Oncall&amp;#39; and &amp;#39;Security Managers&amp;#39; notifications.&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;h3 id=&#34;canary-token-lifecycle&#34;&gt;Canary token lifecycle&lt;/h3&gt;&#xA;&lt;p&gt;We use a simple, four-step lifecycle to operationalize canary tokens and turn them into an actionable detection and response capability:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;Create&lt;/strong&gt;: Generate a unique token, like an AWS API key, PDF link, or DNS subdomain that “phones home” when accessed.  &lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Place:&lt;/strong&gt; Embed tokens where attackers would look, like code repos, config directories, vaults, cloud consoles, databases, or shared drives.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Monitor:&lt;/strong&gt; A background service watches for any token use and sends an alert with metadata (timestamp, IP, hostname). Keep in mind: If you’re not using a platform, you must build custom monitoring.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Respond:&lt;/strong&gt; Investigate alerts, isolate affected assets, and remediate before any real data is touched. Keep the triggered token for forensics and replace it immediately.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;canary-tokens-and-trufflehog-to-the-rescue&#34;&gt;Canary tokens and TruffleHog to the rescue!&lt;/h2&gt;&#xA;&lt;p&gt;We planted AWS API key canary tokens (alongside a few others) in organization- and repository-level secrets. When the attacker exfiltrated the secrets and ran &lt;a href=&#34;https://github.com/trufflesecurity/trufflehog&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;TruffleHog&lt;/a&gt; to validate them, TruffleHog’s &lt;code&gt;sts:GetCallerIdentity&lt;/code&gt; &lt;a href=&#34;https://docs.aws.amazon.com/STS/latest/APIReference/API_GetCallerIdentity.html&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;call&lt;/a&gt; against our tokens triggered the canary, unlike free canary tokens that are automatically detected by TruffleHog &lt;a href=&#34;https://trufflesecurity.com/blog/canaries&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;without calling the AWS API&lt;/a&gt;. &lt;/p&gt;&#xA;&lt;p&gt;Because Thinkst was watching those AWS accounts, we got an immediate Slack alert. That one notification, thanks to our strategic token placement, revealed the exact entry point. The Detection &amp;amp; Response team reacted to the notification and raised an incident. Teams across R&amp;amp;D and Security sprang into action to contain and remediate the incident, which, again, resulted in no code modifications, unauthorized access to production systems, exposure of customer data, or access to personal information. &lt;/p&gt;&#xA;&lt;h3 id=&#34;our-canary-token-placement-strategy&#34;&gt;Our canary token placement strategy&lt;/h3&gt;&#xA;&lt;p&gt;Given GitHub&amp;rsquo;s central role as our primary source of truth, safeguarding it with canary tokens is crucial. Specifically, we strategically deploy AWS API key canary tokens within GitHub Secrets by placing the tokens at the organization level (to flag any repo breach) and per repository (to precisely pinpoint intrusions at the repository level). Other platforms get their own flavors. For example, &lt;a href=&#34;https://help.canary.tools/hc/en-gb/articles/360021010497-How-do-I-create-a-Google-Docs-Sheets-Token&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Google Docs&lt;/a&gt; tokens live in shared Google Drive files, email-based tokens in dummy inboxes, and DNS tokens in unused subdomains.&lt;/p&gt;&#xA;&lt;p&gt;The key is to map out every asset (repos, CI/CD pipelines, cloud consoles, vaults, pods, containers, etc.) and sprinkle a diverse mix of tokens wherever an attacker might snoop. We’ve deployed tens of thousands (or an infinite amount, for that matter), so watch your steps, since there’s a tripwire behind every click.&lt;/p&gt;&#xA;&lt;h2 id=&#34;how-you-can-utilize-canary-tokens-in-your-security-setup&#34;&gt;How you can utilize canary tokens in your security setup&lt;/h2&gt;&#xA;&lt;p&gt;Now that we&amp;rsquo;ve walked through how we deploy canary tokens, we want to share some tips for how you can utilize them as well. For the purposes of this blog, we&amp;rsquo;ll focus our advice on the same tools we use internally (because we believe in them as tried and tested technologies), but most of the general guidance still applies for other similar tools.&lt;/p&gt;&#xA;&lt;h3 id=&#34;shaping-your-placement-strategy-with-team-discussion&#34;&gt;Shaping your placement strategy with team discussion&lt;/h3&gt;&#xA;&lt;p&gt;Some key questions you should consider before deciding on your canary placement and alerting strategy include:&lt;/p&gt;&#xA;&lt;h4 id=&#34;which-token-types-catch-attackers-best&#34;&gt;Which token types catch attackers best?&lt;/h4&gt;&#xA;&lt;p&gt;Pick from Thinkst’s &lt;a href=&#34;https://help.canary.tools/hc/en-gb/articles/4701687447325-What-are-Canarytokens&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;catalog&lt;/a&gt; (over two dozen types) to match your environment and threats. Mix cloud/API keys (AWS, Azure, Slack) with file- or link-based tokens (PDFs, DNS, URLs) so you cover code repos, docs, and networks. Use a variety to broaden detection.&lt;/p&gt;&#xA;&lt;h4 id=&#34;how-do-you-make-alerts-impossible-to-miss&#34;&gt;How do you make alerts impossible to miss?&lt;/h4&gt;&#xA;&lt;p&gt;Tune your alert thresholds and channels to strike the right balance between urgency and noise. Consider:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Acknowledge alerts early:&lt;/strong&gt; Acknowledge alerts promptly on the Thinkst platform to avoid grouping subsequent alerts and missing notifications of repeated canary token triggers from different IP addresses.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;METADATA IS IMPORTANT:&lt;/strong&gt; For quicker investigation, ensure every notification includes canary token metadata (name, location, reminder text). The Thinkst platform automates this if the reminder text is correctly configured.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;where-do-alerts-need-to-land&#34;&gt;Where do alerts need to land?&lt;/h4&gt;&#xA;&lt;p&gt;Choose channels your team actually watches:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Immediate channels:&lt;/strong&gt; Slack (with webhooks) or the Grafana Cloud IRM mobile app for 24/7 paging&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Secondary channels:&lt;/strong&gt; Security mailing lists, SIEM, or ticketing (e.g., Splunk) for structured incident tracking&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Map each severity level to the right channel so nothing slips through.&lt;/p&gt;&#xA;&lt;h4 id=&#34;where-should-tokens-live&#34;&gt;Where should tokens live?&lt;/h4&gt;&#xA;&lt;p&gt;Sprinkle tokens in high-risk and high-value spots:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;CI/CD pipelines&lt;/strong&gt;: As dummy environment variables, test jobs, or secondary workflows&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Private GitHub/GitLab repositories&lt;/strong&gt;: In config files, comments or branch-specific .env files&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Developer workstations &amp;amp; build servers&lt;/strong&gt;: In ~/.aws/credentials, hidden directories or registry entries&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Cloud accounts &amp;amp; consoles&lt;/strong&gt;: Nested within IAM policies or metadata documents&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Shared network drives &amp;amp; documentation&lt;/strong&gt;: In ordinary looking directories or PDFs&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Public GitHub/GitLab repositories&lt;/strong&gt;: Be cautious here! Alert fatigue is a real thing. Limit use of canary tokens in public repositories to avoid false positives from automated secret scanners triggered by inadvertently exposed sensitive information like AWS API keys in Git branches (i.e., obvious places).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;how-do-you-prevent-accidental-triggers&#34;&gt;How do you prevent accidental triggers?&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Educate teams&lt;/strong&gt;: Explain the “what” and “where” of canary tokens.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Demo alerts&lt;/strong&gt;: Show how tokens work and what notifications look like.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Announce deployments&lt;/strong&gt;: Share rollout plans in team channels.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Document “off-limits” zones&lt;/strong&gt;: Post common token names and locations in your wiki.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Use runbooks&lt;/strong&gt;: Guide responders through investigations to avoid confusion.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;You have two communication strategies for canary tokens:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Silent&lt;/strong&gt;: No internal notice, which is better for catching insiders but higher false positives.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Communicative&lt;/strong&gt;: Teams know about tokens, with fewer false positives but risk tipping off attackers.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;who-are-you-trying-to-catch&#34;&gt;Who are you trying to catch?&lt;/h4&gt;&#xA;&lt;p&gt;Identify target adversaries for canary tokens. Understand that advanced attackers use unique methods, so tokens alone are insufficient for full access prevention.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;External attackers&lt;/strong&gt; probing repos or cloud assets&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Automated scanners&lt;/strong&gt; hunting for exposed secrets&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Insider threats&lt;/strong&gt; snooping on token-laden areas&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Supply-chain attackers&lt;/strong&gt; targeting CI/CD&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Phishing or social-engineering&lt;/strong&gt; via document or email tokens&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;By answering these, you’ll align token types, alerting, and placement with your organization’s risks and tools, thus turning every token into a reliable tripwire.&lt;/p&gt;&#xA;&lt;h2 id=&#34;best-practices-limitations-and-gotchas&#34;&gt;Best practices, limitations, and gotchas&lt;/h2&gt;&#xA;&lt;p&gt;Canary tokens provide valuable, high-confidence alerts of compromise, but triggering one means an attacker is already inside your system. While effective, they are not a foolproof solution and have limitations.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Provider support varies:&lt;/strong&gt; Not every token type is available on every platform. If you build your own bespoke API or secret-generation service, you’ll need to roll your own monitoring. One way to do that is to log token IDs (never the secret!) into &lt;a href=&#34;/docs/loki/latest/&#34;&gt;Grafana Loki&lt;/a&gt;, set up &lt;a href=&#34;/docs/grafana/latest/alerting/&#34;&gt;Grafana Alerting alerts&lt;/a&gt; on those IDs, and feed incidents into &lt;a href=&#34;/docs/grafana-cloud/alerting-and-irm/irm/&#34;&gt;Grafana Cloud IRM&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Monitoring availability:&lt;/strong&gt; If your token-watching infrastructure goes down, or worse, becomes compromised, you lose visibility entirely. So, secure your infrastructure!&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;False positives from insiders:&lt;/strong&gt; Before we formally announced our token rollout, a handful of teammates accidentally tripped tokens simply by poking around. By asking them why they accessed those credentials, we quickly labeled those alerts as benign and moved on.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Obfuscated attacker source:&lt;/strong&gt; VPNs hide real IPs, so location data can be misleading. Some browser-based tokens can add fingerprinting, but that only works for web-triggered tokens.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;API rate limits:&lt;/strong&gt; Even when vendors advertise “unlimited” API calls, their infrastructure typically enforces limitations. Blast too many token creation or update requests at once and you’ll hit throttling or even break the API.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Here are the key best practices we’ve learnt over time:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;Use descriptive reminders:&lt;/strong&gt; Leverage Thinkst’s “reminder” text field to tag each token with owner, environment, and location. You can also store JSON in that field and retrieve it later via the UI or API.  That metadata lets you pinpoint precisely what was touched.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;One token per location:&lt;/strong&gt; When a token fires, archive it for forensics, since an attacker might reuse or sell it, then replace it ideally with a fresh name that blends in (e.g., AWS_API_CREDS instead of CANARY_TOKEN_AWS).&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Group into flocks:&lt;/strong&gt; Organize tokens by environment, team, or platform into &lt;a href=&#34;https://help.canary.tools/hc/en-gb/articles/360012874638-How-do-I-create-a-new-flock&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;flocks&lt;/a&gt; to simplify bulk management.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Integrate alerts into incident response:&lt;/strong&gt; Route notifications into your messaging system, your SIEM, and/or ticketing system so that nothing slips through the cracks.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Mix token types:&lt;/strong&gt; Don’t rely solely on AWS API keys. Deploy file, URL/DNS, email, and command tokens to cover every attacker tactic.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Automate placement:&lt;/strong&gt; Use Thinkst’s &lt;a href=&#34;https://github.com/thinkst/canary-utils&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;scripts or IaC examples&lt;/a&gt; (Terraform, Ansible, Puppet, and AWS CloudFormation) to ensure consistency. We also worked closely with Thinkst support to master their UI, API, and tooling and learn some best practices.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Test your tokens and document actions:&lt;/strong&gt; Trigger a few tokens in a safe environment after deployment to verify alert delivery and downstream automation. This will also enhance your incident response plan. This practice allows you to simulate real-world scenarios and refine your response procedures. Document these simulated incidents and the corresponding steps taken to create comprehensive runbooks. These runbooks will serve as valuable guides when canary tokens are triggered in the future, ensuring a more efficient and effective response and less confusion.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Communicate widely and wisely:&lt;/strong&gt; Make your teams (or even your broader community) aware of canary tokens. That transparency reduces accidental triggers and builds security awareness.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;By understanding these limitations and following these practices, you’ll keep your canary token deployment lean, reliable, and ready to catch real attacks the moment they unfold. &lt;/p&gt;&#xA;&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;&#xA;&lt;p&gt;Canary tokens have been a force multiplier for us, turning every corner of our infrastructure into a potential tripwire and giving us the precious minutes needed to stop a breach before it escalates. &lt;/p&gt;&#xA;&lt;p&gt;Seed your environment with right token types, integrate alerts for automation, and never underestimate the advantage of knowing an adversary is inside before they ever touch your real assets.&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;/products/cloud/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt;&lt;/em&gt; &lt;em&gt;is the easiest way to get started with metrics, logs, traces, dashboards, and more. We have a generous forever-free tier and plans for every use case.&lt;/em&gt; &lt;em&gt;&lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Sign up for free now!&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;】&lt;p&gt;我们详细介绍了最近与Github动作有关的安全事件，但我们尚未公开的是如何找到攻击者留下的小径：金丝雀令牌。 &lt;/p&gt;&#xA;&lt;p&gt;快速回顾&lt;a href =“/blog/2025/05/15/grafana-security-post-post-cost-indind-fiew-for-github-github-github-workflow-workflow-vulnerability-vulnerability-and-whats-next/”&gt;安全事件&lt;/a&gt;在4月26日，在4月26日，一个脆弱的Github Action Workflow允许使用Une useflimimit conseffe useffe oss usess offe usefter/per po&gt;&#xA;&lt;p&gt;Our &lt;a href=&#34;/blog/2025/05/15/grafana-security-update-post-incident-review-for-github-workflow-vulnerability-and-whats-next/&#34;&gt;investigation&lt;/a&gt; into the incident concluded May 12, and we confirmed that &lt;strong&gt;there were no code modifications, unauthorized access to production systems, exposure of customer data, or access to personal信息。&lt;/strong&gt; &lt;/p&gt;&#xA;&lt;p&gt;触发了最初的事件（但在我们的调查结束之前）后，攻击者删除了他们的叉子，PRS和工作流程，以试图掩盖其轨道。这导致未经授权访问五个公共存储库的秘密，尽管这也不会影响生产系统或客户数据。我们禁用受影响的工作流程，旋转所有暴露的凭据，并使用TruffleHog审核我们的存储库，&lt;a href =“/blog/blog/2025/06/26/how-to-to-to-to-detect-vulnerable-github-actions-github-actions-at-scale-at-Scale-at-scale-zizmor/”&gt; Zizmor/“&gt; Zizmor &lt;/a&gt; and Gato-x。我们还在Grafana Loki和其他数据源进行了完整的访问日志审查。您可以阅读初始公告&lt;a href =“/blog/2025/04/27/grafana-security-update-no-customer-impact-impact-from-github-workflow-vulnerability/”&gt;在这里&lt;/a&gt;和pir &lt;a href =“/blog/2025/05/15/grafana-security-update-post-indident-indident-indident-review for-github-workflow-vulnerability-and-vulnerability-and-whats-next/”&gt;在这里&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;没有金丝雀令牌和我们的注意团队，检测攻击将需要更长的时间。在此博客中，我们将解释金丝雀令牌是什么，并向您展示它们如何帮助我们。我们还将告诉您他们如何在成为严重的安全事件之前帮助您检测入侵。 &lt;/p&gt;&#xA;&lt;h2 id =“什么是tokenary-tokens and-do-do-we-us-them-at-at grafana-labs”&gt;什么是金丝雀令牌？我们如何在Grafana Labs使用它们？&lt;/h2&gt;&#xA;&lt;p&gt;金丝雀代币是数字绊窗或诱饵，看起来对入侵者很有价值，但没有合法使用。如果有人找到并使用了您已部署的，您将立即收到警报。 &lt;/p&gt;&#xA;&lt;p&gt;以煤矿装饰（有毒天然气的预警）命名，这些令牌比蜜罐轻得多。他们可以采用许多简单的表格，例如API键，文件，URL或DNS条目，使它们快速易于在环境中部署。&lt;/p&gt;&#xA;&lt;p&gt;在我们的情况下，金丝雀令牌不仅是一个实验，它们是告诉我们攻击者在里面的主要信号：AWS API密钥已由攻击者验证；我们得到了实时警报；团队蜂拥而至；并在几分钟内包含入侵。&lt;/p&gt;&#xA;&lt;p&gt;在这里e从该检测中的可操作的课程，以及为什么放置和部署比令牌本身更重要：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt; &lt;strong&gt;速度获胜：&lt;/strong&gt;金丝雀令牌将小时的分类变成遏制分钟。&lt;/li&gt;&#xA;&lt;li&gt; &lt;strong&gt;放置很重要：&lt;/strong&gt;选择正确的令牌类型，并将其放置在攻击者实际上。&lt;/li&gt;&#xA;&lt;li&gt; &lt;strong&gt;精确指标的精度：&lt;/strong&gt;利用组织级令牌进行广泛的妥协检测和存储库级令牌以识别特定的入口点。&lt;/li&gt;&#xA;&lt;li&gt; &lt;strong&gt;元数据是黄金：&lt;/strong&gt;综合提醒文本，象征名称和位置对于有效的分类至关重要。&lt;/li&gt;&#xA;&lt;li&gt; &lt;strong&gt;集成是关键：&lt;/strong&gt;金丝雀令牌只有在与清晰的命名，自动警报和集成响应工作流程配对时。&lt;/li&gt;&#xA;&lt;li&gt; &lt;strong&gt;迭代缩放：&lt;/strong&gt;首先在高风险区域的小规模放置开始。只有这样，通过完善您的响应策略，您才能扩展使用金丝雀令牌。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id =“如何建造 - 您的token-token-Infrasture”&gt;我们如何构建金丝雀令牌基础架构&lt;/h3&gt;&#xA;&lt;p&gt;部署金丝雀令牌有两个选项：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt; &lt;strong&gt; DIY设置：&lt;/strong&gt;自己生成令牌（API键，假文件，自定义URL），并构建或插入现有的监视系统以捕获任何令牌使用。这使您可以完全控制令牌行为和警报处理，使其非常适合自定义平台。&lt;/li&gt;&#xA;&lt;li&gt; &lt;strong&gt;自动化平台：&lt;/strong&gt;解决方案，例如&lt;a href =“ https://canary.tools/” target =“ _ blank” rel =“ noopener noreferrer”&gt; thinkst &lt;/a&gt;或开箱即用的令牌创建，监视和大量云提供商和应用程序的通知。对于任何定制令牌或角落场景，您仍然需要处理自己的监视以确保完全覆盖。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;虽然DIY方法对于相对较小的环境可能就足够了，但我们需要可以在不手动干预的情况下进行扩展的东西。因此，在尝试了Thinkst的&lt;a href =“ https://github.com/thinkst/canarytokens” target =“ _ blank” rel =“ noopener noreferrer”&gt; oss &lt;/a&gt;和&lt;a href =“ noreferrer&#34;&gt;free&lt;/a&gt; editions, we switched to their &lt;a href=&#34;https://canary.tools/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;cloud&lt;/a&gt; version for features missing in OSS, such as undetectable tokens, a robust API, audit-trail logging, and a full authentication/authorization system.&lt;/p&gt;&#xA;&lt;p&gt;为了充分利用我们的设置，我们将Thinkst平台的通知连接到Grafana Cloud Irm &lt;a href =“/docs/docs/docs/grafana-cloud/artering-anding-and-mirm/irm/irm/ configure/integrations/webhooks/inchooks/incoming-webhooks-webhooks-webhooks-webhooks/oncall-webhooks/oncall-webhooks/oncall-webhooks pp/&#xA;&lt;图&#xA;class =“ figup-wrapper figuper-wrapper__lightbox W-100P”&#xA;样式=“最大宽度：无;”&#xA;itemprop =“ iSsectedmedia”&#xA;itemScope =“”&#xA;itemType =“ http：// schema.org/imageObject“&#xA;&gt; &lt;a&#xA;class =“ Lightbox-link”&#xA;href =“ https://a-us.storyblok.com/f/1022730/1159x439/562ee4a70e/webhook-feed.png”&#xA;itemprop =“ contenturl”&#xA;&gt; &lt;div class =“ img-wrapper W-100P H-auto”&gt; &lt;img&#xA;class =“ Lazyload”&#xA;data-src =“ https://a-us.storyblok.com/f/1022730/1159x439/562ee4a70e/webhook-feed.png” Alt =“ Alt =”网上页面的ScreenShot，显示一个全球Webhooks，显示一个全球webhooks fef部分，该部分用于管理植物和安装Web的webhooks。&#xA;&lt;NoScript&gt;&#xA;&lt;img&#xA;src =“ https://a-us.storyblok.com/f/1022730/1159x439/562ee4a70e/webhook-feed.png”&#xA;Alt =“网页的屏幕截图显示一个全局Webhooks提要部分，其中包含用于管理羊群和已安装的Webhooks的选项。”/&gt;&#xA;&lt;/noscript&gt; &lt;/div&gt; &lt;/a&gt; &lt;/figie&gt;&#xA;&lt;p&gt;然后，webhook被grafana cloud IRM集成聆听：&lt;/p&gt;&#xA;&lt;图&#xA;class =“ figup-wrapper figuper-wrapper__lightbox W-100P”&#xA;样式=“最大宽度：无;”&#xA;itemprop =“ iSsectedmedia”&#xA;itemScope =“”&#xA;itemType =“ http://schema.org/imageObject”&#xA;&gt; &lt;a&#xA;class =“ Lightbox-link”&#xA;href =“ https://a-us.storyblok.com/f/1022730/1693x1009/ae9bb0e4c2/canary-tokens-integration.png”&#xA;itemprop =“ contenturl”&#xA;&gt; &lt;div class =“ img-wrapper W-100P H-auto”&gt; &lt;img&#xA;class =“ Lazyload”&#xA;data-src=&#34;https://a-us.storyblok.com/f/1022730/1693x1009/ae9bb0e4c2/canary-tokens-integration.png&#34;alt=&#34;Screenshot of a Canary Tokens configuration page showing HTTP Endpoint, labels schema, templates, and routes options for security alerts.&#34;/&gt;&#xA;&lt;NoScript&gt;&#xA;&lt;img&#xA;src =“ https://a-us.storyblok.com/f/1022730/1693x1009/ae9bb0e4c2/canary-tokens-integration.png”&#xA;alt =“金丝雀令牌配置页面的屏幕截图显示HTTP端点，标签架构，模板和路由安全警报的选项。”/&gt;&#xA;&lt;/noscript&gt; &lt;/div&gt; &lt;/a&gt; &lt;/figie&gt;&#xA;&lt;p&gt;此设置允许我们将Canary令牌的通知路由放松（如上所述的路线部分所示），并自动化升级链（如下面的屏幕截图所示）。如果您想做类似的事情，请提供有关Grafana Cloud IRM集成的更多详细信息&lt;a href =“/docs/docs/grafana-cloud/alerting-and-mirm/irm/irm/configure/intementations/&#39;&gt;在这里&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;图&#xA;class =“ figup-wrapper figuper-wrapper__lightbox W-100P”&#xA;样式=“最大宽度：无;”&#xA;itemprop =“ iSsectedmedia”&#xA;itemScope =“”&#xA;itemType =“ http://schema.org/imageObject”&#xA;&gt; &lt;a&#xA;class =“ Lightbox-link”&#xA;href =“ https://a-us.storyblok.com/f/1022730/19999x424/6cb3222bee6/security-oncall.png”&#xA;itemprop =“ contenturl”&#xA;&gt; &lt;div class =“ img-wrapper W-100P H-auto”&gt; &lt;img&#xA;class =“ Lazyload”&#xA;data-src =“ https://a-us.storyblok.com/f/1022730/19999x424/6cb3222bee6/security-oncall.png” alt =“ Alt =” Alt =“一个时间表接口显示五个步骤，显示了五个步骤，并在开始，等待和导入&#39;安全OnCall OnCall OnCall OnCall OnCall和“安全管理者”的“安全管理器”，“&#xA;&lt;NoScript&gt;&#xA;&lt;img&#xA;src =“ https://a-us.storyblok.com/f/1022730/1999x424/6cb3222bee6/security-oncall.png”&#xA;alt =“计划界面显示五个步骤，其中启动，等待和导入操作&#39;安全性OnCall&#39;和&#39;安​​全经理&#39;通知。”/&gt;&#xA;&lt;/noscript&gt; &lt;/div&gt; &lt;/a&gt; &lt;/figie&gt;&#xA;&lt;h3 id =“金丝雀token-lifecycle”&gt; canAry令牌生命周期&lt;/h3&gt;&#xA;&lt;p&gt;我们使用一个简单的四步生命周期来操作金丝雀令牌，并将其变成可操作的检测和响应能力：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt; &lt;strong&gt;创建&lt;/strong&gt;：生成一个独特的令牌，例如AWS API键，PDF链接或DNS子域，该子域在访问时“ home home”。  &lt;/li&gt;&#xA;&lt;li&gt; &lt;strong&gt;地点：&lt;/strong&gt;嵌入代币，攻击者会在其中看，例如代码存储库，配置目录，保险库，云控制台，数据库或共享驱动器。&lt;/li&gt;&#xA;&lt;li&gt; &lt;strong&gt;监视器：&lt;/strong&gt;背景服务手表可用于任何令牌使用，并使用元数据（Timestamp，ip，hostname）发送警报。请记住：如果您不使用平台，则必须构建自定义监视。&lt;/li&gt;&#xA;&lt;li&gt; &lt;strong&gt;响应：&lt;/strong&gt;调查警报，隔离受影响的资产并在触摸任何实际数据之前进行补救。将触发的令牌保留以进行取证并立即替换。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id =“金丝雀tokens and trufflehog-to-the-inscue”&gt;金丝雀令牌和Trufflehog进行营救！&lt;/h2&gt;&#xA;&lt;p&gt;我们在组织和存储库水平的秘密中种植了AWS API关键的金丝雀令牌（与其他几个）。当攻击者删除秘密并运行时href =“ https://docs.aws.amazon.com/sts/latest/apireference/api_getCallerItidentity.html” target =“ _ black” rel =“ noopener noreferrer”&gt;呼叫&lt;/a&gt; call &lt;/a&gt;对我们的代币触发的触发，&lt;/a&gt;触发了&lt;/a&gt;，触发了canary truff tike the canary tick &lt; href =“ https://trufflesecurity.com/blog/canaries” target =“ _ blank” rel =“ noopener noreferrer”&gt;而无需调用AWS API &lt;/a&gt;。 &lt;/p&gt;&#xA;&lt;p&gt;因为Thinkst在观看这些AWS帐户，所以我们得到了立即的松弛警报。该通知，由于我们的战略代币放置，这一通知揭示了确切的入口点。检测与响应小组对通知做出了反应，并提出了事件。 R＆D和安全性的团队逐渐采取行动，以控制和纠正事件，这再次导致没有代码修改，未经授权访问生产系统，暴露客户数据或访问个人信息。 &lt;/p&gt;&#xA;&lt;H3 ID =“我们的式式置换式策略”&gt;我们的金丝雀令牌放置策略&lt;/h3&gt;&#xA;&lt;p&gt;鉴于Github作为我们的主要真理来源的核心作用，使用金丝雀令牌保护它至关重要。具体来说，我们通过将令牌放置在组织级别（以标记任何回购漏洞）和每个存储库（以精确的位置在存储库级别上），从而在GitHub Secrets中战略性地部署AWS API关键的金丝雀令牌。其他平台获得了自己的口味。 For example, &lt;a href=&#34;https://help.canary.tools/hc/en-gb/articles/360021010497-How-do-I-create-a-Google-Docs-Sheets-Token&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Google Docs&lt;/a&gt; tokens live in shared Google Drive files, email-based tokens in dummy收件箱，和未使用子域中的DNS令牌。&lt;/p&gt;&#xA;&lt;p&gt;关键是要绘制每个资产（存储库，CI/CD管道，云控制台，保险库，吊舱，容器等），并在攻击者可能窥探的任何地方撒上各种代币的混合物。我们已经部署了成千上万的（或无限的金额），因此请注意您的步骤，因为每次点击后都有绊脚线。&lt;/p&gt;&#xA;&lt;h2 id =“ how-you-can-utilize-canary-tokens in your-security-stetup”&gt;如何在安全设置中使用金丝雀令牌&lt;/h2&gt;&#xA;&lt;p&gt;既然我们已经浏览了如何部署金丝雀令牌，我们想分享一些技巧，以了解如何利用它们。出于本博客的目的，我们将建议我们的建议上对我们内部使用的相同工具（因为我们认为它们是经过尝试和测试的技术），但是大多数一般指导仍然适用于其他类似的工具。&lt;/p&gt; &lt;/p&gt;&#xA;&lt;h3 id =“塑造自己的平台 - 策略与团队讨论”&gt;通过团队讨论来塑造您的安置策略&lt;/h3&gt;&#xA;&lt;p&gt;在决定金丝雀放置和警报策略之前，您应该考虑一些关键问题：&lt;/p&gt;&#xA;&lt;h4 id =“哪个typty-types-catch-攻击者 -  best”&gt;哪种令牌类型最好地捕捉攻击者？&lt;/h4&gt;&#xA;&lt;p&gt;从Thinkst的&lt;a href =“ https://help.canary.tools/hc/en-gb/articles/4701687447325-what-what-what-are-canarytokens” target =“ _ blank” rel =“ rel =” noopener noreferrer“&gt;” noopener noreferrer“将云/API键（AWS，Azure，Slack）与基于文件或链接的令牌（PDFS，DNS，URL）混合，因此您涵盖了代码存储库，文档和网络。使用各种范围扩大检测。&lt;/p&gt;&#xA;&lt;h4 id =“如何做 - 莫克 - 阿特斯 - 无法解决的失误”&gt;如何使警报不可能错过？&lt;/h4&gt;&#xA;&lt;p&gt;调整您的警报阈值和通道，以在紧迫性和噪声之间达到适当的平衡。考虑：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt; &lt;strong&gt;尽早确认警报：&lt;/strong&gt;在ThinkSt平台上及时确认警报，以避免将随后的警报分组，并从不同的IP地址分组重复的金丝雀令牌触发器的通知。&lt;/li&gt;&#xA;&lt;li&gt; &lt;strong&gt;元数据很重要：&lt;/strong&gt;进行更快的调查，确保每一个通知都包括金丝雀令牌元数据（名称，位置，提醒文本）。如果提醒文本已正确配置，则Thinkst平台将自动化此。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id =“ do-alerts-need-to-land”&gt;警报需要在哪里登陆？&lt;/h4&gt;&#xA;&lt;p&gt;选择团队实际观看的频道：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt; &lt;strong&gt;即时渠道：&lt;/strong&gt;松弛（带Webhooks）或Grafana Cloud IRM移动应用程序24/7分页&lt;/li&gt;&#xA;&lt;li&gt; &lt;strong&gt;辅助渠道：&lt;/strong&gt;安全邮件列表，SIEM或票务（例如Splunk）结构化事件跟踪&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;将每个严重性级别映射到正确的通道，因此没有滑动。&lt;/p&gt;&#xA;&lt;h4 id =“在哪里可以放tokens-live”&gt;代币应该在哪里？&lt;/h4&gt;&#xA;&lt;p&gt;在高风险和高价值斑点中撒上代币：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt; &lt;strong&gt; CI/CD管道&lt;/strong&gt;：作为虚拟环境变量，测试工作或次要工作FLOWS &lt;/li&gt;&#xA;&lt;li&gt; &lt;strong&gt;私有github/gitlab存储库&lt;/strong&gt;：在配置文件，注释或特定于分支的.env文件&lt;/li&gt;中&#xA;&lt;li&gt; &lt;strong&gt;开发人员工作站和构建服务器&lt;/strong&gt;：在〜/.aws/.aws/vertentials，隐藏的目录或注册表条目&lt;/li&gt;&#xA;&lt;li&gt; &lt;strong&gt;云帐户和控制台&lt;/strong&gt;：嵌套在IAM策略或元数据文档中&lt;/li&gt;&#xA;&lt;li&gt; &lt;strong&gt;共享网络驱动器和文档&lt;/strong&gt;：在普通的外观目录或pdfs &lt;/li&gt;中&#xA;&lt;li&gt; &lt;strong&gt;公共github/gitlab存储库&lt;/strong&gt;：在这里谨慎！警报疲劳是真实的。限制在公共存储库中使用金丝雀令牌，以避免由自动秘密扫描仪造成的误报，这是由无意间暴露的敏感信息触发的，例如GIT分支机构中的AWS API键（即显而易见的位置）。&lt;/li&gt; &lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id =“如何进行预防措施-Accidental-Triggers”&gt;您如何防止意外触发器？&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt; &lt;strong&gt;教育团队&lt;/strong&gt;：解释金丝雀令牌的“什么”和“哪里”。&lt;/li&gt;&#xA;&lt;li&gt; &lt;strong&gt;演示警报&lt;/strong&gt;：显示代币的工作方式以及通知是什么样的。&lt;/li&gt;&#xA;&lt;li&gt; &lt;strong&gt;宣布部署&lt;/strong&gt;：在团队渠道中分享推出计划。&lt;/li&gt;&#xA;&lt;li&gt; &lt;strong&gt;文档“禁区”区域&lt;/strong&gt;：在您的Wiki中发布共同的令牌名称和位置。&lt;/li&gt;&#xA;&lt;li&gt; &lt;strong&gt;使用Runbooks &lt;/strong&gt;：通过调查引导响应者避免混乱。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;您有两种金丝雀令牌的通信策略：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt; &lt;strong&gt;沉默&lt;/strong&gt;：没有内部通知，这比捕获内部人士，但误报更高。&lt;/li&gt;&#xA;&lt;li&gt; &lt;strong&gt;交流&lt;/strong&gt;：团队知道令牌，误报较少，但有可能降低攻击者的风险。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;在&#xA;&lt;p&gt;确定金丝雀令牌的目标对手。了解高级攻击者使用独特的方法，因此仅代币不足以预防全面访问。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt; &lt;strong&gt;外部攻击者&lt;/strong&gt;探测存储库或云资产&lt;/li&gt;&#xA;&lt;li&gt; &lt;strong&gt;自动扫描仪&lt;/strong&gt;寻找暴露的秘密&lt;/li&gt;&#xA;&lt;li&gt; &lt;strong&gt;内部人士威胁&lt;/strong&gt;在载有代币的地区窥探&lt;/li&gt;&#xA;&lt;li&gt; &lt;strong&gt;供应链攻击者&lt;/strong&gt;针对CI/CD &lt;/li&gt;&#xA;&lt;li&gt; &lt;strong&gt;网络钓鱼或社交工程&lt;/strong&gt;通过文档或电子邮件令牌&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;通过回答这些问题，您将使令牌类型与组织的风险和工具保持一致，提醒和放置，从而将每个令牌变成可靠的Tripwire。&lt;/p&gt;&#xA;&lt;h2 id =“最佳实践限制和gotchas”&gt;最佳实践，限制和gotchas &lt;/h2&gt;&#xA;&lt;p&gt;金丝雀令牌提供了有价值的，高信心的妥协警报，但触发攻击者已经在系统内部。虽然有效，但它们不是万无一失的解决方案，并且有局限性。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt; &lt;strong&gt;提供者支持各不相同：&lt;/strong&gt;并非每个平台上都可以使用每种令牌类型。如果您建立自己的定制API或秘密生成服务，您需要进行自己的监视。一种方法是将令牌ID（绝不是秘密！）登录到&lt;a href =“/doc/docs/loki/最终/”&gt; grafana loki &lt;/a&gt;，设置&lt;a href =“/doc/docs/docs/grafana/最终/alteral/nevering/” href =“/docs/grafana-cloud/natering-and-inm/irm/“&gt; grafana cloud irm &lt;/a&gt;。&lt;/li&gt;&#xA;&lt;li&gt; &lt;strong&gt;监视可用性：&lt;/strong&gt;如果您的令牌观察基础架构下降，或者更糟的是，您会完全失去可见度。因此，确保您的基础架构！&lt;/li&gt;&#xA;&lt;li&gt; &lt;strong&gt;内部人士的误报：&lt;/strong&gt;在我们正式宣布令牌推出之前，少数队友仅通过戳戳而意外地跳闸令牌。通过询问他们为什么访问这些凭据，我们迅速将这些警报标记为良性并继续前进。&lt;/li&gt;&#xA;&lt;li&gt; &lt;strong&gt;混淆攻击者来源：&lt;/strong&gt; vpns隐藏真实的IP，因此位置数据可能会误导。一些基于浏览器的令牌可以添加指纹印刷，但这仅适用于Web触发的令牌。&lt;/li&gt;&#xA;&lt;li&gt; &lt;strong&gt; API速率限制：&lt;/strong&gt;即使供应商宣传“无限”的API呼叫，其基础架构通常会实现限制。一次爆炸太多的代币创建或更新请求，您将击中节流甚至打破API。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;这是我们随着时间的推移学到的关键最佳实践：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt; &lt;strong&gt;使用描述性提醒：&lt;/strong&gt;利用Thinkst的“提醒”文本字段，将每个令牌标记为所有者，环境和位置。您还可以将JSON存储在该字段中，并以后通过UI或API检索。  那个元数据使您可以精确地指出所触摸的内容。&lt;/li&gt;&#xA;&lt;li&gt; &lt;strong&gt;每个位置一个令牌：&lt;/strong&gt;当令牌大火时，将其存档以进行取证，因为攻击者可能会重复使用或出售它，然后将其理想地替换为融合的新名称（例如，AWS_API_CREDS，而不是canary_token_aws）。&#xA;&lt;li&gt; &lt;strong&gt;小组成群：&lt;/strong&gt;按环境，团队或平台组织&lt;a href =” https://help.canary.tools/hc/en-gb/articles/360012874638-how-do-do-do-do-do-i-create-create-create-a-new-flock--------12874638- Noreferrer“&gt;羊群&lt;/a&gt;简化批量管理。&lt;/li&gt;&#xA;&lt;li&gt; &lt;strong&gt;将警报集成到事件响应中：&lt;/strong&gt;路由通知到您的消息传递系统，您的siem和/或票务系统，以便没有任何通过裂缝滑动的。&lt;/li&gt;&#xA;&lt;li&gt; &lt;strong&gt;混合令牌类型：&lt;/strong&gt;不要仅依靠AWS API键。部署文件，URL/DNS，电子邮件和命令令牌以涵盖每个攻击者策略。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Automate placement:&lt;/strong&gt; Use Thinkst’s &lt;a href=&#34;https://github.com/thinkst/canary-utils&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;scripts or IaC examples&lt;/a&gt; (Terraform, Ansible, Puppet, and AWS CloudFormation) to ensure consistency.我们还与Thinkst的支持紧密合作，以掌握其UI，API和工具并学习一些最佳实践。&lt;/li&gt;&#xA;&lt;li&gt; &lt;strong&gt;测试您的令牌和文档操作：&lt;/strong&gt;触发一些令牌部署后的安全环境以验证警报交付和下游自动化。这也将增强您的事件响应计划。这种做法使您可以模拟现实情况并完善您的响应程序。记录这些模拟事件以及为创建全面运行书所采取的相应步骤。当将来触发金丝雀令牌时，这些运行簿将作为有价值的指南，确保更有效，更有效的响应和更少的混乱。&lt;/li&gt; &lt;/li&gt;&#xA;&lt;li&gt; &lt;strong&gt;沟通广泛，明智：&lt;/strong&gt;使您的团队（甚至更广泛的社区）意识到金丝雀令牌。透明度降低了意外触发因素并建立了安全意识。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;通过了解这些局限性并遵循这些实践，您将保持金丝雀令牌部署精益，可靠，并准备好在展开的那一刻就可以捕捉到真正的攻击。 &lt;/p&gt;&#xA;&lt;H2 ID =“结论”&gt;结论&lt;/h2&gt;&#xA;&lt;p&gt;金丝雀令牌对我们来说是一种力量乘数，将我们的基础设施的每个角落变成了潜在的绊脚线，并为我们提供了在升级之前停止违规所需的宝贵时间。 &lt;/p&gt;&#xA;&lt;p&gt;用正确的令牌类型播种您的环境，集成自动化警报，并且永远不会低估知道对手在触摸您的真实资产之前就在内部的优势。&lt;/p&gt;&#xA;&lt;p&gt; &lt;em&gt; &lt;a href =“/products/cloud/？pg = blog＆plcmt = body-txt”&gt; grafana cloud &lt;/a&gt; &lt;/em&gt; &lt;em&gt;是开始使用指标，日志，痕迹，仪表，仪表板等最简单的方法。我们有一个宽敞的永远的层次和计划。&lt;/em&gt; &lt;em&gt; &lt;a href =“/auth/auth/insip/create-user/？pg = blog＆plcmt = body-txt = body-txt”&gt;现在免费注册！&lt;/a&gt; &lt;/a&gt; &lt;/em&gt; &lt;/em&gt; &lt;/p&gt; &lt;/em&gt; &lt;/p&gt;</description>
      <pubDate>Mon, 25 Aug 2025 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Grafana Mimir: 3 reasons to run the TSDB for Prometheus on bare metal】Grafana Mimir：在裸机上运行Prometheus的TSDB的3个理由</title>
      <link>https://grafana.com/blog/2025/08/22/grafana-mimir-3-reasons-to-run-the-tsdb-for-prometheus-on-bare-metal/</link>
      <description>【&lt;p&gt;&lt;em&gt;Wilfried Roset is an engineering manager who leads an SRE team and he is a Grafana Champion. Wilfried currently works at OVHcloud where he focuses on prioritizing sustainability, resilience, and industrialization to guarantee customers satisfaction.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;Whether it&amp;rsquo;s for efficient resource allocation, flexibility, high availability, or scalability, it makes a lot of sense to run Grafana Mimir on Kubernetes—but it&amp;rsquo;s not the only way to deploy Mimir.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;/oss/mimir/&#34;&gt;Mimir&lt;/a&gt; is Grafana Labs&amp;rsquo; horizontally scalable, highly available, multi-tenant TSDB for long-term storage for Prometheus metrics, and in this blog post I&amp;rsquo;ll cover three reasons why you might want to run it on virtual machines and/or bare metal instead.&lt;/p&gt;&#xA;&lt;h2 id=&#34;you-dont-have-kubernetes&#34;&gt;You don&amp;rsquo;t have Kubernetes&lt;/h2&gt;&#xA;&lt;p&gt;The most obvious reason you wouldn&amp;rsquo;t deploy Mimir on Kubernetes is that you don&amp;rsquo;t have a Kubernetes cluster at hand, so you cannot deploy Mimir—or anything else—on it. If you are in that camp, you might want to use &lt;a href=&#34;/docs/mimir/latest/set-up/puppet/&#34;&gt;Puppet&lt;/a&gt; or Ansible to deploy your TSDB. Similar to the guidance in the official &lt;a href=&#34;/docs/grafana/latest/setup-grafana/installation/debian/&#34;&gt;Grafana documentation&lt;/a&gt;, you could install Mimir in a few commands on a Debian-based system:&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;button x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;Copy code to clipboard&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;Copy&lt;/span&gt;&#xA;&lt;/button&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;sudo apt-get update&#xA;sudo apt-get install -y apt-transport-https software-properties-common wget&#xA;sudo mkdir -p /etc/apt/keyrings/&#xA;wget -q -O - https://apt.grafana.com/gpg.key | gpg --dearmor | sudo tee /etc/apt/keyrings/grafana.gpg &amp;gt; /dev/null&#xA;echo &amp;#34;deb [signed-by=/etc/apt/keyrings/grafana.gpg] https://apt.grafana.com stable main&amp;#34; | sudo tee -a /etc/apt/sources.list.d/grafana.list&#xA;sudo apt-get update&#xA;sudo apt-get install mimir&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;p&gt;For a RHEL-based system, run this command (the full instruction can be found in the &lt;a href=&#34;/docs/grafana/latest/setup-grafana/installation/redhat-rhel-fedora/&#34;&gt;corresponding documentation&lt;/a&gt;):&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;button x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;Copy code to clipboard&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;Copy&lt;/span&gt;&#xA;&lt;/button&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;sudo dnf install wget&#xA;wget -q -O gpg.key https://rpm.grafana.com/gpg.key&#xA;sudo rpm --import gpg.key&#xA;sudo bash -c &amp;#39;cat &amp;lt;&amp;lt; EOF &amp;gt; /etc/yum.repos.d/grafana.repo&#xA;[grafana]&#xA;name=grafana&#xA;baseurl=https://rpm.grafana.com&#xA;repo_gpgcheck=1&#xA;enabled=1&#xA;gpgcheck=1&#xA;gpgkey=https://rpm.grafana.com/gpg.key&#xA;sslverify=1&#xA;sslcacert=/etc/pki/tls/certs/ca-bundle.crt&#xA;EOF&amp;#39;&#xA;sudo dnf install mimir&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;h2 id=&#34;you-want-to-break-circular-dependencies&#34;&gt;You want to break circular dependencies&lt;/h2&gt;&#xA;&lt;p&gt;Depending on your information system and organization, you could be in a position where you&amp;rsquo;re the service provider to many teams, and you provide an internal metrics service to the Kubernetes/platform team. &lt;/p&gt;&#xA;&lt;p&gt;In this scenario, you probably have at least one critical circular dependency—the ops team running the Kubernetes cluster rely on their metrics, which are stored in the service you provide. An outage on the Kubernetes cluster, even a small one, can have a severe impact on your deployment, which then impacts access to the metrics. &lt;/p&gt;&#xA;&lt;p&gt;One way to break this circular dependency is to run at least two Kubernetes clusters and two Mimir clusters:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The Kubernetes cluster-A hosts Mimir cluster-1.&lt;/li&gt;&#xA;&lt;li&gt;The Kubernetes cluster-B hosts Mimir cluster-2.&lt;/li&gt;&#xA;&lt;li&gt;Mimir cluster-1 hosts the metrics of Kubernetes cluster-B.&lt;/li&gt;&#xA;&lt;li&gt;Mimir cluster-2 hosts the metrics of Kubernetes cluster-A.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;With this deployment approach, you have broken the circular dependencies, though you have increased the number of Kubernetes clusters run by your ops team. Be mindful that cross-Kubernetes outages exist and you should take that into account when designing your information system.&lt;/p&gt;&#xA;&lt;p&gt;Another way to break these circular dependencies is to not run Mimir on Kubernetes at all. In that case, I&amp;rsquo;d recommend following the process outlined in the &amp;ldquo;You don&amp;rsquo;t have Kubernetes&amp;rdquo; section above. &lt;/p&gt;&#xA;&lt;h2 id=&#34;you-want-to-learn-the-hard-way&#34;&gt;You want to learn the hard way&lt;/h2&gt;&#xA;&lt;p&gt;Finally, you might want to run Mimir outside of Kubernetes, just to learn how it works the hard way. &lt;/p&gt;&#xA;&lt;p&gt;Kubernetes offers so many features, integrations, and automation that it can sometimes be mistaken for magic. But with a bit of free time you can learn a lot about software without the &lt;em&gt;Kubernetes magic&lt;/em&gt;; Mimir is not different. &lt;/p&gt;&#xA;&lt;p&gt;If you are looking for your next metrics TSDB, I recommend spending some time looking at all aspects of your software. You could begin by following the &lt;a href=&#34;/docs/mimir/latest/get-started/play-with-grafana-mimir/&#34;&gt;getting started guide&lt;/a&gt;, then evaluate your critical dependencies. Once you are ready, you can &lt;a href=&#34;/docs/mimir/latest/set-up/helm-chart/&#34;&gt;deploy Mimir on Kubernetes&lt;/a&gt; or on bare metal. If you choose to deploy Mimir on bare metal and you manage your configuration with Puppet like I discussed earlier, we have &lt;a href=&#34;/docs/mimir/latest/set-up/puppet/&#34;&gt;the module for you&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;running-mimir-on-kubernetes-vs-bare-metal&#34;&gt;Running Mimir on Kubernetes vs. bare metal&lt;/h2&gt;&#xA;&lt;p&gt;While running Mimir on Kubernetes can bring many benefits, there are also some potential drawbacks and considerations to be aware of. Ultimately, the decision depends on your specific needs, resources, and expertise. &lt;/p&gt;&#xA;&lt;p&gt;Weigh the benefits against the potential drawbacks and consider a proof-of-concept deployment to determine the best approach for your use case. More specifically, make sure to have a closer look at the pros and cons of bare metal deployments:&lt;/p&gt;&#xA;&lt;p&gt;Pros:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Can be deployed without a Kubernetes cluster&lt;/li&gt;&#xA;&lt;li&gt;Allows for breaking of circular dependencies&lt;/li&gt;&#xA;&lt;li&gt;Opportunity to learn about the software without relying on Kubernetes features and automation&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Cons:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;May require more manual configuration and management&lt;/li&gt;&#xA;&lt;li&gt;Could increase the complexity of deployment and maintenance&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;em&gt;Want to share your Grafana story and dashboards with the community? Drop us a note at&lt;/em&gt; &lt;em&gt;&lt;a href=&#34;mailto:stories@grafana.com&#34;&gt;stories@grafana.com!&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;】&lt;p&gt; &lt;em&gt; Wilfried Roset是一名工程经理，领导SRE团队，他是Grafana冠军。威尔弗里德（Wilfried）目前在OVHCloud工作，他专注于优先考虑可持续性，韧性和工业化以保证客户满意度。&lt;/em&gt; &lt;/p&gt;&#xA;&lt;p&gt;是否是用于有效的资源分配，灵活性，高可用性或可扩展性，在Kubernetes上运行Grafana Mimir很有意义，但这并不是部署Mimir的唯一方法。&lt;/p&gt;&#xA;&lt;p&gt; &lt;a href =“/oss/mimir/”&gt; mimir &lt;/a&gt;是Grafana Labs的水平扩展，高度可用，多租户的TSDB，用于长期存储用于Prometheus指标的长期存储，在此博客文章中，我可能想掩盖三个理由在虚拟机器和/或裸露的金属上使用三个理由。&#xA;&lt;h2 id =“ you-dont-have-kubernetes”&gt;您没有kubernetes &lt;/h2&gt;&#xA;&lt;p&gt;您不会在Kubernetes上部署Mimir的最明显原因是您手头上没有Kubernetes群集，因此您不能在其中部署Mimir（或其他任何东西）。如果您在那个营地，则可能需要使用&lt;a href =“/doc/mimir/最终/set-in-set-up/puppet/”&gt; puppet &lt;/a&gt;或可安排来部署您的TSDB。类似于官方&lt;a href =“/docs/grafana/最终/setup-grafana/installation/debian/“&gt; grafana文档&lt;/a&gt;，您可以在基于debian的系统上安装mimir：&lt;/p&gt;&gt;&#xA;&lt;div class =“ code-snippet code-snippet__mini”&gt; &lt;div class =“ lang-toolbar__mini”&gt;&#xA;&lt;span class =“ code-clipboard”&gt;&#xA;&lt;button x-data =“ app_code_snippet（）” x-init =“ init（）” @click =“ copy（）”&gt;&#xA;&lt;img class =“ code-clipboard__icon” src =“/媒体/images/icons/icon-copy-small-2.svg” alt =“复制代码到剪贴板” width =“ 14”高度=“ 13”&gt;&#xA;&lt;span&gt;复制&lt;/span&gt;&#xA;&lt;/button&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt; &lt;div class =“代码 - 尼珀代码snippet__border”&gt;&#xA;&lt;pre data-expanded =“ false”&gt; &lt;code class =“ language-none”&gt; sudo apt-get更新&#xA;sudo apt-get install -y apt-transport-https https软件 - 普罗托斯 - 普通wget&#xA;sudo mkdir -p/etc/apt/keyrings/&#xA;WGET -Q -O -https：//apt.grafana.com/gpg.key | GPG  -  dearmor | sudo tee /etc/apt/keyrings/grafana.gpg&gt;/dev/null&#xA;echo“ deb [signed-by =/etc/apt/keyrings/grafana.gpg] https://apt.grafana.com稳定的main” | sudo tee -a/etc/apt/sources.list.d/grafana.list.list&#xA;sudo apt-get更新&#xA;sudo apt-get安装mimir &lt;/code&gt; &lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt; &lt;p&gt;对于基于RHEL的系统，运行此命令（可以在&lt;a a href =“/docs/grafana/grafana/最新/setup-grafana/installation/redhat-rhel-fedora/”中找到完整的指令&lt;/a&gt;）：&lt;/p&gt;）：&lt;/p&gt;）：&lt;/p&gt;）&#xA;&lt;div class =“ code-snippet code-snippet__mini”&gt; &lt;div class =“ lang-toolbar__mini”&gt;&#xA;&lt;span class =“ code-clipboard”&gt;&#xA;&lt;button x-data =“ app_code_snippet（）” x-init =“ init（）” @click =“ copy（）”&gt;&#xA;&lt;img class =“ code-clipboard__icon” src =“/媒体/images/icons/icon-copy-small-2.svg” alt =“复制代码到剪贴板” width =“ 14”高度=“ 13”&gt;&#xA;&lt;span&gt;复制&lt;/span&gt;&#xA;&lt;/button&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt; &lt;div class =“代码 - 尼珀代码snippet__border”&gt;&#xA;&lt;pre data-expanded =“ false”&gt; &lt;code class =“ language-none”&gt; sudo dnf安装wget&#xA;WGET -Q -O GPG.Key https://rpm.grafana.com/gpg.key&#xA;sudo rpm -import gpg.key&#xA;sudo bash -c&#39;cat &lt;&lt; eof&gt; /etc/yum.repos.d/grafana.repo&#xA;[Grafana]&#xA;名称= Grafana&#xA;baseurl = https：//rpm.grafana.com&#xA;repo_gpgcheck = 1&#xA;启用= 1&#xA;gpgcheck = 1&#xA;gpgkey = https：//rpm.grafana.com/gpg.key&#xA;sslverify = 1&#xA;sslcacert =/etc/pki/tls/certs/ca-bundle.crt&#xA;eof&#39;&#xA;sudo dnf安装mimir &lt;/code&gt; &lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt; &lt;h2 id =“你想偏向圆形的依赖性”&gt;您想打破循环依赖项&lt;/h2&gt;&#xA;&lt;p&gt;根据您的信息系统和组织，您可以处于许多团队的服务提供商的位置，并且为Kubernetes/Platform团队提供内部指标服务。 &lt;/p&gt;&#xA;&lt;p&gt;在这种情况下，您可能至少有一个关键的循环依赖性 - 运行Kubernetes群集的OPS团队依赖于其指标，这些指标存储在您提供的服务中。 Kubernetes群集的中断，甚至是一个小群集，可能会对您的部署产生严重影响，从而影响对指标的访问。 &lt;/p&gt;&#xA;&lt;p&gt;打破这种循环依赖性的一种方法是至少运行两个kubernetes簇和两个mimir簇：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt; kubernetes cluster-a主持mimir cluster-1。&lt;/li&gt;&#xA;&lt;li&gt; kubernetes cluster-b主机mimir cluster-2。&lt;/li&gt;&#xA;&lt;li&gt; mimir cluster-1托有Kubernetes cluster-B。&lt;/li&gt;的指标&#xA;&lt;li&gt; mimir cluster-2托管kubernetes cluster-a的指标。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;使用这种部署方法，您已经打破了循环依赖性，尽管您增加了OPS团队运行的Kubernetes群集的数量。请注意，跨库伯涅特存在存在，在设计信息系统时应考虑到这一点。&lt;/p&gt;&#xA;&lt;p&gt;打破这些循环依赖性的另一种方法是根本不在kubernetes上运行mimir。在这种情况下，我建议按照上面的“您没有kubernetes”部分概述的过程遵循该过程。 &lt;/p&gt;&#xA;&lt;h2 id =“你是愿意的学习 - 艰难的路”&gt;您想学习困难的方法&lt;/h2&gt;&#xA;&lt;p&gt;最后，您可能想在Kubernetes之外运行Mimir，只是为了了解它的工作方式。 &lt;/p&gt;&#xA;&lt;p&gt; kubernetes提供了许多功能，集成和自动化，有时可能会误认为魔术。但是，如果没有&lt;em&gt; kubernetes Magic &lt;/em&gt;，您可以在空闲时间里学到很多有关软件的知识；米米尔没有什么不同。 &lt;/p&gt;&#xA;&lt;p&gt;如果您正在寻找下一个指标TSDB，建议您花一些时间查看软件的各个方面。您可以首先关注&lt;a href =“/doc/mimir/lestest/wet get-started/play-with-with-with-with-with-with-with-with-with-with-with-with-with grafana-mimir/”&gt;入门指南&lt;/a&gt;，然后评估您的关键依赖性。准备就绪后，您可以&lt;a href =“/doc/mimir/最新/设置/helm-chart/”&gt;在kubernetes上部署mimir &lt;/a&gt;或在裸机上。如果您选择在裸金属上部署mimir，并且像我之前讨论的那样用木偶来管理配置，那么我们有&lt;a href =“/docs/mimir/最终/sett/stet/set-up/puppet/“&gt; for you for you &lt;/a&gt;。&lt;/p&gt;&#xA;&lt;h2 id =“跑步mimir-on-kubernetes-vs-bare-metal“&gt; kubernetes上的米米尔与裸机&lt;/h2&gt;&#xA;&lt;p&gt;在Kubernetes上运行Mimir可以带来许多好处，但也有一些潜在的缺点和注意事项需要注意。最终，决定取决于您的特定需求，资源和专业知识。 &lt;/p&gt;&#xA;&lt;p&gt;权衡收益与潜在缺点，并考虑概念验证的部署，以确定用例的最佳方法。更具体地说，请确保仔细研究裸机部署的利弊：&lt;/p&gt;&#xA;&lt;p&gt;专业人士：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;可以在没有kubernetes群集的情况下部署&#xA;&lt;li&gt;允许打破圆形依赖关系&lt;/li&gt;&#xA;&lt;li&gt;有机会在不依赖Kubernetes功能和自动化的情况下了解该软件&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt; cons：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;可能需要更多的手动配置和管理&lt;/li&gt;&#xA;&lt;li&gt;可以增加部署和维护的复杂性&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt; &lt;em&gt;想与社区分享您的Grafana故事和仪表板吗？给我们留言&lt;/em&gt; &lt;em&gt; &lt;a href =“ mailto：story@grafana.com”&gt; story@grafana.com！&lt;/a&gt; &lt;/em&gt; &lt;/em&gt; &lt;/p&gt;</description>
      <pubDate>Fri, 22 Aug 2025 00:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>