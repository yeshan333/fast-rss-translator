<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Grafana Labs blog on Grafana Labs</title>
    <link>/blog/index.xml</link>
    <description>Recent content in Grafana Labs blog on Grafana Labs</description>
    <item>
      <title>【Add observability to cart: How online retailer ASOS reduces MTTR with Grafana Cloud】添加可观察性到购物车：在线零售商 ASOS 如何使用 Grafana Cloud 降低 MTTR</title>
      <link>https://grafana.com/blog/2024/12/30/add-observability-to-cart-how-online-retailer-asos-reduces-mttr-with-grafana-cloud/</link>
      <description>【&lt;p&gt;Like the fit your friend got on ASOS? There&amp;rsquo;s a good chance Grafana Cloud had something to do with that.&lt;/p&gt;&#xA;&lt;p&gt;Each year, more than 20 million customers come to the UK-based online retailer to fill their digital carts, and they expect a seamless online experience as they shop and check out. ASOS can consistently provide that with the help of Grafana Cloud.&lt;/p&gt;&#xA;&lt;p&gt;“There are alerts set up for many of our customer-facing journeys,” said Dylan Morley, Lead Principal Engineer at ASOS. &amp;ldquo;We know pretty instantly as soon as something starts going wrong.”&lt;/p&gt;&#xA;&lt;div&#xA;class=&#34;youtube-lazyload responsive-video&#34;&#xA;data-embed=&#34;t4a9q4OLXfo&#34;&#xA;data-url=&#34;https://www.youtube.com/embed/t4a9q4OLXfo?autoplay=1&amp;amp;rel=0&#34;&#xA;data-title=&#34;YouTube Video&#34;&#xA;&gt;&#xA;&lt;div class=&#34;play-button&#34;&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;That was not always the case. About 10 years ago, &amp;ldquo;observability didn&amp;rsquo;t really exist as a concept. Data was spread out. It was difficult to find what you needed,&amp;rdquo; says Morley. Without a centralized data store, &amp;ldquo;when there was an incident, you had to go and find all of the information you wanted.&amp;rdquo;&lt;/p&gt;&#xA;&lt;p&gt;To alleviate that stress, ASOS began to use Grafana OSS in 2017, in large part due to Grafana Labs&amp;rsquo; &amp;ldquo;big tent&amp;rdquo; philosophy, which allows organizations to choose their own tools and bring together all of their disparate data into one dynamic dashboard.&lt;/p&gt;&#xA;&lt;p&gt;With a growing catalog of &lt;a href=&#34;/grafana/plugins/all-plugins/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;100+ plugins for Grafana&lt;/a&gt; and &lt;a href=&#34;/docs/grafana-cloud/data-configuration/integrations/integration-reference/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;65+ Grafana Cloud integrations&lt;/a&gt; for monitoring third-party tools, &amp;ldquo;the data source model that Grafana gives us means that we can quickly plot any data from any source that we want alongside existing telemetry data that we might already have,&amp;rdquo; says Morley. &amp;ldquo;It gives us this holistic view to understand our systems from a user perspective.&amp;rdquo;&lt;/p&gt;&#xA;&lt;p&gt;Given the immediate benefits of Grafana, ASOS’ adoption of the open source tool grew quickly. By 2022, the team moved to the fully hosted Grafana Cloud platform to avoid updating and maintaining Grafana so they can focus on scaling their observability strategy and investing in other Grafana Cloud tools, such as &lt;a href=&#34;/products/cloud/slo/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana SLO&lt;/a&gt; and &lt;a href=&#34;/solutions/kubernetes/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Kubernetes Monitoring&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Access to &lt;a href=&#34;/docs/plugins/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Enterprise plugins&lt;/a&gt; was another key benefit of moving to Grafana Cloud.&lt;/p&gt;&#xA;&lt;p&gt;“When we were running Grafana ourselves, we needed to query New Relic and ServiceNow, so we built some in-house versions of plugins — but all that came with the overhead of maintenance,” Morley said. “One of the benefits of the Enterprise plugins was that we could deprecate [our existing plugins], just take advantage of the Grafana Cloud offering, and have less code that we need to own and maintain.&amp;rdquo;&lt;/p&gt;&#xA;&lt;p&gt;Now when an issue occurs, &amp;ldquo;all the monitoring in one place helps,&amp;rdquo; says Fahri Ulucay, Site Reliability Engineer at ASOS. &amp;ldquo;We have high-level dashboards. If we see something fluctuating there, we can all go into Grafana, zoom in, look into details and that helps to identify [the issue] quicker and then resolve it quicker as well.&amp;rdquo;&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;em&gt;&amp;ldquo;When something shows red on our SLOs or our error budgets, we know that that&amp;rsquo;s a real problem … We are much more confident that the metrics that we are using accurately represent and describe the systems that ASOS relies on.&amp;rdquo;&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;— Adam Watson, Lead Site Reliability Engineer&lt;/em&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;Sounds too good to be true? There are about 800 other ASOS engineers using Grafana who would back this up.&lt;/p&gt;&#xA;&lt;p&gt;&amp;ldquo;We have quite a few tools actually in SRE that we try and get people to use in the platforms, but I have never seen people have a problem with Grafana,&amp;rdquo; says Adam Watson, Lead Site Reliability Engineer. &amp;ldquo;I have to say one of the nice things about Grafana is, it&amp;rsquo;s just never been a blocker.&amp;rdquo;&lt;/p&gt;&#xA;&lt;p&gt;As a result, &amp;ldquo;we are more prepared and more confident,&amp;rdquo; continues Watson. &amp;ldquo;We understand not only what metrics matter most to us but we understand how they sit in the holistic picture of the systems and the services that we support.&amp;rdquo;&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;To learn more about ASOS&amp;rsquo; observability stack and how Grafana Cloud has reduced MTTR and their overall costs, check out the &lt;a href=&#34;/success/asos/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;ASOS success story&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;】&lt;p&gt;喜欢您朋友在 ASOS 上的表现吗？ Grafana Cloud 很可能与此有关。&lt;/p&gt;&#xA;&lt;p&gt;每年，超过 2000 万客户来到这家英国在线零售商填写他们的数字购物车，他们希望在购物和结账时获得无缝的在线体验。 ASOS 可以在 Grafana Cloud 的帮助下始终如一地提供这一服务。&lt;/p&gt;&#xA;&lt;p&gt;“我们为许多面向客户的旅程设置了警报，”ASOS 首席首席工程师 Dylan Morley 说道。 “一旦出现问题，我们就会立即知道。”&lt;/p&gt;&#xA;&lt;div&#xA;类 =“youtube-lazyload 响应视频”&#xA;数据嵌入=“t4a9q4OLXfo”&#xA;data-url=&#34;https://www.youtube.com/embed/t4a9q4OLXfo?autoplay=1&amp;rel=0&#34;&#xA;数据标题=“YouTube 视频”&#xA;&gt;&#xA;&lt;div class=&#34;play-button&#34;&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;情况并非总是如此。大约 10 年前，“可观察性并不是一个真正存在的概念。数据被分散开来。很难找到你需要的东西，”莫利说。如果没有集中式数据存储，“当发生事件时，您必须去查找所需的所有信息。”&lt;/p&gt;&#xA;&lt;p&gt;为了缓解这种压力，ASOS 于 2017 年开始使用 Grafana OSS，这在很大程度上归功于 Grafana Labs 的“大帐篷”理念，该理念允许组织选择自己的工具并将所有不同的数据汇集到一个动态中仪表板。&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;/grafana/plugins/all-plugins/?pg=blog&amp;plcmt=body-txt&#34;&gt;100 多个 Grafana 插件&lt;/a&gt;和&lt;a href=&#34;/docs/ grafana-cloud/data-configuration/integrations/integration-reference/?pg=blog&amp;plcmt=body-txt&#34;&gt;65+ Grafana Cloud 集成&lt;/a&gt;，用于监控第三方工具，“数据源模型Grafana 为我们提供了一种方法，让我们可以快速绘制我们想要的任何来源的任何数据以及我们可能已经拥有的现有遥测数据。”Morley 说道。 “它为我们提供了从用户角度理解我们系统的整体视图。”&lt;/p&gt;&#xA;&lt;p&gt;鉴于 Grafana 带来的直接好处，ASOS 对开源工具的采用迅速增长。到 2022 年，该团队迁移到完全托管的 Grafana Cloud 平台，以避免更新和维护 Grafana，这样他们就可以专注于扩展其可观测性策略并投资其他 Grafana Cloud 工具，例如 &lt;a href=&#34;/products/cloud/slo/ ?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana SLO&lt;/a&gt; 和 &lt;a href=&#34;/solutions/kubernetes/?pg=blog&amp;plcmt=body-txt&#34;&gt;Kubernetes监控&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;访问 &lt;a href=&#34;/docs/plugins/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana Enterprise 插件&lt;/a&gt;是迁移到 Grafana Cloud 的另一个主要好处。&lt;/p&gt;&#xA;&lt;p&gt;“当我们自己运行 Grafana 时，我们需要查询 New Relic 和 ServiceNow，因此我们构建了一些内部版本的插件 - 但所有这些都伴随着维护开销，”Morley 说。 “企业插件的好处之一是我们可以弃用[我们现有的插件]，只需利用 Grafana云服务，我们需要拥有和维护的代码更少。”&lt;/p&gt;&#xA;&lt;p&gt;现在，当出现问题时，“在一个地方进行所有监控都会有所帮助”，ASOS 站点可靠性工程师 Fahri Ulucay 说道。 “我们有高级仪表板。如果我们看到那里有一些波动，我们都可以进入 Grafana，放大，查看细节，这有助于更快地识别[问题]，然后也更快地解决它。”&lt;/p&gt;&#xA;&lt;块引用&gt;&#xA;&lt;p&gt;&lt;em&gt;“当我们的 SLO 或错误预算上出现红色时，我们就知道这是一个真正的问题……我们更有信心，我们使用的指标能够准确地表示和描述 ASOS 所依赖的系统。 ”&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;— Adam Watson，首席站点可靠性工程师&lt;/em&gt;&lt;/p&gt;&#xA;&lt;/块引用&gt;&#xA;&lt;p&gt;听起来好得令人难以置信？还有大约 800 名其他使用 Grafana 的 ASOS 工程师会支持这一点。&lt;/p&gt;&#xA;&lt;p&gt;“我们实际上在 SRE 中拥有相当多的工具，我们尝试让人们在平台中使用它们，但我从未见过人们对 Grafana 遇到问题，”首席站点可靠性工程师 Adam Watson 说道。 “我不得不说 Grafana 的优点之一是，它从来都不是一个障碍。”&lt;/p&gt;&#xA;&lt;p&gt;因此，“我们准备得更充分，也更有信心，”沃森继续说道。 “我们不仅了解哪些指标对我们最重要，而且了解它们在我们支持的系统和服务的整体情况中的地位。”&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;要详细了解 ASOS 的可观测性堆栈以及 Grafana Cloud 如何降低 MTTR 及其总体成本，请查看 &lt;a href=&#34;/success/asos/?pg=blog&amp;plcmt=body-txt&#34;&gt;ASOS成功故事&lt;/a&gt;。&lt;/em&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 30 Dec 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Inside Grafana Labs: how we foster a culture of continuous learning】Grafana Labs 内部：我们如何培养持续学习的文化</title>
      <link>https://grafana.com/blog/2024/12/19/inside-grafana-labs-how-we-foster-a-culture-of-continuous-learning/</link>
      <description>【&lt;p&gt;&lt;em&gt;&lt;strong&gt;“What did you learn today?”&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;It’s a question many of us heard as a child. Maybe a parent asked you on the way home from school, or a sibling around the dinner table, or even a curious aunt or uncle at a family gathering. But when was the last time someone asked you, as an adult, what you actually &lt;em&gt;learned&lt;/em&gt; at the end of a day?&lt;/p&gt;&#xA;&lt;p&gt;The truth is, as we grow older, the expectation to be constantly learning diminishes. It seems we’re simply too tired, or too busy with other responsibilities, to be learning all the time. As a member of the Learning and Development team here at Grafana Labs, I strive to reset that expectation.&lt;/p&gt;&#xA;&lt;p&gt;Since our early days as a company, we’ve fostered a culture of continuous learning. We start during an employee’s first few days as a Grafanista, beginning with our virtual onboarding sessions (Grafana Labs is a &lt;a href=&#34;/blog/2023/05/12/inside-grafana-labs-remote-first-is-relationship-first/&#34;&gt;remote-first company&lt;/a&gt;) and then through our week-long, in-person onboarding events, which are a great way to connect with other new employees and members of the Grafana Labs leadership team.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1999px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link captioned&#34;&#xA;href=&#34;/media/blog/continuous-learning/continuous-learning-onboarding.jpg&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload mb-0&#34;&#xA;data-src=&#34;/media/blog/continuous-learning/continuous-learning-onboarding.jpg&#34;data-srcset=&#34;/media/blog/continuous-learning/continuous-learning-onboarding.jpg?w=320 320w, /media/blog/continuous-learning/continuous-learning-onboarding.jpg?w=550 550w, /media/blog/continuous-learning/continuous-learning-onboarding.jpg?w=750 750w, /media/blog/continuous-learning/continuous-learning-onboarding.jpg?w=900 900w, /media/blog/continuous-learning/continuous-learning-onboarding.jpg?w=1040 1040w, /media/blog/continuous-learning/continuous-learning-onboarding.jpg?w=1240 1240w, /media/blog/continuous-learning/continuous-learning-onboarding.jpg?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A photo from a recent Grafana Labs onboarding event.&#34;width=&#34;1999&#34;height=&#34;1051&#34;title=&#34;*A photo from a 2024 Grafana Labs in-person onboarding event in Washington, DC.*&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/continuous-learning/continuous-learning-onboarding.jpg&#34;&#xA;alt=&#34;A photo from a recent Grafana Labs onboarding event.&#34;width=&#34;1999&#34;height=&#34;1051&#34;title=&#34;*A photo from a 2024 Grafana Labs in-person onboarding event in Washington, DC.*&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;figcaption class=&#34;w-100p caption text-gray-13 &#34;&gt;&lt;em&gt;A photo from a 2024 Grafana Labs in-person onboarding event in Washington, DC.&lt;/em&gt;&lt;/figcaption&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;Our goal is to inspire our employees to learn and grow right from the start by investing heavily in their initial onboarding experience. But we also encourage employees to continue learning throughout their careers at Grafana Labs.&lt;/p&gt;&#xA;&lt;p&gt;In this post, we share exactly how we do that. Read on to learn more about our learning management systems, professional development budgets, and other ways we ensure Grafanistas learn something each and every day.&lt;/p&gt;&#xA;&lt;h2 id=&#34;learning-on-demand&#34;&gt;Learning on demand&lt;/h2&gt;&#xA;&lt;p&gt;All Grafana Labs employees are respectfully empowered to work in the way that is best for them. Flexibility and autonomy are &lt;a href=&#34;/about/careers/&#34;&gt;cornerstones of our work&lt;/a&gt;, so it makes sense that those values also extend to our learning culture. Therefore, we provide a variety of on-demand resources for Grafanistas to learn what they want to learn, when and how they want to learn it.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.docebo.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Docebo&lt;/a&gt;, our learning management system (LMS), provides access to a variety of custom courses. These courses — created by Grafanistas, for Grafanistas — provide relevant content that accounts for our unique circumstances.&lt;/p&gt;&#xA;&lt;p&gt;For example, our Level-Up Toolkits contain curated resources to help people managers dive deeper into critical topics like delegation, change management, and feedback. These toolkits are part of a learning path that Grafana Labs employees are free to opt in or out of, based on their interests and availability.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1010px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link captioned&#34;&#xA;href=&#34;/media/blog/continuous-learning/continuous-learning-toolkit.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload mb-0&#34;&#xA;data-src=&#34;/media/blog/continuous-learning/continuous-learning-toolkit.png&#34;data-srcset=&#34;/media/blog/continuous-learning/continuous-learning-toolkit.png?w=320 320w, /media/blog/continuous-learning/continuous-learning-toolkit.png?w=550 550w, /media/blog/continuous-learning/continuous-learning-toolkit.png?w=750 750w, /media/blog/continuous-learning/continuous-learning-toolkit.png?w=900 900w, /media/blog/continuous-learning/continuous-learning-toolkit.png?w=1040 1040w, /media/blog/continuous-learning/continuous-learning-toolkit.png?w=1240 1240w, /media/blog/continuous-learning/continuous-learning-toolkit.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A screenshot of courses for Grafana Labs employees in Docebo.&#34;width=&#34;1010&#34;height=&#34;748&#34;title=&#34;*Custom toolkits on Docebo encourage continued learning about various topics.*&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/continuous-learning/continuous-learning-toolkit.png&#34;&#xA;alt=&#34;A screenshot of courses for Grafana Labs employees in Docebo.&#34;width=&#34;1010&#34;height=&#34;748&#34;title=&#34;*Custom toolkits on Docebo encourage continued learning about various topics.*&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;figcaption class=&#34;w-100p caption text-gray-13 &#34;&gt;&lt;em&gt;Custom toolkits on Docebo encourage continued learning about various topics.&lt;/em&gt;&lt;/figcaption&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;Additionally, our partnership with LinkedIn Learning allows our team members to browse thousands of additional courses directly from our LMS.&lt;/p&gt;&#xA;&lt;p&gt;We’re also working on a new Learning &amp;amp; Development Hub that will serve as a one-stop shop for employees to access process documentation, public speaking resources, new hire onboarding documentation, and other on-demand learning materials.&lt;/p&gt;&#xA;&lt;h2 id=&#34;learning-live-and-with-your-team&#34;&gt;Learning live (and with your team)&lt;/h2&gt;&#xA;&lt;p&gt;As a remote-first company, we want to help Grafanistas build connections with their peers, even when they live on different continents. One way we achieve this — while also encouraging continuous learning — is through our Concierge Services, a program that offers live learning opportunities in a group setting.&lt;/p&gt;&#xA;&lt;p&gt;Concierge Services brings learning directly to Grafana Labs employees. They simply choose from a menu of courses, let us know their preferred date and time, and that’s it! Our L&amp;amp;D team handles the coordination, preparation, and delivery of the training — either in person or virtually — by an experienced facilitator. Sessions can be run for as few or as many people as desired and span a variety of topics, including time management, career progression, and public speaking. If one of the existing sessions doesn’t quite hit the mark, Grafanistas can request custom sessions designed specifically for their unique interests.&lt;/p&gt;&#xA;&lt;h2 id=&#34;professional-development-budget&#34;&gt;Professional development budget&lt;/h2&gt;&#xA;&lt;p&gt;When Grafanistas want to branch out a bit further — maybe to obtain a professional certification, learn another language, or attend an industry conference — we offer our professional development budget.&lt;/p&gt;&#xA;&lt;p&gt;Each Grafana Labs employee is allocated $1500 USD per calendar year to invest in their professional development. Few limits exist on the program; everybody has the freedom to use their budget in a way that works for them.&lt;/p&gt;&#xA;&lt;p&gt;This year, I used my professional development budget to attend the &lt;a href=&#34;https://afrotechconference.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Afrotech Conference&lt;/a&gt; in Houston, Texas. It was so exciting to build out connections, network with other professionals, and learn valuable insights to bring back to Grafana Labs at the end of my trip!&lt;/p&gt;&#xA;&lt;p&gt;Other common ways to use the budget include spending on:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Books&lt;/strong&gt;: &lt;a href=&#34;https://brenebrown.com/hubs/dare-to-lead/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;“Dare to Lead”&lt;/a&gt; by Brene Brown is a popular one.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Industry certifications&lt;/strong&gt;: For our engineers, &lt;a href=&#34;https://kubernetes.io/training/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Kubernetes&lt;/a&gt; and &lt;a href=&#34;https://www.comptia.org/certifications&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;CompTIA&lt;/a&gt; certifications are especially common.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Subscriptions&lt;/strong&gt;: &lt;a href=&#34;https://www.shrm.org/home&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;SHRM memberships&lt;/a&gt;, as one example, are something our People Team recommends.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Conferences&lt;/strong&gt;: In the past, Grafanistas have attended the &lt;a href=&#34;https://www.gs1us.org/education-and-events/events/gs1-connect&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;GS1 Connect Summit&lt;/a&gt;, &lt;a href=&#34;https://latinasintech.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Latinas in Tech&lt;/a&gt;, and, of course, major events in the open source software space, such as &lt;a href=&#34;https://events.linuxfoundation.org/kubecon-cloudnativecon-north-america/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;KubeCon&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Other &lt;strong&gt;technical or professional development courses&lt;/strong&gt;, including those offered by &lt;a href=&#34;https://www.boot.dev/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Boot.dev&lt;/a&gt; and &lt;a href=&#34;https://www.udemy.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Udemy&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;learn-more-about-working-at-grafana-labs&#34;&gt;Learn more about working at Grafana Labs&lt;/h2&gt;&#xA;&lt;p&gt;At Grafana Labs, you never age out of discovering new things. By taking advantage of our on-demand and live learning opportunities, each Grafanista has the opportunity to expand their knowledge and lean into our value of helping ourselves, and others, thrive.&lt;/p&gt;&#xA;&lt;p&gt;If you’re interested in learning more about working at Grafana Labs — including some of our open positions right now — please refer to our &lt;a href=&#34;/about/careers/&#34;&gt;careers page&lt;/a&gt;. We’d love to hear from you!&lt;/p&gt;】&lt;p&gt;&lt;em&gt;&lt;strong&gt;“你今天学到了什么？”&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;这是我们很多人小时候都听过的问题。也许是家长在放学回家的路上问你，或者是餐桌旁的兄弟姐妹，甚至是家庭聚会上好奇的阿姨或叔叔。但是，最后一次有人问你，作为一个成年人，你在一天结束时实际上学到了什么？&lt;/p&gt;&#xA;&lt;p&gt;事实是，随着年龄的增长，不断学习的期望逐渐减弱。看来我们只是太累了，或者太忙于其他责任，无法一直学习。作为 Grafana Labs 学习和开发团队的一员，我努力重新设定这一期望。&lt;/p&gt;&#xA;&lt;p&gt;自公司成立之初起，我们就培养了持续学习的文化。我们从员工成为 Grafanista 的头几天开始，从我们的虚拟入职会议开始（Grafana Labs 是一个 &lt;a href=&#34;/blog/2023/05/12/inside-grafana-labs-remote-first-is-relationship -first/&#34;&gt;远程优先公司&lt;/a&gt;），然后通过我们为期一周的面对面入职活动，这是与其他新员工和成员建立联系的好方法Grafana Labs 领导团队。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1999px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接标题”&#xA;href=&#34;/media/blog/continuous-learning/continuous-learning-onboarding.jpg&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“lazyload mb-0”&#xA;数据-src =“/媒体/博客/连续学习/连续学习-onboarding.jpg”数据-srcset =“/媒体/博客/连续学习/连续学习-onboarding.jpg？w = 320 320w，/媒体/博客/持续学习/持续学习-onboarding.jpg？w=550 550w， /media/blog/持续学习/持续学习-onboarding.jpg？w=750 750w，/media/blog/持续学习/持续学习-onboarding.jpg？w=900 900w，/media/博客/连续-学习/持续学习-onboarding.jpg?w=1040 1040w, /media/blog/持续学习/持续学习-onboarding.jpg？w=1240 1240w，/媒体/博客/持续学习/持续学习-onboarding.jpg？w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;最近 Grafana Labs 入职活动的照片。&#34;width=&#34;1999&#34;height=&#34;1051&#34;title=&#34;*2024 年在华盛顿举行的 Grafana Labs 现场入职活动的照片，直流电。*&#34;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/Continous-learning/Continous-learning-onboarding.jpg”&#xA;alt=&#34;最近 Grafana Labs 入职活动的照片。&#34;width=&#34;1999&#34;height=&#34;1051&#34;title=&#34;*2024 年在华盛顿特区举办的 Grafana Labs 现场入职活动的照片。*&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;figcaption class=&#34;w-100p title text-gray-13 &#34;&gt;&lt;em&gt;2024 年在华盛顿特区举办的 Grafana Labs 现场入职活动照片。&lt;/em&gt;&lt;/em&gt;&lt;/noscript&gt;&lt;/div&gt;图标题&gt;&lt;/a&gt;&lt;/图&gt;&#xA;&lt;p&gt;我们的目标是通过大力投资于他们的初始入职体验，激励员工从一开始就学习和成长。但我们也鼓励让员工在整个职业生涯中都能在 Grafana Labs 继续学习。&lt;/p&gt;&#xA;&lt;p&gt;在这篇文章中，我们具体分享了我们是如何做到这一点的。请继续阅读，详细了解我们的学习管理系统、专业发展预算以及我们确保 Grafanista 每天都能学到东西的其他方法。&lt;/p&gt;&#xA;&lt;h2 id=&#34;learning-on-demand&#34;&gt;按需学习&lt;/h2&gt;&#xA;&lt;p&gt;所有 Grafana Labs 员工都被尊重地授权以最适合自己的方式工作。灵活性和自主性是&lt;a href=&#34;/about/careers/&#34;&gt;我们工作的基石&lt;/a&gt;，因此这些价值观也延伸到我们的学习文化中是有道理的。因此，我们为 Grafanista 提供各种点播资源，让他们了解他们想学什么、何时以及如何学习。&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.docebo.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Docebo&lt;/a&gt;，我们的学习管理系统 (LMS)，提供对各种内容的访问定制课程。这些课程由 Grafanistas 创建，为 Grafanistas 提供，提供了适合我们独特情况的相关内容。&lt;/p&gt;&#xA;&lt;p&gt;例如，我们的升级工具包包含精选资源，可帮助职能经理更深入地研究授权、变更管理和反馈等关键主题。这些工具包是学习路径的一部分，Grafana Labs 员工可以根据自己的兴趣和空闲时间自由选择加入或退出。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1010px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接标题”&#xA;href=&#34;/media/blog/continuous-learning/continuous-learning-toolkit.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“lazyload mb-0”&#xA;data-src =“/media/blog/Continous-learning/Continous-learning-toolkit.png”data-srcset =“/media/blog/Continous-learning/Continous-learning-toolkit.png？w = 320 320w，/媒体/博客/持续学习/持续学习工具包.png？w=550 550w， /media/blog/continuous-learning/continuous-learning-toolkit.png?w=750 750w, /media/blog/continuous-learning/continuous-learning-toolkit.png?w=900 900w, /media/blog/continuous -学习/持续学习工具包.png?w=1040 1040w, /media/blog/continuous-learning/continuous-learning-toolkit.png?w=1240 1240w, /media/blog/continuous-learning/continuous-learning-toolkit.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;Docebo 中为 Grafana Labs 员工提供的课程屏幕截图。&#34;width=&#34;1010&#34;height=&#34;748&#34;title=&#34;*Docebo 上的自定义工具包鼓励继续学习各种主题。*&#34;/ &gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/Continous-learning/Continous-learning-toolkit.png”&#xA;alt=&#34;Docebo 中为 Grafana Labs 员工提供的课程屏幕截图。&#34;width=&#34;1010&#34;height=&#34;748&#34;title=&#34;*Docebo 上的自定义工具包鼓励继续学习各种主题。*&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;figcaption class=&#34;w-100p title text-gray-13 &#34;&gt;&lt;em&gt;Docebo 上的自定义工具包鼓励继续学习各种主题。&lt;/em&gt;&lt;/figca选项&gt;&lt;/a&gt;&lt;/图&gt;&#xA;&lt;p&gt;此外，我们与 LinkedIn Learning 的合作伙伴关系使我们的团队成员可以直接从我们的 LMS 浏览数千个其他课程。&lt;/p&gt;&#xA;&lt;p&gt;我们还在开发一个新的学习与发展中心，该中心将作为员工访问流程文档、公开演讲资源、新员工入职文档和其他按需学习材料的一站式商店。&lt;/ p&gt;&#xA;&lt;h2 id=&#34;learning-live-and-with-your-team&#34;&gt;现场学习（并与您的团队一起）&lt;/h2&gt;&#xA;&lt;p&gt;作为一家远程优先的公司，我们希望帮助 Grafanista 与同行建立联系，即使他们生活在不同的大陆。我们实现这一目标的方法之一是通过我们的礼宾服务，同时也鼓励持续学习，这是一项在团体环境中提供现场学习机会的计划。&lt;/p&gt;&#xA;&lt;p&gt;礼宾服务直接为 Grafana Labs 员工带来学习。他们只需从课程菜单中进行选择，让我们知道他们喜欢的日期和时间，就这样！我们的学习与发展团队由经验丰富的辅导员负责亲自或虚拟培训的协调、准备和交付。会议可以根据需要为尽可能少的人或任意多的人举办，并且涵盖各种主题，包括时间管理、职业发展和公开演讲。如果现有会议之一不太符合要求，Grafanista 可以请求专门针对他们独特兴趣设计的自定义会议。&lt;/p&gt;&#xA;&lt;h2 id=&#34;professional-development-budget&#34;&gt;专业发展预算&lt;/h2&gt;&#xA;&lt;p&gt;当 Grafanista 想要进一步扩展时（也许是为了获得专业认证、学习另一种语言或参加行业会议），我们会提供专业发展预算。&lt;/p&gt;&#xA;&lt;p&gt;每个 Grafana Labs 员工每年都会获得 1500 美元的拨款，用于投资于他们的专业发展。该计划几乎没有限制；每个人都可以自由地以适合自己的方式使用预算。&lt;/p&gt;&#xA;&lt;p&gt;今年，我用我的专业发展预算参加了在休斯顿举行的&lt;a href=&#34;https://afrotechconference.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Afrotech 会议&lt;/a&gt;，德克萨斯州。与其他专业人士建立联系、建立联系并学习宝贵的见解并在旅行结束时带回 Grafana Labs 真是太令人兴奋了！&lt;/p&gt;&#xA;&lt;p&gt;使用预算的其他常见方式包括支出：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;书籍&lt;/strong&gt;：&lt;a href=&#34;https://brenebrown.com/hubs/dare-to-lead/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;“敢于领导”&lt;/a&gt; 布琳·布朗 (Brene Brown) 的作品很受欢迎。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;行业认证&lt;/strong&gt;：对于我们的工程师来说，&lt;a href=&#34;https://kubernetes.io/training/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Kubernetes&lt;/a&gt; &lt;a href=&#34;https://www.comptia.org/certifications&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;CompTIA&lt;/a&gt; 认证尤其常见。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;订阅&lt;/strong&gt;：&lt;a href=&#34;https://www.shrm.org/home&#34; target=&#34;_例如，我们的人员团队建议加入空白&#34; rel=&#34;noopener noreferrer&#34;&gt;SHRM 会员资格&lt;/a&gt;。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;会议&lt;/strong&gt;：过去，Grafanista 曾参加过&lt;a href=&#34;https://www.gs1us.org/education-and-events/events/gs1-connect&#34; target=&#34; _blank&#34; rel=&#34;noopener noreferrer&#34;&gt;GS1 Connect 峰会&lt;/a&gt;，&lt;a href=&#34;https://latinasintech.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;拉丁裔科技&lt;/a&gt;，当然还有开源软件领域的重大事件，例如 &lt;a href=&#34;https://events.linuxfoundation.org/kubecon-cloudnativecon-north-america/&#34; target=&#34; _blank&#34; rel=&#34;noopener noreferrer&#34;&gt;KubeCon&lt;/a&gt;。&lt;/li&gt;&#xA;&lt;li&gt;其他&lt;strong&gt;技术或专业发展课程&lt;/strong&gt;，包括 &lt;a href=&#34;https://www.boot.dev/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Boot 提供的课程.dev&lt;/a&gt; 和 &lt;a href=&#34;https://www.udemy.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Udemy&lt;/a&gt;。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;learn-more-about-working-at-grafana-labs&#34;&gt;了解有关在 Grafana Labs 工作的更多信息&lt;/h2&gt;&#xA;&lt;p&gt;在 Grafana Labs，您永远不会因发现新事物而变老。通过利用我们的点播和实时学习机会，每个 Grafanista 都有机会扩展他们的知识，并了解我们帮助自己和他人蓬勃发展的价值观。&lt;/p&gt;&#xA;&lt;p&gt;如果您有兴趣了解有关在 Grafana Labs 工作的更多信息（包括我们目前的一些空缺职位），请参阅我们的&lt;a href=&#34;/about/careers/&#34;&gt;职业页面&lt;/a&gt;。我们很乐意听取您的意见！&lt;/p&gt;</description>
      <pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Open standards, lower costs, and centralized observability: Why FalconX moved to Grafana Cloud】开放标准、降低成本和集中可观测性：为什么 FalconX 迁移到 Grafana Cloud</title>
      <link>https://grafana.com/blog/2024/12/27/open-standards-lower-costs-and-centralized-observability-why-falconx-moved-to-grafana-cloud/</link>
      <description>【&lt;p&gt;When &lt;a href=&#34;https://www.falconx.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;FalconX&lt;/a&gt;, a crypto prime brokerage with offices in the U.S., Europe, and Asia, needed to move off their proprietary observability provider, DevOps Manager Vaibhav Krishna knew just where to turn.&lt;/p&gt;&#xA;&lt;p&gt;At a previous job, Vaibhav had used Grafana in the early days of &lt;a href=&#34;/oss/loki/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Loki&lt;/a&gt;, and he&amp;rsquo;d seen the growth in offerings from Grafana Labs ever since. He felt the open source tooling fit with FalconX&amp;rsquo;s ethos, and he saw the potential to save time and money by consolidating on one platform. He wanted a platform that could scale with them (15 TB of logs ingested monthly, and counting), help them with security and compliance, and accommodate modern software development processes—all while removing the burden of his team having to manage it all.&lt;/p&gt;&#xA;&lt;p&gt;Vaibhav recently talked with Grafana Labs about why FalconX migrated to &lt;a href=&#34;/products/cloud/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt;—a process that was completed in a month and instantly translated to 40% savings—and how the fully managed platform checked all the boxes for them.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;For starters, tell us why you decided to go with Grafana Cloud.&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;We had a lot of reasons. First, the setup we had at that time was very expensive. Second, we wanted to expand our footprint. We are in crypto trading and financing—it&amp;rsquo;s an evolving market, so our requirements change and growth is exponential, but our monitoring infrastructure was not readily scalable. We wanted something that was more of a &amp;ldquo;plug and play&amp;rdquo; that is easy to maintain. We did not want the headache of managing our own observability setup.&lt;/p&gt;&#xA;&lt;p&gt;Our goal was to find a solution that seamlessly integrates with Kubernetes, where most of our applications run. Beyond Kubernetes, we needed a platform that could support additional tools and add-ons across our clusters while offering various plugin support and a single pane of glass for everything.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Were open standards an important part of your decision as well?&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;Yes, this was important for me and for our team. We are not comfortable with a closed-solution approach as we want real-time visibility into our data and security.&lt;/p&gt;&#xA;&lt;p&gt;And from an engineering/DevOps perspective, a lot of really good work is happening in open standards. It&amp;rsquo;s not just about Grafana, but the entire ecosystem of open source tooling, and that open source tech, in my experience, is more fruitful. If you have closed source tools, which don&amp;rsquo;t integrate well, it will inevitably be a pain point. Given that we had a clear directional vision for our growth as an organization and department, we were very focused on open source solutions.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;You used Grafana at a past job, but was everyone else as willing to jump on board?&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;Moving to a new tech stack is never easy. We had a decent amount of diligence and garnering of internal support, particularly because there are so many traditional name-brand tools out there. Pitching it to the C-level executives was a challenge, too, as some came from companies like Google and were used to completely different setups. On top of that, there were times when investment partners or others suggested alternative solutions. But the Grafana team supported us along the way and designed an incremental approach, gradually shifting workloads and seeing results month over month, which gave everyone the confidence to fully transition.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;So how did you ultimately win them over?&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;I think the evolution of the feature set in Grafana—it&amp;rsquo;s not the same Grafana as what I used earlier. There&amp;rsquo;s a lot of evolution; there&amp;rsquo;s a lot of maturity, and if you look at the roadmap, it&amp;rsquo;s not only looking at metrics but a holistic approach to observability.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;And were you able to save money by switching to Grafana Cloud?&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;It&amp;rsquo;s fair to say we were able to immediately save 40%.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;What about the functionality? Sometimes you go someplace and it&amp;rsquo;s 40% cheaper and you get a 40% worse product.&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;We didn&amp;rsquo;t see any degraded performance. I think a lot of this cost is also getting slashed because of logs. Logs are the key to cutting costs. OpenSearch is very expensive compared to Loki. We still have metrics in Datadog, and if we do a full flip we will definitely save some cost when we do Grafana Cloud. But I think we would save a lot more in Loki because of the way it indexes and the way it stores data.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;I understand you also used &lt;a href=&#34;/docs/grafana-cloud/cost-management-and-billing/reduce-costs/metrics-costs/control-metrics-usage-via-adaptive-metrics/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Adaptive Metrics&lt;/a&gt;, our cardinality optimization feature that helps identify and eliminate unused time series metrics.&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;I was very skeptical about how well Adaptive Metrics would work. There was this sales call and whatever contract was offered, I was not confident with the metrics calibration there because Adaptive Metrics was calculated there, too. And when he pitched, &amp;ldquo;Hey, this is how much Adaptive Metrics will slash,&amp;rdquo; and I was not at all confident. I didn&amp;rsquo;t think it would even cut down more than 5% or 10% of the overall metrics, but I can see now that it cut upwards of 40% or more. Now I&amp;rsquo;m very happy with how Adaptive Metrics is working.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;So have you tried &lt;a href=&#34;/blog/2024/09/24/introducing-adaptive-logs/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Adaptive Logs&lt;/a&gt; yet?&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;Now I&amp;rsquo;m very excited to do Adaptive Logs.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;How does your experience today compare to the Grafana you used in your previous company?&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;I like the way Grafana has matured. From an end user perspective, I really like the offerings and the direction. It started with metrics, then logs, then traces, then you could add other metrics and include all your signals. Then there was Grafana Alerting in place, and IRM, and now Frontend Observability.&lt;/p&gt;&#xA;&lt;p&gt;I&amp;rsquo;m looking forward to how Sift will evolve, because Grafana has all of our data, so I would assume that over time we get more mature and it gives us very pinpointed recommendations that are actually solutions—like, why is something broken?&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;How does that centralization support your efforts?&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;It makes our life simpler. Whatever tooling I build internally, I have fewer headaches because I only have to manage one stack.&lt;/p&gt;&#xA;&lt;p&gt;It&amp;rsquo;s a lot of pain to set up multiple tools, and it&amp;rsquo;s a lot of context switching, too. Managing more tools is very hard for leaner teams. Even for mature teams, it&amp;rsquo;s still hard, and it&amp;rsquo;s pretty unnecessary. From an administrative perspective, it&amp;rsquo;s very simple because I&amp;rsquo;ve built out pipelines on how to install Grafana everywhere. Whenever I want to extend to more metrics or more signals, I just modify these existing pipelines. If I have to manage multiple tools, I have to manage all of this internally again, which means I also lose more bandwidth.&lt;/p&gt;】&lt;p&gt;当&lt;a href=&#34;https://www.falconx.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;FalconX&lt;/a&gt;（一家在美国、欧洲设有办事处的加密货币大宗经纪公司）亚洲和亚洲需要摆脱其专有的可观测性提供商，DevOps 经理 Vaibhav Krishna 知道该转向哪里。&lt;/p&gt;&#xA;&lt;p&gt;在之前的工作中，Vaibhav 在 &lt;a href=&#34;/oss/loki/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana Loki&lt;/a&gt; 早期使用过 Grafana，并且他见过自此以来，Grafana Labs 的产品不断增长。他认为开源工具符合 FalconX 的精神，并且他看到了通过整合到一个平台上来节省时间和金钱的潜力。他想要一个能够随他们一起扩展的平台（每月摄取 15 TB 的日志，并且还在不断增加），帮助他们实现安全性和合规性，并适应现代软件开发流程，同时消除他的团队必须管理这一切的负担。&lt; /p&gt;&#xA;&lt;p&gt;Vaibhav 最近与 Grafana Labs 讨论了为什么 FalconX 迁移到 &lt;a href=&#34;/products/cloud/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt;——这个过程在一个月内完成，并且立即转化为 40% 的节省，以及完全托管的平台如何为他们勾选所有选项。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;首先，请告诉我们您为什么决定使用 Grafana Cloud。&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;我们有很多理由。首先，我们当时的设置非常昂贵。其次，我们想扩大我们的足迹。我们从事加密货币交易和融资——这是一个不断发展的市场，因此我们的需求变化和增长呈指数级增长，但我们的监控基础设施不易扩展。我们想要一种更“即插即用”且易于维护的东西。我们不想为管理我们自己的可观察性设置而头痛。&lt;/p&gt;&#xA;&lt;p&gt;我们的目标是找到一种与 Kubernetes 无缝集成的解决方案，我们的大多数应用程序都在 Kubernetes 上运行。除了 Kubernetes 之外，我们还需要一个平台，该平台可以支持跨集群的其他工具和附加组件，同时提供各种插件支持和单一管理平台。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;开放标准也是您决策的重要组成部分吗？&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;是的，这对我和我们的团队都很重要。我们不喜欢封闭的解决方案方法，因为我们希望实时了解我们的数据和安全性。&lt;/p&gt;&#xA;&lt;p&gt;从工程/DevOps 的角度来看，开放标准中正在发生许多非常好的工作。这不仅涉及 Grafana，还涉及整个开源工具生态系统，而根据我的经验，开源技术更加富有成效。如果你有闭源工具，但不能很好地集成，这将不可避免地成为一个痛点。鉴于我们作为一个组织和部门的发展有明确的方向性愿景，因此我们非常关注开源解决方案。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;您在过去的工作中使用过 Grafana，但其他人都愿意加入吗？&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;迁移到新的技术堆栈绝非易事。我们哈我们付出了相当多的努力并获得了内部支持，特别是因为有很多传统的名牌工具。向 C 级高管推销它也是一个挑战，因为有些人来自谷歌等公司，习惯于完全不同的设置。最重要的是，有时投资合作伙伴或其他人会提出替代解决方案。但 Grafana 团队一路支持我们，并设计了一种增量方法，逐渐转移工作负载并逐月看到结果，这让每个人都有信心完全过渡。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;那么你最终是如何赢得他们的支持的呢？&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;我认为 Grafana 中功能集的演变——它与我之前使用的 Grafana 不同。有很多进化；有很多成熟度，如果你看一下路线图，你会发现它不仅关注指标，而且关注可观察性的整体方法。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;切换到 Grafana Cloud 是否能够节省资金？&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;可以公平地说，我们立即节省了 40%。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;功能怎么样？有时你去某个地方，价格便宜了 40%，但你得到的产品却差了 40%。&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;我们没有看到任何性能下降。我认为大部分成本也因为日志而被削减。原木是削减成本的关键。与 Loki 相比，OpenSearch 非常昂贵。我们在Datadog中仍然有指标，如果我们进行全面翻转，我们在做Grafana Cloud时肯定会节省一些成本。但我认为，由于 Loki 的索引方式和存储数据的方式，我们会节省更多。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;我知道您还使用了&lt;a href=&#34;/docs/grafana-cloud/cost-management-and-billing/reduce-costs/metrics-costs/control-metrics-usage-via-adaptive-metrics /?pg=blog&amp;plcmt=body-txt&#34;&gt;自适应指标&lt;/a&gt;，我们的基数优化功能，可帮助识别和消除未使用的时间序列指标。&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;我对自适应指标的效果非常怀疑。有一次销售电话，无论提供什么合同，我对那里的指标校准都没有信心，因为自适应指标也是在那里计算的。当他提出“嘿，这就是自适应指标将削减多少”时，我一点也不自信。我认为它不会减少超过 5% 或 10% 的总体指标，但我现在看到它减少了 40% 或更多。现在我对自适应指标的工作方式非常满意。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;那么您尝试过&lt;a href=&#34;/blog/2024/09/24/introducing-adaptive-logs/?pg=blog&amp;plcmt=body-txt&#34;&gt;自适应日志&lt;/a&gt;了吗？&lt;/强&gt;&lt;/p&gt;&#xA;&lt;p&gt;现在我很高兴能够进行自适应日志。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;您今天的体验与您在之前公司使用的 Grafana 相比如何？&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;我喜欢 Grafana 成熟的方式。从最终用户的角度来看，我真的很喜欢这些产品和目录节。它从指标开始，然后是日志，然后是跟踪，然后您可以添加其他指标并包含所有信号。然后是 Grafana Alerting、IRM，以及现在的前端可观察性。&lt;/p&gt;&#xA;&lt;p&gt;我期待 Sift 将如何发展，因为 Grafana 拥有我们所有的数据，所以我认为随着时间的推移，我们会变得更加成熟，它为我们提供了非常精确的建议，这些建议实际上是解决方案，比如，为什么有些东西是这样的坏了？&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;这种集中化如何支持您的工作？&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;它让我们的生活变得更简单。无论我在内部构建什么工具，我都不会那么头疼，因为我只需要管理一个堆栈。&lt;/p&gt;&#xA;&lt;p&gt;设置多个工具非常痛苦，而且需要进行大量的上下文切换。对于精简的团队来说，管理更多的工具非常困难。即使对于成熟的团队来说，这仍然很困难，而且完全没有必要。从管理角度来看，这非常简单，因为我已经构建了如何在各处安装 Grafana 的管道。每当我想要扩展到更多指标或更多信号时，我只需修改这些现有管道即可。如果我必须管理多个工具，我必须再次在内部管理所有这些，这意味着我也会损失更多带宽。&lt;/p&gt;</description>
      <pubDate>Fri, 27 Dec 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【How to send OTLP or Prometheus metrics and logs to Grafana Cloud with Grafana Alloy】如何使用 Grafana Alloy 将 OTLP 或 Prometheus 指标和日志发送到 Grafana Cloud</title>
      <link>https://grafana.com/blog/2025/01/03/how-to-send-otlp-or-prometheus-metrics-and-logs-to-grafana-cloud-with-grafana-alloy/</link>
      <description>【&lt;p&gt;We introduced &lt;a href=&#34;/oss/alloy-opentelemetry-collector/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Alloy&lt;/a&gt; last year in an effort to create the best possible open source &amp;ldquo;big tent&amp;rdquo; telemetry collector. A continuation of our work on Grafana Agent Flow, we designed Alloy to simplify observability at scale and to easily integrate with the OpenTelemetry and Prometheus ecosystems.&lt;/p&gt;&#xA;&lt;p&gt;We&amp;rsquo;ve seen lots of interest since Alloy was &lt;a href=&#34;/oss/alloy-opentelemetry-collector/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;announced at GrafanaCON 2024&lt;/a&gt;, and industry observers are &lt;a href=&#34;https://observability-360.com/article/ViewArticle?id=o11ys-observability-awards-2024&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;taking notice, too&lt;/a&gt;. That&amp;rsquo;s because Alloy is an OTLP-compatible collector with built-in Prometheus optimizations and enterprise-grade features for collecting signals across your metrics, logs, traces, and profiles—making it ideal for all your cloud native infrastructure and application observability demands.&lt;/p&gt;&#xA;&lt;p&gt;Alloy can also process and transform your data before sending it to OTel-compabile databases or collectors, including Grafana Cloud. You can even use Alloy to write alerting rules.&lt;/p&gt;&#xA;&lt;p&gt;If this all sounds great but you aren&amp;rsquo;t sure where to start, keep reading for handy tips and demos from our Grafana Labs experts about how to send and receive telemetry with Alloy.&lt;/p&gt;&#xA;&lt;h2 id=&#34;how-to-receive-otlp-metrics-and-send-them-to-grafana-cloud&#34;&gt;How to receive OTLP metrics and send them to Grafana Cloud&lt;/h2&gt;&#xA;&lt;p&gt;Seeing as how Alloy is a distribution of the OpenTelemetry Collector, it only makes sense to start with OTLP (OpenTelemetry protocol) metrics. More specifically, let&amp;rsquo;s look at how to use Alloy to receive metrics from an application instrumented with OTel and then send that data to &lt;a href=&#34;/products/cloud/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;To do so, you&amp;rsquo;ll use four OpenTelemetry components:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;otelcol.receiver.otlp&lt;/code&gt;, which receives metrics in OTLP format via HTTP and forwards them&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;otelcol.processor.attributes&lt;/code&gt;, which transforms the attributes associated with a metric&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;otelcol.exporter.otlphttp&lt;/code&gt;, which sends the metrics to Grafana Cloud using credentials&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;otelcol.auth.basic&lt;/code&gt; for exposing those credentials&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;We&amp;rsquo;ll also enable Alloy&amp;rsquo;s &lt;a href=&#34;/docs/alloy/latest/troubleshoot/debug/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;live debugging&lt;/a&gt; feature, which will help build the transformations we want for the attributes processor and to make sure we&amp;rsquo;re comfortable with those attributes before we begin sending the metrics to Grafana Cloud.&lt;/p&gt;&#xA;&lt;p&gt;Once you have that set up, you&amp;rsquo;ll use the &lt;code&gt;run&lt;/code&gt; command, and you&amp;rsquo;ll then be able to see the four connected components in the Alloy UI. If you click on the &lt;code&gt;otelcol.processor.attributes&lt;/code&gt; component, you can go into live debugging to see which metrics are passing through the component and identify any necessary changes.&lt;/p&gt;&#xA;&lt;p&gt;From there, you can go to your Grafana Cloud instance and look for the specific OTLP metric you&amp;rsquo;ve set Alloy to collect. If you run a query on that metric, it should appear in your graph in just a few seconds.&lt;/p&gt;&#xA;&lt;p&gt;For more details on how to set up this type of OTLP metrics pipeline, check out the full Ask the Experts demo from William Dumont, a software engineer on the Alloy squad, below.&lt;/p&gt;&#xA;&lt;div&#xA;class=&#34;youtube-lazyload responsive-video&#34;&#xA;data-embed=&#34;IRqQEzc0kvA&#34;&#xA;data-url=&#34;https://www.youtube.com/embed/IRqQEzc0kvA?autoplay=1&amp;amp;rel=0&#34;&#xA;data-title=&#34;YouTube Video&#34;&#xA;&gt;&#xA;&lt;div class=&#34;play-button&#34;&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; As we alluded to earlier, if you have experience with Grafana Agent Flow, you&amp;rsquo;ll be right at home with Alloy, as it uses the same components, code, and concepts. However, Grafana Agent and Grafana Agent Operator have been depreciated. They are currently in Long-Term Support (LTS) and are expected to reach End-of-Life (EOL) on Nov. 1, 2025. For more information on how to transition to Alloy, check out our &lt;a href=&#34;/blog/2024/04/09/grafana-agent-to-grafana-alloy-opentelemetry-collector-faq/&#34;&gt;Agent to Alloy FAQ blog post&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h2 id=&#34;how-to-send-prometheus-metrics-to-grafana-cloud-using-alloy&#34;&gt;How to send Prometheus metrics to Grafana Cloud using Alloy&lt;/h2&gt;&#xA;&lt;p&gt;As we already mentioned, while Alloy is a distribution of the OpenTelmetry Collector, it&amp;rsquo;s also designed to work seamlessly with Prometheus, as well. This is essential functionality, as 85% of OpenTelemetry users also use Prometheus in production, according to our second annual &lt;a href=&#34;/observability-survey/2024/?pg=blog&amp;amp;plcmt=body-txt#oss-is-the-de-facto-approach-to-observability&#34;&gt;Observability Survey&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;To illustrate how to use Alloy to send Prometheus metrics to Grafana Cloud, let&amp;rsquo;s imagine you have an application exposing metrics in a Docker container. For this, we&amp;rsquo;ll need three components:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;prometheus.scrape&lt;/code&gt;, which collects metrics from our target every three seconds&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;prometheus.relabel&lt;/code&gt;, which is used to edit labels attached to the metrics.&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;prometheus.remote_write&lt;/code&gt;, which sends the metrics to Grafana Cloud using basic authentication to pass the necessary credentials.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Again, we&amp;rsquo;ll use live debugging—this time to assist in building the rules for &lt;code&gt;prometheus.relabel&lt;/code&gt;. Before running the config, we&amp;rsquo;ll use a little trick and break the pipeline so we can shape the labels before they&amp;rsquo;re stored in our database. To do so, use the &lt;code&gt;run&lt;/code&gt; command, bypass the path for the config file, and set the stability level to &lt;code&gt;experimental&lt;/code&gt;. From there you check your &lt;code&gt;prometheus.remove_write&lt;/code&gt; component via live debugging and add any desired rules to filter out any unwanted data.&lt;/p&gt;&#xA;&lt;p&gt;Just like our last example, once you&amp;rsquo;ve set up your pipeline, you can go to Grafana Cloud, where you should be able to find your metric and quickly run a query on it. For more details, check out William&amp;rsquo;s second Ask the Expert video below.&lt;/p&gt;&#xA;&lt;div&#xA;class=&#34;youtube-lazyload responsive-video&#34;&#xA;data-embed=&#34;_MbB8IVKMfw&#34;&#xA;data-url=&#34;https://www.youtube.com/embed/_MbB8IVKMfw?autoplay=1&amp;amp;rel=0&#34;&#xA;data-title=&#34;YouTube Video&#34;&#xA;&gt;&#xA;&lt;div class=&#34;play-button&#34;&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;h2 id=&#34;how-to-send-grafana-alloy-logs-to-grafana-cloud&#34;&gt;How to send Grafana Alloy logs to Grafana Cloud&lt;/h2&gt;&#xA;&lt;p&gt;Now that we&amp;rsquo;ve walked through sending OpenTelemetry and Prometheus metrics to Grafana Cloud, let&amp;rsquo;s look at the next most popular telemetry type: logs. In this example, we&amp;rsquo;ll send the data to Grafana Cloud Logs, which is powered by Grafana Loki.&lt;/p&gt;&#xA;&lt;p&gt;To do so, we&amp;rsquo;ll need three components:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;logging&lt;/code&gt;, and in our example we&amp;rsquo;ll use &lt;code&gt;debug&lt;/code&gt; level to get the most information possible, as well as &lt;code&gt;logfmt&lt;/code&gt; for the format, though you can also use JSON. The other important argument here is &lt;code&gt;write_to&lt;/code&gt;, which tells the logging framework where to send those logs&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;loki.process&lt;/code&gt;, which is a pipeline unto itself. You can add any number of stages here, but for our purposes we&amp;rsquo;ll just add the service name, and we&amp;rsquo;ll use &lt;code&gt;alloy&lt;/code&gt; so we can identify it on the frontend&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;loki.write&lt;/code&gt;, is what actually sends the data from Alloy to Grafana Cloud, or any Loki-compatible endpoint.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Once you have that set up to suit your needs, go back to the Alloy UI to see all your components running. Then, go to Grafana Cloud and look for the Alloy label filter. If you run a query on that label filter, you should see logs coming though and you can manipulate your data as needed.&lt;/p&gt;&#xA;&lt;p&gt;To find out more, check out this Ask the Expert video below from Matthew Durham, a senior software developer on the Alloy squad.&lt;/p&gt;&#xA;&lt;div&#xA;class=&#34;youtube-lazyload responsive-video&#34;&#xA;data-embed=&#34;nUwHzT1sprU&#34;&#xA;data-url=&#34;https://www.youtube.com/embed/nUwHzT1sprU?autoplay=1&amp;amp;rel=0&#34;&#xA;data-title=&#34;YouTube Video&#34;&#xA;&gt;&#xA;&lt;div class=&#34;play-button&#34;&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;h2 id=&#34;learn-more-about-alloyonline-or-in-person&#34;&gt;Learn more about Alloy—online or in person&lt;/h2&gt;&#xA;&lt;p&gt;If you&amp;rsquo;re looking for more information to help you get started with Grafana Alloy, check out our &lt;a href=&#34;/docs/alloy/latest/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;documentation&lt;/a&gt; for all sorts of helpful resources, and read &lt;a href=&#34;/tags/grafana-alloy/&#34;&gt;some of our Grafana Alloy-related blogs&lt;/a&gt; that run through specific Alloy use cases.&lt;/p&gt;&#xA;&lt;p&gt;You can also watch our &lt;a href=&#34;/events/grafanacon/2024/introducing-otel-collector-distribution-grafana-alloy/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;GrafanaCON 2024&lt;/a&gt; and &lt;a href=&#34;/events/observabilitycon/2024/opentelemetry-grafana-alloy-beyla-demo-of-instrumentation-ingestion/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;ObservabilityCON 2024&lt;/a&gt; talks that featured the collector. And if you plan on attending either &lt;a href=&#34;/events/grafanacon/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;GrafanaCON 2025 in Seattle&lt;/a&gt; this May, or ObservabilityCON 2025 later this year, remember that we&amp;rsquo;ll have Ask the Expert booths fully staffed to help answer all your toughest questions.&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;/products/cloud/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Cloud &lt;/a&gt;is the easiest way to get started with metrics, logs, traces, dashboards, and more. We have a generous forever-free tier and plans for every use case. &lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Sign up for free now!&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;】&lt;p&gt;我们去年推出了&lt;a href=&#34;/oss/alloy-opentelemetry-collector/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana Alloy&lt;/a&gt;，致力于打造最好的开源“大帐篷” ”遥测收集器。作为 Grafana Agent Flow 工作的延续，我们设计了 Alloy 来大规模简化可观测性，并轻松与 OpenTelemetry 和 Prometheus 生态系统集成。&lt;/p&gt;&#xA;&lt;p&gt;自 Alloy &lt;a href=&#34;/oss/alloy-opentelemetry-collector/?pg=blog&amp;plcmt=body-txt&#34;&gt;在 GrafanaCON 2024 上发布&lt;/a&gt;以来，我们已经看到了很多人的兴趣，行业观察家也表示&lt;a href=&#34;https://observability-360.com/article/ViewArticle?id=o11ys-observability-awards-2024&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;也注意到了&lt;/a&gt;。这是因为 Alloy 是一款兼容 OTLP 的收集器，具有内置的 Prometheus 优化和企业级功能，用于收集指标、日志、跟踪和配置文件中的信号，使其成为满足所有云原生基础设施和应用程序可观测性需求的理想选择。 p&gt;&#xA;&lt;p&gt;Alloy 还可以在将数据发送到 OTel 兼容数据库或收集器（包括 Grafana Cloud）之前处理和转换您的数据。您甚至可以使用 Alloy 编写警报规则。&lt;/p&gt;&#xA;&lt;p&gt;如果这一切听起来不错，但您不确定从哪里开始，请继续阅读我们的 Grafana Labs 专家提供的有关如何使用 Alloy 发送和接收遥测数据的实用提示和演示。&lt;/p&gt;&#xA;&lt;h2 id=&#34;how-to-receive-otlp-metrics-and-send-them-to-grafana-cloud&#34;&gt;如何接收 OTLP 指标并将其发送到 Grafana Cloud&lt;/h2&gt;&#xA;&lt;p&gt;鉴于 Alloy 是 OpenTelemetry Collector 的一个发行版，只有从 OTLP（OpenTelemetry 协议）指标开始才有意义。更具体地说，让我们看看如何使用 Alloy 从使用 OTel 检测的应用程序接收指标，然后将该数据发送到 &lt;a href=&#34;/products/cloud/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a &gt;.&lt;/p&gt;&#xA;&lt;p&gt;为此，您将使用四个 OpenTelemetry 组件：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;otelcol.receiver.otlp&lt;/code&gt;，它通过 HTTP 接收 OTLP 格式的指标并转发它们&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;otelcol.processor.attributes&lt;/code&gt;，用于转换与指标关联的属性&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;otelcol.exporter.otlphttp&lt;/code&gt;，它使用凭据将指标发送到 Grafana Cloud&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;otelcol.auth.basic&lt;/code&gt; 用于公开这些凭据&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;我们还将启用 Alloy 的&lt;a href=&#34;/docs/alloy/latest/troubleshoot/debug/?pg=blog&amp;plcmt=body-txt&#34;&gt;实时调试&lt;/a&gt;功能，这将有助于构建我们的转换需要属性处理器，并确保在开始将指标发送到 Grafana Cloud 之前我们对这些属性感到满意。&lt;/p&gt;&#xA;&lt;p&gt;完成设置后，您将使用 &lt;code&gt;run&lt;/code&gt; 命令，然后您将能够在 Alloy UI 中看到四个连接的组件。如果点击&lt;code&gt;otelcol.processor.attributes&lt;/code&gt;组件，就可以进入live 调试以查看哪些指标正在通过组件并确定任何必要的更改。&lt;/p&gt;&#xA;&lt;p&gt;从那里，您可以转到 Grafana Cloud 实例并查找您设置 Alloy 收集的特定 OTLP 指标。如果您对该指标运行查询，它应该会在几秒钟内出现在您的图表中。&lt;/p&gt;&#xA;&lt;p&gt;有关如何设置此类 OTLP 指标管道的更多详细信息，请查看下面由 Alloy 团队的软件工程师 William Dumont 提供的完整“专家咨询”演示。&lt;/p&gt;&#xA;&lt;div&#xA;类 =“youtube-lazyload 响应视频”&#xA;数据嵌入=“IRqQEzc0kvA”&#xA;data-url=&#34;https://www.youtube.com/embed/IRqQEzc0kvA?autoplay=1&amp;rel=0&#34;&#xA;数据标题=“YouTube 视频”&#xA;&gt;&#xA;&lt;div class=&#34;play-button&#34;&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;块引用&gt;&#xA;&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;正如我们之前提到的，如果您有使用 Grafana Agent Flow 的经验，您就会熟悉 Alloy，因为它使用相同的组件、代码和概念。但是，Grafana Agent 和 Grafana Agent Operator 已折旧。它们目前处于长期支持 (LTS) 状态，预计将于 2025 年 11 月 1 日达到生命周期终止 (EOL)。有关如何过渡到 Alloy 的更多信息，请查看我们的 &lt;a href=&#34;/ blog/2024/04/09/grafana-agent-to-grafana-alloy-opentelemetry-collector-faq/&#34;&gt;Agent to Alloy 常见问题博文&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;/块引用&gt;&#xA;&lt;h2 id=&#34;how-to-send-prometheus-metrics-to-grafana-cloud-using-alloy&#34;&gt;如何使用 Alloy 将 Prometheus 指标发送到 Grafana Cloud&lt;/h2&gt;&#xA;&lt;p&gt;正如我们已经提到的，虽然 Alloy 是 OpenTelmetry Collector 的发行版，但它也被设计为与 Prometheus 无缝协作。这是一项基本功能，因为根据我们的第二份年度报告，85% 的 OpenTelemetry 用户也在生产中使用 Prometheus &lt;a href=&#34;/observability-survey/2024/?pg=blog&amp;plcmt=body-txt#oss-is-the-de -facto-approach-to-observability&#34;&gt;可观察性调查&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;为了说明如何使用 Alloy 将 Prometheus 指标发送到 Grafana Cloud，我们假设您有一个在 Docker 容器中公开指标的应用程序。为此，我们需要三个组件：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;prometheus.scrape&lt;/code&gt;，每三秒从我们的目标收集一次指标&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;prometheus.relabel&lt;/code&gt;，用于编辑附加到指标的标签。&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;prometheus.remote_write&lt;/code&gt;，它使用基本身份验证来传递必要的凭据，将指标发送到 Grafana Cloud。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;我们将再次使用实时调试，这一次是为了帮助构建 &lt;code&gt;prometheus.relabel&lt;/code&gt; 的规则。在运行配置之前，我们将使用一些小技巧并打破管道，以便我们可以在将标签存储到数据库之前对其进行整形。为此，请使用 &lt;code&gt;run&lt;/code&gt; 命令，绕过配置文件的路径，并将稳定性级别设置为&lt;code&gt;实验&lt;/code&gt;。从那里，您可以通过实时调试检查您的 &lt;code&gt;prometheus.remove_write&lt;/code&gt; 组件，并添加任何所需的规则来过滤掉任何不需要的数据。&lt;/p&gt;&#xA;&lt;p&gt;就像我们的上一个示例一样，设置管道后，您可以转到 Grafana Cloud，您应该能够在其中找到您的指标并快速对其运行查询。有关更多详细信息，请观看下面 William 的第二个“询问专家”视频。&lt;/p&gt;&#xA;&lt;div&#xA;类 =“youtube-lazyload 响应视频”&#xA;数据嵌入=“_MbB8IVKMfw”&#xA;data-url=&#34;https://www.youtube.com/embed/_MbB8IVKMfw?autoplay=1&amp;rel=0&#34;&#xA;数据标题=“YouTube 视频”&#xA;&gt;&#xA;&lt;div class=&#34;play-button&#34;&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;h2 id=&#34;how-to-send-grafana-alloy-logs-to-grafana-cloud&#34;&gt;如何将 Grafana Alloy 日志发送到 Grafana Cloud&lt;/h2&gt;&#xA;&lt;p&gt;现在我们已经完成了将 OpenTelemetry 和 Prometheus 指标发送到 Grafana Cloud 的过程，让我们看看下一个最流行的遥测类型：日志。在此示例中，我们将数据发送到由 Grafana Loki 提供支持的 Grafana Cloud Logs。&lt;/p&gt;&#xA;&lt;p&gt;为此，我们需要三个组件：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;logging&lt;/code&gt;，在我们的示例中，我们将使用 &lt;code&gt;debug&lt;/code&gt; 级别来获取尽可能多的信息，以及 &lt;code&gt;logfmt&lt;/code&gt; 格式，不过您也可以使用 JSON。这里的另一个重要参数是 write_to，它告诉日志框架将这些日志发送到哪里&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;loki.process&lt;/code&gt;，它本身就是一个管道。您可以在此处添加任意数量的阶段，但出于我们的目的，我们将仅添加服务名称，并且我们将使用&lt;code&gt;alloy&lt;/code&gt;，以便我们可以在前端识别它&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;loki.write&lt;/code&gt; 实际上是将数据从 Alloy 发送到 Grafana Cloud 或任何与 Loki 兼容的端点。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;完成满足您需求的设置后，请返回 Alloy UI 以查看所有组件的运行情况。然后，转到 Grafana Cloud 并查找 Alloy 标签过滤器。如果您对该标签过滤器运行查询，您应该会看到日志，并且您可以根据需要操作数据。&lt;/p&gt;&#xA;&lt;p&gt;要了解更多信息，请观看下面由 Alloy 团队的高级软件开发人员 Matthew Durham 制作的“询问专家”视频。&lt;/p&gt;&#xA;&lt;div&#xA;类 =“youtube-lazyload 响应视频”&#xA;数据嵌入=“nUwHzT1sprU”&#xA;data-url=&#34;https://www.youtube.com/embed/nUwHzT1sprU?autoplay=1&amp;rel=0&#34;&#xA;数据标题=“YouTube 视频”&#xA;&gt;&#xA;&lt;div class=&#34;play-button&#34;&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;h2 id=&#34;learn-more-about-alloyonline-or-in-person&#34;&gt;在线或亲自了解有关 Alloy 的更多信息&lt;/h2&gt;&#xA;&lt;p&gt;如果您正在寻找更多信息来帮助您开始使用 Grafana Alloy，请查看我们的&lt;a href=&#34;/docs/alloy/latest/?pg=blog&amp;plcmt=body-txt&#34;&gt;文档&lt;/a&gt;获取各种有用的资源，并阅读&lt;a href=&#34;/tags/grafana-alloy/&#34;&gt;我们的一些与 Grafana Alloy 相关的博客&lt;/a&gt;，其中介绍了特定的 Alloy 使用案例。&lt;/p&gt;&#xA;&lt;p&gt;您还可以观看我们的&lt;a href=&#34;/events/grafanacon/2024/introducing-otel-collector-distribution-grafana-alloy/?pg=blog&amp;plcmt=body-txt&#34;&gt;GrafanaCON 2024&lt;/a&gt;和&lt;一个href=&#34;/events/observabilitycon/2024/opentelemetry-grafana-alloy-beyla-demo-of-instrumentation-ingestion/?pg=blog&amp;plcmt=body-txt&#34;&gt;ObservabilityCON 2024&lt;/a&gt; 以收藏家为主角的演讲。如果您计划参加&lt;a href=&#34;/events/grafanacon/?pg=blog&amp;plcmt=body-txt&#34; &gt;今年 5 月在西雅图举行的 GrafanaCON 2025&lt;/a&gt;，或今年晚些时候举行的 ObservabilityCON 2025，请记住，我们将配备配备齐全的“专家咨询”摊位来帮助回答所有问题你最棘手的问题。&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;/products/cloud/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt;是开始使用指标、日志、跟踪、仪表板等的最简单方法。我们为每个用例提供慷慨的永久免费套餐和计划。 &lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;plcmt=body-txt&#34;&gt;立即免费注册！&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 03 Jan 2025 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Metrics, logs, and literature: Inside The National Library of the Netherlands’ observability stack】指标、日志和文献：荷兰国家图书馆可观测性堆栈内部</title>
      <link>https://grafana.com/blog/2025/01/06/metrics-logs-and-literature-inside-the-national-library-of-the-netherlands-observability-stack/</link>
      <description>【&lt;p&gt;Even in the digital age, you can’t deny the power of a good book. And at The National Library of the Netherlands, ensuring seamless access to those books is a top priority.&lt;/p&gt;&#xA;&lt;p&gt;“Literature adds value to humanity,” said Gerard van Engelen, platform engineer for The National Library of the Netherlands, during &lt;a href=&#34;/events/grafanacon/2024/data-management-and-monitoring-at-national-library-of-the-netherlands/&#34;&gt;a talk at GrafanaCON 2024&lt;/a&gt;. “We connect people around the world, but mainly in the Netherlands, by making Dutch literature available in a digital and physical way.”&lt;/p&gt;&#xA;&lt;p&gt;Physically, the library houses a lot of books — so many, in fact, that the collection could span an impressive 120 kilometers if laid out back to back. But it also stores a lot of data to help eager readers digitally access those books and other literary resources via their website.&lt;/p&gt;&#xA;&lt;p&gt;“We store 3.5 petabytes of digital literature, and it&amp;rsquo;s growing at 300-400 terabytes a year,” van Engelen explained. “We have literature dating back 406 years, and we make it available 24/7 on our site.”&lt;/p&gt;&#xA;&lt;p&gt;To deliver on that goal — and ensure seamless and reliable access to their digital assets — the team turned to Grafana.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Want to tell your own story at GrafanaCON, our largest community conference of the year? We’re &lt;a href=&#34;https://pretalx.com/grafanacon-2025/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;looking for speakers to share their real-world experiences&lt;/a&gt; with Grafana, custom-built plugins, cool dashboards, and more. This is a community-driven conference focused on your favorite visualization tool, its big tent of data source plugins, and the surrounding open source ecosystem — Prometheus, Loki, OpenTelemetry, Mimir, and more.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h2 id=&#34;authoring-an-observability-strategy&#34;&gt;Authoring an observability strategy&lt;/h2&gt;&#xA;&lt;p&gt;The National Library of the Netherlands wanted to formalize their observability strategy for a few critical reasons. For starters, they prioritize the user experience, and wanted deeper insights into application performance.&lt;/p&gt;&#xA;&lt;p&gt;“I think we all write software to solve a problem. And if the problem is not solved, the software is not working,” van Engelen said. “But if you don&amp;rsquo;t know that your software isn’t working, how can you act upon it?”&lt;/p&gt;&#xA;&lt;div&#xA;class=&#34;youtube-lazyload responsive-video&#34;&#xA;data-embed=&#34;tICGNIIW-n8&#34;&#xA;data-url=&#34;https://www.youtube.com/embed/tICGNIIW-n8?autoplay=1&amp;amp;rel=0&#34;&#xA;data-title=&#34;YouTube Video&#34;&#xA;&gt;&#xA;&lt;div class=&#34;play-button&#34;&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;Next, as a government organization, they have strict requirements around log retention times. They wanted a platform that could provide centralized log storage, with clear and defined policies.&lt;/p&gt;&#xA;&lt;p&gt;Lastly, the team wanted the ability to make decisions based on real-time data.&lt;/p&gt;&#xA;&lt;p&gt;“In the case of the Dutch library, we are expanding our storage a lot,” van Engelen said. “We want to be able to plan for that upfront, and observability can help us with that.”&lt;/p&gt;&#xA;&lt;h2 id=&#34;why-the-grafana-stack-for-library-stacks&#34;&gt;Why the Grafana stack for library stacks&lt;/h2&gt;&#xA;&lt;p&gt;The National Library of the Netherlands had previous experience with Splunk, but ultimately chose to implement Grafana to drive their observability strategy. Ease of use, according to van Engelen, was a big reason why, especially because the engineering team wanted to empower developers to build their own dashboards for data visualization.&lt;/p&gt;&#xA;&lt;p&gt;“Once you get your infrastructure rolled out, the developer experience with Grafana is pretty easy, and I think most people that use Grafana already know this,” he said.&lt;/p&gt;&#xA;&lt;p&gt;The second factor in choosing Grafana over Splunk was cost. “It meant a cost reduction of nearly 80,000 Euros a year, which is a nice one, in terms of OpEx,” van Engelen said.&lt;/p&gt;&#xA;&lt;p&gt;Native Prometheus support was also a major factor in the decision to go with Grafana.&lt;/p&gt;&#xA;&lt;p&gt;“In the end, we looked at all these attributes and came up with Grafana as being number one for us,” van Engelen told attendees.&lt;/p&gt;&#xA;&lt;h2 id=&#34;empowering-developers-and-reducing-mttr&#34;&gt;Empowering developers and reducing MTTR&lt;/h2&gt;&#xA;&lt;p&gt;The National Library of the Netherlands deployed two Grafana servers on bare-metal VMs with a PostgreSQL database, as well as &lt;a href=&#34;/oss/mimir/&#34;&gt;Grafana Mimir&lt;/a&gt; for metrics and &lt;a href=&#34;/oss/loki/&#34;&gt;Grafana Loki&lt;/a&gt; for logs, both running in &lt;a href=&#34;/docs/mimir/latest/references/architecture/deployment-modes/#monolithic-mode&#34;&gt;monolithic mode&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1999px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/national-library-of-netherlands/dutch-library_logs-dashboard.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/national-library-of-netherlands/dutch-library_logs-dashboard.png&#34;data-srcset=&#34;/media/blog/national-library-of-netherlands/dutch-library_logs-dashboard.png?w=320 320w, /media/blog/national-library-of-netherlands/dutch-library_logs-dashboard.png?w=550 550w, /media/blog/national-library-of-netherlands/dutch-library_logs-dashboard.png?w=750 750w, /media/blog/national-library-of-netherlands/dutch-library_logs-dashboard.png?w=900 900w, /media/blog/national-library-of-netherlands/dutch-library_logs-dashboard.png?w=1040 1040w, /media/blog/national-library-of-netherlands/dutch-library_logs-dashboard.png?w=1240 1240w, /media/blog/national-library-of-netherlands/dutch-library_logs-dashboard.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A Grafana dashboard for displaying log data at The National Library of the Netherlands.&#34;width=&#34;1999&#34;height=&#34;1086&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/national-library-of-netherlands/dutch-library_logs-dashboard.png&#34;&#xA;alt=&#34;A Grafana dashboard for displaying log data at The National Library of the Netherlands.&#34;width=&#34;1999&#34;height=&#34;1086&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;For all applications that run on VMs in their landscape, they installed &lt;a href=&#34;/docs/agent/latest/&#34;&gt;Grafana Agent&lt;/a&gt;, which scrapes the logs and then the Prometheus endpoints, and then sends those logs and metrics to Loki and Mimir. &lt;em&gt;(Note: At GrafanaCON 2024, we &lt;a href=&#34;/blog/2024/04/09/grafana-alloy-opentelemetry-collector-with-prometheus-pipelines/&#34;&gt;introduced Grafana Alloy&lt;/a&gt;, our new open source telemetry collector that is 100% OTLP compatible and offers native pipelines for OpenTelemetry and Prometheus telemetry formats, supporting metrics, logs, traces, and profiles. Alloy uses the same components, code, and concepts that were first introduced in Grafana Agent Flow. Grafana Agent is now deprecated and is in Long-Term Support. To learn more, please refer to this &lt;a href=&#34;/blog/2024/04/09/grafana-agent-to-grafana-alloy-opentelemetry-collector-faq/&#34;&gt;blog post&lt;/a&gt;.)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;The team also created their own &lt;a href=&#34;https://github.com/grafana/grafana-ansible-collection&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Grafana Ansible collection&lt;/a&gt; to further simplify the developer experience.&lt;/p&gt;&#xA;&lt;p&gt;“We templated this all out, and actually, the only thing that developers need to do when defining their infrastructure as code is to define a variable with an app name and a port number, and then they&amp;rsquo;re good to go,” van Engelen said. “Everything else is rolled out automatically.”&lt;/p&gt;&#xA;&lt;p&gt;By visualizing application performance data in Grafana, the team is able to achieve what any librarian hopes for: a quiet environment where teams can debug issues and identify root causes faster.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1999px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/national-library-of-netherlands/dutch-library_metrics-dashboard.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/national-library-of-netherlands/dutch-library_metrics-dashboard.png&#34;data-srcset=&#34;/media/blog/national-library-of-netherlands/dutch-library_metrics-dashboard.png?w=320 320w, /media/blog/national-library-of-netherlands/dutch-library_metrics-dashboard.png?w=550 550w, /media/blog/national-library-of-netherlands/dutch-library_metrics-dashboard.png?w=750 750w, /media/blog/national-library-of-netherlands/dutch-library_metrics-dashboard.png?w=900 900w, /media/blog/national-library-of-netherlands/dutch-library_metrics-dashboard.png?w=1040 1040w, /media/blog/national-library-of-netherlands/dutch-library_metrics-dashboard.png?w=1240 1240w, /media/blog/national-library-of-netherlands/dutch-library_metrics-dashboard.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A Grafana dashboard for application performance metrics at The National Library of the Netherlands.&#34;width=&#34;1999&#34;height=&#34;1087&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/national-library-of-netherlands/dutch-library_metrics-dashboard.png&#34;&#xA;alt=&#34;A Grafana dashboard for application performance metrics at The National Library of the Netherlands.&#34;width=&#34;1999&#34;height=&#34;1087&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;“We can use these dashboards to really drill down into issues relatively quickly with a minimal amount of configuration,” van Engelen said.&lt;/p&gt;&#xA;&lt;h2 id=&#34;whats-next&#34;&gt;What’s next&lt;/h2&gt;&#xA;&lt;p&gt;The National Library of the Netherlands has big plans to expand their use of the Grafana stack for their library stacks.&lt;/p&gt;&#xA;&lt;p&gt;Looking ahead, for example, they’re going to implement &lt;a href=&#34;/docs/grafana/latest/alerting/&#34;&gt;Grafana Alerting&lt;/a&gt; to address performance issues more proactively, &lt;a href=&#34;/oss/tempo/&#34;&gt;Grafana Tempo&lt;/a&gt; for distributed tracing, and &lt;a href=&#34;/oss/faro/&#34;&gt;Grafana Faro&lt;/a&gt; for real user monitoring and frontend app observability.&lt;/p&gt;&#xA;&lt;p&gt;“Ths is is just the tip of the iceberg for us,” van Engelen said.&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;/products/cloud/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Cloud &lt;/a&gt;is the easiest way to get started with metrics, logs, traces, dashboards, and more. We have a generous forever-free tier and plans for every use case. &lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Sign up for free now!&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;】&lt;p&gt;即使在数字时代，你也不能否认一本好书的力量。在荷兰国家图书馆，确保无缝访问这些图书是首要任务。&lt;/p&gt;&#xA;&lt;p&gt;“文学为人类增添了价值，”荷兰国家图书馆平台工程师 Gerard van Engelen 在&lt;a href=&#34;/events/grafanacon/2024/data-management-and-monitoring-at-national -library-of-the-netherlands/&#34;&gt;GrafanaCON 2024 上的演讲&lt;/a&gt;。 “我们通过以数字和物理方式提供荷兰文学，将世界各地的人们联系在一起，但主要是荷兰的人们。”&lt;/p&gt;&#xA;&lt;p&gt;从物理上看，图书馆藏有大量书籍，事实上，如果背靠背排列，藏书的长度可能会长达 120 公里。但它还存储了大量数据，以帮助热切的读者通过其网站以数字方式访问这些书籍和其他文学资源。&lt;/p&gt;&#xA;&lt;p&gt;“我们存储了 3.5 PB 的数字文献，并且每年以 300-400 TB 的速度增长，”van Engelen 解释道。 “我们拥有 406 年前的文献，并且我们的网站上全天候 (24/7) 提供这些文献。”&lt;/p&gt;&#xA;&lt;p&gt;为了实现这一目标，并确保无缝、可靠地访问其数字资产，团队转向了 Grafana。&lt;/p&gt;&#xA;&lt;块引用&gt;&#xA;&lt;p&gt;想在我们年度最大的社区会议 GrafanaCON 上讲述您自己的故事吗？我们正在&lt;a href=&#34;https://pretalx.com/grafanacon-2025/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;寻找演讲者与 Grafana 分享他们的真实经验&lt;/a&gt;，定制插件、炫酷的仪表板等等。这是一个社区驱动的会议，重点讨论您最喜欢的可视化工具、其庞大的数据源插件以及周围的开源生态系统 - Prometheus、Loki、OpenTelemetry、Mimir 等。&lt;/p&gt;&#xA;&lt;/块引用&gt;&#xA;&lt;h2 id=&#34;authoring-an-observability-strategy&#34;&gt;编写可观察性策略&lt;/h2&gt;&#xA;&lt;p&gt;出于一些关键原因，荷兰国家图书馆希望正式制定其可观测性策略。首先，他们优先考虑用户体验，并希望更深入地了解应用程序性能。&lt;/p&gt;&#xA;&lt;p&gt;“我认为我们编写软件都是为了解决问题。如果问题没有解决，软件就无法工作，”van Engelen 说。 “但是，如果您不知道您的软件无法运行，您该如何采取行动呢？”&lt;/p&gt;&#xA;&lt;div&#xA;类 =“youtube-lazyload 响应视频”&#xA;数据嵌入=“tICGNIIW-n8”&#xA;data-url=&#34;https://www.youtube.com/embed/tICGNIIW-n8?autoplay=1&amp;rel=0&#34;&#xA;数据标题=“YouTube 视频”&#xA;&gt;&#xA;&lt;div class=&#34;play-button&#34;&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;其次，作为政府组织，他们对日志保留时间有严格的要求。他们想要一个能够提供集中日志存储并具有明确定义的策略的平台。&lt;/p&gt;&#xA;&lt;p&gt;最后，团队希望能够根据实时数据做出决策。&lt;/p&gt;&#xA;&lt;p&gt;“就荷兰图书馆而言，我们正在大量扩大我们的存储空间，”范恩格伦说。 “我们希望能够为预先做好准备，可观察性可以帮助我们做到这一点。”&lt;/p&gt;&#xA;&lt;h2 id=&#34;why-the-grafana-stack-for-library-stacks&#34;&gt;为什么将 Grafana 堆栈用于库堆栈&lt;/h2&gt;&#xA;&lt;p&gt;荷兰国家图书馆之前曾使用过 Splunk，但最终选择实施 Grafana 来推动其可观测性策略。 van Engelen 认为，易用性是一个重要原因，特别是因为工程团队希望让开发人员能够构建自己的数据可视化仪表板。&lt;/p&gt;&#xA;&lt;p&gt;“一旦推出基础设施，Grafana 的开发人员体验就非常简单，我认为大多数使用 Grafana 的人已经知道这一点，”他说。&lt;/p&gt;&#xA;&lt;p&gt;选择 Grafana 而不是 Splunk 的第二个因素是成本。 “这意味着每年可以降低近 80,000 欧元的成本，就运营支出而言，这是一个不错的结果，”van Engelen 说。&lt;/p&gt;&#xA;&lt;p&gt;原生 Prometheus 支持也是决定使用 Grafana 的一个主要因素。&lt;/p&gt;&#xA;&lt;p&gt;“最后，我们考虑了所有这些属性，并认为 Grafana 是我们的第一选择，”van Engelen 告诉与会者。&lt;/p&gt;&#xA;&lt;h2 id=&#34;empowering-developers-and-reducing-mttr&#34;&gt;为开发者赋能并缩短 MTTR&lt;/h2&gt;&#xA;&lt;p&gt;荷兰国家图书馆在带有 PostgreSQL 数据库的裸机虚拟机上部署了两台 Grafana 服务器，以及用于指标和 &lt;a href 的 &lt;a href=&#34;/oss/mimir/&#34;&gt;Grafana Mimir&lt;/a&gt; =&#34;/oss/loki/&#34;&gt;Grafana Loki&lt;/a&gt; 用于日志，两者都在 &lt;a 中运行href=&#34;/docs/mimir/latest/references/architecture/deployment-modes/#monolithic-mode&#34;&gt;整体模式&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1999px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/national-library-of-netherlands/dutch-library_logs-dashboard.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src =“/media/blog/national-library-of-netherlands/dutch-library_logs-dashboard.png”data-srcset =“/media/blog/national-library-of-netherlands/dutch-library_logs-dashboard。 w=320 320w, /media/blog/荷兰国家图书馆/dutch-library_logs-dashboard.png?w=550 550w, /media/blog/荷兰国家图书馆/dutch-library_logs-dashboard.png?w=750 750瓦， /media/blog/荷兰国家图书馆/dutch-library_logs-dashboard.png?w=900 900w，/media/blog/荷兰国家图书馆/dutch-library_logs-dashboard.png?w=1040 1040瓦， /media/blog/荷兰国家图书馆/dutch-library_logs-dashboard.png?w=1240 1240w，/media/blog/荷兰国家图书馆/dutch-library_logs-dashboard.png?w=1920 1920瓦”&#xA;data-sizes=&#34;auto&#34;alt=&#34;用于显示荷兰国家图书馆日志数据的 Grafana 仪表板。&#34;width=&#34;1999&#34;height=&#34;1086&#34;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/national-library-of-netherlands/dutch-library_logs-dashboard.png”&#xA;alt=&#34;用于显示荷兰国家图书馆日志数据的 Grafana 仪表板。&#34;width=&#34;1999&#34;高度=&#34;1086&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;对于在其环境中的虚拟机上运行的所有应用程序，他们安装了 &lt;a href=&#34;/docs/agent/latest/&#34;&gt;Grafana Agent&lt;/a&gt;，该代理会抓取日志，然后抓取 Prometheus 端点，然后发送将这些日志和指标发送给 Loki 和 Mimir。 &lt;em&gt;（注：在 GrafanaCON 2024 上，我们&lt;a href=&#34;/blog/2024/04/09/grafana-alloy-opentelemetry-collector-with-prometheus-pipelines/&#34;&gt;推出了 Grafana Alloy&lt;/a&gt;，我们的新的开源遥测收集器，100% OTLP 兼容，并为 OpenTelemetry 和 Prometheus 遥测格式提供本机管道，支持指标、日志、 Alloy 使用 Grafana Agent Flow 中首次引入的相同组件、代码和概念，现已弃用并提供长期支持。要了解更多信息，请参阅此 &lt;a href=&#34;。 /blog/2024/04/09/grafana-agent-to-grafana-alloy-opentelemetry-collector-faq/&#34;&gt;博客文章&lt;/a&gt;。）&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;团队还创建了自己的 &lt;a href=&#34;https://github.com/grafana/grafana-ansible-collection&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Grafana Ansible 集合&lt;/a&gt;进一步简化开发者体验。&lt;/p&gt;&#xA;&lt;p&gt;“我们将这一切都模板化了，实际上，开发人员在将基础设施定义为代码时需要做的唯一一件事就是定义一个带有应用程序名称和端口号的变量，然后就可以开始了， ”范恩格伦说道。 “其他一切都会自动推出。”&lt;/p&gt;&#xA;&lt;p&gt;通过在 Grafana 中可视化应用程序性能数据，团队能够实现任何图书馆员所希望的：一个安静的环境，团队可以在其中更快地调试问题并确定根本原因。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1999px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/national-library-of-netherlands/dutch-library_metrics-dashboard.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/blog/national-library-of-netherlands/dutch-library_metrics-dashboard.png&#34;data-srcset=&#34;/media/blog/national-library-of-netherlands/dutch-library_metrics-dashboard. w=320 320w, /media/blog/荷兰国家图书馆/dutch-library_metrics-dashboard.png?w=550 550w, /media/blog/荷兰国家图书馆/dutch-library_metrics-dashboard.png?w=750 750瓦， /media/blog/荷兰国家图书馆/dutch-library_metrics-dashboard.png?w=900 900w，/media/blog/荷兰国家图书馆/dutch-library_metrics-dashboard.png?w=1040 1040瓦， /media/blog/荷兰国家图书馆/dutch-library_metrics-dashboard.png?w=1240 1240w，/media/blog/荷兰国家图书馆/dutch-library_metrics-dashboard.png?w=1920 1920瓦”&#xA;data-sizes=&#34;auto&#34;alt=&#34;荷兰国家图书馆应用程序性能指标的 Grafana 仪表板。&#34;width=&#34;1999&#34;height=&#34;1087&#34;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src=&#34;/media/blog/national-libra荷兰/dutch-library_metrics-dashboard.png&#34;&#xA;alt=&#34;荷兰国家图书馆应用程序性能指标的 Grafana 仪表板。&#34;width=&#34;1999&#34;height=&#34;1087&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;“我们可以使用这些仪表板，以最少的配置相对快速地真正深入研究问题，”van Engelen 说。&lt;/p&gt;&#xA;&lt;h2 id=&#34;whats-next&#34;&gt;下一步是什么&lt;/h2&gt;&#xA;&lt;p&gt;荷兰国家图书馆制定了扩大 Grafana 堆栈在图书馆书库中的使用范围的宏伟计划。&lt;/p&gt;&#xA;&lt;p&gt;例如，展望未来，他们将实施 &lt;a href=&#34;/docs/grafana/latest/alerting/&#34;&gt;Grafana Alerting&lt;/a&gt; 来更主动地解决性能问题，&lt;a href=&#34;/ oss/tempo/&#34;&gt;Grafana Tempo&lt;/a&gt; 用于分布式跟踪，&lt;a href=&#34;/oss/faro/&#34;&gt;Grafana Faro&lt;/a&gt; 用于真实用户监控和前端应用程序可观察性。&lt;/p&gt;&#xA;&lt;p&gt;“这对我们来说只是冰山一角，”van Engelen 说。&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;/products/cloud/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt;是开始使用指标、日志、跟踪、仪表板等的最简单方法。我们为每个用例提供慷慨的永久免费套餐和计划。 &lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;plcmt=body-txt&#34;&gt;立即免费注册！&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 06 Jan 2025 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【Grafana LLM plugin updates: choose the large language models and providers that work best for you】Grafana LLM 插件更新：选择最适合您的大型语言模型和提供商</title>
      <link>https://grafana.com/blog/2024/12/18/grafana-llm-plugin-updates-choose-the-large-language-models-and-providers-that-work-best-for-you/</link>
      <description>【&lt;p&gt;At Grafana Labs, our mission has always been to empower users with the tools they need to build their own observability solutions. Our big tent philosophy embodies this mission by allowing you to choose the tools and technologies that best suit your needs.&lt;/p&gt;&#xA;&lt;p&gt;In this post, we want to share an update to our &lt;a href=&#34;/docs/grafana-cloud/alerting-and-irm/machine-learning/llm/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;LLM plugin&lt;/a&gt; that reflects this philosophy in action. As of the &lt;a href=&#34;https://github.com/grafana/grafana-llm-app/releases/tag/0.10.0&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;0.10.0 release&lt;/a&gt; earlier this year, the Grafana LLM plugin, which provides centralized access to large language models across Grafana, now supports &lt;a href=&#34;https://promptmetheus.com/resources/llm-knowledge-base/open-weights-model&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;open-weights models&lt;/a&gt; and non-OpenAI providers. This offers you greater flexibility to choose the LLMs and providers that best meet your needs in terms of performance, privacy, and cost.&lt;/p&gt;&#xA;&lt;h2 id=&#34;an-overview-of-the-grafana-llm-plugin&#34;&gt;An overview of the Grafana LLM plugin&lt;/h2&gt;&#xA;&lt;p&gt;The Grafana LLM plugin — currently in public preview in Grafana OSS, Grafana Enterprise, and Grafana Cloud — leverages generative AI to simplify your workflows. More specifically, the plugin helps you leverage LLMs to:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Annotate your dashboards and panels with more descriptive titles&lt;/li&gt;&#xA;&lt;li&gt;Automatically generate incident summaries&lt;/li&gt;&#xA;&lt;li&gt;Explain log patterns in a more human-friendly way&lt;/li&gt;&#xA;&lt;li&gt;Analyze complex flame graph profiles with&lt;a href=&#34;/blog/2024/05/15/ai-powered-insights-for-continuous-profiling-introducing-flame-graph-ai-in-grafana-cloud/&#34;&gt; Flame graph AI&lt;/a&gt; (shown below)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 948px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/docs/grafana-cloud/profiles/pyorsope-flamegraph-ai-analysis.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/docs/grafana-cloud/profiles/pyorsope-flamegraph-ai-analysis.png&#34;data-srcset=&#34;/media/docs/grafana-cloud/profiles/pyorsope-flamegraph-ai-analysis.png?w=320 320w, /media/docs/grafana-cloud/profiles/pyorsope-flamegraph-ai-analysis.png?w=550 550w, /media/docs/grafana-cloud/profiles/pyorsope-flamegraph-ai-analysis.png?w=750 750w, /media/docs/grafana-cloud/profiles/pyorsope-flamegraph-ai-analysis.png?w=900 900w, /media/docs/grafana-cloud/profiles/pyorsope-flamegraph-ai-analysis.png?w=1040 1040w, /media/docs/grafana-cloud/profiles/pyorsope-flamegraph-ai-analysis.png?w=1240 1240w, /media/docs/grafana-cloud/profiles/pyorsope-flamegraph-ai-analysis.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A screenshot of Flame graph AI.&#34;width=&#34;948&#34;height=&#34;918&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/docs/grafana-cloud/profiles/pyorsope-flamegraph-ai-analysis.png&#34;&#xA;alt=&#34;A screenshot of Flame graph AI.&#34;width=&#34;948&#34;height=&#34;918&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;The update we made in the 0.10.0 release makes these capabilities more accessible, no matter which LLMs or LLM provider you prefer, by allowing you to choose what works best for you and to balance cost, performance, and privacy.&lt;/p&gt;&#xA;&lt;h2 id=&#34;unified-support-for-llms&#34;&gt;Unified support for LLMs&lt;/h2&gt;&#xA;&lt;p&gt;Initially, Grafana&amp;rsquo;s LLM features were exclusive to models from &lt;a href=&#34;https://openai.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;OpenAI&lt;/a&gt;, leveraging their powerful GPT models. While these models are remarkable, we recognized the need for flexibility. With the latest update, you now have the freedom to integrate any model you prefer, as long as it is behind an OpenAI-compatible API and supports a system prompt.&lt;/p&gt;&#xA;&lt;p&gt;This means you can now take advantage of:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Self-hosted models:&lt;/strong&gt; You can use powerful open source models like &lt;a href=&#34;https://www.llama.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Llama 3&lt;/a&gt; and deploy them independently to gain full control over your data and model management.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Support for alternative LLM providers:&lt;/strong&gt; Through OpenAI-compatible proxies, such as &lt;a href=&#34;https://www.litellm.ai/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;LiteLLM&lt;/a&gt;, you can tap into models from different providers such as &lt;a href=&#34;https://gemini.google.com/app&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Google&amp;rsquo;s Gemini&lt;/a&gt; or &lt;a href=&#34;https://www.anthropic.com/claude&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Anthropic&amp;rsquo;s Claude&lt;/a&gt;, no matter which cloud service you&amp;rsquo;re using.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;To make this transition as seamless as possible, we are presenting two simplified options: a Base model for cost-effective LLM completions (e.g., gpt-4o-mini) or a Large model for use cases that require more advanced capabilities or larger context windows (e.g., gpt-4o). Grafana administrators can override these defaults and pick custom models that balance cost, performance, and privacy.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1050px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/llm-plugin-updates/LLM-plugin-updates-model-mapping.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/llm-plugin-updates/LLM-plugin-updates-model-mapping.png&#34;data-srcset=&#34;/media/blog/llm-plugin-updates/LLM-plugin-updates-model-mapping.png?w=320 320w, /media/blog/llm-plugin-updates/LLM-plugin-updates-model-mapping.png?w=550 550w, /media/blog/llm-plugin-updates/LLM-plugin-updates-model-mapping.png?w=750 750w, /media/blog/llm-plugin-updates/LLM-plugin-updates-model-mapping.png?w=900 900w, /media/blog/llm-plugin-updates/LLM-plugin-updates-model-mapping.png?w=1040 1040w, /media/blog/llm-plugin-updates/LLM-plugin-updates-model-mapping.png?w=1240 1240w, /media/blog/llm-plugin-updates/LLM-plugin-updates-model-mapping.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A screenshot of the model mappings feature in the LLM plugin.&#34;width=&#34;1050&#34;height=&#34;530&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/llm-plugin-updates/LLM-plugin-updates-model-mapping.png&#34;&#xA;alt=&#34;A screenshot of the model mappings feature in the LLM plugin.&#34;width=&#34;1050&#34;height=&#34;530&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;Some OpenAI-compatible API proxies, such as LiteLLM, have additional routing capabilities, allowing you to use different models from different providers (including your own self-hosted provider) for either the Base or Large model, depending on your unique needs and requirements.&lt;/p&gt;&#xA;&lt;h2 id=&#34;getting-started-with-custom-llm-providers&#34;&gt;Getting started with custom LLM providers&lt;/h2&gt;&#xA;&lt;p&gt;To use an alternative provider or self-hosted LLM model, follow these simple steps:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;/grafana/plugins/grafana-llm-app/&#34;&gt;Install the plugin&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Set up your LLM API&lt;/strong&gt;: Make sure you have an OpenAI-compatible API server, such as &lt;a href=&#34;https://github.com/vllm-project/vllm&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;vLLM&lt;/a&gt;, &lt;a href=&#34;https://ollama.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Ollama&lt;/a&gt;, &lt;a href=&#34;https://lmstudio.ai/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;LM Studio&lt;/a&gt;, or &lt;a href=&#34;https://www.litellm.ai/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;LiteLLM&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Configure the plugin:&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;In the plugin settings, select &lt;strong&gt;Use your own OpenAI Account.&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;Set the OpenAI API URL to point to your self-hosted API (e.g. &lt;a href=&#34;http://vllm.internal.url:8000/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;http://vllm.internal.url:8000/&lt;/a&gt;).&lt;/li&gt;&#xA;&lt;li&gt;Map your custom models in &lt;strong&gt;Model Settings &amp;gt; Model mappings&lt;/strong&gt; by specifying the &lt;code&gt;Base&lt;/code&gt; and &lt;code&gt;Large&lt;/code&gt; model (e.g., &lt;code&gt;meta-llama/Meta-Llama-3-8B-Instruct&lt;/code&gt;).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;That&amp;rsquo;s it! You can now enjoy Grafana’s LLM-powered features with your chosen model. On top of that, you now have the option to change the default model used to Base or Large, depending on your needs.&lt;/p&gt;&#xA;&lt;h2 id=&#34;benchmarking-non-openai-llms-on-grafana&#34;&gt;Benchmarking non-OpenAI LLMs on Grafana&lt;/h2&gt;&#xA;&lt;p&gt;As we opened the doors to bringing your own LLMs, we wanted to ensure that Grafana’s AI features still work as expected when using non-OpenAI options. This is easier said than done, since it&amp;rsquo;s not easy to guarantee a prompt still works consistently across diverse providers and open LLM models.&lt;/p&gt;&#xA;&lt;p&gt;Part of our testing approach was to benchmark our AI features across some popular LLMs. We discovered that the current prompt structure wasn&amp;rsquo;t reliable for a subset of models (particularly llama3), since it was using multiple system prompts. By being able to test different approaches, we were able to improve it and make sure our features still work as best as they can, regardless of the model you choose.&lt;/p&gt;&#xA;&lt;h3 id=&#34;benchmark-results&#34;&gt;Benchmark results&lt;/h3&gt;&#xA;&lt;table&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;&lt;strong&gt;Model&lt;/strong&gt;&#xA;&lt;/td&gt;&#xA;&lt;td&gt;&lt;strong&gt;Panel description&lt;/strong&gt; &lt;br&#xA;&lt;/strong&gt;N=841&#xA;&lt;/td&gt;&#xA;&lt;td&gt;&lt;strong&gt;Panel title&lt;/strong&gt; &lt;br&#xA;&lt;/strong&gt;N=841&#xA;&lt;/td&gt;&#xA;&lt;td&gt;&lt;strong&gt;Dashboard title&lt;/strong&gt; &lt;br&#xA;&lt;/strong&gt;N=506&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;gemini-1.5-flash&#xA;&lt;/td&gt;&#xA;&lt;td&gt;78.1%&#xA;&lt;/td&gt;&#xA;&lt;td&gt;&lt;strong&gt;82.0%&lt;/strong&gt;&#xA;&lt;/td&gt;&#xA;&lt;td&gt;67.2%&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;claude-3.5-sonnet&#xA;&lt;/td&gt;&#xA;&lt;td&gt;&lt;strong&gt;78.4%&lt;/strong&gt;&#xA;&lt;/td&gt;&#xA;&lt;td&gt;80.5%&#xA;&lt;/td&gt;&#xA;&lt;td&gt;&lt;strong&gt;68.7%&lt;/strong&gt;&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;gpt-4o-2024-05-13&#xA;&lt;/td&gt;&#xA;&lt;td&gt;77.8%&#xA;&lt;/td&gt;&#xA;&lt;td&gt;81.3%&#xA;&lt;/td&gt;&#xA;&lt;td&gt;66.1%&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;gpt-4o-mini-2024-07-18&#xA;&lt;/td&gt;&#xA;&lt;td&gt;78.0%&#xA;&lt;/td&gt;&#xA;&lt;td&gt;80.7%&#xA;&lt;/td&gt;&#xA;&lt;td&gt;66.8%&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;gpt-4-turbo-2024-04-09&#xA;&lt;/td&gt;&#xA;&lt;td&gt;77.6%&#xA;&lt;/td&gt;&#xA;&lt;td&gt;79.4%&#xA;&lt;/td&gt;&#xA;&lt;td&gt;66.9%&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;gpt-3.5-turbo-0125&#xA;&lt;/td&gt;&#xA;&lt;td&gt;76.3%&#xA;&lt;/td&gt;&#xA;&lt;td&gt;77.8%&#xA;&lt;/td&gt;&#xA;&lt;td&gt;63.6%&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;llama3:8b-instruct&#xA;&lt;/td&gt;&#xA;&lt;td&gt;73.0%&#xA;&lt;/td&gt;&#xA;&lt;td&gt;73.1%&#xA;&lt;/td&gt;&#xA;&lt;td&gt;65.0%&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;llama3.1:8b-instruct (AWQ)&#xA;&lt;/td&gt;&#xA;&lt;td&gt;76.7%&#xA;&lt;/td&gt;&#xA;&lt;td&gt;70.9%&#xA;&lt;/td&gt;&#xA;&lt;td&gt;63.1%&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;llama3:8b-instruct (pre-fix)&#xA;&lt;/td&gt;&#xA;&lt;td&gt;59.2%&#xA;&lt;/td&gt;&#xA;&lt;td&gt;58.5%&#xA;&lt;/td&gt;&#xA;&lt;td&gt;64.1%&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/table&gt;&#xA;&lt;p&gt;As expected, larger models deliver better performance, and by supporting smaller models, as well, we provide more flexibility and options for trading off cost and performance.&lt;/p&gt;&#xA;&lt;h2 id=&#34;whats-next-for-llms-in-grafana&#34;&gt;What’s next for LLMs in Grafana?&lt;/h2&gt;&#xA;&lt;p&gt;As we’re looking ahead, we want to bring more LLM capabilities to Grafana developers and continue to embrace our big tent philosophy.&lt;/p&gt;&#xA;&lt;p&gt;One of the features we&amp;rsquo;re excited to explore is enabling function calling and tool integration. This would allow developers to use LLMs to interact with Grafana to, for example, create new incidents or update dashboards.&lt;/p&gt;&#xA;&lt;p&gt;A recent Grafana Labs &lt;a href=&#34;/blog/2024/03/01/grafana-labs-hackathon-projects-where-are-they-now/&#34;&gt;hackathon&lt;/a&gt; project experimented with the &lt;a href=&#34;https://modelcontextprotocol.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Model Context Protocol&lt;/a&gt; (MCP) and created a Grafana MCP server that offers this functionality and more. This lets users ask questions of their Grafana instance from any compatible MCP client, such as Claude Desktop or Zed. Furthermore, it paves the way to a more &lt;a href=&#34;https://hbr.org/2024/12/what-is-agentic-ai-and-how-will-it-change-work&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;agentic&lt;/a&gt; approach to interacting with Grafana: imagine being able to chat with your Grafana instance from Slack, with an assistant that can search for relevant dashboards, add comments to incidents, or start &lt;a href=&#34;/docs/grafana-cloud/alerting-and-irm/machine-learning/sift/&#34;&gt;Sift investigations&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Stay tuned to learn more, as we continue to build out LLM capabilities in Grafana.&lt;/p&gt;】&lt;p&gt;在 Grafana Labs，我们的使命始终是为用户提供构建自己的可观测性解决方案所需的工具。我们的大帐篷理念体现了这一使命，让您可以选择最适合您需求的工具和技术。&lt;/p&gt;&#xA;&lt;p&gt;在这篇文章中，我们想分享&lt;a href=&#34;/docs/grafana-cloud/alerting-and-irm/machine-learning/llm/?pg=blog&amp;plcmt=body-txt&#34;&gt;LLM 的更新插件&lt;/a&gt;在行动中体现了这一理念。自 &lt;a href=&#34;https://github.com/grafana/grafana-llm-app/releases/tag/0.10.0&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;0.10.0 版本&lt;/ a&gt; 今年早些时候，Grafana LLM 插件提供了对 Grafana 大型语言模型的集中访问，现在支持 &lt;a href=&#34;https://promptmetheus.com/resources/llm-knowledge-base/open-weights-model&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;开放权重模型&lt;/a&gt;和非 OpenAI 提供商。这使您可以更加灵活地选择最能满足您在性能、隐私和成本方面的需求的法学硕士和提供商。&lt;/p&gt;&#xA;&lt;h2 id=&#34;an-overview-of-the-grafana-llm-plugin&#34;&gt;Grafana LLM 插件概述&lt;/h2&gt;&#xA;&lt;p&gt;Grafana LLM 插件目前在 Grafana OSS、Grafana Enterprise 和 Grafana Cloud 中提供公共预览版，利用生成式 AI 来简化您的工作流程。更具体地说，该插件可帮助您利用法学硕士来：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;使用更具描述性的标题来注释您的仪表板和面板&lt;/li&gt;&#xA;&lt;li&gt;自动生成事件摘要&lt;/li&gt;&#xA;&lt;li&gt;以更人性化的方式解释日志模式&lt;/li&gt;&#xA;&lt;li&gt;使用&lt;a href=&#34;/blog/2024/05/15/ai-powered-insights-for-continuous-profiling-introducing-flame-graph-ai-in-grafana-cloud/&#34;分析复杂的火焰图剖面&gt; 火焰图AI&lt;/a&gt;（如下图）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：948px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接”&#xA;href=&#34;/media/docs/grafana-cloud/profiles/pyorsope-flamegraph-ai-analysis.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src =“/media/docs/grafana-cloud/profiles/pyorsope-flamegraph-ai-analysis.png”data-srcset =“/media/docs/grafana-cloud/profiles/pyorsope-flamegraph-ai-analysis.png” png?w=320 320w，/media/docs/grafana-cloud/profiles/pyorsope-flamegraph-ai-analysis.png?w=550 550w， /media/docs/grafana-cloud/profiles/pyorsope-flamegraph-ai-analysis.png?w=750 750w，/media/docs/grafana-cloud/profiles/pyorsope-flamegraph-ai-analysis.png?w=900 900w，/media/docs/grafana-cloud/profiles/pyorsope-flamegraph-ai-analysis.png?w=1040 1040w、/media/docs/grafana-cloud/profiles/pyorsope-flamegraph-ai-analysis.png?w=1240 1240w、/media/docs/grafana-cloud/profiles/pyorsope-flamegraph-ai-analysis.png?w =1920 1920w&#34;&#xA;data-sizes =“auto”alt =“火焰图AI的屏幕截图。”width =“948”height =“918”/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/docs/grafana-cloud/profiles/pyorsope-flamegraph-ai-analysis.png”&#xA;alt=&#34;A sc火焰图 AI 重拍。&#34;width=&#34;948&#34;height=&#34;918&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;我们在 0.10.0 版本中进行的更新使您可以更轻松地使用这些功能，无论您喜欢哪个 LLM 或 LLM 提供商，您都可以选择最适合您的选项并平衡成本、性能和隐私。&lt; /p&gt;&#xA;&lt;h2 id=&#34;unified-support-for-llms&#34;&gt;对法学硕士的统一支持&lt;/h2&gt;&#xA;&lt;p&gt;最初，Grafana 的 LLM 功能是 &lt;a href=&#34;https://openai.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;OpenAI&lt;/a&gt; 的模型独有的，利用其强大的 GPT 模型。虽然这些模型非常出色，但我们认识到灵活性的必要性。通过最新的更新，您现在可以自由地集成您喜欢的任何模型，只要它位于兼容 OpenAI 的 API 后面并支持系统提示即可。&lt;/p&gt;&#xA;&lt;p&gt;这意味着您现在可以利用：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;自托管模型&lt;/strong&gt;：您可以使用强大的开源模型，例如 &lt;a href=&#34;https://www.llama.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34; &gt;Llama 3&lt;/a&gt; 并独立部署它们，以完全控制您的数据和模型管理。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;支持替代 LLM 提供商&lt;/strong&gt;：通过 OpenAI 兼容代理，例如 &lt;a href=&#34;https://www.litellm.ai/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer &#34;&gt;LiteLLM&lt;/a&gt;，您可以利用来自不同提供商的模型，例如 &lt;a href=&#34;https://gemini.google.com/app&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Google 的模型Gemini&lt;/a&gt; 或 &lt;a href=&#34;https://www.anthropic.com/claude&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Anthropic 的 Claude&lt;/a&gt;，无论您使用哪种云服务使用。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;为了使这一过渡尽可能无缝，我们提供了两个简化的选项：用于经济高效的 LLM 完成的基本模型（例如 gpt-4o-mini）或用于需要更高级功能或的用例的大型模型更大的上下文窗口（例如 gpt-4o）。 Grafana 管理员可以覆盖这些默认值并选择平衡成本、性能和隐私的自定义模型。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1050px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/llm-plugin-updates/LLM-plugin-updates-model-mapping.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/blog/llm-plugin-updates/LLM-plugin-updates-model-mapping.png&#34;data-srcset=&#34;/media/blog/llm-plugin-updates/LLM-plugin-updates- model-mapping.png?w=320 320w，/media/blog/llm-plugin-updates/LLM-plugin-updates-model-mapping.png?w=550 550w，/media/blog/llm-plugin-updates/LLM-plugin-updates-model-mapping.png?w=750 750w，/media/blog/llm-plugin-updates/LLM-plugin-updates-model-mapping .png?w=900 900w, /media/blog/llm-plugin-updates/LLM-plugin-updates-model-mapping.png?w=1040 1040w，/media/blog/llm-plugin-updates/LLM-plugin-updates-model-mapping.png ?w=1240 1240w，/media/blog/llm-plugin-updates/LLM-plugin-updates-model-mapping.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;LLM 插件中模型映射功能的屏幕截图。&#34;width=&#34;1050&#34;height=&#34;530&#34;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/llm-plugin-updates/LLM-plugin-updates-model-mapping.png”&#xA;alt=&#34;LLM 插件中模型映射功能的屏幕截图。&#34;width=&#34;1050&#34;height=&#34;530&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;一些与 OpenAI 兼容的 API 代理（例如 LiteLLM）具有额外的路由功能，允许您根据您的独特需求，针对基本模型或大型模型使用来自不同提供商（包括您自己的自托管提供商）的不同模型和要求。&lt;/p&gt;&#xA;&lt;h2 id=&#34;getting-started-with-custom-llm-providers&#34;&gt;自定义 LLM 提供商入门&lt;/h2&gt;&#xA;&lt;p&gt;要使用替代提供商或自托管 LLM 模型，请按照以下简单步骤操作：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;/grafana/plugins/grafana-llm-app/&#34;&gt;安装插件&lt;/a&gt;&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;设置您的 LLM API&lt;/strong&gt;：确保您拥有与 OpenAI 兼容的 API 服务器，例如 &lt;a href=&#34;https://github.com/vllm-project/vllm&#34; target= &#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;vLLM&lt;/a&gt;，&lt;a href=&#34;https://ollama.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Ollama&lt;/a&gt;，&lt;a href=&#34;https://lmstudio.ai/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;LM Studio&lt;/a&gt;，或 &lt;a href=&#34;https://www.litellm.ai/&#34; target= “_blank”rel =“noopener noreferrer”&gt;LiteLLM&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;配置插件：&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;在插件设置中，选择&lt;strong&gt;使用您自己的 OpenAI 帐户。&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;将 OpenAI API URL 设置为指向您的自托管 API（例如 &lt;a href=&#34;http://vllm.internal.url:8000/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;http: //vllm.internal.url:8000/&lt;/a&gt;)。&lt;/li&gt;&#xA;&lt;li&gt;通过指定 &lt;code&gt;Base&lt;/code&gt; 和 &lt;code&gt;Large&lt;/code&gt; 模型（例如 &lt;code&gt;meta-llama /Meta-Llama-3-8B-Instruct&lt;/code&gt;）。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;就是这样！现在，您可以通过您选择的模型享受 Grafana 的 LLM 支持的功能。最重要的是，您现在可以选择根据您的需要将默认模型更改为“基本”或“大”。&lt;/p&gt;&#xA;&lt;h2 id=&#34;benchmarking-non-openai-llms-on-grafana&#34;&gt;在 Grafana 上对非 OpenAI LLM 进行基准测试&lt;/h2&gt;&#xA;&lt;p&gt;当我们为您带来自己的法学硕士敞开大门时，我们希望确保 Grafana 的 AI 功能在使用非 OpenAI 选项时仍然按预期工作。这说起来容易做起来难，因为要保证提示在不同的提供商和开放的 LLM 模型中仍然一致地工作并不容易。&lt;/p&gt;&#xA;&lt;p&gt;我们测试方法的一部分是在一些流行的法学硕士中对我们的人工智能功能进行基准测试。我们发现当前的提示结构对于部分模型（特别是 llama3）来说并不可靠，因为它使用多个系统提示。通过测试不同的方法，我们能够改进它并确保我们的无论您选择哪种型号，功能仍然会尽其所能地发挥作用。&lt;/p&gt;&#xA;&lt;h3 id=&#34;benchmark-results&#34;&gt;基准测试结果&lt;/h3&gt;&#xA;&lt;表&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;&lt;strong&gt;型号&lt;/strong&gt;&#xA;&lt;/td&gt;&#xA;&lt;td&gt;&lt;strong&gt;面板说明&lt;/strong&gt; &lt;br&#xA;&lt;/strong&gt;N=841&#xA;&lt;/td&gt;&#xA;&lt;td&gt;&lt;strong&gt;面板标题&lt;/strong&gt; &lt;br&#xA;&lt;/strong&gt;N=841&#xA;&lt;/td&gt;&#xA;&lt;td&gt;&lt;strong&gt;仪表板标题&lt;/strong&gt; &lt;br&#xA;&lt;/strong&gt;N=506&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;gemini-1.5-flash&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;78.1%&#xA;&lt;/td&gt;&#xA;&lt;td&gt;&lt;strong&gt;82.0%&lt;/strong&gt;&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;67.2%&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;claude-3.5-十四行诗&#xA;&lt;/td&gt;&#xA;&lt;td&gt;&lt;strong&gt;78.4%&lt;/strong&gt;&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;80.5%&#xA;&lt;/td&gt;&#xA;&lt;td&gt;&lt;strong&gt;68.7%&lt;/strong&gt;&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;gpt-4o-2024-05-13&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;77.8%&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;81.3%&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;66.1%&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;gpt-4o-mini-2024-07-18&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;78.0%&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;80.7%&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;66.8%&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;gpt-4-turbo-2024-04-09&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;77.6%&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;79.4%&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;66.9%&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;gpt-3.5-turbo-0125&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;76.3%&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;77.8%&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;63.6%&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;llama3:8b-指令&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;73.0%&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;73.1%&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;65.0%&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;llama3.1:8b-指令 (AWQ)&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;76.7%&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;70.9%&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;63.1%&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;llama3:8b-指令（前缀）&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;59.2%&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;58.5%&#xA;&lt;/td&gt;&#xA;&lt;TD&gt;64.1%&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/表&gt;&#xA;&lt;p&gt;正如预期的那样，较大的模型可提供更好的性能，并且通过支持较小的模型，我们提供了更多的灵活性和选项来权衡成本和性能。&lt;/p&gt;&#xA;&lt;h2 id=&#34;whats-next-for-llms-in-grafana&#34;&gt;Grafana 法学硕士的下一步是什么？&lt;/h2&gt;&#xA;&lt;p&gt;展望未来，我们希望为 Grafana 开发人员带来更多 LLM 功能，并继续秉承我们的大帐篷理念。&lt;/p&gt;&#xA;&lt;p&gt;我们很高兴探索的功能之一是支持函数调用和工具集成。这将允许开发人员使用 LLM 与 Grafana 进行交互，例如创建新事件或更新仪表板。&lt;/p&gt;&#xA;&lt;p&gt;最近的 Grafana Labs &lt;a href=&#34;/blog/2024/03/01/grafana-labs-hackathon-projects-where-are-they-now/&#34;&gt;黑客马拉松&lt;/a&gt; 项目试验了&lt;a href=&#34;https://modelcontextprotocol.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;模型上下文协议&lt;/a&gt; (MCP) 并创建了 Grafana MCP 服务器它提供了此功能以及更多功能。这使用户可以从任何兼容的 MCP 客户端（例如 Claude Desktop 或 Zed）询问其 Grafana 实例的问题。此外，它为更多&lt;a href=&#34;https://hbr.org/2024/12/what-is-agentic-ai-and-how-will-it-change-work&#34; target=&#34;_blank &#34; rel=&#34;noopener noreferrer&#34;&gt;代理&lt;/a&gt; 与 Grafana 交互的方法：想象一下能够通过 Slack 与 Grafana 实例聊天，助手可以搜索相关仪表板、向事件添加评论或启动&lt;a href=&#34;/docs/grafana-cloud/alerting-and-irm/machine-learning/sift/&#34;&gt;筛选调查&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;请继续关注以了解更多信息，我们将继续在 Grafana 中构建 LLM 功能。&lt;/p&gt;</description>
      <pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【How CERN uses Grafana and Mimir to monitor the world&#39;s largest computer grid】CERN 如何使用 Grafana 和 Mimir 监控世界上最大的计算机网格</title>
      <link>https://grafana.com/blog/2025/01/02/how-cern-uses-grafana-and-mimir-to-monitor-the-worlds-largest-computer-grid/</link>
      <description>【&lt;p&gt;The European Organization for Nuclear Research (CERN) is famous for operating &lt;a href=&#34;https://home.web.cern.ch/science/accelerators/large-hadron-collider&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;the world&amp;rsquo;s largest particle accelerator&lt;/a&gt;, but did you know that CERN is also at the heart of the world&amp;rsquo;s largest computing grid? And with such unprecedented computing demands comes some serious observability needs.&lt;/p&gt;&#xA;&lt;p&gt;CERN operates two data centers at its facility near Ganeva, Switzerland, which includes 11,000 servers, 470,000 cores, and 380 PB of archived data. But CERN also wants to make that data available for scientists around the world to analyze, which is why they coordinate the Worldwide Large Hadron Collider Computing Grid (WLCG). The WLCG extends to 170 institutes and universities across 42 countries, bringing the combined infrastructure to 1.4 million computing cores and 1.5 exabytes of available storage, generating 2 million tasks per day at a global transfer rate of 260 GB/s.&lt;/p&gt;&#xA;&lt;p&gt;In other words, it&amp;rsquo;s &lt;em&gt;a lot&lt;/em&gt; of data.&lt;/p&gt;&#xA;&lt;p&gt;&amp;ldquo;Of course, such infrastructure requires monitoring, and this is where the monitoring service itself comes into place with our main mandate to monitor the data center, WLGC, but also our services that are running in our IT department,&amp;rdquo; said Nikolay Tsvetkov, Staff Computing Engineer at CERN.&lt;/p&gt;&#xA;&lt;p&gt;CERN uses Grafana and Grafana Mimir as part of a scalable, fault-tolerant stack that makes sure the 12,000 physicists who rely on the WLCG have access to the data they need.&lt;/p&gt;&#xA;&lt;p&gt;&amp;ldquo;Grafana is crucial for the monitoring service at CERN, providing us with many, many useful dashboards, but also with alerting functionality,&amp;rdquo; Tsvetkov said, noting that the recent addition of Grafana Mimir &amp;ldquo;provides the missing bit&amp;rdquo; in their Prometheus architecture.&lt;/p&gt;&#xA;&lt;p&gt;Tsvetkov works on the IT Monitoring and Data Streaming services at CERN and also serves as the service manager for their monitoring visualization tools. He &lt;a href=&#34;/events/grafanacon/2024/cern-monitors-largest-computing-grid-with-grafana-and-mimir/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;shared his experience at GrafanaCON 2024&lt;/a&gt;, highlighting how Grafana and &lt;a href=&#34;/oss/mimir/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Mimir&lt;/a&gt; help CERN and the WLCG operate at a truly massive scale.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Want to tell your story at GrafanaCON, our largest community conference of the year? We’re &lt;a href=&#34;https://pretalx.com/grafanacon-2025/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;looking for speakers to share their real-world experiences&lt;/a&gt; with Grafana, custom-built plugins, cool dashboards, and more. This is a community-driven conference focused on your favorite visualization tool, its big tent of data source plugins, and the surrounding open source ecosystem — Prometheus, Loki, OpenTelemetry, Mimir, and more.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h2 id=&#34;how-cern-uses-grafana-to-visualize-its-data&#34;&gt;How CERN uses Grafana to visualize its data&lt;/h2&gt;&#xA;&lt;p&gt;Tsvetkov&amp;rsquo;s team monitors roughly 15,000 hosts and receives around 85,000 documents every second, which translates to 3.3 TB of data stored every day.&lt;/p&gt;&#xA;&lt;p&gt;&amp;ldquo;Having such a wide range of services to monitor, of course provides some challenges for us,&amp;rdquo; Tsvetkov said. &amp;ldquo;The first one is that we get data from heterogeneous data sources. We need to actually unify the way we get this data so we can cope with this.&amp;rdquo;&lt;/p&gt;&#xA;&lt;div&#xA;class=&#34;youtube-lazyload responsive-video&#34;&#xA;data-embed=&#34;UDMoWQxW3iA&#34;&#xA;data-url=&#34;https://www.youtube.com/embed/UDMoWQxW3iA?autoplay=1&amp;amp;rel=0&#34;&#xA;data-title=&#34;YouTube Video&#34;&#xA;&gt;&#xA;&lt;div class=&#34;play-button&#34;&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;In 2016, CERN adopted Grafana as its primary monitoring interface to address that issue. Today with more than 5,000 Grafana users across 70 organizations creating more than 2,700 dashboards and 680 alert rules, it&amp;rsquo;s safe to say, &amp;ldquo;our users, they love it,&amp;rdquo; said Tsvetkov. &amp;ldquo;Of course, they&amp;rsquo;re creating a lot of dashboards, but we found that Grafana is quite useful as a unified data source.&amp;rdquo;&lt;/p&gt;&#xA;&lt;p&gt;That&amp;rsquo;s because Grafana provides a proxy, so some of CERN&amp;rsquo;s systems are accessing data from Grafana data sources through the Grafana APIs. &amp;ldquo;It actually hides the complexity of the different databases that are behind the data sources,&amp;rdquo; Tsvetkov said.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1516px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/cern-gcon/cern-etf-tests.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/cern-gcon/cern-etf-tests.png&#34;data-srcset=&#34;/media/blog/cern-gcon/cern-etf-tests.png?w=320 320w, /media/blog/cern-gcon/cern-etf-tests.png?w=550 550w, /media/blog/cern-gcon/cern-etf-tests.png?w=750 750w, /media/blog/cern-gcon/cern-etf-tests.png?w=900 900w, /media/blog/cern-gcon/cern-etf-tests.png?w=1040 1040w, /media/blog/cern-gcon/cern-etf-tests.png?w=1240 1240w, /media/blog/cern-gcon/cern-etf-tests.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A Grafana dashboard for ETF tests&#34;width=&#34;1516&#34;height=&#34;774&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/cern-gcon/cern-etf-tests.png&#34;&#xA;alt=&#34;A Grafana dashboard for ETF tests&#34;width=&#34;1516&#34;height=&#34;774&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;Their Grafana deployment is split between a public instance that&amp;rsquo;s available to anyone (hosted on two VMs behind load balancers in different availability zones), and private instances that sit behind CERN&amp;rsquo;s SSO (multi-organization, with six servers behind a DNS load balancer and VMs in three availability zones.)&lt;/p&gt;&#xA;&lt;p&gt;Managing all those dashboards can present some operational challenges, so they rely on the &lt;a href=&#34;/docs/grafana/latest/administration/organization-management/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;organizations&lt;/a&gt; feature in Grafana. Public organizations need to be available to all Grafana users, so Tsvetkov&amp;rsquo;s team runs some scripts to synchronize them regularly. The private organizations are mainly used by service managers, so those managers are given the flexibility to decide who should have access.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1536px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/cern-gcon/cern-openstack-services.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/cern-gcon/cern-openstack-services.png&#34;data-srcset=&#34;/media/blog/cern-gcon/cern-openstack-services.png?w=320 320w, /media/blog/cern-gcon/cern-openstack-services.png?w=550 550w, /media/blog/cern-gcon/cern-openstack-services.png?w=750 750w, /media/blog/cern-gcon/cern-openstack-services.png?w=900 900w, /media/blog/cern-gcon/cern-openstack-services.png?w=1040 1040w, /media/blog/cern-gcon/cern-openstack-services.png?w=1240 1240w, /media/blog/cern-gcon/cern-openstack-services.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;Grafana dashboard for monitoring CERN&amp;#39;s OpenStack environment&#34;width=&#34;1536&#34;height=&#34;784&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/cern-gcon/cern-openstack-services.png&#34;&#xA;alt=&#34;Grafana dashboard for monitoring CERN&amp;#39;s OpenStack environment&#34;width=&#34;1536&#34;height=&#34;784&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;Even managing plugins became easier: While physicists often created custom plugins for Grafana, in recent years, this hasn&amp;rsquo;t been an issue. &amp;ldquo;Grafana has became a more and more complete product, and we are getting anything that we need almost out of the box,&amp;rdquo; Tsvetkov said.&lt;/p&gt;&#xA;&lt;h2 id=&#34;grafana-mimir-the-missing-piece&#34;&gt;Grafana Mimir: the missing piece&lt;/h2&gt;&#xA;&lt;p&gt;From the beginning, the team was aware of a lack of support in their stack for users who wanted to integrate long-term storage for Prometheus metrics. They began working on a solution in 2020 using InfluxDB as a backend, but it was clear that it wouldn&amp;rsquo;t scale well in the future, Tsvetkov said. They ultimately turned their attention to Mimir, our horizontally scalable, highly available, multi-tenant TSDB for long-term storage, and began testing how it would suit their use case.&lt;/p&gt;&#xA;&lt;p&gt;With 80 million active series, they found Mimir could scale to meet their needs.&lt;/p&gt;&#xA;&lt;p&gt;&amp;ldquo;Also, we liked the fact that you can scale at a different component, either at the ingestion site or the query site,&amp;rdquo; Tsvetkov said. &amp;ldquo;Mimir also provides a lot of flexibility, with multi-tenancy and getting data from, from different users, so this would also allow us to integrate all the data into a single storage.&amp;rdquo;&lt;/p&gt;&#xA;&lt;p&gt;They began a pilot service in 2023 running on their Kubernetes deployment, which had 49 nodes, including 46 worker nodes that provide more than 1.2 TB of memory and 730 CPU cores, as well as different node groups to address the different hardware requirements. They also used Amazon S3 as their object storage, with 40-day default retention.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1388px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/cern-gcon/cern-cluster.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/cern-gcon/cern-cluster.png&#34;data-srcset=&#34;/media/blog/cern-gcon/cern-cluster.png?w=320 320w, /media/blog/cern-gcon/cern-cluster.png?w=550 550w, /media/blog/cern-gcon/cern-cluster.png?w=750 750w, /media/blog/cern-gcon/cern-cluster.png?w=900 900w, /media/blog/cern-gcon/cern-cluster.png?w=1040 1040w, /media/blog/cern-gcon/cern-cluster.png?w=1240 1240w, /media/blog/cern-gcon/cern-cluster.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;Kubernetes monitoring with a Grafana dashboard&#34;width=&#34;1388&#34;height=&#34;590&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/cern-gcon/cern-cluster.png&#34;&#xA;alt=&#34;Kubernetes monitoring with a Grafana dashboard&#34;width=&#34;1388&#34;height=&#34;590&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;In Mimir, they were running 29 tenants, producing 30 millions of active series. By their calculations, those tenants could have accommodated 150 million active series and processed around 2,000 queries per second.&lt;/p&gt;&#xA;&lt;p&gt;As a result, &amp;ldquo;now Mimir is well integrated within the pipeline,&amp;rdquo; Tsvetkov said.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1370px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/cern-gcon/cern-distributor.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/cern-gcon/cern-distributor.png&#34;data-srcset=&#34;/media/blog/cern-gcon/cern-distributor.png?w=320 320w, /media/blog/cern-gcon/cern-distributor.png?w=550 550w, /media/blog/cern-gcon/cern-distributor.png?w=750 750w, /media/blog/cern-gcon/cern-distributor.png?w=900 900w, /media/blog/cern-gcon/cern-distributor.png?w=1040 1040w, /media/blog/cern-gcon/cern-distributor.png?w=1240 1240w, /media/blog/cern-gcon/cern-distributor.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;Grafana dashboard for CERN&amp;#39;s distributors&#34;width=&#34;1370&#34;height=&#34;768&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/cern-gcon/cern-distributor.png&#34;&#xA;alt=&#34;Grafana dashboard for CERN&amp;#39;s distributors&#34;width=&#34;1370&#34;height=&#34;768&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;Going forward, more open source tools are under consideration for CERN, including Open Telemetry and Grafana Tempo for tracing.&lt;/p&gt;&#xA;&lt;p&gt;But no matter how big the computing grid becomes, the foundation for their infrastructure is firmly rooted in Grafana.&lt;/p&gt;&#xA;&lt;p&gt;&amp;ldquo;It has been with us since the beginning of the architecture,&amp;rdquo; Tsvetkov said, &amp;ldquo;and we have always been very happy using Grafana.&amp;rdquo;&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;/products/cloud/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Cloud &lt;/a&gt;is the easiest way to get started with metrics, logs, traces, dashboards, and more. We have a generous forever-free tier and plans for every use case. &lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Sign up for free now!&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;】&lt;p&gt;欧洲核研究组织 (CERN) 因运营 &lt;a href=&#34;https://home.web.cern.ch/science/accelerators/large-hadron-collider&#34; target=&#34;_blank&#34; rel= 而闻名“noopener noreferrer&#34;&gt;世界上最大的粒子加速器&lt;/a&gt;，但您是否知道 CERN 也是世界上最大的计算网格的核心？伴随着这种前所未有的计算需求，随之而来的是一些严重的可观测性需求。&lt;/p&gt;&#xA;&lt;p&gt;CERN 在瑞士加内瓦附近的设施中运营着两个数据中心，其中包括 11,000 台服务器、470,000 个核心和 380 PB 的存档数据。但欧洲核子研究中心也希望将这些数据提供给世界各地的科学家进行分析，这就是他们协调全球大型强子对撞机计算网格（WLCG）的原因。 WLCG 扩展到 42 个国家/地区的 170 个研究所和大学，使综合基础设施拥有 140 万个计算核心和 1.5 艾字节可用存储，每天以 260 GB/s 的全球传输速率生成 200 万个任务。&lt;/p&gt;&#xA;&lt;p&gt;换句话说，这是&lt;em&gt;大量&lt;/em&gt;数据。&lt;/p&gt;&#xA;&lt;p&gt;“当然，这样的基础设施需要监控，这就是监控服务本身发挥作用的地方，我们的主要任务是监控数据中心、WLGC，以及我们 IT 部门运行的服务，”Nikolay 说道Tsvetkov，CERN 计算工程师。&lt;/p&gt;&#xA;&lt;p&gt;CERN 使用 Grafana 和 Grafana Mimir 作为可扩展、容错堆栈的一部分，确保依赖 WLCG 的 12,000 名物理学家能够访问他们所需的数据。&lt;/p&gt;&#xA;&lt;p&gt;“Grafana 对于 CERN 的监控服务至关重要，它为我们提供了很多很多有用的仪表板，而且还具有警报功能，”Tsvetkov 说，并指出最近添加的 Grafana Mimir “提供了 Prometheus 中缺失的部分”架构。&lt;/p&gt;&#xA;&lt;p&gt;Tsvetkov 在 CERN 从事 IT 监控和数据流服务工作，并担任其监控可视化工具的服务经理。他&lt;a href=&#34;/events/grafanacon/2024/cern-monitors-largest-computing-grid-with-grafana-and-mimir/?pg=blog&amp;plcmt=body-txt&#34;&gt;分享了他在 GrafanaCON 2024 上的经验&lt;/a &gt;，重点介绍 Grafana 和 &lt;a href=&#34;/oss/mimir/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana Mimir&lt;/a&gt;帮助 CERN 和 WLCG 真正大规模运作。&lt;/p&gt;&#xA;&lt;块引用&gt;&#xA;&lt;p&gt;想在我们年度最大的社区会议 GrafanaCON 上讲述您的故事吗？我们正在&lt;a href=&#34;https://pretalx.com/grafanacon-2025/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;寻找演讲者与 Grafana 分享他们的真实经验&lt;/a&gt;，定制插件、炫酷的仪表板等等。这是一个社区驱动的会议，重点讨论您最喜欢的可视化工具、其庞大的数据源插件以及周围的开源生态系统 - Prometheus、Loki、OpenTelemetry、Mimir 等。&lt;/p&gt;&#xA;&lt;/块引用&gt;&#xA;&lt;h2 id=&#34;how-cern-uses-grafana-to-visualize-its-data&#34;&gt;CERN 如何使用 Grafana 进行可视化整理其数据&lt;/h2&gt;&#xA;&lt;p&gt;Tsvetkov 的团队监控大约 15,000 台主机，每秒接收大约 85,000 个文档，这意味着每天存储 3.3 TB 的数据。&lt;/p&gt;&#xA;&lt;p&gt;“要监控如此广泛的服务，当然给我们带来了一些挑战，”Tsvetkov 说。 “第一个是我们从异构数据源获取数据。我们实际上需要统一获取这些数据的方式，以便我们能够应对这一问题。”&lt;/p&gt;&#xA;&lt;div&#xA;类 =“youtube-lazyload 响应视频”&#xA;数据嵌入=“UDMoWQxW3iA”&#xA;data-url=&#34;https://www.youtube.com/embed/UDMoWQxW3iA?autoplay=1&amp;rel=0&#34;&#xA;数据标题=“YouTube 视频”&#xA;&gt;&#xA;&lt;div class=&#34;play-button&#34;&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;2016 年，CERN 采用 Grafana 作为其主要监控界面来解决该问题。如今，70 个组织的 5,000 多名 Grafana 用户创建了 2,700 多个仪表板和 680 条警报规则，可以肯定地说，“我们的用户喜欢它，”Tsvetkov 说。 “当然，他们正在创建很多仪表板，但我们发现 Grafana 作为统一数据源非常有用。”&lt;/p&gt;&#xA;&lt;p&gt;这是因为 Grafana 提供了代理，因此 CERN 的一些系统正在通过 Grafana API 访问来自 Grafana 数据源的数据。 “它实际上隐藏了数据源背后不同数据库的复杂性，”Tsvetkov 说。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1516px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/cern-gcon/cern-etf-tests.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src =“/media/blog/cern-gcon/cern-etf-tests.png”data-srcset =“/media/blog/cern-gcon/cern-etf-tests.png？w = 320 320w，/媒体/博客/cern-gcon/cern-etf-tests.png?w=550 550w, /media/blog/cern-gcon/cern-etf-tests.png?w=750 750w, /media/blog/cern-gcon/cern-etf-tests.png?w=900 900w, /media/blog/cern -gcon/cern-etf-tests.png?w=1040 1040w, /media/blog/cern-gcon/cern-etf-tests.png?w=1240 1240w，/media/blog/cern-gcon/cern-etf-tests.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;用于 ETF 测试的 Grafana 仪表板&#34;width=&#34;1516&#34;height=&#34;774&#34;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/cern-gcon/cern-etf-tests.png”&#xA;alt=&#34;用于 ETF 测试的 Grafana 仪表板&#34;width=&#34;1516&#34;height=&#34;774&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;他们的 Grafana 部署分为可供任何人使用的公共实例（托管在不同可用区域的负载均衡器后面的两个虚拟机上）和位于 CERN SSO 后面的私有实例（多组织，在 DNS 负载后面有六台服务器）平衡器和虚拟机位于三个可用区。）&lt;/p&gt;&#xA;&lt;p&gt;管理所有这些仪表板可能会带来一些运营挑战，因此它们依赖于&lt;a href=&#34;/docs/grafana/latest/administration/organization-management/?pg=blog&amp;plcmt=body-txt&#34;&gt;组织&lt;/a &gt; Grafana 中的功能。公共组织需要o 可供所有 Grafana 用户使用，因此 Tsvetkov 的团队运行一些脚本来定期同步它们。私有组织主要由服务经理使用，因此这些经理可以灵活地决定谁应该有权访问。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1536px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/cern-gcon/cern-openstack-services.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src =“/media/blog/cern-gcon/cern-openstack-services.png”data-srcset =“/media/blog/cern-gcon/cern-openstack-services.png？w = 320 320w，/媒体/博客/cern-gcon/cern-openstack-services.png?w=550 550w, /media/blog/cern-gcon/cern-openstack-services.png?w=750 750w, /media/blog/cern-gcon/cern-openstack-services.png?w=900 900w, /media/blog/cern -gcon/cern-openstack-services.png?w=1040 1040w, /media/blog/cern-gcon/cern-openstack-services.png?w=1240 1240w，/media/blog/cern-gcon/cern-openstack-services.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;用于监控 CERN OpenStack 环境的 Grafana 仪表板&#34;width=&#34;1536&#34;height=&#34;784&#34;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/cern-gcon/cern-openstack-services.png”&#xA;alt=&#34;用于监控 CERN OpenStack 环境的 Grafana 仪表板&#34;width=&#34;1536&#34;height=&#34;784&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;甚至管理插件也变得更加容易：虽然物理学家经常为 Grafana 创建自定义插件，但近年来，这已经不再是问题。 “Grafana 已经成为一个越来越完整的产品，我们几乎可以开箱即用地获得我们需要的任何东西，”Tsvetkov 说。&lt;/p&gt;&#xA;&lt;h2 id=&#34;grafana-mimir-the-missing-piece&#34;&gt;Grafana Mimir：缺失的部分&lt;/h2&gt;&#xA;&lt;p&gt;从一开始，团队就意识到他们的堆栈中缺乏对想要集成 Prometheus 指标长期存储的用户的支持。 Tsvetkov 表示，他们于 2020 年开始研究使用 InfluxDB 作为后端的解决方案，但很明显，该解决方案未来无法很好地扩展。他们最终将注意力转向 Mimir，这是我们用于长期存储的水平可扩展、高可用性、多租户 TSDB，并开始测试它如何适合他们的用例。&lt;/p&gt;&#xA;&lt;p&gt;凭借 8000 万个活跃系列，他们发现 Mimir 可以扩展以满足他们的需求。&lt;/p&gt;&#xA;&lt;p&gt;“此外，我们还喜欢这样一个事实：您可以在不同的组件上进行扩展，无论是在摄取站点还是在查询站点，”Tsvetkov 说。 “Mimir 还提供了很大的灵活性，支持多租户并从不同用户获取数据，因此这也使我们能够将所有数据集成到单个存储中。”&lt;/p&gt;&#xA;&lt;p&gt;他们于 2023 年开始在 Kubernetes 部署上运行试点服务，该部署有 49 个节点，其中包括 46 个工作节点，提供超过 1.2 TB 的内存和 730 个 CPU 核心，以及不同的节点组来满足不同的硬件要求。他们还使用 Amazon S3 作为对象存储，默认保留期为 40 天。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1388px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/cern-gcon/cern-cluster.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src =“/media/blog/cern-gcon/cern-cluster.png”data-srcset =“/media/blog/cern-gcon/cern-cluster.png？w = 320 320w，/media/blog/ cern-gcon/cern-cluster.png?w=550 550w，/media/blog/cern-gcon/cern-cluster.png?w=750 750w，/media/blog/cern-gcon/cern-cluster.png？w=900 900w，/media/blog/cern-gcon/cern-cluster.png？w=1040 1040w，/media/blog/cern-gcon /cern-cluster.png?w=1240 1240w, /media/blog/cern-gcon/cern-cluster.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;使用 Grafana 仪表板进行 Kubernetes 监控&#34;width=&#34;1388&#34;height=&#34;590&#34;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/cern-gcon/cern-cluster.png”&#xA;alt=&#34;使用 Grafana 仪表板进行 Kubernetes 监控&#34;width=&#34;1388&#34;height=&#34;590&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;在 Mimir，他们运营着 29 个租户，生产了 3000 万个活跃剧集。根据他们的计算，这些租户可以容纳 1.5 亿个活跃系列，每秒处理大约 2,000 个查询。&lt;/p&gt;&#xA;&lt;p&gt;因此，“现在 Mimir 已经很好地集成到了管道中，”Tsvetkov 说。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1370px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/cern-gcon/cern-distributor.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src =“/media/blog/cern-gcon/cern-distributor.png”data-srcset =“/media/blog/cern-gcon/cern-distributor.png？w = 320 320w，/media/blog/ cern-gcon/cern-distributor.png?w=550 550w, /media/blog/cern-gcon/cern-distributor.png?w=750 750w, /media/blog/cern-gcon/cern-distributor.png?w=900 900w, /media/blog/cern-gcon/cern -distributor.png?w=1040 1040w, /media/blog/cern-gcon/cern-distributor.png?w=1240 1240w, /media/blog/cern-gcon/cern-distributor.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;CERN 分销商的 Grafana 仪表板&#34;width=&#34;1370&#34;height=&#34;768&#34;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/cern-gcon/cern-distributor.png”&#xA;alt=&#34;CERN 分销商的 Grafana 仪表板&#34;width=&#34;1370&#34;height=&#34;768&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;展望未来，CERN 正在考虑更多开源工具，包括用于跟踪的 Open Telemetry 和 Grafana Tempo。&lt;/p&gt;&#xA;&lt;p&gt;但无论计算网格变得有多大，其基础设施的基础都牢牢植根于 Grafana。&lt;/p&gt;&#xA;&lt;p&gt;“从架构一开始，它就一直伴随着我们，”Tsvetkov 说，“我们一直非常高兴使用 Grafana。”&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;/products/cloud/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana Cloud &lt;/a&gt;是最简单的这是开始使用指标、日志、跟踪、仪表板等的方法。我们为每个用例提供慷慨的永久免费套餐和计划。 &lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;plcmt=body-txt&#34;&gt;立即免费注册！&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 02 Jan 2025 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【How to monitor your local weather with Grafana】如何使用 Grafana 监控当地天气</title>
      <link>https://grafana.com/blog/2024/12/26/how-to-monitor-your-local-weather-with-grafana/</link>
      <description>【&lt;p&gt;Ever look at a wall of raw data and wonder, &amp;ldquo;How am I supposed to make sense of &lt;em&gt;this&lt;/em&gt;?&amp;rdquo; That’s exactly where Grafana comes in, turning your data into beautiful dashboards with panels of graphs and other visualization types.&lt;/p&gt;&#xA;&lt;p&gt;In this blog post, which is geared towards those new to Grafana, we’ll walk through an example that demonstrates how, exactly, Grafana can transform your data into eye-catching dashboards. To do this, we’ll build a free weather dashboard using &lt;a href=&#34;/products/cloud/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt;. (Don’t have a Grafana Cloud account yet? No worries. We have a generous free-forever tier that you can &lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;sign up for today&lt;/a&gt;.)&lt;/p&gt;&#xA;&lt;h2 id=&#34;a-quick-overview-of-grafana-and-grafana-cloud&#34;&gt;A quick overview of Grafana and Grafana Cloud&lt;/h2&gt;&#xA;&lt;p&gt;Grafana is an open source solution that enables you to collect, correlate, and visualize your data, regardless of where that data is stored. This is because Grafana supports a vast number of data sources and accommodates a wide range of use cases — whether it’s monitoring server health or &lt;a href=&#34;/blog/2024/04/01/how-to-monitor-your-kids-chores-an-introduction-to-grafana-powered-parenting/&#34;&gt;your kids completing their chores&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1483px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link captioned&#34;&#xA;href=&#34;/media/blog/weather-dashboard/weather-dashboard-grafana-example.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload mb-0&#34;&#xA;data-src=&#34;/media/blog/weather-dashboard/weather-dashboard-grafana-example.png&#34;data-srcset=&#34;/media/blog/weather-dashboard/weather-dashboard-grafana-example.png?w=320 320w, /media/blog/weather-dashboard/weather-dashboard-grafana-example.png?w=550 550w, /media/blog/weather-dashboard/weather-dashboard-grafana-example.png?w=750 750w, /media/blog/weather-dashboard/weather-dashboard-grafana-example.png?w=900 900w, /media/blog/weather-dashboard/weather-dashboard-grafana-example.png?w=1040 1040w, /media/blog/weather-dashboard/weather-dashboard-grafana-example.png?w=1240 1240w, /media/blog/weather-dashboard/weather-dashboard-grafana-example.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A sample Grafana dashboard to monitor Linux server health. &#34;width=&#34;1483&#34;height=&#34;985&#34;title=&#34;*A sample Grafana dashboard to monitor Linux server health.*&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/weather-dashboard/weather-dashboard-grafana-example.png&#34;&#xA;alt=&#34;A sample Grafana dashboard to monitor Linux server health. &#34;width=&#34;1483&#34;height=&#34;985&#34;title=&#34;*A sample Grafana dashboard to monitor Linux server health.*&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;figcaption class=&#34;w-100p caption text-gray-13 &#34;&gt;&lt;em&gt;A sample Grafana dashboard to monitor Linux server health.&lt;/em&gt;&lt;/figcaption&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;Introduced as an open source project in 2013, Grafana has grown to have a thriving community of more than 25 million users worldwide. (&lt;em&gt;Note: if you want to learn more about the origins and evolution of Grafana, you can check out &lt;a href=&#34;/blog/2024/02/12/the-story-of-grafana-documentary-from-one-developers-dream-to-20-million-users-worldwide/&#34;&gt;‘The Story of Grafana’ documentary.&lt;/a&gt;&lt;/em&gt;)&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;/products/cloud/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt;, meanwhile, is our fully managed, cloud-hosted observability platform powered by the Grafana LGTM (&lt;a href=&#34;/oss/loki/&#34;&gt;Loki&lt;/a&gt; for logs, &lt;a href=&#34;/oss/grafana?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana&lt;/a&gt; for visualization, &lt;a href=&#34;/oss/tempo/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Tempo&lt;/a&gt; for traces, &lt;a href=&#34;/oss/mimir/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Mimir&lt;/a&gt; for metrics) Stack. We’ll be using Grafana Cloud to create our free weather dashboard.&lt;/p&gt;&#xA;&lt;h2 id=&#34;how-to-build-a-custom-weather-dashboard-with-grafana-cloud&#34;&gt;How to build a custom weather dashboard with Grafana Cloud&lt;/h2&gt;&#xA;&lt;p&gt;Now we’ll walk through an example of how to transform raw JSON data into a weather forecast dashboard using Grafana Cloud. It should take about 30 minutes to do, and when we’re finished, you’ll have a useful weather forecast dashboard that you can check right from your cell phone.&lt;/p&gt;&#xA;&lt;p&gt;We’ll use a &lt;a href=&#34;http://api.weather.gov&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;free public API&lt;/a&gt; from the &lt;a href=&#34;https://www.weather.gov/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;U.S. National Weather Service&lt;/a&gt; that offers detailed forecast information for all areas in the United States. If you’re outside the U.S., you can use &lt;a href=&#34;https://open-meteo.com/en/docs&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;OpenMeteo&lt;/a&gt; (in Europe) or &lt;a href=&#34;https://openweathermap.org/api&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;OpenWeatherMap&lt;/a&gt; (globally) to fetch your local weather data.&lt;/p&gt;&#xA;&lt;p&gt;Here’s an example of the weather API response with data formatted as JSON:&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 573px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/weather-dashboard/weather-dashboard-grafana-cloud-JSON.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/weather-dashboard/weather-dashboard-grafana-cloud-JSON.png&#34;data-srcset=&#34;/media/blog/weather-dashboard/weather-dashboard-grafana-cloud-JSON.png?w=320 320w, /media/blog/weather-dashboard/weather-dashboard-grafana-cloud-JSON.png?w=550 550w, /media/blog/weather-dashboard/weather-dashboard-grafana-cloud-JSON.png?w=750 750w, /media/blog/weather-dashboard/weather-dashboard-grafana-cloud-JSON.png?w=900 900w, /media/blog/weather-dashboard/weather-dashboard-grafana-cloud-JSON.png?w=1040 1040w, /media/blog/weather-dashboard/weather-dashboard-grafana-cloud-JSON.png?w=1240 1240w, /media/blog/weather-dashboard/weather-dashboard-grafana-cloud-JSON.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A screenshot of raw JSON data.&#34;width=&#34;573&#34;height=&#34;455&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/weather-dashboard/weather-dashboard-grafana-cloud-JSON.png&#34;&#xA;alt=&#34;A screenshot of raw JSON data.&#34;width=&#34;573&#34;height=&#34;455&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;It’s packed with useful info, but most people don’t want to read JSON to check the weather. This is where Grafana Cloud dashboards will come in.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 500px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link captioned&#34;&#xA;href=&#34;/media/blog/weather-dashboard/weather-dashboard-meme.jpg&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload mb-0&#34;&#xA;data-src=&#34;/media/blog/weather-dashboard/weather-dashboard-meme.jpg&#34;data-srcset=&#34;/media/blog/weather-dashboard/weather-dashboard-meme.jpg?w=320 320w, /media/blog/weather-dashboard/weather-dashboard-meme.jpg?w=550 550w, /media/blog/weather-dashboard/weather-dashboard-meme.jpg?w=750 750w, /media/blog/weather-dashboard/weather-dashboard-meme.jpg?w=900 900w, /media/blog/weather-dashboard/weather-dashboard-meme.jpg?w=1040 1040w, /media/blog/weather-dashboard/weather-dashboard-meme.jpg?w=1240 1240w, /media/blog/weather-dashboard/weather-dashboard-meme.jpg?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A screenshot of a meme about JSON code being difficult to read.&#34;width=&#34;500&#34;height=&#34;500&#34;title=&#34;*JSON: Great for computers, difficult for humans.*&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/weather-dashboard/weather-dashboard-meme.jpg&#34;&#xA;alt=&#34;A screenshot of a meme about JSON code being difficult to read.&#34;width=&#34;500&#34;height=&#34;500&#34;title=&#34;*JSON: Great for computers, difficult for humans.*&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;figcaption class=&#34;w-100p caption text-gray-13 &#34;&gt;&lt;em&gt;JSON: Great for computers, difficult for humans.&lt;/em&gt;&lt;/figcaption&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;We’ll also use the &lt;a href=&#34;/grafana/plugins/yesoreyeram-infinity-datasource/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Infinity data source&lt;/a&gt; plugin for Grafana, which lets you query and visualize data from JSON, CSV, XML, and GraphQL endpoints (think of it as a universal plugin for ingesting data from almost anywhere). This plugin is how we will get the raw weather data that powers our dashboard.&lt;/p&gt;&#xA;&lt;p&gt;Grafana Cloud will connect to the weather.gov API every time you load your dashboard, and render the results in a table.&lt;/p&gt;&#xA;&lt;p&gt;Below you’ll find a brief summary of the steps to create your weather dashboard. For more detailed instructions, please check out &lt;a href=&#34;https://github.com/scarolan/grafana-cloud-tutorial/tree/main/01-the-journey-begins&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;this tutorial on GitHub&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;&lt;strong&gt;Sign up for Grafana Cloud&lt;/strong&gt;: &lt;/a&gt;You can use any of our sign-in providers or sign up with an email address and password.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 614px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/weather-dashboard/weather-dashboard-grafana-cloud-signin.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/weather-dashboard/weather-dashboard-grafana-cloud-signin.png&#34;data-srcset=&#34;/media/blog/weather-dashboard/weather-dashboard-grafana-cloud-signin.png?w=320 320w, /media/blog/weather-dashboard/weather-dashboard-grafana-cloud-signin.png?w=550 550w, /media/blog/weather-dashboard/weather-dashboard-grafana-cloud-signin.png?w=750 750w, /media/blog/weather-dashboard/weather-dashboard-grafana-cloud-signin.png?w=900 900w, /media/blog/weather-dashboard/weather-dashboard-grafana-cloud-signin.png?w=1040 1040w, /media/blog/weather-dashboard/weather-dashboard-grafana-cloud-signin.png?w=1240 1240w, /media/blog/weather-dashboard/weather-dashboard-grafana-cloud-signin.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A screenshot of the Grafana Cloud sign up page. &#34;width=&#34;614&#34;height=&#34;585&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/weather-dashboard/weather-dashboard-grafana-cloud-signin.png&#34;&#xA;alt=&#34;A screenshot of the Grafana Cloud sign up page. &#34;width=&#34;614&#34;height=&#34;585&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;ol start=&#34;2&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;/grafana/plugins/yesoreyeram-infinity-datasource/?pg=blog&amp;amp;plcmt=body-txt&amp;amp;tab=installation&#34;&gt;Install the Infinity data source plugin&lt;/a&gt;&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Import a preconfigured weather dashboard&lt;/strong&gt;: Grafana Cloud allows you to import dashboards created by other users. If you can copy and paste some text, you can import a dashboard!&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Connect your local weather data using the National Weather Service API&lt;/strong&gt;: To find your local weather station, you’ll use the National Weather Service grid points for your chosen city, based on your longitude and latitude.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Customize the dashboard&lt;/strong&gt; with your city’s name and bookmark it for later use. Its format is optimized for display on a mobile device.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 418px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/weather-dashboard/weather-dashboard-grafana-cloud-forecast-resized.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/weather-dashboard/weather-dashboard-grafana-cloud-forecast-resized.png&#34;data-srcset=&#34;/media/blog/weather-dashboard/weather-dashboard-grafana-cloud-forecast-resized.png?w=320 320w, /media/blog/weather-dashboard/weather-dashboard-grafana-cloud-forecast-resized.png?w=550 550w, /media/blog/weather-dashboard/weather-dashboard-grafana-cloud-forecast-resized.png?w=750 750w, /media/blog/weather-dashboard/weather-dashboard-grafana-cloud-forecast-resized.png?w=900 900w, /media/blog/weather-dashboard/weather-dashboard-grafana-cloud-forecast-resized.png?w=1040 1040w, /media/blog/weather-dashboard/weather-dashboard-grafana-cloud-forecast-resized.png?w=1240 1240w, /media/blog/weather-dashboard/weather-dashboard-grafana-cloud-forecast-resized.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A screenshot of the Grafana Cloud dashboard for monitoring weather. &#34;width=&#34;418&#34;height=&#34;625&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/weather-dashboard/weather-dashboard-grafana-cloud-forecast-resized.png&#34;&#xA;alt=&#34;A screenshot of the Grafana Cloud dashboard for monitoring weather. &#34;width=&#34;418&#34;height=&#34;625&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;h2 id=&#34;your-grafana-cloud-adventure-awaits&#34;&gt;Your Grafana Cloud adventure awaits&lt;/h2&gt;&#xA;&lt;p&gt;This exercise is just one small example of what you can achieve with Grafana Cloud.&lt;/p&gt;&#xA;&lt;p&gt;To learn more, please check out these &lt;a href=&#34;/products/cloud/resources/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Cloud resources&lt;/a&gt;, including blog posts, technical docs, webinars, and quick-start guides. And if you have any questions, please reach out on our &lt;a href=&#34;https://community.grafana.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;community forums&lt;/a&gt; or &lt;a href=&#34;https://slack.grafana.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Slack&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;/products/cloud/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt; is the easiest way to get started with metrics, logs, traces, dashboards, and more. We have a generous forever-free tier and plans for every use case. &lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Sign up for free now!&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;】&lt;p&gt;您是否曾在看着一堵原始数据墙时想知道，“我该如何理解&lt;em&gt;这个&lt;/em&gt;？”这正是 Grafana 的用武之地，它将您的数据转变为带有图形面板和其他可视化类型的漂亮仪表板。&lt;/p&gt;&#xA;&lt;p&gt;在这篇面向 Grafana 新手的博文中，我们将通过一个示例来演示 Grafana 究竟如何将您的数据转换为引人注目的仪表板。为此，我们将使用 &lt;a href=&#34;/products/cloud/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt; 构建免费的天气仪表板。 （还没有 Grafana Cloud 帐户？不用担心。我们有一个慷慨的永久免费套餐，您可以 &lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;plcmt=body-txt&#34; &gt;今天就报名&lt;/a&gt;。）&lt;/p&gt;&#xA;&lt;h2 id=&#34;a-quick-overview-of-grafana-and-grafana-cloud&#34;&gt;Grafana 和 Grafana Cloud 快速概述&lt;/h2&gt;&#xA;&lt;p&gt;Grafana 是一种开源解决方案，使您能够收集、关联和可视化数据，无论数据存储在何处。这是因为 Grafana 支持大量数据源并适应广泛的用例 - 无论是监控服务器运行状况还是 &lt;a href=&#34;/blog/2024/04/01/how-to-monitor-your-kids- crimes-an-introduction-to-grafana-powered-parenting/&#34;&gt;你的孩子完成他们的家务&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1483px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接标题”&#xA;href=&#34;/media/blog/weather-dashboard/weather-dashboard-grafana-example.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“lazyload mb-0”&#xA;data-src=&#34;/media/blog/weather-dashboard/weather-dashboard-grafana-example.png&#34;data-srcset=&#34;/media/blog/weather-dashboard/weather-dashboard-grafana-example.png?w= 320 320w，/media/blog/weather-dashboard/weather-dashboard-grafana-example.png?w=550 550w, /media/blog/weather-dashboard/weather-dashboard-grafana-example.png?w=750 750w, /media/blog/weather-dashboard/weather-dashboard-grafana-example.png?w=900 900w, /media/blog/weather-dashboard/weather-dashboard-grafana-example.png?w=1040 1040w, /media/blog/weather-dashboard/weather-dashboard-grafana-example.png?w=1240 1240w, /media/blog/weather-dashboard/weather-dashboard-grafana-example.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;用于监控 Linux 服务器运行状况的示例 Grafana 仪表板。&#34;width=&#34;1483&#34;height=&#34;985&#34;title=&#34;*用于监控 Linux 服务器运行状况的示例 Grafana 仪表板。*&#34;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/weather-dashboard/weather-dashboard-grafana-example.png”&#xA;alt=&#34;用于监控 Linux 服务器运行状况的示例 Grafana 仪表板。&#34;width=&#34;1483&#34;height=&#34;985&#34;title=&#34;*用于监控 Linux 服务器运行状况的示例 Grafana 仪表板。*&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;figcaption class=&#34;w-100p title text-gray-13 &#34;&gt;&lt;em&gt;用于监控 Linux 服务器运行状况的 Grafana 仪表板示例。&lt;/em&gt;&lt;/figcaption&gt;&lt;/a&gt;&lt; /图&gt;&#xA;&lt;p&gt;Grafana 于 2013 年作为开源项目推出现已发展成为一个由全球超过 2500 万用户组成的蓬勃发展的社区。 （&lt;em&gt;注：如果您想了解更多关于 Grafana 的起源和演变，您可以查看 &lt;a href=&#34;/blog/2024/02/12/the-story-of-grafana-documentary-from-一个开发者梦想成为全球 2000 万用户/&#34;&gt;“Grafana 的故事”纪录片。&lt;/a&gt;&lt;/em&gt;)&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;/products/cloud/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt; 同时，是我们完全托管的云托管可观测平台，由 Grafana LGTM (&lt;a href=&#34;/oss/loki/&#34;&gt;Loki&lt;/a&gt; 用于日志，&lt;a href=&#34;/oss/grafana?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana&lt;/a&gt; 用于可视化，&lt;a href=&#34;/oss/tempo/?pg=blog&amp;plcmt=body-txt&#34;&gt;节奏&lt;/a&gt;用于轨迹，&lt;a href=&#34;/oss/mimir/?pg=blog&amp;plcmt=body-txt&#34;&gt;Mimir&lt;/a &gt; 对于指标）堆栈。我们将使用 Grafana Cloud 创建免费的天气仪表板。&lt;/p&gt;&#xA;&lt;h2 id=&#34;how-to-build-a-custom-weather-dashboard-with-grafana-cloud&#34;&gt;如何使用 Grafana Cloud 构建自定义天气仪表板&lt;/h2&gt;&#xA;&lt;p&gt;现在我们将通过一个示例演示如何使用 Grafana Cloud 将原始 JSON 数据转换为天气预报仪表板。完成大约需要 30 分钟，完成后，您将拥有一个有用的天气预报仪表板，您可以直接通过手机进行查看。&lt;/p&gt;&#xA;&lt;p&gt;我们将使用 &lt;a href=&#34;https://api.weather.gov&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;免费公共 API&lt;/a&gt; ://www.weather.gov/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;美国国家气象局&lt;/a&gt;提供美国所有地区的详细预报信息。如果您在美国境外，可以使用 &lt;a href=&#34;https://open-meteo.com/en/docs&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;OpenMeteo&lt;/a&gt;（在欧洲) 或 &lt;a href=&#34;https://openweathermap.org/api&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;OpenWeatherMap&lt;/a&gt;（全球）获取您当地的天气数据。&lt;/p&gt;&#xA;&lt;p&gt;以下是天气 API 响应的示例，其中数据格式为 JSON：&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：573px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/weather-dashboard/weather-dashboard-grafana-cloud-JSON.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/blog/weather-dashboard/weather-dashboard-grafana-cloud-JSON.png&#34;data-srcset=&#34;/media/blog/weather-dashboard/weather-dashboard-grafana-cloud-JSON. w=320 320w, /media/blog/weather-dashboard/weather-dashboard-grafana-cloud-JSON.png?w=550 550w, /media/blog/weather-dashboard/weather-dashboard-grafana-cloud-JSON.png?w=750 750瓦， /media/blog/weather-dashboard/weather-dashboard-grafana-cloud-JSON.png?w=900 900w, /media/blog/weather-dashboard/weather-dashboard-grafana-cloud-JSON.png?w=1040 1040瓦， /media/blog/weather-dashboard/weather-dashboard-grafana-cloud-JSON.png?w=1240 1240w，/media/blog/weather-dashboard/weather-dashboard-grafana-cloud-JSON.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;原始 JSON 数据的屏幕截图。&#34;width=&#34;573&#34;height=&#34;455&#34;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src=&#34;/media/blog/weather-dashboard/weather-dashboard-grafana-cloud-JSON.png&#34;&#xA;alt=&#34;原始 JSON 数据的屏幕截图。&#34;width=&#34;573&#34;height=&#34;455&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;它包含有用的信息，但大多数人不想读取 JSON 来检查天气。这就是 Grafana Cloud 仪表板的用武之地。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：500px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接标题”&#xA;href=&#34;/media/blog/weather-dashboard/weather-dashboard-meme.jpg&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“lazyload mb-0”&#xA;data-src=&#34;/media/blog/weather-dashboard/weather-dashboard-meme.jpg&#34;data-srcset=&#34;/media/blog/weather-dashboard/weather-dashboard-meme.jpg?w=320 320w, /媒体/博客/天气仪表板/天气仪表板-meme.jpg?w=550 550w, /media/blog/weather-dashboard/weather-dashboard-meme.jpg?w=750 750w, /media/blog/weather-dashboard/weather-dashboard-meme.jpg?w=900 900w, /media/blog/weather -仪表板/天气仪表板-meme.jpg?w=1040 1040w, /media/blog/weather-dashboard/weather-dashboard-meme.jpg?w=1240 1240w, /media/blog/weather-dashboard/weather-dashboard-meme.jpg?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;有关 JSON 代码难以阅读的模因的屏幕截图。&#34;width=&#34;500&#34;height=&#34;500&#34;title=&#34;*JSON：对计算机来说很好，对人类来说很难。*&#34; /&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src=&#34;/media/blog/weather-dashboard/weather-dashboard-meme.jpg&#34;&#xA;alt=&#34;有关 JSON 代码难以阅读的模因的屏幕截图。&#34;width=&#34;500&#34;height=&#34;500&#34;title=&#34;*JSON：对计算机来说很好，对人类来说很难。*&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;figcaption class=&#34;w-100p title text-gray-13 &#34;&gt;&lt;em&gt;JSON：对于计算机来说很好，对于人类来说很难。&lt;/em&gt;&lt;/figcaption&gt;&lt;/a&gt;&lt; /图&gt;&#xA;&lt;p&gt;我们还将使用 Grafana 的 &lt;a href=&#34;/grafana/plugins/yesoreyeram-infinity-datasource/?pg=blog&amp;plcmt=body-txt&#34;&gt;Infinity 数据源&lt;/a&gt; 插件，该插件可让您进行查询并可视化来自 JSON、CSV、XML 和 GraphQL 端点的数据（将其视为几乎可以从任何地方提取数据的通用插件）。这个插件是我们获取为仪表板提供支持的原始天气数据的方式。&lt;/p&gt;&#xA;&lt;p&gt;每次您加载仪表板时，Grafana Cloud 都会连接到weather.gov API，并将结果呈现在表格中。&lt;/p&gt;&#xA;&lt;p&gt;下面是创建天气仪表板的步骤的简要摘要。有关更详细的说明，请查看 &lt;a href=&#34;https://github.com/scarolan/grafana-cloud-tutorial/tree/main/01-the-journey-begins&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;GitHub 上的本教程&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;plcmt=body-txt&#34;&gt;&lt;strong&gt;注册 Grafana Cloud&lt;/strong&gt;：&lt;/a&gt;您可以使用任何我们的登录提供商或使用电子邮件地址和密码进行注册。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p“&#xA;样式=“最大宽度：614px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/weather-dashboard/weather-dashboard-grafana-cloud-signin.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/blog/weather-dashboard/weather-dashboard-grafana-cloud-signin.png&#34;data-srcset=&#34;/media/blog/weather-dashboard/weather-dashboard-grafana-cloud-signin.png w=320 320w, /media/blog/weather-dashboard/weather-dashboard-grafana-cloud-signin.png?w=550 550w, /media/blog/weather-dashboard/weather-dashboard-grafana-cloud-signin.png?w=750 750瓦， /media/blog/weather-dashboard/weather-dashboard-grafana-cloud-signin.png?w=900 900w, /media/blog/weather-dashboard/weather-dashboard-grafana-cloud-signin.png?w=1040 1040瓦， /media/blog/weather-dashboard/weather-dashboard-grafana-cloud-signin.png?w=1240 1240w, /media/blog/weather-dashboard/weather-dashboard-grafana-cloud-signin.png?w=1920 1920瓦”&#xA;data-sizes=&#34;auto&#34;alt=&#34;Grafana Cloud 注册页面的屏幕截图。&#34;width=&#34;614&#34;height=&#34;585&#34;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src=&#34;/media/blog/weather-dashboard/weather-dashboard-grafana-cloud-signin.png&#34;&#xA;alt=&#34;Grafana Cloud 注册页面的屏幕截图。&#34;width=&#34;614&#34;height=&#34;585&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;ol开始=“2”&gt;&#xA;&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;/grafana/plugins/yesoreyeram-infinity-datasource/?pg=blog&amp;plcmt=body-txt&amp;tab=installation&#34;&gt;安装 Infinity 数据源插件&lt;/a&gt;&lt;/strong&gt;。&lt; /里&gt;&#xA;&lt;li&gt;&lt;strong&gt;导入预配置的天气仪表板&lt;/strong&gt;：Grafana Cloud 允许您导入其他用户创建的仪表板。如果您可以复制并粘贴一些文本，则可以导入仪表板！&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;使用国家气象服务 API 连接您当地的天气数据&lt;/strong&gt;：要查找您当地的气象站，您将根据您所在的经度和纬度使用所选城市的国家气象服务网格点.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;使用您所在城市的名称自定义信息中心&lt;/strong&gt;并将其添加为书签以供以后使用。其格式针对在移动设备上的显示进行了优化。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：418px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/weather-dashboard/weather-dashboard-grafana-cloud-forecast-resized.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/blog/weather-dashboard/weather-dashboard-grafana-cloud-forecast-resized.png&#34;data-srcset=&#34;/media/blog/weather-dashboard/weather-dashboard-grafana-cloud-预测调整大小.png?w=320 320w, /media/blog/weather-dashboard/weather-dashboard-grafana-cloud-forecast-resized.png?w=550 550w，/media/blog/weather-dashboard/weather-dashboard-grafana-cloud-forecast-resized.png ?w=750 750w, /media/blog/weather-dashboard/weather-dashboard-grafana-cloud-forecast-resized.png?w=900 900w, /media/blog/weather-dashboard/weather-dashboard-grafana-cloud-forecast-resized.png?w=1040 1040w, /media/blog/weather-dashboard/weather-dashboard-grafana -cloud-forecast-resized.png?w=1240 1240w, /media/blog/weather-dashboard/weather-dashboard-grafana-cloud-forecast-resized.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;用于监控天气的 Grafana Cloud 仪表板的屏幕截图。&#34;width=&#34;418&#34;height=&#34;625&#34;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/weather-dashboard/weather-dashboard-grafana-cloud-forecast-resized.png”&#xA;alt=&#34;用于监控天气的 Grafana Cloud 仪表板的屏幕截图。&#34;width=&#34;418&#34;height=&#34;625&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;h2 id=&#34;your-grafana-cloud-adventure-await&#34;&gt;您的 Grafana Cloud 冒险等待着&lt;/h2&gt;&#xA;&lt;p&gt;此练习只是说明使用 Grafana Cloud 可以实现的目标的一个小示例。&lt;/p&gt;&#xA;&lt;p&gt;要了解更多信息，请查看这些 &lt;a href=&#34;/products/cloud/resources/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana Cloud 资源&lt;/a&gt;，包括博客文章、技术文档、网络研讨会、和快速入门指南。如果您有任何疑问，请访问我们的&lt;a href=&#34;https://community.grafana.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;社区论坛&lt;/a&gt;或&lt;a href =&#34;https://slack.grafana.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Slack&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;/products/cloud/?pg=blog&amp;plcmt=body-txt&#34;&gt;Grafana Cloud&lt;/a&gt; 是开始使用指标、日志、跟踪、仪表板等的最简单方法。我们为每个用例提供慷慨的永久免费套餐和计划。 &lt;a href=&#34;/auth/sign-up/create-user/?pg=blog&amp;plcmt=body-txt&#34;&gt;立即免费注册！&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 26 Dec 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【How to securely connect Grafana to Google BigQuery using Workload Identity Federation】如何使用工作负载身份联合安全地将 Grafana 连接到 Google BigQuery</title>
      <link>https://grafana.com/blog/2024/12/17/how-to-securely-connect-grafana-to-google-bigquery-using-workload-identity-federation/</link>
      <description>【&lt;p&gt;&lt;em&gt;Umesh Pawar is a Senior Cloud Engineer at Searce, and is also the co-organizer of the Grafana and Friends Delhi Group. Umesh has been focused on infrastructure and app modernization, as well as observability solutions including the Grafana LGTM Stack, for the past two years.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;With the &lt;a href=&#34;/grafana/plugins/grafana-bigquery-datasource/&#34;&gt;Google BigQuery data source plugin&lt;/a&gt; for Grafana, you can easily query and visualize data from BigQuery directly in Grafana. This enables a wide range of use cases, such as creating dashboards for log analysis, billing data, sales metrics, traffic analysis, and digital marketing campaign tracking.&lt;/p&gt;&#xA;&lt;p&gt;When running Grafana on Google Kubernetes Engine (GKE) and connecting to BigQuery as a data source, it&amp;rsquo;s essential to prioritize security. This blog explores how Workload Identity Federation can help you securely connect a Grafana instance running on GKE to the Google BigQuery service without exposing a service account key.&lt;/p&gt;&#xA;&lt;h2 id=&#34;authentication-with-gcp-using-workload-identity-federation&#34;&gt;Authentication with GCP using Workload Identity Federation&lt;/h2&gt;&#xA;&lt;p&gt;You can securely access Google Cloud APIs from your workloads running in GKE clusters by using &lt;a href=&#34;https://cloud.google.com/iam/docs/workload-identity-federation&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Workload Identity Federation&lt;/a&gt; for GKE.&lt;/p&gt;&#xA;&lt;p&gt;If you are running Grafana on GKE in &lt;a href=&#34;https://cloud.google.com/kubernetes-engine/docs/concepts/autopilot-overview&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Autopilot &lt;/a&gt;mode, Workload Identity Federation is enabled by default. When you are running in &lt;a href=&#34;https://cloud.google.com/kubernetes-engine/docs/concepts/choose-cluster-mode&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Standard&lt;/a&gt; mode, you enable Workload Identity Federation on clusters and node pools using the Google Cloud CLI or the Google Cloud console. Workload Identity Federation for GKE must be enabled at the cluster level before you can enable it for GKE on node pools.&lt;/p&gt;&#xA;&lt;p&gt;To enable on a new cluster:&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;button x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;Copy code to clipboard&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;Copy&lt;/span&gt;&#xA;&lt;/button&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;gcloud container clusters create CLUSTER_NAME \&#xA;--location=LOCATION \&#xA;--workload-pool=PROJECT_ID.svc.id.goog&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;p&gt;To enable on an existing cluster:&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;button x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;Copy code to clipboard&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;Copy&lt;/span&gt;&#xA;&lt;/button&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;gcloud container clusters update CLUSTER_NAME \&#xA;--location=LOCATION \&#xA;--workload-pool=PROJECT_ID.svc.id.goog&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;h2 id=&#34;configure-grafana-to-use-workload-identity-federation-for-gke&#34;&gt;Configure Grafana to use Workload Identity Federation for GKE&lt;/h2&gt;&#xA;&lt;p&gt;To let your GKE application — in our case, Grafana — authenticate to Google Cloud APIs using Workload Identity Federation for GKE, you need to create IAM policies for the specific APIs.&lt;/p&gt;&#xA;&lt;p&gt;If you are using a Helm chart, just edit this code to values.yaml.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1452px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/bigquery-grafana/bigquery-grafana-service-account-code.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/bigquery-grafana/bigquery-grafana-service-account-code.png&#34;data-srcset=&#34;/media/blog/bigquery-grafana/bigquery-grafana-service-account-code.png?w=320 320w, /media/blog/bigquery-grafana/bigquery-grafana-service-account-code.png?w=550 550w, /media/blog/bigquery-grafana/bigquery-grafana-service-account-code.png?w=750 750w, /media/blog/bigquery-grafana/bigquery-grafana-service-account-code.png?w=900 900w, /media/blog/bigquery-grafana/bigquery-grafana-service-account-code.png?w=1040 1040w, /media/blog/bigquery-grafana/bigquery-grafana-service-account-code.png?w=1240 1240w, /media/blog/bigquery-grafana/bigquery-grafana-service-account-code.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A screenshot of code for IAM policies.&#34;width=&#34;1452&#34;height=&#34;548&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/bigquery-grafana/bigquery-grafana-service-account-code.png&#34;&#xA;alt=&#34;A screenshot of code for IAM policies.&#34;width=&#34;1452&#34;height=&#34;548&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;If you are deploying as a &lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/deployment/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Kubernetes deployment&lt;/a&gt;, create a &lt;a href=&#34;https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Kubernetes service account&lt;/a&gt; for Grafana to use. You can also use any existing Kubernetes service account in any namespace. If you don&amp;rsquo;t assign a service account to your workload, Kubernetes assigns the default service account in the namespace.&lt;/p&gt;&#xA;&lt;p&gt;Grant your IAM service account the roles that it needs on specific Google Cloud APIs. In our case, Grafana wants to query the BigQuery API, so we will give it the &lt;a href=&#34;https://cloud.google.com/bigquery/docs/access-control#bigquery.admin&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;BigQuery Admin role&lt;/a&gt; (but, in general, always follow the principle of least privilege).&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;button x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;Copy code to clipboard&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;Copy&lt;/span&gt;&#xA;&lt;/button&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;gcloud projects add-iam-policy-binding IAM_SA_PROJECT_ID \&#xA;--member &amp;#34;serviceAccount:IAM_SA_NAME@IAM_SA_PROJECT_ID.iam.gserviceaccount.com&amp;#34; \&#xA;--role &amp;#34;ROLE_NAME&amp;#34;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;p&gt;Create an &lt;a href=&#34;https://cloud.google.com/iam/docs/policies&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;IAM allow policy&lt;/a&gt; that gives the Kubernetes service account access to impersonate the IAM service account. As a good practice, grant permissions to specific Google Cloud resources that your application needs to access. You must have relevant IAM permissions to create allow policies in your project.&lt;/p&gt;&#xA;&lt;p&gt;In the code block below, &lt;code&gt;KSA_NAME&lt;/code&gt; represents the Kubernetes service account name attached to the Grafana workload, and&lt;code&gt;NAMESPACE&lt;/code&gt; represents the namespace on which Grafana is deployed.&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;button x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;Copy code to clipboard&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;Copy&lt;/span&gt;&#xA;&lt;/button&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;gcloud iam service-accounts add-iam-policy-binding IAM_SA_NAME@IAM_SA_PROJECT_ID.iam.gserviceaccount.com \&#xA;--role roles/iam.workloadIdentityUser \&#xA;--member &amp;#34;serviceAccount:PROJECT_ID.svc.id.goog[NAMESPACE/KSA_NAME]&amp;#34;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;p&gt;Now we need to annotate the Kubernetes service account so GKE sees the link between the service accounts. &lt;em&gt;Note: if you are deploying through Helm, skip this step and instead annotate on your Helm chart, as seen on the above step.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;button x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;Copy code to clipboard&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;Copy&lt;/span&gt;&#xA;&lt;/button&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;kubectl annotate serviceaccount KSA_NAME \&#xA;--namespace NAMESPACE \&#xA;iam.gke.io/gcp-service-account=IAM_SA_NAME@IAM_SA_PROJECT_ID.iam.gserviceaccount.com&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;h2 id=&#34;configure-the-google-bigquery-data-source-for-grafana&#34;&gt;Configure the Google BigQuery data source for Grafana&lt;/h2&gt;&#xA;&lt;p&gt;As mentioned above, the &lt;a href=&#34;/grafana/plugins/grafana-bigquery-datasource/&#34;&gt;Google BigQuery data source plugin&lt;/a&gt; allows you to query and visualize Google BigQuery data from within Grafana.&lt;/p&gt;&#xA;&lt;h3 id=&#34;install-the-plugin&#34;&gt;Install the plugin&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Navigate to the BigQuery plugin homepage.&lt;/li&gt;&#xA;&lt;li&gt;On the right-hand side, click the &lt;strong&gt;Install&lt;/strong&gt; button.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1600px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/bigquery-grafana/bigquery-grafana-install-plugin-page.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/bigquery-grafana/bigquery-grafana-install-plugin-page.png&#34;data-srcset=&#34;/media/blog/bigquery-grafana/bigquery-grafana-install-plugin-page.png?w=320 320w, /media/blog/bigquery-grafana/bigquery-grafana-install-plugin-page.png?w=550 550w, /media/blog/bigquery-grafana/bigquery-grafana-install-plugin-page.png?w=750 750w, /media/blog/bigquery-grafana/bigquery-grafana-install-plugin-page.png?w=900 900w, /media/blog/bigquery-grafana/bigquery-grafana-install-plugin-page.png?w=1040 1040w, /media/blog/bigquery-grafana/bigquery-grafana-install-plugin-page.png?w=1240 1240w, /media/blog/bigquery-grafana/bigquery-grafana-install-plugin-page.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A screenshot of the the installation page for the BigQuery data source in Grafana.&#34;width=&#34;1600&#34;height=&#34;902&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/bigquery-grafana/bigquery-grafana-install-plugin-page.png&#34;&#xA;alt=&#34;A screenshot of the the installation page for the BigQuery data source in Grafana.&#34;width=&#34;1600&#34;height=&#34;902&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;h3 id=&#34;verify-that-the-plugin-is-installed&#34;&gt;Verify that the plugin is installed&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;In Grafana, navigate to &lt;strong&gt;Configuration &amp;gt; Data sources&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;From the top-right corner, click the &lt;strong&gt;Add data source&lt;/strong&gt; button.&lt;/li&gt;&#xA;&lt;li&gt;Search for Google BigQuery in the search field, and hover over the Google BigQuery search result.&lt;/li&gt;&#xA;&lt;li&gt;Click the &lt;strong&gt;Select&lt;/strong&gt; button for Google BigQuery. If you can click the &lt;strong&gt;Select&lt;/strong&gt; button, then it is installed.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1600px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/bigquery-grafana/bigquery-grafana-verify-the-data-source-works.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/bigquery-grafana/bigquery-grafana-verify-the-data-source-works.png&#34;data-srcset=&#34;/media/blog/bigquery-grafana/bigquery-grafana-verify-the-data-source-works.png?w=320 320w, /media/blog/bigquery-grafana/bigquery-grafana-verify-the-data-source-works.png?w=550 550w, /media/blog/bigquery-grafana/bigquery-grafana-verify-the-data-source-works.png?w=750 750w, /media/blog/bigquery-grafana/bigquery-grafana-verify-the-data-source-works.png?w=900 900w, /media/blog/bigquery-grafana/bigquery-grafana-verify-the-data-source-works.png?w=1040 1040w, /media/blog/bigquery-grafana/bigquery-grafana-verify-the-data-source-works.png?w=1240 1240w, /media/blog/bigquery-grafana/bigquery-grafana-verify-the-data-source-works.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A screenshot of the Settings tab for the BigQuery data source in Grafana.&#34;width=&#34;1600&#34;height=&#34;853&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/bigquery-grafana/bigquery-grafana-verify-the-data-source-works.png&#34;&#xA;alt=&#34;A screenshot of the Settings tab for the BigQuery data source in Grafana.&#34;width=&#34;1600&#34;height=&#34;853&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;h3 id=&#34;authentication&#34;&gt;Authentication&lt;/h3&gt;&#xA;&lt;p&gt;By automatically retrieving credentials using Workload Identity Federation (when running Grafana on GKE), make sure that the service account has been given read access to the BigQuery API.&lt;/p&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1600px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/bigquery-grafana/bigquery-grafana-plugin-authentication.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/bigquery-grafana/bigquery-grafana-plugin-authentication.png&#34;data-srcset=&#34;/media/blog/bigquery-grafana/bigquery-grafana-plugin-authentication.png?w=320 320w, /media/blog/bigquery-grafana/bigquery-grafana-plugin-authentication.png?w=550 550w, /media/blog/bigquery-grafana/bigquery-grafana-plugin-authentication.png?w=750 750w, /media/blog/bigquery-grafana/bigquery-grafana-plugin-authentication.png?w=900 900w, /media/blog/bigquery-grafana/bigquery-grafana-plugin-authentication.png?w=1040 1040w, /media/blog/bigquery-grafana/bigquery-grafana-plugin-authentication.png?w=1240 1240w, /media/blog/bigquery-grafana/bigquery-grafana-plugin-authentication.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A screenshot of the Authentication page for the BigQuery data source plugin.&#34;width=&#34;1600&#34;height=&#34;904&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/bigquery-grafana/bigquery-grafana-plugin-authentication.png&#34;&#xA;alt=&#34;A screenshot of the Authentication page for the BigQuery data source plugin.&#34;width=&#34;1600&#34;height=&#34;904&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;h3 id=&#34;query-the-data-source&#34;&gt;Query the data source&lt;/h3&gt;&#xA;&lt;p&gt;The query editor allows you to query the Google BigQuery data source. Queries can contain &lt;a href=&#34;/docs/plugins/yesoreyeram-infinity-datasource/latest/query/macros/&#34;&gt;macros&lt;/a&gt;, which simplify syntax and allow your queries to be more dynamic. The SQL query editor comes with a rich support for standard SQL, as well as autocompletion for:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;BigQuery standard SQL language syntax&lt;/li&gt;&#xA;&lt;li&gt;BigQuery datasets, tables, and columns&lt;/li&gt;&#xA;&lt;li&gt;Macros and template variables&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;figure&#xA;class=&#34;figure-wrapper figure-wrapper__lightbox w-100p &#34;&#xA;style=&#34;max-width: 1600px;&#34;&#xA;itemprop=&#34;associatedMedia&#34;&#xA;itemscope=&#34;&#34;&#xA;itemtype=&#34;http://schema.org/ImageObject&#34;&#xA;&gt;&lt;a&#xA;class=&#34;lightbox-link&#34;&#xA;href=&#34;/media/blog/bigquery-grafana/bigquery-grafana-query-the-data-source.png&#34;&#xA;itemprop=&#34;contentUrl&#34;&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;class=&#34;lazyload &#34;&#xA;data-src=&#34;/media/blog/bigquery-grafana/bigquery-grafana-query-the-data-source.png&#34;data-srcset=&#34;/media/blog/bigquery-grafana/bigquery-grafana-query-the-data-source.png?w=320 320w, /media/blog/bigquery-grafana/bigquery-grafana-query-the-data-source.png?w=550 550w, /media/blog/bigquery-grafana/bigquery-grafana-query-the-data-source.png?w=750 750w, /media/blog/bigquery-grafana/bigquery-grafana-query-the-data-source.png?w=900 900w, /media/blog/bigquery-grafana/bigquery-grafana-query-the-data-source.png?w=1040 1040w, /media/blog/bigquery-grafana/bigquery-grafana-query-the-data-source.png?w=1240 1240w, /media/blog/bigquery-grafana/bigquery-grafana-query-the-data-source.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;A screenshot of a query for the BigQuery data source.&#34;width=&#34;1600&#34;height=&#34;908&#34;/&gt;&#xA;&lt;noscript&gt;&#xA;&lt;img&#xA;src=&#34;/media/blog/bigquery-grafana/bigquery-grafana-query-the-data-source.png&#34;&#xA;alt=&#34;A screenshot of a query for the BigQuery data source.&#34;width=&#34;1600&#34;height=&#34;908&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;h2 id=&#34;how-to-learn-more&#34;&gt;How to learn more&lt;/h2&gt;&#xA;&lt;p&gt;To explore more on this topic, you can check out &lt;a href=&#34;https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;these docs&lt;/a&gt; about Workload Identity Federation for GKE, as well as&lt;a href=&#34;/grafana/plugins/grafana-bigquery-datasource/&#34;&gt; this page&lt;/a&gt; dedicated to the BigQuery data source plugin for Grafana.&lt;/p&gt;】&lt;p&gt;&lt;em&gt;Umesh Pawar 是 Searce 的高级云工程师，也是 Grafana 和 Friends Delhi Group 的联合组织者。过去两年，Umesh 一直专注于基础设施和应用现代化，以及包括 Grafana LGTM Stack 在内的可观测性解决方案。&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;借助适用于 Grafana 的 &lt;a href=&#34;/grafana/plugins/grafana-bigquery-datasource/&#34;&gt;Google BigQuery 数据源插件&lt;/a&gt;，您可以直接在 Grafana 中轻松查询和可视化来自 BigQuery 的数据。这支持广泛的用例，例如创建用于日志分析、计费数据、销售指标、流量分析和数字营销活动跟踪的仪表板。&lt;/p&gt;&#xA;&lt;p&gt;在 Google Kubernetes Engine (GKE) 上运行 Grafana 并连接到 BigQuery 作为数据源时，必须优先考虑安全性。本博客探讨了 Workload Identity Federation 如何帮助您将 GKE 上运行的 Grafana 实例安全地连接到 Google BigQuery 服务，而无需暴露服务帐户密钥。&lt;/p&gt;&#xA;&lt;h2 id=&#34;authentication-with-gcp-using-workload-identity-federation&#34;&gt;使用工作负载联合身份验证通过 GCP 进行身份验证&lt;/h2&gt;&#xA;&lt;p&gt;您可以使用 &lt;a href=&#34;https://cloud.google.com/iam/docs/workload-identity-federation&#34; target=&#34;_blank&#34; rel 从 GKE 集群中运行的工作负载安全地访问 Google Cloud API =&#34;noopener noreferrer&#34;&gt;GKE 的工作负载身份联合&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;如果您在 &lt;a href=&#34;https://cloud.google.com/kubernetes-engine/docs/concepts/autopilot-overview&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt; 中的 GKE 上运行 Grafana Autopilot 模式，Workload Identity Federation 默认启用。当您以&lt;a href=&#34;https://cloud.google.com/kubernetes-engine/docs/concepts/choose-cluster-mode&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;标准&lt;/a运行时&gt; 模式下，您可以使用 Google Cloud CLI 或 Google Cloud 控制台在集群和节点池上启用工作负载联合身份验证。必须先在集群级别启用 GKE 的工作负载身份联合，然后才能在节点池上为 GKE 启用它。&lt;/p&gt;&#xA;&lt;p&gt;要在新集群上启用：&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;按钮 x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;将代码复制到剪贴板&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;复制&lt;/span&gt;&#xA;&lt;/按钮&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;gcloud 容器集群创建 CLUSTER_NAME \&#xA;--位置=位置\&#xA;--workload-pool=PROJECT_ID.svc.id.goog&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;p&gt;要在现有集群上启用：&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;按钮 x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;将代码复制到剪贴板”宽度=“14”高度=“13”&gt;&#xA;&lt;span&gt;复制&lt;/span&gt;&#xA;&lt;/按钮&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;gcloud 容器集群更新 CLUSTER_NAME \&#xA;--位置=位置\&#xA;--workload-pool=PROJECT_ID.svc.id.goog&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;h2 id=&#34;configure-grafana-to-use-workload-identity-federation-for-gke&#34;&gt;配置 Grafana 以使用适用于 GKE 的工作负载联合身份验证&lt;/h2&gt;&#xA;&lt;p&gt;要让您的 GKE 应用程序（在我们的示例中为 Grafana）使用 Workload Identity Federation for GKE 向 Google Cloud API 进行身份验证，您需要为特定 API 创建 IAM 政策。&lt;/p&gt;&#xA;&lt;p&gt;如果您使用的是 Helm 图表，只需将此代码编辑为values.yaml。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1452px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/bigquery-grafana/bigquery-grafana-service-account-code.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/blog/bigquery-grafana/bigquery-grafana-service-account-code.png&#34;data-srcset=&#34;/media/blog/bigquery-grafana/bigquery-grafana-service-account-code. png?w=320 320w，/media/blog/bigquery-grafana/bigquery-grafana-service-account-code.png?w=550 550w， /media/blog/bigquery-grafana/bigquery-grafana-service-account-code.png?w=750 750w，/media/blog/bigquery-grafana/bigquery-grafana-service-account-code.png?w=900 900w，/media/blog/bigquery-grafana/bigquery-grafana-service-account-code.png?w=1040 1040w、/media/blog/bigquery-grafana/bigquery-grafana-service-account-code.png?w=1240 1240w、/media/blog/bigquery-grafana/bigquery-grafana-service-account-code.png?w =1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;IAM 策略代码的屏幕截图。&#34;width=&#34;1452&#34;height=&#34;548&#34;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src=&#34;/media/blog/bigquery-grafana/bigquery-grafana-service-account-code.png&#34;&#xA;alt=&#34;IAM 策略代码的屏幕截图。&#34;width=&#34;1452&#34;height=&#34;548&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;p&gt;如果您要部署为 &lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/deployment/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Kubernetes 部署&lt;/a &gt;，创建一个 &lt;a href=&#34;https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Kubernetes 服务帐户&lt;/a&gt;供 Grafana 使用。您还可以使用任何命名空间中的任何现有 Kubernetes 服务帐户。如果您没有为工作负载分配服务帐户，Kubernetes 会在命名空间中分配默认服务帐户。&lt;/p&gt;&#xA;&lt;p&gt;向您的 IAM 服务帐号授予其在特定 Google Cloud API 上所需的角色。在我们的例子中，Grafana 想要查询 BigQuery API，因此我们将为它提供 &lt;a href=&#34;https://cloud.google.com/bigquery/docs/access-control#bigquery.admin&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;BigQuery 管理员角色&lt;/a&gt;（但是，一般来说，始终遵循最小权限原则伊莱格）。&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;按钮 x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;将代码复制到剪贴板&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;复制&lt;/span&gt;&#xA;&lt;/按钮&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;gcloud 项目 add-iam-policy-binding IAM_SA_PROJECT_ID \&#xA;--member &#34;serviceAccount:IAM_SA_NAME@IAM_SA_PROJECT_ID.iam.gserviceaccount.com&#34; \&#xA;--角色“ROLE_NAME”&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;p&gt;创建一个 &lt;a href=&#34;https://cloud.google.com/iam/docs/policies&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;IAM 允许政策&lt;/a&gt;授予 Kubernetes 服务帐户访问权限来模拟 IAM 服务帐户。最佳做法是向您的应用程序需要访问的特定 Google Cloud 资源授予权限。您必须拥有相关的 IAM 权限才能在项目中创建允许策略。&lt;/p&gt;&#xA;&lt;p&gt;在下面的代码块中，&lt;code&gt;KSA_NAME&lt;/code&gt; 表示附加到 Grafana 工作负载的 Kubernetes 服务帐户名称，&lt;code&gt;NAMESPACE&lt;/code&gt; 表示部署 Grafana 的命名空间。&lt;/p &gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;按钮 x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;将代码复制到剪贴板&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;复制&lt;/span&gt;&#xA;&lt;/按钮&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;gcloud iam service-accounts add-iam-policy-binding IAM_SA_NAME@IAM_SA_PROJECT_ID.iam.gserviceaccount.com \&#xA;--角色角色/iam.workloadIdentityUser \&#xA;--member &#34;serviceAccount:PROJECT_ID.svc.id.goog[NAMESPACE/KSA_NAME]&#34;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;p&gt;现在我们需要注释 Kubernetes 服务帐户，以便 GKE 看到服务帐户之间的链接。 &lt;em&gt;注意：如果您通过 Helm 进行部署，请跳过此步骤，而是在 Helm 图表上进行注释，如上述步骤所示。&lt;/em&gt;&lt;/p&gt;&#xA;&lt;div class=&#34;code-snippet code-snippet__mini&#34;&gt;&lt;div class=&#34;lang-toolbar__mini&#34;&gt;&#xA;&lt;span class=&#34;code-clipboard&#34;&gt;&#xA;&lt;按钮 x-data=&#34;app_code_snippet()&#34; x-init=&#34;init()&#34; @click=&#34;copy()&#34;&gt;&#xA;&lt;img class=&#34;code-clipboard__icon&#34; src=&#34;/media/images/icons/icon-copy-small-2.svg&#34; alt=&#34;将代码复制到剪贴板&#34; width=&#34;14&#34; height=&#34;13&#34;&gt;&#xA;&lt;span&gt;复制&lt;/span&gt;&#xA;&lt;/按钮&gt;&#xA;&lt;/span&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;code-snippet code-snippet__border&#34;&gt;&#xA;&lt;pre data-expanded=&#34;false&#34;&gt;&lt;code class=&#34;language-none&#34;&gt;kubectl 注释 serviceaccount KSA_NAME \&#xA;--命名空间 命名空间 \&#xA;iam.gke.io/gcp-service-account=IAM_SA_NAME@IAM_SA_PROJECT_ID.iam.gserviceaccount.com&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;h2 id=&#34;configure-the-google-bigquery-data-source-for-grafana&#34;&gt;为 G 配置 Google BigQuery 数据源拉法纳&lt;/h2&gt;&#xA;&lt;p&gt;如上所述，&lt;a href=&#34;/grafana/plugins/grafana-bigquery-datasource/&#34;&gt;Google BigQuery 数据源插件&lt;/a&gt;可让您在 Grafana 中查询和可视化 Google BigQuery 数据。&lt;/ p&gt;&#xA;&lt;h3 id=&#34;install-the-plugin&#34;&gt;安装插件&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;导航至 BigQuery 插件主页。&lt;/li&gt;&#xA;&lt;li&gt;点击右侧的&lt;strong&gt;安装&lt;/strong&gt;按钮。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1600px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/bigquery-grafana/bigquery-grafana-install-plugin-page.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/blog/bigquery-grafana/bigquery-grafana-install-plugin-page.png&#34;data-srcset=&#34;/media/blog/bigquery-grafana/bigquery-grafana-install-plugin-page. png?w=320 320w，/media/blog/bigquery-grafana/bigquery-grafana-install-plugin-page.png?w=550 550w， /media/blog/bigquery-grafana/bigquery-grafana-install-plugin-page.png?w=750 750w，/media/blog/bigquery-grafana/bigquery-grafana-install-plugin-page.png?w=900 900w，/media/blog/bigquery-grafana/bigquery-grafana-install-plugin-page.png?w=1040 1040w、/media/blog/bigquery-grafana/bigquery-grafana-install-plugin-page.png?w=1240 1240w、/media/blog/bigquery-grafana/bigquery-grafana-install-plugin-page.png?w =1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;Grafana 中 BigQuery 数据源的安装页面的屏幕截图。&#34;width=&#34;1600&#34;height=&#34;902&#34;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src=&#34;/media/blog/bigquery-grafana/bigquery-grafana-install-plugin-page.png&#34;&#xA;alt=&#34;Grafana 中 BigQuery 数据源的安装页面的屏幕截图。&#34;width=&#34;1600&#34;height=&#34;902&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;h3 id=&#34;verify-that-the-plugin-is-installed&#34;&gt;验证插件是否已安装&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;在 Grafana 中，导航至&lt;strong&gt;配置 &gt; 数据源&lt;/strong&gt;。&lt;/li&gt;&#xA;&lt;li&gt;点击右上角的&lt;strong&gt;添加数据源&lt;/strong&gt;按钮。&lt;/li&gt;&#xA;&lt;li&gt;在搜索字段中搜索 Google BigQuery，并将鼠标悬停在 Google BigQuery 搜索结果上。&lt;/li&gt;&#xA;&lt;li&gt;点击 Google BigQuery 的&lt;strong&gt;选择&lt;/strong&gt;按钮。如果您可以单击&lt;strong&gt;选择&lt;/strong&gt;按钮，则表示已安装。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1600px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/bigquery-grafana/bigquery-grafana-verify-the-data-source-works.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/blog/bigquery-grafana/bigquery-grafana-verify-the-data-source-works.png&#34;data-srcset=&#34;/media/blog/bigquery-grafana/bigquery-grafana-verify- the-data-source-works.png?w=320 320w, /media/blog/bigquery-grafana/bigquery-grafana-verify-the-data-source-works.png?w=550 550w，/media/blog/bigquery-grafana/bigquery-grafana-verify-the-data-source-works.png?w=750 750w，/media/blog/bigquery-grafana/bigquery-grafana-verify-the-data-source-works.png?w =900 900w， /media/blog/bigquery-grafana/bigquery-grafana-verify-the-data-source-works.png?w=1040 1040w，/media/blog/bigquery-grafana/bigquery-grafana-verify-the-data-source -works.png?w=1240 1240w, /media/blog/bigquery-grafana/bigquery-grafana-verify-the-data-source-works.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;Grafana 中 BigQuery 数据源的“设置”选项卡的屏幕截图。&#34;width=&#34;1600&#34;height=&#34;853&#34;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src=&#34;/media/blog/bigquery-grafana/bigquery-grafana-verify-the-data-source-works.png&#34;&#xA;alt=&#34;Grafana 中 BigQuery 数据源的“设置”选项卡的屏幕截图。&#34;width=&#34;1600&#34;height=&#34;853&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;h3 id=&#34;authentication&#34;&gt;身份验证&lt;/h3&gt;&#xA;&lt;p&gt;通过使用 Workload Identity Federation 自动检索凭据（在 GKE 上运行 Grafana 时），请确保服务帐户已被授予对 BigQuery API 的读取权限。&lt;/p&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1600px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/bigquery-grafana/bigquery-grafana-plugin-authentication.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/blog/bigquery-grafana/bigquery-grafana-plugin-authentication.png&#34;data-srcset=&#34;/media/blog/bigquery-grafana/bigquery-grafana-plugin-authentication.png?w= 320 320w，/media/blog/bigquery-grafana/bigquery-grafana-plugin-authentication.png?w=550 550w、/media/blog/bigquery-grafana/bigquery-grafana-plugin-authentication.png?w=750 750w、/media/blog/bigquery-grafana/bigquery-grafana-plugin-authentication.png?w=900 900w、 /media/blog/bigquery-grafana/bigquery-grafana-plugin-authentication.png?w=1040 1040w, /media/blog/bigquery-grafana/bigquery-grafana-plugin-authentication.png?w=1240 1240w, /media/blog/bigquery-grafana/bigquery-grafana-plugin-authentication.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;BigQuery 数据源插件的身份验证页面的屏幕截图。&#34;width=&#34;1600&#34;height=&#34;904&#34;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src=&#34;/media/blog/bigquery-grafana/bigquery-grafana-plugin-authentication.png&#34;&#xA;alt=&#34;BigQuery 数据源插件的身份验证页面的屏幕截图。&#34;width=&#34;1600&#34;height=&#34;904&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;h3 id=&#34;query-the-data-source&#34;&gt;查询数据源&lt;/h3&gt;&#xA;&lt;p&gt;查询编辑器允许您查询 Google BigQuery 数据源。查询可以包含&lt;a href=&#34;/docs/plugins/yesoreyeram-infinity-datasource/latest/query/macros/&#34;&gt;宏&lt;/a&gt;，它简化了语法并使您的查询更加动态。 SQL 查询编辑器提供了对标准 SQL 的丰富支持，以及以下自动完成功能：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;BigQuery 标准 SQL 语言语法&lt;/li&gt;&#xA;&lt;li&gt;BigQuery 数据集、表和列&lt;/li&gt;&#xA;&lt;li&gt;宏和模板变量&lt;/li&gt;&#xA;&lt;/u我&gt;&#xA;&lt;图&#xA;类=“图包装图包装__lightbox w-100p”&#xA;样式=“最大宽度：1600px；”&#xA;itemprop =“关联媒体”&#xA;项目范围=“”&#xA;itemtype =“http://schema.org/ImageObject”&#xA;&gt;&lt;一个&#xA;类=“灯箱链接”&#xA;href=&#34;/media/blog/bigquery-grafana/bigquery-grafana-query-the-data-source.png&#34;&#xA;itemprop=“内容网址”&#xA;&gt;&lt;div class=&#34;img-wrapper w-100p h-auto&#34;&gt;&lt;img&#xA;类=“延迟加载”&#xA;data-src=&#34;/media/blog/bigquery-grafana/bigquery-grafana-query-the-data-source.png&#34;data-srcset=&#34;/media/blog/bigquery-grafana/bigquery-grafana-query-the-数据源.png?w=320 320w，/media/blog/bigquery-grafana/bigquery-grafana-query-the-data-source.png?w=550 550w，/media/blog/bigquery-grafana/bigquery-grafana-query-the-data-source.png?w=750 750w，/media/blog/bigquery-grafana/bigquery-grafana-query-the-data-source .png?w=900 900w, /media/blog/bigquery-grafana/bigquery-grafana-query-the-data-source.png?w=1040 1040w，/media/blog/bigquery-grafana/bigquery-grafana-query-the-data-source.png ?w=1240 1240w, /media/blog/bigquery-grafana/bigquery-grafana-query-the-data-source.png?w=1920 1920w&#34;&#xA;data-sizes=&#34;auto&#34;alt=&#34;BigQuery 数据源查询的屏幕截图。&#34;width=&#34;1600&#34;height=&#34;908&#34;/&gt;&#xA;&lt;无脚本&gt;&#xA;&lt;图片&#xA;src =“/media/blog/bigquery-grafana/bigquery-grafana-query-the-data-source.png”&#xA;alt=&#34;BigQuery 数据源查询的屏幕截图。&#34;width=&#34;1600&#34;height=&#34;908&#34;/&gt;&#xA;&lt;/noscript&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&#xA;&lt;h2 id=&#34;how-to-learn-more&#34;&gt;如何了解更多信息&lt;/h2&gt;&#xA;&lt;p&gt;要了解有关此主题的更多信息，您可以查看&lt;a href=&#34;https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity&#34; target=&#34;_blank&#34; rel= &#34;noopener noreferrer&#34;&gt;这些文档&lt;/a&gt;有关 GKE 的工作负载身份联合，以及&lt;a href=&#34;/grafana/plugins/grafana-bigquery-datasource/&#34;&gt;此页面&lt;/a&gt;专门介绍 BigQuery 数据来源Grafana 插件。&lt;/p&gt;</description>
      <pubDate>Tue, 17 Dec 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>【OpenTelemetry: past, present, and future】OpenTelemetry：过去、现在和未来</title>
      <link>https://grafana.com/blog/2024/12/20/opentelemetry-past-present-and-future/</link>
      <description>【&lt;p&gt;Here&amp;rsquo;s something most people probably didn&amp;rsquo;t have on their 2024 bingo cards: the terms &amp;ldquo;gossip&amp;rdquo; and &amp;ldquo;scandalous details&amp;rdquo; popping up on an episode of “Grafana’s Big Tent.&amp;quot; But if you did, congratulations!&lt;/p&gt;&#xA;&lt;p&gt;It happened during a conversation about &lt;a href=&#34;/oss/opentelemetry/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;OpenTelemetry&lt;/a&gt;, in which co-hosts Mat Ryer, Grafana Labs Engineering Director, and Matt Toback, Grafana Labs VP of Culture, playfully tried to get some scoop about the inner-workings of the OpenTelemetry Governance Committee from two of its members, podcast guests Juraci Paixão Kröhling, Grafana Principal Engineer, and Daniel Gomez Blanco, Principal Engineer at Skyscanner. (Truth be told, the most scandalous detail to come out of the episode might be that Matt still owns a zip drive cable . . .)&lt;/p&gt;&#xA;&lt;p&gt;You can read some of the show’s highlights below, but listen to the full episode to hear more about instrumentation and distributed tracing, as well as OTel history — including its early names — TBT (trace-based testing), ODD (observability-driven development), and Mat&amp;rsquo;s Broadway moment.&lt;/p&gt;&#xA;&lt;iframe width=&#34;100%&#34; height=&#34;180&#34; frameborder=&#34;no&#34; scrolling=&#34;no&#34; seamless=&#34;&#34; src=&#34;https://share.transistor.fm/e/e8c53636&#34;&gt;&lt;/iframe&gt;&#xA;&lt;p&gt;&lt;em&gt;Note: The following are highlights from episode 9, season 2 of “Grafana’s Big Tent” podcast. The transcript below has been edited for length and clarity.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;the-basics-of-opentelemetry&#34;&gt;The basics of OpenTelemetry&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Mat Ryer:&lt;/strong&gt; For anyone not familiar with OTel, what is it?&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Daniel Gomez Blanco:&lt;/strong&gt; OpenTelemetry is a framework that allows you to instrument, to collect, to process, and then to transport telemetry data. It&amp;rsquo;s focused on cloud native systems, and one of the major goals is that you can produce all that telemetry from any application, any library, any language, in a standard format and using a standard set of naming conventions as well, and then push that to any backend. It&amp;rsquo;s vendor-neutral, so you can do whatever you want with your telemetry. You&amp;rsquo;re not forced to use a particular solution or backend.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Mat:&lt;/strong&gt; Before that, we had all different systems, and they have different traditions, different names, different techniques. So this is a goal to unify it all and get everyone behind one set of standards.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Daniel:&lt;/strong&gt; Yeah, it&amp;rsquo;s one set of standards as well as something that is really, really important for observability, which is context. We&amp;rsquo;re no longer thinking about your metrics here, and your logs here, and your traces here. You have everything as part of one set of telemetry data that is correlated in order to allow you to get better insights from your applications.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Juraci Paixão Kröhling:&lt;/strong&gt; One of the nice things about OpenTelemetry is that it came to be when existing tools were very successful already, so we tried to make open telemetry play nicely with the things that came before us. Of course, not everything is 100% philosophically compatible, but we tried to make it so that people could use OpenTelemetry even if they don&amp;rsquo;t like every part of it, or even if they were already happy with other parts.&lt;/p&gt;&#xA;&lt;h2 id=&#34;learning-the-rules&#34;&gt;Learning the rules&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Mat:&lt;/strong&gt; You mentioned logs, metrics, and traces. As an everyday developer, how do you know which of these telemetry types we should use? Is there a set of rules, or is this intuition and experience that you have to learn over time?&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Daniel:&lt;/strong&gt; It depends so much on the system. The first question to ask is if you should be adding that telemetry yourself, or if you should be relying on telemetry that is emitted by instrumentation libraries or the libraries themselves? One of the things that OpenTelemetry enables is instrumentation authors to write that telemetry for you, as well library authors. So let&amp;rsquo;s say that you pick an open source library that comes already instrumented with the metrics that you need, or with the spans and the tracing instrumentation that you need — you don&amp;rsquo;t need to add that yourself.&lt;/p&gt;&#xA;&lt;p&gt;When we&amp;rsquo;re talking about instrumenting our own data, our own applications, I think it&amp;rsquo;s important to choose the telemetry that is right for your use case. So if you&amp;rsquo;re looking to drive, for example, alerts or dashboards or something that you&amp;rsquo;re looking at long-term, you&amp;rsquo;re probably looking at time series data so that you need your metrics. If you&amp;rsquo;re looking at really high granularity insights, and you&amp;rsquo;re interested in how it all fits together in a complex, distributed system, and you&amp;rsquo;re interested in context, then you want traces. And then if you want to integrate with some of the legacy systems that, perhaps, didn&amp;rsquo;t produce any spans or any metrics, then you want to rely on logs.&lt;/p&gt;&#xA;&lt;p&gt;But the important thing is that you get all those parts of the context, the same set of correlated data. And that&amp;rsquo;s something OTel helps with — to bridge that gap.&lt;/p&gt;&#xA;&lt;p&gt;Another way of thinking about it is going into multiple different levels of granularity. You may start from metrics, and then you want to correlate that to your traces, and then maybe keep going down in your level of abstraction and then going down into profiles.&lt;/p&gt;&#xA;&lt;p&gt;The story that we&amp;rsquo;re trying to tell is that you need all that data and you need it to be correlated.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Juraci:&lt;/strong&gt; The mental model I have is a little bit different. When I&amp;rsquo;m developing an application, I try to put myself in the future — like at 2 a.m. during an outage, looking at my code and thinking, What do I need to know to understand what&amp;rsquo;s going on? It&amp;rsquo;s very likely that I don&amp;rsquo;t need the individual log entries. When I need aggregate information, then I need metrics and I can think, What are the metrics that I need? Do I need a gauge for the size of the queue that I&amp;rsquo;m handling right now? Do I need a latency for the outgoing HTTP requests? Things like that.&lt;/p&gt;&#xA;&lt;p&gt;The second mode is, What do I need to understand the context of the transaction specifically? When I&amp;rsquo;m thinking about the transaction as a whole — microservices — then I know I need a span. I know I need distributed tracing. And when I&amp;rsquo;m thinking about the neighboring services, the one thing that I know that I need is one span representing my incoming HTTP request or my incoming RPC, and one span representing my outgoing RPC. So that&amp;rsquo;s all that I really need when it comes to distributed tracing, because then I see the whole chain in a trace. I feel like logs are mostly for the life cycle events of my application.&lt;/p&gt;&#xA;&lt;h2 id=&#34;making-a-game-out-of-learning&#34;&gt;Making a game out of learning&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Matt:&lt;/strong&gt; A lot of times, when we talk about how to instrument your application, there&amp;rsquo;s this feeling that you&amp;rsquo;re choosing instrumentation for your future self to troubleshoot. How often do you see differences in team approaches on the same application?&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Daniel:&lt;/strong&gt; It depends on what teams are used to. One of the things that I&amp;rsquo;ve been doing recently with some of the teams of Skyscanner is going through the OTel demo and doing a bit of a game. We put them in front of the demo, we inject some failures into that system, and then ask them to go and debug it. We try to have different teams compete against each other and see who gets to the root cause first.&lt;/p&gt;&#xA;&lt;p&gt;You get to the root cause a lot faster if you use context than if you start from, perhaps, an alert that we set up that&amp;rsquo;s driven from metrics. Just by looking at the metrics, you won&amp;rsquo;t be able to answer the questions &amp;ldquo;What is the root cause here? What made it fail?&amp;rdquo;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Matt:&lt;/strong&gt; Have you seen eureka moments when someone discovers that they&amp;rsquo;re able to see more than they were before?&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Daniel:&lt;/strong&gt; There was an engineer who was adamant that they were able to debug this through logs alone, because that&amp;rsquo;s what they were used to. And they didn&amp;rsquo;t win. People in another room were using tracing and were a lot further advanced in finding the root cause, so that was fun.&lt;/p&gt;&#xA;&lt;h2 id=&#34;why-some-people-still-dont-understand-observability&#34;&gt;Why some people still don&amp;rsquo;t understand observability&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Juraci:&lt;/strong&gt; I also think about telemetry when writing code, but I think there is some barrier to entry there. Out of curiosity, I was looking at the curriculum for some computer science classes in Brazil — but I think this applies elsewhere — and we teach people how to write operating systems, but we don&amp;rsquo;t tell people how to monitor them. We don&amp;rsquo;t teach them how to do observability, like how to understand what&amp;rsquo;s going on, and this is a real gap.&lt;/p&gt;&#xA;&lt;p&gt;People have a hard time understanding distributed tracing. It &lt;em&gt;is&lt;/em&gt; a hard topic. It is difficult to imagine that parts of that data are going directly to a collector somewhere, and parts of the data are being propagated down as part of the RPC. So which one is which? What is where? How does that actually work? Why do I need a trace context there with two types of IDs and flags? Those are things that we just assume that people know, and if they don&amp;rsquo;t, we provide the tools to them. But then they use them without knowing what&amp;rsquo;s in there, and it makes it very hard to debug when things go wrong with the telemetry systems they have.&lt;/p&gt;&#xA;&lt;p&gt;On one hand, I see that the tooling to develop instrumentation is necessary. On the other hand, I think we end up having a huge cost problem, which is already a reality in observability by having tools that are generating a lot of telemetry data that we don&amp;rsquo;t actually need. When we look at most traces that we&amp;rsquo;ve collected, we don&amp;rsquo;t use most of them. A few years ago, someone mentioned close to 90% of traces are created, transmitted, and stored, and never seen — all of that work for pretty much nothing.&lt;/p&gt;&#xA;&lt;p&gt;If we were to have only manual instrumentation, then we would have only high valuable data being stored, and way less data than what we have right now. But because it is so difficult to understand and to manually instrument, we end up using those very powerful tools that generate a lot of telemetry that we might not need in the hopes that they become useful sometime in the future.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Matt:&lt;/strong&gt; How often will you prune it?&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Juraci:&lt;/strong&gt; We never do. I think it&amp;rsquo;s in our nature to not delete something because of fear that that thing might be useful in the future. I think this is where academia is way more advanced than we are. There is some research going in this area of turning on and off instrumentation points based on the current state of the systems. I think the future is not that we are &lt;em&gt;not&lt;/em&gt; going to instrument things as much as what we are doing today, but I think the future is whether we collect and store and transmit that data in the first place.&lt;/p&gt;&#xA;&lt;h2 id=&#34;the-need-for-a-cultural-shift&#34;&gt;The need for a cultural shift&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Mat:&lt;/strong&gt; What is the biggest challenge to adoption, that people just don&amp;rsquo;t really know it, or are there other resistances?&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Daniel:&lt;/strong&gt; One of the challenges is that people don&amp;rsquo;t know it. You need to change years of culture and people within a distributed system operating them as if it were monoliths — like isolated entities — without thinking of your overall system. And I think that&amp;rsquo;s something that needs to change from an engineering perspective, or, like, how do we operate systems.&lt;/p&gt;&#xA;&lt;p&gt;There is, as well, another challenge for adoption, which tends to be cost-related, because we generate a lot of telemetry data from distributed systems. Before you perhaps had one big replica that was massive, now you&amp;rsquo;ve got little components that all produce telemetry. I think it&amp;rsquo;s important as well to understand that distributed tracing and that context allows you to make better decisions in what to keep and what not to keep.&lt;/p&gt;&#xA;&lt;p&gt;Cost is a challenge, but is not an insurmountable challenge.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Juraci:&lt;/strong&gt; I think there&amp;rsquo;s also the situation where people only see the value when they have experience. It takes a while for people to realize that they need observability, and they might not even realize it even after years of experience.&lt;/p&gt;&#xA;&lt;h2 id=&#34;weighing-the-trade-offs-of-using-otel&#34;&gt;Weighing the trade-offs of using OTel&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Mat:&lt;/strong&gt; Are there downsides to using OTel, or trade-offs that we have to be aware of?&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Daniel:&lt;/strong&gt; It depends where you are in your observability journey as an organization. So if you&amp;rsquo;ve got really stable processes, and there may be something in OTel that is not quite stable yet, there are parts that are very stable that you could adopt and try to simplify and consolidate on that. There are other parts that are less stable, for example, things related to profiles. So I think if you&amp;rsquo;ve got something that is currently working, it&amp;rsquo;s probably one of the things where you wait until things get a bit more stable.&lt;/p&gt;&#xA;&lt;p&gt;If you&amp;rsquo;re completely greenfield and you&amp;rsquo;re starting from scratch, your balance will probably tip towards innovation.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Juraci:&lt;/strong&gt; I think it&amp;rsquo;s all relative as well. The collector has not reached a v1 yet, so in theory, it is not stable. But it doesn&amp;rsquo;t stop people like Vijay [Samuel] from eBay from implementing a highly scalable collector pipeline there and giving talks at KubeCon.&lt;/p&gt;&#xA;&lt;p&gt;We think it&amp;rsquo;s fine for some things, but not so fine for other things.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Daniel:&lt;/strong&gt; It does require a little bit of due diligence from a platform engineering team. At Skyscanner, for example, we run collectors at scale as well, handling more than a million spans per second, and handling hundreds of thousands of data points per second. The collector is not v1, but the components that we rely on — OTLP, receive, and export — and the processors that we use are stable.&lt;/p&gt;&#xA;&lt;h2 id=&#34;governance-committee-scoop&#34;&gt;Governance Committee scoop&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Mat:&lt;/strong&gt; Tell us a little more about what you do on the Governance Committee, in particular if you&amp;rsquo;re working on anything interesting right now. Or I&amp;rsquo;d love to know any gossip about big places you disagreed, or something from behind-the-scenes.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Daniel:&lt;/strong&gt; I don&amp;rsquo;t think we disagree much. We&amp;rsquo;re all quite aligned.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Juraci:&lt;/strong&gt; All our calls are recorded, so the meeting notes are public and the recordings &lt;a href=&#34;https://github.com/open-telemetry/community?tab=readme-ov-file#governing-bodies&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;are available&lt;/a&gt; — it is an open source project after all. We do have private sessions for things that are really related to code of conduct or complaints from people from the community. It is a big community, so disagreement is bound to happen. Our group is there to balance that, and to make sure that we are moving forward as a community and that we are not ignoring problems that may cause even bigger problems in the future.&lt;/p&gt;&#xA;&lt;p&gt;But I think our biggest challenge is even though OpenTelemetry is full of people from vendors — most people there work for vendors — even though we have that commercial interest behind the project, we’re all, at the end of the day, volunteers. Most of us end up doing things during our working hours. We are being paid for that, but this is not something that we put on our OKRs.&lt;/p&gt;&#xA;&lt;p&gt;The difficult part as part of the GC, of the governance committee, is to agree on a roadmap, and convince other people that they have to pay attention to what we are saying, as “This is what we believe to be important. Not only listening to us, but also following the path that we are trying to go into.”&lt;/p&gt;&#xA;&lt;p&gt;We are software engineers, so we find new toys every single day, and we want to play with those toys. At this point, my candid opinion is that we have too many toys and we have to do some spring cleaning and see what is worth keeping and what is not, and what we should declare as something that is a good idea, but for the future.&lt;/p&gt;&#xA;&lt;h2 id=&#34;whats-coming-up-for-otel&#34;&gt;What&amp;rsquo;s coming up for OTel&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Mat:&lt;/strong&gt; Speaking of new toys, what is new? What&amp;rsquo;s the exciting thing that&amp;rsquo;s next for OTel?&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Daniel:&lt;/strong&gt; One of the things that&amp;rsquo;s got everyone excited is profiling as a new signal, and how you can get profiles correlated with your traces. That is just going to open such a new avenue to explore within your debugging practices.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Juraci:&lt;/strong&gt; I&amp;rsquo;m looking forward to so many things. I think one of them is the &lt;a href=&#34;https://github.com/open-telemetry/community?tab=readme-ov-file#specification-sigs&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Entity SIG&lt;/a&gt;. I like to think that is our first big refactoring in OpenTelemetry, and that is refactoring the idea of resource attributes. Resources is the context that Dan mentioned before. It ties all of the signals together.&lt;/p&gt;&#xA;&lt;p&gt;It turns out that not everything that we thought would be good values for resource attributes are actually good. They might be problematic for things that don&amp;rsquo;t deal very well with high cardinality, like &lt;a href=&#34;/oss/prometheus/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Prometheus&lt;/a&gt;, so we probably do not want to store the process ID as part of resource attributes. It&amp;rsquo;s nice metadata to have about the process, but we don&amp;rsquo;t actually need it there.&lt;/p&gt;&#xA;&lt;p&gt;The Entities SIG would break down the resource context into what is the identity resources and identity SIG — so what is the identity of my resource and what is the metadata for my resource, so that this linking context between the signals would be very thin, and I could use those in Prometheus and &lt;a href=&#34;/oss/loki/?pg=blog&amp;amp;plcmt=body-txt&#34;&gt;Loki&lt;/a&gt; or in different data stores, and the metadata could be stored elsewhere. It doesn&amp;rsquo;t have to be indexed. It doesn&amp;rsquo;t have to be part of the identity of the object.&lt;/p&gt;&#xA;&lt;p&gt;It&amp;rsquo;s not as exciting as profiling, perhaps, but I think it is very necessary, and it&amp;rsquo;s a sign of maturity that we are doing a refactoring.&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;“Grafana’s Big Tent” podcast wants to hear from you. If you have a great story to share, want to join the conversation, or have any feedback, please contact the Big Tent team at &lt;a href=&#34;/blog/2024/08/23/grafanas-big-tent-podcast-season-2-is-here/bigtent@grafana.com&#34;&gt;bigtent@grafana.com&lt;/a&gt;. You can also catch up on the first and second season of “Grafana’s Big Tent” on &lt;a href=&#34;https://podcasts.apple.com/us/podcast/grafanas-big-tent/id1616725129&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Apple Podcasts&lt;/a&gt; and &lt;a href=&#34;https://open.spotify.com/show/3beQvS8to0rYs1gxOnPrfD?si=bf046f54fe214615&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Spotify&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;】&lt;p&gt;大多数人的 2024 年宾果卡上可能没有这样的内容：在“Grafana 的大帐篷”的一集中突然出现“八卦”和“丑闻细节”等术语。但如果您这样做了，那么恭喜您！&lt;/p &gt;&#xA;&lt;p&gt;这件事发生在一次关于 &lt;a href=&#34;/oss/opentelemetry/?pg=blog&amp;plcmt=body-txt&#34;&gt;OpenTelemetry&lt;/a&gt; 的对话中，对话的共同主持人包括 Grafana Labs 工程总监 Mat Ryer 和 Matt Grafana Labs 文化副总裁 Toback 开玩笑地试图从两位成员、播客嘉宾 Juraci 那里了解 OpenTelemetry 治理委员会的内部运作情况Grafana 首席工程师 Paixão Kröhling 和 Skyscanner 首席工程师 Daniel Gomez Blanco。 （说实话，这一集中最令人震惊的细节可能是马特仍然拥有一根拉链驱动器电缆......）&lt;/p&gt;&#xA;&lt;p&gt;您可以阅读下面的一些节目亮点，但也可以收听完整剧集，了解有关仪器和分布式跟踪的更多信息，以及 OTel 的历史 - 包括其早期名称 - TBT（基于跟踪的测试）、ODD（可观测性） -驱动的发展），以及马特的百老汇时刻。&lt;/p&gt;&#xA;&lt;iframe width =“100％”height =“180”frameborder =“否”滚动=“否”无缝=“”src =“https://share.transistor.fm/e/e8c53636”&gt; &lt;/ iframe&gt;&#xA;&lt;p&gt;&lt;em&gt;注意：以下是“Grafana’s Big Tent”播客第二季第 9 集的精彩片段。为了长度和清晰度，下面的文字记录已经过编辑。&lt;/em&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;the-basics-of-opentelemetry&#34;&gt;OpenTelemetry 基础知识&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Mat Ryer：&lt;/strong&gt;对于不熟悉 OTel 的人来说，这是什么？&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Daniel Gomez Blanco&lt;/strong&gt;：OpenTelemetry 是一个框架，可让您检测、收集、处理并传输遥测数据。它专注于云原生系统，主要目标之一是您可以以标准格式并使用一组标准命名约定从任何应用程序、任何库、任何语言生成所有遥测数据，然后将其推送到任何后端。它与供应商无关，因此您可以通过遥测进行任何您想做的事情。您不必被迫使用特定的解决方案或后端。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Mat：&lt;/strong&gt;在此之前，我们有不同的系统，它们有不同的传统、不同的名称、不同的技术。因此，我们的目标是统一所有内容并让每个人都遵循一套标准。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;丹尼尔：&lt;/strong&gt;是的，这是一套标准，也是对可观察性非常非常重要的东西，即上下文。我们不再考虑您的指标、日志和痕迹。您将所有内容作为一组相互关联的遥测数据的一部分，以便您从应用程序中获得更好的见解。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Juraci Paixão Kröhling：&lt;/strong&gt;OpenTelemetry 的优点之一是它是在现有工具非常成功的情况下出现的已经足够了，所以我们试图让开放遥测与我们之前的事情很好地配合。当然，并不是所有东西在哲学上都是 100% 兼容的，但我们试图让人们可以使用 OpenTelemetry，即使他们不喜欢它的每个部分，或者即使他们已经对其他部分感到满意​​。&lt;/p&gt;&#xA;&lt;h2 id=&#34;learning-the-rules&#34;&gt;学习规则&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Mat：&lt;/strong&gt;您提到了日志、指标和跟踪。作为一名日常开发人员，您如何知道我们应该使用哪些遥测类型？是否有一套规则，或者这种直觉和经验是你必须随着时间的推移而学习的？&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;丹尼尔：&lt;/strong&gt;这很大程度上取决于系统。要问的第一个问题是您是否应该自己添加遥测数据，或者是否应该依赖仪器库或库本身发出的遥测数据？ OpenTelemetry 的功能之一是仪器作者以及库作者为您编写遥测数据。因此，假设您选择了一个开源库，该库已经配备了您需要的指标，或者您需要的跨度和跟踪工具 - 您不需要自己添加。&lt;/p&gt;&#xA;&lt;p&gt;当我们谈论检测我们自己的数据、我们自己的应用程序时，我认为选择适合您的用例的遥测技术非常重要。因此，如果您希望驱动警报或仪表板或您长期关注的内容，您可能会查看时间序列数据，以便需要指标。如果您正在寻找真正高粒度的见解，并且您对它们如何在复杂的分布式系统中组合在一起感兴趣，并且您对上下文感兴趣，那么您需要跟踪。然后，如果您想与一些可能不会产生任何跨度或任何指标的遗留系统集成，那么您需要依赖日志。&lt;/p&gt;&#xA;&lt;p&gt;但重要的是您可以获得上下文的所有这些部分，即同一组相关数据。这正是 OTel 所提供的帮助——弥合这一差距。&lt;/p&gt;&#xA;&lt;p&gt;另一种思考方式是进入多个不同的粒度级别。您可能从指标开始，然后想要将其与您的跟踪相关联，然后可能继续降低抽象级别，然后深入到配置文件。&lt;/p&gt;&#xA;&lt;p&gt;我们想要讲述的故事是，您需要所有这些数据，并且需要将它们关联起来。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Juraci：&lt;/strong&gt;我的心理模型有点不同。当我开发应用程序时，我会尝试将自己置于未来——比如凌晨 2 点停电期间，查看我的代码并思考，我需要知道什么才能了解​​正在发生的情况？我很可能不需要单独的日志条目。当我需要汇总信息时，我需要指标，我可以想，W我需要哪些指标？我需要测量我现在正在处理的队列的大小吗？传出 HTTP 请求是否需要延迟？诸如此类的事情。&lt;/p&gt;&#xA;&lt;p&gt;第二种模式是，我具体需要了解交易的上下文是什么？当我将事务视为一个整体（微服务）时，我知道我需要一个跨度。我知道我需要分布式跟踪。当我考虑相邻服务时，我知道我需要的一件事是一个代表我的传入 HTTP 请求或我的传入 RPC 的跨度，以及一个代表我的传出 RPC 的跨度。这就是我在分布式跟踪方面真正需要的一切，因为这样我就可以在跟踪中看到整个链。我觉得日志主要是我的应用程序的生命周期事件。&lt;/p&gt;&#xA;&lt;h2 id=&#34;making-a-game-out-of-learning&#34;&gt;通过学习制作游戏&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Matt：&lt;/strong&gt;很多时候，当我们谈论如何检测您的应用程序时，您会感觉您正在为未来的自己选择检测来进行故障排除。您多久会发现同一应用程序上的团队方法存在差异？&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;丹尼尔：&lt;/strong&gt;这取决于团队的习惯。我最近与 Skyscanner 的一些团队一起做的事情之一是浏览 OTel 演示并制作一些游戏。我们把他们放在演示前面，我们向该系统注入一些故障，然后要求他们去调试它。我们尝试让不同的团队相互竞争，看看谁先找到根本原因。&lt;/p&gt;&#xA;&lt;p&gt;如果您使用上下文，您可以更快地找到根本原因，而不是从我们设置的由指标驱动的警报开始。仅通过查看指标，您将无法回答“根本原因是什么？是什么导致了它的失败？”&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;马特：&lt;/strong&gt;你是否见过有人发现自己比以前看得更多的恍然大悟的时刻？&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;丹尼尔：&lt;/strong&gt;有一位工程师坚信他们能够仅通过日志进行调试，因为这是他们习惯的。但他们没有赢。另一个房间里的人正在使用跟踪，并且在查找根本原因方面取得了很大的进展，所以这很有趣。&lt;/p&gt;&#xA;&lt;h2 id=&#34;why-some-people-still-dont-understand-observability&#34;&gt;为什么有些人仍然不理解可观察性&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Juraci：&lt;/strong&gt;我在编写代码时也会考虑遥测，但我认为进入那里存在一些障碍。出于好奇，我查看了巴西一些计算机科学课程的课程——但我认为这也适用于其他地方——我们教人们如何编写操作系统，但我们不告诉人们如何监控它们。我们没有教他们如何进行可观察性，比如如何理解正在发生的事情，这是一个真正的差距。&lt;/p&gt;&#xA;&lt;人们很难理解分布式追踪。这是一个很难的话题。很难想象部分数据会直接发送到某个地方的收集器，并且部分数据会作为 RPC 的一部分向下传播。那么哪一个是哪一个呢？什么是哪里？这实际上是如何运作的？为什么我需要一个具有两种类型的 ID 和标志的跟踪上下文？这些是我们假设人们知道的事情，如果他们不知道，我们会向他们提供工具。但随后他们在不知道里面有什么的情况下使用它们，当他们拥有的遥测系统出现问题时，这使得调试变得非常困难。&lt;/p&gt;&#xA;&lt;p&gt;一方面，我认为开发仪器的工具是必要的。另一方面，我认为我们最终会遇到一个巨大的成本问题，这在可观测性方面已经是一个现实，因为我们拥有生成大量我们实际上并不需要的遥测数据的工具。当我们查看收集到的大多数痕迹时，我们并没有使用其中的大部分。几年前，有人提到近 90% 的痕迹都是被创建、传输和存储的，但从未被看到过——所有这些几乎没有任何作用。&lt;/p&gt;&#xA;&lt;p&gt;如果我们只有手动仪器，那么我们将只存储高价值的数据，并且比我们现在拥有的数据少得多。但由于它很难理解和手动检测，我们最终使用了那些非常强大的工具来生成大量我们可能不需要的遥测数据，希望它们在未来的某个时候变得有用。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;马特：&lt;/strong&gt;你多久修剪一次？&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Juraci：&lt;/strong&gt;我们从来不这样做。我认为不删除某些东西是我们的本性，因为担心该东西将来可能有用。我认为这就是学术界比我们先进得多的地方。在这一领域正在进行一些研究，根据系统的当前状态打开和关闭仪表点。我认为未来并不是我们不再像今天所做的那样对事物进行仪器化，而是我们是否首先收集、存储和传输这些数据。 &lt;/p&gt;&#xA;&lt;h2 id=&#34;the-need-for-a-culture-shift&#34;&gt;文化转变的必要性&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Mat：&lt;/strong&gt;采用的最大挑战是什么，人们并不真正了解它，还是存在其他阻力？&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;丹尼尔：&lt;/strong&gt;挑战之一是人们不知道这一点。您需要改变多年来的文化和分布式系统中的人员，将其视为整体（如孤立的实体），而不考虑整个系统。我认为从工程角度来看，这需要改变，或者我们如何操作系统。&lt;/p&gt;&#xA;&lt;p&gt;采用还存在另一个挑战，这往往与成本相关，因为我们从分布式系统生成大量遥测数据。贝夫如果你之前可能有一个巨大的复制品，那么现在你只有很小的组件来产生遥测数据。我认为了解分布式跟踪和上下文可以让您更好地决定保留什么和不保留什么，这一点也很重要。&lt;/p&gt;&#xA;&lt;p&gt;成本是一个挑战，但并非不可克服的挑战。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Juraci：&lt;/strong&gt;我认为还有一种情况，人们只有在拥有经验时才能看到价值。人们需要一段时间才能意识到他们需要可观察性，即使经过多年的经验，他们甚至可能没有意识到这一点。&lt;/p&gt;&#xA;&lt;h2 id=&#34;weighing-the-trade-offs-of-using-otel&#34;&gt;权衡使用 OTel 的利弊&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Mat：&lt;/strong&gt;使用 OTel 是否有缺点，或者我们必须注意哪些权衡？&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;丹尼尔：&lt;/strong&gt;这取决于您作为一个组织在可观察性之旅中所处的阶段。因此，如果您拥有非常稳定的流程，并且 OTel 中可能有些东西还不太稳定，那么您可以采用非常稳定的部分，并尝试对其进行简化和整合。还有其他部分不太稳定，例如与配置文件相关的东西。所以我认为，如果你有一些目前正在发挥作用的东西，那么它可能是你需要等到事情变得更加稳定的事情之一。&lt;/p&gt;&#xA;&lt;p&gt;如果您完全是新手并且从头开始，您的天平可能会倾向于创新。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Juraci：&lt;/strong&gt;我认为这也是相对的。该收集器还没有达到 v1，所以理论上它还不稳定。但这并不能阻止像 eBay 的 Vijay [Samuel] 这样的人在那里实施高度可扩展的收集器管道并在 KubeCon 上发表演讲。&lt;/p&gt;&#xA;&lt;p&gt;我们认为这对于某些事情来说很好，但对于其他事情来说就不太好了。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;丹尼尔：&lt;/strong&gt;它确实需要平台工程团队进行一些尽职调查。例如，在 Skyscanner，我们也大规模运行收集器，每秒处理超过一百万个跨度，每秒处理数十万个数据点。收集器不是 v1，但我们依赖的组件（OTLP、接收和导出）以及我们使用的处理器是稳定的。&lt;/p&gt;&#xA;&lt;h2 id=&#34;governance-committee-scoop&#34;&gt;治理委员会独家报道&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Mat：&lt;/strong&gt;请告诉我们更多有关您在治理委员会所做的工作的信息，特别是如果您现在正在从事任何有趣的事情。或者我很想知道关于你不同意的大地方的八卦，或者幕后的事情。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;丹尼尔：&lt;/strong&gt;我认为我们没有太大分歧。我们都非常一致。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Juraci：&lt;/strong&gt;我们所有的通话都会被录音，因此会议记录是公开的，并且录音&lt;a href=&#34;https://github.com/open-telemetry/community?tab=readme- ov-file#governing-bodies&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;可用&lt;/a&gt; - 毕竟这是一个开源项目。我们确实有私人会议，讨论与行为准则真正相关的事情或来自社区的人们的投诉。这是一个很大的社区，所以分歧肯定会发生。我们的团队会平衡这一点，并确保我们作为一个社区不断前进，并且我们不会忽视可能在未来造成更大问题的问题。&lt;/p&gt;&#xA;&lt;p&gt;但我认为我们最大的挑战是，尽管 OpenTelemetry 充满了来自供应商的人员 - 那里的大多数人为供应商工作 - 尽管我们在该项目背后有商业利益，但归根结底，我们都是，志愿者。我们大多数人最终都会在工作时间做一些事情。我们为此获得报酬，但这不是我们纳入 OKR 的内容。&lt;/p&gt;&#xA;&lt;p&gt;作为 GC 治理委员会的一部分，困难的部分是就路线图达成一致，并说服其他人他们必须关注我们所说的内容，因为“这是我们认为重要的事情” 。不仅倾听我们的意见，而且遵循我们正在努力走的道路。”&lt;/p&gt;&#xA;&lt;p&gt;我们是软件工程师，所以我们每天都会发现新玩具，并且我们想玩这些玩具。在这一点上，我坦率的意见是，我们有太多玩具，我们必须进行一些春季大扫除，看看什么值得保留，什么不值得，以及我们应该宣布什么是好主意，但为了未来.&lt;/p&gt;&#xA;&lt;h2 id=&#34;whats-coming-up-for-otel&#34;&gt;OTel 即将推出的产品&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Mat：&lt;/strong&gt;说到新玩具，什么是新的？ OTel 接下来令人兴奋的事情是什么？&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Daniel&lt;/strong&gt;：让每个人都兴奋的事情之一是将分析作为新信号，以及如何获得与跟踪相关的分析。这将为您在调试实践中探索开辟一条新途径。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Juraci：&lt;/strong&gt;我期待很多事情。我认为其中之一是 &lt;a href=&#34;https://github.com/open-telemetry/community?tab=readme-ov-file#specification-sigs&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;实体 SIG&lt;/a&gt;。我认为这是我们在 OpenTelemetry 中的第一次重大重构，即重构资源属性的想法。资源就是 Dan 之前提到的上下文。它将所有信号连接在一起。&lt;/p&gt;&#xA;&lt;p&gt;事实证明，并非所有我们认为对资源属性具有良好价值的东西实际上都是好的。对于那些不能很好地处理高基数的事情，例如 &lt;a href=&#34;/oss/prometheus/?pg=blog&amp;plcmt=body-txt&#34;&gt;Prometheus&lt;/a&gt; ，它们可能会出现问题，所以我们可能不想要将进程 ID 存储为资源属性的一部分。关于流程的元数据是很好的，但我们实际上并不需要它。&lt;/p&gt;&#xA;&lt;p&gt;实体 SIG 将资源上下文分解为身份资源和身份 SIG ��� 那么我的资源的身份是什么，我的资源的元数据是什么，这样信号之间的链接上下文就会非常薄，我可以在 Prometheus 和 &lt;a href=&#34;/oss/loki/ 中使用它们?pg=blog&amp;plcmt=body-txt&#34;&gt;Loki&lt;/a&gt; 或不同的数据存储中，元数据可以存储在其他地方。它不必被索引。它不必是对象标识的一部分。&lt;/p&gt;&#xA;&lt;p&gt;也许它不像分析那么令人兴奋，但我认为这是非常必要的，而且这是我们正在进行重构的成熟标志。&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;“Grafana 的大帐篷”播客希望收到您的来信。如果您有精彩的故事要分享、想要加入对话或有任何反馈，请联系 Big Tent 团队：&lt;a href=&#34;/blog/2024/08/23/grafanas-big-tent-podcast-season -2-is-here/bigtent@grafana.com&#34;&gt;bigtent@grafana.com&lt;/a&gt;。您还可以在 &lt;a href=&#34;https://podcasts.apple.com/us/podcast/grafanas-big-tent/id1616725129&#34; target=&#34;_blank&#34; 上观看《Grafana&#39;s Big Tent》第一季和第二季rel=&#34;noopener noreferrer&#34;&gt;Apple 播客&lt;/a&gt; 和 &lt;a href=&#34;https://open.spotify.com/show/3beQvS8to0rYs1gxOnP​​rfD?si=bf046f54fe214615&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Spotify&lt;/a&gt;。&lt;/em&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 20 Dec 2024 00:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>