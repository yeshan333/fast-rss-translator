<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Uber Engineering Blog</title>
    <link>http://rsshub.rssforever.com/uber/blog</link>
    <description>The technology behind Uber Engineering - Powered by RSSHub</description>
    <managingEditor>contact@rsshub.app (RSSHub)</managingEditor>
    <item>
      <title>【Modernizing Uber’s Batch Data Infrastructure with Google Cloud Platform】使用 Google Cloud Platform 实现 Uber 批量数据基础设施的现代化</title>
      <link>https://www.uber.com/blog/modernizing-ubers-data-infrastructure-with-gcp/</link>
      <description>【&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;3b346459-b64f-4a7c-a4fd-74c5e5ccd06a&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-introduction&#34;&gt;Introduction&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;21359d5b-ec8c-44c1-b5c0-2f24d053f635&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Uber runs one of the largest Hadoop installations in the world. Our &lt;a href=&#34;https://www.uber.com/blog/uber-big-data-platform/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Hadoop ecosystem&lt;/a&gt; hosts more than 1 exabyte of data across tens of thousands of servers in each of our two regions. The open source data ecosystem, including the Hadoop ecosystem discussed in previous &lt;a href=&#34;https://www.uber.com/blog/engineering/data/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;engineering blogs&lt;/a&gt;, has been the core of our data platform. &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6b7695fe-0b3d-44f8-9c71-a4591d18a7bf&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Over the past few months, we have been assessing our platform and infrastructure needs to make sure we are well positioned to modernize our big data infrastructure to keep up with the growing needs of Uber.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;dc6a6591-ea0b-4c63-976b-6ae8b92810cf&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Today, we are excited to announce that we are working with Google Cloud Platform (GCP) to move our batch data analytics and ML training stack to GCP.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;16e72208-638d-4350-b32a-959e0b8b5b36&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Uber Data Platform’s mission is to democratize data-driven business decisions through intuitive, reliable, and efficient data products. Modernizing with GCP will enable big gains in user productivity, engineering velocity, improved cost efficiency, access to new innovation, and expanded data governance.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;84304abb-8844-4204-9732-ab2a99b269f2&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-strategy&#34;&gt;Strategy&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;36694de4-6854-49b0-8deb-0fb1916561eb&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Our strategy for the initial migration to GCP is to leverage cloud’s object store for the data lake storage while migrating the rest of the data stack to cloud IaaS (Infrastructure as a Service). This approach facilitates a fast migration path with minimum disruption to existing jobs and pipelines as we can replicate the exact versions of our on-prem software stack, engines, and security model on IaaS. We plan to adopt applicable PaaS (Platform as a Service) offerings, for example GCP Dataproc or BigQuery, after the initial migration to GCP to take full advantage of the elasticity and performance benefits cloud native services provide. Our plan is to execute on this strategy over the next several quarters, documenting our progress and sharing our learnings through a series of blog posts, of which this is the first. So bookmark this blog and stay tuned!&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;cddfe6e6-7861-40ea-8e12-fc924d6993da&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;709d0c51-5f63-4349-8d7f-2ff58cf91f10&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/Wx5iHeuUr_MaCochwvxq39y6wvy3aP3z8euxLBVPwOIujVTJ7GPvI8jyKFH4-JhfSps-0dQeWb9PJ7-fMn2Qgs1LXnmnOfxg8XeodrfTcnrrj8S8OZLEx_taJfS1JTrJ0c2_MZ27nPTq_6JfxFk6BWc&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;dd6b5e59-c9f1-4673-9cee-9bd91a4f8aa2&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;b2c01abd-5e77-4f02-b18d-070ee57e1cd9&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/vJcumVtF5yY4yqe5-7chOwkB6uyypCxfeuj9YVNhO3Xyi3YBjdig7sYRDC4RAU5IUh9XWbcWH-1D8KJs9ilaWkwsOAPKKmsbpV23AR5mxSGPRYXbSlREjembU5CMm4FLq_1RYHvloRng1Jz7xADjq6E&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;92883264-370f-48d3-80a1-e55e4346626d&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;bd32953e-1a1a-4194-868b-ac11b928d137&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-migration-principles&#34;&gt;Migration Principles&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;84911e7f-af9e-4cd7-a019-71245f11848f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Here are the core principles that we are keeping in mind for this daunting migration:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;c3c28e67-c28f-4fe3-947a-2da697212828&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-avoid-painful-migrations-for-data-users&#34;&gt;Avoid painful migrations for data users&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;08732ab0-c663-492a-b4a3-5cd31af4046e&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;By moving the majority of the batch data stack onto cloud IaaS as-is, we expect to shield our users such as dashboard owners, pipelines authors, ML practitioners, etc., from needing any changes to their artifacts or services. We’ll leverage well-known abstractions and open standards to make the migration as transparent as possible to data users.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2d7e5b84-0f3f-4401-89f2-a924cca00592&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We will be relying heavily on a cloud storage connector that implements the Hadoop FileSystem interface to Google Cloud Storage, providing HDFS compatibility. We will leverage open standards such as &lt;a href=&#34;https://parquet.apache.org/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Apache Parquet&lt;/a&gt;™ file format, &lt;a href=&#34;https://hudi.apache.org/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Apache Hudi&lt;/a&gt;™ table format, &lt;a href=&#34;https://spark.apache.org/&#34;&gt;Apache Spark&lt;/a&gt;™, &lt;a href=&#34;https://prestodb.io/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Presto’s&lt;/a&gt; SQL dialect, &lt;a href=&#34;https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/YARN.html&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Apache Hadoop YARN&lt;/a&gt;™, and &lt;a href=&#34;https://kubernetes.io/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;K8s&lt;/a&gt; to minimize the migration challenges even for the teams within the data platform organization. We will standardize our &lt;a href=&#34;https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Apache Hadoop HDFS&lt;/a&gt;™ clients to abstract the on-prem HDFS implementation specifics. Therefore, all the services that access HDFS on-prem today will seamlessly integrate with the GCP-hosted object store based storage layer without any changes. The standardized HDFS client will be modified to translate the HDFS paths to Object store based paths via a “Path Translation Service.” We will share more details on this in a future blog post.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;ec154e3d-fa37-4bdf-b3c1-b3cf99193a6c&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-enhance-data-access-proxies-to-federate-traffic-across-on-prem-or-cloud&#34;&gt;Enhance data access proxies to federate traffic across on-prem or cloud&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;fbee9041-cce0-42e4-8e2c-9d245810815a&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We have developed data access proxies (for &lt;a href=&#34;https://www.uber.com/blog/presto/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Presto&lt;/a&gt;, &lt;a href=&#34;https://www.uber.com/blog/uscs-apache-spark/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Spark&lt;/a&gt;, and Hive) that abstract out the details of the underlying physical compute clusters. During the testing phase, these proxies will support selectively routing test traffic toward the corresponding cloud-based Presto or YARN (for Spark and Hive) clusters. During full migration, all queries or jobs submitted to these proxies will be routed to the cloud-based stack.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;08214700-ac04-41bc-b154-05d11b0250ef&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-leverage-uber-s-existing-cloud-agnostic-container-and-deployment-infrastructure&#34;&gt;Leverage Uber’s existing cloud-agnostic container and deployment infrastructure&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;75d203f7-c3db-4d2e-905f-40e88fe01bb3&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The batch data stack sits on top of Uber’s infrastructure building blocks such as Uber’s &lt;a href=&#34;https://www.uber.com/blog/hadoop-container-blog/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;container environment&lt;/a&gt;, compute platform, and deployment tools which are built to be &lt;a href=&#34;https://www.uber.com/blog/crane-ubers-next-gen-infrastructure-stack/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;agnostic between cloud and on-prem&lt;/a&gt;. These platforms easily allow us to expand the batch data ecosystem microservices onto the cloud IaaS.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;af42a770-69b0-40af-817d-5362cdbebab4&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-forecast-potential-data-governance-issues-from-cloud-services&#34;&gt;Forecast potential data governance issues from cloud services&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;db3817d2-67a0-420e-a3c3-e3b4916c6eba&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;As a platform team we will build and enhance existing data management services to only support selected and approved data services from the cloud vendor’s portfolio to avoid data governance complexities moving forward.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3afca685-ea51-43d4-a886-aa783383b1b0&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;dac5769f-563e-416c-b583-35ed277e3ea6&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-major-workstreams&#34;&gt;Major Workstreams&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;9e276b5e-0bcb-42c1-8678-b168dbd7c5cc&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-bucket-mapping-and-cloud-resources-layout&#34;&gt;Bucket mapping and cloud resources layout&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;14080aa3-0e0b-4725-b862-6ed89dda2dd1&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;While migrating data, we need to map HDFS files and directories from the source cluster to cloud objects, which reside in one or more buckets. We also need to apply IAM policies at varying levels of granularity such as bucket, prefix or object level. Common constraints on buckets and objects include number of buckets per organization, read/write throughput from/to a bucket, IOPS throttling, and the number of ACLs, which can be applied via bucket policies.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3d023652-9af2-4b74-88b0-717034b0b63d&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The goal of this workstream is to formulate a mapping algorithm that satisfies these constraints and creates the corresponding cloud buckets. We also plan to incorporate &lt;a href=&#34;https://martinfowler.com/articles/data-mesh-principles.html&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;data mesh principles&lt;/a&gt; to organize these data resources in an organization-centric hierarchical manner, allowing for better data administration and management.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;0a5d9986-5494-4535-bf0f-03b29145c949&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-security-integration&#34;&gt;Security integration&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;aa77e826-c57c-424b-8959-9f427859b64d&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Our existing, Kerberos-based tokens and Hadoop Delegation tokens will not directly work with cloud PaaS, specifically GCS object storage. Cloud providers generally don’t have a ready-to-use PaaS solution for such interoperability.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e16b3e10-5ab3-45c8-90ba-8378443006e3&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The goal of this workstream is to enable a seamless support for all users, groups, and service accounts to continue to be &lt;a href=&#34;https://www.uber.com/blog/scaling-adoption-of-kerberos-at-uber/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;authenticated&lt;/a&gt; against the object store data lake and any other cloud PaaS. Also to maintain the same levels of authorized access as on-prem from there on.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;115cf99b-bca7-4a45-ba32-33df68a63d07&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-data-replication&#34;&gt;Data replication&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2a1f5933-a393-4d84-b5ac-a171a6c88279&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;HiveSync is a permissions-aware, bi-directional data replication service built at Uber (based on &lt;a href=&#34;https://github.com/airbnb/reair&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;ReAir&lt;/a&gt;/&lt;a href=&#34;https://hadoop.apache.org/docs/stable/hadoop-distcp/DistCp.html&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;distcp&lt;/a&gt;). HiveSync allows us to operate in an active-active mode with the batch and incremental replication features keeping our data lakes in the two regions in sync.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7c3b84fb-37c7-4908-af88-39606ae0e825&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The goal of this workstream is to extend HiveSync’s capabilities and Hudi library capabilities to replicate the on-prem data lake’s data into the cloud-based data lake and corresponding Hive Metastore. This includes the one time bootstrap (bulk migration)&amp;nbsp; and then ongoing incremental updates till the cloud-based stack is the primary.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;5790e635-cb93-4200-af60-bed2f3e4f68f&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-yarn-and-presto-clusters&#34;&gt;YARN and Presto clusters&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2e47faa7-17a5-45bd-a458-4f9650cf3636&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We would provision new YARN and Presto clusters on IaaS from the GCP. The existing data access proxies which federate query and job traffic to these clusters will then route traffic to the cloud-based stack through the migration.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;94d1060d-c08d-414f-b477-78ad7e615915&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;db8d825b-21f5-451a-a842-eb6506bdb03a&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-challenges-and-initiatives&#34;&gt;Challenges and Initiatives&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4fdf7398-74eb-4fab-966a-dde691f38eb9&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;This migration is a formidable undertaking and we are aware of the typical challenges that we&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;14970a1d-a79e-4991-99a8-742a44d28809&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;might face. Here are some of the large categories of challenges we are anticipating along with the mitigations and initiatives to handle them:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;23bed934-f004-4692-8bb0-71b400526ef5&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;Performance&lt;/strong&gt;: There are several well-known differences in features and performance characteristics between Object Store and HDFS. (e.g., atomic renames, file listing performance, etc.). We would leverage the Hadoop connectors from open source and help evolve them to maximize performance.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;Usage governance&lt;/strong&gt;: Cloud-related usage costs can balloon out of control if we don’t&amp;nbsp; &lt;a href=&#34;https://www.uber.com/blog/cost-efficient-big-data-platform/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;effectively&lt;/a&gt; and proactively manage them. We would leverage cloud’s elasticity to offset these costs. We will also partner with our internal capacity engineering team to build a finer attribution mechanism and tracking.&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;Non-analytics/ML specific usage of HDFS&lt;/strong&gt; &lt;strong&gt;by applications&lt;/strong&gt;: Over the years, teams have also started to use HDFS as a generic file store. We would be proactively migrating these use cases to other internal blob stores while also providing a transparent migration path to avoid disruptions.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;Unknown unknowns&lt;/strong&gt;: Finally, with a ~7 year old on-prem stack, we will definitely face unanticipated challenges. We hope to proactively uncover issues with early end-to-end integrations, refine proposed abstractions with customers, deprecate legacy use cases aggressively rather than carry them forward, etc., to stay ahead of these challenges.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3567e764-ec2c-490d-9270-12b5534db563&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Stay tuned on our journey as we will share our detailed designs, execution progress, and the lessons learned along the way!&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;fontSize&amp;quot;:&amp;quot;small&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;08f9da88-7d7c-4c43-9e5d-d526dbbab62f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34; class=&#34;has-small-font-size&#34;&gt;&lt;em&gt;Apache&lt;sup&gt;®&lt;/sup&gt;, Apache Parquet™, Apache Hudi™, Apache Spark™, &lt;em&gt;Apache Hadoop YARN™&lt;/em&gt; are registered trademarks or trademarks of the&amp;nbsp;&lt;/em&gt;&lt;a href=&#34;http://www.apache.org/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;&lt;em&gt;Apache Software Foundation&lt;/em&gt;&lt;/a&gt;&lt;em&gt;&amp;nbsp;in the United States and/or other countries. No endorsement by The Apache Software Foundation is implied by the use of these marks.&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;fontSize&amp;quot;:&amp;quot;small&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;9cd655f7-4966-44c6-aac8-82788b4fd2e9&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34; class=&#34;has-small-font-size&#34;&gt;Cover Photo Attribution: “&lt;a href=&#34;https://www.flickr.com/photos/55856449@N04/17510835551&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Country road and yellow field&lt;/a&gt;” by&amp;nbsp;&lt;a href=&#34;https://www.flickr.com/photos/55856449@N04&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Infomastern&lt;/a&gt;&amp;nbsp;is licensed under&amp;nbsp;&lt;a href=&#34;https://creativecommons.org/licenses/by-sa/2.0/?ref=openverse&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;CC BY-SA 2.0&lt;/a&gt;.&lt;/p&gt;】&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:1,&#34;hash&#34;:&#34;3b346459-b64f-4a7c-a4fd-74c5e5ccd06a&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-introduction&#34;&gt;简介&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;21359d5b-ec8c-44c1-b5c0-2f24d053f635&#34;,&#34;dropCap&#34;:false}&#34;&gt;Uber 运行一个世界上最大的 Hadoop 安装。我们的 &lt;a href=&#34;https://www.uber.com/blog/uber-big-data-platform/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Hadoop 生态系统&lt;/a&gt; 托管超过 1 艾字节我们两个地区的数万台服务器上的数据。开源数据生态系统，包括之前&lt;a href=&#34;https://www.uber.com/blog/engineering/data/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;工程博客&lt;中讨论的Hadoop生态系统&lt; /a&gt;，一直是我们数据平台的核心。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;6b7695fe-0b3d-44f8-9c71-a4591d18a7bf&#34;,&#34;dropCap&#34;:false}&#34;&gt;过去几个月来，我们一直在评估我们的平台和基础设施需求，以确保我们能够很好地实现大数据基础设施的现代化，以满足 Uber 不断增长的需求。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;dc6a6591-ea0b-4c63-976b-6ae8b92810cf&#34;,&#34;dropCap&#34;:false}&#34;&gt;今天，我们我们很高兴地宣布，我们正在与 Google Cloud Platform (GCP) 合作，将批量数据分析和机器学习训练堆栈迁移到 GCP。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;16e72208-638d-4350-b32a-959e0b8b5b36&#34;,&#34;dropCap&#34;:false}&#34;&gt;Uber 数据平台使命是通过直观、可靠和高效的数据产品使数据驱动的业务决策民主化。利用 GCP 实现现代化将大大提高用户工作效率、工程速度、提高成本效率、获得新创新并扩展数据治理。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:1,&#34;hash&#34;:&#34;84304abb-8844-4204-9732-ab2a99b269f2&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-strategy&#34;&gt;策略&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;36694de4-6854-49b0-8deb-0fb1916561eb&#34;,&#34;dropCap&#34;:false}&#34;&gt;我们的策略向 GCP 的初始迁移是利用云的对象存储作为数据湖存储，同时将其余数据堆栈迁移到云 IaaS（基础设施即服务）。这种方法有助于实现快速迁移路径，同时最大限度地减少对现有作业和管道的干扰，因为我们可以在 IaaS 上复制本地软件堆栈、引擎和安全模型的精确版本。我们计划在初次迁移到 GCP 后采用适用的 PaaS（平台即服务）产品，例如 GCP Dataproc 或 BigQuery，以充分利用弹性和性能优势提供云原生服务。我们的计划是在接下来的几个季度执行这一战略，通过一系列博客文章（这是第一篇）记录我们的进展并分享我们的经验教训。因此，请将此博客添加为书签并继续关注！&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;cddfe6e6-7861-40ea-8e12-fc924d6993da&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;align&#34;:&#34;center&#34;,&#34;hash&#34;:&#34;709d0c51-5f63-4349-8d7f-2ff58cf91f10&#34;,&#34;alt&#34; :&#34;&#34;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img 解码=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/Wx5iHeuUr_MaCochwvxq39y6wvy3aP3z8euxLBVPwOIujVTJ7GPvI8jyKFH4-JhfSps-0dQeWb9PJ7-fMn2Qgs1LXnmnOfxg8Xeod rfTcnrrj8S8OZLEx_taJfS1JTrJ0c2_MZ27nPTq_6JfxFk6BWc&#34; alt=&#34;&#34;referrerpolicy=&#34;no-推荐人&#34;&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;dd6b5e59-c9f1-4673-9cee-9bd91a4f8aa2&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;align&#34;:&#34;center&#34;,&#34;hash&#34;:&#34;b2c01abd-5e77-4f02-b18d-070ee57e1cd9&#34;,&#34;alt&#34; ：&#34;&#34;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img 解码=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/vJcumVtF5yY4yqe5-7chOwkB6uyypCxfeuj9YVNhO3Xyi3YBjdig7sYRDC4RAU5IUh9XWbcWH-1D8KJs9ilaWkwsOAPKKmsbpV23AR5 mxSGPRYXbSlREjembU5CMm4FLq_1RYHvloRng1Jz7xADjq6E&#34; alt=&#34;&#34;referrerpolicy=&#34;no-referrer&#34; &gt;&lt;/图&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;92883264-370f-48d3-80a1-e55e4346626d&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;bd32953e-1a1a-4194-868b-ac11b928d137&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-migration-principles&#34;&gt;迁移原则&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;84911e7f-af9e-4cd7-a019-71245f11848f&#34;,&#34;dropCap&#34;:false}&#34;&gt;这里是对于这一艰巨的迁移，我们牢记核心原则：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;c3c28e67-c28f-4fe3-947a-2da697212828&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-avoid-painful-migrations-for-data-users&#34;&gt;避免数据用户痛苦的迁移&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;08732ab0-c663-492a-b4a3-5cd31af4046e&#34;,&#34;dropCap&#34;:false}&#34;&gt;通过移动大多数批量数据堆栈按原样存储到云 IaaS 上，我们希望保护我们的用户，例如仪表板所有者、管道作者、ML 从业者等c.，需要对其工件或服务进行任何更改。我们将利用众所周知的抽象和开放标准，使迁移对数据用户尽可能透明。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;2d7e5b84-0f3f-4401-89f2-a924cca00592&#34;,&#34;dropCap&#34;:false}&#34;&gt;我们将严重依赖云存储连接器，该连接器实现了 Google Cloud Storage 的 Hadoop 文件系统接口，提供 HDFS 兼容性。我们将利用开放标准，例如 &lt;a href=&#34;https://parquet.apache.org/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Apache Parquet&lt;/a&gt;™ 文件格式、&lt;a href=&#34; https://hudi.apache.org/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Apache Hudi&lt;/a&gt;™ 表格式，&lt;a href=&#34;https://spark.apache.org/&#34;&gt; Apache Spark&lt;/a&gt;™、&lt;a href=&#34;https://prestodb.io/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Presto 的&lt;/a&gt; SQL 方言、&lt;a href=&#34;https:// /hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/YARN.html&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Apache Hadoop YARN&lt;/a&gt;™ 和 &lt;a href =&#34;https://kubernetes.io/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;K8s&lt;/a&gt; 最大限度地减少迁移挑战，即使对于数据平台组织内的团队也是如此。我们将标准化我们的 &lt;a href=&#34;https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Apache Hadoop HDFS&lt;/a&gt;™ 客户端抽象本地 HDFS 实现细节。因此，现在访问本地 HDFS 的所有服务都将与基于 GCP 托管的对象存储的存储层无缝集成，无需任何更改。标准化 HDFS 客户端将被修改为通过“路径转换服务”将 HDFS 路径转换为基于对象存储的路径。我们将在未来的博客文章中分享更多相关细节。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;ec154e3d-fa37-4bdf-b3c1-b3cf99193a6c&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-enhance-data-access-proxies-to-federate-traffic-across-on-prem-or-cloud&#34;&gt;增强数据访问代理以联合本地或云端的流量&lt;/ H3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;fbee9041-cce0-42e4-8e2c-9d245810815a&#34;,&#34;dropCap&#34;:false}&#34;&gt;我们开发了数据访问代理（对于 &lt;a href=&#34;https://www.uber.com/blog/presto/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Presto&lt;/a&gt;、&lt;a href=&#34;https: //www.uber.com/blog/uscs-apache-spark/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Spark&lt;/a&gt; 和 Hive），抽象出底层物理计算集群的详细信息。在测试阶段，这些代理将支持选择性地将测试流量路由到相应的基于云的 Presto 或 YARN（适用于 Spark 和 Hive）集群。在完全迁移期间，提交给这些代理的所有查询或作业都将路由到基于云的堆栈。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;核心/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;08214700-ac04-41bc-b154-05d11b0250ef&#34;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-leverage- uber-s-existing-cloud-agnostic-container-and-deployment-infrastructure&#34;&gt;利用 Uber 现有的与云无关的容器和部署基础设施&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;75d203f7-c3db-4d2e-905f-40e88fe01bb3&#34;,&#34;dropCap&#34;:false}&#34;&gt;批量数据堆栈位于 Uber 基础设施构建块之上，例如 Uber 的 &lt;a href=&#34;https://www.uber.com/blog/hadoop-container-blog/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;容器环境&lt;/a&gt;、计算平台和部署工具，其构建为&lt;a href=&#34;https://www.uber.com/blog/crane-ubers-next-gen-infrastruct-stack/&#34; target=&#34;_blank “ rel=&#34;noreferrer noopener&#34;&gt;云和本地之间不可知&lt;/a&gt;。这些平台使我们能够轻松地将批量数据生态系统微服务扩展到云IaaS上。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;af42a770-69b0-40af-817d-5362cdbebab4&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-forecast-pottial-data-governance-issues-from-cloud-services&#34;&gt;预测云服务潜在的数据治理问题&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;db3817d2-67a0-420e-a3c3-e3b4916c6eba&#34;,&#34;dropCap&#34;:false}&#34;&gt;作为平台团队中，我们将构建和增强现有的数据管理服务，以仅支持云供应商产品组合中选定和批准的数据服务，以避免未来数据治理的复杂性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;3afca685-ea51-43d4-a886-aa783383b1b0&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;dac5769f-563e-416c-b583-35ed277e3ea6&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-major-workstreams&#34;&gt;主要工作流&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;9e276b5e-0bcb-42c1-8678-b168dbd7c5cc&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-bucket-mapping-and-cloud-resources-layout&#34;&gt;桶映射和云资源布局&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;14080aa3-0e0b-4725-b862-6ed89dda2dd1&#34;,&#34;dropCap&#34;:false}&#34;&gt;迁移数据时，我们需要将 HDFS 文件和目录从源集群映射到驻留在一个或多个存储桶中的云对象。我们还需要在不同的粒度级别（例如存储桶、前缀或对象级别）应用 IAM 策略。对存储桶和对象的常见约束包括每个组织的存储桶数量、存储桶的读/写吞吐量、IOPS 限制以及可应用的 ACL 数量ia 存储桶策略。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;3d023652-9af2-4b74-88b0-717034b0b63d&#34;,&#34;dropCap&#34;:false}&#34;&gt;目标该工作流程是制定满足这些约束的映射算法并创建相应的云桶。我们还计划纳入&lt;a href=&#34;https://martinfowler.com/articles/data-mesh-principles.html&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;数据网格原则&lt;/a&gt;来组织这些数据资源以组织为中心的分层方式，可以更好地管理和管理数据。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;0a5d9986-5494-4535-bf0f-03b29145c949&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-security-integration&#34;&gt;安全集成&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;aa77e826-c57c-424b-8959-9f427859b64d&#34;,&#34;dropCap&#34;:false}&#34;&gt;我们现有的，基于 Kerberos 的令牌和 Hadoop 委托令牌不能直接与云 PaaS（特别是 GCS 对象存储）配合使用。云提供商通常没有现成的 PaaS 解决方案来实现此类互操作性。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;e16b3e10-5ab3-45c8-90ba-8378443006e3&#34;,&#34;dropCap&#34;:false}&#34;&gt;目标此工作流旨在为所有用户、组和服务帐户提供无缝支持，以继续&lt;a href=&#34;https://www.uber.com/blog/scaling-adoption-of-kerberos-at-uber/ “ target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;针对对象存储数据湖和任何其他云 PaaS 进行身份验证&lt;/a&gt;。还要保持与本地相同级别的授权访问权限。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;115cf99b-bca7-4a45-ba32-33df68a63d07&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-data-replication&#34;&gt;数据复制&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;2a1f5933-a393-4d84-b5ac-a171a6c88279&#34;,&#34;dropCap&#34;:false}&#34;&gt;HiveSync 是一个Uber 构建的权限感知双向数据复制服务（基于 &lt;a href=&#34;https://github.com/airbnb/reair&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;ReAir&lt;/a&gt; /&lt;a href=&#34;https://hadoop.apache.org/docs/stable/hadoop-distcp/DistCp.html&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;distcp&lt;/a&gt;）。 HiveSync 允许我们以主动-主动模式运行，并具有批量和增量复制功能，使两个区域的数据湖保持同步。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;7c3b84fb-37c7-4908-af88-39606ae0e825&#34;,&#34;dropCap&#34;:false}&#34;&gt;目标该工作流是扩展 HiveSync 的功能和 Hudi 库功能，以将本地数据湖的数据复制到基于云的数据湖和相应的 Hive M埃塔商店。这包括一次性引导（批量迁移），然后持续增量更新，直到基于云的堆栈成为主要堆栈。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;5790e635-cb93-4200-af60-bed2f3e4f68f&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-yarn-and-presto-clusters&#34;&gt;YARN 和 Presto 集群&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;2e47faa7-17a5-45bd-a458-4f9650cf3636&#34;,&#34;dropCap&#34;:false}&#34;&gt;我们将提供来自 GCP 的 IaaS 上的新 YARN 和 Presto 集群。然后，将查询和作业流量联合到这些集群的现有数据访问代理将通过迁移将流量路由到基于云的堆栈。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;94d1060d-c08d-414f-b477-78ad7e615915&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;db8d825b-21f5-451a-a842-eb6506bdb03a&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-challenges-and-initiatives&#34;&gt;挑战和举措&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;4fdf7398-74eb-4fab-966a-dde691f38eb9&#34;,&#34;dropCap&#34;:false}&#34;&gt;此迁移是这是一项艰巨的任务，我们意识到我们面临的典型挑战&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;14970a1d-a79e-4991-99a8-742a44d28809&#34;,&#34;dropCap&#34;:false}&#34;&gt;可能会面临。以下是我们预计将面临的一些大类挑战以及应对这些挑战的缓解措施和举措：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;23bed934-f004-4692-8bb0-71b400526ef5&#34;,&#34;ordered&#34;:false,&#34;values&#34;:&#34; “}”&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;性能&lt;/strong&gt;：之间的功能和性能特征存在一些众所周知的差异对象存储和 HDFS。 （例如，原子重命名、文件列表性能等）。我们将利用开源的 Hadoop 连接器并帮助改进它们以最大限度地提高性能。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;使用治理&lt;/strong&gt;：如果我们不采取措施，与云相关的使用成本可能会失控。不主动&lt;a href=&#34;https://www.uber.com/blog/cost-efficient-big-data-platform/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;有效&lt;/a&gt;管理他们。我们将利用云的弹性来抵消这些成本。我们还将与内部容量工程团队合作，建立更精细的归因机制和跟踪。 &lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;HDFS 的非分析/ML 特定使用&lt;/strong&gt; &lt;strong&gt;应用程序&lt;/strong&gt;：多年来，团队也开始使用 HDFS 作为通用文件存储。我们将主动将这些用例迁移到其他内部 Blob 存储，同时提供透明的迁移路径以避免中断。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;未知的未知&lt;/strong&gt;：最后，使用了大约 7 年历史的本地堆栈，我们一定会面临意想不到的挑战。我们希望通过早期端到端集成主动发现问题，与客户一起完善提议的抽象，积极弃用而不是继续使用旧用例等，以保持领先地位。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;3567e764-ec2c-490d-9270-12b5534db563&#34;,&#34;dropCap&#34;:false}&#34;&gt;敬请关注我们的旅程，我们将分享我们的详细设计、执行进度以及一路上吸取的经验教训！&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;fontSize&#34;:&#34;小&#34;,&#34;hash&#34;:&#34;08f9da88-7d7c-4c43-9e5d-d526dbbab62f&#34;,&#34;dropCap&#34; :false}&#34; class=&#34;has-small-font-size&#34;&gt;&lt;em&gt;Apache&lt;sup&gt;®&lt;/sup&gt;、Apache Parquet™、Apache Hudi™、Apache Spark™、&lt;em&gt;Apache Hadoop YARN™&lt;/ em&gt; 是&lt;a href=&#34;http://www.apache.org/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;&lt;em&gt;Apache Software Foundation&lt;/em&gt;的注册商标或商标&gt;&lt;/a&gt;&lt;em&gt; 在美国和/或其他国家/地区。使用这些标记并不暗示 Apache 软件基金会的认可。&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;fontSize&#34;:&#34;小&#34;,&#34;hash&#34;:&#34;9cd655f7-4966-44c6-aac8-82788b4fd2e9&#34;,&#34;dropCap&#34; :false}&#34; class=&#34;has-small-font-size&#34;&gt;封面照片归属：“&lt;a href=&#34;https://www.flickr.com/photos/55856449@N04/17510835551&#34; target=&#34;_blank&#34; rel =&#34;noreferrer noopener&#34;&gt;乡村道路和黄色田野&lt;/a&gt;”作者：&lt;a href=&#34;https://www.flickr.com/photos/55856449@N04&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt; Infomastern&lt;/a&gt; 已获得 &lt;a href=&#34;https://creativecommons.org/licenses/by-sa/2.0/?ref=openverse&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;CC BY-SA 许可2.0&lt;/a&gt;.&lt;/p&gt;</description>
      <pubDate>Thu, 30 May 2024 07:21:12 +0000</pubDate>
    </item>
    <item>
      <title>【Introduction to Kafka Tiered Storage at Uber】Uber 的 Kafka 分层存储简介</title>
      <link>https://www.uber.com/blog/kafka-tiered-storage/</link>
      <description>【&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;433c69f8-24e4-4e25-8a58-c3011be3d1bb&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-introduction&#34;&gt;Introduction&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b3315f9e-7720-4fae-a737-4602be48fcf0&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Apache Kafka® is the cornerstone of Uber’s tech stack. It plays an important role in powering several critical use cases and is the foundation for batch and real-time systems at Uber.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;bae21b7b-4f98-483f-92f9-60ab827ef689&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;5fd7c743-bdd7-40d7-9e81-86f4e342f1a4&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXePSpSp72unfaVqK7tofbbbOpMaZLJ7qYJ2Es-Chg3CHBeZ9kcJDZ9ouvPRYs-CarI8bAqXs2459rJ0_QrsgBaUwqikE5fwYSianNkl1u6Ehbjz_yH6XuWJGn54P5kCaRSaBrCgeVPN4q2QC_RDu9ag1YgU?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 1: Uber’s Data Pipeline.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;bba04fc7-d627-4e13-97a1-c1511775c833&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;213c11a1-ab13-4d60-a5f8-2bf22f25ae86&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Kafka stores the messages in append-only log segments on the broker’s local storage. Each topic can be configured with the targeted retention based on size or time. It gives guarantees for users to consume the data within the retention period or size even when the respective consuming applications fail or become slow for several reasons. Total storage on a cluster depends upon factors like the total number of topic partitions, produce throughput, and retention configuration. A Kafka broker typically needs to have larger storage to support the required topic partitions hosted on a broker.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;f27d9aad-98e4-44d8-8c39-d27574431a59&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-motivation-background-behind-project&#34;&gt;Motivation/Background Behind Project&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2acf6879-58ec-4dc2-9411-023216a9e7e4&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Kafka cluster storage is typically scaled by adding more broker nodes to the cluster. But this also adds needless memory and CPUs to the cluster, making overall storage cost less efficient compared to storing the older data in external storage. A larger cluster with more nodes also adds to the deployment complexity and increases operational costs because of the tight coupling of storage and processing. So, it brings several issues related to scalability, efficiency, and operations.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0657efab-21dc-423f-b42f-c4dc1ed5da8d&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We proposed Kafka Tiered Storage (&lt;a href=&#34;https://cwiki.apache.org/confluence/display/KAFKA/KIP-405%3A+Kafka+Tiered+Storage&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;KIP-405&lt;/a&gt;) to avoid tight coupling of storage and processing in a broker. It provides two tiers of storage, called local and remote. These two tiers can have respective retention policies based on the respective use cases.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7bb99c16-9f01-4606-9393-18634deb8b8c&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;width&amp;quot;:&amp;quot;700px&amp;quot;,&amp;quot;height&amp;quot;:&amp;quot;auto&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;e25cccec-32e4-4c15-976a-4a4725861800&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXdrkDm5z8lSbIzR0Xure8R4qrXa8JqczXMcNyQs17yede4tKZScrbVWTc4PjScxs-k_qrcks2cLmf2nOJi9x4tf2Zyzyql2Ql7jA3Ty4qNQoth7NeTL9itjkQnaJKIwm3zZVYUgYXx_2yr4lgyAF-9eLr-i?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 2: End to end interaction of Kafka broker with tiered storage.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d3f58e6f-e3fc-4df8-84f2-247071e699aa&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;00272d69-19b6-4d44-b7f1-ab451bbd36af&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-goals&#34;&gt;Goals&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f8ada8a4-3425-4352-bd37-c99f0a8e6291&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Below are the main goals that we set for tiered storage:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3cd3f2c9-a5d0-44a3-8335-ca7b05d03d38&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Extend the storage beyond the broker&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Memory/PageCache&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Local storage&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Remote storage support (including cloud/object stores like S3/GCS/Azure)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Durability and Consistency semantics similar to local storage&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Isolation of reading latest and historical data&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;No changes are required from clients&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Easy tuning and provisioning of clusters&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Improve operational and cost efficiency&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f96a808a-53f5-4733-a618-0ed612929034&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;87df347d-17d7-42dc-b9b6-856160fbd93e&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-architecture&#34;&gt;Architecture&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f6ceb13c-20bc-44d2-be91-a3cc6b3523ae&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Kafka cluster enabled with tiered storage is configured with two tiers of storage called local and remote. The local tier is the broker’s local storage where the segments are stored currently. The new remote tier is the extended storage, such as HDFS/S3/GCS/Azure. Both these tiers will have respective retention configurations based on size and time. The retention period for the local tier can be significantly reduced from days to a few hours. The retention period for the remote tier can be much longer–days, or even months. Applications sensitive to latency conduct tail reads and are catered to from the local tier, utilizing Kafka’s efficient page cache utilization for data retrieval. On the other hand, applications such as backfill or those recovering from failures requiring older data than what’s locally available, are served from the remote tier.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;99e485ed-bfbb-4a06-83f3-7781b0ccb009&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;This approach enables the scalability of storage in a Kafka cluster without being tied to memory and CPU resources, thus transforming Kafka into a viable long-term storage option. Moreover, it decreases the local storage burden on Kafka brokers, consequently reducing the data to be transferred during recovery and rebalancing. Log segments accessible in the remote tier don’t require restoration on the broker and can be accessed directly from the remote tier. It eliminates the necessity to expand the Kafka cluster storage and add new nodes when extending the retention period. Additionally, it allows for significantly longer data retention without the requirement for separate data pipelines to transfer data from Kafka to external storage (a common practice in many current setups).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;285c094f-9538-44de-9270-4721f1bf1133&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Tiered storage divides a topic partition’s log into two different logical components called local log and remote log. Local log contains a list of local log segments and remote log contains a list of remote log segments. The remote log subsystem copies each topic partition’s eligible segments from local storage to the remote storage. A segment is eligible to be copied when its end offset is less than &lt;em&gt;LastStableOffset&lt;/em&gt; of a partition.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2d6d304d-aba7-46d5-aa43-bad98a0e13d3&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;bf09d07e-1d0f-4647-8465-310196ef72ff&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXdDJEudzpCrGDSR9yN0sNZ5YU_AM1ExXihNssXH0d5SGi01nOJ4R6xY0yY7frm6ESriC5o6XFiqQMVSCVDWpRK0l6nFxaF8CBCdY0ZpN1beZUsmqpSe4VragjX8kjUjh5VXGKMD-g2i9GMOaIJ99if2dJkj?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 3: Local log offsets and remote log offsets.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;656259a5-41ec-4162-a1a8-fa9680404f3d&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure data-wp-block-name=&#34;core/table&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;970a47e8-729d-4286-a17f-307c713c9f18&amp;quot;,&amp;quot;hasFixedLayout&amp;quot;:false,&amp;quot;head&amp;quot;:[],&amp;quot;body&amp;quot;:[],&amp;quot;foot&amp;quot;:[]}&#34; class=&#34;wp-block-table&#34;&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt; Lz&amp;nbsp; = Local log end offset&amp;nbsp;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;Lx&amp;nbsp; = Local log start offset &amp;nbsp;&lt;/td&gt;&lt;td&gt;Ly&amp;nbsp; = Last stable offset(LSO)&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure data-wp-block-name=&#34;core/table&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c7fa71b6-1b3f-414b-9d7d-8967a9a41e7a&amp;quot;,&amp;quot;hasFixedLayout&amp;quot;:false,&amp;quot;head&amp;quot;:[],&amp;quot;body&amp;quot;:[],&amp;quot;foot&amp;quot;:[]}&#34; class=&#34;wp-block-table&#34;&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;Ry&amp;nbsp; = Remote log end offset &lt;/td&gt;&lt;td&gt;Rx&amp;nbsp; = Remote log start offset&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;em&gt;Lz &amp;gt;= Ly &amp;gt;= Lx and Ly &amp;gt;= Ry &amp;gt;= Rx&lt;/em&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;cdfcf4f5-b74b-4219-ab12-4bb78c78a00a&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a1242f90-4a1d-4f87-9dc7-e49627a2062a&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Apache Kafka storage subsystem maintains the above offset constraints for local and remote log segments of a topic partition.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b4c968f9-e76a-4c83-a966-e0dae7131168&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;width&amp;quot;:&amp;quot;700px&amp;quot;,&amp;quot;height&amp;quot;:&amp;quot;auto&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;f687a646-355f-4412-9ad8-f793d9942d75&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXcnNa5SMjEkpYEOgrEV8WQaKzXNhUFy5I1iuFKcHifODuPUg26arhCP8wvWpPsm7onOA8jTn2IS7_tTF9VXmg2NHC2p5IPSFLXw39fP8b4c47ksowG9dYI-iyFHE2szvRfNMn-QBQc4s_lgOg0tMYH3sKw?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 4: High level architecture of Kafka tiered storage components.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a7ef1ee3-e8df-4942-b3ac-a88b2ec5feca&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d568d925-c3a2-4eed-ab17-976503458642&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The above diagram gives a high-level overview of the new architecture with newly introduced components:&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9c25ec3d-7751-4e49-9a9d-183df57a2782&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;RemoteStorageManager&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;RemoteLogMetadataManager&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;RemoteLogManager&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6ffe5286-c491-4dd9-9573-0439c7790602&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We introduced two pluggable components within the storage layer called &lt;em&gt;RemoteStorageManager&lt;/em&gt; and &lt;em&gt;RemoteLogMetadataManager&lt;/em&gt;. These can be implemented by developers based on their targeted storage systems and plugged into their Kafka environments.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c3bb416c-1811-4b68-bd52-f28cc63a8d4f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;em&gt;RemoteStorageManager&lt;/em&gt; interface provides the actions for remote log segments that include copy, fetch, and delete from remote storage.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7c9686e1-1c96-4cd4-81fc-4e4651a9ca6e&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;em&gt;RemoteLogMetadataManager&lt;/em&gt; interface provides the lifecycle operations of metadata about remote log segments with strongly consistent semantics. There is a default implementation that uses an internal topic. Users can plugin their implementation if they intend to use another system to store remote log segment metadata.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;10f1a733-e2e1-4da9-9e2b-f0575b8179ce&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;em&gt;RemoteLogManager&lt;/em&gt; is a logical layer responsible for managing the life cycle of remote log segments. That includes:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;cfbe1efc-e968-4d3c-a129-657cab42d2c5&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Copying segments to the remote storage&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Cleaning up of expired segments in the remote storage&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Fetching the data from remote storage&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6085e748-3614-425e-a85e-1814e32e68d3&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;It also uses the pluggable remote storage components as and when needed. Each remote log segment is identified with a unique identifier called &lt;em&gt;RemoteLogSegmentId&lt;/em&gt;, even for the same topic partition and offsets.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1b79721a-afd5-45be-aa53-a361a4db4016&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;f9f19038-588b-4ba3-b4f1-61bf5bd2c67e&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-copying-segments-to-remote-storage&#34;&gt;Copying Segments to Remote Storage&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6501289f-c0a1-44f9-8bd8-c47cc0d57d36&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Each topic partition stores data in a logical log, which contains a sequence of physical log segments with the respective auxiliary files like segment indexes, producer state snapshots, and leader epoch checkpoints. Each partition replica creates these log segments, flushes them to disk and rolls over the segment based on segment roll configurations based on size or time. A log segment is eligible if its end offset is less than the &lt;em&gt;last-stable-offset&lt;/em&gt; of the partition. The broker acting as a leader for a topic partition is responsible for copying the eligible log segments to the remote storage. It copies the log segments from the earliest segment to the latest segment in a sequence. It uses &lt;em&gt;RemoteStorageManager&lt;/em&gt; for copying the segment with its indexes like offset, timestamp, producer snapshot, and its respective leader epoch cache. It also adds and updates entries in &lt;em&gt;RemoteLogMetadataManager&lt;/em&gt; with respective states for each copied segment.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;595ecbe5-36d6-43dc-9fe1-0c740e87c7e5&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The below diagram shows the sequence of copying the segments by maintaining local and remote log segments:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;db6e0950-4607-4d3f-9176-15c6f1f3552e&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;9e0b7194-32dc-4f35-96f9-3c9aea1767ac&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXcf2ufqsgcmWb4xf9M4813H55wCn9NC_n8HxCRK5nOT12LvqY5GNmRP_Rh4fqfiDk0SYdJ-63XaxZU5bTrleU-Ap77XBl0eyvjYc1_RIME_6AxlIGXWu9oLOoa3j9PQWyICHXjeOqISivV5Rcx2AhuAHGaU?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 5: The above diagram depicts a topic partition’s log segments with their respective start offsets. Before tiered storage is enabled, there will not be any segments in the remote storage.&amp;nbsp;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8578077d-7ecc-44cf-b2f0-ee21c603f836&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;c14dd36f-9fea-4da5-902f-1e4de0392748&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXc26wPlPeq7XR91GrM_6-QfWh0y6rKGCpGvA1islRticBFGAx33pR0Wm5cMl8OZSoDFm1RNKtpNcRKlj6Bcvuke-cdXBhNEGImxFphNDUBYoI3zb0XTYUek87oPOzV7OfcLoO86FkTeqyFrgFZpfzmAKT0?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 6: The above diagram depicts the eligible segments started copying to remote storage after tiered storage is enabled for that topic.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a33e00c6-209c-44cb-91ac-5222d96c8ab9&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1091633,&amp;quot;sizeSlug&amp;quot;:&amp;quot;full&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;055f601e-69cd-4a34-b281-14623b69c018&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;899&#34; height=&#34;333&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/07/Figure7.png&#34; alt=&#34;&#34; class=&#34;wp-image-1091633&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=899,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/07/Figure7.png 899w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/07/Figure7.png 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/07/Figure7.png 768w&#34; sizes=&#34;(max-width: 899px) 100vw, 899px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 7: The above diagram depicts some of the segments in the local storage were deleted based on the local retention configuration. We can see that segments earlier to offset 300 were deleted, but those segments are available in remote storage.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;47e9b3a2-d752-4c0a-b5b3-c66e7a0fcbf4&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;1058e67b-5adb-4dac-9629-89c807ae2bc7&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-cleaning-up-of-remote-segments&#34;&gt;Cleaning up of Remote Segments&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;035f67ed-dda2-4d78-bbf0-cbf76a605f64&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;As mentioned earlier, each topic will have a retention configuration based on size and time for both local data and remote data. Remote data is cleaned up at regular intervals by computing the eligible segments by a dedicated thread pool. This is different from the asynchronous cleaning up of the local log segments. When a topic is deleted, cleaning up of remote log segments is done asynchronously and it will not block the existing delete operation or recreate a new topic.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9d0dbe68-efc5-4c44-93c5-b07b115f3954&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;990b7b23-7491-49d7-a00a-1d9f3469b53b&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXczW4_RY_MyEEv6A1X0Rw2k7Yr-bPzt139veWuSaeGKqD_27xKyhqivZW609v4GUADtafNrZBmdzC9S9xj72tOTtqbKl9n_ivg9vkIdTJb4Lt7sK7I6UNt20kjrDUP2dwODaVr7rERXZgMfeazr9nxKJhe8?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 8: The above diagram depicts the cleaning up of remote log segments based on the complete log retention configuration. Here, segments earlier to offset 200 were deleted.&amp;nbsp;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c74af8b0-ee98-426a-893e-788c5b3562cc&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;9df2b72c-e610-471d-a7bb-752f19e9e225&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-fetching-segments-from-remote-storage&#34;&gt;Fetching Segments from Remote Storage&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1139aefd-e5bd-423e-9902-ebc767f49ba0&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;When a consumer fetch request is received and it is only available only in remote storage, then it is served using a dedicated thread pool. If the targeted offset is available in the broker’s local storage, then it is served using the existing local fetch mechanism. So, a broker separates the local reads from remote reads and they will not block each other.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4d905c15-c255-49f9-b98c-2fd8fb2e2d4a&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;em&gt;RemoteLogManager&lt;/em&gt; determines the targeted remote segment based on the desired offset and leader epoch by looking into the metadata store using &lt;em&gt;RemoteLogMetadataManager&lt;/em&gt;. It uses &lt;em&gt;RemoteStorageManager&lt;/em&gt; to find the position within the segment and start fetching the desired data.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0af941c5-ea10-4ee5-9180-0fa2f7d5be33&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;width&amp;quot;:&amp;quot;700px&amp;quot;,&amp;quot;height&amp;quot;:&amp;quot;auto&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;9289e088-db11-4e29-86df-02a1996c879d&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXfCCN3aludPERABf77NGITGxCPFcslvI11RammENhBCFoxUSl4XtWKzILkalB2GRWE4MO6WxBxw0QWLV8shK8Y1IVbUKUAQueS3mnZLbVx1E-T_rq_udar088WHjkWVIEt7xhf2xq5tCNBwZrsk4PuzIli8?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 9: Remote fetch path.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e8bfa664-6413-43d2-ac3c-06d4c632a8d8&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;02f4064f-5abd-43a4-a24e-9ac92c32faa2&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-follower-replication&#34;&gt;Follower Replication&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8a9f7dc7-6191-48fc-8184-b987a9abfde7&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Followers replicate the data from a leader to become an in-sync replica. They need to maintain the message lineage across a sequence of log segments as the leader. They may also do truncation of the segments if needed to maintain the message ordering.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;26775e4f-0ecd-4026-b6bb-79139de3d112&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;With tiered storage, follower replicas need to replicate the segments that are available on the leader’s local storage. Each log also needs auxiliary data like leader epoch state and producer-ID snapshots. So, a follower needs to build this auxiliary data before it starts fetching any messages from the leader. The follower fetch protocol makes sure to maintain the consistency and ordering of messages across all the replicas irrespective of changes in the cluster like broker replacements, failures, etc. If you are interested in understanding the inner workings of the enhanced follower fetch protocol, you can read it in the &lt;a href=&#34;https://cwiki.apache.org/confluence/display/KAFKA/KIP-405%3A+Kafka+Tiered+Storage#KIP405:KafkaTieredStorage-FollowerReplication&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;original document&lt;/a&gt; to understand the detailed design and how it handles several scenarios.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;5cf5ae52-b9e7-4d38-b2a6-d2346e2d9e75&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-conclusion&#34;&gt;Conclusion&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ed0dbc6e-6b12-4836-b874-e1a7425c4815&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In this blog, we covered an introduction and high-level architecture of tiered storage at Uber. If you are interested in more details, you can read the detailed design in &lt;a href=&#34;https://cwiki.apache.org/confluence/display/KAFKA/KIP-405%3A+Kafka+Tiered+Storage&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;KIP-405&lt;/a&gt;. Most of this work was done collaborating with the Apache Kafka community. The major part of this feature is available as early access in Apache Kafka 3.6.0.&amp;nbsp; This feature has been running in production for ~1-2 years in different workloads respectively. In the next part of this blog series we will cover our production experience and how it helped with better reliability, scalability, and efficiency of our clusters.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;fontSize&amp;quot;:&amp;quot;small&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;3b7d71e6-2de6-46a6-8a92-a754b708a278&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34; class=&#34;has-small-font-size&#34;&gt;Apache®, Apache Kafka™, and Kafka™ are either registered trademarks or trademarks of the Apache Software Foundation in the United States and/or other countries. No endorsement by The Apache Software Foundation is implied by the use of these marks.&lt;/p&gt;】&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:1,&#34;hash&#34;:&#34;433c69f8-24e4-4e25-8a58-c3011be3d1bb&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-introduction&#34;&gt;简介&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;b3315f9e-7720-4fae-a737-4602be48fcf0&#34;,&#34;dropCap&#34;:false}&#34;&gt;Apache Kafka®是 Uber 技术堆栈的基石。它在支持多个关键用例方面发挥着重要作用，并且是 Uber 批处理和实时系统的基础。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;bae21b7b-4f98-483f-92f9-60ab827ef689&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;align&#34;:&#34;center&#34;,&#34;hash&#34;:&#34;5fd7c743-bdd7-40d7-9e81-86f4e342f1a4&#34;,&#34;alt&#34; :&#34;&#34;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img 解码=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXePSpSp72unfaVqK7tofbbbOpMaZLJ7qYJ2Es-Chg3CHBeZ9kcJDZ9ouvPRYs-CarI8bAqXs2459rJ0_QrsgBaUwqikE5fw YSianNkl1u6Ehbjz_yH6XuWJGn54P5kCaRSaBrCgeVPN4q2QC_RDu9ag1YgU?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34;referrerpolicy =&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;图 1：Uber 的数据管道。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;bba04fc7-d627-4e13-97a1-c1511775c833&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;213c11a1-ab13-4d60-a5f8-2bf22f25ae86&#34;,&#34;dropCap&#34;:false}&#34;&gt;Kafka 存储代理本地存储上仅附加日志段中的消息。每个主题都可以根据大小或时间配置目标保留。即使各个消费应用程序由于多种原因出现故障或变慢，它也可以保证用户在保留期限或大小内消费数据。集群上的总存储取决于主题分区总数、生产吞吐量和保留配置等因素。 Kafka 代理通常需要更大的存储来支持代理上托管的所需主题分区。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;f27d9aad-98e4-44d8-8c39-d27574431a59&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-motivation-background-behind-project&#34;&gt;项目背后的动机/背景&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;2acf6879-58ec-4dc2-9411-023216a9e7e4&#34;,&#34;dropCap&#34;:false}&#34;&gt;Kafka 集群存储通常通过向集群添加更多代理节点来进行扩展。但这也向集群添加了不必要的内存和 CPU，从而使整体存储成本效率较低编辑将旧数据存储在外部存储器中。由于存储和处理的紧密耦合，具有更多节点的更大集群也会增加部署复杂性并增加运营成本。因此，它带来了与可扩展性、效率和操作相关的几个问题。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;0657efab-21dc-423f-b42f-c4dc1ed5da8d&#34;,&#34;dropCap&#34;:false}&#34;&gt;我们建议使用 Kafka分层存储 (&lt;a href=&#34;https://cwiki.apache.org/confluence/display/KAFKA/KIP-405%3A+Kafka+Tiered+Storage&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;KIP- 405&lt;/a&gt;）以避免代理中存储和处理的紧密耦合。它提供两层存储，称为本地存储和远程存储。这两个层可以根据各自的用例有各自的保留策略。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;7bb99c16-9f01-4606-9393-18634deb8b8c&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;width&#34;:&#34;700px&#34;,&#34;height&#34;:&#34;auto&#34;,&#34;align&#34;:&#34;center&#34;,&#34;hash&#34; :&#34;e25cccec-32e4-4c15-976a-4a4725861800&#34;,&#34;alt&#34;:&#34;&#34;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img 解码=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent. com/docsz/AD_4nXdrkDm5z8lSbIzR0Xure8R4qrXa8JqczXMcNyQs17yede4tKZScrbVWTc4PjScxs-k_qrcks2cLmf2nOJi9x4tf2Zyzyql2Ql7jA3Ty4qNQoth7NeTL9itjkQnaJKIwm3z ZVYUgYXx_2yr4lgyAF-9eLr-i?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34; &gt;图2：Kafka代理与分层存储的端到端交互。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;d3f58e6f-e3fc-4df8-84f2-247071e699aa&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;00272d69-19b6-4d44-b7f1-ab451bbd36af&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-goals&#34;&gt;目标&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;f8ada8a4-3425-4352-bd37-c99f0a8e6291&#34;,&#34;dropCap&#34;:false}&#34;&gt;以下是我们为分层存储设定的主要目标：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;3cd3f2c9-a5d0-44a3-8335-ca7b05d03d38&#34;,&#34;ordered&#34;:false,&#34;values&#34;:&#34; “}”&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;将存储扩展到代理之外&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;ordered&#34;:false,&#34;values&#34;:&#34;&#34;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;内存/页面缓存&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;核心/列表-项目&#34; data-wp-block=&#34;[]&#34;&gt;本地存储&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;远程存储支持（包括 S3/GCS/Azure 等云/对象存储）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;与本地存储类似的持久性和一致性语义&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;隔离读取最新数据和历史数据&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;客户无需进行任何更改&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;轻松调整和配置集群&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;提高运营效率和成本效率&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;f96a808a-53f5-4733-a618-0ed612929034&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;87df347d-17d7-42dc-b9b6-856160fbd93e&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-architecture&#34;&gt;架构&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;f6ceb13c-20bc-44d2-be91-a3cc6b3523ae&#34;,&#34;dropCap&#34;:false}&#34;&gt;已启用 Kafka 集群分层存储配置有称为本地和远程的两层存储。本地层是代理的本地存储，当前存储段。新的远程层是扩展存储，例如HDFS/S3/GCS/Azure。这两个层都将根据大小和时间具有各自的保留配置。本地层的保留期可以从几天显着缩短到几个小时。远程层的保留期可能更长——几天，甚至几个月。对延迟敏感的应用程序会进行尾部读取，并从本地层进行处理，利用 Kafka 高效的页面缓存利用率进行数据检索。另一方面，回填或从故障中恢复等应用程序需要比本地可用数据更旧的数据，这些应用程序是从远程层提供服务的。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;99e485ed-bfbb-4a06-83f3-7781b0ccb009&#34;,&#34;dropCap&#34;:false}&#34;&gt;此方法支持Kafka 集群中存储的可扩展性，无需依赖内存和 CPU 资源，从而将 Kafka 转变为可行的长期存储选项。此外，它还减少了 Kafka 代理的本地存储负担，从而减少了恢复和重新平衡期间要传输的数据。在远程层中可访问的日志段不需要在代理上恢复，并且可以直接从远程层访问。它消除了在延长保留期限时扩展Kafka集群存储和添加新节点的必要性。此外，它还允许显着更长的数据保留时间，无需单独的数据管道将数据从 Kafka 传输到外部存储（许多当前设置中的常见做法）。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;285c094f-9538-44de-9270-4721f1bf1133&#34;,&#34;dropCap&#34;:false}&#34;&gt;分层存储划分主题分区的日志分为两个不同的逻辑组件，称为本地日志和远程日志。本地日志包含本地日志段列表，远程日志包含远程日志段列表。远程日志子系统将每个主题分区的合格段从本地存储复制到远程存储。当段的结束偏移量小于分区的&lt;em&gt;LastStableOffset&lt;/em&gt;时，该段就有资格被复制。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;2d6d304d-aba7-46d5-aa43-bad98a0e13d3&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;align&#34;:&#34;center&#34;,&#34;hash&#34;:&#34;bf09d07e-1d0f-4647-8465-310196ef72ff&#34;,&#34;alt&#34; ：&#34;&#34;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img 解码=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXdDJEudzpCrGDSR9yN0sNZ5YU_AM1ExXihNssXH0d5SGi01nOJ4R6xY0yY7frm6ESriC5o6XFiqQMVSCVDWpRK0l6nFxaF 8CBCdY0ZpN1beZUsmqpSe4VragjX8kjUjh5VXGKMD-g2i9GMOaIJ99if2dJkj?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34;referrerpolicy=&#34; no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;图 3：本地日志偏移量和远程日志偏移量。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;656259a5-41ec-4162-a1a8-fa9680404f3d&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure data-wp-block-name=&#34;core/table&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;970a47e8-729d-4286-a17f-307c713c9f18&#34;,&#34;hasFixedLayout&#34;:false,&#34;head&#34;:[ ],&#34;body&#34;:[],&#34;foot&#34;:[]}&#34; class=&#34;wp-block-table&#34;&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt; Lz = 本地日志结束偏移量&lt;/td&gt;&lt; td&gt;&lt;/td&gt;&lt;td&gt;Lx = 本地日志起始偏移量 &lt;/td&gt;&lt;td&gt;Ly = 最后稳定偏移量(LSO)&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure data-wp-block-name=&#34;core/table&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;c7fa71b6-1b3f-414b-9d7d-8967a9a41e7a&#34;,&#34;hasFixedLayout&#34;:false,&#34;head&#34;:[ ],&#34;body&#34;:[],&#34;foot&#34;:[]}&#34; class=&#34;wp-block-table&#34;&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;Ry = 远程日志结束偏移&lt;/td&gt;&lt; td&gt;Rx = 远程日志起始偏移&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;em&gt;Lz &gt;= Ly &gt;= Lx 且 Ly &gt;= Ry &gt;= Rx&lt;/em&gt;&lt;/td&gt;&lt;td &gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;cdfcf4f5-b74b-4219-ab12-4bb78c78a00a&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator”有-alpha-通道-不透明度&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;a1242f90-4a1d-4f87-9dc7-e49627a2062a&#34;,&#34;dropCap&#34;:false}&#34;&gt;Apache Kafka 存储子系统维护主题分区的本地和远程日志段的上述偏移量约束。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;b4c968f9-e76a-4c83-a966-e0dae7131168&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;width&#34;:&#34;700px&#34;,&#34;height&#34;:&#34;auto&#34;,&#34;align&#34;:&#34;center&#34;,&#34;hash&#34; :&#34;f687a646-355f-4412-9ad8-f793d9942d75&#34;,&#34;alt&#34;:&#34;&#34;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img 解码=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent. com/docsz/AD_4nXcnNa5SMjEkpYEOgrEV8WQaKzXNhUFy5I1iuFKcHifODuPUg26arhCP8wvWpPsm7onOA8jTn2IS7_tTF9VXmg2NHC2p5IPSFLXw39fP8b4c47ksowG9dYI-iyFHE2szvRfNMn-QBQc 4s_lgOg0tMYH3sKw?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;图图4：Kafka分层存储组件的高层架构。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;a7ef1ee3-e8df-4942-b3ac-a88b2ec5feca&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;d568d925-c3a2-4eed-ab17-976503458642&#34;,&#34;dropCap&#34;:false}&#34;&gt;上图提供了新架构和新引入组件的高级概述：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;9c25ec3d-7751-4e49-9a9d-183df57a2782&#34;,&#34;ordered&#34;:false,&#34;values&#34;:&#34; “}”&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;RemoteStorageManager&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;RemoteLogMetadataManager&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;RemoteLogManager&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;6ffe5286-c491-4dd9-9573-0439c7790602&#34;,&#34;dropCap&#34;:false}&#34;&gt;我们引入了两个存储层中的可插入组件称为RemoteStorageManager 和RemoteLogMetadataManager。这些可以由开发人员根据他们的目标存储系统来实现，并插入到他们的 Kafka 环境中。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;c3bb416c-1811-4b68-bd52-f28cc63a8d4f&#34;,&#34;dropCap&#34;:false}&#34;&gt;&lt;em&gt; RemoteStorageManager接口提供远程日志段的操作，包括从远程存储复制、获取和删除。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;核心/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;7c9686e1-1c96-4cd4-81fc-4e4651a9ca6e&#34;,&#34;dropCap&#34;:false}&#34;&gt;&lt;em&gt;RemoteLogMetadataManager&lt;/em&gt;接口提供元数据的生命周期操作关于具有强一致语义的远程日志段。如果用户打算使用另一个系统来存储远程日志段元数据，则可以使用一个默认实现。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;10f1a733-e2e1-4da9-9e2b-f0575b8179ce&#34;,&#34;dropCap&#34;:false}&#34;&gt;&lt;em&gt; RemoteLogManager是一个逻辑层，负责管理远程日志段的生命周期。其中包括：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;cfbe1efc-e968-4d3c-a129-657cab42d2c5&#34;,&#34;ordered&#34;:false,&#34;values&#34;:&#34; “}”&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;将段复制到远程存储&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;清理远程存储中的过期段&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;从远程存储获取数据&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;6085e748-3614-425e-a85e-1814e32e68d3&#34;,&#34;dropCap&#34;:false}&#34;&gt;它还使用需要时可插拔远程存储组件。每个远程日志段都使用名为 &lt;em&gt;RemoteLogSegmentId&lt;/em&gt; 的唯一标识符进行标识，即使对于相同的主题分区和偏移量也是如此。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;1b79721a-afd5-45be-aa53-a361a4db4016&#34;,&#34;opacity&#34;:&#34;alpha 通道&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;f9f19038-588b-4ba3-b4f1-61bf5bd2c67e&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-copying-segments-to-remote-storage&#34;&gt;将段复制到远程存储&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;6501289f-c0a1-44f9-8bd8-c47cc0d57d36&#34;,&#34;dropCap&#34;:false}&#34;&gt;每个主题分区将数据存储在逻辑日志中，其中包含一系列物理日志段以及相应的辅助文件，例如段索引、生产者状态快照和领导者纪元检查点。每个分区副本都会创建这些日志段，将它们刷新到磁盘，并根据基于大小或时间的段滚动配置滚动该段。如果日志段的结束偏移量小于分区的&lt;em&gt;last-stable-offset&lt;/em&gt;，则该日志段是合格的。充当主题分区领导者的代理负责将符合条件的日志段复制到远程存储。它将日志段按顺序从最早的段复制到最新的段。它使用RemoteStorageManager来进行协作将段及其索引（如偏移量、时间戳、生产者快照及其各自的领导纪元缓存）进行映射。它还在 &lt;em&gt;RemoteLogMetadataManager&lt;/em&gt; 中添加和更新条目以及每个复制段的各自状态。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;595ecbe5-36d6-43dc-9fe1-0c740e87c7e5&#34;,&#34;dropCap&#34;:false}&#34;&gt;下图显示通过维护本地和远程日志段来复制段的顺序：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;db6e0950-4607-4d3f-9176-15c6f1f3552e&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;align&#34;:&#34;center&#34;,&#34;hash&#34;:&#34;9e0b7194-32dc-4f35-96f9-3c9aea1767ac&#34;,&#34;alt&#34; :&#34;&#34;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img 解码=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXcf2ufqsgcmWb4xf9M4813H55wCn9NC_n8HxCRK5nOT12LvqY5GNmRP_Rh4fqfiDk0SYdJ-63XaxZU5bTrleU-Ap77 XBl0eyvjYc1_RIME_6AxlIGXWu9oLOoa3j9PQWyICHXjeOqISivV5Rcx2AhuAHGaU?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34;referrerpolicy =&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;图 5：上图描绘了主题分区的日志段及其各自的起始偏移量。在启用分层存储之前，远程存储中不会有任何段。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;8578077d-7ecc-44cf-b2f0-ee21c603f836&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;align&#34;:&#34;center&#34;,&#34;hash&#34;:&#34;c14dd36f-9fea-4da5-902f-1e4de0392748&#34;,&#34;alt&#34; :&#34;&#34;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img 解码=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXc26wPlPeq7XR91GrM_6-QfWh0y6rKGCpGvA1islRticBFGAx33pR0Wm5cMl8OZSoDFm1RNKtpNcRKlj6Bcvuke-cdXB hNEGImxFphNDUBYoI3zb0XTYUek87oPOzV7OfcLoO86FkTeqyFrgFZpfzmAKT0?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34;referrerpolicy =&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;图 6：上图描述了在为该主题启用分层存储后，符合条件的段开始复制到远程存储。&lt;/figcaption&gt;&lt;/figure &gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;a33e00c6-209c-44cb-91ac-5222d96c8ab9&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;id&#34;:1091633,&#34;sizeSlug&#34;:&#34;full&#34;,&#34;linkDestination&#34;:&#34;none&#34;,&#34;align&#34;:&#34;中心&#34;,&#34;哈希&#34;:&#34;055f601e-69cd-4a34-b281-14623b69c018&#34;,&#34;alt&#34;:&#34;&#34;}&#34; class=&#34;aligncenter size-full&#34;&gt;&lt;img 加载=&#34;lazy&#34; 解码=&#34;async&#34; width=&#34;899&#34; height=&#34;333&#34; src=&#34;https:// /blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/07/Figure7.png&#34; alt=&#34;&#34; 类=&#34;wp-image-1091633&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=899,quality=80,onerror=redirect,format=auto/wp-content/uploads /2024/07/Figure7.png 899w，https://blog.uber-cdn.com/cdn-cgi/image/width=300，quality=80，onerror=redirect，format=auto/wp-content/uploads/ 2024/07/Figure7.png 300w，https://blog.uber-cdn.com/cdn-cgi/image/width=768，quality=80，onerror=redirect，format=auto/wp-content/uploads/2024 /07/Figure7.png 768w&#34;sizes=&#34;(max-width: 899px) 100vw, 899px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;图 7：上图描绘了一些根据本地保留配置删除了本地存储中的段。我们可以看到偏移量 300 之前的段已被删除，但这些段在远程存储中可用。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;47e9b3a2-d752-4c0a-b5b3-c66e7a0fcbf4&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;1058e67b-5adb-4dac-9629-89c807ae2bc7&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-cleaning-up-of-remote-segments&#34;&gt;清理远程段&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;035f67ed-dda2-4d78-bbf0-cbf76a605f64&#34;,&#34;dropCap&#34;:false}&#34;&gt;如前所述，每个主题都会有一个基于本地数据和远程数据的大小和时间的保留配置。通过专用线程池计算符合条件的段，定期清理远程数据。这与本地日志段的异步清理不同。删除主题时，远程日志段的清理是异步完成的，不会阻塞现有的删除操作或重新创建新主题。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;9d0dbe68-efc5-4c44-93c5-b07b115f3954&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;align&#34;:&#34;center&#34;,&#34;hash&#34;:&#34;990b7b23-7491-49d7-a00a-1d9f3469b53b&#34;,&#34;alt&#34; ：&#34;&#34;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img 解码=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXczW4_RY_MyEEv6A1X0Rw2k7Yr-bPzt139veWuSaeGKqD_27xKyhqivZW609v4GUADtafNrZBmdzC9S9xj72tOT tqbKl9n_ivg9vkIdTJb4Lt7sK7I6UNt20kjrDUP2dwODaVr7rERXZgMfeazr9nxKJhe8?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34;referrerpolicy=&#34; no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;图 8：上图描述了基于完整日志保留配置的远程日志段的清理。此处，偏移量 200 之前的段被删除。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;c74af8b0-ee98-426a-893e-788c5b3562cc&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;9df2b72c-e610-471d-a7bb-752f19e9e225&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-fetching-segments-from-remote-storage&#34;&gt;从远程存储中获取段&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;1139aefd-e5bd-423e-9902-ebc767f49ba0&#34;,&#34;dropCap&#34;:false}&#34;&gt;当消费者接收到获取请求并且它仅在远程存储中可用，然后使用专用线程池提供服务。如果目标偏移量在代理的本地存储中可用，则使用现有的本地获取机制提供服务。因此，代理将本地读取与远程读取分开，并且它们不会互相阻塞。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;4d905c15-c255-49f9-b98c-2fd8fb2e2d4a&#34;,&#34;dropCap&#34;:false}&#34;&gt;&lt;em&gt; RemoteLogManager&lt;/em&gt;通过使用&lt;em&gt;RemoteLogMetadataManager&lt;/em&gt;查看元数据存储，根据所需的偏移量和领导纪元确定目标远程段。它使用 RemoteStorageManager 来查找段内的位置并开始获取所需的数据。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;0af941c5-ea10-4ee5-9180-0fa2f7d5be33&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;width&#34;:&#34;700px&#34;,&#34;height&#34;:&#34;auto&#34;,&#34;align&#34;:&#34;center&#34;,&#34;hash&#34; :&#34;9289e088-db11-4e29-86df-02a1996c879d&#34;,&#34;alt&#34;:&#34;&#34;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img 解码=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent. com/docsz/AD_4nXfCCN3aludPERABf77NGITGxCPFcslvI11RammENhBCFoxUSl4XtWKzILkalB2GRWE4MO6WxBxw0QWLV8shK8Y1IVbUKUAQueS3mnZLbVx1E-T_rq_udar088WHjkWVIEt7xhf2xq5tCNBwZrs k4PuzIli8?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;图 9:远程获取路径。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;e8bfa664-6413-43d2-ac3c-06d4c632a8d8&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;02f4064f-5abd-43a4-a24e-9ac92c32faa2&#34;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-follower-replication&#34;&gt;关注者复制&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;8a9f7dc7-6191-48fc-8184-b987a9abfde7&#34;,&#34;dropCap&#34;:false}&#34;&gt;关注者复制来自领导者的数据成为同步副本。他们需要作为领导者维护一系列日志段中的消息沿袭。如果需要维持消息顺序，他们还可以截断段。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;26775e4f-0ecd-4026-b6bb-79139de3d112&#34;,&#34;dropCap&#34;:false}&#34;&gt;使用分层存储，追随者副本需要复制领导者本地存储上可用的段。每个日志还需要辅助数据，例如领导者纪元状态和生产者 ID 快照。因此，追随者需要在开始从领导者那里获取任何消息之前构建此辅助数据。 follower fetch 协议确保维护所有副本之间消息的一致性和顺序，而不管集群中的更改（如代理替换、故障等）。如果您有兴趣了解增强型 follower fetch 协议的内部工作原理，您可以在 &lt;a href=&#34;https://cwiki.apache.org/confluence/display/KAFKA/KIP-405%3A+Kafka+Tiered+Storage#KIP405:KafkaTieredStorage-FollowerReplication&#34; target=&#34;_blank&#34; rel= 中阅读&#34;noreferrer noopener&#34;&gt;原始文档&lt;/a&gt;，了解详细设计以及它如何处理多种场景。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:1,&#34;hash&#34;:&#34;5cf5ae52-b9e7-4d38-b2a6-d2346e2d9e75&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-conclusion&#34;&gt;结论&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;ed0dbc6e-6b12-4836-b874-e1a7425c4815&#34;,&#34;dropCap&#34;:false}&#34;&gt;在此博客中，我们介绍了 Uber 分层存储的简介和高级架构。如果您对更多细节感兴趣，可以阅读 &lt;a href=&#34;https://cwiki.apache.org/confluence/display/KAFKA/KIP-405%3A+Kafka+Tiered+Storage&#34; target= 中的详细设计“_blank”rel =“noreferrer noopener”&gt;KIP-405&lt;/a&gt;。大部分工作是与 Apache Kafka 社区合作完成的。此功能的主要部分可在 Apache Kafka 3.6.0 中提前访问。  该功能已分别在不同的工作负载下在生产环境中运行了约 1-2 年。在本博客系列的下一部分中，我们将介绍我们的生产经验以及它如何帮助我们提高集群的可靠性、可扩展性和效率。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;fontSize&#34;:&#34;小&#34;,&#34;hash&#34;:&#34;3b7d71e6-2de6-46a6-8a92-a754b708a278&#34;,&#34;dropCap&#34; :false}&#34; class=&#34;has-small-font-size&#34;&gt;Apache®、Apache Kafka™ 和 Kafka™ 是 t 的注册商标或商标美国和/或其他国家的 Apache 软件基金会。使用这些标记并不暗示 Apache 软件基金会的认可。&lt;/p&gt;</description>
      <pubDate>Mon, 01 Jul 2024 10:58:33 +0000</pubDate>
    </item>
    <item>
      <title>【Personalized Marketing at Scale: Uber’s Out-of-App Recommendation System】大规模个性化营销：Uber 的应用外推荐系统</title>
      <link>https://www.uber.com/blog/personalized-marketing-at-scale/</link>
      <description>【&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;ed846de2-1f8d-4c8a-ac75-16404c880b37&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-introduction&#34;&gt;Introduction&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;cceddfbd-0b50-4e8e-84be-d756460ae988&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Out-of-app (OOA) communication (such as email, push, and SMS) is an important growth lever at Uber. It allows marketers, product owners, and operation teams to connect with users on a plethora of topics, including user promotions, new and favorite restaurants, etc. Building a system to personalize these communications presents unique and exciting challenges. In this blog post, we walk through these challenges and our journey in tackling them.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;03e1b597-f2a8-4f0b-a775-851cd064f322&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9ebb35aa-f3b0-43a7-b17d-5cbfc2d79f7d&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-challenges-nbsp&#34;&gt;Challenges&amp;nbsp;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;67137cec-8a0f-490d-be5c-6cda7ac5f415&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-lack-of-recommendation-context&#34;&gt;Lack of Recommendation Context&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5d2b2ed0-45cf-47de-b769-f4fc911d0509&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The first challenge is the lack of user context in OOA communications. At the core of these personalized communications are restaurant recommendations and merchant offer recommendations. These recommendations are highly local (i.e., users can only order from nearby restaurants). In standard product recommendation systems, ‌users are shown recommendations as they enter the app. Both the user’s location and intentions are often known. On the other hand, recommendations in OOA communications are pushed proactively to ‌users for nondeterministic future viewing. Ensuring that recommendations stay relevant, even in the absence of critical user context, is a major challenge for our system.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;e874f2c8-2e58-4694-99e4-04ebe7da8e26&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-incorporating-campaign-objectives&#34;&gt;Incorporating Campaign Objectives&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0171d53d-19bd-4ce8-bdd2-eedae77753c6&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The second challenge is that recommendations in OOA communications need to be relevant to both the end users and the context of the communications. An email on membership benefits should include exclusive restaurant’s promotions, while an email celebrating the city’s neighborhoods should highlight locals’ favorite restaurants.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;27ee3c76-2839-4ca1-b5c6-5dc89a45f0c6&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-system-costs&#34;&gt;System Costs&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;eaab7c9d-c1d4-4a3d-b1e8-22bf8b90696d&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Lastly, being able to tackle the above challenges at scale and in a cost-effective manner is another challenge to us. The system is currently responsible for over 4 billion personalized messages to our users across all geographic areas and lines of business. There are three major cost areas for producing OOA recommendations:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;12156d58-31bd-4f26-b70f-02fd4aec1613&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;Online Feature Store&lt;/strong&gt;: This involves expenses related to the storage, retrieval, and management of features used in the recommendation system. The online feature store facilitates the quick access and processing of user, item, and interaction features, which is critical for real-time personalization. The costs here are driven by the need for scalable, high-performance databases that can handle large volumes of data with low latency.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;Online Prediction:&lt;/strong&gt; Running complex models for real-time predictions incurs significant costs. These models, which are more sophisticated than those in our previous architecture, require substantial computational resources for continuous data processing and analysis. The expenses associated with the computing power necessary to run these models, including server costs, and the maintenance and scaling of additional computational resources for experiment’s purpose.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;High Throughput and Broad Audiences:&lt;/strong&gt; The expansion to cater to a larger audience and handle higher message throughput further escalates costs. As the system scales to accommodate more users and a wider range of marketing scenarios, the infrastructure must also scale. To process the real-time personalization of more than billions of messages, the necessary throughput can reach 10 times that of in-app recommendation systems.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8a402395-ce3c-4ed9-98ae-d7400cb6667f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Managing these costs effectively is crucial for the sustainability of our new architecture, necessitating a balance between performance, scalability, and cost-efficiency. Techniques like optimizing algorithms for better performance, utilizing cost-effective auto-scaling infrastructure, and optimizing feature strategies can significantly aid controlling these expenses.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;bfe5520e-eb36-4acd-909b-47bde72db240&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0f440374-91eb-437a-8e22-4c19a2e4f18f&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-nbsp-architecture-overview-nbsp&#34;&gt;&amp;nbsp;Architecture Overview&amp;nbsp;&lt;/h2&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;width&amp;quot;:&amp;quot;700px&amp;quot;,&amp;quot;height&amp;quot;:&amp;quot;auto&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;2de9b098-7848-4076-afba-9713096e01a9&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXfgrQtPFPJjdzvNKpMosLG74j6oOD8dEA602cpHo6_OeMD6HJ-2NJBPXMWB5ApZFJASs1SRJCniWle1RK8JOjxusx10elXiP1mdX2oHl6sdV17iS2d-Ijaz4z4P0_QNXdyx5bPRRD-1FXDVhpS9ghLK0q8?key=DgmRI0YIzHZkraGCSk9ZeA&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 1: Marketing Personalizer Architecture.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;cbaa68b5-c46f-4152-b4e3-60f872581454&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5e2ff2bb-f82f-4eca-baf2-576608e00782&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Candidate Retrieval&lt;/strong&gt;: This process involves identifying a broad set of potential recommendations for each user. Using a first-pass ranking algorithm based on location, the system scans through a vast pool of items, considering various factors like user history, store popularity, and contextual data to retrieve a preliminary list of candidate recommendations.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;bb2430de-a4de-4de2-9c59-1f84d1443cfc&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;em&gt;Core technology: Local Graph (Uber’s Knowledge Graph)&amp;nbsp;&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;52036fc8-9616-431c-8e8e-15c6c21f16e4&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Blending&lt;/strong&gt;: Once candidates are retrieved, they undergo a filtering and blending process. The step weeds out less relevant or undesirable options based on predefined business rules and criteria. It ensures that the final recommendations align with both the user’s preferences and any business constraints.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a275add5-873c-42ee-882e-4e48760d38c6&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;em&gt;Core technology: &lt;/em&gt;&lt;a href=&#34;https://github.com/google/cel-spec&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;&lt;em&gt;CEL-based&lt;/em&gt;&lt;/a&gt;&lt;em&gt; rule engine&lt;/em&gt; (using &lt;a href=&#34;https://www.uber.com/blog/flipr/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Flipr&lt;/a&gt;)&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7bd3044a-9b81-4f15-8315-de39752a0266&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Ranking&lt;/strong&gt;: In the ranking stage, the candidates are ranked to determine their order of presentation to the user. This ranking is based on a full set of ranking features that evaluate the relevance of each item to the user’s context and preferences. The aim is to position the most pertinent and appealing recommendations at the top, maximizing the likelihood of user engagement.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5502e588-bf09-4ecc-a8ec-46a6c3a68349&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;em&gt;Core technology: &lt;a href=&#34;https://www.uber.com/blog/palette-meta-store-journey/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Palette Feature Store&lt;/a&gt;, &lt;a href=&#34;https://www.uber.com/blog/michelangelo-machine-learning-platform/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Michelangelo&lt;/a&gt;&amp;nbsp;&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3f34a9c3-40c0-40fa-b569-fd478055ea9c&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6163dfc0-f673-43d0-9ed3-6574b234f47e&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-solution-formulation-nbsp&#34;&gt;Solution Formulation&amp;nbsp;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7c96cb0a-f90f-422d-9ac1-b73cd0a32aef&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;To address our three primary challenges, we introduced enhancements to each portion of our architecture to provide relevant and thematically consistent content to users in an efficient and scalable system. We discuss each of these enhancements in detail below.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;49b01814-2a13-4341-b689-c32430a241a2&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;b74a42c6-e441-470f-94ca-0a009c268465&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-candidate-list-generation-nbsp&#34;&gt;Candidate List Generation&amp;nbsp;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ccdd7bcf-fca4-424d-8c0b-cb3d98a1d325&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;A unique portion of recommendations on Uber Eats is candidate lists that are highly localized to a user’s location. When users open the Uber Eats app, they are recommended restaurants, grocery, and retail stores that can deliver to either their current location or their most recent order location. For our OOA recommendation system, this crucial context is missing from our candidate list generation. We developed two solutions to overcome this impediment.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;867291d7-4276-4314-b997-9a97c187790f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;For general recommendation use cases, we developed an ML solution to determine which neighborhood a user was most likely to receive an order in next. As our system supports marketing campaigns for frequent, infrequent, and new Uber Eats users, this ML solution required integration of high and low throughput signals from both the Uber Eats and Uber apps over multiple-year time horizons. To ensure the scalability of this solution to the hundreds of millions of Uber users campaign owners communicate with, we focused on reducing these signals to a small set of ~10 features which the ML solution utilized to define a user’s next likely order location. With this likely location, user’s candidate lists are generated by finding all restaurants, grocery, or retail stores that deliver to this location.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;91c2b91c-36f0-4466-9d1f-cdc94dc0c322&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;While this base solution provides crucial context for our OOA recommendation system, it does not always provide the correct context for every campaign. In campaign settings where the user is likely traveling (e.g., Airport Trips, Uber Reserve, Uber for Business) the aforementioned ML solution will likely not have the necessary context to reflect the user’s recent behavioral changes. In this setting, we utilize an event-based override which updates the user’s candidate list to contain restaurants, grocery, and retail stores that deliver to their most recent neighborhood. By updating this candidate list, we increase the relevancy of communications for users and provide campaign owners the flexibility to control these candidate lists to ensure thematic consistency for their campaigns.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;22025f48-b703-42d4-8aa8-714960881c7d&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Together, these solutions inject critical user metadata into the user’s candidate list, ensuring our recommendations are relevant to users and reflect their recent behavior. By providing a general ML solution for all Uber users, campaign owners can have confidence that user’s candidate lists are accurate and can accommodate their campaign objectives.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e6acfcde-5908-47b1-9bed-44186846eb9d&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;bff409bf-2801-40e0-8fe2-15b13673bc25&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-first-pass-ranking&#34;&gt;First Pass Ranking&lt;/h3&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;width&amp;quot;:&amp;quot;700px&amp;quot;,&amp;quot;height&amp;quot;:&amp;quot;auto&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;7fc71338-1e9b-4a17-95d7-51cac79d83d0&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXcpvTCnINAXH7xDcMWM5D7jUOEVwOrEsKKugQ4byxZxyT47qLsOM8tcHZwRhy6n-0YCXX4AbYrvS80h2tFTkka94fyYIEZpYxFZ_rrFj5GuBBpvEZlgEkgWSC7Qnrawk0sHnUfLyH4p1OpyapRuYIsUI1IM?key=DgmRI0YIzHZkraGCSk9ZeA&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 2: first-pass ranking.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e19636ed-8eed-45bb-afa0-e4985aff33d0&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;eef1f569-4102-4907-ab17-00a4a866b0c7&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The primary goal of the first-pass ranking is to quickly reduce the set of all eligible candidate merchants to a smaller set of potential merchants for each user. This helps conserve system bandwidth and reduces machine learning-related costs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a404e10f-c69d-4d87-b450-ac79ced27b0f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;After retrieving all the candidates based on the user’s location, we initiate a preliminary filtering process. This phase excludes candidates based on criteria like unavailability and invalid deliverability (such as cross-border merchants).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7e45baef-353d-4708-825c-12ed9b7c08b7&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In certain campaigns, we display a variety of restaurant types. To refine our selection, candidates undergo additional filtering tailored to specific use cases. For example, our primary recommendation strategy is to assess the relevance of candidates based on the user’s past interactions with Uber Eats. We also introduce candidates that are offering promotions, and inspire users by recommending candidates from restaurants they haven’t ordered from but might find appealing.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7cf9b299-8d27-4a19-9152-32931102c91a&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;For each of these use cases, we apply a low-cost scoring function to all eligible candidate merchants. The function is a simple linear combination over a small set of features, including ‌past interactions between the user and merchant. The weights are tuned to maximize the recall metrics.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e1e9c760-cb6a-4e08-8376-d0fea6e5ad55&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Finally, to ensure a varied selection for the user, we run a deduplication process. This step removes candidates belonging to the same parent chain, avoiding repetitive recommendations.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6c9e32e6-116e-42a0-8948-12b945dc3946&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;6d33a86b-c8ea-4b12-a20d-5a727c70fa64&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-second-pass-ranking&#34;&gt;Second Pass Ranking&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;93cb1bfc-14c3-4bc1-a518-b4f4621b2526&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The objective of the second ranking stage is to rank the small set of merchants retrieved from the first-pass ranking to maximize the likelihood of user engagement. To do so, we utilize features that capture a user’s past order history, in-app and out-of-app engagement, and the merchant’s quality, reliability, and affordability. Many of these features are also utilized by the home feed ranking system and are shared via Uber’s Online Feature Store, &lt;a href=&#34;https://www.uber.com/blog/palette-meta-store-journey/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Palette&lt;/a&gt;. By sharing feature sets across recommendation services, we promote parity in the user experience across in-app and out-of-app surfaces. These features are utilized inside a learning-to-rank LTR modeling framework with custom relevancy weights to encourage desirable user behaviors.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9b9ade24-3b90-443e-b035-3ffd92252682&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;While ‌user-centric features are rich for frequent users, they are often not available for new and churned users. As the OOA system caters heavily to the infrequent user segment, we have to rely on long-dated user signals in order to provide good recommendations. Moreover, we need to be able to store and use such signals in a cost-efficient manner. To overcome this challenge with restaurant recommendations, we constructed a lightweight feature set summarizing a user’s cuisine preferences over the entirety of their Uber Eats history. At Uber, we label each restaurant with a set of cuisines that the merchant serves, which we utilize to create a feature vector summarizing the user’s cuisine preferences. We update this feature daily with a Bayesian update logic and upweight recent orders to reflect the user’s recent behavioral changes. Incorporating this feature in our second pass ranking system drove a 4% lift in email’s CTR in recent online experimentation.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a1c3dd21-e4c7-459a-9bab-9ab34e711597&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Many of the features utilized in our second pass ranking system effectively summarize a user’s past order behavior but do not reveal which restaurants a user may be interested in trying next. Due to the geographic constraints of orders on Uber Eats, it can be difficult for collaborative recommendation system techniques to learn restaurant similarity. For example, two restaurants in different neighborhoods may serve similar dishes at similar prices but have no common customers due to their geographic differences. While learning restaurant similarity is difficult through collaborative based approaches, utilizing content based recommendation approaches with the restaurant’s cuisine labels provides an opportunity to learn restaurant similarities and encourages users to explore new restaurants on Uber Eats. We posit that users will be interested in new restaurants that serve cuisines that are similar to cuisines they have ordered in the past. Building on this premise, we conducted an analysis to quantify the similarity between cuisines. We performed spectral clustering on a regularized cuisine co-occurrence matrix that captured which cuisines were frequently served by the same restaurant. From this clustering exercise we found that while there are hundreds of cuisines a merchant can serve, these cuisines fall into a small number of natural groupings. In Figure 3, we visualize the embedding vectors for each cuisine mapped to a two-dimensional space via t-SNE, which highlights these natural cuisine clusters.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e71ad85b-0f8f-447c-ab04-1b2d3ea03ede&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;0a0e33b5-6874-4c16-821a-0e174f469461&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXclTIOVrXS9GosD3MlTmw3WJ6vNDCKLZ5P8yDa5Fru2bv4mhA4sGVo29-KyGWF7GZpO8axvCO52o_w_Xs4IwW_wW3rYodhyYhan-2PRcl5NBdd6mBWGKWIQifmwnWmtHePk-5xBREjN3xNW10pp9C54_As?key=DgmRI0YIzHZkraGCSk9ZeA&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 3: Cuisine categorization based on similarity analysis.&amp;nbsp;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;33a54c0d-7108-4057-9705-1c9b550ca5df&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0f70a1cc-aae9-44d0-967e-6de3fbb43c43&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;These groupings motivated us to smooth each user’s cuisine preference feature according to these cuisine similarities. Utilizing this smoothed feature vector in our second pass ranking system provided our system an exploration lever, encouraging users to try new cuisines similar to cuisines they enjoy while maintaining recommendation relevancy. In addition to this exploration lever, these groupings also provided us an opportunity to reduce system costs. By embedding the cuisine preference feature according to these cuisine groupings, we reduced the size of this feature 10x, mitigating online storage costs while maintaining the majority of the feature’s signal. Moreover, by utilizing a lightweight embedding scheme, we are able to perform this feature embedding efficiently through simple distributed matrix multiplication, which can be carried out in any standard ETL pipeline framework.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;447774ed-d9f0-46fa-a859-0bac001d49ab&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;By building a lightweight feature set summarizing a user’s cuisine preferences across their entire Uber Eats history, we provide crucial context to our second pass ranking model. This context provides our recommendation system with an exploration lever, encouraging users to explore new cuisines and merchants, and ensures that infrequent Uber Eats users receive relevant restaurant recommendations. By embedding these cuisine preference features, we can greatly reduce online storage costs and ensure that the recommendation system can support campaigns targeting any cohort of the Uber user base.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a6cae821-5d45-41bf-aef6-48d4edfa98e3&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;76ebb488-7b65-40ac-ab1a-88f6b96ca159&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-re-ranking-amp-blending-nbsp&#34;&gt;Re-Ranking &amp;amp; Blending&amp;nbsp;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;06c7bba6-99f2-4105-9aee-e9f6225e38da&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;As CRM communication comes from different internal stakeholders, the system needs a mechanism to tailor ‌the embedded recommendations toward different brand strategies and marketing priorities. Hence, we introduce a re-ranking and blending layer post the ML-based second-pass ranking. For example, we allow stakeholders to enhance merchants’ visibility (Figure 4) based on specific marketing strategies.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a0b0297a-639f-4b7d-a344-c6d091834bf5&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;6a83af6f-44cb-45d0-af65-7b0e07253ba0&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXfaBCsP7f9PtQJIas64-wKhFJSRYAN7bn0uOjMvJfrKrAmIK-BN5YuVxqKTy2UWASUp8PwClRpu5GsXceUirADVn2Wpy_I-N3953rek6wl5T1Yxx_pmchFXQFMzWlvSp2EyzPa4ac565MAjz5TaPqNAujEa?key=DgmRI0YIzHZkraGCSk9ZeA&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 4: enhance the visibility of selected merchants.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;559a6e0f-bfa6-4a19-a49b-b94f12375893&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;67ed7887-a83c-41e8-986d-bb8688edef88&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Through our configuration engine, local marketing teams can define their own strategies flexibly and with minimal work. This is enabled by the automated hierarchical configuration merge and override at different geographical region levels. For example, New York City can inherit most of the re-ranking strategies with the US, but the NYC local marketing team can apply some partial overrides on specific parameters. Figure 5 demonstrates the configurations to enhance the selected merchants shown in Figure 4.&lt;/p&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;width&amp;quot;:&amp;quot;700px&amp;quot;,&amp;quot;height&amp;quot;:&amp;quot;auto&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;0873a777-dbb9-4b07-b267-6021290d2a47&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXdJ5NWHGLcrbj4jUtlNt2EQ5D2ZC11o_EJnaOArqzUgVf3-iKqGbyrULBZ5OpxAH_H7OrkQhFrFBn5sNlYOCtq6gW8elbCvzVAPLf7f42NxPVeqDomvf54fiS5myotklOMEPHLi15npddLftZtdb6pGmGrf?key=DgmRI0YIzHZkraGCSk9ZeA&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 5: configurations to enhance selected merchants with hierarchical overrides.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2dac800f-5bb4-4c8e-b06f-53580fd7858e&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;2f2886cd-1104-4288-9426-b09972626633&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-next-steps&#34;&gt;Next Steps&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;09b861ab-c5bc-4d76-8407-84817f05c3eb&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;While much of the early work focused on surfacing merchant recommendations, the need for personalized marketing at Uber extends beyond our delivery business. The next steps for our platform to bring the same personalization capabilities to the other lines of business, particularly Rider and Earner communications. To better serve these new business surfaces, the team has plans to expand, as well as sourcing from partner teams at Uber, our personalized content repository. The new developments include dynamic creatives to unify the personalized recommendations and other marketing creatives; personalized travel recommendations; and personalized earning opportunities to drive marketplace demand and supply.&amp;nbsp;&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a023a443-c2cb-4aa8-b211-d60c4cad2bba&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-acknowledgements&#34;&gt;Acknowledgements&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5084df9e-a3a4-4e68-af96-016201be90c0&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;This would not have been possible without the contribution of multiple Growth and Marketing teams. We’d like to thank the following folks for their contributions: Isabella Huang, Ajit Pawar, Apoorv Sharma, Jennifer Li, Hari Thadakamalla, Cameron Kalegi, Nikhil Anantharaman, Vladimir Schipunov, Denis Perino, Shelley Hatting, April Chu, Nora Murphy, Fernanda Gomes, Abby Blecker, Carolina Aprea, Marie Oquet, Ann Parden, Michael Tam.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;93180c87-77f2-4ab5-824d-f5fa7e71da01&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Special thanks to our tech partners on the LocalGraph team (Jiaxin Lin, Kaymyar Arbabifard, Santosh Golecha), Delivery Intelligence team (Yifan Ma, Tiejun Wang), Michelangelo team (Jin Sun, Paarth Chothani, Nicholas Marcott, Victoria Wu), and Offers &amp;amp; Affordability team (Shirley Ye, Boyang Li, Jun Yao) for helping us design the system and leverage Uber-wide AI building blocks.&lt;/p&gt;】&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:1,&#34;hash&#34;:&#34;ed846de2-1f8d-4c8a-ac75-16404c880b37&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-introduction&#34;&gt;简介&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;cceddfbd-0b50-4e8e-84be-d756460ae988&#34;,&#34;dropCap&#34;:false}&#34;&gt;超出-应用程序（OOA）通信（例如电子邮件、推送和短信）是 Uber 的重要增长杠杆。它允许营销人员、产品所有者和运营团队就大量主题与用户建立联系，包括用户促销、新餐厅和最喜欢的餐厅等。构建一个系统来个性化这些通信提出了独特且令人兴奋的挑战。在这篇博文中，我们将介绍这些挑战以及我们应对这些挑战的历程。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;03e1b597-f2a8-4f0b-a775-851cd064f322&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;9ebb35aa-f3b0-43a7-b17d-5cbfc2d79f7d&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-challenges-nbsp&#34;&gt;挑战&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;67137cec-8a0f-490d-be5c-6cda7ac5f415&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-lack-of-recommendation-context&#34;&gt;缺少推荐上下文&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;5d2b2ed0-45cf-47de-b769-f4fc911d0509&#34;,&#34;dropCap&#34;:false}&#34;&gt;第一个挑战OOA 通信中缺乏用户上下文。这些个性化通信的核心是餐厅推荐和商家报价推荐。这些推荐是高度本地化的（即用户只能从附近的餐馆订购）。在标准产品推荐系统中，用户在进入应用程序时会看到推荐。用户的位置和意图通常都是已知的。另一方面，OOA 通信中的推荐会主动推送给用户，以供不确定的未来观看。即使在没有关键用户上下文的情况下，确保推荐保持相关性也是我们系统面临的一项重大挑战。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;e874f2c8-2e58-4694-99e4-04ebe7da8e26&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-incorporating-campaign-objectives&#34;&gt;纳入活动目标&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;0171d53d-19bd-4ce8-bdd2-eedae77753c6&#34;,&#34;dropCap&#34;:false}&#34;&gt;第二个挑战OOA 通信中的建议需要与最终用户和通信上下文相关。关于会员优惠的电子邮件应包括独家餐厅的促销活动，而电子邮件单元格介绍城市的街区应该突出当地人最喜欢的餐馆。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;27ee3c76-2839-4ca1-b5c6-5dc89a45f0c6&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-system-costs&#34;&gt;系统成本&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;eaab7c9d-c1d4-4a3d-b1e8-22bf8b90696d&#34;,&#34;dropCap&#34;:false}&#34;&gt;最后，能够以具有成本效益的方式大规模应对上述挑战是我们面临的另一项挑战。该系统目前负责向所有地理区域和业务线的用户发送超过 40 亿条个性化消息。生成 OOA 建议的成本主要包括三个方面：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;12156d58-31bd-4f26-b70f-02fd4aec1613&#34;,&#34;ordered&#34;:false,&#34;values&#34;:&#34; “}”&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;在线特征存储&lt;/strong&gt;：这涉及与存储、检索和存储相关的费用管理推荐系统中使用的功能。在线特征存储有助于快速访问和处理用户、项目和交互特征，这对于实时个性化至关重要。这里的成本是由对可扩展、高性能数据库的需求驱动的，这些数据库可以以低延迟处理大量数据。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;在线预测&lt;/strong&gt;：运行复杂模型进行实时预测会产生大量成本。这些模型比我们之前的架构中的模型更加复杂，需要大量的计算资源来进行连续的数据处理和分析。与运行这些模型所需的计算能力相关的费用，包括服务器成本以及用于实验目的的额外计算资源的维护和扩展。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;高吞吐量和广泛的受众&lt;/strong&gt;：为迎合更多受众而进行的扩展处理更高的消息吞吐量会进一步增加成本。随着系统扩展以适应更多用户和更广泛的营销场景，基础设施也必须扩展。要处理超过数十亿条消息的实时个性化，所需的吞吐量可以达到应用内推荐系统的 10 倍。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;8a402395-ce3c-4ed9-98ae-d7400cb6667f&#34;,&#34;dropCap&#34;:false}&#34;&gt;管理这些成本有效对于我们新架构的可持续性至关重要，需要在性能、可扩展性和成本效率之间取得平衡。优化算法以获得更好的性能、利用经济高效的自动扩展基础设施等技术，以及选择优化功能策略可以显着帮助控制这些费用。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;bfe5520e-eb36-4acd-909b-47bde72db240&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;0f440374-91eb-437a-8e22-4c19a2e4f18f&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-nbsp-architecture-overview-nbsp&#34;&gt;架构概述&lt;/h2&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;width&#34;:&#34;700px&#34;,&#34;height&#34;:&#34;auto&#34;,&#34;align&#34;:&#34;center&#34;,&#34;hash&#34; :&#34;2de9b098-7848-4076-afba-9713096e01a9&#34;,&#34;alt&#34;:&#34;&#34;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img 解码=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent. com/docsz/AD_4nXfgrQtPFPJjdzvNKpMosLG74j6oOD8dEA602cpHo6_OeMD6HJ-2NJBPXMWB5ApZFJASs1SRJCniWle1RK8JOjxusx10elXiP1mdX2oHl6sdV17iS2d-Ijaz4z4P0_QNXdyx5bPRRD -1FXDVhpS9ghLK0q8?key=DgmRI0YIzHZkraGCSk9ZeA&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34; &gt;图 1：营销个性化架构。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;cbaa68b5-c46f-4152-b4e3-60f872581454&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;5e2ff2bb-f82f-4eca-baf2-576608e00782&#34;,&#34;dropCap&#34;:false}&#34;&gt;&lt;strong&gt;候选检索：此过程涉及为每个用户确定一组广泛的潜在推荐。该系统使用基于位置的首次通过排名算法，扫描大量商品，考虑用户历史记录、商店受欢迎程度和上下文数据等各种因素，以检索候选推荐的初步列表。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;bb2430de-a4de-4de2-9c59-1f84d1443cfc&#34;,&#34;dropCap&#34;:false}&#34;&gt;&lt;em&gt;核心技术：Local Graph（Uber 的知识图谱）&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;52036fc8-9616-431c-8e8e-15c6c21f16e4&#34;,&#34;dropCap&#34;:false}&#34;&gt;&lt;strong&gt;混合：一旦检索到候选者，它们就会经历过滤和混合过程。该步骤根据预定义的业务规则和标准淘汰不太相关或不需要的选项。它确保最终的建议符合用户的偏好和任何业务限制。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;a275add5-873c-42ee-882e-4e48760d38c6&#34;,&#34;dropCap&#34;:false}&#34;&gt;&lt;em&gt;核心技术：&lt;/em&gt;&lt;a href=&#34;https://github.com/google/cel-spec&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;&lt;em&gt;基于 CEL&lt;/em&gt;&lt;/a&gt;&lt;em&gt; 规则引擎&lt;/em&gt;（使用 &lt;a href=&#34;https: //www.uber.com/blog/flipr/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Flipr&lt;/a&gt;)&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;7bd3044a-9b81-4f15-8315-de39752a0266&#34;,&#34;dropCap&#34;:false}&#34;&gt;&lt;strong&gt;排名：在排名阶段，对候选者进行排名以确定其向用户呈现的顺序。该排名基于一整套排名功能，用于评估每个项目与用户上下文和偏好的相关性。目的是将最相关和最具吸引力的推荐放在顶部，最大限度地提高用户参与的可能性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;5502e588-bf09-4ecc-a8ec-46a6c3a68349&#34;,&#34;dropCap&#34;:false}&#34;&gt;&lt;em&gt;核心技术：&lt;a href=&#34;https://www.uber.com/blog/palette-meta-store-journey/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Palette Feature Store&lt;/a&gt;、&lt; a href=&#34;https://www.uber.com/blog/michelangelo-machine-learning-platform/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;米开朗基罗&lt;/a&gt; &lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;3f34a9c3-40c0-40fa-b569-fd478055ea9c&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;6163dfc0-f673-43d0-9ed3-6574b234f47e&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-solution-formulation-nbsp&#34;&gt;解决方案配方&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;7c96cb0a-f90f-422d-9ac1-b73cd0a32aef&#34;,&#34;dropCap&#34;:false}&#34;&gt;解决我们的问题针对三个主要挑战，我们对架构的每个部分都进行了增强，以便在高效且可扩展的系统中向用户提供相关且主题一致的内容。我们将在下面详细讨论每项增强功能。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;49b01814-2a13-4341-b689-c32430a241a2&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;b74a42c6-e441-470f-94ca-0a009c268465&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-candidate-list- Generation-nbsp&#34;&gt;候选列表生成&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;ccdd7bcf-fca4-424d-8c0b-cb3d98a1d325&#34;,&#34;dropCap&#34;:false}&#34;&gt;独特部分Uber Eats 优食上的推荐是高度本地化于用户位置的候选列表。当用户打开 Uber Eats 优食应用程序时，系统会向他们推荐可以送货到当前位置或最近地点的餐厅、杂货店和零售店t 最近的订单位置。对于我们的 OOA 推荐系统，我们的候选列表生成中缺少这一关键上下文。我们开发了两种解决方案来克服这一障碍。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;867291d7-4276-4314-b997-9a97c187790f&#34;,&#34;dropCap&#34;:false}&#34;&gt;一般推荐在用例中，我们开发了一个机器学习解决方案来确定用户接下来最有可能在哪个社区收到订单。由于我们的系统支持针对频繁、不频繁和新 Uber Eats 用户的营销活动，因此该 ML 解决方案需要集成来自 Uber Eats 和 Uber 应用程序多年时间范围内的高和低吞吐量信号。为了确保该解决方案的可扩展性，以适应与活动所有者沟通的数亿 Uber 用户，我们专注于将这些信号减少到一小组约 10 个功能，机器学习解决方案利用这些功能来定义用户的下一个可能的订单位置。有了这个可能的位置，用户的候选列表是通过查找所有送货到该位置的餐馆、杂货店或零售店来生成的。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;91c2b91c-36f0-4466-9d1f-cdc94dc0c322&#34;,&#34;dropCap&#34;:false}&#34;&gt;虽然这个基础解决方案为我们的 OOA 推荐系统提供了重要的背景，但它并不总是为每个活动提供正确的背景。在用户可能旅行的活动设置中（例如，机场旅行、Uber Reserve、Uber for Business），上述 ML 解决方案可能没有必要的上下文来反映用户最近的行为变化。在此设置中，我们利用基于事件的覆盖来更新用户的候选列表，以包含送货到最近社区的餐馆、杂货店和零售店。通过更新此候选列表，我们提高了用户沟通的相关性，并为活动所有者提供了控制这些候选列表的灵活性，以确保其活动的主题一致性。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;22025f48-b703-42d4-8aa8-714960881c7d&#34;,&#34;dropCap&#34;:false}&#34;&gt;一起，这些解决方案将关键的用户元数据注入用户的候选列表中，确保我们的建议与用户相关并反映他们最近的行为。通过为所有 Uber 用户提供通用的机器学习解决方案，活动所有者可以确信用户的候选列表是准确的，并且可以满足他们的活动目标。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;e6acfcde-5908-47b1-9bed-44186846eb9d&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;bff409bf-2801-40e0-8fe2-15b13673bc25&#34;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-first-pass-ranking&#34;&gt;首次通过排名&lt;/h3&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;width&#34;:&#34;700px&#34;,&#34;height&#34;:&#34;auto&#34;,&#34;align&#34;:&#34;center&#34;,&#34;hash&#34; :&#34;7fc71338-1e9b-4a17-95d7-51cac79d83d0&#34;,&#34;alt&#34;:&#34;&#34;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img 解码=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent. com/docsz/AD_4nXcpvTCnINAXH7xDcMWM5D7jUOEVwOrEsKKugQ4byxZxyT47qLsOM8tcHZwRhy6n-0YCXX4AbYrvS80h2tFTkka94fyYIEZpYxFZ_rrFj5GuBBpvEZlgEkgWSC7Qnrawk0sHnUfLyH 4p1OpyapRuYIsUI1IM?key=DgmRI0YIzHZkraGCSk9ZeA&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;图 2:首轮排名。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;e19636ed-8eed-45bb-afa0-e4985aff33d0&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;eef1f569-4102-4907-ab17-00a4a866b0c7&#34;,&#34;dropCap&#34;:false}&#34;&gt;主要目标首遍排名的目的是快速将每个用户所有符合条件的候选商户集合缩减为较小的潜在商户集合。这有助于节省系统带宽并降低与机器学习相关的成本。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;a404e10f-c69d-4d87-b450-ac79ced27b0f&#34;,&#34;dropCap&#34;:false}&#34;&gt;检索完所有内容后根据用户的位置候选者，我们启动初步筛选过程。此阶段根据不可用和无效送达能力（例如跨境商家）等标准排除候选者。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;7e45baef-353d-4708-825c-12ed9b7c08b7&#34;,&#34;dropCap&#34;:false}&#34;&gt;在某些广告系列中，我们展示多种餐厅类型。为了完善我们的选择，候选人会根据特定用例进行额外的筛选。例如，我们的主要推荐策略是根据用户过去与 Uber Eats 优食的互动来评估候选者的相关性。我们还介绍提供促销活动的候选者，并通过向用户推荐尚未订购但可能有吸引力的餐厅的候选者来激励用户。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;7cf9b299-8d27-4a19-9152-32931102c91a&#34;,&#34;dropCap&#34;:false}&#34;&gt;对于每个针对这些用例，我们对所有符合条件的候选商家应用低成本评分功能。该函数是一小组特征的简单线性组合，包括用户和商家之间过去的交互。调整权重以最大化召回指标。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;核心/段落&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;e1e9c760-cb6a-4e08-8376-d0fea6e5ad55&#34;,&#34;dropCap&#34;:false}&#34;&gt;最后，为了确保用户有多种选择，我们运行了重复数据删除过程。此步骤删除属于同一父链的候选者，避免重复推荐。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;6c9e32e6-116e-42a0-8948-12b945dc3946&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;6d33a86b-c8ea-4b12-a20d-5a727c70fa64&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-second-pass-ranking&#34;&gt;第二关排名&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;93cb1bfc-14c3-4bc1-a518-b4f4621b2526&#34;,&#34;dropCap&#34;:false}&#34;&gt;目标第二个排名阶段是对从第一次排名中检索到的一小部分商家进行排名，以最大化用户参与的可能性。为此，我们利用一些功能来捕获用户过去的订单历史记录、应用内和应用外的参与度以及商家的质量、可靠性和承受能力。其中许多功能也被家庭提要排名系统使用，并通过 Uber 的在线功能商店共享，&lt;a href=&#34;https://www.uber.com/blog/palette-meta-store-journey/&#34; target= &#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;调色板&lt;/a&gt;。通过在推荐服务之间共享功能集，我们促进了应用内和应用外界面的用户体验的平等。这些功能在学习排名 LTR 建模框架中使用，并具有自定义相关权重，以鼓励理想的用户行为。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;9b9ade24-3b90-443e-b035-3ffd92252682&#34;,&#34;dropCap&#34;:false}&#34;&gt;当 ‌user-中心功能对于经常使用的用户来说很丰富，但对于新用户和流失用户来说通常无法使用。由于 OOA 系统主要迎合不频繁的用户群体，因此我们必须依赖长期的用户信号才能提供良好的推荐。此外，我们需要能够以经济高效的方式存储和使用此类信号。为了通过餐厅推荐克服这一挑战，我们构建了一个轻量级功能集，总结了用户在整个 Uber Eats 优食历史中的美食偏好。在 Uber，我们为每家餐厅标记了商家提供的一组美食，我们利用这些美食创建一个总结用户美食偏好的特征向量。我们每天使用贝叶斯更新逻辑更新此功能，并增加最近订单的权重，以反映用户最近的行为变化。在最近的在线实验中，将此功能纳入我们的第二次排名系统中，电子邮件的点击率提高了 4%。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;a1c3dd21-e4c7-459a-9bab-9ab34e711597&#34;,&#34;dropCap&#34;:false}&#34;&gt;我们的第二遍排名系统中使用的许多功能有效地总结了用户过去的订单行为，但没有透露用户下一步可能有兴趣尝试哪些餐厅。由于 Uber Eats 优食订单的地理限制，协作推荐系统技术很难学习餐厅相似性。例如，不同社区的两家餐馆可能以相似的价格提供相似的菜肴，但由于地理差异而没有共同的顾客。虽然通过基于协作的方法来了解餐厅相似性很困难，但利用基于内容的推荐方法和餐厅的美食标签提供了了解餐厅相似性的机会，并鼓励用户在 Uber Eats 优食上探索新餐厅。我们假设用户会对提供与他们过去订购的菜肴相似的菜肴的新餐厅感兴趣。在此前提下，我们进行了一项分析来量化菜系之间的相似性。我们对正则化的美食共现矩阵进行谱聚类，捕获同一家餐厅经常提供哪些菜肴。从这个聚类练习中，我们发现，虽然商家可以提供数百种菜肴，但这些菜肴可以自然地归入少数几个类别。在图 3 中，我们可视化通过 t-SNE 映射到二维空间的每种美食的嵌入向量，突出显示了这些自然美食集群。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;e71ad85b-0f8f-447c-ab04-1b2d3ea03ede&#34;,&#34;opacity&#34;:&#34;alpha 通道&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;align&#34;:&#34;center&#34;,&#34;hash&#34;:&#34;0a0e33b5-6874-4c16-821a-0e174f469461&#34;,&#34;alt&#34; :&#34;&#34;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img 解码=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXclTIOVrXS9GosD3MlTmw3WJ6vNDCKLZ5P8yDa5Fru2bv4mhA4sGVo29-KyGWF7GZpO8axvCO52o_w_Xs4IwW_wW3 rYodhyYhan-2PRcl5NBdd6mBWGKWIQifmwnWmtHePk-5xBREjN3xNW10pp9C54_As?key=DgmRI0YIzHZkraGCSk9ZeA&#34; alt=&#34; &#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;图 3：基于相似性分析的美食分类。 &lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;33a54c0d-7108-4057-9705-1c9b550ca5df&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;0f70a1cc-aae9-44d0-967e-6de3fbb43c43&#34;,&#34;dropCap&#34;:false}&#34;&gt;这些分组的动机我们根据这些菜系的相似度来平滑每个用户的菜系偏好特征。利用这个我们的第二次排名系统中的平滑特征向量为我们的系统提供了一个探索杠杆，鼓励用户尝试与他们喜欢的美食相似的新美食，同时保持推荐相关性。除了这种探索杠杆之外，这些分组还为我们提供了降低系统成本的机会。通过根据这些菜系分组嵌入菜系偏好功能，我们将该功能的大小缩小了 10 倍，降低了在线存储成本，同时保留了该功能的大部分信号。此外，通过利用轻量级嵌入方案，我们能够通过简单的分布式矩阵乘法有效地执行此特征嵌入，这可以在任何标准 ETL 管道框架中执行。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;447774ed-d9f0-46fa-a859-0bac001d49ab&#34;,&#34;dropCap&#34;:false}&#34;&gt;通过构建轻量级功能集总结了用户在整个 Uber Eats 优食历史中的美食偏好，为我们的第二次排名模型提供了重要的背景。这种背景为我们的推荐系统提供了探索杠杆，鼓励用户探索新的美食和商家，并确保不常使用 Uber Eats 优食的用户收到相关的餐厅推荐。通过嵌入这些美食偏好功能，我们可以大大降低在线存储成本，并确保推荐系统可以支持针对任何 Uber 用户群的活动。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;a6cae821-5d45-41bf-aef6-48d4edfa98e3&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;76ebb488-7b65-40ac-ab1a-88f6b96ca159&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-re-ranking-amp-blending-nbsp&#34;&gt;重新排名和混合&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;06c7bba6-99f2-4105-9aee-e9f6225e38da&#34;,&#34;dropCap&#34;:false}&#34;&gt;作为 CRM 通信来自不同的内部利益相关者，系统需要一种机制来针对不同的品牌战略和营销优先事项定制嵌入的建议。因此，我们在基于机器学习的第二遍排名后引入了重新排名和混合层。例如，我们允许利益相关者根据特定的营销策略来提高商家的知名度（图4）。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;a0b0297a-639f-4b7d-a344-c6d091834bf5&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;align&#34;:&#34;center&#34;,&#34;hash&#34;:&#34;6a83af6f-44cb-45d0-af65-7b0e07253ba0&#34;,&#34;alt&amp;quot;:&#34;&#34;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img 解码=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXfaBCsP7f9PtQJIas64-wKhFJSRYAN7bn0uOjMvJfrKrAmIK-BN5YuVxqKTy2UWASUp8PwClRpu5GsXceUirADVn2Wpy_I- N3953rek6wl5T1Yxx_pmchFXQFMzWlvSp2EyzPa4ac565MAjz5TaPqNAujEa?key=DgmRI0YIzHZkraGCSK9ZeA&#34; 替代=&#34;&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;图4：增强所选商户的曝光度。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;559a6e0f-bfa6-4a19-a49b-b94f12375893&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;67ed7887-a83c-41e8-986d-bb8688edef88&#34;,&#34;dropCap&#34;:false}&#34;&gt;通过我们的配置引擎，本地营销团队可以灵活地定义自己的策略，并且只需最少的工作。这是通过不同地理区域级别的自动分层配置合并和覆盖来实现的。例如，纽约市可以继承美国的大部分重新排名策略，但纽约市本地营销团队可以对特定参数应用一些部分覆盖。图 5 演示了增强图 4 中所选商家的配置。&lt;/p&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;width&#34;:&#34;700px&#34;,&#34;height&#34;:&#34;auto&#34;,&#34;align&#34;:&#34;center&#34;,&#34;hash&#34; :&#34;0873a777-dbb9-4b07-b267-6021290d2a47&#34;,&#34;alt&#34;:&#34;&#34;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img 解码=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent. com/docsz/AD_4nXdJ5NWHGLcrbj4jUtlNt2EQ5D2ZC11o_EJnaOArqzUgVf3-iKqGbyrULBZ5OpxAH_H7OrkQhFrFBn5sNlYOCtq6gW8elbCvzVAPLf7f42NxPVeqDomvf54fiS5myotklOMEPHLi15np ddLftZtdb6pGmGrf?key=DgmRI0YIzHZkraGCSk9ZeA&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;图 5:通过分层覆盖来增强选定商家的配置。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;2dac800f-5bb4-4c8e-b06f-53580fd7858e&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:1,&#34;hash&#34;:&#34;2f2886cd-1104-4288-9426-b09972626633&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-next-steps&#34;&gt;后续步骤&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;09b861ab-c5bc-4d76-8407-84817f05c3eb&#34;,&#34;dropCap&#34;:false}&#34;&gt;虽然大部分早期的工作重点是提供商家推荐，Uber 对个性化营销的需求超出了我们的送货业务范围。我们平台的后续步骤是将相同的个性化功能引入其他业务领域ss，特别是骑手和挣钱者的沟通。为了更好地服务这些新的业务面，该团队计划扩展我们的个性化内容存储库，并向 Uber 的合作伙伴团队采购。新的发展包括动态创意，以统一个性化推荐和其他营销创意；个性化的旅行建议；以及个性化的盈利机会来推动市场需求和供应。  &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;a023a443-c2cb-4aa8-b211-d60c4cad2bba&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-acknowledgements&#34;&gt;致谢&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;5084df9e-a3a4-4e68-af96-016201be90c0&#34;,&#34;dropCap&#34;:false}&#34;&gt;这不会这一切的实现离不开多个增长和营销团队的贡献。我们要感谢以下人员的贡献：Isabella Huang、Ajit Pawar、Apoorv Sharma、Jennifer Li、Hari Thadakamalla、Cameron Kalegi、Nikhil Anantharaman、Vladimir Schipunov、Denis Perino、Shelley Hatting、April Chu、Nora Murphy、Fernanda戈麦斯、艾比·布莱克、卡罗莱纳·阿普雷亚、玛丽·奥奎特、安·帕登、迈克尔·谭。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;93180c87-77f2-4ab5-824d-f5fa7e71da01&#34;,&#34;dropCap&#34;:false}&#34;&gt;特别感谢我们的技术合作伙伴包括 LocalGraph 团队（Jiaxin Lin、Kaymyar Arbabifard、Santosh Golecha）、Delivery Intelligence 团队（Yifan Ma、Tiejun Wang）、Michelangelo 团队（Jin Sun、Paarth Chothani、Nicholas Marcott、Victoria Wu）以及 Offers &amp; Affordability 团队（Shirley Ye、Boyang Li、Jun Yao）帮助我们设计系统并利用 Uber 范围内的人工智能构建模块。&lt;/p&gt;</description>
      <pubDate>Thu, 13 Jun 2024 07:02:17 +0000</pubDate>
    </item>
    <item>
      <title>【Pickup in 3 minutes: Uber’s implementation of Live Activity on iOS】3 分钟内接载：Uber 在 iOS 上实现 Live Activity</title>
      <link>https://www.uber.com/blog/live-activity-on-ios/</link>
      <description>【&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;d8d5a54c-aece-4e72-a8ee-4b0719264e19&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-introduction&#34;&gt;Introduction&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a21eee85-8e66-4b3f-9bbe-f9d6fac23655&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The 2022 WWDC keynote brought an unexpected surprise when Apple™ unveiled the new Live Activities feature, using Uber’s Rider app as a prominent example. This announcement generated excitement for the feature to come and set the stage for an exhilarating journey for our team.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0acb5d83-99cb-4643-9aae-959dc48f59a6&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;What follows is the story of how we started designing for surfaces outside the app, the engineering problems we had to solve along the way, and ultimately how we measurably improved the experience of riders and drivers.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;fdbf46e9-3a89-4d91-b5cf-b2d21a6a0728&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;584c60c8-0e10-4ce8-99b7-d11e81af48b6&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-planning-the-work-ahead&#34;&gt;Planning the Work Ahead&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;48cba36c-9ab1-4cb3-a7f3-f058e5ef4f3e&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Given the secretive nature of the announcement,&amp;nbsp; only a few directors on our side were in the loop. For the rest of the engineering and design team, it was an exhilarating surprise, immediately followed by the realization that we needed to move quickly.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;630d3cda-62e6-463e-b161-71f6818da440&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;At a company the size of Uber, work is usually planned on a half-year schedule and resources and timelines are always tight.&amp;nbsp; So, while considering the prioritization of this feature, we recognized the potential upside of being in the App Store® on day one, to be a champion of the platform.&amp;nbsp; We also believed that this feature would be of great benefit to our users, as now they would be able to observe trip updates from outside of the app in a granular way.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3356d1f0-c441-4d92-98b7-a9da8eed85b0&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We got into a room and began redrawing our plans, reallocating resources, starting from a minimal team that could work on this as their main project. We then recruited additional resources on a side project basis, making sure to plan their contributions to avoid too much context switching.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8d58daf1-1c9b-4423-914b-237970e72c48&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We began by tech-proofing the concept as much as possible up front, working closely with the UX and design team. We set specific guardrails to keep the scope manageable, knowing that we needed to construct a space for flexible thinking. Everyone on the team had enough know-how and authority to allow for plan changes based on product iterations, newly discovered engineering limitations, or staffing conflicts. The autonomy given to each member of the team was a crucial aspect, meant to minimize the turnaround time of changes in scope and requirements while navigating the uncharted waters of developing for a new app surface.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6cbee0ca-c76d-4d97-8158-efbe72e5a662&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e9ecafd5-4990-4b89-89f9-a2dea56c85ba&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-ui-at-a-glance&#34;&gt;UI at a Glance&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;eeae5d98-28d3-4108-bebc-6a82dea8f7b7&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;From a UX perspective, we quickly recognized the unique challenge posed by Live Activities. Information on this surface is only glanced at for a few seconds at a time, and it extends beyond the boundaries of the main app. Attempting to cram the same information from our app into the Live Activity view would have been a mistake. Users would only look at it briefly, so we categorized the information based on what we believe users’ priorities would be during a trip:&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c1b61d5e-2b15-4c06-a6bf-9c7680a7c60b&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;P0. time to pick up/destination. &lt;/strong&gt;Important information during the waiting-for-pickup phase, the user wants to know how long before being picked up, so they can get ready and still use their phone without constantly hopping into the app to check.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;P1. license number, and picture of the vehicle.&lt;/strong&gt; At pickup time it helps the user identify the location of the vehicle in the real world.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;P1. name and picture of the driver. &lt;/strong&gt;This adds safety context and helps the user ensure they are getting into the right vehicle.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;P2. overall progress of the trip.&lt;/strong&gt; Brings the experience all together. It has been designed with a dynamic display curve, where the last 20% of the progress bar represents the last 2 min of the progress no matter how long the whole waiting time is.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;dd5dd607-b688-4cfe-9347-14e25b04da37&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;This prioritization not only informed the feature design, but also guided us whenever we encountered engineering issues. The information priority was always the main anchor point when evaluating and justifying the scope of a change.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5d3238c9-235e-4005-a235-a53678b5d069&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;48fbba51-0143-485b-85d9-99891d53f77e&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXfnNfm5WFNr_nxKNiRnUfm365F_py2lz4MjHL7SSdCM4DhNliUd83sfhJHg1gKDhSt_CPcyeMoDHyquxmzWhcmKRzKLQHYlwUeUQVw-TB-0XrJi4O97G4O2R-J8TlI1jOEhDG66JT4rylDmiTI11MV0hwA?key=rkl1fUrFyfE6SsnQYMStNA&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 1: Visual representation of the hierarchy of information on the live activity.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0b6e161c-a75a-439f-9d87-84ee9846e681&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;850bc16f-fbde-471b-a027-bbc943d7c502&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Working with the Dynamic Island, the pill-shaped cutout that shows app information on top of the screen, took this concept to an extreme, due to its minuscule amount of space. Unlike a standalone Live Activity, the Dynamic Island shares its limited real estate with other apps and system information. This meant that our design had to be even more concise and efficient. We had to ensure that our information was clear and useful within the tiny space, without overwhelming the user or clashing with other data. For example, during the on-trip phase, we had several iterations to make sure the drop-off time wasn’t going to be mistaken with the system clock. Every pixel counted, and we had to be exceptionally creative to maximize the utility of this feature.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;80db5ef0-fb5e-46e5-98c6-316697cfbd6d&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;5dba3263-5965-4b92-9c5b-c0974a4d0ed7&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXcJ6ljMLzX0eQB8NpOhehU_arCfn53RdDCuJ37Qm9bcRWqKlBL9Z7w5FhYxkD7YrBMSI794qrnEQtM1Ir9_lg0HFX7IUX_rkUnKXiSsn8zIe5vQtWRw6X2lahNcbySZpDr5X3LPceyZtT4dOcI7U_GYFlD3?key=rkl1fUrFyfE6SsnQYMStNA&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 2: All the phases of a trip expressed in the Dynamic Island.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d38c74f9-da14-4861-b302-9e1a378e48e5&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7ec25563-ca41-42ac-8100-018f7c14ad49&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-overcoming-technical-challenges&#34;&gt;Overcoming Technical Challenges&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6ff1c177-70bb-40a1-a455-4eff1d095bae&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Live Activities are designed as a separate target from the main application, with no access to networking capabilities and no state. They are updated through the main app or push notifications. Once invoked, the Live Activity constructs its own SwiftUI® view and exists without the ability to directly communicate back to the main target. This setup presented a major challenge: how to handle images dynamically needed by the Live Activity, such as the driver and vehicle’s&amp;nbsp; picture.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;887d7962-8772-40c8-8cd3-8238eac23125&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;To solve this, we leveraged two technical characteristics of the app: the main target being in the background during the trip request and App Groups, which allows targets to read and write into a shared directory. Upon a payload update, we process any image URLs found and serialize them to disk. The Live Activity then reads those same URLs from disk.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;fd4a0b78-7ba6-43b5-85b6-9844b42e0d98&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;2e2f3801-246c-4c2d-842a-bf9fbadbc11e&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXeMRO_W2T4rGjwycnXIGluXrdrMbIf0OYp_WFp8cH5CU7HHZ82EHLuDI8xHHnlj3b3H0jEALsmcsNWxXOfo_cPU9PDV8ji47KX9HUMRhGtyGCfT4VYgGw5x84Xk00MxZFsg3_RgYBNQsKKzR5cWWrwI-jLE?key=rkl1fUrFyfE6SsnQYMStNA&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 3: Timeline of Live Activity update and asset caching strategy.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;093216e5-b2bc-49d6-8ec3-1f40b2b09545&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;78f18350-259b-45be-abff-c247c5f4ccd1&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;What is usually the simple task of downloading assets and presenting them on screen, becomes, with Live Activities, a more complicated process that adds several possible failure points. The only silver lining, in our situation,&amp;nbsp; is that since assets rarely change during a trip, we have the opportunity to retry at every payload update if necessary.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;dbc5915a-63ff-4885-bcc7-2094023de069&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Later in this article we will discuss possible alternative solutions, but there is one main aspect that is worth noting up front: the app is not guaranteed to be running in the background during a trip. The Rider app uses an entitlement to run in the background, so we can update the user location and guarantee precise pickup information, but the user or the OS can still kill the app, stopping the stream of updates.&lt;br&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2280f88d-0b85-4b8d-99af-ef7fe91fc1cc&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In our first design, we relied exclusively on the app running in the background to update the live activity, but during beta testing we received reports from users lamenting that the Live Activity stopped updating or it was not dismissed after trip completion. We consequently opted for a different design that leverages a backend service and Push Notifications (more in the OOA Service section).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b4838fb0-80f5-49a4-aa4a-45dd71bc9475&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;A major part of the first solution was to estimate the impact of this feature on the backend API.&amp;nbsp; While this feature would add traffic to our API services, we believed users would spend less time inside the application, reducing traffic at the same time (the app needs to pull data frequently while in the foreground). We could not guess how our users’ behavior would change, but we estimated the load transfer from foreground to background use would not be impactful. Additionally, as an initial safeguard, a feature flag was added to control the rate of pulling while in the background. However, after moving to the aforementioned OOA Service, the rate of updates is already controlled by the backend, which has a more sophisticated load balancing and throttling logic.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;19436a26-34b7-4c92-86a8-b30aaee10551&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c8d6621d-1612-4011-b4ec-95d339b65083&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-measuring-impact-and-collecting-data&#34;&gt;Measuring Impact and Collecting Data&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9dfe427e-8bb8-46ec-a555-7acb9d1651af&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Measuring the impact of new features is a standard practice at Uber. We anticipated that Live Activities would change how users interacted with our app, leading to significant improvements in metrics such as reduced cancellations and waiting times at pickup. The figures below may seem small, but they are in fact huge wins at the scale we operate. Based on the results, we believe riders are more aware of when they are getting picked up, resulting in more completed trips (and earnings for drivers).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c89351e4-6746-48a7-ba52-663a2065b074&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;2.26% &lt;/strong&gt;reduction in driver cancellations at pickup&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;2.13% &lt;/strong&gt;reduction in rider cancellation at pickup&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;1.06% &lt;/strong&gt;reduction in pickup defects per request&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;43903745-6d9a-43b0-95c5-4744b7c1d72d&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The metrics above are a measure of user behavior which are measured independently by features that are added to the app. When it comes to collecting engineering metrics for Live Activities, their unique behavior made the task more challenging. Unlike a normal app, Live Activities don’t offer easy ways to gather metrics without significant gaps. We had to make assumptions based on incomplete data, such as monitoring the sequence of &lt;strong&gt;&lt;em&gt;activityStateUpdates&lt;/em&gt;&lt;/strong&gt; to see if Live Activities were correctly cleared at the end of a trip. However this sequence only emits if the app is running in the background, which is not guaranteed, meaning that a significant amount of events would be missing.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a3b3ca98-e5d4-4f17-8059-02618ee0592d&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;To mitigate the issue we had to join data about foreground events where a Live Activity is present without a trip in progress. This method does not guarantee 100% coverage of the cases, but it allows us to set an acceptable baseline and create regression metrics and dashboards that, while they don’t represent a complete picture, are still useful to catch regressions in production or during development.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a51bd47b-2864-49b0-9706-ec7976b60310&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;334591db-c22f-4942-a6e8-976a7a645b60&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-implementing-feature-flags&#34;&gt;Implementing Feature Flags&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d254d666-52ca-4769-bc1f-ea32d1a5279c&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Another standard Uber practice is to flag new features or sizable iteration changes. With Live Activities, this was tricky due to the lack of network access and bilateral communication with the main target. We use the same trick as with image loading: at the startup of the main target, we read the feature flags from our standard pipeline and write their values to disk. The Live Activity then reads these values from disk when invoked.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;cca24f0a-abe0-45ec-99db-1fb195ddccf4&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1093155,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;19c012b7-97a2-4c31-868c-077278b52895&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;673&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/07/Figure_4-1024x673.png&#34; alt=&#34;&#34; class=&#34;wp-image-1093155&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/07/Figure_4.png 1024w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/07/Figure_4.png 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/07/Figure_4.png 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1536,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/07/Figure_4.png 1536w, https://blog.uber-cdn.com/cdn-cgi/image/width=2048,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/07/Figure_4.png 2048w&#34; sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 4: Diagram describing the passthrough of Feature flags to the Live Activity.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4fc898b4-1f9b-4b46-a83e-b8ccc3816348&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;259718db-b6a1-44c4-a575-b1bcc18eee74&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-dsl-android-and-the-ooa-service&#34;&gt;DSL, Android™, and the OOA Service&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d3f56171-ce5b-4fcf-b17b-0879dd541e2e&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;While Android doesn’t have a direct counterpart to Live Activities, we could still enhance the push notification strategy by updating push notifications, as opposed to sending new ones, adding the same visual element used in the Live Activity to achieve feature parity.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;07aad116-6775-46cc-9ca2-bd25434510fc&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;To streamline this process and ensure consistency across iOS™ and Android, we developed a simple server-driven language. This language allows us to easily modify the content presented in both the Live Activity and Android Push Notifications. By centralizing the content logic on the server, we can dynamically update and tailor the user experience without requiring app updates. This system provides flexibility and ensures that any changes or new features can quickly be implemented across both platforms, maintaining a unified experience for all our users.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9b69d100-3fed-475f-afdb-03d7c707d53e&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We needed to design a domain specific language (DSL) that had a very small implementation footprint and few external dependencies. Uber already has a Server Driven UI system, but it is pretty extensive and as a result it cannot be imported to an external target without impact on the binary size. Furthermore keeping the capabilities to a minimum also allows to reduce the maintenance cost in the future.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e42c67ef-657d-4313-9398-f883de028b97&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;br&gt;Our solution was to build a very opinionated, semi-descriptive DSL. Only UI elements that can be present in Live Activities are included (no text fields or segmented controllers for example) and no extensive styling was provided. For views that need styling, we provide an array of tags that is then processed at the client level. For example, the title label could be represented by a component of type &lt;em&gt;Label&lt;/em&gt;, along with the text and a tag of type &lt;em&gt;title&lt;/em&gt;. Then the client applies the font, color, number of lines, alignment, etc. for the specific style &lt;em&gt;title&lt;/em&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;619096ff-7460-4c11-8324-b4bcc1860df4&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;950fa69b-2d4b-4e55-8d75-b059467bd53e&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXdsNu5jyXsfpaTI9Vg-oHlbNbNdMHh9Idpf30MDWoRihwehyVMrjCdIn0CM6qhbfwG9uYmXvj0ix5Or984gWE7ADWXuAYEgIOzwgEQT0PRdKv01TZ384gQ8-Jm6gyVLby8pQtNqLa4ABIhQfBaZvKMwMl8?key=rkl1fUrFyfE6SsnQYMStNA&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 5: Exemplification of a DSL payload that hydrates the Live Activity.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;308b68d5-cb9c-4a9a-9caa-3831abbae52c&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e8ef1a57-fd18-40bc-849e-803fa8a1e81d&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Lastly the DSL would not represent any framing or anchoring information. A different view could be provided for the header or the progress bar, but the location of each view is set by the client and cannot change (unless for instructions that are applied with the aforementioned tags).&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c7252015-a88b-44e8-9a77-4a9a4df67519&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1093156,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;d033db0f-5c7e-4ce8-9ce5-91ffb62239f7&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;220&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/07/Figure_6-1024x220.jpg&#34; alt=&#34;&#34; class=&#34;wp-image-1093156&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/07/Figure_6.jpg 1024w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/07/Figure_6.jpg 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/07/Figure_6.jpg 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1521,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/07/Figure_6.jpg 1521w&#34; sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 6: Demonstration of how the templating works on the Live Activity and Android Push Notification.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;29e191ed-f97e-412e-8c92-f2d44abda49c&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8ce1fd0b-1827-46de-be68-99978022606e&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Working in tandem with this new DSL system we developed a backend service specifically designed for surfaces that live outside of the app; we call it the OOA Service (Out Of App). The OOA Service is responsible for the logic to balance the amount of updates delivered to the Apple Push Notifications Service. It evaluates whether changes to the application state are important enough to be delivered, as well as debouncing state changes that happen in rapid succession. Because of the need to evaluate and debounce, this service has to cache previous states for all concurrent trips on the platform, which is a substantial scaling effort.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f1c38265-62e8-44a2-ac71-622ac7b4a94d&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Building the DSL and the OOA Service was a significant step forward. It didn’t only simplify the development process, but also opened the door to integrate changes without having to duplicate the decision tree logic&amp;nbsp; and deploy code on multiple platforms. By building this generic solution, we avoid solving complex problems multiple times on different teams. This, in particular, is a decision that we believe will pay dividends in the future as more and more vertical teams at Uber utilize the Live Activity flow.&lt;br&gt;Even the Eats platform is already using a good part of the mobile framework that deals with the Live Activity life cycle, the image caching and the feature flag injection. They are also evaluating onboarding the DSL and the OOA Service after seeing ‌the positive results of the Rider integration.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7c605f28-0f27-430e-aa1b-856fb0a30877&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;456dd394-451c-43ec-8264-99820ff236a2&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-conclusion&#34;&gt;Conclusion&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8fdbe365-654c-49bf-becc-de4ebf7d98b6&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Building the Rider iOS Live Activity was an intense, but rewarding journey. From the surprise of the WWDC announcement to the challenges of developing and implementing a new technology on a tight timeline, the experience showcased the resilience, adaptability, and creativity of our team. We navigated technical hurdles, redefined our UX approach, and ultimately delivered a feature that we believe improved the rider and driver experience. I hope the pieces of ingenuity we have shown in this article may inspire any developer working on Live Activities, to help them overcome similar scenarios and generally take a pragmatic approach for experiences that live outside of the main app.&lt;br&gt;At a personal level, it was a great experience and opportunity: developing an early adopter product at a company of our scale is challenging, but insanely fulfilling.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;73a51cf5-4e2c-4d8a-8ca9-51e142dde84b&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-acknowledgments&#34;&gt;Acknowledgments&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;cfcd3e00-4b2b-4695-be8f-619d8c2dc7f9&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;A special thanks to the whole team. This project not only demonstrated everyone’s technical prowess, but also highlighted the collaborative spirit that drives innovation at Uber. Kyle Gabriel, Ken Nguyen, Tiffany Chang, Hyewon Son, Radhika Gemawat, Maxim Bogatov, Yifan Ding, Evan Cooper&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;fontSize&amp;quot;:&amp;quot;small&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;0d80d3ae-d935-48d4-823a-9768c64618bd&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34; class=&#34;has-small-font-size&#34;&gt;Apple, App Store, Swift, and SwiftUI are trademarks of Apple Inc., registered in the U.S. and other countries and regions.&lt;br&gt;iOS is a trademark or registered trademark of Cisco in the U.S. and other countries and is used by Apple under license.&lt;br&gt;Android is a trademark of Google LLC, registered in the U.S. and other countries and regions.&lt;/p&gt;】&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:1,&#34;hash&#34;:&#34;d8d5a54c-aece-4e72-a8ee-4b0719264e19&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-introduction&#34;&gt;简介&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;a21eee85-8e66-4b3f-9bbe-f9d6fac23655&#34;,&#34;dropCap&#34;:false}&#34;&gt;2022 年 WWDC当 Apple™ 以 Uber 的 Rider 应用程序作为突出示例推出新的实时活动功能时，主题演讲带来了意想不到的惊喜。这一公告让我们对即将推出的功能感到兴奋，并为我们团队的激动人心的旅程奠定了基础。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;0acb5d83-99cb-4643-9aae-959dc48f59a6&#34;,&#34;dropCap&#34;:false}&#34;&gt;接下来是我们如何开始设计应用程序之外的表面，一路上必须解决的工程问题，以及最终我们如何显着改善乘客和驾驶员的体验。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;fdbf46e9-3a89-4d91-b5cf-b2d21a6a0728&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;584c60c8-0e10-4ce8-99b7-d11e81af48b6&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-planning-the-work-ahead&#34;&gt;规划未来的工作&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;48cba36c-9ab1-4cb3-a7f3-f058e5ef4f3e&#34;,&#34;dropCap&#34;:false}&#34;&gt;鉴于秘密由于该公告的性质，我们这边只有少数董事了解情况。对于工程和设计团队的其他成员来说，这是一个令人兴奋的惊喜，随后我们立即意识到我们需要迅速采取行动。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;630d3cda-62e6-463e-b161-71f6818da440&#34;,&#34;dropCap&#34;:false}&#34;&gt;在一家公司就 Uber 的规模而言，工作通常按半年计划一次，而且资源和时间安排总是很紧张。  因此，在考虑此功能的优先级时，我们认识到第一天进入 App Store® 的潜在优势，即成为该平台的冠军。  我们还相信，此功能将为我们的用户带来很大好处，因为现在他们将能够从应用程序外部以精细的方式观察行程更新。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;3356d1f0-c441-4d92-98b7-a9da8eed85b0&#34;,&#34;dropCap&#34;:false}&#34;&gt;我们进入一个房间，并开始重新制定我们的计划，重新分配资源，从一个可以将其作为主要项目的最小团队开始。然后，我们在业余项目的基础上招募了额外的资源，确保规划他们的贡献以避免过多的上下文切换。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;核心/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;8d58daf1-1c9b-4423-914b-237970e72c48&#34;,&#34;dropCap&#34;:false}&#34;&gt;我们首先尽可能地预先对这个概念进行技术验证，工作我们与用户体验和设计团队密切合作，设置了特定的护栏以保持范围的可控性，因为我们知道我们需要构建一个灵活思考的空间，以便根据产品迭代进行计划变更。 、新发现的工程限制或人员冲突，给予团队每个成员的自主权是一个至关重要的方面，这意味着在探索新应用程序界面开发的未知领域时，可以最大限度地缩短范围和需求变化的周转时间。 /p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;6cbee0ca-c76d-4d97-8158-efbe72e5a662&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;e9ecafd5-4990-4b89-89f9-a2dea56c85ba&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-ui-at-a-glance&#34;&gt;用户界面概览&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;eeae5d98-28d3-4108-bebc-6a82dea8f7b7&#34;,&#34;dropCap&#34;:false}&#34;&gt;来自用户体验从角度来看，我们很快认识到现场活动带来的独特挑战。一次只能浏览该表面上的信息几秒钟，并且它超出了主应用程序的边界。试图将我们应用程序中的相同信息塞入“实时活动”视图将是一个错误。用户只会简单地查看它，因此我们根据我们认为用户在旅行期间的优先事项对信息进行了分类：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;c1b61d5e-2b15-4c06-a6bf-9c7680a7c60b&#34;,&#34;ordered&#34;:false,&#34;values&#34;:&#34; “}”&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;P0。接车时间/目的地。 &lt;/strong&gt;等待接载阶段的重要信息，用户想知道距离接载还有多长时间，这样他们就可以做好准备并继续使用手机，而无需不断地跳入应用程序进行检查。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;P1。车牌号码和车辆图片。&lt;/strong&gt;在取车时，它可以帮助用户识别车辆在现实世界中的位置。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;P1。司机的姓名和照片。 &lt;/strong&gt;这增加了安全背景，并帮助用户确保他们进入正确的车辆。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;P2。旅行的整体进度。&lt;/strong&gt;将所有体验汇集在一起​​。采用动态显示曲线设计，最后20%进度为r代表进度的最后2分钟，无论整个等待时间有多长。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;dd5dd607-b688-4cfe-9347-14e25b04da37&#34;,&#34;dropCap&#34;:false}&#34;&gt;此优先级不不仅为功能设计提供了信息，而且在我们遇到工程问题时也为我们提供了指导。在评估和证明变更范围的合理性时，信息优先级始终是主要锚点。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;5d3238c9-235e-4005-a235-a53678b5d069&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;align&#34;:&#34;center&#34;,&#34;hash&#34;:&#34;48fbba51-0143-485b-85d9-99891d53f77e&#34;,&#34;alt&#34; :&#34;&#34;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img 解码=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXfnNfm5WFNr_nxKNiRnUfm365F_py2lz4MjHL7SSdCM4DhNliUd83sfhJHg1gKDhSt_CPcyeMoDHyquxmzWhcmKRzKLQHYl wUeUQVw-TB-0XrJi4O97G4O2R-J8TlI1jOEhDG66JT4rylDmitI11MV0hwA?key=rkl1fUrFyfE6SsnQYMStNA&#34; alt=&#34; &#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;图 1：实时活动信息层次结构的直观表示。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;0b6e161c-a75a-439f-9d87-84ee9846e681&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;850bc16f-fbde-471b-a027-bbc943d7c502&#34;,&#34;dropCap&#34;:false}&#34;&gt;使用动态岛是一种在屏幕顶部显示应用程序信息的药丸状切口，由于其空间极小，因此将这一概念发挥到了极致。与独立的实时活动不同，动态岛与其他应用程序和系统信息共享其有限的空间。这意味着我们的设计必须更加简洁和高效。我们必须确保我们的信息在狭小的空间内清晰有用，而不会让用户感到不知所措或与其他数据发生冲突。例如，在行程阶段，我们进行了多次迭代，以确保还车时间不会与系统时钟发生错误。每个像素都很重要，我们必须具有非凡的创造力才能最大限度地利用此功能。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;80db5ef0-fb5e-46e5-98c6-316697cfbd6d&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;align&#34;:&#34;center&#34;,&#34;hash&#34;:&#34;5dba3263-5965-4b92-9c5b-c0974a4d0ed7&#34;,&#34;alt&#34; ：“”;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img 解码=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXcJ6ljMLzX0eQB8NpOhehU_arCfn53RdDCuJ37Qm9bcRWqKlBL9Z7w5FhYxkD7YrBMSI794qrnEQtM1Ir9_lg0HFX7IUX _rkUnKXiSsn8zIe5vQtWRw6X2lahNcbySZpDr5X3LPceyZtT4dOcI7U_GYFlD3?key=rkl1fUrFyfE6SsnQYMStNA&#34; alt=&#34;&#34;referrerpolicy=&#34;无引荐来源&#34; &gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;图 2：动态岛中表达的旅行的所有阶段。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;d38c74f9-da14-4861-b302-9e1a378e48e5&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;7ec25563-ca41-42ac-8100-018f7c14ad49&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-overcoming-technical-challenges&#34;&gt;克服技术挑战&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;6ff1c177-70bb-40a1-a455-4eff1d095bae&#34;,&#34;dropCap&#34;:false}&#34;&gt;实时活动是设计为与主应用程序分离的目标，无法访问网络功能，也没有状态。它们通过主应用程序或推送通知进行更新。一旦被调用，Live Activity 就会构建自己的 SwiftUI® 视图，并且存在时无法直接与主要目标进行通信。此设置提出了一个重大挑战：如何动态处理实时活动所需的图像，例如驾驶员和车辆的图片。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;887d7962-8772-40c8-8cd3-8238eac23125&#34;,&#34;dropCap&#34;:false}&#34;&gt;解决此问题，我们利用了该应用程序的两个技术特征：主要目标在行程请求期间位于后台，以及应用程序组，允许目标读取和写入共享目录。有效负载更新后，我们会处理找到的所有图像 URL 并将它们序列化到磁盘。然后，实时活动从磁盘读取这些相同的 URL。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;fd4a0b78-7ba6-43b5-85b6-9844b42e0d98&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;align&#34;:&#34;center&#34;,&#34;hash&#34;:&#34;2e2f3801-246c-4c2d-842a-bf9fbadbc11e&#34;,&#34;alt&#34; :&#34;&#34;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img 解码=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXeMRO_W2T4rGjwycnXIGluXrdrMbIf0OYp_WFp8cH5CU7HHZ82EHLuDI8xHHnlj3b3H0jEALsmcsNWxXOfo_cPU9PDV 8ji47KX9HUMRhGtyGCfT4VYgGw5x84Xk00MxZFsg3_RgYBNQsKKzR5cWWrwI-jLE?key=rkl1fUrFyfE6SsnQYMStNA&#34; alt=&#34;&#34;referrerpolicy=&#34; no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;图 3：实时活动更新时间线和资产缓存策略。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;小时数据-wp-block-name=&#34;核心/分隔符&#34; data-wp-block=&#34;{&#34;散列&#34;:&#34;093216e5-b2bc-49d6-8ec3-1f40b2b09545&#34;,&#34;不透明度&#34;:&#34;alpha通道&#34;}&#34; class=&#34; wp-块分隔符具有-alpha-通道-不透明度&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;78f18350-259b-45be-abff-c247c5f4ccd1&#34;,&#34;dropCap&#34;:false}&#34;&gt;通常是什么下载资产并将其显示在屏幕上的简单任务，通过实时活动变成了一个更复杂的过程，增加了几个可能的故障点。在我们的情况下，唯一的一线希望是，由于资产在旅行期间很少发生变化，因此我们有机会在必要时重试每次有效负载更新。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;dbc5915a-63ff-4885-bcc7-2094023de069&#34;,&#34;dropCap&#34;:false}&#34;&gt;稍后在本文中，我们将讨论可能的替代解决方案，但有一个主要方面值得注意：不保证该应用程序在旅行期间在后台运行。 Rider 应用程序使用在后台运行的权限，因此我们可以更新用户位置并保证精确的接送信息，但用户或操作系统仍然可以终止该应用程序，从而停止更新流。&lt;br&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;2280f88d-0b85-4b8d-99af-ef7fe91fc1cc&#34;,&#34;dropCap&#34;:false}&#34;&gt;在我们的第一个在设计上，我们完全依赖在后台运行的应用程序来更新实时活动，但在 Beta 测试期间，我们收到了用户的报告，抱怨实时活动停止更新，或者在旅行完成后没有取消。因此，我们选择了利用后端服务和推送通知的不同设计（更多内容请参见 OOA 服务部分）。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;b4838fb0-80f5-49a4-aa4a-45dd71bc9475&#34;,&#34;dropCap&#34;:false}&#34;&gt;主要部分第一个解决方案的目的是估计此功能对后端 API 的影响。  虽然此功能会增加我们 API 服务的流量，但我们相信用户会在应用程序内花费更少的时间，同时减少流量（应用程序需要在前台频繁提取数据）。我们无法猜测用户的行为会如何变化，但我们估计从前台到后台使用的负载转移不会产生影响。此外，作为初始保护措施，添加了一个功能标志来控制后台拉动的速率。然而，在转向上述 OOA 服务后，更新速率已经由后端控制，后端具有更复杂的负载平衡和节流逻辑。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;19436a26-34b7-4c92-86a8-b30aaee10551&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp块分隔符”具有 alpha 通道不透明度&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;c8d6621d-1612-4011-b4ec-95d339b65083&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-measuring-impact-and-collecting-data&#34;&gt;衡量影响和收集数据&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;9dfe427e-8bb8-46ec-a555-7acb9d1651af&#34;,&#34;dropCap&#34;:false}&#34;&gt;衡量影响推出新功能是 Uber 的标准做法。我们预计实时活动将改变用户与我们的应用程序交互的方式，从而显着改进指标，例如减少取消和取货等待时间。下面的数字可能看起来很小，但实际上就我们的运营规模而言，它们是巨大的胜利。根据结果​​，我们相信乘客会更清楚自己何时被接载，从而完成更多行程（以及司机的收入）。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;c89351e4-6746-48a7-ba52-663a2065b074&#34;,&#34;ordered&#34;:false,&#34;values&#34;:&#34; “}”&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;取车时取消司机数量减少 2.26%&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;取车时取消乘客数量减少 2.13%&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;每个请求的取件缺陷减少 1.06%&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;43903745-6d9a-43b0-95c5-4744b7c1d72d&#34;,&#34;dropCap&#34;:false}&#34;&gt;上述指标是对用户行为的衡量，通过添加到应用程序的功能独立衡量。在收集实时活动的工程指标时，它们独特的行为使任务更具挑战性。与普通应用程序不同，实时活动不提供简单的方法来收集没有明显差距的指标。我们必须根据不完整的数据做出假设，例如监控&lt;strong&gt;&lt;em&gt;activityStateUpdates&lt;/em&gt;&lt;/strong&gt;的顺序，以查看实时活动是否在行程结束时正确清除。但是，此序列仅在应用程序在后台运行时才会发出，这是无法保证的，这意味着会丢失大量事件。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;a3b3ca98-e5d4-4f17-8059-02618ee0592d&#34;,&#34;dropCap&#34;:false}&#34;&gt;为了缓解问题是，我们必须加入有关前台事件的数据，其中存在实时活动而没有正在进行的行程。此方法不能保证 100% 覆盖案例，但它允许我们设置可接受的基线并创建回归指标和仪表板，虽然它们不能代表完整的情况，但对于捕获生产或开发过程中的回归仍然有用.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;a51bd47b-2864-49b0-9706-ec7976b60310&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34; class=&#34;wp-block-separator has-alpha-channel -不透明度&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;334591db-c22f-4942-a6e8-976a7a645b60&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-implementing-feature-flags&#34;&gt;实现功能标志&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;d254d666-52ca-4769-bc1f-ea32d1a5279c&#34;,&#34;dropCap&#34;:false}&#34;&gt;另一个标准 Uber实践是标记新功能或相当大的迭代更改。对于实时活动，由于缺乏网络访问以及与主要目标的双边通信，这很棘手。我们使用与图像加载相同的技巧：在主目标启动时，我们从标准管道中读取功能标志并将其值写入磁盘。然后，实时活动在调用时从磁盘读取这些值。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;cca24f0a-abe0-45ec-99db-1fb195ddccf4&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;id&#34;:1093155,&#34;sizeSlug&#34;:&#34;large&#34;,&#34;linkDestination&#34;:&#34;none&#34;,&#34;align&#34;:&#34;中心”，“散列”：“19c012b7-97a2-4c31-868c-077278b52895”，“alt”：“”}“class =“aligncenter size-large”&gt;&lt;img加载=“惰性”解码=“异步”宽度= “1024”高度=“673”src=“https://blog.uber-cdn.com/cdn-cgi/image/width=2160，质量= 80，onerror=重定向，format=auto/wp-content/uploads /2024/07/Figure_4-1024x673.png&#34; alt=&#34;&#34; class=&#34;wp-image-1093155&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality =80，onerror=重定向，format=auto/wp-content/uploads/2024/07/Figure_4.png 1024w，https://blog.uber-cdn.com/cdn-cgi/image/width=300，quality= 80，onerror=重定向，format=auto/wp-content/uploads/2024/07/Figure_4.png 300w，https://blog.uber-cdn.com/cdn-cgi/image/width=768，quality=80 ,onerror=重定向,format=auto/wp-content/uploads/2024/07/Figure_4.png 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1536,quality=80, onerror=重定向，format=auto/wp-content/uploads/2024/07/Figure_4.png 1536w，https://blog.uber-cdn.com/cdn-cgi/image/width=2048，quality=80，onerror =重定向，格式=自动/wp-content/uploads/2024/07/Figure_4.png 2048w“尺寸=”（最大宽度：1024px）100vw，1024px“referrerpolicy=“no-referrer”&gt;&lt;figcaption class=“wp” -element-caption&#34;&gt;图 4：描述功能标志传递到实时活动的图表。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;4fc898b4-1f9b-4b46-a83e-b8ccc3816348&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 数据a-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;259718db-b6a1-44c4-a575-b1bcc18eee74&#34;,&#34;level&#34;:2}&#34; class=&#34;wp-block -heading&#34; id=&#34;h-dsl-android-and-the-ooa-service&#34;&gt;DSL、Android™ 和 OOA 服务&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;d3f56171-ce5b-4fcf-b17b-0879dd541e2e&#34;,&#34;dropCap&#34;:false}&#34;&gt;虽然 Android 没有虽然没有与实时活动直接对应的内容，但我们仍然可以通过更新推送通知来增强推送通知策略，而不是发送新通知，添加与实时活动中使用的相同视觉元素以实现功能对等。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;07aad116-6775-46cc-9ca2-bd25434510fc&#34;,&#34;dropCap&#34;:false}&#34;&gt;简化此操作为了处理并确保 iOS™ 和 Android 之间的一致性，我们开发了一种简单的服务器驱动语言。这种语言使我们能够轻松修改实时活动和 Android 推送通知中呈现的内容。通过将内容逻辑集中在服务器上，我们可以动态更新和定制用户体验，而无需更新应用程序。该系统提供了灵活性，并确保任何更改或新功能都可以在两个平台上快速实施，从而为所有用户保持统一的体验。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;9b69d100-3fed-475f-afdb-03d7c707d53e&#34;,&#34;dropCap&#34;:false}&#34;&gt;我们需要设计一种具有非常小的实现占用空间和很少的外部依赖项的领域特定语言 (DSL)。 Uber 已经有一个服务器驱动的 UI 系统，但它相当广泛，因此无法在不影响二进制大小的情况下导入到外部目标。此外，将功能保持在最低限度还可以降低未来的维护成本。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;e42c67ef-657d-4313-9398-f883de028b97&#34;,&#34;dropCap&#34;:false}&#34;&gt;&lt;br&gt;我们的解决方案是构建一个非常固执己见、半描述性的 DSL。仅包含可以在实时活动中出现的 UI 元素（例如，没有文本字段或分段控制器），并且没有提供广泛的样式。对于需要样式的视图，我们提供了一组标签，然后在客户端级别进行处理。例如，标题标签可以由 &lt;em&gt;Label&lt;/em&gt; 类型的组件以及文本和 &lt;em&gt;title&lt;/em&gt; 类型的标签来表示。然后客户端应用特定样式&lt;em&gt;标题&lt;/em&gt;的字体、颜色、行数、对齐方式等。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;619096ff-7460-4c11-8324-b4bcc1860df4&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;align&#34;:&#34;center&#34;,&#34;hash&#34;:&#34;950fa69b-2d4b-4e55-8d75-b059467bd53e&#34;,&#34;alt&#34;:&#34;&#34;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img解码=&#34;async&#34; src =&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXdsNu5jyXsfpaTI9Vg-oHlbNbNdMHh9Idpf30MDWoRihwehyVMrjCdIn0CM6qhbfwG9uYmXvj0ix5Or984gWE7ADWXuAYEgIOzwgEQT0PRdKv01TZ384gQ8- Jm6gyVLby8pQtNqLa4ABIhQfBaZvKMwMl8?key=rkl1fUrFyfE6SsnQYMStNA&#34; alt=&#34;&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;图 5：水合实时活动的 DSL 有效负载示例。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;308b68d5-cb9c-4a9a-9caa-3831abbae52c&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;e8ef1a57-fd18-40bc-849e-803fa8a1e81d&#34;,&#34;dropCap&#34;:false}&#34;&gt;最后是 DSL不代表任何框架或锚定信息。可以为标题或进度条提供不同的视图，但每个视图的位置由客户端设置并且不能更改（除非与上述标签一起应用的指令）。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;c7252015-a88b-44e8-9a77-4a9a4df67519&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;id&#34;:1093156,&#34;sizeSlug&#34;:&#34;large&#34;,&#34;linkDestination&#34;:&#34;none&#34;,&#34;align&#34;:&#34;中心”，“散列”：“d033db0f-5c7e-4ce8-9ce5-91ffb62239f7”，“alt”：“”}“类=“aligncenter size-large”&gt;&lt;img加载=“惰性”解码=“异步”宽度= “1024”高度=“220”src=“https://blog.uber-cdn.com/cdn-cgi/image/width=2160，质量= 80，onerror=重定向，format=auto/wp-content/uploads /2024/07/Figure_6-1024x220.jpg&#34; alt=&#34;&#34; class=&#34;wp-image-1093156&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality =80，onerror=重定向，format=auto/wp-content/uploads/2024/07/Figure_6.jpg 1024w，https://blog.uber-cdn.com/cdn-cgi/image/width=300，quality= 80，onerror=重定向，format=auto/wp-content/uploads/2024/07/Figure_6.jpg 300w，https://blog.uber-cdn.com/cdn-cgi/image/width=768，quality=80 ,onerror=重定向,format=auto/wp-content/uploads/2024/07/Figure_6.jpg 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1521,quality=80, onerror=redirect，format=auto/wp-content/uploads/2024/07/Figure_6.jpg 1521w&#34; 尺寸=&#34;(最大宽度：1024px) 100vw，1024px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34; wp-element-caption&#34;&gt;图 6：演示模板如何在实时活动和 Android 推送通知上工作。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;29e191ed-f97e-412e-8c92-f2d44abda49c&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;8ce1fd0b-1827-46de-be68-99978022606e&#34;,&#34;dropCap&#34;:false}&#34;&gt;协同工作通过这个新的 DSL 系统，我们开发了一项专门为应用程序外部的界面设计的后端服务；我们称之为 OOA 服务（Out Of App）。 OOA 服务负责平衡传送到 Apple 推送通知服务的更新量的逻辑。它评估应用程序状态的更改是否重要到需要交付，以及消除快速连续发生的状态更改。由于需要评估和反跳，该服务必须缓存平台上所有并发行程的先前状态，这是一项巨大的扩展工作。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;f1c38265-62e8-44a2-ac71-622ac7b4a94d&#34;,&#34;dropCap&#34;:false}&#34;&gt;构建 DSL OOA 服务是向前迈出的重要一步。它不仅简化了开发过程，而且还为集成更改打开了大门，而无需复制决策树逻辑并在多个平台上部署代码。通过构建这个通用解决方案，我们可以避免在不同的团队中多次解决复杂的问题。尤其是，我们相信这一决定将在未来带来红利，因为 Uber 越来越多的垂直团队利用实时活动流程。&lt;br&gt;甚至 Eats 平台也已经使用了处理移动框架的很大一部分。与实时活动生命周期、图像缓存和功能标志注入。在看到 Rider 集成的积极成果后，他们还在评估 DSL 和 OOA 服务的上线。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;7c605f28-0f27-430e-aa1b-856fb0a30877&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:1,&#34;hash&#34;:&#34;456dd394-451c-43ec-8264-99820ff236a2&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-conclusion&#34;&gt;结论&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;8fdbe365-654c-49bf-becc-de4ebf7d98b6&#34;,&#34;dropCap&#34;:false}&#34;&gt;构建 Rider iOS Live Activity 是一次紧张但收获颇丰的旅程。从 WWDC 宣布的惊喜到在紧迫的时间内开发和实施新技术的挑战，这些经历展示了我们团队的韧性、适应性和创造力。我们克服了技术障碍，重新定义了我们的用户体验方法，并最终提供了一项我们认为改善了骑手和驾驶员体验的功能。我希望我们在本文中所展示的独创性可以启发对于任何从事实时活动的开发人员来说，帮助他们克服类似的场景，并通常对主应用程序之外的体验采取务实的方法。&lt;br&gt;在个人层面上，这是一次很好的经历和机会：培养早期采用者对于我们这样规模的公司来说，开发产品具有挑战性，但却非常令人满意。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;73a51cf5-4e2c-4d8a-8ca9-51e142dde84b&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-acknowledgments&#34;&gt;致谢&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;cfcd3e00-4b2b-4695-be8f-619d8c2dc7f9&#34;,&#34;dropCap&#34;:false}&#34;&gt;特别感谢给整个团队。这个项目不仅展示了每个人的技术实力，还凸显了 Uber 推动创新的协作精神。凯尔·加布里埃尔、Ken Nguyen、Tiffany Chang、Hyewon Son、Radhika Gemawat、Maxim Bogatov、丁一凡、Evan Cooper&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;fontSize&#34;:&#34;小&#34;,&#34;hash&#34;:&#34;0d80d3ae-d935-48d4-823a-9768c64618bd&#34;,&#34;dropCap&#34; :false}&#34; class=&#34;has-small-font-size&#34;&gt;Apple、App Store、Swift 和 SwiftUI 是 Apple Inc. 在美国和其他国家和地区注册的商标。&lt;br&gt;iOS 是商标或是 Cisco 在美国和其他国家/地区的注册商标，Apple 经许可使用。&lt;br&gt;Android 是 Google LLC 在美国和其他国家/地区注册的商标。&lt;/p&gt;</description>
      <pubDate>Thu, 25 Jul 2024 07:32:52 +0000</pubDate>
    </item>
    <item>
      <title>【Odin: Uber’s Stateful Platform】Odin：Uber 的有状态平台</title>
      <link>https://www.uber.com/blog/odin-stateful-platform/</link>
      <description>【&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;90695143-31cf-483d-b85f-7ce1334bb6f8&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-introduction&#34;&gt;Introduction&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;548c2e1c-75fa-4ffa-905e-ca342260c0d0&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Uber employs various technologies for data storage, including well-known open-source products such as Kafka, Cassandra, and MySQL, alongside internally developed solutions. In 2014, Uber underwent rapid expansion. Like many startups, the technology teams manually performed provisioning and maintenance operations using runbooks. This approach led to operational toil as storage demands rapidly increased. Uber created a technology-agnostic management platform called Odin to uplevel operational throughput through automation and allow the teams to manage thousands of databases effortlessly.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8cf61d25-9d6d-40de-a187-c932da9d9811&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The Odin platform aims to provide a unified operational experience by encompassing all aspects of managing stateful workloads. These aspects include host lifecycle, workload scheduling, cluster management, monitoring, state propagation, operational user interfaces, alerting, auto-scaling, and automation. Uber deploys stateful systems at global, regional, and zonal levels, and Odin is designed to manage these systems consistently and in a technology-agnostic manner. Moreover, Odin supports co-location to increase hardware cost efficiency. All stateful workloads must be fully containerized, a relatively novel and &lt;a href=&#34;https://news.ycombinator.com/item?id=13054793&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;controversial&lt;/a&gt; concept when the platform was created.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6f97caa1-0a1f-46ab-8261-61b142951e9f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;This blog post is the first of a series on Uber’s stateful platform. The series aims to be accessible and engaging for readers with no prior knowledge of building container platforms and those with extensive expertise. This post provides an overview of Odin’s origins, the fundamental principles, and the challenges encountered early on. The next post will explore how we have safely scaled operational throughput, significantly improving our handling of large-scale, fleet-wide operations and up-leveling runbooks through workflows. Stay tuned for more posts in the series.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5d8805b0-a807-4ce6-b495-7e2138a76eba&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0e529716-5369-49b9-a516-66e71fa92691&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-the-scale-of-the-platform&#34;&gt;The Scale of the Platform&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c7275b4e-2c3a-465d-ae42-598f1e28f875&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Since 2014, Uber’s storage and data infrastructure has grown dramatically, from a few hundred hosts to over 100,000 today. These hosts support the operation of 300,000 workloads across various storage clusters. Each workload on the Odin platform is similar to a Kubernetes® pod, comprising a collection of containers. Currently, the platform manages 3.8 million individual containers. The fleet of hosts collectively boasts a storage capacity of multiple exbibytes and millions of compute cores.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;70705850-6138-44c0-b04f-cfc5d407b5a5&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The platform supports 23 technologies, ranging from traditional online databases such as MySQL® and Cassandra® to advanced data platform technologies, including HDFS™, Presto™, and Kafka®. It also integrates resource scheduling frameworks like Yarn™ and Buildkite™, primarily due to the platform’s robust capacity management and scaling solutions.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;bc701c08-c47b-4395-bee9-06a97e004924&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The platform is heavily colocated to leverage the resources available on the hosts best. Uber uses locally attached drives for all stateful workloads for performance. Our scheduler, therefore, has to optimize to keep allocation rates high across all three dimensions (i.e., CPU, memory, and disk) to be efficient. We boast a very high allocation rate of +95% on the bottlenecked resource, and we have hosts with +100 databases.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a952ccc3-67f4-44c4-8ebd-c3867d80f3cd&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The Odin platform is both technology-agnostic and cloud-agnostic through &lt;a href=&#34;https://www.uber.com/en-SE/blog/crane-ubers-next-gen-infrastructure-stack/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Uber’s cloud abstraction&lt;/a&gt; and currently runs across OCI, GCP, and Uber’s on-prem fleet.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0aba77a1-cb2f-4642-93ee-48c85afed8ba&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;49ba8eed-f6b5-48d7-9472-a225618b4db4&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-a-self-healing-platform&#34;&gt;A Self-Healing Platform&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;578c4714-ae37-4b95-94aa-7902076a06d7&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Odin is built to be fully declarative and intent-based. This results in properties such as failure tolerance, scalability, and self-healing. The desired state is expressed as the goal state, which the platform uses to converge the actual state automatically. We accomplish this by using an extensive collection of small, autonomous remediation loops designed to ensure the system’s actual state converges with the declared goal state by continuously nudging the system in the “right direction.”&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7df9c643-7221-4e50-99b6-e7223356e28f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Today, Odin and Kubernetes® share many similarities. This mental model will be helpful as you read through the blog series.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;fe74b631-4317-499c-a507-32164ec308bc&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The example below illustrates the anatomy of a remediation loop. A remediation loop starts by inspecting the goal state. It then collects the actual state, identifies discrepancies between the two, and uses &lt;a href=&#34;https://cadenceworkflow.io/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Cadence™ workflows&lt;/a&gt; to adjust the system state to close the gap. This is similar to how Kubernetes controllers work–except they directly manipulate the state through the APIServer.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f6ae9904-86ac-423f-95e2-a04e0f831377&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;4743a97f-d970-4b9e-bcc7-60029013f43b&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXfrbiVvJh6xCuhP9K9RQRFzpiFd5uwiRBFOOtPiMfB7iRYc_z-MMSXNB34iLdfE_-mIIx2HbQz08pY1IRYeuaaa_W6JlTy2IvK3owVsrkDSPqnwXAXAvy9LX3zySlsEbvmUXL3AcAaXGIMgzpvf0RwXAeP-?key=0kVK3UHY5mqh0YpEHEfxHw&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 1: High-level overview of an Odin remediation loop.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;79575b6a-b658-4b7e-adff-72767d32195f&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8b602db4-cbe7-46fb-8ce3-a60810a26396&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Our remediation loops prioritize modularity and loose coupling. This facilitates horizontal scaling and ease of development so that each loop can be developed as an independent microservice.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2397929c-c8f4-432b-ba9d-96439c194265&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;On the Odin platform, we have streamlined the development of these loops by providing an up-to-date view of the global system state through our data integration platform, &lt;a href=&#34;https://eng.uber.com/grail&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Grail&lt;/a&gt;. Grail delivers a unified data model that spans all technologies and provides an up-to-date view of the platform’s goal and actual states, including hosts, containers, and even the technology-specific internal state. Our Grail setup also allows performing queries with a global scope, fetching data provided in all the data centers and regions around the globe where Uber operates. In essence, think of Grail as the resource model in the Kubernetes APIServer on steroids.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e0b4f9d7-27e9-4f5a-b0be-32ff310cbbe9&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The platform’s control plane focuses solely on high-level decisions, such as scheduling workloads and managing cluster topology.&amp;nbsp; The API for manipulating the goal state is the execution of a workflow. Both remediation loops and human operators start workflows. The platform provides a UI that allows operators to quickly overview the state of their databases and apply operations when needed.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;141a1dce-0b34-4801-b240-c434901bc5ec&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Workflows are incredibly valuable because of the insights they provide. A workflow for updating goal state usually consists of two steps. First, the goal state is updated, and then the workflow will monitor the actual state until it converges on the specified goal state. So when it doesn’t, it is clear which operations didn’t converge, including the context of why that operation was performed in the first place. As the actual state is not expected to converge immediately, the system must prevent the remediation loops from continuously starting workflows that attempt to fix the same issues.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;cf949352-02eb-4d3b-a249-178fe472a2a3&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;271afd88-96a7-4bd9-849c-7e5886fc5d50&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXfkpBCcYU1h2PhNjamcT3aGcIQWIAr7wn-77iP7vY861TcFRrSJ9b4oayn5Brm7MgSzS3nqJqB0J9Qys0t6CnYtHWgIYckWP64HUxy-8LKxmnHBgC-DJU2zkpCZpmTZiLEJ4GP08aLD5yqOgOuk6S4KDsc4?key=0kVK3UHY5mqh0YpEHEfxHw&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 2: A 10.000ft view of Odin’s architecture.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;56db4950-7d76-45b8-819e-0dd0fa247fdd&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2acecab1-597e-464e-a287-66bd80786482&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-managing-generic-storage-clusters&#34;&gt;Managing Generic Storage Clusters&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d0ffd8b7-98aa-4deb-94ae-15aee37e8492&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Odin is built on a technology-agnostic cluster model that provides generic operations for managing clusters of workloads of any kind. This model supports generic operations such as adding or removing workloads, upgrading container images, and handling other cluster-related tasks uniformly across technologies. As the model and operations are technology-agnostic, the technology is required to extend the platform through a collection of plugins to tailor various aspects of cluster management according to their specific needs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;cda4e095-7482-482f-b6b2-a05a92a267d6&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-two-host-agents&#34;&gt;Two Host Agents&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;dd82e5e7-cf72-4e2e-ab87-2d536dd42dbe&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The Odin control plane is divided into two parts. So far, we have only discussed the global part. At the host level, there are two agents. One is shared among all workloads on the host and is technology-agnostic. We simply refer to this as the &lt;em&gt;odin-agent&lt;/em&gt;. The other agent is technology-specific and runs containerized as part of the workload. These two agents, when combined, serve the same functionality as the &lt;em&gt;kubelet&lt;/em&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;65a90e51-2220-4720-94ac-84668c27dbbd&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;a12eed6c-d521-456b-8c52-de1b38e4bec2&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXdSePHcS8Ijkt17F1dBAJtAyQ4DANP0C3CoVQdZFqpTDNdMg6oUZLrPRUgoTrTUC_3ukppykFnZiFLkJkfTrH_iV_OW5XdhajSi6fKC9z7fSq9Yw6x8l0XgDvomdfCgZqe5Z5ZZYeHvmvAwoeaMPNZEyoHs?key=0kVK3UHY5mqh0YpEHEfxHw&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 3: The anatomy of an Odin host with the two host-level agents communicating with the global control plane.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e0817d94-ec97-4063-9a8c-4e9904175475&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1621dd43-a4be-45da-b5d6-0d17c0c5bb08&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The host agent communicates the latest goal and actual states with the global control plane. Its primary responsibility is managing host-level resource allocation, such as scheduling cores for workloads, creating and managing disk volumes/cgroups, and bootstrapping the workloads when assigned to the host.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8fa5a88e-540a-4c48-b1cc-ed7df86a3a00&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The technology-specific agent is known as the &lt;em&gt;worker&lt;/em&gt;. The worker is a supervisor running alongside each workload in a side container. Its primary role is to ensure that the running containers align with the goal state and to collect health and other relevant data for reporting to the global part of the control plane. The worker’s generic functionality includes starting and stopping containers. You can think of the worker as the translator between the generic cluster state the platform understands and the running database containers in the workload.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9965fa47-2eb1-4626-b1d3-dc518449f76a&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The technology team can customize the worker to collect the technology-specific actual state and apply the goal state to the workload. For instance, the MySQL worker is tasked with ensuring that MySQL masters and replicas maintain their roles and report the current state for consumption to the global control plane. This allows the team to write new workflows for operating the cluster based on the actual state of the cluster. Many technologies have extended their workers to perform self-healing cluster operations in their workers. Examples could be coordinating leader elections or data replication when the cluster topology changes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;5598ca20-758c-4080-b97b-81afc4cffece&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-optimizing-for-robustness-and-resilience&#34;&gt;Optimizing for Robustness and Resilience&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;26972dfb-89dd-40ce-906d-ca16199626d9&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Separating the control plane into a host-local and a global component allows us to deploy worker changes per workload, limiting the potential blast radius of bad changes to the smallest possible unit. The same applies to each container in a workload, as the platform allows in-place upgrading containers individually.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;138c489d-3c9f-4892-84e1-6387f9265a64&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;For both agents, a rule is that the goal state must first be written to disk before any changes to the running workloads are made. This approach guarantees self-sufficient clusters that can be initialized without an active control plane, effectively addressing the bootstrap issue. Furthermore, it offers robust failure resilience, allowing workloads to function during control plane degradations and simplifying writing emergency tooling.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;f07917a0-558e-42cb-b46f-c7a20196c247&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-transitioning-identities&#34;&gt;Transitioning Identities&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1eef1f47-896d-478c-9dfe-b43cd5b83885&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;As we continuously optimize for efficiency and modernize our host fleet, moving a workload from one host to another has become one of the most common operations on the platform. To date, we reschedule up to 60% of our stateful workloads per month. A crucial requirement of stateful workloads is maintaining the workload identity across rescheduling. This capability allows, for example, the replacement of one workload serving a shard with another serving the same shard. In Kubernetes, this is managed through StatefulSets by assigning a stable pod identity that persists across rescheduling. When a pod is deleted, a new one is provisioned with the same identity. Let us explore why this model does not suit Uber’s use case well.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1bbb811d-86a9-4cd2-b96b-21285d91dabe&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;As mentioned, Uber uses locally attached drives for all stateful workloads for performance. This setup requires that data on a host be replicated and made available elsewhere before the corresponding workload can be terminated. The cluster becomes temporarily under-provisioned if a workload is shut down before its replacement is fully ready. This delay, which is not negligible with a median time of 1 hour, exposes the cluster to an increased risk of data loss or availability issues. Moreover, this delay also diminishes the cluster’s overall capacity to handle requests.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;3b6e5f94-d8c1-4822-aff4-a93c79b744c9&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-replacing-workloads&#34;&gt;“Replacing” Workloads&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;aa7ad1d4-ea62-4c1c-910d-8286f06a3711&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Consequently, the most essential operation on Odin is migrating a workload from one host to another–or, in Odin terms, “replacing” the workload. A replace operation is purposely designed to &lt;em&gt;make-before-break&lt;/em&gt;. This means it creates a new workload that can carry the identity and data of the workload it replaces &lt;em&gt;before&lt;/em&gt; the old workload is shut down, wherever possible. The technology integrations can choose which parts of the goal state to propagate between workloads. The goal state model makes the two workloads explicitly aware of each other’s existence. This is essential because it allows the respective workers to coordinate the process for data replication and other things. In rare cases, when &lt;em&gt;make-before-break&lt;/em&gt; semantics are impossible (e.g., the old workload is on a failed host), the old workload is deleted simultaneously with the replacement workload being created.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f2c8a1a1-fe85-4656-bbd8-381c24da7641&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Using make-before-break also has an efficiency benefit, as the alternative would require us to run the clusters overprovisioned continuously. In our model, we only temporarily overprovision when we have to.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;de1ed6fc-1a1e-4666-b2e9-c58224a32d9e&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c29e483c-a48a-4924-a033-ef8503c36fe1&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-growing-pains&#34;&gt;Growing Pains&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;dad7f7a3-0ea3-479b-a1fe-9bfa5af38d18&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The first iteration of the Odin platform was a giant leap forward concerning the teams’ ability to operate their storage clusters. Storage teams could converge all their operations and insights on a single platform with a shared operational model. However, the platform was still very much human-centered. Humans were the principal actors initiating changes on the platform, and, crucially, they were the ones vouching for the safety and the fit of the operations performed. The role of the remediation loops was confined to operations with a relatively small scope, such as a single replace workflow&lt;em&gt;.&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;fad8c154-683f-4e0d-ba9b-d1d4b7157cb8&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Operational overhead started to grow as the business continued to scale to the point where fleet-wide operations spanning technologies were not practically possible for human operators to do. Examples of complex, fleet-wide, cross-technology operations that require us to move workloads are:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0c6b29b5-a3b0-4770-b81e-5374de15e4b5&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Optimizing workload placement for resiliency against infrastructural failures like rack or zone failures&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Host bin-packing to improve cost-efficiency&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Fleet-wide host upgrades like new kernels, firmware, or functionality like LVM/cgroupv2&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Facilitating the bringing up of new data centers or decommissioning existing data centers&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;668aa557-dc41-41b6-a40a-29371389096e&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Furthermore, the large number of databases on a single host makes handling host failures daunting. These limitations indicated that we had to double down on automation by developing new remediation loops with much broader scopes than we used to.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;56f8fe34-2ef2-4a3f-bb0d-4f69c90b960c&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-coordination-required&#34;&gt;Coordination Required&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8036e749-8a7a-4c7f-b617-1321eac2cf8f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The increased operational load could quickly result in outages if not carefully coordinated. Imagine a situation where a workload in a 3-node consensus-based storage cluster is taken down to perform a container upgrade. Now imagine another remediation loop that has identified that one of the other workloads in the cluster would benefit from being moved for efficiency reasons. If allowed, this would result in the storage cluster losing quorum, impacting the write availability.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;44963a9c-9e27-4921-91da-42d031dd81be&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Initially, we started augmenting the remediation loops to perform concurrency control internally (Figure 3). This way, they could prevent operations of the same type from creating problems for the storage clusters. For instance, the container upgrade loop would block overlapping upgrades. However, this approach fell short as it didn’t solve the issue of conflicting operations started by different remediation loops. Figure 3 shows a case where two independent operations can operate two workloads in the same storage cluster, resulting in an availability loss.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;37267e15-3898-4883-b5d5-6617d00f67ce&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;d131b897-0c2b-4684-8052-d5db42a85208&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXd4i6HPr3ZkL1WFmR1Kd-mkiLceVO0Liik1jb6NR51eaucwSAjFss_8QW_m-doDIHsbCW9kv5TJwgPukhH3rPiaE1o0lWbpvtlwSliGofFpGiD68jS5NGuxR1V3HZs6HxnZYsScd9vpweh0ouKSHRF0RlbN?key=0kVK3UHY5mqh0YpEHEfxHw&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 4: Internal concurrency control does not protect storage clusters against overlapping operations and can compromise availability.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4ab49524-3b00-4ca5-b966-d2a03569fdc2&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5304b888-d27b-4d5c-8703-a262a8183b7f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Different technologies exhibit widely varying tolerances for safe cluster operations. For some technologies, the specific workloads being operated are crucial, while all workloads are treated equally for others. Some technologies focus solely on ensuring that a certain number of workloads are always available within the cluster. This diversity in requirements made it such that we had to support customizing cluster management strategies to the specific needs of each technology.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d2d9eb70-3d33-4f06-a09d-71c7ba530c6c&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We needed to ensure global, cross-type coordination of operations using a system that could guarantee to preserve the cluster availability by leveraging technology-specific limits based on the current workload health and disruption budget. Furthermore, it should protect against engineering mistakes and overload of the internal platform systems by enforcing platform-wide global concurrency and rate limits.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;573fa4c8-a71a-4934-bdd2-6e76c64ce602&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;4b05fc1f-55a2-498f-8240-0bbc9d986ea0&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-summary&#34;&gt;Summary&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;cd8543d3-0d20-4857-97d7-92d0f10392a5&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In this introductory post of our series, we explored the background and foundational principles of Uber’s stateful platform, Odin. Odin stands out as a generic, technology-agnostic platform capable of managing various technologies with special demands on how databases are operated.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b162d0bd-d1af-4e18-bad6-01cf9829155e&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We discussed how Uber’s databases use locally attached disks for enhanced performance and cost-efficiency and the challenges this presents, as the stored data must follow the workload identity.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a6a3e2b0-f102-45ac-8dab-4f45887f56c1&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We also examined how the platform is inherently intent-based, with disparate remediation loops continuously striving to align the actual state of the managed workloads with their intended goal states. These loops initiate Cadence workflows to update the goal state and wait for convergence—a process that, at scale, requires careful coordination to safely manage without compromising the availability of the managed databases.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;89518bc2-03a8-452f-a779-fab4eb21f534&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In the next blog post, we will discuss how we centralized the coordination of all operations and leveraged it to significantly improve Uber’s ability to operate the fleet at scale.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;74b918d1-e0a6-4dd8-adb0-261d96dcccdb&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-acknowledgments&#34;&gt;Acknowledgments&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;114640af-7176-4346-87ab-dd430c350a03&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The Odin platform was only possible with the effort of many contributors through the years. The authors would like to thank all the teams working on the platform or contributing integrations and to previous team members who helped make the platform great.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;fontSize&amp;quot;:&amp;quot;small&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;5ad1e8e8-0a5d-4299-8c12-36015f6ef911&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34; class=&#34;has-small-font-size&#34;&gt;The cover photo was generated using OpenAI’s ChatCPT Enterprise and edited using Pixlr.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;fontSize&amp;quot;:&amp;quot;small&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;44181acd-1a06-48b7-97b3-2538dfbffe59&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34; class=&#34;has-small-font-size&#34;&gt;Kubernetes® is a registered trademark of the Linux Foundation in the United States and other countries.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;fontSize&amp;quot;:&amp;quot;small&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;a3a471c0-0118-4ea6-840b-90e764c1ea0e&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34; class=&#34;has-small-font-size&#34;&gt;MySQL® is a registered trademark of Oracle Corporation and/or its affiliates.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;fontSize&amp;quot;:&amp;quot;small&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;3827feed-6951-4e20-bd15-7fb796002361&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34; class=&#34;has-small-font-size&#34;&gt;Apache Cassandra®, Apache HDFS™, Apache Kafka®, Apache Yarn™, and Apache Presto™ are registered trademarks or trademarks of the Apache Software Foundation in the United States and/or other countries. The use of these marks does not imply endorsement by the Apache Software Foundation.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;fontSize&amp;quot;:&amp;quot;small&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;06d69f2b-38ee-4898-946e-02588d178a99&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34; class=&#34;has-small-font-size&#34;&gt;Buildkite™ is a trademark of Buildkite Pty Ltd.&lt;/p&gt;】&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:1,&#34;hash&#34;:&#34;90695143-31cf-483d-b85f-7ce1334bb6f8&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-introduction&#34;&gt;简介&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;548c2e1c-75fa-4ffa-905e-ca342260c0d0&#34;,&#34;dropCap&#34;:false}&#34;&gt;Uber 使用各种数据存储技术，包括Kafka、Cassandra、MySQL等知名开源产品以及内部开发的解决方案。 2014年，Uber经历了快速扩张。与许多初创公司一样，技术团队使用运行手册手动执行配置和维护操作。随着存储需求的迅速增加，这种方法导致了运营工作的繁重。 Uber 创建了一个名为 Odin 的技术无关管理平台，通过自动化提高运营吞吐量，并允许团队轻松管理数千个数据库。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;8cf61d25-9d6d-40de-a187-c932da9d9811&#34;,&#34;dropCap&#34;:false}&#34;&gt;Odin 平台旨在通过涵盖管理有状态工作负载的各个方面来提供统一的操作体验。这些方面包括主机生命周期、工作负载调度、集群管理、监控、状态传播、操作用户界面、警报、自动扩展和自动化。 Uber 在全球、区域和区域级别部署有状态系统，而 Odin 旨在以与技术无关的方式一致地管理这些系统。此外，Odin 支持主机托管以提高硬件成本效率。所有有状态工作负载都必须完全容器化，这是一个相对新颖且&lt;a href=&#34;https://news.ycombinator.com/item?id=13054793&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;有争议的&lt;/a&gt;平台创建时的概念。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;6f97caa1-0a1f-46ab-8261-61b142951e9f&#34;,&#34;dropCap&#34;:false}&#34;&gt;这篇博文是 Uber 有状态平台系列文章的第一篇。该系列旨在让那些没有构建容器平台知识和具有广泛专业知识的读者能够理解并参与其中。这篇文章概述了 Odin 的起源、基本原则以及早期遇到的挑战。下一篇文章将探讨我们如何安全地扩展运营吞吐量，显着改善我们对大规模、整个车队运营的处理，并通过工作流程升级运行手册。请继续关注该系列的更多帖子。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;5d8805b0-a807-4ce6-b495-7e2138a76eba&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;0e529716-5369-49b9-a516-66e71fa92691&#34;,&#34;level&#34;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-the-scale-of-the-platform&#34;&gt;平台规模&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;c7275b4e-2c3a-465d-ae42-598f1e28f875&#34;,&#34;dropCap&#34;:false}&#34;&gt;自 2014 年以来， Uber 的存储和数据基础设施急剧增长，从几百台主机增加到如今的 100,000 多个主机。这些主机支持跨各种存储集群的 300,000 个工作负载的运行。 Odin 平台上的每个工作负载都类似于 Kubernetes® Pod，由容器集合组成。目前，该平台管理着 380 万个独立容器。主机群总共拥有数艾字节的存储容量和数百万个计算核心。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;70705850-6138-44c0-b04f-cfc5d407b5a5&#34;,&#34;dropCap&#34;:false}&#34;&gt;平台支持23种技术，从传统的在线数据库（如MySQL®和Cassandra®）到先进的数据平台技术（包括HDFS™、Presto™和Kafka®）。它还集成了 Yarn™ 和 Buildkite™ 等资源调度框架，这主要归功于该平台强大的容量管理和扩展解决方案。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;bc701c08-c47b-4395-bee9-06a97e004924&#34;,&#34;dropCap&#34;:false}&#34;&gt;该平台是大量集中在一起，以最好地利用主机上的可用资源。 Uber 使用本地连接的驱动器来处理所有有状态工作负载，以提高性能。因此，我们的调度程序必须进行优化，以在所有三个维度（即 CPU、内存和磁盘）上保持较高的分配率，从而提高效率。我们拥有高达+95%的瓶颈资源分配率，并且我们拥有拥有+100个数据库的主机。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;a952ccc3-67f4-44c4-8ebd-c3867d80f3cd&#34;,&#34;dropCap&#34;:false}&#34;&gt;Odin 平台通过 &lt;a href=&#34;https://www.uber.com/en-SE/blog/crane-ubers-next-gen-infrastruct-stack/&#34; target=&#34;_blank&#34; rel 既与技术无关，又与云无关=&#34;noreferrer noopener&#34;&gt;Uber 的云抽象&lt;/a&gt;，目前在 OCI、GCP 和 Uber 的本地部署中运行。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;0aba77a1-cb2f-4642-93ee-48c85afed8ba&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;49ba8eed-f6b5-48d7-9472-a225618b4db4&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-a-self-healing-platform&#34;&gt;自我修复平台&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;578c4714-ae37-4b95-94aa-7902076a06d7&#34;,&#34;dropCap&#34;:false}&#34;&gt;Odin 已构建完全声明性且基于意图。这导致了诸如容错能力之类的属性性、可扩展性和自我修复。期望状态表示为目标状态，平台使用目标状态自动收敛实际状态。我们通过使用大量小型自主修复循环来实现这一目标，这些循环旨在通过不断推动系统朝“正确的方向”推进，以确保系统的实际状态与声明的目标状态一致。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;7df9c643-7221-4e50-99b6-e7223356e28f&#34;,&#34;dropCap&#34;:false}&#34;&gt;今天，奥丁和 Kubernetes® 有许多相似之处。当您阅读本博客系列时，这种思维模型将会很有帮助。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;fe74b631-4317-499c-a507-32164ec308bc&#34;,&#34;dropCap&#34;:false}&#34;&gt;下面的示例说明了修复循环的剖析。补救循环从检查目标状态开始。然后，它会收集实际状态，识别两者之间的差异，并使用 &lt;a href=&#34;https://cadenceworkflow.io/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Cadence™ 工作流程&lt;/a&gt;进行调整系统状态来缩小差距。这与 Kubernetes 控制器的工作方式类似，只不过它们通过 APIServer 直接操纵状态。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;f6ae9904-86ac-423f-95e2-a04e0f831377&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;align&#34;:&#34;center&#34;,&#34;hash&#34;:&#34;4743a97f-d970-4b9e-bcc7-60029013f43b&#34;,&#34;alt&#34; :&#34;&#34;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img 解码=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXfrbiVvJh6xCuhP9K9RQRFzpiFd5uwiRBFOOtPiMfB7iRYc_z-MMSXNB34iLdfE_-mIIx2HbQz08pY1IRYeuaaa_W6JlTy 2IvK3owVsrkDSPqnwXAXAvy9LX3zySlsEbvmUXL3AcAaXGIMgzpvf0RwXAeP-?key=0kVK3UHY5mqh0YpEHEfxHw&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;图 1：Odin 修复循环的高级概述。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;79575b6a-b658-4b7e-adff-72767d32195f&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;8b602db4-cbe7-46fb-8ce3-a60810a26396&#34;,&#34;dropCap&#34;:false}&#34;&gt;我们的修复循环优先考虑模块化和松耦合。这有利于水平扩展和易于开发，以便每个循环都可以开发为独立的微服务。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;2397929c-c8f4-432b-ba9d-96439c194265&#34;,&#34;dropCap&#34;:false}&#34;&gt;关于奥丁平台，我们简化了开发通过我们的数据集成平台 &lt;a href=&#34;https://eng.uber.com/grail&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34; 提供全局系统状态的最新视图来实现这些循环&gt;圣杯&lt;/a&gt;。 Grail 提供了一个涵盖所有技术的统一数据模型，并提供了平台目标和实际状态的最新视图，包括主机、容器，甚至特定于技术的内部状态。我们的 Grail 设置还允许在全球范围内执行查询，获取 Uber 运营的全球所有数据中心和地区提供的数据。本质上，可以将 Grail 视为 Kubernetes APIServer 中的资源模型。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;e0b4f9d7-27e9-4f5a-b0be-32ff310cbbe9&#34;,&#34;dropCap&#34;:false}&#34;&gt;平台的控制plane 仅专注于高层决策，例如调度工作负载和管理集群拓扑。  用于操作目标状态的 API 是工作流程的执行。修复循环和人工操作员都会启动工作流程。该平台提供的 UI 允许操作员快速概览数据库的状态并在需要时应用操作。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;141a1dce-0b34-4801-b240-c434901bc5ec&#34;,&#34;dropCap&#34;:false}&#34;&gt;工作流程令人难以置信由于他们提供的见解而有价值。更新目标状态的工作流程通常包含两个步骤。首先，更新目标状态，然后工作流将监视实际状态，直到收敛于指定的目标状态。因此，当没有收敛时，哪些操作没有收敛就一目了然，包括为什么首先执行该操作的上下文。由于实际状态预计不会立即收敛，因此系统必须防止修复循环不断启动尝试修复相同问题的工作流程。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;cf949352-02eb-4d3b-a249-178fe472a2a3&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;align&#34;:&#34;center&#34;,&#34;hash&#34;:&#34;271afd88-96a7-4bd9-849c-7e5886fc5d50&#34;,&#34;alt&#34; :&#34;&#34;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img 解码=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXfkpBCcYU1h2PhNjamcT3aGcIQWIAr7wn-77iP7vY861TcFRrSJ9b4oayn5Brm7MgSzS3nqJqB0J9Qys0t6CnYtHW gIYckWP64HUxy-8LKxmnHBgC-DJU2zkpCZpmTZiLEJ4GP08aLD5yqOgOuk6S4KDsc4?key=0kVK3UHY5mqh0YpEHEfxHw&#34; alt=&#34; &#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;图 2：Odin 建筑的 10.000 英尺视图。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;56db4950-7d76-45b8-819e-0dd0fa247fdd&amp;quot;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;2acecab1-597e-464e-a287-66bd80786482&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-managing-generic-storage-clusters&#34;&gt;管理通用存储集群&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;d0ffd8b7-98aa-4deb-94ae-15aee37e8492&#34;,&#34;dropCap&#34;:false}&#34;&gt;Odin 已构建基于与技术无关的集群模型，该模型提供用于管理任何类型工作负载集群的通用操作。该模型支持通用操作，例如添加或删除工作负载、升级容器映像以及跨技术统一处理其他与集群相关的任务。由于模型和操作与技术无关，因此需要通过一系列插件来扩展平台，以根据其特定需求定制集群管理的各个方面。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;cda4e095-7482-482f-b6b2-a05a92a267d6&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-two-host-agents&#34;&gt;两个主机代理&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;dd82e5e7-cf72-4e2e-ab87-2d536dd42dbe&#34;,&#34;dropCap&#34;:false}&#34;&gt;Odin 控件平面分为两部分。到目前为止，我们只讨论了全局部分。在主机级别，有两个代理。一种是在主机上的所有工作负载之间共享的，并且与技术无关。我们简称为&lt;em&gt;odin-agent&lt;/em&gt;。另一个代理是特定于技术的，并作为工作负载的一部分运行容器化。这两个代理结合起来可提供与 kubelet 相同的功能。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;65a90e51-2220-4720-94ac-84668c27dbbd&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;align&#34;:&#34;center&#34;,&#34;hash&#34;:&#34;a12eed6c-d521-456b-8c52-de1b38e4bec2&#34;,&#34;alt&#34; :&#34;&#34;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img 解码=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXdSePHcS8Ijkt17F1dBAJtAyQ4DANP0C3CoVQdZFqpTDNdMg6oUZLrPRUgoTrTUC_3ukppykFnZiFLkJkfTrH_iV_OW5Xdhaj Si6fKC9z7fSq9Yw6x8l0XgDvomdfCgZqe5Z5ZZYeHvmvAwoeaMPNZEyoHs?key=0kVK3UHY5mqh0YpEHEfxHw&#34; alt=&#34;&#34;referrerpolicy=&#34;no- referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;图 3：Odin 主机的剖析，其中两个主机级代理与全局控制平面进行通信。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;e0817d94-ec97-4063-9a8c-4e9904175475&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator”有-alpha-通道不透明度&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;1621dd43-a4be-45da-b5d6-0d17c0c5bb08&#34;,&#34;dropCap&#34;:false}&#34;&gt;主机代理与全局控制平面传达最新目标和实际状态。它的主要职责是管理主机级资源分配，例如为工作负载调度核心、创建和管理磁盘卷/cgroup，以及在分配给主机时引导工作负载。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;8fa5a88e-540a-4c48-b1cc-ed7df86a3a00&#34;,&#34;dropCap&#34;:false}&#34;&gt;技术-特定代理称为&lt;em&gt;工作人员&lt;/em&gt;。工作人员是一个主管，与侧容器中的每个工作负载一起运行。其主要作用是确保正在运行的容器与目标状态保持一致，并收集运行状况和其他相关数据以向控制平面的全局部分报告。 Worker 的通用功能包括启动和停止容器。您可以将工作线程视为平台理解的通用集群状态与工作负载中正在运行的数据库容器之间的转换器。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;9965fa47-2eb1-4626-b1d3-dc518449f76a&#34;,&#34;dropCap&#34;:false}&#34;&gt;技术团队可以定制worker来收集特定于技术的实际状态并将目标状态应用于工作负载。例如，MySQL 工作线程的任务是确保 MySQL 主服务器和副本服务器保持其角色并向全局控制平面报告当前的消费状态。这使得团队可以根据集群的实际状态编写新的工作流程来操作集群。许多技术已经扩展了它们的工作线程，使其能够在工作线程中执行自我修复集群操作。例如，当集群拓扑发生变化时协调领导者选举或数据复制。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;5598ca20-758c-4080-b97b-81afc4cffece&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-optimizing-for-robustness-and-resilience&#34;&gt;优化鲁棒性和弹性&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;26972dfb-89dd-40ce-906d-ca16199626d9&#34;,&#34;dropCap&#34;:false}&#34;&gt;分离控件平面到主机本地和全局组件允许我们根据工作负载部署工作更改，将不良更改的潜在爆炸半径限制在尽可能小的单位。这同样适用于工作负载中的每个容器，因为该平台允许单独就地升级容器。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;138c489d-3c9f-4892-84e1-6387f9265a64&#34;,&#34;dropCap&#34;:false}&#34;&gt;对于两个代理，一个规则是，在对运行中的任何更改之前，必须首先将目标状态写入磁盘工作量已完成。这种方法保证了自给自足的集群可以在没有活动控制平面的情况下进行初始化，从而有效地解决了引导问题。此外，它还提供强大的故障恢复能力，允许工作负载在控制平面降级期间运行并简化紧急工具的编写。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;f07917a0-558e-42cb-b46f-c7a20196c247&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-transitioning-identities&#34;&gt;转换身份&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;1eef1f47-896d-478c-9dfe-b43cd5b83885&#34;,&#34;dropCap&#34;:false}&#34;&gt;随着我们不断优化效率并使我们的主机群现代化，将工作负载从一台主机转移到另一台主机已成为平台上最常见的操作之一。迄今为止，我们每月重新安排多达 60% 的有状态工作负载。有状态工作负载的一个关键要求是在重新调度期间保持工作负载身份。例如，此功能允许将服务于某个分片的一个工作负载替换为服务于同一分片的另一个工作负载。在 Kubernetes 中，这是通过 StatefulSets 进行管理的，方法是分配一个在重新调度过程中持续存在的稳定 Pod 身份。删除 pod 后，会使用相同的身份配置一个新的 pod。让我们探讨一下为什么这个模型不太适合 Uber 的用例。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;1bbb811d-86a9-4cd2-b96b-21285d91dabe&#34;,&#34;dropCap&#34;:false}&#34;&gt;如上所述， Uber 使用本地连接的驱动器来处理所有有状态工作负载，以提高性能。此设置要求在终止相应的工作负载之前复制主机上的数据并使其在其他地方可用。如果在替换工作负载完全准备好之前关闭工作负载，则集群会暂时出现配置不足的情况。这种延迟对于 1 小时的中位时间来说是不可忽略的，它使集群面临更大的数据丢失或可用性问题的风险。此外，这种延迟还会降低集群处理请求的整体能力。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;3b6e5f94-d8c1-4822-aff4-a93c79b744c9&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-replacing-workloads&#34;&gt;“替换”工作负载&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;aa7ad1d4-ea62-4c1c-910d-8286f06a3711&#34;,&#34;dropCap&#34;:false}&#34;&gt;因此， Odin 上最重要的操作是将工作负载从一台主机迁移到另一台主机，或者用 Odin 的术语来说，“替换”工作负载。替换操作是专门为&lt;em&gt;make-before-break&lt;/em&gt;而设计的。这意味着它会创建一个新的工作负载，只要有可能，在旧工作负载关闭之前，该新工作负载可以承载其所替换的工作负载的身份和数据。技术集成可以选择目标状态的哪些部分要在工作负载之间传播。目标状态模型使两个工作负载明确意识到彼此的存在。这是至关重要的，因为它允许各个工作人员协调数据复制和其他事情的过程。在极少数情况下，当&lt;em&gt;make-before-break&lt;/em&gt;语义不可能时（例如，旧工作负载位于故障主机上），旧工作负载将在创建替换工作负载的同时被删除。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;f2c8a1a1-fe85-4656-bbd8-381c24da7641&#34;,&#34;dropCap&#34;:false}&#34;&gt;使用 make- before-break 还具有效率优势，因为替代方案将要求我们持续运行过度配置的集群。在我们的模型中，我们只会在必要时暂时过度配置。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;de1ed6fc-1a1e-4666-b2e9-c58224a32d9e&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;c29e483c-a48a-4924-a033-ef8503c36fe1&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-forming-pains&#34;&gt;成长的烦恼&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;dad7f7a3-0ea3-479b-a1fe-9bfa5af38d18&#34;,&#34;dropCap&#34;:false}&#34;&gt;第一次迭代Odin 平台的使用对于团队操作存储集群的能力来说是一个巨大的飞跃。存储团队可以通过共享运营模型将所有运营和见解融合在一个平台上。然而，该平台仍然非常以人为本。人类是在平台上发起变革的主要参与者，而且最重要的是，他们是所执行操作的安全性和适合性的保证者。修复循环的作用仅限于范围相对较小的操作，例如单个替换工作流程&lt;em&gt;。&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;fad8c154-683f-4e0d-ba9b-d1d4b7157cb8&#34;,&#34;dropCap&#34;:false}&#34;&gt;运营开销已开始随着业务不断扩展，跨车队的跨技术操作实际上是人类操作员无法完成的。需要我们转移工作负载的复杂、跨车队、跨技术的操作示例包括：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;0c6b29b5-a3b0-4770-b81e-5374de15e4b5&#34;,&#34;ordered&#34;:false,&#34;values&#34;:&#34; “}”&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;优化工作负载放置，以提高抵御机架或区域故障等基础设施故障的能力&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;主机装箱以提高成本效率&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;核心/list-item&#34; data-wp-block=&#34;[]&#34;&gt;整个队列的主机升级，例如新内核、固件或 LVM/cgroupv2 等功能&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;促进新数据中心的建立或现有数据中心的退役&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;668aa557-dc41-41b6-a40a-29371389096e&#34;,&#34;dropCap&#34;:false}&#34;&gt;此外，单个主机上的大量数据库使得处理主机故障变得令人畏惧。这些限制表明，我们必须通过开发范围比以前更广泛的新修复循环来加倍自动化。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;56f8fe34-2ef2-4a3f-bb0d-4f69c90b960c&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-coordination-required&#34;&gt;需要协调&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;8036e749-8a7a-4c7f-b617-1321eac2cf8f&#34;,&#34;dropCap&#34;:false}&#34;&gt;增加了可操作性如果不仔细协调，负载可能很快就会导致中断。想象一下这样一种情况：删除基于共识的 3 节点存储集群中的工作负载以执行容器升级。现在想象另一个修复循环，该循环已确定集群中的其他工作负载之一将受益于出于效率原因而被移动。如果允许，这将导致存储集群失去仲裁，从而影响写入可用性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;44963a9c-9e27-4921-91da-42d031dd81be&#34;,&#34;dropCap&#34;:false}&#34;&gt;最初，我们开始增强修复循环以在内部执行并发控制（图 3）。这样，他们可以防止相同类型的操作给存储集群带来问题。例如，容器升级循环会阻止重叠升级。然而，这种方法存在缺陷，因为它没有解决不同修复循环引发的操作冲突问题。图 3 显示了两个独立操作可以在同一存储集群中操作两个工作负载，从而导致可用性损失的情况。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;37267e15-3898-4883-b5d5-6617d00f67ce&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;align&#34;:&#34;center&#34;,&#34;hash&#34;:&#34;d131b897-0c2b-4684-8052-d5db42a85208&#34;,&#34;alt&#34; :&#34;&#34;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img 解码=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXd4i6HPr3ZkL1WFmR1Kd-mkiLceVO0Liik1jb6NR51eaucwSAjFss_8QW_m-doDIHsbCW9kv5TJwgPukhH3rPiaE1o0lWbp vtlwSliGofFpGiD68jS5NGuxR1V3HZs6HxnZYsScd9vpweh0ouKSHRF0RlbN?key=0kVK3UHY5mqh0YpEHEfxHw&#34; alt=&#34;&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;图 4：内部并发控制不能保护存储集群免受重叠操作的影响，并且可能会损害可用性。&lt;/figcaption&gt;&lt; /图&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;4ab49524-3b00-4ca5-b966-d2a03569fdc2&#34;,&#34;opacity&#34;:&#34;alpha 通道&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;5304b888-d27b-4d5c-8703-a262a8183b7f&#34;,&#34;dropCap&#34;:false}&#34;&gt;展示不同的技术安全集群操作的容差差异很大。对于某些技术来说，正在运行的特定工作负载至关重要，而所有工作负载对于其他技术都一视同仁。某些技术仅专注于确保集群内始终可用一定数量的工作负载。这种需求的多样性使得我们必须支持根据每种技术的特定需求定制集群管理策略。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;d2d9eb70-3d33-4f06-a09d-71c7ba530c6c&#34;,&#34;dropCap&#34;:false}&#34;&gt;我们需要确保使用一个系统进行全局、跨类型的操作协调，该系统可以通过利用基于当前工作负载健康状况和中断预算的特定技术限制来保证保持集群可用性。此外，它应该通过强制执行平台范围内的全局并发和速率限制来防止工程错误和内部平台系统过载。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;573fa4c8-a71a-4934-bdd2-6e76c64ce602&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:1,&#34;hash&#34;:&#34;4b05fc1f-55a2-498f-8240-0bbc9d986ea0&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-summary&#34;&gt;摘要&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;cd8543d3-0d20-4857-97d7-92d0f10392a5&#34;,&#34;dropCap&#34;:false}&#34;&gt;在此介绍性内容中在我们的系列文章中，我们探讨了 Uber 有状态平台 Odin 的背景和基本原则。 Odin 是一个与技术无关的通用平台，能够管理对数据库操作方式有特殊要求的各种技术。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;b162d0bd-d1af-4e18-bad6-01cf9829155e&#34;,&#34;dropCap&#34;:false}&#34;&gt;我们讨论了如何Uber 的数据库使用本地连接的磁盘来提高性能和成本效率，并解决由此带来的挑战，因为存储的数据必须遵循工作负载身份。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;核心/段落&#34; data-wp-block=&#34;{&#34;哈希&#34;:&#34;a6a3e2b0-f102-45ac-8dab-4f45887f56c1&#34;,&#34;dropCap&#34;:false}&#34;&gt;我们还检查了该平台本质上是如何基于意图的，通过不同的补救循环不断努力使托管工作负载的实际状态与其预期目标状态保持一致。这些循环启动 Cadence 工作流程来更新目标状态并等待收敛，这个过程在规模上需要仔细协调才能安全管理，而不影响托管数据库的可用性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;89518bc2-03a8-452f-a779-fab4eb21f534&#34;,&#34;dropCap&#34;:false}&#34;&gt;在下一个在博客文章中，我们将讨论如何集中协调所有运营，并利用它来显着提高 Uber 大规模运营车队的能力。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;74b918d1-e0a6-4dd8-adb0-261d96dcccdb&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-acknowledgments&#34;&gt;致谢&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;114640af-7176-4346-87ab-dd430c350a03&#34;,&#34;dropCap&#34;:false}&#34;&gt;Odin 平台多年来，只有在许多贡献者的努力下才可能实现。作者要感谢所有在该平台上工作或贡献集成的团队，以及帮助使该平台变得更加出色的以前的团队成员。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;fontSize&#34;:&#34;小&#34;,&#34;hash&#34;:&#34;5ad1e8e8-0a5d-4299-8c12-36015f6ef911&#34;,&#34;dropCap&#34; :false}&#34; class=&#34;has-small-font-size&#34;&gt;封面照片是使用 OpenAI 的 ChatCPT Enterprise 生成并使用 Pixlr 编辑的。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;fontSize&#34;:&#34;小&#34;,&#34;hash&#34;:&#34;44181acd-1a06-48b7-97b3-2538dfbffe59&#34;,&#34;dropCap&#34; :false}&#34; class=&#34;has-small-font-size&#34;&gt;Kubernetes® 是 Linux 基金会在美国和其他国家/地区的注册商标。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;fontSize&#34;:&#34;小&#34;,&#34;hash&#34;:&#34;a3a471c0-0118-4ea6-840b-90e764c1ea0e&#34;,&#34;dropCap&#34; :false}&#34; class=&#34;has-small-font-size&#34;&gt;MySQL® 是 Oracle Corporation 和/或其附属公司的注册商标。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;fontSize&#34;:&#34;小&#34;,&#34;hash&#34;:&#34;3827feed-6951-4e20-bd15-7fb796002361&#34;,&#34;dropCap&#34; :false}&#34; class=&#34;has-small-font-size&#34;&gt;Apache Cassandra®、Apache HDFS™、Apache Kafka®、Apache Yarn™ 和 Apache Presto™ 是 Apache Software Foundation 在美国的注册商标或商标和/或其他国家。使用这些标记并不意味着 Apache 软件基金会的认可。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;fontSize&#34;:&#34;small&#34;,&amp;quot;hash&#34;:&#34;06d69f2b-38ee-4898-946e-02588d178a99&#34;,&#34;dropCap&#34;:false}&#34; class=&#34;has-small-font-size&#34;&gt;Buildkite™ 是 Buildkite Pty Ltd 的商标。&lt;/p&gt;</description>
      <pubDate>Thu, 18 Jul 2024 06:12:33 +0000</pubDate>
    </item>
    <item>
      <title>【Modernizing Logging at Uber with CLP (Part II)】使用 CLP 实现 Uber 日志记录现代化（第二部​​分）</title>
      <link>https://www.uber.com/blog/modernizing-logging-with-clp-ii/</link>
      <description>【&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;76db94ed-6b6e-49c2-98fe-3e96d67a8cc3&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-introduction&#34;&gt;Introduction&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6528f5e9-19a8-4ff7-9a1b-6bf9927f3b68&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;This is the second installment in our series detailing the modernization of Uber’s logging infrastructure using &lt;a href=&#34;https://github.com/y-scope/clp&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;CLP&lt;/a&gt;. &lt;a href=&#34;https://www.uber.com/en-US/blog/reducing-logging-cost-by-two-orders-of-magnitude-using-clp&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;In our last blog&lt;/a&gt;, we described how we split CLP’s compression algorithm into two phases: (1) distributed, row-based streaming compression that produces a compressed intermediate representation on each container or host, and (2) full columnar compression into more efficient archives. We developed a Log4j appender that uses the streaming compression and integrated it into our Spark platform. This resulted in a substantial compression ratio (169:1), which contributed to the resolution of the SSD burnouts caused by writing large amounts of log data while allowing us to extend our log retention period by 10x.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7a97a89e-3344-4301-9c90-c5dbea8fd781&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In collaboration with CLP’s developers, we have further developed an innovative end-to-end system to manage unstructured logs across Uber’s various data and ML platforms. Many log management systems, including the one described in a &lt;a href=&#34;https://www.uber.com/blog/logging/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;previous blog&lt;/a&gt;, tend to focus solely on search and aggregation, which are useful for developers to bootstrap a debugging session (e.g. locating an error event or detecting anomalies occurring at a certain point in time). However, to understand how and why the error occurred, developers need to further view the sequence of logs leading up to the event. Thus, search is only useful if integrated with convenient log-file viewing, a feature often overlooked by existing tools. Our new system includes advanced log viewing and programmable analytics directly on the compressed logs, unlocking the full potential of text logs using CLP.&amp;nbsp; Figure 1 below shows our current end-to-end deployment. Most of the core tools and basic features described in this blog are now &lt;a href=&#34;https://github.com/y-scope/clp&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;open source&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;41b1241d-7607-4a2f-ac57-6511ea24d7c0&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;91cc078d-a2f6-46d1-be6a-0cd1cd0915fa&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXfssVNYjd66JKnkJRxGEC8980IxP8rDsweshb_36DETnG5pGsONCOeY_BJeGEtc4pPq0XZRt7HXSfRmVnLxKn_7_ZkdsZFIJhn5DMsFKPSDxT2qZLPJ8oZEp37_5j2LZ9rs35_WMiWhU9L8pCWB1A2WmraD?key=6KS8UuwM_zrmkURjL-jcyQ&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 1: The Current CLP Ecosystem Deployed At Uber.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e6192bff-7988-4fe5-9610-17d9d528f9f9&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;66341d1f-30f6-4172-a003-f023ad4f5182&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-unstructured-amp-semi-structured-logs-their-role-and-associated-challenges&#34;&gt;Unstructured &amp;amp; Semi-structured Logs: Their Role and Associated Challenges&lt;/h2&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;fe3db487-e486-4e63-a936-0310ca7b8d2c&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXeND5RFoGztFr9Rw7LDu3h96JyG7BnwUrW5bSYIdonxvvbQdidi3IOtd3WaCjGemEh0U3zZsXlfil_8YjtnRdUWpUv6caVAI3gJwX7wUeh3GW79mVzmpcU5AqG0pYFIJZXH7BD0Ap5DvWoMkJu5vr-1E3PM?key=6KS8UuwM_zrmkURjL-jcyQ&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 2: The diversity of logs at Uber and the systems suitable to handle each type.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a64083f3-5338-4818-b252-5fd3ced40aef&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;44d0e2f6-f0ba-44c7-979c-ff24b1e6c2fc&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;At Uber, logs are diverse and exhibit varying degrees of structure, as shown in Figure 2 above. Each unstructured or semi-structured log event is dominated by a single string containing a message intertwined with variable values. Compared to various forms of structured logs, not only are free-text logs convenient with ubiquitous cultural acceptance, they are also used for different purposes. Developers typically use such logs to describe the sequential operation of a system in an effort to allow them to reconstruct the execution flow with some context. In contrast, most structured logs exhibit properties of a trace-point that is used to record certain metrics, significant singular events, and periodic statistical information. In general, structured log events are mostly independent from each other, whereas unstructured log events collectively record an execution based on the code paths that a developer wants to track. Therefore, structured logs are typically used for monitoring purposes (e.g., detecting system errors, whereas unstructured logs are used to debug &lt;strong&gt;why&lt;/strong&gt; the error occurred). This suggests the two types of logs require different types of management solutions.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;460ac7fa-214b-464b-889b-5cb52602ff28&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;When a system is small, it is not too difficult to debug using unstructured logs. Debugging can be done by simply SSH-ing into each node, viewing or grepping the logs, and diagnosing the root cause. However, as the system grows, SSH-ing into hundreds of thousands of nodes becomes unmanageable. Before our initiative, Apache Spark®, YARN®, Flink®, many Hadoop-ecosystem-based platforms, and many ML applications running on top of these platforms used the ancient MapReduce Job History Server to view their logs on each host directly. Uber also had a custom node-browsing interface (similar to SSH), but both of these tools are insufficient at Uber’s current scale. The Job History Server couldn’t scale effectively due to the sheer number of log files overwhelming the file limits of the underlying HDFS storage, coupled with a user interface that was too sluggish and unresponsive to handle the display of typical large log files. The latter method, while available and frequently used by platform maintainers, is cumbersome, insecure at best, and is not exposed to the application end-user. Thus, engineers need better tooling.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d6f453fd-c2c3-438b-9547-a0925ed53ada&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Unfortunately, there are a plethora of observability tools targeted at structured logs, but few targeted at unstructured logs. This is likely because structured logs lend themselves to being stored in a database-like backend where search and analytics can be performed and accelerated via indexing on top of tabular data (we use the term “database” to refer to any data management tool whose primary interface is search; this includes conventional RDBMSes, systems with native JSON support, NoSQL databases like Pinot, and reverse indexing tools such as Apache Lucene® that power a range of tools including Elasticsearch). As a result, developers often try to shoehorn their unstructured logs into the popular observability tool of the day; but since databases are not designed to store and analyze unstructured logs, developers are often left fighting more with the database than debugging their systems. For instance, when storing unstructured data, the database’s indices can quickly balloon in size, leading to a corresponding increase in on-disk storage and memory usage per query. In practice, retaining and searching all of Uber’s unstructured logs in such a tool would be exorbitantly costly. More importantly, it would take away the functionality that users are used to—namely, accessing and quickly viewing and analyzing individual log files.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1106bd23-a421-4d6e-bece-19fd2f33e312&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;42393c34-675c-4750-a146-fc327c4d2758&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-log-viewing&#34;&gt;Log Viewing&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d61ad8ac-0118-473d-8489-0d454515d8d3&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The ability to view and analyze the original log files remains an essential requirement—one that, regrettably, many existing observability tools overlook. To address this, we collaborated with the CLP development team to implement and customize a serverless log viewer that allows users to directly view the compressed logs by decompressing them on the fly, in their browser. Building on top of Microsoft Visual Studio Code’s high performance Monaco editor, the log viewer provides an intuitive and familiar interface for viewing compressed log files.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;528fd8bd-6771-4dd5-9ffc-9491d966cf76&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;9f3b1dd9-7e21-4098-b18a-2aef2df4e0ec&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXdbtS2LwlhA0rgmG8BvTEMHtOZwJQB4lCtLz_odrb-aJ9_4Bu2zISkgoAgXyIy-mzHaq4oD3NtLgO2_hDKn7raUfREPt46MpNbqVf6AFIpC-Kt3FKK2n7sYnLjbnOqxZetGWI37aAOdVU75Z-S2lQNlLL-W?key=6KS8UuwM_zrmkURjL-jcyQ&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 3: Using the log viewer to filter for critical (ERROR or below) log events.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6c8dab47-012f-41b2-99f6-9a3aa7f2b63c&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9b94a194-836e-4819-8a0a-673b6c225900&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;It also has many features specific to logs. For example:&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f2de87b7-9f86-4969-ba3a-2ec92a0de6ea&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;Smart Pagination&lt;/strong&gt; to handle large log files efficiently, ones that would be unwieldy in standard text editors or command-line tools like VIM. The pagination feature lowers the browser’s memory use while allowing other features such as search to work across pages.&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;Log-level Filtering&lt;/strong&gt; to allow engineers to easily hide logs above a certain level. For example, users initially focus on critical errors and then exploratively broaden their view to info-level logs to understand the surrounding context (the log viewer makes sure to keep the cursor on the same log event when toggling between log levels, even though the pagination will change).&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;Advanced Search&lt;/strong&gt; to allow quick queries of substrings or regular expressions (users can click on a result and quickly navigate to the corresponding log event), across the pages of the log file.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;Multi-line Support&lt;/strong&gt; to search and navigate between multi-line events (e.g., stack traces).&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;Synchronized Viewing&lt;/strong&gt; to allow viewing logs side by side, with synchronized scrolling by timestamp for cross-referencing events between different log files.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;Permanent Linking&lt;/strong&gt; where each log event in a compressed log file has a shareable and embeddable permanent link, eliminating the need to copy-paste logs or take screenshots, streamlining collaboration and issue tracking.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;Log Prettification &lt;/strong&gt;to automatically transform minified JSON strings, code snippets, and long lists within log events into a more readable format.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;Text Colorization&lt;/strong&gt; to support various language modes similar to those in Visual Studio Code, along with custom modes tailored to make typical Uber logs more readable.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6bb1a7ee-8736-4897-bec0-b57836512a6a&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The GIF above shows how a user can filter the logs by their log level, and the CLP log viewer correctly recognizes a multi-line ERROR log containing a stack trace as a single log event. The capability to offer these specialized log viewing features stems from the use of CLP to parse and compress the logs, since it automatically identifies the timestamp, log level, variable values, etc.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;bd471bdc-b58a-4cc6-bf29-fcbd3e08fb00&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d46beeef-88b9-4e01-93dc-c8dc740cec57&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-analytics-libraries&#34;&gt;Analytics Libraries&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ea9b9982-ff01-4700-9953-52fed4d6c5af&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In addition to log viewing, which satisfies users’ basic needs, we also offer libraries for users to perform programmable analytics. The core of these libraries is developed in C++ with native bindings for Python, Go, and Java. Since CLP parses the logs as they’re compressed, the library is able to provides users with direct access to structured data such as the Unix epoch timestamp, log type (i.e. the static text portion of a log message), variables within the message, and of course the decompressed log message itself. This approach relieves users from the burden of crafting extra text parsing logic for raw messages and mitigates the runtime performance costs associated with such parsing, particularly for multi-line log messages, allowing them to concentrate on the core logic of their log analytics programs. Today, a diverse set of users use the libraries for various purposes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6078c748-9ac1-4499-a14b-15527429657d&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;For platform maintainers, the analytics library streamlines complex programmatic queries, such as analyzing log types and the frequency of permission errors within a specific application over the past 30 days. Users often conduct substring searches and then apply further aggregation and deduplication logic to the results provided by the CLP analytics library. For instance, users can use the log type of each matching event as a means to identify duplicates, rather than using the decompressed message, which might change due to variable values. This facilitates the grouping of different unstructured log events with similar structures with ease.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;69440122-c73a-44e2-9d43-bfd38fa3a1d0&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;For on-call duties or root-cause analysis, users can create a scripted search that detects a series of specific known problematic log events or sequences of log events that meet user-defined criteria, assisting in swiftly and automatically narrowing down the scope of analysis. When a suspicious log event is identified, users can obtain its permanent link from the CLP log event object and clicking this link takes them directly to the specific matching event within the corresponding log file in the log viewer, for further in-depth analysis.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d302a707-d5dc-4bad-83fb-d7d3171f4d9c&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;For ML teams, the analytics library facilitates the quick extraction and processing of valuable training or inference data from logs, within various environments like Jupyter Notebooks, production scripts, or locally, on a user’s development laptop. Once the analytics results are available, the data can then be used as input for automated scripts, for instance, as part of the next training batch, or compiled into analytical reports for evaluation and decision-making purposes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a3cd1252-d276-4a01-9ef0-b2158def8901&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4c1772f3-4168-4665-82f0-7b15b3deb91e&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-ingesting-a-huge-number-of-log-files&#34;&gt;Ingesting a Huge Number of Log Files&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e95384e3-9a77-440d-9c52-a5ce486b0190&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The initial log ingestion pipeline, reliant on HDFS, had a few significant limitations for our logging workload. First, HDFS couldn’t scale to meet our log retention requirements due to the NameNode struggling to maintain an index of a huge number of small log files. In addition, data access, especially on developers’ laptops or development machines outside of a walled-off production environment, was primarily hindered by complex Kerberos authentication and other access barriers. In contrast, modern object storage solutions like S3 and GCS, designed for massive scalability, can accommodate petabytes of data and billions of objects. These platforms lessen our management load by obviating the need for HDFS cluster maintenance and offer enhanced security features such as encryption at rest and during transit, along with integrated ACLs and other access control features, automatic object lifecycle (i.e., retention time) management as well as providing a higher reliability and availability. We also benefit from the pay-as-you-go model, and the flexibility to significantly boost storage needs temporarily, for instance, extending log retention period following a major security incident. Thus, we switched from uploading and storing logs on HDFS to storing them in an object store.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;da78559c-f87a-4182-bd84-04dcaf2f998a&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;One key distinction between HDFS and common object stores is that HDFS employs a filesystem hierarchy whereas object stores function as flat key-value stores. Luckily, in large distributed systems, log files typically have a unique, unchanging filesystem path based on the logging entity’s hierarchy in the system, so this path works well as the key for the compressed logs. Furthermore, object stores offer APIs that facilitate key access in a manner akin to file system navigation, thereby maintaining a familiar log browsing experience.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6996a877-7091-47d2-b2c4-350475b1ed03&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;16491513-72b3-4ed5-a386-c5ef95924897&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-ensuring-and-guaranteeing-log-freshness&#34;&gt;Ensuring and Guaranteeing Log Freshness&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f49b6443-1f9a-4671-99e5-63f4c47d439d&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Services like YARN and streaming applications, including Flink jobs, are typically designed for prolonged execution and are only shut down infrequently, in the event of failures, hardware replacements, or upgrades. Consequently, log uploads can’t be deferred until the “end” of a job as was feasible in Phase I with shorter-duration Spark applications. Also, object storage systems typically lack support for append operations, posing a challenge for log freshness when dealing with the upload of large log files.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;62ee02cf-af7f-4001-a42b-b8cf16d449d1&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Our log management includes a rotation feature that segments extensive log files into smaller, more practical chunks. We trigger the creation of a new compressed log file when the existing file hits the 16MB mark. The chosen size is a strategic compromise for object stores, maximizing compression ratio, minimizing storage and synchronization overhead while only slightly raising API access costs. Note that despite the small compressed log file size, the high compression ratio means the 16MB chunk of compressed data represents a substantial amount of uncompressed data.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5ef299cc-97e8-4dbf-99f7-b9528e5ee0fa&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;To enhance log collection with near-real-time behavior and resilience, and at the same time minimize API costs associated with each upload request, our log library employs a tailored flush and upload policy specific to logging needs. We initially considered uploading logs every time they were flushed, but by default log libraries flush every time a log event is appended. This is too expensive. The libraries can also be configured to flush periodically, but this is too generic for logs. Ideally, we want an approach that changes depending on the characteristics of the logging workload. For instance, uploading sooner when important log events (e.g., ERROR-level) occur or uploading when there’s an absence of logs for a certain period of time.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;21525a1a-2bdf-4024-832e-ad8306c2cfdb&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Our uploading policy can be summarized as follows. Upon logging an event, the file should be uploaded after some delay 𝑆, but 𝑆 can be pushed to a later time if more log events occur before the delay expires. We call this a soft deadline. In contrast, we also maintain a hard deadline 𝐻 such that there is a guaranteed delay 𝐻 before the file is uploaded (𝐻 should be longer than 𝑆). For example, if 𝑆 is set to 10 seconds and 𝐻 is 300 seconds, it means when an event 𝐸 gets logged at time 𝑇 , it will be uploaded at 𝑇 + 10 if no other event arrives between [𝑇, 𝑇 + 10]. Otherwise, 𝐸’s upload will be delayed, but no later than 𝑇 + 300. These delays are configurable per log level, such that, for example, a user can set shorter deadlines for ERROR events than INFO ones. The delays also get reset once an upload occurs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;302ba9e4-c9a9-4820-98b1-f9a30fb54ffe&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ad9c3c07-702a-47bf-bd8b-49d59d5cabbf&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-effective-log-file-filtering-with-tags&#34;&gt;Effective Log File Filtering with Tags&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;11c30aa9-7b8e-4c8e-b484-5c898440a638&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Uber operates a huge number of internal services across various platforms, each of which has dozens of users running many jobs per day. Users often have advanced knowledge of system failures and their timing, thanks to comprehensive metrics and monitoring from integrated platform facilities or external monitoring tools. Therefore, in the majority of cases, users want to immediately limit their log search and viewing to a specific subset of compressed logs (e.g., those from a specific job, application, user, time slice, and their combination).&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2283eabd-3f10-4ead-a35e-a5a5f6067d09&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Our system enables flexible tagging of compressed logs with multiple identifiers, such as service ID, job ID, app ID, user ID, and timestamp range. Tags can be incorporated into object store file paths, recorded in external databases, or simply attached as object metadata and maintained by the object store. The user interface for searching and viewing logs leverages these tags allowing CLP to efficiently narrow down the log files relevant to each user’s search or viewing request.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4465a582-3b90-4aa0-9204-dd8936a0d444&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e43d1e1c-806e-4b05-86d1-9f6c6a8ff0c2&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-cross-platform-integration-of-clp&#34;&gt;Cross-platform Integration of CLP&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e0482a90-2fa8-4a25-bc62-36e165ce898a&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Our initial integration of CLP was with Spark, leveraging a re-implementation of CLP’s C++ code-base in Java for rapid integration with Spark’s default logging framework (Log4j). Its success, reliability, and user experience improvement led to integration requests from other platform teams and application end-users, including many Marketplace and ML teams. However, this integration path posed a challenge for adoption across different applications using other logging frameworks such as Logback and other programming languages, such as Python. Instead, we utilized Foreign Function Interface (FFI) libraries for various languages (including Java, Go, and Python) that interact with the CLP’s C++ library via native bindings. By integrating these into various logging libraries for each language, we were able to integrate CLP’s distributed streaming compression seamlessly into the platform team’s codebase without needing to change the application code.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;519717f8-0716-4280-9a05-ae71ccad20f3&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c4fcd6a9-5a0f-4416-b31d-b962a308fbb3&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-impact&#34;&gt;Impact&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;57736e6e-dc15-4f0c-b021-7c9722cfc1ef&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The cost-effective, distributed CLP compression and ingestion pipeline has become the preferred log ingestion and management solution for Uber’s Data team. As mentioned in our &lt;a href=&#34;https://www.uber.com/en-US/blog/reducing-logging-cost-by-two-orders-of-magnitude-using-clp&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;previous blog&lt;/a&gt;, this system has facilitated the effortless increase of our log retention period to the industry-standard 30 days, significantly reducing concerns over storage costs, maintenance complexity and availability. Furthermore, the log viewer and programmatic analysis features have gained popularity amongst end-users like the ML and Marketplace teams, as well as the platform maintained within Uber’s Data team. For example, the open-source Python CLP log analytics library has been downloaded 141,880 times, and the Python logging library plugin has seen 4,845 downloads in the last six months. The higher download rate of the analytics library reflects its wider use among engineers who analyze logs (“consumers”), compared to the number of service owners who implement the logging library plugin (“producers”).&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4dd9bc34-626e-4d42-9757-8c381d680bc0&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;73a1cf48-ddff-4d5c-9f5d-815d3d6ae174&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-next-steps&#34;&gt;Next Steps&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1b8044df-1dd5-484d-a4a7-f385671d60d0&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We aim to focus our future efforts on three key areas:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;db092b3d-8001-4283-8ca6-7bb9b6613f83&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Observability Platform Integration&lt;/strong&gt;:&amp;nbsp; Integrating CLP with the observability team’s existing log-collection infrastructure, which operates outside of application containers, reducing the severity of log loss during OOM scenarios and capturing logs not directly produced by applications (e.g., bash scripts). User experience can also be enhanced by unifying and streamlining access to both unstructured and structured logs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;502b9e40-7fbc-4a69-80ae-565ec013f0aa&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Migrate Suitable Cold Logs to CLP&lt;/strong&gt;: CLP excels with logs that don’t necessitate near-real-time search capabilities. While CLP is extremely efficient and offers fast search performance, it is not intended to replace existing online indexing-based solutions. Migrating suitable logs to the CLP platform should reduce cost and improve reliability and user experience.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e3f234c6-f2df-4dfc-a911-aa224ab678d3&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Structured Log Support&lt;/strong&gt;: CLP has introduced native support for structured logs, and its effectiveness is documented in an upcoming OSDI ’24 paper showcasing excellent compression and search capabilities for structured log data compared to existing solutions.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;8f0157b0-b2e9-421f-93c8-36572c18ae20&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-conclusion&#34;&gt;Conclusion&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5c5e569b-a21a-42dc-8337-54e3552ef396&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;By seamlessly integrating CLP with advanced features like log viewing, programmable analytics, and efficient log ingestion, Uber has revolutionized our unstructured log management. This comprehensive system not only addresses the challenges of scalability and debugging at Uber’s immense scale but also empowers engineers across various teams with tools that streamline their workflows. As a result, Uber has achieved significant cost savings, improved log retention, and enhanced developer productivity. The open-source availability of core tools and features further solidifies CLP’s impact, fostering broader adoption and innovation within the industry. With ongoing efforts focused on platform integration, log migration, and structured log support, Uber is poised to continue leading the way in efficient and effective log management.&lt;/p&gt;】&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:1,&#34;hash&#34;:&#34;76db94ed-6b6e-49c2-98fe-3e96d67a8cc3&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-introduction&#34;&gt;简介&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;6528f5e9-19a8-4ff7-9a1b-6bf992​​7f3b68&#34;,&#34;dropCap&#34;:false}&#34;&gt;这是这是我们系列的第二部分，详细介绍了使用 &lt;a href=&#34;https://github.com/y-scope/clp&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;CLP&lt;/a&gt; 对 Uber 日志基础设施进行现代化改造。 &lt;a href=&#34;https://www.uber.com/en-US/blog/reducing-logging-cost-by-two-orders-of-magnitude-using-clp&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;在我们的上一篇博客&lt;/a&gt;中，我们描述了如何将 CLP 的压缩算法分为两个阶段：(1) 分布式、基于行的流式压缩，在每个容器或主机上生成压缩的中间表示，以及 (2)全列压缩成更高效的档案。我们开发了一个使用流压缩的 Log4j 附加程序，并将其集成到我们的 Spark 平台中。这带来了相当大的压缩比（169:1），有助于解决因写入大量日志数据而导致的 SSD 烧坏问题，同时允许我们将日志保留期延长 10 倍。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;7a97a89e-3344-4301-9c90-c5dbea8fd781&#34;,&#34;dropCap&#34;:false}&#34;&gt;与以下机构合作作为 CLP 的开发人员，我们进一步开发了一种创新的端到端系统，用于管理 Uber 各种数据和机器学习平台上的非结构化日志。许多日志管理系统，包括&lt;a href=&#34;https://www.uber.com/blog/logging/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;上一篇博客&lt;/a&gt;中描述的系统，倾向于只关注搜索和聚合，这对于开发人员引导调试会话很有用（例如，定位错误事件或检测在某个时间点发生的异常）。但是，要了解错误发生的方式和原因，开发人员需要进一步查看导致该事件的日志序列。因此，搜索只有与方便的日志文件查看相结合才有用，而这一功能经常被现有工具所忽视。我们的新系统包括直接对压缩日志进行高级日志查看和可编程分析，从而使用 CLP 释放文本日志的全部潜力。  下图 1 显示了我们当前的端到端部署。本博客中描述的大多数核心工具和基本功能现在都是&lt;a href=&#34;https://github.com/y-scope/clp&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;开源&lt;/a &gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;41b1241d-7607-4a2f-ac57-6511ea24d7c0&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;核心/图像&#34; data-wp-block=&#34;{“对齐”：“中心”，“哈希”：“91cc078d-a2f6-46d1-be6a-0cd1cd0915fa”，“alt”：“”}“class =“aligncenter”&gt; &lt;img解码=“异步”src =“https： //lh7-us.googleusercontent.com/docsz/AD_4nXfssVNYjd66JKnkJRxGEC8980IxP8rDsweshb_36DETnG5pGsONCOeY_BJeGEtc4pPq0XZRt7HXSfRmVnLxKn_7_ZkdsZFIJhn5DMsFKPSDxT2qZLPJ8oZE p37_5j2LZ9rs35_WMiWhU9L8pCWB1A2WmraD?key=6KS8UuwM_zrmkURjL-jcyQ&#34; alt=&#34;&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;图 1：当前 CLP Uber 部署的生态系统。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;e6192bff-7988-4fe5-9610-17d9d528f9f9&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;66341d1f-30f6-4172-a003-f023ad4f5182&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-unstructured-amp-semi-structed-logs-their-role-and-linked-challenges&#34;&gt;非结构化和半结构化日志：它们的作用和相关挑战&lt;/h2&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;align&#34;:&#34;center&#34;,&#34;hash&#34;:&#34;fe3db487-e486-4e63-a936-0310ca7b8d2c&#34;,&#34;alt&#34; ：&#34;&#34;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img 解码=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXeND5RFoGztFr9Rw7LDu3h96JyG7BnwUrW5bSYIdonxvvbQdidi3IOtd3WaCjGemEh0U3zZsXlfil_8YjtnRdUWpUv6 caVAI3gJwX7wUeh3GW79mVzmpcU5AqG0pYFIJZXH7BD0Ap5DvWoMkJu5vr-1E3PM?key=6KS8UuwM_zrmkURjL-jcyQ&#34; alt=&#34;&#34;referrerpolicy =&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;图 2：Uber 日志的多样性以及适合处理每种类型的系统。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;a64083f3-5338-4818-b252-5fd3ced40aef&#34;,&#34;opacity&#34;:&#34;alpha 通道&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;44d0e2f6-f0ba-44c7-979c-ff24b1e6c2fc&#34;,&#34;dropCap&#34;:false}&#34;&gt;在 Uber，日志多种多样，并表现出不同程度的结构，如上图 2 所示。每个非结构化或半结构化日志事件都由包含与变量值交织在一起的消息的单个字符串主导。与各种形式的结构化日志相比，自由文本日志不仅方便且具有普遍的文化接受度，而且它们的用途也不同。开发人员通常使用此类日志来描述系统的顺序操作，以便他们能够通过某些上下文重建执行流程。相比之下，大多数结构化日志都具有跟踪点的属性，用于记录某些指标、重要的奇异事件和周期性统计信息。一般来说，结构化日志事件大多是相互独立的另一方面，非结构化日志事件根据开发人员想要跟踪的代码路径共同记录执行情况。因此，结构化日志通常用于监控目的（例如，检测系统错误，而非结构化日志用于调试错误发生的原因）。这表明两种类型的日志需要不同类型的管理解决方案。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;460ac7fa-214b-464b-889b-5cb52602ff28&#34;,&#34;dropCap&#34;:false}&#34;&gt;当系统由于规模较小，使用非结构化日志进行调试并不太困难。只需通过 SSH 连接到每个节点、查看或 grep 日志并诊断根本原因即可完成调试。然而，随着系统的增长，通过 SSH 连接到数十万个节点变得难以管理。在我们发起这项计划之前，Apache Spark®、YARN®、Flink®、许多基于 Hadoop 生态系统的平台以及在这些平台上运行的许多 ML 应用程序都使用古老的 MapReduce 作业历史记录服务器来直接查看每个主机上的日志。 Uber 还拥有一个自定义的节点浏览界面（类似于 SSH），但这两种工具对于 Uber 目前的规模来说都不够。由于日志文件数量过多，超出了底层 HDFS 存储的文件限制，而且用户界面过于缓慢且响应迟钝，无法处理典型大型日志文件的显示，因此作业历史记录服务器无法有效扩展。后一种方法虽然可用且经常被平台维护人员使用，但很麻烦，充其量也不安全，并且不会向应用程序最终用户公开。因此，工程师需要更好的工具。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;d6f453fd-c2c3-438b-9547-a0925ed53ada&#34;,&#34;dropCap&#34;:false}&#34;&gt;不幸的是，有针对结构化日志的可观察性工具有很多，但针对非结构化日志的可观察性工具却很少。这可能是因为结构化日志适合存储在类似数据库的后端中，在后端可以通过表格数据上的索引来执行和加速搜索和分析（我们使用术语“数据库”来指代其主要功能的任何数据管理工具）。接口是搜索；这包括传统的 RDBMS、具有本机 JSON 支持的系统、Pinot 等 NoSQL 数据库以及为 Elasticsearch 等一系列工具提供支持的反向索引工具（例如 Apache Lucene®）。因此，开发人员经常尝试将他们的非结构化日志硬塞到当今流行的可观察工具中；但由于数据库不是为存储和分析非结构化日志而设计的，因此开发人员通常更多地与数据库打交道，而不是调试系统。例如，在存储非结构化数据时，数据库索引的大小可能会迅速膨胀，从而导致磁盘存储和每个查询的内存使用量相应增加。在实践中，保留和搜索所有 Uber在这样的工具中处理非结构化日志的成本将非常高昂。更重要的是，它将剥夺用户习惯的功能，即访问、快速查看和分析单个日志文件。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;1106bd23-a421-4d6e-bece-19fd2f33e312&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;42393c34-675c-4750-a146-fc327c4d2758&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-log-viewing&#34;&gt;日志查看&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;d61ad8ac-0118-473d-8489-0d454515d8d3&#34;,&#34;dropCap&#34;:false}&#34;&gt;能够查看和分析原始日志文件仍然是一项基本要求，遗憾的是，许多现有的可观察性工具忽视了这一点。为了解决这个问题，我们与 CLP 开发团队合作，实现并定制了一个无服务器日志查看器，允许用户通过在浏览器中动态解压缩来直接查看压缩日志。日志查看器构建在 Microsoft Visual Studio Code 的高性能 Monaco 编辑器之上，提供了直观且熟悉的界面来查看压缩日志文件。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;528fd8bd-6771-4dd5-9ffc-9491d966cf76&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;align&#34;:&#34;center&#34;,&#34;hash&#34;:&#34;9f3b1dd9-7e21-4098-b18a-2aef2df4e0ec&#34;,&#34;alt&#34; :&#34;&#34;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img 解码=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXdbtS2LwlhA0rgmG8BvTEMHtOZwJQB4lCtLz_odrb-aJ9_4Bu2zISkgoAgXyIy-mzHaq4oD3NtLgO2_hDKn7raUfR EPt46MpNbqVf6AFIPC-Kt3FKK2n7sYnLjbnOqxZetGWI37aAOdVU75Z-S2lQNlLL-W?key=6KS8UuwM_zrmkURjL -jcyQ&#34; alt=&#34;&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;图 3：使用日志查看器过滤关键（错误或以下）日志事件。&lt;/figcaption&gt; &lt;/图&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;6c8dab47-012f-41b2-99f6-9a3aa7f2b63c&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;9b94a194-836e-4819-8a0a-673b6c225900&#34;,&#34;dropCap&#34;:false}&#34;&gt;它还有许多特定于日志的功能。例如：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;f2de87b7-9f86-4969-ba3a-2ec92a0de6ea&#34;,&#34;ordered&#34;:false,&#34;values&#34;:&#34; “}”&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;智能分页&lt;/strong&gt; 有效地处理大型日志文件，这些文件在标准文本编辑器或 VIM 等命令行工具中会很笨重。分页功能降低了浏览器的内存使用量，同时允许其他功能（例如搜索）跨页面工作。 &lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;日志级别过滤&lt;/strong&gt;，让工程师可以轻松隐藏特定级别以上的日志。例如，用户最初关注关键错误，然后探索性地将其视图扩大到信息级日志，以了解周围的上下文（日志查看器确保在日志级别之间切换时将光标保持在同一日志事件上，即使分页会改变）。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;高级搜索&lt;/strong&gt;，允许快速查询子字符串或正则表达式（用户可以点击的结果并快速导航到相应的日志事件），跨日志文件的页面。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;多行支持&lt;/strong&gt;在多行事件之间搜索和导航（例如，堆栈跟踪）。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;同步查看&lt;/strong&gt;允许并排查看日志，并按时间戳同步滚动用于不同日志文件之间的交叉引用事件。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;永久链接&lt;/strong&gt;，其中压缩日志文件中的每个日志事件都有一个可共享和可嵌入的永久链接，无需复制粘贴日志或截取屏幕截图，从而简化了协作和问题跟踪。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;日志美化&lt;/strong&gt;自动转换缩小的 JSON 字符串、代码片段和长列表将日志事件转换为更易读的格式。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;文本着色&lt;/strong&gt;支持与 Visual Studio Code 中类似的各种语言模式，以及定制模式，使典型的 Uber 日志更具可读性。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;6bb1a7ee-8736-4897-bec0-b57836512a6a&#34;,&#34;dropCap&#34;:false}&#34;&gt;上面的 GIF显示用户如何按日志级别过滤日志，并且 CLP 日志查看器正确地将包含堆栈跟踪的多行错误日志识别为单个日志事件。提供这些专门的日志查看功能的能力源于使用 CLP 来解析和压缩日志，因为它会自动识别时间戳、日志级别、变量值等。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;bd471bdc-b58a-4cc6-bf29-fcbd3e08fb00&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 数据-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;d46beeef-88b9-4e01-93dc-c8dc740cec57&#34;,&#34;level&#34;:2}&#34; class=&#34;wp-block-heading&#34; id =&#34;h-analytics-libraries&#34;&gt;分析库&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;ea9b9982-ff01-4700-9953-52fed4d6c5af&#34;,&#34;dropCap&#34;:false}&#34;&gt;除了日志查看，满足用户的基本需求，我们还提供库供用户进行可编程分析。这些库的核心是用 C++ 开发的，具有 Python、Go 和 Java 的本机绑定。由于 CLP 在压缩日志时对其进行解析，因此该库能够为用户提供对结构化数据的直接访问，例如 Unix 纪元时间戳、日志类型（即日志消息的静态文本部分）、消息中的变量、当然还有解压缩的日志消息本身。这种方法减轻了用户为原始消息编写额外文本解析逻辑的负担，并降低了与此类解析相关的运行时性能成本，特别是对于多行日志消息，使他们能够专注于日志分析程序的核心逻辑。如今，各种各样的用户将这些库用于各种目的。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;6078c748-9ac1-4499-a14b-15527429657d&#34;,&#34;dropCap&#34;:false}&#34;&gt;对于平台维护者，分析库简化了复杂的编程查询，例如分析过去 30 天内特定应用程序中的日志类型和权限错误的频率。用户经常进行子字符串搜索，然后对 CLP 分析库提供的结果应用进一步的聚合和重复数据删除逻辑。例如，用户可以使用每个匹配事件的日志类型作为识别重复项的方法，而不是使用解压缩的消息，解压缩的消息可能会因变量值而发生变化。这有助于轻松地对具有相似结构的不同非结构化日志事件进行分组。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;69440122-c73a-44e2-9d43-bfd38fa3a1d0&#34;,&#34;dropCap&#34;:false}&#34;&gt;对于-在呼叫职责或根本原因分析中，用户可以创建脚本式搜索，检测一系列特定的已知有问题的日志事件或满足用户定义标准的日志事件序列，从而帮助快速自动缩小分析范围。当发现可疑日志事件时，用户可以从CLP日志事件对象中获取其永久链接，单击该链接可以直接在日志查看器中转到相应日志文件中的特定匹配事件，以进行进一步的深入分析。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;d302a707-d5dc-4bad-83fb-d7d3171f4d9c&#34;,&#34;dropCap&#34;:false}&#34;&gt;对于机器学习团队，分析库有助于快速提取和p在各种环境（如 Jupyter Notebooks、生产脚本）或本地用户的开发笔记本电脑上处理来自日志的有价值的训练或推理数据。一旦获得分析结果，数据就可以用作自动化脚本的输入，例如，作为下一个训练批次的一部分，或编译成分析报告以用于评估和决策目的。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;a3cd1252-d276-4a01-9ef0-b2158def8901&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;4c1772f3-4168-4665-82f0-7b15b3deb91e&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-ingesting-a-huge-number-of-log-files&#34;&gt;摄取大量日志文件&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;e95384e3-9a77-440d-9c52-a5ce486b0190&#34;,&#34;dropCap&#34;:false}&#34;&gt;初始日志依赖于 HDFS 的摄取管道对我们的日志记录工作负载有一些重大限制。首先，由于 NameNode 难以维护大量小日志文件的索引，HDFS 无法扩展以满足我们的日志保留要求。此外，数据访问，尤其是在封闭生产环境之外的开发人员笔记本电脑或开发机器上，主要受到复杂的 Kerberos 身份验证和其他访问障碍的阻碍。相比之下，S3 和 GCS 等现代对象存储解决方案专为大规模可扩展性而设计，可以容纳 PB 级数据和数十亿个对象。这些平台消除了 HDFS 集群维护的需要，从而减轻了我们的管理负担，并提供增强的安全功能，例如静态和传输过程中的加密，以及集成的 ACL 和其他访问控制功能、自动对象生命周期（即保留时间）管理。提供更高的可靠性和可用性。我们还受益于即用即付模式，以及暂时显着提高存储需求的灵活性，例如，在重大安全事件后延长日志保留期。因此，我们从在 HDFS 上上传和存储日志转为将它们存储在对象存储中。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;da78559c-f87a-4182-bd84-04dcaf2f998a&#34;,&#34;dropCap&#34;:false}&#34;&gt;一键区分HDFS 和普通对象存储之间的区别在于 HDFS 采用文件系统层次结构，而对象存储则充当平面键值存储。幸运的是，在大型分布式系统中，日志文件通常具有基于系统中日志记录实体的层次结构的唯一的、不变的文件系统路径，因此该路径可以很好地作为压缩日志的密钥。此外，对象存储提供 API，以类似于文件系统导航的方式促进密钥访问，从而维护正在享受熟悉的日志浏览体验。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;6996a877-7091-47d2-b2c4-350475b1ed03&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;16491513-72b3-4ed5-a386-c5ef95924897&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-ensuring-and-guaranteeing-log-freshness&#34;&gt;确保和保证日志新鲜度&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;f49b6443-1f9a-4671-99e5-63f4c47d439d&#34;,&#34;dropCap&#34;:false}&#34;&gt;YARN 等服务流应用程序（包括 Flink 作业）通常设计用于长时间执行，并且仅在发生故障、硬件更换或升级时很少关闭。因此，日志上传不能推迟到作业“结束”，这在第一阶段对于持续时间较短的 Spark 应用程序是可行的。此外，对象存储系统通常缺乏对追加操作的支持，这在处理大型日志文件的上传时对日志新鲜度提出了挑战。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;62ee02cf-af7f-4001-a42b-b8cf16d449d1&#34;,&#34;dropCap&#34;:false}&#34;&gt;我们的日志管理包括旋转功能，可将大量日志文件分割成更小、更实用的块。当现有文件达到 16MB 标记时，我们会触发创建新的压缩日志文件。选择的大小是对象存储的战略折衷，最大化压缩比，最小化存储和同步开销，同时仅略微提高 API 访问成本。请注意，尽管压缩日志文件大小较小，但高压缩比意味着 16MB 的压缩数据块代表大量未压缩数据。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;5ef299cc-97e8-4dbf-99f7-b9528e5ee0fa&#34;,&#34;dropCap&#34;:false}&#34;&gt;增强日志为了实现具有近实时行为和弹性的收集，同时最大限度地降低与每个上传请求相关的 API 成本，我们的日志库采用了针对日志记录需求定制的刷新和上传策略。我们最初考虑在每次刷新日志时上传日志，但默认情况下，每次附加日志事件时日志库都会刷新。这太贵了。库也可以配置为定期刷新，但这对于日志来说太通用了。理想情况下，我们需要一种根据日志记录工作负载的特征而变化的方法。例如，当重要日志事件（例如错误级别）发生时尽早上传，或者在一段时间内没有日志时上传。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;21525a1a-2bdf-4024-832e-ad8306c2cfdb&#34;,&#34;dropCap&#34;:false}&#34;&gt;我们的上传政策可以总结如下。记录事件后，文件应在延迟一段时间𝑆后上传，但如果在延迟到期之前发生更多日志事件，则可以将𝑆推到稍后的时间。我们称之为相比之下，我们还维持一个硬期限 𝐻，以便在上传文件之前有一个保证的延迟 𝐻（𝐻 应长于 𝑆），例如，如果 𝑆 设置为 10 秒且 𝐻 为 300。秒，这意味着当事件 𝐸 在时间 𝑇 被记录时，如果 [𝑇, 𝑇 + 10] 之间没有其他事件到达，它将在 𝑇 + 10 上传，否则，𝐸 的上传将被延迟，但不晚于 𝑇 + 。 300. 这些延迟可以根据日志级别进行配置，例如，用户可以为 ERROR 事件设置比 INFO 事件更短的期限，一旦发生上传，延迟也会重置。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;302ba9e4-c9a9-4820-98b1-f9a30fb54ffe&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;ad9c3c07-702a-47bf-bd8b-49d59d5cabbf&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h- effective-log-file-filtering-with-tags&#34;&gt;使用标签进行有效的日志文件过滤&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;11c30aa9-7b8e-4c8e-b484-5c898440a638&#34;,&#34;dropCap&#34;:false}&#34;&gt;Uber 运营跨各种平台的大量内部服务，每个平台都有数十个用户每天运行许多作业。得益于集成平台设施或外部监控工具的综合指标和监控，用户通常对系统故障及其时间有深入的了解。因此，在大多数情况下，用户希望立即将其日志搜索和查看限制为压缩日志的特定子集（例如，来自特定作业、应用程序、用户、时间片及其组合的日志）。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;2283eabd-3f10-4ead-a35e-a5a5f6067d09&#34;,&#34;dropCap&#34;:false}&#34;&gt;我们的系统支持使用多个标识符灵活标记压缩日志，例如服务 ID、作业 ID、应用程序 ID、用户 ID 和时间戳范围。标签可以合并到对象存储文件路径中，记录在外部数据库中，或者简单地附加为对象元数据并由对象存储维护。用于搜索和查看日志的用户界面利用这些标签，使 CLP 能够有效地缩小与每个用户的搜索或查看请求相关的日志文件的范围。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;4465a582-3b90-4aa0-9204-dd8936a0d444&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;e43d1e1c-806e-4b05-86d1-9f6c6a8ff0c2&#34;,&#34;level&#34;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-cross-platform-integration-of-clp &#34;&gt;CLP 跨平台集成&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;e0482a90-2fa8-4a25-bc62-36e165ce898a&#34;,&#34;dropCap&#34;:false}&#34;&gt;我们的初始集成CLP 的主要工作是与 Spark 合作，利用 Java 中 CLP 的 C++ 代码库的重新实现来与 Spark 的默认日志记录框架 (Log4j) 快速集成。它的成功、可靠性和用户体验的改进引起了其他平台团队和应用程序最终用户（包括许多 Marketplace 和 ML 团队）的集成请求。然而，这种集成路径对使用其他日志框架（例如 Logback）和其他编程语言（例如 Python）的不同应用程序的采用提出了挑战。相反，我们利用各种语言（包括 Java、Go 和 Python）的外部函数接口 (FFI) 库，通过本机绑定与 CLP 的 C++ 库进行交互。通过将这些集成到每种语言的各种日志库中，我们能够将 CLP 的分布式流压缩无缝集成到平台团队的代码库中，而无需更改应用程序代码。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;519717f8-0716-4280-9a05-ae71ccad20f3&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;c4fcd6a9-5a0f-4416-b31d-b962a308fbb3&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-impact&#34;&gt;影响&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;57736e6e-dc15-4f0c-b021-7c9722cfc1ef&#34;,&#34;dropCap&#34;:false}&#34;&gt;成本-有效的分布式 CLP 压缩和摄取管道已成为 Uber 数据团队的首选日志摄取和管理解决方案。正如我们的 &lt;a href=&#34;https://www.uber.com/en-US/blog/reducing-logging-cost-by-two-orders-of-magnitude-using-clp&#34; target=&#34;_blank&#34; 中提到的rel=&#34;noreferrer noopener&#34;&gt;上一篇博客&lt;/a&gt;，该系统帮助我们轻松地将日志保留期延长至行业标准的 30 天，显着减少了对存储成本、维护复杂性和可用性的担忧。此外，日志查看器和编程分析功能在 ML 和 Marketplace 团队等最终用户以及 Uber 数据团队内部维护的平台中广受欢迎。例如，开源Python CLP日志分析库已被下载141,880次，Python日志库插件在过去六个月内已被下载4,845次。分析库的下载率较高，反映出与分析日志的服务所有者数量相比，它在分析日志的工程师（“消费者”）中使用更广泛。实现日志库插件（“生产者”）。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;4dd9bc34-626e-4d42-9757-8c381d680bc0&#34;,&#34;opacity&#34;:&#34;alpha 通道&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;73a1cf48-ddff-4d5c-9f5d-815d3d6ae174&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-next-steps&#34;&gt;后续步骤&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;1b8044df-1dd5-484d-a4a7-f385671d60d0&#34;,&#34;dropCap&#34;:false}&#34;&gt;我们的目标是我们未来的努力将集中在三个关键领域：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;db092b3d-8001-4283-8ca6-7bb9b6613f83&#34;,&#34;dropCap&#34;:false}&#34;&gt;&lt;strong&gt;可观测性平台集成&lt;/strong&gt;：将 CLP 与可观测性团队现有的日志收集基础设施集成，该基础设施在应用程序容器之外运行，从而降低 OOM 场景中日志丢失的严重性，并捕获不是由应用程序直接生成的日志（例如 bash 脚本） 。通过统一和简化对非结构化和结构化日志的访问，还可以增强用户体验。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;502b9e40-7fbc-4a69-80ae-565ec013f0aa&#34;,&#34;dropCap&#34;:false}&#34;&gt;&lt;strong&gt;将合适的冷日志迁移到 CLP&lt;/strong&gt;：CLP 擅长处理不需要近实时搜索功能的日志。虽然 CLP 非常高效并提供快速搜索性能，但它并不是要取代现有的基于在线索引的解决方案。将合适的日志迁移到CLP平台应该可以降低成本并提高可靠性和用户体验。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;e3f234c6-f2df-4dfc-a​​911-aa224ab678d3&#34;,&#34;dropCap&#34;:false}&#34;&gt;&lt;strong&gt;结构化日志支持：CLP 引入了对结构化日志的本机支持，其有效性记录在即将发布的 OSDI &#39;24 论文中，该论文展示了与现有解决方案相比，结构化日志数据的出色压缩和搜索功能。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:1,&#34;hash&#34;:&#34;8f0157b0-b2e9-421f-93c8-36572c18ae20&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-conclusion&#34;&gt;结论&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;5c5e569b-a21a-42dc-8337-54e3552ef396&#34;,&#34;dropCap&#34;:false}&#34;&gt;通过无缝集成CLP 具有日志查看、可编程分析和高效日志摄取等高级功能，Uber 彻底改变了我们的非结构化日志管理。这个全面的系统不仅解决了 Uber 规模庞大的可扩展性和调试挑战，还为各个团队的工程师提供了能够帮助他们解决问题的工具。简化他们的工作流程。因此，Uber 实现了显着的成本节省、改进的日志保留并提高了开发人员的工作效率。核心工具和功能的开源可用性进一步巩固了中电的影响力，促进了行业内更广泛的采用和创新。通过持续致力于平台集成、日志迁移和结构化日志支持，Uber 准备继续在高效和有效的日志管理方面保持领先地位。&lt;/p&gt;</description>
      <pubDate>Thu, 27 Jun 2024 07:06:56 +0000</pubDate>
    </item>
    <item>
      <title>【Navigating the LLM Landscape: Uber’s Innovation with GenAI Gateway】驾驭 LLM 格局：Uber 通过 GenAI Gateway 进行创新</title>
      <link>https://www.uber.com/blog/genai-gateway/</link>
      <description>【&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;639e6d58-1937-4773-a697-02436d75c659&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-introduction&#34;&gt;&lt;strong&gt;Introduction&lt;/strong&gt;&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a4ced9b4-63a9-4d41-995b-c471a659eed4&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Large Language Models (LLMs) have emerged as pivotal instruments in the tech industry, unlocking new avenues for innovation and progress across various sectors. At Uber, the impact of LLMs is particularly noticeable, with over 60 distinct use cases being identified in diverse domains, ranging from process automation to customer support and content generation. As teams at Uber embark on the journey of integrating LLMs into their products, several challenges have surfaced. Notably, the disparate integration strategies adopted by different teams have led to inefficiencies and redundant efforts.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;83d057b4-73ce-417e-bd02-f91cc428a2a9&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;To address these challenges and harness the growing demand for LLMs, Uber’s Michelangelo team has innovated a solution: the GenAI Gateway. The GenAI Gateway serves as a unified platform for all LLM use cases within Uber, offering seamless access to models from various vendors like OpenAI and Vertex AI, as well as Uber-hosted models, through a consistent and efficient interface. The GenAI Gateway is designed to simplify the integration process for teams looking to leverage LLMs in their projects. Its easy onboarding process reduces the effort required by teams, providing a clear and straightforward path to harness the power of LLMs. In addition, a standardized review process, managed by the Engineering Security team, reviews use cases against Uber’s data handling standard before use cases are granted access to the gateway.&amp;nbsp; If testing is successful these projects go through our standard, cross-functional software development process. The centralized nature of the gateway also streamlines the management of usage and budgeting across various teams, promoting greater control and operational efficiency in the integration of LLMs across the company.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8f5812a9-767d-43f3-915e-0de639f58afc&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;271006ea-850d-4aaa-9b12-649b7fd88696&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-design-amp-architecture&#34;&gt;&lt;strong&gt;Design &amp;amp; Architecture&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e3d75695-952c-4dcf-aa1b-c4a1f2346c22&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;A pivotal design decision was to mirror the HTTP/JSON interface of the OpenAI API. This strategic choice is rooted in OpenAI’s widespread adoption and thriving open-source ecosystem highlighted by libraries like LangChain and LlamaIndex. This alignment fosters seamless interoperability, ensuring GenAI Gateway’s compatibility with existing open-source tools and libraries while minimizing the need for adjustments. Given the rapid evolution of the open-source community, a proprietary interface would risk becoming quickly outdated. By aligning with OpenAI’s interface, GenAI Gateway stays in step with cutting-edge advancements. This approach not only streamlines the onboarding process for developers but also extends GenAI Gateway’s reach, allowing users to access LLMs from various vendors, like Vertex AI, through a familiar OpenAI API framework. See Figure 1 below for the high-level architecture diagram.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6d3618fd-55dd-44d8-b957-838a8b5dec19&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The following code snippets demonstrate how to use GenAI Gateway to access LLMs from different vendors with unified interface:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6963d647-7655-44b0-9310-a7d510ddb789&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;681fd513-bcc0-4e80-8715-d6e834a589a2&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXeSeRL_lT222k2UnrRa4Ywx8XbtT5alPHmZjCu_7-_RJvRPf-p7TZlT8Lsbm-ysathYSSxqVVCXBE_ALt1IfTeY_Z6CAuCcPuVas1vxly9HbguZ0si1KR0eZ_-9OOlfy3kAmmTSXUrU8SkD5Ct34F2hJB0?key=5egmPsUgOM1kuqOeYjTalA&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2d022d50-550a-4c3c-96f3-5e2b4a27e6d5&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote data-wp-block-name=&#34;core/quote&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;da9b9046-5685-4270-95e5-f47d4210332a&amp;quot;,&amp;quot;value&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;wp-block-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Answer from gpt-4:&amp;nbsp;&lt;/strong&gt;The capital of the USA is Washington D.C.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Answer from chat-bison:&amp;nbsp;&lt;/strong&gt;&amp;nbsp;Washington, D.C. is the capital of the USA.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Answer from llama-2-70b-chat-hf-0:&amp;nbsp;&lt;/strong&gt;The capital of the United States of America is Washington, D.C.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d3cfdec3-78b6-45e0-a99f-228020ce7900&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;As can be seen from above, developers write code as if they’re using native OpenAI client, while being able to access LLMs from different vendors.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;fac9714d-4d09-45e5-a474-501a4df1f5f0&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Architecture-wise, GenAI Gateway is a Go service that acts as an encompassing layer around the clients for third-party vendors, complemented by the in-house serving stacks tailored for Uber’s LLMs.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;35331a76-20eb-4ee4-96cb-06d88b4940d5&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Our approach to integrating with OpenAI involved developing an internal fork of the Go client implementation sourced from &lt;a href=&#34;https://github.com/sashabaranov/go-openai&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;the GitHub repository&lt;/a&gt;. When it came to integrating Vertex AI, specifically for accessing PaLM2, we faced a challenge: the absence of a suitable Go implementation at that time. We took the lead in developing our version and subsequently &lt;a href=&#34;https://github.com/uber/go-vertex-ai&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;open-sourced&lt;/a&gt; it, contributing to the broader community. We encourage community engagement, inviting contributions ranging from bug reports to feature requests. This library mainly focused on features like text generation, chat generation, and embeddings. At the time of writing this blog, Google has also published their &lt;a href=&#34;https://pkg.go.dev/cloud.google.com/go/aiplatform@v1.58.0/apiv1#PredictionClient&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Vertex AI Prediction Client&lt;/a&gt; but we will continue to support our library because of its ease of use.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;08e977a6-95bc-4fea-9bec-77963803511a&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;For Uber-hostedLLMs, we’ve engineered a robust serving stack built upon the STOA inference libraries, to optimize performance and efficiency. This blend of external integration and internal innovation reflects our commitment to staying at the forefront of LLM technology and contributing to its evolving ecosystem.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;dd0f0e30-74ee-4cb0-88cf-849b7182a21c&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;de64298b-1d41-4f31-94dd-8efe0c3fd1f4&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXdm1yQEGqJOKLbzBDtbpKf9DxKGFweuXueR8Din4Z1dKCy1nB2RZgD1OnrxROhyEQlogzt4fLUijzaLvIqkpRwZsNxK9h-tDI9LhoAeKrZDG2fo5j8ThIVw-DQ-XJ234XQIMpDH9k2G0REM6Mdqjsb-dsE?key=5egmPsUgOM1kuqOeYjTalA&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2e53726b-6bc9-4d35-86ab-73767c4c9764&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;25fc1db6-aa70-49af-8770-af946ab52ae8&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Beyond its serving component, an integral facet of GenAI Gateway is the incorporation of a Personal Identifiable Information (PII) redactor. Numerous studies have underscored the susceptibility of LLMs to potential data breaches, presenting significant security concerns for Uber. In response, GenAI Gateway incorporates a PII redactor that anonymizes sensitive information within requests before forwarding them to third-party vendors. Upon receiving responses from these external LLMs, the redacted entities are restored through an un-redaction process. The goal of this redaction/un-redaction process is to minimize the risk of exposing sensitive data.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c6a305fc-df19-4b59-855f-81e55b619b53&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Complementing its core functionalities, GenAI Gateway incorporates additional components designed for authentication and authorization, metrics emission to facilitate reporting and alerting, and the generation of audit logs for comprehensive cost attribution, security audit purposes, quality evaluation, and so on. All these components are seamlessly integrated into Uber’s in-house ecosystem, ensuring a cohesive and synergistic integration that aligns with the organization’s broader technological framework. This strategic alignment underscores GenAI Gateway’s commitment to not only meeting immediate needs, but also seamlessly integrating with Uber’s established infrastructure for enhanced efficiency and compatibility.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e465a37b-3942-438f-b401-047964f7ea17&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Today, GenAI Gateway is used by close to 30 customer teams and serves 16 million queries per month, with a peak QPS of 25.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;c39f3924-1f0f-4622-8415-aff024774735&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-comparison-to-similar-offering&#34;&gt;&lt;strong&gt;Comparison to similar offering&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;dd5d024c-69af-4884-8d0f-693d06a660f3&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Although Databricks recently introduced the &lt;a href=&#34;https://www.databricks.com/blog/announcing-mlflow-ai-gateway&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;MLflow AI Gateway&lt;/a&gt; that shares several features with our GenAI Gateway, GenAI Gateway stands apart in key ways from the MLflow AI Gateway. Our GenAI Gateway closely mirrors OpenAI’s interface, offering benefits not found in the MLflow AI Gateway, which has adopted a unique syntax for LLM access (create_route and query). In addition to aligning with OpenAI’s interface, GenAI Gateway enables a consistent approach to data security and privacy across all use cases. Furthermore, our platform extends beyond Python, providing support for Java and Go, which are the primary programming languages used in Uber’s backend infrastructure. This multi-language support, combined with our focus on security and alignment with OpenAI’s familiar interface, underscores GenAI Gateway’s unique position in the realm of LLM platforms.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7522f8ea-645f-421f-8016-c4ed75c83a03&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;802ff089-59a7-495a-9ff4-6f8b132bc26c&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-challenges&#34;&gt;&lt;strong&gt;Challenges&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7620ca6d-1028-4428-990e-21fa9481b986&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The aim is for this platform to emulate the performance and quality of the native OpenAI API so closely that the transition is imperceptible. In this section of our blog, we will delve into the challenges encountered in achieving this seamless integration, particularly through the lens of handling PII.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;c6009cac-ddc0-4bce-9bd5-312707413fe7&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-pii-redactor&#34;&gt;&lt;strong&gt;PII Redactor&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f3b7ab62-f0d5-4785-9b6b-e777a175b9ea&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The PII redactor, while essential for privacy and security, introduces challenges to both latency and result quality. To understand how PII redactor introduces these challenges, we first need to understand how PII redaction works.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5f946373-3a8b-4878-8264-377734a7ac83&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The PII redactor scans input data, identifying and replacing all instances of PII with anonymized placeholders. Its sophisticated algorithm adeptly recognizes a wide range of PII categories. Each type of PII is substituted with a unique placeholder–for example, names are converted to ANONYMIZED_NAME_, while phone numbers are changed to ANONYMIZED_PHONE_NUMBER_. To maintain distinctiveness, these placeholders are assigned sequential numbers, creating unique identifiers for each occurrence: the first name in a dataset is labeled as ANONYMIZED_NAME_0, followed by ANONYMIZED_NAME_1 for the second, and so forth. The following example illustrates this process in action:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;494420ae-568d-437b-b3c1-d52afd067ab9&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;div data-wp-block-name=&#34;core/columns&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1cac3655-b6a7-4699-9a1a-0258a84f8f74&amp;quot;,&amp;quot;isStackedOnMobile&amp;quot;:true}&#34; class=&#34;wp-block-columns is-layout-flex wp-container-core-columns-is-layout-1 wp-block-columns-is-layout-flex&#34;&gt;&#xA;&lt;div data-wp-block-name=&#34;core/column&#34; data-wp-block=&#34;[]&#34; class=&#34;wp-block-column is-layout-flow wp-block-column-is-layout-flow&#34;&gt;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Original Text&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;George Washington is the first president of the United States. Abraham Lincoln is known for his leadership during the Civil War and the Emancipation Proclamation.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div data-wp-block-name=&#34;core/column&#34; data-wp-block=&#34;[]&#34; class=&#34;wp-block-column is-layout-flow wp-block-column-is-layout-flow&#34;&gt;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Anonymized Text&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;mark class=&#34;has-inline-color has-276-ef-1-color&#34;&gt;ANONYMIZED_NAME_0&lt;/mark&gt; is the first president of the United States. &lt;mark class=&#34;has-inline-color has-276-ef-1-color&#34;&gt;ANONYMIZED_NAME_1&lt;/mark&gt; is known for his leadership during the Civil War and the Emancipation Proclamation.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a390ee88-0d87-45ea-9e39-ef9714ef0190&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1bd16342-68ba-447b-b1e9-58dc0f417e92&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The mapping of PII data to anonymized placeholders is used in the un-redaction process that restores PII data from anonymized placeholders back to its original form, before returning the result to users.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4b0a9f7f-be47-4c51-8207-4f666854ec06&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Depending on the location the PII data is in the input, the same word can be redacted to different anonymized placeholders as it will be appended with different sequential numbers:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6da4648d-9005-47d8-9c1b-457872f11f9f&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;div data-wp-block-name=&#34;core/columns&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2a7aa4dd-5804-45ff-b42d-dce68e393123&amp;quot;,&amp;quot;isStackedOnMobile&amp;quot;:true}&#34; class=&#34;wp-block-columns is-layout-flex wp-container-core-columns-is-layout-2 wp-block-columns-is-layout-flex&#34;&gt;&#xA;&lt;div data-wp-block-name=&#34;core/column&#34; data-wp-block=&#34;[]&#34; class=&#34;wp-block-column is-layout-flow wp-block-column-is-layout-flow&#34;&gt;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Original Text&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Abraham Lincoln is known for his leadership during the Civil War and the Emancipation Proclamation. George Washington is the first president of the United States.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div data-wp-block-name=&#34;core/column&#34; data-wp-block=&#34;[]&#34; class=&#34;wp-block-column is-layout-flow wp-block-column-is-layout-flow&#34;&gt;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Anonymized Text&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;mark class=&#34;has-inline-color has-276-ef-1-color&#34;&gt;ANONYMIZED_NAME_0&lt;/mark&gt; is known for his leadership during the Civil War and the Emancipation Proclamation. &lt;mark class=&#34;has-inline-color has-276-ef-1-color&#34;&gt;ANONYMIZED_NAME_1&lt;/mark&gt; is the first president of the United States.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b782d3a7-95b8-4f93-bfdc-f6fac2dea047&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:4,&amp;quot;hash&amp;quot;:&amp;quot;c80b26e7-853a-4bfd-a948-197d4519ed46&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-latency&#34;&gt;&lt;strong&gt;Latency&lt;/strong&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1470fed1-1c5b-404c-bb90-d42067674e3b&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;While most additional components in GenAI Gateway are lightweight, the PII redactor, by nature of scanning and anonymizing entire requests, incurs added latency proportional to the length of the input request. In cases where the input request is notably large, such as a few thousand tokens, the PII redactor alone can introduce a latency of several seconds. To address this, we’ve transitioned to a CPU-optimized model, resulting in a substantial 80%+ reduction in latency, without compromising accuracy. Furthermore, we are in the process of assessing more advanced models, including one that leverages GPU technology, to further enhance the processing speed and overall efficiency of the PII redactor.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:4,&amp;quot;hash&amp;quot;:&amp;quot;087365ba-af49-4fff-916f-f0fbfa2998ee&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-quality&#34;&gt;&lt;strong&gt;Quality&lt;/strong&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0e2e3c69-1d74-47d1-8e92-34988bac8b83&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The PII redactor can inadvertently impact the quality of results. Its process of anonymizing sensitive data, while safeguarding user information, sometimes strips away crucial context, thereby affecting the response quality of LLMs. For example, a query like “Who is George Washington?” is transformed into “Who is ANONYMIZED_NAME_0” for LLM processing. This anonymization can hinder LLMs’ ability to generate relevant responses due to the loss of specific contextual information.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9fdb0ac0-6a2a-44cb-a471-14462165dd91&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Furthermore, the PII redactor’s mechanism presents unique challenges in scenarios like LLM caching and Retrieval Augmented Generation (RAG). LLM caching, which stores responses for frequently asked questions to facilitate quick retrieval, faces a dilemma. Anonymized queries, such as “Who is George Washington?” and “Who is Abraham Lincoln?”, become indistinguishable post-redaction, leading to potential inaccuracies in cached responses. Similarly, RAG, which relies on fetching pertinent documents to aid LLMs in response generation, struggles with the inconsistencies introduced by anonymization. For instance, embedding a historical article about the American Revolutionary War might involve different anonymized placeholders for the same entity in offline and online contexts, leading to the retrieval of incorrect documents.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2f0c4eea-0d91-4bbb-80ba-cbf460e06a0b&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;These challenges highlight a fundamental issue: the difficulty in linking anonymized placeholders back to their original entities, causing errors in cached results or document retrieval. While maintaining a global table mapping original entities to anonymized placeholders is impractical, we are exploring solutions:&amp;nbsp; One approach encourages customers to use Uber-hostedLLMs, which do not require PII redaction. Simultaneously, we are evaluating the security assurances of third-party vendors to consider the possibility of forgoing the PII redactor entirely, striving to balance privacy concerns with operational effectiveness.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;e1b6de5b-fe78-4d7c-bde0-04951bf725f2&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-other-challenges&#34;&gt;&lt;strong&gt;Other Challenges&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d0f6465d-4a72-4f92-988d-4f7b68bee7ac&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Beyond the previously mentioned difficulties with PII redaction, the GenAI Gateway encounters additional, diverse challenges. The ever-evolving landscape of Large Language Models (LLMs) in recent months has prompted us to dynamically adjust our priorities. For instance, the recent introduction of GPT-4V shook things up by altering the request interface to accommodate image URLs and base64-encoded images. Fortunately, the responsive open-source community swiftly proposed solutions to seamlessly adapt to this change.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;87fc3c4d-83a0-4ebf-9418-3b40fbf0a158&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Given that GenAI Gateway’s core functionality revolves around forwarding requests to relevant LLM vendors, its availability is closely tied to the operational status of these vendors. In the event of a vendor outage, effective communication with users is crucial to prevent any misattribution of issues to the gateway itself. To bolster resilience, we are actively exploring the possibility of incorporating Uber-hostedLLMs as a fallback option when a third-party vendor encounters downtime.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e65b175f-48ce-4c6d-a292-db0227c90f3a&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4c72bb58-460c-4754-be32-ed051f246615&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-use-case-summarisation-of-chats-for-agents-resolution&#34;&gt;&lt;strong&gt;Use Case: Summarisation of Chats for Agents Resolution&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b1ed6027-0b3d-4a7e-a8ab-4e59ae013f4b&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In our continuous pursuit of enhancing customer support efficiency, Uber leverages large language models (LLMs) to streamline the process for our customer support agents. The primary focus is on swiftly summarizing user issues and suggesting potential resolution actions, significantly reducing the time it takes to address user queries. This not only expedites query resolutions but also contributes to an overall improved user experience. We leverage LLMs internally for following&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;ordered&amp;quot;:true,&amp;quot;hash&amp;quot;:&amp;quot;0aee051c-93e7-4bbf-a71b-afb5c6d71f45&amp;quot;,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Enhance chatbot-to-agent transitions, providing agents with concise summaries of prior interactions for improved understanding, faster resolution and addressing key challenges&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Furnish agents with crucial background information and user sentiments, enabling empathetic and contextually accurate support.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Implement automatic summarization of contact interactions, reducing manual summarization time by 80% and improving operational efficiency.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;d7dfbca3-3c84-4ee3-92e3-780a9377fe18&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-impact&#34;&gt;&lt;strong&gt;Impact&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c2da11cc-0927-4036-9dd7-500c408aa19a&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The implementation of LLMs has proven highly beneficial, with 97% of generated summaries found to be useful in resolving customer issues. Agents report significant time savings in reading and documentation, thereby enhancing their overall productivity. The agents are able to revert back to users 6 seconds faster than before. We are generating ~20 million summaries per week leveraging the LLMs, which we plan to expand to more regions and contact types in the future.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d87d11d4-8c61-4223-975e-5b8ee9b78de2&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In essence, our utilization of LLMs at Uber transcends mere automation–it’s a strategic enhancement focused on empowering our customer support agents to provide faster, more accurate, and empathetic resolutions.&amp;nbsp; All with the goal of delivering an unparalleled experience to our users.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;6f3fff59-4eda-4a9e-ba4e-e4d86dd0f080&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-how-gen-ai-gateway-is-used&#34;&gt;&lt;strong&gt;How Gen AI Gateway is used&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3c251dc5-8f76-4f63-8cf6-46b83d4617df&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Within Uber’s Customer Obsession organization, the CO Inference Gateway was initially employed to expose various ML Task-based API contracts internally to other services, abstracting out different ML Model hosts. For Summarization, we expanded this service to include a new Generation ML Task for Text, Chat, and Embedding Generation. This extension enables connections to both Open AI and Google Vertex AI models, fostering flexibility and adaptability.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6e9637f3-267e-49bc-8cbf-b2dbf1ce70e8&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;3a0a4eff-508a-450e-b7b6-d30abd888d73&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXe5_r9WXoElXeydaicgO-hAtPt5YOQr4MqZ3CKPRaVxgFWIkw1EnRrd9QKeEsmG-9SsHwbhGG-epfVUKYq6AGCli5guSvFn445zPBDxDkh6PLqYFzzwu4WE7yWr7f_4E7YOqYQ1z7o_WP3iO5Qyza27D7rI?key=5egmPsUgOM1kuqOeYjTalA&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;631b8d21-ba2a-4a6d-acc3-604bff6e1da1&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7e654ae5-5120-4e71-86fd-67fa18b95853&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;a href=&#34;https://drive.google.com/file/d/1mIgcSDvcFjzWO7H774u1ay20mF00sZEG/view?usp=drive_link&#34;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4c59483c-8bd4-4b50-9c4b-5f82c528ad7d&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Encountering challenges such as PII Redaction, Cost attribution, and the imperative for a centralized service at Uber to connect with any external Language Model (LLM), we made a strategic decision to leverage the Gen AI Gateway instead of directly calling external models. This decision was guided by the need for a comprehensive solution that not only addresses challenges effectively but also ensures a robust and secure integration. By doing so, we navigate complexities and optimize the utility of our AI-powered solutions, aligning with Uber’s commitment to innovation and excellence in customer support.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;85d40cc1-5690-4a43-9b85-98191edf7e4f&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;d8ba6985-0b79-4558-a5b8-078e0e381f63&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXcfFXsQPWf1S4ppo-vik3bFc867WLviUl182cHDZ-K7JZNaut0dfHXU5kKhFpVHJX9KERz4NVNwQS9un8lHVCwt74uD4MJ0sINAUrcyQwifX3COr4k3ZiJwdE338BFLKxROhBOSxwNKAqntSNFWi6-zNTxu?key=5egmPsUgOM1kuqOeYjTalA&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ee250d3c-364e-42b1-bde5-b5d81c1e3f20&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;c5f5f108-19fa-4345-b0bd-99044df1648e&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-prompt&#34;&gt;&lt;strong&gt;Prompt&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ec567b34-0b9f-453d-8864-911845c39aa5&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Following is a sample Prompt for the summarisation of contact tickets. We provide a few examples in the prompt context for few-shot learning.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote data-wp-block-name=&#34;core/quote&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;01b04911-552d-4e9d-b786-8ecb2b12562c&amp;quot;,&amp;quot;value&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;wp-block-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The following is a conversation between an Uber Customer support Bot called BOT, possibly a customer support agent called AGENT and an Uber Eats Customer called USER. Provide a detailed breakdown of the conversation. Identify all issues or intents and associated sentiments from the user. Extract the most pertinent part of user utterances and agent responses for each identified problem.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;input:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;{{conversation_log}} // Conversation log is the actual message history between customers, chatbots and agents.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f23b1fbe-c359-4c05-95ae-1a952fe7008f&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;316cdf49-3163-4cda-b13f-79fc13d055b3&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-learnings&#34;&gt;&lt;strong&gt;Learnings&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;885e8612-3fc7-4e44-b412-044519b57ea9&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In reflecting on our journey with LLMs, a fundamental lesson stands out: the critical need for adaptability in the face of the rapidly evolving LLM landscape. As we delve deeper into the realm of advanced LLM applications, the importance of skillfully managing the interplay between ever-changing technologies, user privacy, and efficiency becomes increasingly evident. This landscape is constantly shifting, and our dedication to continuous improvement is more crucial than ever. Navigating these dynamics with agility and foresight is pivotal to our mission, ensuring that we not only keep pace with technological advancements but also uphold our commitment to user privacy and system efficiency.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;daca159f-1260-4b21-b095-be3639656066&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;314ead02-2022-4b7f-9bb3-a3dc6eb8e93c&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-future-works&#34;&gt;&lt;strong&gt;Future Works&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1ac48011-3d5a-40e7-8c50-8c1736fb0fbe&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Looking ahead, our vision for the GenAI Gateway is to elevate and refine its capabilities to better serve our users. A key focus is on enhancing the onboarding process for new models. Whether these are bespoke, fine-tuned models tailored to specific needs or those sourced from the vibrant open-source community, our goal is to make their integration as fluid and user-friendly as possible. Moreover, we are keen on augmenting the gateway with advanced features that address the dynamic challenges of working with Large Language Models. This includes implementing intelligent LLM caching mechanisms, developing robust fallback logic, and introducing sophisticated hallucination detection. Safety and policy guardrails are also on our agenda to ensure that our platform remains secure and compliant with evolving standards.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c896442c-5abb-420b-85b5-898882f48a1e&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In our journey to expand the gateway’s capabilities, we also recognize the importance of tapping into the vast potential of the open-source ecosystem. To this end, we are actively working towards integrating with libraries. This will not only enhance the functional breadth of our system, but also make it more versatile, enabling our users to explore and leverage a broader range of solutions. These future endeavors underscore our commitment to continually evolve the GenAI Gateway, ensuring it remains a cutting-edge, versatile, and secure platform for harnessing the power of LLMs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;62803538-f24d-48ec-971e-28ba28c745cc&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;c312f523-db66-494c-9407-311cee6c8b60&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-conclusion&#34;&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ad1f31f3-01c4-475c-b839-51e7dd25b3cf&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;LLMs have become a transformative force. The integration of LLMs at Uber, however, has not been without challenges. Inconsistent integration strategies and the absence of a standardized approach have led to inefficiencies and difficulties in monitoring costs and vendor usage.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8def3e9e-3285-449e-9694-e7fcfe114573&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Addressing these issues, Uber’s Michelangelo team developed the GenAI Gateway, a unified platform facilitating access to LLMs from multiple providers, including OpenAI and Vertex AI, as well as Uber’s in-house models. This platform streamlines the integration process, ensuring compliance with privacy and security standards and efficient usage management. GenAI Gateway’s design, mirroring the OpenAI API, ensures compatibility with existing tools and maintains pace with the evolving open-source community. It also features a PII redactor, enhancing security. This strategic development of the GenAI Gateway, coupled with its focus on operational efficiency and alignment with Uber’s broader technological framework, exemplifies Uber’s commitment to innovation while addressing the dynamic challenges of working with LLMs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d24118d6-acbf-4d50-959b-5337150cda8c&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-acknowledgments&#34;&gt;&lt;strong&gt;Acknowledgments&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ae51ea31-0c43-4ce0-9617-47822269b6e2&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We could not have accomplished the technical work outlined in this article without the help of various engineering teams, Uber AI, and the Uber Customer Obsession Team. We would also like to thank the various product teams working with us in adopting Gen AI Gateway.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;fontSize&amp;quot;:&amp;quot;small&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;afc6017c-684e-44ac-abcc-678a2031b044&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34; class=&#34;has-small-font-size&#34;&gt;Cover Photo Attribution: The “&lt;strong&gt;Artificial Intelligence, AI&lt;/strong&gt;” image is covered by a &lt;a href=&#34;https://creativecommons.org/licenses/by/2.0/&#34;&gt;CC BY 2.0&lt;/a&gt; license and is credited to &lt;a href=&#34;https://www.flickr.com/photos/152824664@N07&#34;&gt;mikemacmarketing&lt;/a&gt;. No changes have been made to the image (&lt;a href=&#34;https://openverse.org/image/49410795-b3ba-421b-918b-7f2cd9178f19?q=artificial%20intelligence&#34;&gt;source&lt;/a&gt;).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;fontSize&amp;quot;:&amp;quot;small&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;f526d83b-eb4f-49c3-9e7f-661ae12bcd4b&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34; class=&#34;has-small-font-size&#34;&gt;Vertex AI™, PaLM™, Google Dialogflow™&amp;nbsp; and Go™ are trademarks of Google LLC and this blog post is not endorsed by or affiliated with Google in any way.&lt;/p&gt;】&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:1,&#34;hash&#34;:&#34;639e6d58-1937-4773-a697-02436d75c659&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-introduction&#34;&gt;&lt;strong&gt;简介&lt;/strong&gt;&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;a4ced9b4-63a9-4d41-995b-c471a659eed4&#34;,&#34;dropCap&#34;:false}&#34;&gt;大型语言模型（法学硕士）已成为科技行业的关键工具，为各个行业的创新和进步开辟了新途径。在 Uber，法学硕士的影响尤其明显，在不同领域确定了 60 多个不同的用例，从流程自动化到客户支持和内容生成。当 Uber 的团队开始将法学硕士融入到他们的产品中时，一些挑战已经浮现出来。值得注意的是，不同团队采用不同的集成策略导致效率低下和重复工作。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;83d057b4-73ce-417e-bd02-f91cc428a2a9&#34;,&#34;dropCap&#34;:false}&#34;&gt;解决这些问题为了应对挑战并利用对法学硕士不断增长的需求，Uber 的 Michelangelo 团队创新了一种解决方案：GenAI Gateway。 GenAI Gateway 作为 Uber 内所有 LLM 使用案例的统一平台，通过一致且高效的界面提供对 OpenAI 和 Vertex AI 等不同供应商的模型以及 Uber 托管模型的无缝访问。 GenAI Gateway 旨在简化希望在项目中利用 LLM 的团队的集成流程。其简单的入职流程减少了团队所需的工作量，提供了一条清晰、直接的途径来利用法学硕士的力量。此外，由工程安全团队管理的标准化审查流程会在用例被授予网关访问权限之前根据 Uber 的数据处理标准审查用例。  如果测试成功，这些项目将通过我们标准的跨功能软件开发流程。网关的集中化特性还简化了各个团队的使用和预算管理，提高了整个公司法学硕士集成的控制力和运营效率。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;8f5812a9-767d-43f3-915e-0de639f58afc&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;271006ea-850d-4aaa-9b12-649b7fd88696&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-design-amp-architecture&#34;&gt;&lt;strong&gt;设计与架构&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;e3d75695-952c-4dcf-aa1b-c4a1f2346c22&#34;,&#34;dropCap&#34;:false}&#34;&gt;关键设计决定是镜像 t 的 HTTP/JSON 接口OpenAI API。这一战略选择植根于 OpenAI 的广泛采用和蓬勃发展的开源生态系统，特别是 LangChain 和 LlamaIndex 等库。这种一致性促进了无缝的互操作性，确保 GenAI Gateway 与现有开源工具和库的兼容性，同时最大限度地减少调整的需要。鉴于开源社区的快速发展，专有接口可能会面临快速过时的风险。通过与 OpenAI 的界面保持一致，GenAI Gateway 与前沿技术保持同步。这种方法不仅简化了开发人员的入职流程，还扩展了 GenAI Gateway 的覆盖范围，允许用户通过熟悉的 OpenAI API 框架访问 Vertex AI 等不同供应商的 LLM。请参阅下面的图 1 了解高级架构图。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;6d3618fd-55dd-44d8-b957-838a8b5dec19&#34;,&#34;dropCap&#34;:false}&#34;&gt;以下代码片段演示了如何使用 GenAI Gateway 通过统一的接口访问来自不同供应商的 LLM：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;6963d647-7655-44b0-9310-a7d510ddb789&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;align&#34;:&#34;center&#34;,&#34;hash&#34;:&#34;681fd513-bcc0-4e80-8715-d6e834a589a2&#34;,&#34;alt&#34; :&#34;&#34;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img 解码=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXeSeRL_lT222k2UnrRa4Ywx8XbtT5alPHmZjCu_7-_RJvRPf-p7TZlT8Lsbm-ysathYSSxqVVCXBE_ALt1IfTeY_Z6CAuC cpuVas1vxly9HbguZ0si1KR0eZ_-9OOlfy3kAmmTSXUrU8SkD5Ct34F2hJB0?key=5egmPsUgOM1kuqOeYjTalA&#34; alt =&#34;&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;2d022d50-550a-4c3c-96f3-5e2b4a27e6d5&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote data-wp-block-name=&#34;core/quote&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;da9b9046-5685-4270-95e5-f47d4210332a&#34;,&#34;value&#34;:&#34;&#34;}&#34; class=&#34; wp-block-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;dropCap&#34;:false}&#34;&gt;&lt;strong&gt;gpt-4 的回答：&lt;/strong&gt;美国的首都是华盛顿特区&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;dropCap&#34;:false}&#34;&gt;&lt;strong&gt;chat-bison 的回答：&lt;/strong&gt; 华盛顿特区是首都美国的。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;dropCap&#34;:false}&#34;&gt;&lt;strong&gt;llama-2-70b-chat-hf-0 的回答：&lt;/ strong&gt;美利坚合众国的首都是华盛顿特区&lt;/p&gt;&#xA;&lt;/块引用&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;核心/段落ph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;d3cfdec3-78b6-45e0-a99f-228020ce7900&#34;,&#34;dropCap&#34;:false}&#34;&gt;从上面可以看出，开发者编写代码就像使用原生 OpenAI 客户端，同时能够访问来自不同供应商的 LLM。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;fac9714d-4d09-45e5-a474-501a4df1f5f0&#34;,&#34;dropCap&#34;:false}&#34;&gt;架构方面GenAI Gateway 是一项 Go 服务，充当第三方供应商客户周围的包围层，并由为 Uber 法学硕士量身定制的内部服务堆栈进行补充。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;35331a76-20eb-4ee4-96cb-06d88b4940d5&#34;,&#34;dropCap&#34;:false}&#34;&gt;我们的方法与 OpenAI 集成涉及开发来自 &lt;a href=&#34;https://github.com/sashabaranov/go-openai&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;GitHub 存储库&lt;的 Go 客户端实现的内部分支&lt; /a&gt;.当谈到集成 Vertex AI，特别是访问 PaLM2 时，我们面临着一个挑战：当时缺乏合适的 Go 实现。我们率先开发了我们的版本，并随后&lt;a href=&#34;https://github.com/uber/go-vertex-ai&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;开源&lt;/a&gt;它为更广泛的社区做出贡献。我们鼓励社区参与，邀请从错误报告到功能请求等各种贡献。该库主要关注文本生成、聊天生成和嵌入等功能。在撰写本博客时，Google 还发布了他们的 &lt;a href=&#34;https://pkg.go.dev/cloud.google.com/go/aiplatform@v1.58.0/apiv1#PredictionClient&#34; target=&#34;_blank “ rel=&#34;noreferrer noopener&#34;&gt;Vertex AI 预测客户端&lt;/a&gt;，但我们将继续支持我们的库，因为它易于使用。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;08e977a6-95bc-4fea-9bec-77963803511a&#34;,&#34;dropCap&#34;:false}&#34;&gt;对于 Uber-托管LLM，我们设计了一个基于 STOA 推理库的强大服务堆栈，以优化性能和效率。这种外部整合和内部创新的结合反映了我们致力于保持法学硕士技术的前沿并为其不断发展的生态系统做出贡献。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;dd0f0e30-74ee-4cb0-88cf-849b7182a21c&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;align&#34;:&#34;center&#34;,&#34;hash&#34;:&#34;de64298b-1d41-4f31-94dd-8efe0c3fd1f4&#34;,&#34;alt&#34; ：&#34;&#34;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img 解码=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXdm1yQEGqJOKLbzBDtbpKf9DxKGFweuXueR8Din4Z1dKCy1nB2RZgD1OnrxROhyEQlogzt4fLUijzaLvIqkpRwZsNxK9h-tDI9LhoAeKrZDG2fo5j8ThIVw-DQ-XJ234XQIMpDH9k2G0REM6Mdqjsb-dsE?key=5egmPsUgOM1kuqOeYjTalA&#34; alt=&#34;&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;2e53726b-6bc9-4d35-86ab-73767c4c9764&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;25fc1db6-aa70-49af-8770-af946ab52ae8&#34;,&#34;dropCap&#34;:false}&#34;&gt;超出其服务范围GenAI 网关的一个组成部分是个人身份信息 (PII) 编辑器的合并。大量研究强调了法学硕士对潜在数据泄露的敏感性，这给 Uber 带来了重大的安全问题。作为回应，GenAI Gateway 集成了一个 PII 编辑器，可以在将请求转发给第三方供应商之前对请求中的敏感信息进行匿名处理。收到这些外部法学硕士的响应后，已编辑的实体将通过取消编辑过程恢复。此编辑/取消编辑过程的目标是最大限度地降低敏感数据泄露的风险。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;c6a305fc-df19-4b59-855f-81e55b619b53&#34;,&#34;dropCap&#34;:false}&#34;&gt;补充其核心除了功能之外，GenAI Gateway 还集成了额外的组件，这些组件旨在用于身份验证和授权、指标发射以促进报告和警报，以及生成审核日志以进行综合成本归因、安全审核目的、质量评估等。所有这些组件都无缝集成到 Uber 的内部生态系统中，确保与组织更广泛的技术框架保持一致和协同的集成。这一战略联盟强调了 GenAI Gateway 不仅致力于满足即时需求，而且还与 Uber 现有的基础设施无缝集成，以提高效率和兼容性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;e465a37b-3942-438f-b401-047964f7ea17&#34;,&#34;dropCap&#34;:false}&#34;&gt;今天，GenAI Gateway 已被近 30 个客户团队使用，每月服务 1600 万次查询，峰值 QPS 为 25。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;c39f3924-1f0f-4622-8415-aff024774735&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-comparison-to-similar-offering&#34;&gt;&lt;strong&gt;与类似产品比较&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;dd5d024c-69af-4884-8d0f-693d06a660f3&#34;,&#34;dropCap&#34;:false}&#34;&gt;虽然Databricks最近推出了 &lt;a href=&#34;https://www.databricks.com/blog/announcing-mlflow-ai-gateway&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;MLflow AI 网关&lt;/a&gt;，该网关具有多个共享功能与我们的 GenAI 网关 GenAI Gateway 在关键方面与 MLflow AI Gateway 不同。我们的 GenAI 网关与 OpenAI 的界面密切相关，提供了 MLflow AI 网关所没有的优势，MLflow AI 网关采用了独特的 LLM 访问语法（create_route 和查询）。除了与 OpenAI 的界面保持一致外，GenAI Gateway 还可以在所有用例中采用一致的方法来确保数据安全和隐私。此外，我们的平台超越了 Python，提供了对 Java 和 Go 的支持，这是 Uber 后端基础设施中使用的主要编程语言。这种多语言支持，加上我们对安全性的关注以及与 OpenAI 熟悉的界面的一致性，强调了 GenAI Gateway 在 LLM 平台领域的独特地位。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;7522f8ea-645f-421f-8016-c4ed75c83a03&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;802ff089-59a7-495a-9ff4-6f8b132bc26c&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-challenges&#34;&gt;&lt;strong&gt;挑战&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;7620ca6d-1028-4428-990e-21fa9481b986&#34;,&#34;dropCap&#34;:false}&#34;&gt;目标是该平台能够如此紧密地模拟原生 OpenAI API 的性能和质量，以至于这种转变是难以察觉的。在我们博客的这一部分中，我们将深入探讨实现这种无缝集成所遇到的挑战，特别是通过处理 PII 的角度。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;c6009cac-ddc0-4bce-9bd5-312707413fe7&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-pii-redactor&#34;&gt;&lt;strong&gt;PII 编辑器&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;f3b7ab62-f0d5-4785-9b6b-e777a175b9ea&#34;,&#34;dropCap&#34;:false}&#34;&gt;PII 编辑器虽然对于隐私和安全至关重要，但它给延迟和结果质量带来了挑战。要了解 PII 编辑器如何引入这些挑战，我们首先需要了解 PII 编辑器的工作原理。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;5f946373-3a8b-4878-8264-377734a7ac83&#34;,&#34;dropCap&#34;:false}&#34;&gt;PII 编辑器扫描输入数据，识别并用匿名占位符替换所有 PII 实例。其复杂的算法能够熟练地识别各种 PII 类别。每种类型的 PII 都替换为唯一的占位符 - 例如，姓名会转换为 ANONYMIZED_NAME_，而电话号码会更改为 ANONYMIZED_PHONE_NUMBER_。为了保持独特性，这些占位符被分配了连续的数字，为每次出现创建唯一的标识符：数据集中的第一个名称被标记为 ANONYMIZED_NAME_0，后面是ANONYMIZED_NAME_1 代表第二个，依此类推。以下示例说明了此过程的实际应用：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;494420ae-568d-437b-b3c1-d52afd067ab9&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;div data-wp-block-name=&#34;core/columns&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;1cac3655-b6a7-4699-9a1a-0258a84f8f74&#34;,&#34;isStackedOnMobile&#34;:true}&#34; class=&#34;wp -block-columns is-layout-flex wp-container-core-columns-is-layout-1 wp-block-columns-is-layout-flex&#34;&gt;&#xA;&lt;div data-wp-block-name=&#34;core/column&#34; data-wp-block=&#34;[]&#34; class=&#34;wp-block-column is-layout-flow wp-block-column-is-layout-flow&#34; &gt;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;dropCap&#34;:false}&#34;&gt;&lt;strong&gt;原始文本&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;dropCap&#34;:false}&#34;&gt;乔治·华盛顿是美国第一任总统。亚伯拉罕·林肯因其在内战和《解放黑奴宣言》期间的领导才能而闻名。&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div data-wp-block-name=&#34;core/column&#34; data-wp-block=&#34;[]&#34; class=&#34;wp-block-column is-layout-flow wp-block-column-is-layout-flow&#34; &gt;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;dropCap&#34;:false}&#34;&gt;&lt;strong&gt;匿名文本&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;dropCap&#34;:false}&#34;&gt;&lt;mark class=&#34;has-inline-color has-276-ef-1-color &#34;&gt;ANONYMIZED_NAME_0&lt;/mark&gt; 是美国第一任总统。 &lt;mark class=&#34;has-inline-color has-276-ef-1-color&#34;&gt;ANONYMIZED_NAME_1&lt;/mark&gt; 因其在内战和《解放黑奴宣言》期间的领导才能而闻名。&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;a390ee88-0d87-45ea-9e39-ef9714ef0190&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;1bd16342-68ba-447b-b1e9-58dc0f417e92&#34;,&#34;dropCap&#34;:false}&#34;&gt;映射匿名占位符的 PII 数据用于取消编辑过程，该过程将 PII 数据从匿名占位符恢复为其原始形式，然后将结果返回给用户。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;4b0a9f7f-be47-4c51-8207-4f666854ec06&#34;,&#34;dropCap&#34;:false}&#34;&gt;取决于PII 数据在输入中的位置，相同的单词可以编辑为不同的匿名占位符，因为它将附加不同的序列号：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;6da4648d-9005-47d8-9c1b-457872f11f9f&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;div data-wp-block-name=&#34;核心/列&#34; data-wp-block=&#34;{&#34;哈希&#34;:&#34;2a7aa4dd-5804-45ff-b42d-dce68e393123&#34;,&#34;isStackedOnMobile&#34;:true}&#34; class=&#34;wp-block-columns is-layout-flex wp-container-core-columns-is-layout-2 wp-block-columns-is-layout-flex&#34; &gt;&#xA;&lt;div data-wp-block-name=&#34;core/column&#34; data-wp-block=&#34;[]&#34; class=&#34;wp-block-column is-layout-flow wp-block-column-is-layout-flow&#34; &gt;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;dropCap&#34;:false}&#34;&gt;&lt;strong&gt;原始文本&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;dropCap&#34;:false}&#34;&gt;亚伯拉罕·林肯因其在内战和《解放黑奴宣言》期间的领导才能而闻名。乔治·华盛顿是美国第一任总统。&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div data-wp-block-name=&#34;core/column&#34; data-wp-block=&#34;[]&#34; class=&#34;wp-block-column is-layout-flow wp-block-column-is-layout-flow&#34; &gt;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;dropCap&#34;:false}&#34;&gt;&lt;strong&gt;匿名文本&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;dropCap&#34;:false}&#34;&gt;&lt;mark class=&#34;has-inline-color has-276-ef-1-color &#34;&gt;ANONYMIZED_NAME_0&lt;/mark&gt; 因其在内战和《解放黑奴宣言》期间的领导才能而闻名。 &lt;mark class=&#34;has-inline-color has-276-ef-1-color&#34;&gt;ANONYMIZED_NAME_1&lt;/mark&gt; 是美国第一任总统。&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;b782d3a7-95b8-4f93-bfdc-f6fac2dea047&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:4,&#34;hash&#34;:&#34;c80b26e7-853a-4bfd-a948-197d4519ed46&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-latency&#34;&gt;&lt;strong&gt;延迟&lt;/strong&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;1470fed1-1c5b-404c-bb90-d42067674e3b&#34;,&#34;dropCap&#34;:false}&#34;&gt;虽然大多数附加GenAI Gateway 中的组件是轻量级的，PII 编辑器由于扫描和匿名化整个请求的性质，会产生与输入请求的长度成比例的延迟。在输入请求特别大的情况下，例如几千个令牌，单独的 PII 编辑器可能会导致几秒钟的延迟。为了解决这个问题，我们转向了 CPU 优化模型，在不影响准确性的情况下，延迟大幅减少了 80% 以上。此外，我们正在评估更先进的模型，包括利用 GPU 技术的模型，以进一步提高 PII 编辑器的处理速度和整体效率。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:4,&#34;hash&#34;:&#34;087365ba-af49-4fff-916f-f0fbfa2998ee&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-quality&#34;&gt;&lt;strong&gt;质量&lt;/strong&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;0e2e3c69-1d74-47d1-8e92-34988bac8b83&#34;,&#34;dropCap&#34;:false}&#34;&gt;PII 编辑器可能会无意中影响结果的质量。其在保护用户信息的同时对敏感数据进行匿名化的过程有时会剥夺关键的上下文，从而影响法学硕士的响应质量。例如，像“谁是乔治·华盛顿？”这样的查询转换为“Who is ANONYMIZED_NAME_0”以进行 LLM 处理。由于特定上下文信息的丢失，这种匿名化可能会阻碍法学硕士生成相关回复的能力。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;9fdb0ac0-6a2a-44cb-a471-14462165dd91&#34;,&#34;dropCap&#34;:false}&#34;&gt;此外， PII 编辑器的机制在 LLM 缓存和检索增强生成 (RAG) 等场景中提出了独特的挑战。 LLM 缓存存储常见问题的答案以方便快速检索，但它面临着两难境地。匿名查询，例如“乔治·华盛顿是谁？”和“谁是亚伯拉罕·林肯？”在编辑后变得难以区分，导致缓存的响应可能不准确。同样，RAG 依靠获取相关文档来帮助法学硕士生成回复，但它也面临着匿名化带来的不一致问题。例如，嵌入一篇有关美国独立战争的历史文章可能会在离线和在线上下文中涉及同一实体的不同匿名占位符，从而导致检索到不正确的文档。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;2f0c4eea-0d91-4bbb-80ba-cbf460e06a0b&#34;,&#34;dropCap&#34;:false}&#34;&gt;这些挑战突显了一个根本问题：难以将匿名占位符链接回其原始实体，从而导致缓存结果或文档检索出现错误。虽然维护将原始实体映射到匿名占位符的全局表是不切实际的，但我们正在探索解决方案：一种方法鼓励客户使用 Uber 托管的LLM，这不需要 PII 编辑。同时，我们正在评估第三方供应商的安全保证，以考虑完全放弃 PII 编辑器的可能性，努力平衡隐私问题和运营效率。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;e1b6de5b-fe78-4d7c-bde0-04951bf725f2&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-other-challenges&#34;&gt;&lt;strong&gt;其他挑战&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;d0f6465d-4a72-4f92-988d-4f7b68bee7ac&#34;,&#34;dropCap&#34;:false}&#34;&gt;超越之前除了 PII 编辑方面的困难之外，GenAI 网关还遇到了更多不同的挑战。近几个月来，大型语言模型 (LLM) 不断发展的格局促使我们动态调整我们的优先事项。例如，最近推出的 GPT-4V 通过改变请求集成而改变了一切rface 来容纳图像 URL 和 base64 编码的图像。幸运的是，响应迅速的开源社区迅速提出了解决方案来无缝适应这一变化。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;87fc3c4d-83a0-4ebf-9418-3b40fbf0a158&#34;,&#34;dropCap&#34;:false}&#34;&gt;鉴于 GenAI Gateway的核心功能围绕着向相关LLM供应商转发请求，其可用性与这些供应商的运营状态密切相关。如果发生供应商中断，与用户的有效沟通对于防止将问题错误地归因于网关本身至关重要。为了增强弹性，我们正在积极探索将 Uber 托管的LLM 纳入第三方供应商遇到停机时作为后备选项的可能性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;e65b175f-48ce-4c6d-a292-db0227c90f3a&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;4c72bb58-460c-4754-be32-ed051f246615&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-use-case-summarization-of-chats-for-agents-resolution&#34;&gt;&lt;strong&gt;用例：用于代理解析的聊天摘要&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;b1ed6027-0b3d-4a7e-a​​8ab-4e59ae013f4b&#34;,&#34;dropCap&#34;:false}&#34;&gt;在我们的连续为了提高客户支持效率，Uber 利用大型语言模型 (LLM) 来简化客户支持代理的流程。主要重点是快速总结用户问题并建议潜在的解决措施，从而显着减少解决用户查询所需的时间。这不仅可以加快查询解决速度，还有助于整体改善用户体验。我们在内部利用法学硕士来进行以下工作&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;ordered&#34;:true,&#34;hash&#34;:&#34;0aee051c-93e7-4bbf-a71b-afb5c6d71f45&#34;,&#34;values&#34;:&#34; “}”&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;增强聊天机器人到客服人员的转换，为客服人员提供先前交互的简明摘要，以便更好地理解、更快地解决问题并解决关键挑战&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;为客服人员提供重要的背景信息和用户情绪，从而提供富有同理心且上下文准确的支持。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;实现联系人交互自动汇总，减少 80% 的手动汇总时间，提高运营效率。&lt;/li &gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;d7dfbca3-3c84-4ee3-92e3-780a9377fe18&#34;}&#34; class=&#34;wp -块标题“id=”h-影响&#34;&gt;&lt;strong&gt;影响&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;c2da11cc-0927-4036-9dd7-500c408aa19a&#34;,&#34;dropCap&#34;:false}&#34;&gt;执行事实证明，法学硕士非常有益，97% 的生成摘要对于解决客户问题很有用。代理商表示，在阅读和记录文档方面节省了大量时间，从而提高了他们的整体生产力。代理能够比以前更快 6 秒恢复用户。我们每周利用法学硕士生成约 2000 万份摘要，并计划在未来将其扩展到更多地区和联系人类型。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;d87d11d4-8c61-4223-975e-5b8ee9b78de2&#34;,&#34;dropCap&#34;:false}&#34;&gt;本质上，我们在 Uber 对法学硕士的利用超越了单纯的自动化——这是一项战略增强，重点是让我们的客户支持代理能够提供更快、更准确和更有同理心的解决方案。  所有这些都是为了向我们的用户提供无与伦比的体验。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;6f3fff59-4eda-4a9e-ba4e-e4d86dd0f080&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-how-gen-ai-gateway-is-used&#34;&gt;&lt;strong&gt;Gen AI网关如何使用&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;3c251dc5-8f76-4f63-8cf6-46b83d4617df&#34;,&#34;dropCap&#34;:false}&#34;&gt;在 Uber 客户内Obsession 组织中，CO 推理网关最初用于将各种基于 ML 任务的 API 合约在内部公开给其他服务，从而抽象出不同的 ML 模型主机。对于摘要，我们扩展了此服务，包括用于文本、聊天和嵌入生成的新生成 ML 任务。此扩展支持与 Open AI 和 Google Vertex AI 模型的连接，从而提高灵活性和适应性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;6e9637f3-267e-49bc-8cbf-b2dbf1ce70e8&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;align&#34;:&#34;center&#34;,&#34;hash&#34;:&#34;3a0a4eff-508a-450e-b7b6-d30abd888d73&#34;,&#34;alt&#34; :&#34;&#34;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img 解码=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXe5_r9WXoElXeydaicgO-hAtPt5YOQr4MqZ3CKPRaVxgFWIkw1EnRrd9QKeEsmG-9SsHwbhGG-epfVUKYq6AGCli5guSvFn4 45zPBDxDkh6PLqYFzzwu4WE7yWr7f_4E7YOqYQ1z7o_WP3iO5Qyza27D7rI?key=5egmPsUgOM1kuqOeYjTalA&#34; alt=&#34; “referrerpolicy =“no-referrer”&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;631b8d21-ba2a-4a6d-acc3-604bff6e1da1&#34;,&#34;opacity&#34;:&#34;alpha 通道&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;p 数据-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;7e654ae5-5120-4e71-86fd-67fa18b95853&#34;,&#34;dropCap&#34;:false}&#34;&gt;&lt;a href=&#34;https:// /drive.google.com/file/d/1mIgcSDvcFjzWO7H774u1ay20mF00sZEG/view?usp=drive_link&#34;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;4c59483c-8bd4-4b50-9c4b-5f82c528ad7d&#34;,&#34;dropCap&#34;:false}&#34;&gt;遇到诸如此类的挑战由于 PII 编辑、成本归因以及 Uber 集中服务与任何外部语言模型 (LLM) 连接的必要性，我们做出了利用 Gen AI 网关而不是直接调用外部模型的战略决策。这一决定是基于对全面解决方案的需求，该解决方案不仅能有效应对挑战，还能确保稳健和安全的集成。通过这样做，我们可以应对复杂性并优化人工智能解决方案的效用，这与 Uber 对创新和卓越客户支持的承诺保持一致。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;85d40cc1-5690-4a43-9b85-98191edf7e4f&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;align&#34;:&#34;center&#34;,&#34;hash&#34;:&#34;d8ba6985-0b79-4558-a5b8-078e0e381f63&#34;,&#34;alt&#34; ：&#34;&#34;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img 解码=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXcfFXsQPWf1S4ppo-vik3bFc867WLviUl182cHDZ-K7JZNaut0dfHXU5kKhFpVHJX9KERz4NVNwQS9un8lHVCwt74u D4MJ0sINAUrcyQwifX3COr4k3ZiJwdE338BFLKxROhBOSxwNKAqntSNFWi6-zNTxu?key=5egmPsUgOM1kuqOeYjTalA&#34; alt=&#34; “referrerpolicy =“no-referrer”&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;ee250d3c-364e-42b1-bde5-b5d81c1e3f20&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;c5f5f108-19fa-4345-b0bd-99044df1648e&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-prompt&#34;&gt;&lt;strong&gt;提示&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;ec567b34-0b9f-453d-8864-911845c39aa5&#34;,&#34;dropCap&#34;:false}&#34;&gt;以下是示例 提示汇总联系工单。我们在提示上下文中提供了一些示例，以进行小样本学习。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote data-wp-block-name=&#34;core/quote&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;01b04911-552d-4e9d-b786-8ecb2b12562c&#34;,&#34;value&#34;:&#34;&#34;}&#34; class=&#34; wp-block-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;dropCap&#34;:false}&#34;&gt;以下是名为 BOT 的 Uber 客户支持机器人（可能是客户支持代理）之间的对话称为 AGENT 和 Uber Eats 优食定制呃叫USER。提供对话的详细分析。识别用户的所有问题或意图以及相关情绪。针对每个已识别的问题，提取用户话语和代理响应中最相关的部分。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;dropCap&#34;:false}&#34;&gt;输入：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;dropCap&#34;:false}&#34;&gt;{{conversation_log}} // 对话日志是客户、聊天机器人和聊天机器人之间的实际消息历史记录代理。&lt;/p&gt;&#xA;&lt;/块引用&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;f23b1fbe-c359-4c05-95ae-1a952fe7008f&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;316cdf49-3163-4cda-b13f-79fc13d055b3&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-learnings&#34;&gt;&lt;strong&gt;学习内容&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;885e8612-3fc7-4e44-b412-044519b57ea9&#34;,&#34;dropCap&#34;:false}&#34;&gt;反映在我们的法学硕士之旅中，我们学到了一个重要的教训：面对快速发展的法学硕士环境，迫切需要适应能力。随着我们深入研究高级法学硕士应用领域，巧妙管理不断变化的技术、用户隐私和效率之间相互作用的重要性变得越来越明显。形势在不断变化，我们致力于持续改进比以往任何时候都更加重要。灵活而富有远见地驾驭这些动态对于我们的使命至关重要，确保我们不仅跟上技术进步的步伐，而且恪守我们对用户隐私和系统效率的承诺。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;daca159f-1260-4b21-b095-be3639656066&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;314ead02-2022-4b7f-9bb3-a3dc6eb8e93c&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-future-works&#34;&gt;&lt;strong&gt;未来作品&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;1ac48011-3d5a-40e7-8c50-8c1736fb0fbe&#34;,&#34;dropCap&#34;:false}&#34;&gt;展望未来，我们对 GenAI 网关的愿景是提升和完善其功能，以更好地为我们的用户服务。重点是加强新模型的入职流程。无论这些模型是根据特定需求定制的、经过微调的模型，还是来自充满活力的开源社区的模型，我们的目标都是使它们的集成尽可能流畅且用户友好。此外，我们热衷于通过高级功能来增强网关，以解决使用大型语言模型的动态挑战。这包括实施智能 LLM 缓存机制、开发强大的后备逻辑以及引入复杂的幻觉检测。安全和政策护栏也已列入我们的议程，以确保我们的平台保持安全并符合不断发展的标准。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;c896442c-5abb-420b-85b5-898882f48a1e&#34;,&#34;dropCap&#34;:false}&#34;&gt;在我们的旅程中为了扩展网关的功能，我们还认识到挖掘开源生态系统巨大潜力的重要性。为此，我们正在积极努力与图书馆整合。这不仅会增强我们系统的功能广度，而且会使其更加通用，使我们的用户能够探索和利用更广泛的解决方案。这些未来的努力强调了我们对不断发展 GenAI Gateway 的承诺，确保它仍然是一个利用法学硕士力量的尖端、多功能和安全的平台。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;62803538-f24d-48ec-971e-28ba28c745cc&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:1,&#34;hash&#34;:&#34;c312f523-db66-494c-9407-311cee6c8b60&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-conclusion&#34;&gt;&lt;strong&gt;结论&lt;/strong&gt;&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;ad1f31f3-01c4-475c-b839-51e7dd25b3cf&#34;,&#34;dropCap&#34;:false}&#34;&gt;LLM 已成为一种变革的力量。然而，法学硕士在 Uber 的整合并非没有挑战。不一致的集成策略和缺乏标准化方法导致监控成本和供应商使用情况效率低下和困难。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;8def3e9e-3285-449e-9694-e7fcfe114573&#34;,&#34;dropCap&#34;:false}&#34;&gt;解决这些问题Uber 的 Michelangelo 团队开发了 GenAI Gateway，这是一个统一平台，方便从多个提供商（包括 OpenAI 和 Vertex AI）以及 Uber 的内部模型访问 LLM。该平台简化了集成流程，确保遵守隐私和安全标准以及高效的使用管理。 GenAI Gateway 的设计反映了 OpenAI API，确保与现有工具的兼容性，并与不断发展的开源社区保持同步。它还具有 PII 编辑器，增强了安全性。 GenAI Gateway 的这一战略发展，加上其对运营效率的关注以及与 Uber 更广泛的技术框架的一致性，体现了 Uber 对创新的承诺，同时解决与法学硕士合作的动态挑战。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;d24118d6-acbf-4d50-959b-5337150cda8c&#34;,&#34;level&#34;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-acknowledgments&#34;&gt;&lt;strong&gt;致谢&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;ae51ea31-0c43-4ce0-9617-47822269b6e2&#34;,&#34;dropCap&#34;:false}&#34;&gt;我们不能在没有各个工程团队、Uber AI 和 Uber Customer Obsession 团队的帮助下，我们完成了本文中概述的技术工作。我们还要感谢与我们合作采用 Gen AI Gateway 的各个产品团队。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;fontSize&#34;:&#34;小&#34;,&#34;hash&#34;:&#34;afc6017c-684e-44ac-abcc-678a2031b044&#34;,&#34;dropCap&#34; :false}&#34; class=&#34;has-small-font-size&#34;&gt;封面照片归属：“&lt;strong&gt;人工智能，AI&lt;/strong&gt;”图像被&lt;a href=&#34;https://creativecommons. org/licenses/by/2.0/&#34;&gt;CC BY 2.0&lt;/a&gt; 许可证，并记入 &lt;a href=&#34;https://www.flickr.com/photos/152824664@N07&#34;&gt;mikemacmarketing&lt;/a&gt;。未对图像进行任何更改（&lt;a href=&#34;https://openverse.org/image/49410795-b3ba-421b-918b-7f2cd9178f19?q=artificial%20intelligence&#34;&gt;来源&lt;/a&gt;）。&lt;/a&gt; p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;fontSize&#34;:&#34;小&#34;,&#34;hash&#34;:&#34;f526d83b-eb4f-49c3-9e7f-661ae12bcd4b&#34;,&#34;dropCap&#34; :false}&#34; class=&#34;has-small-font-size&#34;&gt;Vertex AI™、PaLM™、Google Dialogflow™ 和 Go™ 是 Google LLC 的商标，本博文未获得 Google 的认可或以任何方式与 Google 存在关联。 &lt;/p&gt;</description>
      <pubDate>Thu, 11 Jul 2024 06:58:53 +0000</pubDate>
    </item>
    <item>
      <title>【Debugging with Production Neighbors – Powered by SLATE】与生产邻居一起调试 – 由 SLATE 提供支持</title>
      <link>https://www.uber.com/blog/debugging-with-production-neighbors/</link>
      <description>【&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;0277d5f7-0165-458e-a200-4057ec5939da&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-introduction&#34;&gt;Introduction&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d4256add-d86f-4f3f-825b-cbe635b737f3&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Software development is an iterative and staged process that needs validation and testing at function, component, and service levels. In the case of microservice-based architecture, it becomes far more important to develop in conjunction with dependent services. Microservice-based architecture provides distinct advantages that allow us to scale, maintain, and abstract responsibilities. The more abstraction, the easier it is for us to develop and define business logic.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9890ecf7-7a4e-43cb-a0ad-e736e521cba4&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;a href=&#34;https://www.uber.com/blog/simplifying-developer-testing-through-slate/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;SLATE&lt;/a&gt; is an E2E testing tool that bridges the gap by allowing services under test to be deployed and work along with production upstream and downstream services. This allows developers to generate test requests mirroring production call flow yet target services under test. Such functionality facilitates various use cases, including feature development within a production environment or replicating production bugs, which often entail troubleshooting both code and configuration. To aid or simplify the process of troubleshooting and make it nearer to the local experience we have developed features to enable debugging of services deployed in the SLATE environment.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;41d5de27-f980-4ed2-bd72-2950ff5f81ef&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In this blog we’ll explore different debugging options developed on SLATE that emulates the behavior of services under test with production upstream and downstream.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2cf8d798-d6c4-48b5-87be-02e7d6a16823&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Let us check the following three high-level options developed in detail:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;ordered&amp;quot;:true,&amp;quot;hash&amp;quot;:&amp;quot;12e47251-1926-462c-a4f0-3c9230f71035&amp;quot;,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Remote debugging a SLATE deployed instance&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Local Debugging in laptop/dev pod machine&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Debug issues by filtered monitoring&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;00a68086-a170-4640-a605-3b4d6bc61291&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f06b920f-d468-4d51-8c1b-347777a1ca08&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-debugging-until-now&#34;&gt;Debugging Until Now&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;87ca5e62-f730-45a5-8e9f-0d704ebdd0fa&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-debug-via-logs&#34;&gt;Debug via Logs&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4efff6dc-9fd1-4694-a31d-3e921bfdc295&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Debugging using logs is a fundamental practice that provides insights into a program’s execution. Logs enables developers to identify issues. However, inefficient logging can clutter the system with irrelevant information, leading to complicating rather than aiding the debugging process.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;599a8a54-9b98-46f2-95f4-5585f0ab7862&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-debug-via-staging&#34;&gt;Debug via Staging&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b39d20b2-4b5e-4644-b2ce-1e8ac406d13e&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Staging environment is developer controlled environment that mirrors the production setup.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;627706a3-02f5-4a44-811e-293c575ddeda&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;While staging environments are very beneficial, they may still differ from the live environment and provide false confidence with a longer turnaround time.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;b929c6e0-b520-4df1-90d9-74d0103175a0&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-debug-locally&#34;&gt;Debug Locally&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3e41d70e-4563-47d2-bcf2-6b877aa943cf&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Local debugging is essential for faster iteration to test service in isolation. However, debugging user scenarios can be challenging due to constraints in simultaneously debugging multiple services together.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7914ae72-a666-449c-ad31-f41539c33705&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;fc0ea531-43db-40bf-90d1-d317a803e196&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-remote-debugging-of-slate-instance&#34;&gt;Remote Debugging of SLATE Instance&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;27942760-eff9-41b9-bd96-9e3c144c1258&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Testing and debugging on SLATE relies on logs from the service being tested. Depending solely on logs for understanding complex processes isn’t practical. Additionally, adding new logs requires a new deployment, causing delays. Remote debugging can address these issues by letting developers step through statements and monitor variables, eliminating the need for commit and deployment iterations. Co-working with production infra, needs to balance security and developer experience.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1d9e79e3-9f82-4e8e-ac72-c867fd34a9da&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;This brings a need to enhance visibility into the code for runtime debugging, achieved through breakpoints, step-ins, or dynamic tracepoints. Remote debugging is limited to SLATE instances handling test requests to ensure production security.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;63b7af5d-5044-4ba8-91a4-2545b9afb999&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-high-level-goals&#34;&gt;High-level Goals&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ff345dd1-5e7e-46aa-93ba-9f2817dda43a&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Deploy a debuggable binary/code on a SLATE container&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Ability to add breakpoints and tracepoints to a service under test&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Ability to see values of different params on control hitting a breakpoint&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Create a seamless developer experience similar to remote debugging&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Design solutions to be compliant with security and privacy issues&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;ec951a18-fc82-418d-a4e4-3bc2e589ce07&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-design&#34;&gt;Design&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;13353fa3-de1c-4257-b72f-812657c19ed2&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;SLATE leverages the production infrastructure to generate containers, compile code, and execute services. However, modifications were required to the build and deployment infrastructure to facilitate debugging functionalities for services deployed on SLATE. This involved three significant enhancements. Firstly, enabling the generation of builds with integrated debugging tools and functionalities. Secondly, configuring software execution with remote debugging options. Thirdly, facilitating developer access to remote containers by allocating and exposing ports from said containers.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;0c2c17ea-868c-477f-a313-a4ca6375f5bb&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-debuggable-deployment&#34;&gt;Debuggable Deployment&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7f392d92-e347-44f8-9ca7-57adcbd6690b&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The current deployment pipeline is not flexible to support different options to generate both debuggable and production binaries. To be able to generate and deploy debuggable binary, multiple components of the pipeline should realize the type of binary and configure their features accordingly. This diagram indicates the components that would be involved during the feature development.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;22d95a33-f3a7-4c79-8a5d-f55dd55f4970&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090425,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;c1906e48-3b10-4623-b90f-4e766ba96054&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;285&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig2-1024x285.jpeg&#34; alt=&#34;&#34; class=&#34;wp-image-1090425&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig2.jpeg 1024w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig2.jpeg 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig2.jpeg 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1351,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig2.jpeg 1351w&#34; sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Fig 1: Modifications to the deployment pipeline to support debugging for SLATE.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;676b8b24-a254-49fe-8cda-95cfbff522a2&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;f6c802a6-f496-4294-bdee-b03c2e87bd28&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-allocating-ports&#34;&gt;Allocating Ports&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9079639d-492b-449c-8b76-306a451ba65b&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The SLATE Container gets created alongside the production host. To be able to connect to the debugger, we have to expose a new debug port, similar to a gRPC/HTTP port. Currently UP is responsible for allocating random ports and mapping the same to the host port. The exposure of the new port will be opened only for debuggable SLATE deployments and SLATE implicitly handles the test requests by design. This new port exposure needs a security review. The below diagram indicates the high-level interactions.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4ef1347e-9498-4398-84b9-482c926dc6a3&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b1b7007c-b1a8-4303-81c6-8baa95bbe208&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXfNB42pjNG_DCuxWPz9gEvHHrE9XBFFcsEvj1tsaIr7Hn2pTk6nl3ghqed81UCUzrhbtFUaWYoageTGPGBuZJXXTNq_Zx8lT-RoppYjT3hjsjxuViujT4oCun8CeDLuQqzNyIV2C8GjgTr6m1Hs73MActat?key=Ermx74NMIF5DAzxh8Wqoiw&#34; width=&#34;695.85121602289&#34; height=&#34;173.47872782612586&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090426,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;ef9e19b7-cc21-400f-a606-24c9066846b6&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;283&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig1-1024x283.jpeg&#34; alt=&#34;&#34; class=&#34;wp-image-1090426&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig1.jpeg 1024w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig1.jpeg 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig1.jpeg 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1080,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig1.jpeg 1080w, https://blog.uber-cdn.com/cdn-cgi/image/width=1087,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig1.jpeg 1087w&#34; sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Fig 2: Allocation and safely exposing debug ports.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;52c17921-426e-4cc2-bb49-84bb33b65068&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;1802af6b-beea-4b6a-9356-56770a6674e4&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-reaching-debuggable-service&#34;&gt;Reaching Debuggable Service&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d71b7b8d-1510-4c8a-aa45-1748e2bfa1d5&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;To improve the security and avoid malicious access, SLATE debugging needs to be access controlled. This would ensure that only the service owners would be able to connect the debugger. The diagram below indicates the access control that would limit access to only the LDAP users of the service.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f59e6d1b-ce89-46e1-a38a-e2ead87bf3d8&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090429,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;34c12c23-cdd9-453c-80ab-a1796c3cc5b6&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;357&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig3-1-1024x357.jpeg&#34; alt=&#34;&#34; class=&#34;wp-image-1090429&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig3-1.jpeg 1024w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig3-1.jpeg 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig3-1.jpeg 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1060,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig3-1.jpeg 1060w&#34; sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Fig 3: Password-based SSH tunneling to the remote host from the developer machines.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7f039f2a-0cfd-4404-b346-78190cf63b4c&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:4,&amp;quot;hash&amp;quot;:&amp;quot;76babcaa-cab0-4480-8507-b5b34963fcda&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-debugger-execution&#34;&gt;Debugger Execution&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;806a7025-1ec1-4126-982f-3bf7c83531b8&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;The debugger runs the application within a dedicated debugging server&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;The process blocks, awaiting attachment by the debugger client&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;The debugger process listens on a specific TCP/IP network port, referred to as a debug port&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:4,&amp;quot;hash&amp;quot;:&amp;quot;0e325adf-9b00-4e6b-b655-c8c1d1273cb7&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-controlling-program-execution&#34;&gt;Controlling Program Execution&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;bde0ef70-cfa0-47d4-8415-a94df60c277c&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Debugging clients (e.g., VSCode, GoLand, JetBrains) connect via the debug port. Clients issue commands for various debugging tasks like setting breakpoints, displaying local variables and function arguments, printing CPU register contents, etc.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:4,&amp;quot;hash&amp;quot;:&amp;quot;4e33b23b-99e7-47fb-965c-a4ad0c16148a&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-remote-debugging-with-debug-port&#34;&gt;Remote Debugging with Debug Port&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;bba71797-e7ac-45b7-9821-593be4f452a0&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Remote debugging enables debugging on diverse environments, configurations, or architectures. Useful for troubleshooting specific scenarios or hardware/software related issues that cannot be replicated locally.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6c156180-0c50-4e3a-a8a6-f528ffcecde0&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9cb16568-df09-423a-9620-06a015eec13f&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-access-control&#34;&gt;Access Control&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;4c8ec086-34cc-43f6-9859-7bb6234c0e8c&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-restricting-for-ldap-users&#34;&gt;Restricting for LDAP Users&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a273ae87-4c85-419a-817f-0039525eceef&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;During debugging sessions, users attach the debugger to the application to intervene in program execution and gather debug information. This would also mean trying to identify and resolve bugs in the program. This means to get access to some sensitive service information if allowed for every user. So restricting to LDAP users (service developers/owners) is important to ensure minimum security.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;599ec47d-a7c4-42dd-a781-b925786dc85f&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-secure-ssh-connection&#34;&gt;Secure SSH Connection&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;38427b55-698d-4f88-88a4-78f359534d9f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;For remote debugging, a secure SSH connection is established between local and remote systems. This will allow for local port forwarding and redirects debug requests through an SSH tunnel. This tunnel would ensure encrypted communication and secure data transmission.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;bb70ee8d-23cc-4787-be91-df79467c43d5&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-ssh-authorization&#34;&gt;SSH Authorization&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d20f9558-dc9c-4679-88b3-f14a328f9b18&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;To begin an SSH connection, users need the correct password linked to the “slatedev” account. This password is a randomly generated 16-digit code in the file within the service container. The password is generated during the container’s startup before the main service application runs. This Password is accessible only to the container access group, which is service owner LDAP. LDAP users can access the password through Compute CLI, enabling them to establish SSH connections and perform debugging tasks. Compute CLI ensures restricted access to Non-LDAP users, which doesn’t allow password access.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d2dcd9cb-9e60-4927-9709-437e6f52778a&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e4f7db46-498e-45ce-9a76-67083c5cd789&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-limitations&#34;&gt;Limitations&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3128df24-147b-4c41-8b29-e565ced347e4&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Remote debugging on production infra has limitations about dynamic modifications, so it’s limited to read-only&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Large iteration time, as each change involves build, deploy, and test&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9f25985c-b82e-493a-b23b-da0ee9452de6&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;877f5b6c-03ed-4e6d-b459-307eed84a616&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-local-debugging-using-slate-attach&#34;&gt;Local Debugging using SLATE Attach&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0b458a84-2d3d-45bc-8464-f0d2bed998fd&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Remote Debugging allows for read-only debugging on production infrastructure. Being in production infra allows for seamless connections with upstream and downstream services/tools. For a developer it’s very important to experience a debuggable environment with faster iteration to fix and test the same. This gap can be filled by creating a local debugging experience in connection with production upstream and downstream services. SLATE Attach fills this gap and allows for rapid development on attaching local environments.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;26b16577-aec0-4ede-b886-8e3dca0e20a7&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-high-level-goals-0&#34;&gt;High-level Goals&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;fab90a26-f7ff-4ba3-82c2-50b17f1338fa&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The main goal is to reduce the code-deploy-test cycle (and hence, the time to validate iterative changes), by providing E2E testing with local development instances (laptop or dev machine), ensuring production isolation and safety.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;2c391ff7-243f-46bf-a671-3db9d374c1b9&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-iteration-cycle&#34;&gt;Iteration Cycle&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8becb5e9-ce3d-486a-83eb-7d6a7c54f055&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The iteration cycle in this context is the time between making the code change and validating them. The smaller the iteration cycle, the more efficient the use of developers’ time for end-to-end validation of subsequent changes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8e50f42c-6c02-4846-8e0b-52e2012bda37&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090430,&amp;quot;sizeSlug&amp;quot;:&amp;quot;full&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;794ef73a-e926-428b-97fe-b11a0f4ed15e&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;820&#34; height=&#34;221&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig4.jpeg&#34; alt=&#34;&#34; class=&#34;wp-image-1090430&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=820,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig4.jpeg 820w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig4.jpeg 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig4.jpeg 768w&#34; sizes=&#34;(max-width: 820px) 100vw, 820px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Fig 4: Iteration steps for development using SLATE.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c7f6664e-80ae-48c8-8431-59dac8c806ee&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;5ed47996-ad37-4c32-921b-1d59850ed524&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-need-for-slate-attach&#34;&gt;Need for SLATE Attach&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5e842c0b-9224-423e-87d0-5b0498fefe01&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Iterative development generates a build binary at a faster pace&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Reduced code-deploy-test cycle&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Faster identification and resolution of local, E2E failures&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Faster setup time&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Avoid the need for service changes or onboarding&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ebecbddf-739b-4bf3-8027-63cc10028542&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2feec9ce-de38-4282-bd46-8f8ed6b46b64&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-design-0&#34;&gt;Design&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c0f6f7d6-1ae8-4a46-a3a9-2e6e569f3bfc&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;This design aims to introduce a SLATE proxy that handles all the test requests aimed at SLATE instances for local debugging. These requests will then be redirected to the appropriate local developer machine for debugging and development. This allows users to iterate faster and improve developers’ productivity.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ad3a7aa8-a42a-49e2-a3f7-0ec4812f3deb&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;This feature could be enabled mainly in 2 contexts in SLATE environment lifecycle:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;ordered&amp;quot;:true,&amp;quot;hash&amp;quot;:&amp;quot;d122ed7f-f7b0-49b6-9be0-cedaae60ec26&amp;quot;,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;SLATE Control plane&lt;/strong&gt; that maps local laptop/devpod to a slate environment&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;Test Request Data plane&lt;/strong&gt; that redirects the requests to developers’ laptops&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;879353b5-bf5f-4dbd-a4b6-a90907c4a437&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;fc0e575f-51cb-45c2-8ea1-2b00b9bd027c&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-control-plane&#34;&gt;Control Plane&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0a982fcd-aefc-447e-9ac7-9a83e9877ae9&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The main feature of the control plane is to enable services running in local laptops or devpods to attach to a SLATE environment. The local laptop/devpod that intends to run the service has to attach local environment credentials to a SLATE environment so that test requests are routed locally. The prerequisite for this attachment is to create a SLATE environment. This will allow mapping updates in routing control DB and local routing DB.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9f9c73ee-1938-4f29-8e82-827493504e86&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090431,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;a7fc2c6a-5999-43b2-b636-04ec980e468e&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;560&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig5-1024x560.jpg&#34; alt=&#34;&#34; class=&#34;wp-image-1090431&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig5.jpg 1024w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig5.jpg 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig5.jpg 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1036,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig5.jpg 1036w&#34; sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Fig 5: Request Call flow for testing code running on developer machines&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0fc0d21b-6a51-4ba0-912f-e4a1ece3b94a&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:4,&amp;quot;hash&amp;quot;:&amp;quot;68ef7376-005b-4c34-8ca9-8d91c2071b73&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-call-flow&#34;&gt;Call flow&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;ordered&amp;quot;:true,&amp;quot;hash&amp;quot;:&amp;quot;4d4c2d52-cb99-49a9-a1dc-22f53a3c5c2a&amp;quot;,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;User initiates SLATE attach from local laptop/devpod&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;The SLATE CLI calls Attach() API of SLATE Backend&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;SLATE Backend fetches the Proxy information (host:port) from SLATE Proxy&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;SLATE Backend updates the routing override in routing control DB using the fetched proxy info&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;User initiates the SSH Session using the Cerberus CLI&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Cerberus gateway adds the mapping of deputized tenancy/UUID to the laptop credentials in Flipr DB and creates a SSH session for the laptop&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:4,&amp;quot;hash&amp;quot;:&amp;quot;33cbd3ba-84e6-4fb7-b51f-c32368b85ec3&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-routing-control-db&#34;&gt;Routing Control DB&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3091a315-341a-4ac2-8c3d-aa18ad2dfa66&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Routing Control DB maps test tenancy to routing overrides and user account UUIDs to test tenancy. It stores the SLATE Proxy host:port against the service under test and ensures that all requests targeting a particular SLATE environment, reaches SLATE Proxy. SLATE Proxy finally routes the request to the development instance running in the user’s machine.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:4,&amp;quot;hash&amp;quot;:&amp;quot;1af3bcce-3d51-4a3b-af45-fd2f0aa37403&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-local-routing-db&#34;&gt;Local Routing DB&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;fa9af186-07d9-4578-9ab9-6352df586e83&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Local routing DB contains the development instance’s credentials that have been attached to the SLATE environment. SLATE Proxy interacts with the local routing DB to fetch routing credentials and finally routes the request to service-under-test running in local environment&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ae9e74db-9b41-4a46-ba9d-d600c0350856&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;714ae8c2-f980-4c03-9133-3981f34c4945&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-data-plane&#34;&gt;Data Plane&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3c12e2f9-9a26-4969-a929-e66e5b9a207d&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;This section mainly talks about the flow of test requests from different clients (mobile, studio, web, etc.). This data plane mainly involves 2 entities: routing override header and host tenancy mapping. The below diagram indicates how different test requests reach a local laptop through the SLATE proxy. The control plane ensures routing override and host mapping maintained in different databases.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0cc4187b-d85a-4b70-be55-c158994fefdb&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090432,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;5b649275-8ac1-4340-b0e8-a19be825d309&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;520&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig6-1024x520.jpeg&#34; alt=&#34;&#34; class=&#34;wp-image-1090432&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig6.jpeg 1024w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig6.jpeg 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig6.jpeg 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig6.jpeg 1300w&#34; sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Fig 6: Proxy setup for routing test requests to developer machines.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d0682e8a-4e5e-4860-bf0a-27125c9e134a&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d5a8b75c-9546-48e7-aeab-107b253f5169&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Above is the test request flow targeted for local laptop with production upstreams and downstreams:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;ordered&amp;quot;:true,&amp;quot;hash&amp;quot;:&amp;quot;4ea9f2b6-a6c3-452e-9629-1505324f32c8&amp;quot;,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Test account request originates from mobile client&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;E2E test proxy retrieves routing override and injects the routing header to the test request&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;The test request propagates through production services via Mutley until the request has service 3 target&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;The request redirects to SLATE proxy as the routing override has slate proxy host:port against service 3&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;SLATE proxy forwards the request to an open port on Cerberus-gateway based on a host:port config in the Cerberus-deputy Flipr namespace, set by the user when running the Cerberus CLI&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;The Cerberus-gateway forwards the request to the user’s local development machine for the user to debug&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;From the local laptop, the request will be finally forwarded to production downstreams through Cerberus&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;c1062a3f-701f-40f2-8416-7ccd43c088cb&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-limitations-0&#34;&gt;Limitations&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7d9da5c3-f6e2-4fb8-b038-71dbe8495dad&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Running a service locally may not be feasible for some complex services, as they need support for some dependencies like spanners that can only exist in production infra&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;This is limited to test requests as it enables dynamic changing of requests and in turn secures production traffic&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Requests timeout on longer wait for a debug request in local&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f205b844-fe96-41cf-a695-c12f79b9e330&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;86cb82b0-8d3f-4afe-b4a8-e46ab6edf12d&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-impact&#34;&gt;Impact&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4af528af-4339-4de0-b65a-ba6a68054d0e&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Plug-and-play development environment to improve developer productivity&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Ability to create local experiences that co-work with production for developers&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Increase Developer Velocity: Production debugging can help developers identify and fix issues more efficiently&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;db759f9c-b972-4bf3-85c6-106704f28b6c&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090433,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;f769cc84-59fb-4db5-b270-85f9cc38bc6c&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;280&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig7-1024x280.jpeg&#34; alt=&#34;&#34; class=&#34;wp-image-1090433&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig7.jpeg 1024w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig7.jpeg 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig7.jpeg 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1536,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig7.jpeg 1536w, https://blog.uber-cdn.com/cdn-cgi/image/width=1680,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig7.jpeg 1680w&#34; sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Fig 7. Impact figures for improving developer velocity using SLATE attach feature.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;92748031-56ec-41fe-af5f-e28c13872b72&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;089b91b9-e785-426b-9acc-98c513dbecb7&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-what-s-next&#34;&gt;What’s Next&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0fab3aae-e3c1-4f43-b6cd-31314da60b97&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;SLATE Sniffer to debug issues by monitoring&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;25ad3857-16be-4803-b58a-19203bd4ff77&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The remote and local debugging mainly allow for test requests to debug. There is a need for observability on production, beyond logs that come up in uMonitor Tool. We aim to create this observability precisely and on-demand using SLATE Sniffer.&amp;nbsp; The main goals of SLATE Sniffer include:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9512a824-5d47-4526-b7b9-a3da8258f058&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Capture the request and responses as a filter of a service and UUID&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Ability to support and filter on Production and Test requests&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f11a73c1-4e1a-40b2-96a4-987bfccd4683&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;a623f4dc-0808-4f1f-a5c6-a75a520f8f0e&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-conclusion&#34;&gt;Conclusion&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c06ce4bc-9946-41bd-95b1-37c27416e5ee&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Our objective is to enhance the SLATE platform, positioning it as the primary tool for debugging production issues. The debugging features integrated into SLATE strike a balance between security and developers’ requirements. SLATE has introduced a new paradigm for developers’ code-related activities and service bootstrapping. We are looking forward to collaborating with different teams to shift the quality left and create visibility on potential issues at the early stage of development.&lt;/p&gt;】&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:1,&#34;hash&#34;:&#34;0277d5f7-0165-458e-a200-4057ec5939da&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-introduction&#34;&gt;简介&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;d4256add-d86f-4f3f-825b-cbe635b737f3&#34;,&#34;dropCap&#34;:false}&#34;&gt;软件开发是需要在功能、组件和服务级别进行验证和测试的迭代和分阶段过程。在基于微服务的架构中，与依赖服务结合开发变得更加重要。基于微服务的架构提供了独特的优势，使我们能够扩展、维护和抽象职责。越抽象，我们就越容易开发和定义业务逻辑。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;9890ecf7-7a4e-43cb-a0ad-e736e521cba4&#34;,&#34;dropCap&#34;:false}&#34;&gt;&lt;a href =&#34;https://www.uber.com/blog/simplifying-developer-testing-through-slate/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;SLATE&lt;/a&gt; 是一个 E2E 测试工具，可以桥接通过允许部署测试中的服务并与生产上游和下游服务一起工作来弥补差距。这允许开发人员生成镜像生产调用流程的测试请求，但目标是测试中的服务。此类功能有助于各种用例，包括生产环境中的功能开发或复制生产错误，这通常需要对代码和配置进行故障排除。为了帮助或简化故障排除过程并使其更接近本地体验，我们开发了一些功能来支持对 SLATE 环境中部署的服务进行调试。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;41d5de27-f980-4ed2-bd72-2950ff5f81ef&#34;,&#34;dropCap&#34;:false}&#34;&gt;在此博客中我们将探索在 SLATE 上开发的不同调试选项，这些选项可模拟上游和下游生产环境中测试的服务的行为。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;2cf8d798-d6c4-48b5-87be-02e7d6a16823&#34;,&#34;dropCap&#34;:false}&#34;&gt;让我们检查一下详细制定了​​以下三个高级选项：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;ordered&#34;:true,&#34;hash&#34;:&#34;12e47251-1926-462c-a4f0-3c9230f71035&#34;,&#34;values&#34;:&#34; “}”&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;远程调试 SLATE 部署的实例&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;笔记本电脑/开发 Pod 机器中的本地调试&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;通过过滤监控调试问题&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;00a68086-a170-4640-a605-3b4d6bc61291&#34;,&#34;不透明度&amp;quot;:&#34;alpha-channel&#34;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;f06b920f-d468-4d51-8c1b-347777a1ca08&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-debugging-until-now&#34;&gt;调试到现在&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;87ca5e62-f730-45a5-8e9f-0d704ebdd0fa&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-debug-via-logs&#34;&gt;通过日志调试&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;4efff6dc-9fd1-4694-a31d-3e921bfdc295&#34;,&#34;dropCap&#34;:false}&#34;&gt;使用日志进行调试是一种基本实践，可以深入了解程序的执行情况。日志使开发人员能够识别问题。然而，低效的日志记录可能会用不相关的信息使系统变得混乱，从而导致调试过程变得复杂，而不是帮助调试过程。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;599a8a54-9b98-46f2-95f4-5585f0ab7862&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-debug-via-staging&#34;&gt;通过暂存进行调试&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;b39d20b2-4b5e-4644-b2ce-1e8ac406d13e&#34;,&#34;dropCap&#34;:false}&#34;&gt;暂存环境为开发人员控制的环境反映了生产设置。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;627706a3-02f5-4a44-811e-293c575ddeda&#34;,&#34;dropCap&#34;:false}&#34;&gt;暂存环境时非常有益，但它们可能仍然与现场环境不同，并提供错误的信心和更长的周转时间。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;b929c6e0-b520-4df1-90d9-74d0103175a0&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-debug-locally&#34;&gt;本地调试&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;3e41d70e-4563-47d2-bcf2-6b877aa943cf&#34;,&#34;dropCap&#34;:false}&#34;&gt;本地调试为对于更快地迭代以隔离测试服务至关重要。然而，由于同时调试多个服务的限制，调试用户场景可能具有挑战性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;7914ae72-a666-449c-ad31-f41539c33705&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;fc0ea531-43db-40bf-90d1-d317a803e196&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-remote-debugging-of-slate-instance&#34;&gt;SLATE 实例远程调试&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;27942760-eff9-41b9-bd96-9e3c144c1258&#34;,&#34;dropCap&#34;:false}&#34;&gt;测试和调试在 SLATE 上依赖于 lo来自正在测试的服务的 gs。仅仅依靠日志来理解复杂的流程是不切实际的。此外，添加新日志需要新的部署，从而导致延迟。远程调试可以通过让开发人员逐步执行语句并监视变量来解决这些问题，从而消除提交和部署迭代的需要。与生产基础设施协作，需要平衡安全性和开发人员体验。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;1d9e79e3-9f82-4e8e-ac72-c867fd34a9da&#34;,&#34;dropCap&#34;:false}&#34;&gt;这会带来需要增强代码的可见性以进行运行时调试，这可以通过断点、单步执行或动态跟踪点来实现。远程调试仅限于处理测试请求的 SLATE 实例，以确保生产安全。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;63b7af5d-5044-4ba8-91a4-2545b9afb999&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-high-level-goals&#34;&gt;高级目标&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;ff345dd1-5e7e-46aa-93ba-9f2817dda43a&#34;,&#34;ordered&#34;:false,&#34;values&#34;:&#34; “}”&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;在 SLATE 容器上部署可调试的二进制文件/代码&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;能够向测试中的服务添加断点和跟踪点&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;能够在遇到断点的控件上查看不同参数的值&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;打造类似于远程调试的无缝开发者体验&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;设计符合安全和隐私问题的解决方案&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;ec951a18-fc82-418d-a4e4-3bc2e589ce07&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-design&#34;&gt;设计&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;13353fa3-de1c-4257-b72f-812657c19ed2&#34;,&#34;dropCap&#34;:false}&#34;&gt;SLATE 利用用于生成容器、编译代码和执行服务的生产基础设施。然而，需要对构建和部署基础设施进行修改，以便于调试部署在 SLATE 上的服务的功能。这涉及三项重大改进。首先，使用集成的调试工具和功能来生成构建。其次，使用远程调试选项配置软件执行。第三，通过分配和公开远程容器的端口，方便开发人员访问远程容器。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;0c2c17ea-868c-477f-a313-a4ca6375f5bb&#34;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-debuggable-deployment&#34;&gt;可调试部署&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;7f392d92-e347-44f8-9ca7-57adcbd6690b&#34;,&#34;dropCap&#34;:false}&#34;&gt;当前部署管道不灵活，无法支持生成可调试和生产二进制文件的不同选项。为了能够生成和部署可调试的二进制文件，管道的多个组件应该实现二进制文件的类型并相应地配置其功能。该图指示了功能开发期间将涉及的组件。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;22d95a33-f3a7-4c79-8a5d-f55dd55f4970&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;id&#34;:1090425,&#34;sizeSlug&#34;:&#34;large&#34;,&#34;linkDestination&#34;:&#34;none&#34;,&#34;align&#34;:&#34;中心”，“散列”：“c1906e48-3b10-4623-b90f-4e766ba96054”，“alt”：“”}“class =“aligncenter size-large”&gt;&lt;img加载=“惰性”解码=“异步”宽度= “1024”高度=“285”src=“https://blog.uber-cdn.com/cdn-cgi/image/width=2160，质量= 80，onerror=重定向，format=auto/wp-content/uploads /2024/06/Fig2-1024x285.jpeg&#34; alt=&#34;&#34; class=&#34;wp-image-1090425&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality =80，onerror=重定向，格式=auto/wp-content/uploads/2024/06/Fig2.jpeg 1024w，https://blog.uber-cdn.com/cdn-cgi/image/width=300，质量= 80，onerror=重定向，format=auto/wp-content/uploads/2024/06/Fig2.jpeg 300w，https://blog.uber-cdn.com/cdn-cgi/image/width=768，quality=80 ,onerror=重定向,format=auto/wp-content/uploads/2024/06/Fig2.jpeg 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1351,quality=80, onerror=重定向，格式=自动/wp-content/uploads/2024/06/Fig2.jpeg 1351w&#34; 尺寸=&#34;(最大宽度：1024px) 100vw，1024px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34; wp-element-caption&#34;&gt;图 1：修改部署管道以支持 SLATE 调试。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;676b8b24-a254-49fe-8cda-95cfbff522a2&#34;,&#34;opacity&#34;:&#34;alpha 通道&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;f6c802a6-f496-4294-bdee-b03c2e87bd28&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-allocing-ports&#34;&gt;分配端口&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;9079639d-492b-449c-8b76-306a451ba65b&#34;,&#34;dropCap&#34;:false}&#34;&gt;SLATE 容器与生产主机一起创建。为了能够连接到调试器，我们必须公开一个新的调试端口，类似于 gRPC/HTTP 端口。目前 UP 负责或者分配随机端口并将其映射到主机端口。新端口的公开将仅针对可调试的 SLATE 部署开放，并且 SLATE 按设计隐式处理​​测试请求。这个新端口暴露需要进行安全审查。下图显示了高层交互。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;4ef1347e-9498-4398-84b9-482c926dc6a3&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;b1b7007c-b1a8-4303-81c6-8baa95bbe208&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-&#34;&gt;&lt;img 解码=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXfNB42pjNG_DCuxWPz9gEvHHrE9XBFFcsEvj1tsaIr7Hn2pTk6nl3ghqed81UCUzrhbtFUaWYoageTGPGBuZJXXTNq_Zx8l T-RoppYjT3hjsjxuViujT4oCun8CeDLuQqzNyIV2C8GjgTr6m1Hs73MActat?key=Ermx74NMIF5DAzxh8Wqoiw&#34; 宽度 = &#34;695.85121602289&#34; 高度=&#34;173.47872782612586&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;id&#34;:1090426,&#34;sizeSlug&#34;:&#34;large&#34;,&#34;linkDestination&#34;:&#34;none&#34;,&#34;align&#34;:&#34;中心”，“散列”：“ef9e19b7-cc21-400f-a606-24c9066846b6”，“alt”：“”}“类=“aligncenter size-large”&gt; &lt;img加载=“惰性”解码=“异步”宽度= “1024”高度=“283”src=“https://blog.uber-cdn.com/cdn-cgi/image/width=2160，质量= 80，onerror=重定向，format=auto/wp-content/uploads /2024/06/Fig1-1024x283.jpeg&#34; alt=&#34;&#34; class=&#34;wp-image-1090426&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality =80，onerror=重定向，格式=auto/wp-content/uploads/2024/06/Fig1.jpeg 1024w，https://blog.uber-cdn.com/cdn-cgi/image/width=300，质量= 80，onerror=重定向，格式=auto/wp-content/uploads/2024/06/Fig1.jpeg 300w，https://blog.uber-cdn.com/cdn-cgi/image/width=768，质量=80 ，onerror=重定向，格式=auto/wp-content/uploads/2024/06/Fig1.jpeg 768w，https://blog.uber-cdn.com/cdn-cgi/image/width=1080，质量=80， onerror=重定向，format=auto/wp-content/uploads/2024/06/Fig1.jpeg 1080w，https://blog.uber-cdn.com/cdn-cgi/image/width=1087，quality=80，onerror =重定向，格式=自动/wp-content/uploads/2024/06/Fig1.jpeg 1087w”尺寸=“（最大宽度：1024px）100vw，1024px”referrerpolicy=“no-referrer”&gt;&lt;figcaption class=“wp” -element-caption&#34;&gt;图 2：分配和安全公开调试端口。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;52c17921-426e-4cc2-bb49-84bb33b65068&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;1802af6b-beea-4b6a-9356-56770a6674e4&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-reaching-debuggable-service&#34;&gt;到达可调试服务&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;pdata-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;d71b7b8d-1510-4c8a-aa45-1748e2bfa1d5&#34;,&#34;dropCap&#34;:false}&#34;&gt;为了提高安全性和避免恶意访问，SLATE调试需要进行访问控制。这将确保只有服务所有者才能连接调试器。下图显示了将访问权限限制为仅服务的 LDAP 用户的访问控制。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;f59e6d1b-ce89-46e1-a38a-e2ead87bf3d8&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;id&#34;:1090429,&#34;sizeSlug&#34;:&#34;large&#34;,&#34;linkDestination&#34;:&#34;none&#34;,&#34;align&#34;:&#34;中心”，“散列”：“34c12c23-cdd9-453c-80ab-a1796c3cc5b6”，“alt”：“”}“类=“aligncenter size-large”&gt;&lt;img加载=“惰性”解码=“异步”宽度= “1024”高度=“357”src=“https://blog.uber-cdn.com/cdn-cgi/image/width=2160，质量= 80，onerror=重定向，format=auto/wp-content/uploads /2024/06/Fig3-1-1024x357.jpeg&#34; alt=&#34;&#34; class=&#34;wp-image-1090429&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024 ，质量= 80，onerror =重定向，格式= auto/wp-content/uploads/2024/06/Fig3-1.jpeg 1024w，https://blog.uber-cdn.com/cdn-cgi/image/width= 300，质量= 80，onerror =重定向，格式= auto/wp-content/uploads/2024/06/Fig3-1.jpeg 300w，https://blog.uber-cdn.com/cdn-cgi/image/width =768，质量=80，onerror=重定向，格式=auto/wp-content/uploads/2024/06/Fig3-1.jpeg 768w，https://blog.uber-cdn.com/cdn-cgi/image/宽度=1060，质量=80，onerror=重定向，格式=自动/wp-content/uploads/2024/06/Fig3-1.jpeg 1060w“尺寸=”（最大宽度：1024px）100vw，1024px“referrerpolicy=” no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;图 3：从开发人员计算机到远程主机的基于密码的 SSH 隧道。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;7f039f2a-0cfd-4404-b346-78190cf63b4c&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:4,&#34;hash&#34;:&#34;76babcaa-cab0-4480-8507-b5b34963fcda&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-debugger-execution&#34;&gt;调试器执行&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;806a7025-1ec1-4126-982f-3bf7c83531b8&#34;,&#34;ordered&#34;:false,&#34;values&#34;:&#34; “}”&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;调试器在专用调试服务器中运行应用程序&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;进程块，等待调试器客户端附加&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;调试器进程侦听特定的 TCP/IP 网络端口，称为调试端口&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:4,&#34;hash&#34;:&#34;0e325adf-9b00-4e6b-b655-c8c1d1273cb7&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-controlling-program-execution&#34;&gt;控制程序执行&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;bde0ef70-cfa0-47d4-8415-a94df60c277c&#34;,&#34;dropCap&#34;:false}&#34;&gt;调试客户端 (例如，VSCode、GoLand、JetBrains）通过调试端口连接。客户端发出命令来执行各种调试任务，例如设置断点、显示局部变量和函数参数、打印 CPU 寄存器内容等。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:4,&#34;hash&#34;:&#34;4e33b23b-99e7-47fb-965c-a4ad0c16148a&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-remote-debugging-with-debug-port&#34;&gt;使用调试端口进行远程调试&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;bba71797-e7ac-45b7-9821-593be4f452a0&#34;,&#34;dropCap&#34;:false}&#34;&gt;启用远程调试在不同的环境、配置或架构上进行调试。对于解决无法本地复制的特定场景或硬件/软件相关问题非常有用。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;6c156180-0c50-4e3a-a8a6-f528ffcecde0&#34;,&#34;opacity&#34;:&#34;alpha 通道&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;9cb16568-df09-423a-9620-06a015eec13f&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-access-control&#34;&gt;访问控制&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;4c8ec086-34cc-43f6-9859-7bb6234c0e8c&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-restricting-for-ldap-users&#34;&gt;限制 LDAP 用户&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;a273ae87-4c85-419a-817f-0039525eceef&#34;,&#34;dropCap&#34;:false}&#34;&gt;在调试会话期间，用户将调试器附加到应用程序以干预程序执行并收集调试信息。这也意味着尝试识别并解决程序中的错误。这意味着如果允许每个用户访问一些敏感的服务信息。因此，限制 LDAP 用户（服务开发人员/所有者）对于确保最低安全性非常重要。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;599ec47d-a7c4-42dd-a781-b925786dc85f&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-secure-ssh-connection&#34;&gt;安全 SSH 连接&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;38427b55-698d-4f88-88a4-78f359534d9f&#34;,&#34;dropCap&#34;:false}&#34;&gt;用于远程调试, 一个安全在本地和远程系统之间建立 SSH 连接。这将允许本地端口转发并通过 SSH 隧道重定向调试请求。该隧道将确保加密通信和安全数据传输。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;bb70ee8d-23cc-4787-be91-df79467c43d5&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-ssh-authorization&#34;&gt;SSH 授权&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;d20f9558-dc9c-4679-88b3-f14a328f9b18&#34;,&#34;dropCap&#34;:false}&#34;&gt;开始SSH 连接，用户需要链接到“slatedev”帐户的正确密码。该密码是服务容器内文件中随机生成的 16 位代码。密码是在主服务应用程序运行之前容器启动期间生成的。该密码只能由容器访问组（即服务所有者 LDAP）访问。 LDAP 用户可以通过 Compute CLI 访问密码，从而使他们能够建立 SSH 连接并执行调试任务。计算 CLI 确保对非 LDAP 用户的访问受到限制，不允许密码访问。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;d2dcd9cb-9e60-4927-9709-437e6f52778a&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;e4f7db46-498e-45ce-9a76-67083c5cd789&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-limitations&#34;&gt;限制&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;3128df24-147b-4c41-8b29-e565ced347e4&#34;,&#34;ordered&#34;:false,&#34;values&#34;:&#34; “}”&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;生产基础设施上的远程调试对动态修改有限制，因此仅限于只读&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;迭代时间较长，因为每次更改都涉及构建、部署和测试&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;9f25985c-b82e-493a-b23b-da0ee9452de6&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;877f5b6c-03ed-4e6d-b459-307eed84a616&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-local-debugging-using-slate-attach&#34;&gt;使用 SLATE Attach 进行本地调试&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;0b458a84-2d3d-45bc-8464-f0d2bed998fd&#34;,&#34;dropCap&#34;:false}&#34;&gt;允许远程调试用于生产基础设施上的只读调试。处于生产基础设施中可以实现与上游和下游服务/工具的无缝连接。对于开发人员来说，这是版本体验可调试环境以及更快的迭代来修复和测试相同的环境非常重要。这一差距可以通过创建与生产上游和下游服务相关的本地调试体验来填补。 SLATE Attach 填补了这一空白，并允许在附加本地环境上进行快速开发。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;26b16577-aec0-4ede-b886-8e3dca0e20a7&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-high-level-goals-0&#34;&gt;高级目标&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;fab90a26-f7ff-4ba3-82c2-50b17f1338fa&#34;,&#34;dropCap&#34;:false}&#34;&gt;主要目标是通过使用本地开发实例（笔记本电脑或开发机器）提供端到端测试来缩短代码部署测试周期（从而缩短验证迭代更改的时间），确保生产隔离和安全。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;2c391ff7-243f-46bf-a671-3db9d374c1b9&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-iteration-cycle&#34;&gt;迭代周期&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;8becb5e9-ce3d-486a-83eb-7d6a7c54f055&#34;,&#34;dropCap&#34;:false}&#34;&gt;迭代周期在这种情况下，是指更改代码和验证代码之间的时间。迭代周期越小，就越能更有效地利用开发人员的时间对后续变更进行端到端验证。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;8e50f42c-6c02-4846-8e0b-52e2012bda37&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;id&#34;:1090430,&#34;sizeSlug&#34;:&#34;full&#34;,&#34;linkDestination&#34;:&#34;none&#34;,&#34;align&#34;:&#34;中心”，“散列”：“794ef73a-e926-428b-97fe-b11a0f4ed15e”，“alt”：“”}“类=“aligncenter size-full”&gt;&lt;img加载=“惰性”解码=“异步”宽度= “820”高度=“221”src=“https://blog.uber-cdn.com/cdn-cgi/image/width=2160，质量= 80，onerror=重定向，format=auto/wp-content/uploads /2024/06/Fig4.jpeg&#34; alt=&#34;&#34; class=&#34;wp-image-1090430&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=820,quality=80 ,onerror=重定向,format=auto/wp-content/uploads/2024/06/Fig4.jpeg 820w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80, onerror=重定向，format=auto/wp-content/uploads/2024/06/Fig4.jpeg 300w，https://blog.uber-cdn.com/cdn-cgi/image/width=768，quality=80，onerror =重定向，格式=自动/wp-content/uploads/2024/06/Fig4.jpeg 768w”尺寸=“（最大宽度：820px）100vw，820px”referrerpolicy=“no-referrer”&gt;&lt;figcaption class=“wp” -element-caption&#34;&gt;图 4：使用 SLATE 进行开发的迭代步骤。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;核心/分隔符&#34; data-wp-block=&#34;{&amp;quot;哈希&#34;:&#34;c7f6664e-80ae-48c8-8431-59dac8c806ee&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;5ed47996-ad37-4c32-921b-1d59850ed524&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-need-for-slate-attach&#34;&gt;需要 SLATE Attach&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;5e842c0b-9224-423e-87d0-5b0498fefe01&#34;,&#34;ordered&#34;:false,&#34;values&#34;:&#34; “}”&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;迭代开发以更快的速度生成构建二进制文件&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;缩短代码部署测试周期&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;更快地识别和解决本地端到端故障&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;更快的设置时间&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;避免服务变更或新手入门&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;ebecbddf-739b-4bf3-8027-63cc10028542&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;2feec9ce-de38-4282-bd46-8f8ed6b46b64&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-design-0&#34;&gt;设计&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;c0f6f7d6-1ae8-4a46-a3a9-2e6e569f3bfc&#34;,&#34;dropCap&#34;:false}&#34;&gt;此设计旨在引入一个 SLATE 代理来处理针对 SLATE 实例的所有测试请求以进行本地调试。然后，这些请求将被重定向到适当的本地开发人员计算机以进行调试和开发。这使得用户能够更快地迭代并提高开发人员的生产力。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;ad3a7aa8-a42a-49e2-a3f7-0ec4812f3deb&#34;,&#34;dropCap&#34;:false}&#34;&gt;此功能可以主要在 SLATE 环境生命周期的 2 个上下文中启用：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;ordered&#34;:true,&#34;hash&#34;:&#34;d122ed7f-f7b0-49b6-9be0-cedaae60ec26&#34;,&#34;values&#34;:&#34; “}”&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;SLATE 控制平面&lt;/strong&gt;，将本地笔记本电脑/devpod 映射到 slate 环境&lt;/李&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;测试请求数据平面&lt;/strong&gt;，将请求重定向到开发者的笔记本电脑&lt;/li &gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;879353b5-bf5f-4dbd-a4b6-a90907c4a437&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator”有-alpha-channel-opac城市&gt;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;fc0e575f-51cb-45c2-8ea1-2b00b9bd027c&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-control-plane&#34;&gt;控制平面&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;0a982fcd-aefc-447e-9ac7-9a83e9877ae9&#34;,&#34;dropCap&#34;:false}&#34;&gt;主要功能控制平面的作用是使本地笔记本电脑或 devpod 中运行的服务能够附加到 SLATE 环境。打算运行该服务的本地笔记本电脑/devpod 必须将本地环境凭据附加到 SLATE 环境，以便测试请求在本地路由。此附件的先决条件是创建 SLATE 环境。这将允许路由控制数据库和本地路由数据库中的映射更新。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;9f9c73ee-1938-4f29-8e82-827493504e86&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;id&#34;:1090431,&#34;sizeSlug&#34;:&#34;large&#34;,&#34;linkDestination&#34;:&#34;none&#34;,&#34;align&#34;:&#34;中心”，“散列”：“a7fc2c6a-5999-43b2-b636-04ec980e468e”，“alt”：“”}“class =“aligncenter size-large”&gt;&lt;img加载=“惰性”解码=“异步”宽度= “1024”高度=“560”src=“https://blog.uber-cdn.com/cdn-cgi/image/width=2160，质量= 80，onerror=重定向，format=auto/wp-content/uploads /2024/06/Fig5-1024x560.jpg&#34; alt=&#34;&#34; class=&#34;wp-image-1090431&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality =80，onerror=重定向，format=auto/wp-content/uploads/2024/06/Fig5.jpg 1024w，https://blog.uber-cdn.com/cdn-cgi/image/width=300，quality= 80，onerror=重定向，format=auto/wp-content/uploads/2024/06/Fig5.jpg 300w，https://blog.uber-cdn.com/cdn-cgi/image/width=768，quality=80 ,onerror=重定向,format=auto/wp-content/uploads/2024/06/Fig5.jpg 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1036,quality=80, onerror=重定向，format=auto/wp-content/uploads/2024/06/Fig5.jpg 1036w&#34; 尺寸=&#34;(最大宽度：1024px) 100vw，1024px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34; wp-element-caption&#34;&gt;图 5：用于测试在开发人员计算机上运行的代码的请求调用流程&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;0fc0d21b-6a51-4ba0-912f-e4a1ece3b94a&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:4,&#34;hash&#34;:&#34;68ef7376-005b-4c34-8ca9-8d91c2071b73&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-call-flow&#34;&gt;调用流程&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;ordered&#34;:true,&#34;hash&#34;:&#34;4d4c2d52-cb99-49a9-a1dc-22f53a3c5c2a&#34;,&#34;values&#34;:&#34; “}”&gt;&#xA;&lt;lidata-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;用户从本地笔记本电脑/devpod 启动 SLATE 连接&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;SLATE CLI 调用 SLATE 后端的 Attach() API&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;SLATE 后端从 SLATE 代理获取代理信息（主机：端口）&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;SLATE 后端使用获取的代理信息更新路由控制数据库中的路由覆盖&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;用户使用 Cerberus CLI 启动 SSH 会话&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Cerberus 网关将代理租赁/UUID 的映射添加到 Flipr DB 中的笔记本电脑凭据，并创建 SSH 会话对于笔记本电脑&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:4,&#34;hash&#34;:&#34;33cbd3ba-84e6-4fb7-b51f-c32368b85ec3&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-routing-control-db&#34;&gt;路由控制数据库&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;3091a315-341a-4ac2-8c3d-aa18ad2dfa66&#34;,&#34;dropCap&#34;:false}&#34;&gt;路由控制数据库将测试租赁映射到路由覆盖，并将用户帐户 UUID 映射到测试租赁。它针对测试中的服务存储 SLATE 代理主机：端口，并确保针对特定 SLATE 环境的所有请求都到达 SLATE 代理。 SLATE Proxy 最终将请求路由到在用户计算机中运行的开发实例。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:4,&#34;hash&#34;:&#34;1af3bcce-3d51-4a3b-af45-fd2f0aa37403&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-local-routing-db&#34;&gt;本地路由数据库&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;fa9af186-07d9-4578-9ab9-6352df586e83&#34;,&#34;dropCap&#34;:false}&#34;&gt;本地路由数据库包含已附加到 SLATE 环境的开发实例的凭据。 SLATE Proxy 与本地路由数据库交互以获取路由凭证，并最终将请求路由到在本地环境中运行的被测服务&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;ae9e74db-9b41-4a46-ba9d-d600c0350856&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;714ae8c2-f980-4c03-9133-3981f34c4945&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-data-plane&#34;&gt;数据平面&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;3c12e2f9-9a26-4969-a929-e66e5b9a207d&#34;,&#34;dropCap&#34;:false}&#34;&gt;本节主要讨论来自不同客户端（移动、工作室、Web 等）的测试请求流程。该数据平面主要涉及2个实体：路由覆盖h头和主机租用映射。下图显示了不同的测试请求如何通过 SLATE 代理到达本地笔记本电脑。控制平面确保路由覆盖和主机映射维护在不同的数据库中。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;0cc4187b-d85a-4b70-be55-c158994fefdb&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;id&#34;:1090432,&#34;sizeSlug&#34;:&#34;large&#34;,&#34;linkDestination&#34;:&#34;none&#34;,&#34;align&#34;:&#34;中心”，“散列”：“5b649275-8ac1-4340-b0e8-a19be825d309”，“alt”：“”}“类=“aligncenter size-large”&gt; &lt;img加载=“惰性”解码=“异步”宽度= “1024”高度=“520”src=“https://blog.uber-cdn.com/cdn-cgi/image/width=2160，质量= 80，onerror=重定向，format=auto/wp-content/uploads /2024/06/Fig6-1024x520.jpeg&#34; alt=&#34;&#34; class=&#34;wp-image-1090432&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality =80，onerror =重定向，格式= auto/wp-content/uploads/2024/06/Fig6.jpeg 1024w，https://blog.uber-cdn.com/cdn-cgi/image/width=300，质量= 80，onerror=重定向，格式=auto/wp-content/uploads/2024/06/Fig6.jpeg 300w，https://blog.uber-cdn.com/cdn-cgi/image/width=768，质量=80 ，onerror=重定向，格式=auto/wp-content/uploads/2024/06/Fig6.jpeg 768w，https://blog.uber-cdn.com/cdn-cgi/image/width=1300，质量=80， onerror=重定向，格式=自动/wp-content/uploads/2024/06/Fig6.jpeg 1300w&#34; 尺寸=&#34;(最大宽度：1024px) 100vw，1024px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34; wp-element-caption&#34;&gt;图 6：用于将测试请求路由到开发人员计算机的代理设置。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;d0682e8a-4e5e-4860-bf0a-27125c9e134a&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;d5a8b75c-9546-48e7-aeab-107b253f5169&#34;,&#34;dropCap&#34;:false}&#34;&gt;以上是针对具有生产上游和下游的本地笔记本电脑的测试请求流：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;ordered&#34;:true,&#34;hash&#34;:&#34;4ea9f2b6-a6c3-452e-9629-1505324f32c8&#34;,&#34;values&#34;:&#34; “}”&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;测试帐户请求来自移动客户端&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;E2E 测试代理检索路由覆盖并将路由标头注入测试请求&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;测试请求通过 Mutley 在生产服务中传播，直到请求达到服务 3 目标&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;请求st 重定向到 SLATE 代理，因为路由覆盖具有针对服务 3 的 slate 代理主机：端口&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;SLATE 代理根据主机中的主机：端口配置将请求转发到 Cerberus 网关上的开放端口Cerberus-deputy Flipr 命名空间，由用户在运行 Cerberus CLI 时设置&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Cerberus-gateway 将请求转发到用户的本地开发机器供用户调试&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;来自本地笔记本电脑的请求将最终通过 Cerberus 转发到生产下游&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;c1062a3f-701f-40f2-8416-7ccd43c088cb&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-limitations-0&#34;&gt;限制&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;7d9da5c3-f6e2-4fb8-b038-71dbe8495dad&#34;,&#34;ordered&#34;:false,&#34;values&#34;:&#34; “}”&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;对于某些复杂的服务来说，在本地运行服务可能不可行，因为它们需要支持某些依赖项（例如扳手）只能存在于生产基础设施中&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;这仅限于测试请求，因为它可以动态更改请求，进而保护生产流量&lt;/li &gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;在本地等待调试请求时间较长时请求超时&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;f205b844-fe96-41cf-a695-c12f79b9e330&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;86cb82b0-8d3f-4afe-b4a8-e46ab6edf12d&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-impact&#34;&gt;影响&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;4af528af-4339-4de0-b65a-ba6a68054d0e&#34;,&#34;ordered&#34;:false,&#34;values&#34;:&#34; “}”&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;即插即用开发环境，提高开发人员工作效率&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;能够为开发者创建与生产协同工作的本地体验&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;提高开发人员速度：生产调试可以帮助开发人员更有效地识别和解决问题&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;db759f9c-b972-4bf3-85c6-106704f28b6c&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;id&#34;:1090433,&#34;sizeSlug&#34;:&#34;大&#34;,&#34;linkDestination&#34;:&#34;无&#34;,&#34;align&#34;:&#34;center&#34;,&#34;hash&#34;:&#34;f769cc84-59fb -4db5-b270-85f9cc38bc6c&#34;,&#34;alt&#34;:&#34;&#34;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img 加载=&#34;lazy&#34; 解码=&#34;异步&#34; width=&#34;1024&#34; height=&#34;280&#34; src=&#34; https://blog.uber-cdn.com/cdn-cgi/image/width=2160，quality=80，onerror=redirect，format=auto/wp-content/uploads/2024/06/Fig7-1024x280.jpeg” alt=&#34;&#34; class=&#34;wp-image-1090433&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/ wp-content/uploads/2024/06/Fig7.jpeg 1024w，https://blog.uber-cdn.com/cdn-cgi/image/width=300，quality=80，onerror=redirect，format=auto/wp -content/uploads/2024/06/Fig7.jpeg 300w，https://blog.uber-cdn.com/cdn-cgi/image/width=768，quality=80，onerror=redirect，format=auto/wp-内容/uploads/2024/06/Fig7.jpeg 768w，https://blog.uber-cdn.com/cdn-cgi/image/width=1536，quality=80，onerror=redirect，format=auto/wp-content /uploads/2024/06/Fig7.jpeg 1536w，https://blog.uber-cdn.com/cdn-cgi/image/width=1680，quality=80，onerror=redirect，format=auto/wp-content/ uploads/2024/06/Fig7.jpeg 1680w&#34;sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;图 7. 影响数据使用 SLATE 附加功能提高开发人员速度。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;92748031-56ec-41fe-af5f-e28c13872b72&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;089b91b9-e785-426b-9acc-98c513dbecb7&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-what-s-next&#34;&gt;下一步是什么&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;0fab3aae-e3c1-4f43-b6cd-31314da60b97&#34;,&#34;dropCap&#34;:false}&#34;&gt;&lt;strong&gt; SLATE Sniffer 通过监控来调试问题&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;25ad3857-16be-4803-b58a-19203bd4ff77&#34;,&#34;dropCap&#34;:false}&#34;&gt;远程和本地调试主要允许测试请求进行调试。除了 uMonitor 工具中出现的日志之外，还需要对生产进行可观察性。我们的目标是使用 SLATE Sniffer 精确地按需创建这种可观察性。  SLATE Sniffer 的主要目标包括：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;9512a824-5d47-4526-b7b9-a3da8258f058&#34;,&#34;ordered&#34;:false,&#34;values&#34;:&#34; “}”&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;捕获请求和响应作为服务和 UUID 的过滤器&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;能够支持和过滤生产和测试请求&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr 数据-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;f11a73c1-4e1a-40b2-96a4-987bfccd4683&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34; class=&#34;wp-block -分隔符有-alpha-通道-不透明度&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:1,&#34;hash&#34;:&#34;a623f4dc-0808-4f1f-a5c6-a75a520f8f0e&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-conclusion&#34;&gt;结论&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;c06ce4bc-9946-41bd-95b1-37c27416e5ee&#34;,&#34;dropCap&#34;:false}&#34;&gt;我们的目标是增强 SLATE 平台，将其定位为调试生产问题的主要工具。 SLATE 中集成的调试功能在安全性和开发人员的要求之间取得了平衡。 SLATE 为开发人员的代码相关活动和服务引导引入了新的范例。我们期待与不同团队合作，将质量左移并在开发早期阶段就潜在问题建立可见性。&lt;/p&gt;</description>
      <pubDate>Tue, 18 Jun 2024 07:21:37 +0000</pubDate>
    </item>
    <item>
      <title>【How Uber ensures Apache Cassandra®’s tolerance for single-zone failure】Uber 如何确保 Apache Cassandra® 对单区域故障的容忍度</title>
      <link>https://www.uber.com/blog/single-zone-failure-tolerance/</link>
      <description>【&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;5fc4fe6c-0737-484b-8ddf-2ca57c80d238&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-introduction&#34;&gt;Introduction&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f69c5f13-3615-4077-8d5f-3532e989de50&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;a href=&#34;https://www.uber.com/blog/how-uber-optimized-cassandra-operations-at-scale/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Uber has been running an open-source Apache Cassandra&lt;sup&gt;®&lt;/sup&gt; database as a service&lt;/a&gt; that powers a variety of mission-critical online transaction processing (OLTP) workloads for more than six years now at Uber scale, with millions of queries per second and petabytes of data. As Uber operates data centers in multiple zones across multiple regions, a Cassandra cluster at Uber typically has its nodes spread across multiple zones and regions. With high availability being essential for Uber’s business, we’d like to have Cassandra’s availability unaffected in the scenario of a single zone going down. This blog shows how we ensured the single-zone failure tolerance for Cassandra, and particularly how we converted the large Cassandra fleet in real-time with zero downtime from non-zone-failure-tolerant to single-zone-failure tolerant.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;8bf0dfb4-b39f-4171-a3a5-76b927541e21&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-terminology&#34;&gt;Terminology&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2431446b-d46b-46d1-baad-d718dcd4ef1e&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;SZFT&lt;/strong&gt;: Single Zone Failure Tolerant&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;24344de4-31a2-4468-a72d-66d5affba862&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d97f5b1b-c277-4496-9fa0-047ad05bcab4&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-background&#34;&gt;Background&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8de7f022-5e6c-4de1-b92b-82da803c634f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Cassandra naturally supports multiple copies of data. One of the biggest benefits of having multiple copies of data is high availability: if a minority of copies becomes unavailable, the majority of copies can still be accessed. When a Cassandra cluster is deployed across multiple availability zones, we would like to ideally have all the copies distributed evenly among the zones so that an impact to a zone does not impact user requests.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;31d3be95-4092-4049-b767-eb4c022744af&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;width&amp;quot;:&amp;quot;700px&amp;quot;,&amp;quot;height&amp;quot;:&amp;quot;auto&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;2cea3750-1b38-41c4-b6f8-8d34e8657bbf&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXcSTnDyAkLVo_Z0_2lEv-UqaswqOQAZup6hMZKsVASGPumgKy0uf5wCQdcYGmCaI2vFl0U-bVkUY8dz3hfPZATIx7Hzr-HbtdDc53mSvXCfAMUoWI8-kx3MghC73muhugYyr71fk18Au-vNl8eGN5W5uFm9?key=AZe-MVriCM2tBK0R_Gauew&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 1: Single Zone Failure and Availability Impact.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;20fb85c8-ac12-44fb-92b6-67da7927088a&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b16bb2b2-5305-4e3f-89b7-64e3a706b11b&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Figure 1 illustrates the problem. In this example, the replication factor is 3. A data record is considered available when the majority of its copies are available. When zone 1 is down, data record 1 becomes unavailable because it loses the majority (two) of its copies. Meanwhile however, data record 2 is still available because it happens to have a minority (only one) of its replicas placed in the failed zone. If all data records had their replicas placed in the same way as data record 2 where &lt;strong&gt;the&lt;/strong&gt; &lt;strong&gt;replicas are evenly distributed across the zones such that each zone contains only a minority of the copies&lt;/strong&gt;, then the failure of any single zone would have no impact on the overall availability.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3b088613-eab3-4e9c-924f-cab2781b86ca&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Cassandra inherently supports separating the replicas with a feature that logically groups the nodes. Replicas are then separated by the groups. The grouping is done via a file called &lt;em&gt;cassandra-rackdc.properties&lt;/em&gt;.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1a8f3002-e385-400c-9536-18440e038d5d&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In this feature, each Cassandra node is assigned with two properties: &lt;em&gt;dc&lt;/em&gt; and &lt;em&gt;rack&lt;/em&gt;. For example, a Cassandra node in region 1 would be configured as the following:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f7b444cf-2440-4ceb-9242-0cfb4f2192ef&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090731,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;2f30f93b-38f1-4da1-80a7-4ac554f07b0e&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;377&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/cassandra-rackdc-1-1024x377.png&#34; alt=&#34;&#34; class=&#34;wp-image-1090731&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/cassandra-rackdc-1.png 1024w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/cassandra-rackdc-1.png 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/cassandra-rackdc-1.png 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1152,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/cassandra-rackdc-1.png 1152w&#34; sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7fcbecf9-cedf-44b5-9198-1466c53822fe&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;141a0703-68ef-4756-a663-280c3f3e3923&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;When the replication strategy is &lt;a href=&#34;https://cassandra.apache.org/doc/4.1/cassandra/architecture/dynamo.html#network-topology-strategy&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;&lt;em&gt;NetworkTopologyStrategy&lt;/em&gt;&lt;/a&gt;, within a &lt;em&gt;dc&lt;/em&gt;, &lt;strong&gt;for any data record, Cassandra’s replica placement algorithm places replicas onto as many &lt;em&gt;racks&lt;/em&gt; as possible&lt;/strong&gt;. This is illustrated in the below figure:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;310ac262-65e9-42db-9af7-73869e5ed300&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;width&amp;quot;:&amp;quot;700px&amp;quot;,&amp;quot;height&amp;quot;:&amp;quot;auto&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;4b273450-10bf-4b79-9cc1-1d4aa7cd9015&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXegRc24Cr4H85C9-HrRQ-xwAG1MIjpD5JJssb_oLn96JwP4lqx631rWoB5Vq_0vzWcCJmrOmFx5fLvimGURLmBi18tWM_LyYbngSsFq9oEJopiGCtpi1BxEsrVDHC2UU_7ADVBMbc457vFs1rkOXj81_Co?key=AZe-MVriCM2tBK0R_Gauew&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 2: The Desired Setup: Grouping the Nodes by Zone.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7c873913-1e5d-4dbe-bb28-ee53f21efa1a&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f3d6bc04-a9db-4537-aa5e-fc29c32b97a4&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The setup in Figure 2, assuming replication factor is 3, is a desired setup that is SZFT (single zone failure tolerant). No matter which single zone goes down, there will still be two healthy replicas in the other zones serving reads and writes, for any data records.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;cee7de72-24a5-4715-820e-1105e9b512c8&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8001718d-3454-46d5-b978-672a211e47da&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-why-was-cassandra-at-uber-not-szft&#34;&gt;Why was Cassandra at Uber not SZFT&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5827de2f-ffb2-439f-90bd-b1a8b1824771&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Uber was not using the setup in Figure 3–we simply didn’t take advantage of the “rack” property. All the Cassandra nodes were assigned the same “default” value for the rack property, resulting in only one unique rack value in the region. Replicas failed to be properly separated because to separate replicas multiple values for the rack property are needed. As a result, a majority or potentially all replicas can be placed in the same zone, as illustrated in the below figure:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1ce859ad-c8d6-472d-a0e4-b27150790359&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;50737eb5-593e-4692-a938-17c34ea8122d&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXfHvNOqIU6eb_3TL4Xjq32UOYUMe-vrXXI-ZriBakzeWwFkn2FuW-BUakKJAIujnE3tS8zljn1XXGk9w9pVglzfMur7NB8PNxhlcGHGHRqQzy6ZeVFWoPG3QjRNZCoKlpHitu14LgFXiBSvIpNaClZ6qHsn?key=AZe-MVriCM2tBK0R_Gauew&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 3: Uber’s Old Setup: Single Unique Rack.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f9c291a4-b5d8-4b5f-833d-aa3fbc694b80&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a36f68e6-50aa-4c91-8139-248760bf08e4&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;At a high level, solving the problem for Uber essentially meant the transition from the single-rack setup (in Figure 3) to the multi-rack setup with a zone-based rack assignment strategy (in Figure 2). The transition posed multiple challenges. Let’s see what they are and how we overcame them at Uber.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;dcb7aee5-a584-4695-ae8e-e78756263a6c&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;803bbc14-466f-4232-945f-e3bd44f7f148&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-challenge-1-in-place-transition-not-an-option&#34;&gt;Challenge 1: In-Place Transition Not an Option&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b365319c-ad0d-4155-ac47-ea64d2e51119&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;It proved &lt;strong&gt;impractical&lt;/strong&gt; to transition &lt;strong&gt;in-place &lt;/strong&gt;the existing nodes in a region from the single-rack setup to the multi-rack setup. This is because if a node associated with a new rack is introduced to an existing single-rack node setup, it will immediately make the new member a hotspot. As already stated, Cassandra’s replica placement algorithm places replicas onto as many unique racks as possible. The moment a node brings a second rack to Cassandra, all the data records will each place a replica onto the new rack, even though there is only one node in it! Figure 4 well illustrates the problem:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;241bb4ac-9167-4202-b585-dc701823c298&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090555,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;43e1fb21-afc9-493b-bffd-0358b6422dcb&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1007&#34; height=&#34;1024&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f4-1007x1024.png&#34; alt=&#34;&#34; class=&#34;wp-image-1090555&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1007,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f4.png 1007w, https://blog.uber-cdn.com/cdn-cgi/image/width=295,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f4.png 295w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f4.png 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1510,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f4.png 1510w, https://blog.uber-cdn.com/cdn-cgi/image/width=1776,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f4.png 1776w&#34; sizes=&#34;(max-width: 1007px) 100vw, 1007px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 4: Hotspot Issue When Introducing a New Rack to a Single-Rack Setup.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c722bf2c-4ae7-413d-867e-35281af4e864&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f5b50da6-4305-482f-b65a-dc7c7dc5a5b0&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Due to the limitation of the replica placement algorithm, we are left with only one option which at a high level looks as follows:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;ordered&amp;quot;:true,&amp;quot;hash&amp;quot;:&amp;quot;8094ae43-e636-4409-b07e-96330ae4593b&amp;quot;,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Create a new Cassandra ring, or a new “dc” as in NetworkTopologyStrategy,&amp;nbsp; within the same region. The new ring is created with the multi-rack setup to meet the SZFT requirement.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Rebuild the newly created ring through &lt;a href=&#34;https://cassandra.apache.org/doc/stable/cassandra/tools/nodetool/rebuild.html&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;rebuild&lt;/a&gt; from the old live ring.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Transparently swap the new ring with the old ring by moving the customer traffic from one ring to another.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Remove the old ring.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7bc7bde9-ae24-4c8c-a6b7-7273321f4f32&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We set the following principles for this whole migration:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;fa1567e6-8471-40cb-ba85-3797dc9bfc06&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Zero customer involvement—our stakeholders must not be involved or exposed to the migration (e.g., changing service logic, client code, or routing)&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;High Availability—no down time during migration&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Maintaining pre-existing performance SLOs, such as latency&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Rollback capability so we can switch back and forth between the old ring and the new ring as an emergency measure&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d72209cb-bf37-4bba-bcb9-13bf56090f3e&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c05fd87f-a68f-420e-bc70-6eec86ab7dd2&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-the-rebuild-procedure&#34;&gt;The Rebuild Procedure&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;17273b8c-c1ad-4f02-b207-ec110a0acf91&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-phase-1-provision-a-new-set-of-offline-multi-rack-nodes-in-the-region&#34;&gt;Phase 1: Provision a new set of “offline” multi-rack nodes in the region&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c542c36c-5bac-4c84-a50a-4a13c99551dd&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In the selected region, add a new ring of nodes to the cluster. The hardware resource given to the new nodes (e.g., node count, CPU cores, memory, disk size) need to be the same as the existing ring in that region. Distribute the new nodes evenly across the zones. Group them with the zone-based strategy by configuring the &lt;em&gt;cassandra-rackdc.properties&lt;/em&gt; file of each node as following:&lt;/p&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;13351642-4379-4fca-ade3-76c075a1d3e5&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXcH74hsYf-WXgoNrypJz7LTOJWRLDvYZIIguWfE3jCblgpTyxzh28JN2ORfhR_odddRm1wXerjO-rUZj0A0qruZ6TXDxTHwvWHxBXnebkbT4fGIEfLhcEa5s9LsNCnzmWVoJ7gmv0t0MAhSgBAirKebyVxP?key=AZe-MVriCM2tBK0R_Gauew&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;dfd9890d-56d6-4ee5-93ea-961bb9ffddad&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Lastly, all the new nodes should be created with &lt;a href=&#34;https://cassandra.apache.org/doc/stable/cassandra/tools/nodetool/disablebinary.html&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;native transport disabled&lt;/a&gt; to prevent CQL connection to them. This is crucial for a seamless traffic switch later from the existing ring to the new one.&lt;/p&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090556,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;a093cbf1-7fb7-4aa4-b322-e097fb5623c9&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;729&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f5-1024x729.png&#34; alt=&#34;&#34; class=&#34;wp-image-1090556&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f5.png 1024w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f5.png 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f5.png 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1262,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f5.png 1262w&#34; sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 5: Phase 1: provision a new set of multi-rack nodes with binary disabled.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;55ba8202-8606-42db-a101-766aa2dad5f5&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;a9d92e66-3feb-4b57-8e47-a956de997fd8&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-phase-2-data-sync-for-live-writes&#34;&gt;Phase 2: Data Sync for Live Writes&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;99451c2d-2a9a-47db-b1ad-89faaf1e6b05&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;As our end goal is to have the new ring replace the old ring, we need to have all the data replicated and existing in both rings. This includes both the data from the live writes as well as the historical data. For the data from the live writes, we need to add the new ring to the replication setting of all the keyspaces such that they can start to indirectly receive live writes thanks to Cassandra’s cross-dc replication.&lt;/p&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090732,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;b6d4f985-4d8b-4576-9d1b-0c5bc080432c&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;381&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/alter-keyspace-3333-1024x381.png&#34; alt=&#34;&#34; class=&#34;wp-image-1090732&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/alter-keyspace-3333.png 1024w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/alter-keyspace-3333.png 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/alter-keyspace-3333.png 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1118,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/alter-keyspace-3333.png 1118w&#34; sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090557,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;9135df85-dfb1-4042-81d1-613a49c2b509&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;720&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f6-1024x720.png&#34; alt=&#34;&#34; class=&#34;wp-image-1090557&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f6.png 1024w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f6.png 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f6.png 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1253,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f6.png 1253w&#34; sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 6: Phase 2: include the new set of nodes in replication.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d1bd50b8-60b7-41eb-b01a-d6e5c6419802&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;59ce3e71-3b3d-4137-ab38-44de16f17590&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-phase-3-data-sync-for-historical-data&#34;&gt;Phase 3: Data Sync for Historical Data&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f59b9c48-c2f1-41c7-b67e-e58b7332b54d&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;For historical data, we need to have the new ring stream it from the old ring. Although the new nodes are now receiving live writes, they are still lacking all the data from the past. Cassandra provides a tool to stream such data using the nodetool rebuild command. The following command needs to be run on every new node of &lt;em&gt;region1_new&lt;/em&gt; to stream data from &lt;em&gt;region1&lt;/em&gt;:&lt;/p&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090734,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;5b44bf2e-a523-43d6-a2ca-de30b10f1fbc&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;138&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/nodetool-rebuild-1024x138.png&#34; alt=&#34;&#34; class=&#34;wp-image-1090734&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/nodetool-rebuild.png 1024w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/nodetool-rebuild.png 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/nodetool-rebuild.png 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1112,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/nodetool-rebuild.png 1112w&#34; sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;0d7b769d-7498-4d2c-b195-9804f3f9a1bd&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXft9Qy90P61zHHyDGRk1L-IrXN866dHr8WMyGbEe-_05rtLUdE_171HSBDlkFowzOnG9Ka40w79XsIiT91h2md32ikNehFv86ncC0xmN-G6aDa7S5yUS1eRhB_-sfHRy7veOzNTt0lSRc9FjuzEMpFDDD9D?key=AZe-MVriCM2tBK0R_Gauew&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 7: Phase 3: sync old data.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c85a1994-e788-449e-b314-f2d43b9ce04c&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;e2d1ad85-f797-4d28-a4b1-c8501a92d9b6&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-phase-4-traffic-switch&#34;&gt;Phase 4: Traffic Switch&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9be925b3-a119-4af6-bb79-ece136ee2b52&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;After the historical data has been streamed, we are ready to have the Cassandra client connect to the new ring of nodes and stop connecting to the old. This is done by &lt;a href=&#34;https://cassandra.apache.org/doc/stable/cassandra/tools/nodetool/enablebinary.html&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;enabling native transport&lt;/a&gt; on all the nodes in the new ring and then &lt;a href=&#34;https://cassandra.apache.org/doc/stable/cassandra/tools/nodetool/disablebinary.html&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;disabling native transport&lt;/a&gt; on all the nodes in the old ring. We’ve eliminated the need for any actions on the client side, the reason for which will be discussed in the next section where we are going to see the Cassandra client enhancement we’ve made at Uber.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e786234e-2d54-41ba-9ff9-510533cf9c09&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;width&amp;quot;:&amp;quot;700px&amp;quot;,&amp;quot;height&amp;quot;:&amp;quot;auto&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;11e99c4b-be82-4521-9ac8-9640150d0621&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXf6wcyJD06iUE8_JWw81JUucwUyHl-xEeQRmUNftN2rLvtBeU0vgE53GWTIYQvWhGvMFM7Stbz4hUuuBGTpQX1qBDikqwrHNa__Y3tkcvdnoRk3MA3f97eyOHW0sXJahDq2I1PaxzPxcNet7SNYvVGpoNiP?key=AZe-MVriCM2tBK0R_Gauew&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 8: Phase 4: traffic switch.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;06b8cced-4362-435e-bae3-a26771b778a2&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;c65f13f4-e2c6-4605-bf58-b71a9a56a80c&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-phase-5-remove-old-nodes&#34;&gt;Phase 5: Remove Old Nodes&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6aabb217-a3d9-4462-bf23-982607dbff4c&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Firstly, the replication setting of all the keyspaces needs to be altered so that the old ring is no longer part of the data replication.&lt;/p&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090735,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;e5955543-fc53-4e83-8345-b7f3075c17c1&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;339&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Alter-keyspace-333-1024x339.png&#34; alt=&#34;&#34; class=&#34;wp-image-1090735&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Alter-keyspace-333.png 1024w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Alter-keyspace-333.png 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Alter-keyspace-333.png 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1196,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Alter-keyspace-333.png 1196w&#34; sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;918a3fa8-869a-4608-84f5-6ea3614dd859&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Once this is done, the nodes in the old ring are decommissioned.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b9a9e310-db11-4ed5-9360-7697535fc833&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;width&amp;quot;:&amp;quot;700px&amp;quot;,&amp;quot;height&amp;quot;:&amp;quot;auto&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;5a00a491-e698-481f-b0d5-f467b6dc803c&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXcDvHs74P1MCQgreqSpD_eOglh3jidW2ydJN4TthFJGd5BOMq6tTk-FE04jLk-LFacE1cRXKQGH6nvmXzP1FDpO7TiQefYYl8dhEV34zSMIZ1uPfQZu66743WCZrHkz3aloDsPF8qVOs_fZhgUM_TyoncnY?key=AZe-MVriCM2tBK0R_Gauew&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 9: Phase 5: get rid of the old set of nodes.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2bb0dfc4-90fd-4d9d-93cb-0911117b0dc2&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;8c10f5cd-7b7e-4079-8526-49f4f2d7b3a3&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-phase-6-repeat-for-the-other-regions&#34;&gt;Phase 6: Repeat for the other regions&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b6d9edbf-0438-41f0-bf95-5ed8b9965802&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The Cassandra cluster in the selected region is now SZFT. The same procedure needs to be repeated for the other regions.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e083bdef-556a-48f0-98aa-5a89b24bb74d&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;171cb21c-d216-4dfe-9660-cf05b6590cbc&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-cassandra-client-enhancement&#34;&gt;Cassandra Client Enhancement&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1dca4857-15d6-43db-adce-9e74a2876528&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;During the above procedure, no client side actions are involved. This is because at Uber, we have a fork of GoCQL and Java drivers where we have enhanced them to be capable of dynamically switching traffic from one ring to another without a restart.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8023f66f-9c9c-4197-8940-3aa9f7b23f02&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In order to achieve a seamless traffic switch, the expectation on the Cassandra clients are to:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;ordered&amp;quot;:true,&amp;quot;hash&amp;quot;:&amp;quot;5afa16f1-8c7d-4306-b970-2b77b6776b4a&amp;quot;,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Always be provided with initial Cassandra contact points (i.e., the Cassandra nodes for the initial topology discovery) from the same region where the client is.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Always choose coordinator nodes from the same region where the client is.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Automatically connect to the nodes of the new ring, after native-transport is enabled on them and disabled on the nodes of the old ring, as in Phase 4 of the Rebuild Procedure.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;cb8bdfe0-6a4b-4bb0-b12c-1bde36b71eea&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Requirement #1 was fulfilled with a new micro-service that’s dedicated to publishing the contact information of Cassandra clusters. It has an integration with our Cassandra control plane and thus understands the topology of every Cassandra cluster. The consumer of this service (in this case a Cassandra client) sends a request containing only the name of the target Cassandra cluster. The service returns the contact information (e.g., IPs and ports) of all the nodes belonging to the cluster &lt;strong&gt;that are in the same region as the consumer&lt;/strong&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;53df3941-e5cd-4cf5-a1da-83eb75c79101&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The above logic is hidden from the client API, and our Cassandra users simply need to change their way of providing the client with contact points, as the following:&lt;/p&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090736,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;699f2caf-abaa-4db0-a1f2-d9a3f415dc64&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;91&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Cluster-builder-1024x91.png&#34; alt=&#34;&#34; class=&#34;wp-image-1090736&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Cluster-builder.png 1024w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Cluster-builder.png 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Cluster-builder.png 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1302,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Cluster-builder.png 1302w&#34; sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;53df3941-e5cd-4cf5-a1da-83eb75c79101&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Requirement #2 was done with a new host filter we implemented at Uber within the Cassandra clients. This new host filter excludes all the coordinator nodes that are located in regions remote to the client.&lt;/p&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090737,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;a830e016-1133-47a6-bf87-9d28e3b6ec7b&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;105&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/HostFilterPolicy-1024x105.png&#34; alt=&#34;&#34; class=&#34;wp-image-1090737&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/HostFilterPolicy.png 1024w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/HostFilterPolicy.png 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/HostFilterPolicy.png 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1290,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/HostFilterPolicy.png 1290w&#34; sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;64649522-f053-4d5c-8da2-601abe88fa8e&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Requirement #3 was achieved by specifying the load balance policy as TokenAware + RoundRobin. The thing that really matters is not the use of these policies, but the elimination of the use of DCAwarePolicy. DCAwarePolicy, which was once seen in many Cassandra applications at Uber, pins the coordinator node selection to the old ring. Open-source clients were already capable of capturing the native-transport-related changes in a timely fashion, automatically dropping connection to the native-transport-disabled nodes and automatically connecting to the newly-native-transport-enabled nodes. Therefore all we needed to do was allow clients to connect to any rings in the same region.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f63648b9-e4f6-4c52-bfd8-ed8ac6de4cb8&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In the end, we standardized the Cassandra client configuration at Uber like this:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090738,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;afa165bc-ce7b-40fc-8755-707011ddc4c7&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;wp-block-image size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;337&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/HostFilter-and-Clusterbuilder-1024x337.png&#34; alt=&#34;&#34; class=&#34;wp-image-1090738&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/HostFilter-and-Clusterbuilder.png 1024w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/HostFilter-and-Clusterbuilder.png 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/HostFilter-and-Clusterbuilder.png 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1308,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/HostFilter-and-Clusterbuilder.png 1308w&#34; sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d13ccf86-6323-4320-a12f-38966090aea7&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;These enhancements in the client elegantly decouple users from the low-level topology detail of the Cassandra cluster–e.g., IP, port, dc (as in NetworkTopologyStrategy), etc. It paves the way for a seamless traffic switch in Phase 4 of the rebuild procedure. Moreover, the region-based coordinator selection paired with “LOCAL_QUORUM” reads and writes ensures that during the rebuild procedure in one region, Cassandra clients in the other regions won’t see any impact, as they are always directly exchanging data with Cassandra nodes in their local region, allowing for region-by-region SZFT transition.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e6638124-5a65-43fb-960c-4dcd83b0d3c5&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;21ab4486-37ee-4594-a963-77246bfe6045&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-challenge-2-nbsp-lack-of-uniform-spare-server-capacity-across-zones&#34;&gt;Challenge 2:&amp;nbsp; Lack of uniform spare server capacity across Zones&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8d569cb2-ac03-4406-92cc-a7cdf09cfa9f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;For the multi-rack setup where each Cassandra rack is a zone, we need to ensure there are always enough zones available (i.e., number of zones ≥ replication_factor). In addition, the spare capacity in each of the zones needs to be uniform for each of the racks to be equally scaled when scaling the cluster.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c53bdf23-33c3-45aa-851c-2b1285a00629&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;This can appear less challenging in cases where the size of the clusters is small and hence the amount of scaling needed is small or if there are stronger guarantees of spare capacity in all zones. However in practice, it is very possible to have the available capacity spread non-uniformly across the zones. In such a scenario, performing a potentially urgent horizontal upscaling of the cluster would inevitably lead to sacrificing the SZFT property of the cluster.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9da57313-7bdd-4177-a093-d742ceb324e8&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Regardless of the capacity situation, we should be prepared for handling such a scenario. When both the SZFT property and the urgent need for horizontal scale can not be met at the same time, we have to prioritize the immediate performance needs of the cluster via the horizontal scale. It is important to keep in mind that, once additional capacity eventually arrives at the other zones, we should be able to “relocate” the nodes added during the scale to the desired zones with minimal number of node replacements, ultimately achieving SZFT. The entire process is quite operationally demanding, and we need refined automation to significantly reduce manual effort.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4ea136ad-bb51-4dbd-bb80-9dd7b1a25a13&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We are not going to expand on this challenge in this blog, as it pertains to the server capacity management aspect. We at Uber have ensured that we are prepared to tackle such a scenario in a fully automated manner, thanks to our &lt;em&gt;Stateful Platform&lt;/em&gt; team, which runs our underlying storage management and control plane platform.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;644a0056-674f-4a88-a1e9-25b7190d63b3&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8fec6c26-c92d-4819-aebc-6b735d32f312&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-highlights&#34;&gt;Highlights&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ec4afdb3-1091-4066-9ee9-3f0d9292df3e&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The success of this critical project is measured as follows:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;ordered&amp;quot;:true,&amp;quot;hash&amp;quot;:&amp;quot;2e3f35e9-e450-4b32-bf05-d9242d9ebe4a&amp;quot;,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;The rollout has completed on the vast majority of the Cassandra fleet. For months after the rollout, no issue has been seen.&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;During the rollout, no major incident was caused.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;The whole exercise was entirely transparent for our stakeholders.&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;We conducted multiple tests in which we virtually brought down an entire production zone, and Cassandra’s stakeholders were unaffected!&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8f01d5e8-18b4-42ab-88e9-e8f5889107a9&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;01a2d6cf-39f7-4607-8f6a-4e30019cc229&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-conclusion&#34;&gt;Conclusion&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3cfe4f93-9652-4f6d-9bc0-0d4eedc7c3c2&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In this article, we have showcased the Cassandra deployment at Uber. We have also highlighted the challenges of achieving single zone failure tolerance, and dived deep into the solutions.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;fontSize&amp;quot;:&amp;quot;small&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;c67767ae-c3de-43f5-b72e-4960a271ebf5&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34; class=&#34;has-small-font-size&#34;&gt;&lt;strong&gt;Cover Photo Attribution&lt;/strong&gt;: This image was generated using ChatGPT.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;fontSize&amp;quot;:&amp;quot;small&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;6fd34c76-0a77-427f-b89c-eb366e6d8379&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34; class=&#34;has-small-font-size&#34;&gt;Apache® and Apache Cassandra® are either registered trademarks or trademarks of the Apache Software Foundation in the United States and/or other countries. No endorsement by The Apache Software Foundation is implied by the use of these marks.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;fontSize&amp;quot;:&amp;quot;small&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;bc71ef0b-63c9-4699-b17a-379b441aabb7&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34; class=&#34;has-small-font-size&#34;&gt;Oracle, Java, MySQL, and NetSuite are registered trademarks of Oracle and/or its affiliates. Other names may be trademarks of their respective owners.&lt;/p&gt;】&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:1,&#34;hash&#34;:&#34;5fc4fe6c-0737-484b-8ddf-2ca57c80d238&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-introduction&#34;&gt;简介&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;f69c5f13-3615-4077-8d5f-3532e989de50&#34;,&#34;dropCap&#34;:false}&#34;&gt;&lt;a href =&#34;https://www.uber.com/blog/how-uber-optimized-cassandra-operations-at-scale/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Uber 一直在运行开源 Apache Cassandra&lt;sup&gt;®&lt;/sup&gt; 数据库即服务&lt;/a&gt;，为各种关键任务在线事务处理 (OLTP) 工作负载提供支持已超过六年，目前已达到 Uber 规模，每秒有数百万次查询和 PB 级数据数据的。由于 Uber 在多个地区的多个专区运营数据中心，因此 Uber 的 Cassandra 集群的节点通常分布在多个专区和地区。由于高可用性对于 Uber 的业务至关重要，我们希望 Cassandra 的可用性在单个区域出现故障的情况下不受影响。本博客展示了我们如何确保 Cassandra 的单区容错能力，特别是如何将大型 Cassandra 队列以零停机时间实时从非区容错转换为单区容错。&lt;/p &gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;8bf0dfb4-b39f-4171-a3a5-76b927541e21&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-terminology&#34;&gt;术语&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;2431446b-d46b-46d1-baad-d718dcd4ef1e&#34;,&#34;dropCap&#34;:false}&#34;&gt;&lt;strong&gt; SZFT&lt;/strong&gt;：单区故障容忍&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;24344de4-31a2-4468-a72d-66d5affba862&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;d97f5b1b-c277-4496-9fa0-047ad05bcab4&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-background&#34;&gt;​​背景&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;8de7f022-5e6c-4de1-b92b-82da803c634f&#34;,&#34;dropCap&#34;:false}&#34;&gt;Cassandra 天然支持数据的多个副本。拥有多个数据副本的最大好处之一是高可用性：如果少数副本不可用，大多数副本仍然可以访问。当 Cassandra 集群部署在多个可用区时，我们希望所有副本在理想情况下均匀分布在各个可用区中，这样对一个可用区的影响就不会影响用户请求。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;31d3be95-4092-4049-b767-eb4c022744af&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-块-分隔符有-alpha-通道-不透明度&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;width&#34;:&#34;700px&#34;,&#34;height&#34;:&#34;auto&#34;,&#34;align&#34;:&#34;center&#34;,&#34;hash&#34; :&#34;2cea3750-1b38-41c4-b6f8-8d34e8657bbf&#34;,&#34;alt&#34;:&#34;&#34;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img 解码=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent. com/docsz/AD_4nXcSTnDyAkLVo_Z0_2lEv-UqaswqOQAZup6hMZKsVASGPumgKy0uf5wCQdcYGmCaI2vFl0U-bVkUY8dz3hfPZATIx7Hzr-HbtdDc53mSvXCfAMUOWI8-kx3MghC73muhugYyr 71fk18Au-vNl8eGN5W5uFm9?key=AZe-MVriCM2tBK0R_Gauew&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34; wp-element-caption&#34;&gt;图 1：单区域故障和可用性影响。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;20fb85c8-ac12-44fb-92b6-67da7927088a&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;b16bb2b2-5305-4e3f-89b7-64e3a706b11b&#34;,&#34;dropCap&#34;:false}&#34;&gt;图 1 说明问题。在此示例中，复制因子为 3。当数据记录的大部分副本可用时，该数据记录被视为可用。当区域 1 关闭时，数据记录 1 将变得不可用，因为它丢失了大部分（两个）副本。但与此同时，数据记录 2 仍然可用，因为它恰好有少数（只有一个）副本放置在故障区域中。如果所有数据记录的副本都以与数据记录 2 相同的方式放置，其中&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;副本均匀分布在各个区域中，使得每个区域仅包含少数副本&lt;/strong&gt; ，那么任何一个可用区的故障都不会影响整体可用性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;3b088613-eab3-4e9c-924f-cab2781b86ca&#34;,&#34;dropCap&#34;:false}&#34;&gt;Cassandra 本身支持通过对节点进行逻辑分组的功能来分隔副本。然后副本按组分开。分组是通过名为 &lt;em&gt;cassandra-rackdc.properties&lt;/em&gt; 的文件完成的。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;1a8f3002-e385-400c-9536-18440e038d5d&#34;,&#34;dropCap&#34;:false}&#34;&gt;在此功能中，每个 Cassandra 节点都分配有两个属性：&lt;em&gt;dc&lt;/em&gt; 和 &lt;em&gt;rack&lt;/em&gt;。例如，区域 1 中的 Cassandra 节点将配置如下：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;f7b444cf-2440-4ceb-9242-0cfb4f2192ef&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;id&#34;:1090731,&#34;sizeSlug&#34;:&#34;large&#34;,&amp;quot;linkDestination&#34;:&#34;无&#34;,&#34;align&#34;:&#34;center&#34;,&#34;hash&#34;:&#34;2f30f93b-38f1-4da1-80a7-4ac554f07b0e&#34;,&#34;alt&#34;:&#34;&#34;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt; img 加载 =“惰性”解码 =“异步”宽度 =“1024”高度 =“377”src =“https://blog.uber-cdn.com/cdn-cgi/image/width=2160，质量=80， onerror=重定向，format=auto/wp-content/uploads/2024/06/cassandra-rackdc-1-1024x377.png&#34; alt=&#34;&#34; class=&#34;wp-image-1090731&#34; srcset=&#34;https://blog. uber-cdn.com/cdn-cgi/image/width=1024，quality=80，onerror=redirect，format=auto/wp-content/uploads/2024/06/cassandra-rackdc-1.png 1024w，https:// /blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/cassandra-rackdc-1.png 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768，quality=80，onerror=redirect，format=auto/wp-content/uploads/2024/06/cassandra-rackdc-1。 png 768w，https://blog.uber-cdn.com/cdn-cgi/image/width=1152，quality=80，onerror=redirect，format=auto/wp-content/uploads/2024/06/cassandra-rackdc -1.png 1152w“尺寸=”（最大宽度：1024px）100vw，1024px“referrerpolicy=“no-referrer”&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;7fcbecf9-cedf-44b5-9198-1466c53822fe&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;141a0703-68ef-4756-a663-280c3f3e3923&#34;,&#34;dropCap&#34;:false}&#34;&gt;复制时策略是 &lt;a href=&#34;https://cassandra.apache.org/doc/4.1/cassandra/architecture/dynamo.html#network-topology-strategy&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;&lt;em&gt; NetworkTopologyStrategy&lt;/em&gt;&lt;/a&gt;，在&lt;em&gt;dc&lt;/em&gt;内，&lt;strong&gt;对于任何数据记录，Cassandra 的副本放置算法会将副本放置到尽可能多的&lt;em&gt;机架&lt;/em&gt;上&lt;/em&gt;强&gt;。如下图所示：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;310ac262-65e9-42db-9af7-73869e5ed300&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;width&#34;:&#34;700px&#34;,&#34;height&#34;:&#34;auto&#34;,&#34;align&#34;:&#34;center&#34;,&#34;hash&#34; :&#34;4b273450-10bf-4b79-9cc1-1d4aa7cd9015&#34;,&#34;alt&#34;:&#34;&#34;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img 解码=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent. com/docsz/AD_4nXegRc24Cr4H85C9-HrRQ-xwAG1MIjpD5JJssb_oLn96JwP4lqx631rWoB5Vq_0vzWcCJmrOmFx5fLvimGURLmBi18tWM_LyYbngSsFq9oEJopiGCtpi1BxEsrVDHC2U U_7ADVBMbc457vFs1rkOXj81_Co?key=AZe-MVriCM2tBK0R_Gauew&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34; &gt;图 2：所需设置：按区域对节点进行分组。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;核心/分隔符&#34; data-wp-block=&#34;{“哈希”：“7c873913-1e5d-4dbe-bb28-ee53f21efa1a”，“不透明度”：“alpha-channel”}“class =“wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;f3d6bc04-a9db-4537-aa5e-fc29c32b97a4&#34;,&#34;dropCap&#34;:false}&#34;&gt;设置图 2（假设复制因子为 3）是所需的 SZFT（单区域容错）设置。无论哪个区域出现故障，其他区域中仍然会有两个健康的副本为任何数据记录提供读取和写入服务。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;cee7de72-24a5-4715-820e-1105e9b512c8&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;8001718d-3454-46d5-b978-672a211e47da&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-why-was-cassandra-at-uber-not-szft&#34;&gt;为什么 Uber 的 Cassandra 不是 SZFT&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;5827de2f-ffb2-439f-90bd-b1a8b1824771&#34;,&#34;dropCap&#34;:false}&#34;&gt;Uber 不是使用图 3 中的设置——我们根本没有利用“rack”属性。所有 Cassandra 节点都被分配了相同的机架属性“默认”值，导致该区域中只有一个唯一的机架值。无法正确分离副本，因为要分离副本，需要多个机架属性值。因此，大多数或可能所有副本都可以放置在同一个区域中，如下图所示：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;1ce859ad-c8d6-472d-a0e4-b27150790359&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;align&#34;:&#34;center&#34;,&#34;hash&#34;:&#34;50737eb5-593e-4692-a938-17c34ea8122d&#34;,&#34;alt&#34; ：&#34;&#34;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img 解码=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXfHvNOqIU6eb_3TL4Xjq32UOYUMe-vrXXI-ZriBakzeWwFkn2FuW-BUakKJAIujnE3tS8zljn1XXGk9w9pVglzfMur7NB8 PNxhlcGGHHRqQzy6ZeVFWoPG3QjRNZCoKlpHitu14Lg​​FXiBSvIpNaClZ6qHsn?key=AZe-MVriCM2tBK0R_Gauew&#34; alt =&#34;&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;图 3：Uber 的旧设置：单个唯一机架。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;f9c291a4-b5d8-4b5f-833d-aa3fbc694b80&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;a36f68e6-50aa-4c91-8139-248760bf08e4&#34;,&#34;dropCap&#34;:false}&#34;&gt;处于高位水平，求解Uber 面临的问题本质上意味着从单机架设置（如图 3 所示）过渡到采用基于区域的机架分配策略的多机架设置（如图 2 所示）。这一转变带来了多重挑战。让我们看看它们是什么以及我们在 Uber 如何克服它们。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;dcb7aee5-a584-4695-ae8e-e78756263a6c&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:1,&#34;hash&#34;:&#34;803bbc14-466f-4232-945f-e3bd44f7f148&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-challenge-1-in-place-transition-not-an-option&#34;&gt;挑战 1：就地转换不是一个选项&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;b365319c-ad0d-4155-ac47-ea64d2e51119&#34;,&#34;dropCap&#34;:false}&#34;&gt;事实证明&lt;将区域中的现有节点从单机架设置转换为多机架设置是不切实际的。这是因为，如果将与新机架关联的节点引入到现有的单机架节点设置中，它将立即使新成员成为热点。如前所述，Cassandra 的副本放置算法将副本放置到尽可能多的独特机架上。当节点将第二个机架引入 Cassandra 时，所有数据记录都会将一个副本放置到新机架上，即使其中只有一个节点！图4很好地说明了这个问题：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;241bb4ac-9167-4202-b585-dc701823c298&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;id&#34;:1090555,&#34;sizeSlug&#34;:&#34;large&#34;,&#34;linkDestination&#34;:&#34;none&#34;,&#34;align&#34;:&#34;中心”，“散列”：“43e1fb21-afc9-493b-bffd-0358b6422dcb”，“alt”：“”}“类=“aligncenter size-large”&gt;&lt;img加载=“惰性”解码=“异步”宽度= “1007”高度=“1024”src=“https://blog.uber-cdn.com/cdn-cgi/image/width=2160，质量= 80，onerror=重定向，format=auto/wp-content/uploads /2024/06/szft-blog-f4-1007x1024.png&#34; alt=&#34;&#34; class=&#34;wp-image-1090555&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width =1007，质量=80，onerror=重定向，格式=auto/wp-content/uploads/2024/06/szft-blog-f4.png 1007w，https://blog.uber-cdn.com/cdn-cgi/图片/宽度=295，质量=80，onerror=重定向，格式=auto/wp-content/uploads/2024/06/szft-blog-f4.png 295w，https://blog.uber-cdn.com/cdn -cgi/image/width=768，quality=80，onerror=redirect，format=auto/wp-content/uploads/2024/06/szft-blog-f4.png 768w，https://blog.uber-cdn。 com/cdn-cgi/image/width=1510，quality=80，onerror=redirect，format=auto/wp-content/uploads/2024/06/szft-blog-f4.png 1510w，https://blog.uber -cdn.com/cdn-cgi/image/width=1776,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f4.png 1776w&#34; 尺寸=&#34;(最大-width: 1007px) 100vw, 1007px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;图 4：将新机架引入单机架设置时出现热点问题。&lt;/figcaption&gt; &lt;/图&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;c722bf2c-4ae7-413d-867e-35281af4e864&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;f5b50da6-4305-482f-b65a-dc7c7dc5a5b0&#34;,&#34;dropCap&#34;:false}&#34;&gt;由于由于副本放置算法的限制，我们只剩下一个选项，在较高级别上看起来如下：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;ordered&#34;:true,&#34;hash&#34;:&#34;8094ae43-e636-4409-b07e-96330ae4593b&#34;,&#34;values&#34;:&#34; “}”&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;在同一区域内创建一个新的 Cassandra 环或 NetworkTopologyStrategy 中的新“dc”。新环是通过多机架设置创建的，以满足 SZFT 要求。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;通过 &lt;a href=&#34;https://cassandra.apache.org/doc 重建新创建的环/stable/cassandra/tools/nodetool/rebuild.html&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;从旧的实时环重建&lt;/a&gt;。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;通过将客户流量从一个环转移到另一个环，以透明方式交换新环与旧环。&lt;/李&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;移除旧环。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;7bc7bde9-ae24-4c8c-a6b7-7273321f4f32&#34;,&#34;dropCap&#34;:false}&#34;&gt;我们设置整个迁移遵循以下原则：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;fa1567e6-8471-40cb-ba85-3797dc9bfc06&#34;,&#34;ordered&#34;:false,&#34;values&#34;:&#34; “}”&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;客户零参与 - 我们的利益相关者不得参与或暴露于迁移（例如，更改服务逻辑、客户端代码或路由）&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;高可用性 - 迁移期间无需停机&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;维护预先存在的性能 SLO，例如延迟&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;回滚功能，以便我们可以在旧环和新环之间来回切换，作为紧急措施&lt; /里&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;d72209cb-bf37-4bba-bcb9-13bf56090f3e&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;c05fd87f-a68f-420e-bc70-6eec86ab7dd2&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-the-rebuild-procedure&#34;&gt;重建过程&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;17273b8c-c1ad-4f02-b207-ec110a0acf91&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-phase-1-provision-a-new-set-of-offline-multi-rack-nodes-in-the-region&#34;&gt;阶段 1：提供一组新的“离线”节点区域内多机架节点&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;c542c36c-5bac-4c84-a50a-4a13c99551dd&#34;,&#34;dropCap&#34;:false}&#34;&gt;在选定的区域，将新的节点环添加到集群中。分配给新节点的硬件资源（例如节点数、CPU 核心、内存、磁盘大小）需要与该区域中的现有环相同。将新节点均匀分布在各个区域中。通过配置每个节点的 &lt;em&gt;cassandra-rackdc.properties&lt;/em&gt; 文件，将它们与基于区域的策略分组，如下所示：&lt;/p&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;align&#34;:&#34;center&#34;,&#34;hash&#34;:&#34;13351642-4379-4fca-ade3-76c075a1d3e5&#34;,&#34;alt&#34; :&#34;&#34;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img 解码=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXcH74hsYf-WXgoNrypJz7LTOJWRLDvYZIIguWfE3jCblgpTyxzh28JN2ORfhR_odddRm1wXerjO-rUZj0A0qruZ6TXD xTHwvWHxBXnebkbT4fGIEfLhcEa5s9LsNCnzmWVoJ7gmv0t0MAhSgBAirKebyVxP?key=AZe-MVriCM2tBK0R_Gauew&#34; alt=&#34; “referrerpolicy =“no-referrer”&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;dfd9890d-56d6-4ee5-93ea-961bb9ffddad&#34;,&#34;dropCap&#34;:false}&#34;&gt;最后，所有新节点应使用 &lt;a href=&#34;https://cassandra.apache.org/doc/stable/cassandra/tools/nodetool/disablebinary.html&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;本机传输创建禁用&lt;/a&gt;以防止 CQL 连接到它们。这对于后续从现有环到新环的无缝流量切换至关重要。&lt;/p&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;id&#34;:1090556,&#34;sizeSlug&#34;:&#34;large&#34;,&#34;linkDestination&#34;:&#34;none&#34;,&#34;align&#34;:&#34;中心”，“散列”：“a093cbf1-7fb7-4aa4-b322-e097fb5623c9”，“alt”：“”}“类=“aligncenter size-large”&gt;&lt;img加载=“惰性”解码=“异步”宽度= “1024”高度=“729”src=“https://blog.uber-cdn.com/cdn-cgi/image/width=2160，质量= 80，onerror=重定向，format=auto/wp-content/uploads /2024/06/szft-blog-f5-1024x729.png&#34; alt=&#34;&#34; class=&#34;wp-image-1090556&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width =1024，质量=80，onerror=重定向，格式=自动/wp-content/uploads/2024/06/szft-blog-f5.png 1024w，https://blog.uber-cdn.com/cdn-cgi/image/width=300，quality=80，onerror=redirect，format=auto/wp-content/uploads/2024/06/szft-blog-f5。 png 300w，https://blog.uber-cdn.com/cdn-cgi/image/width=768，quality=80，onerror=redirect，format=auto/wp-content/uploads/2024/06/szft-blog -f5.png 768w，https://blog.uber-cdn.com/cdn-cgi/image/width=1262，quality=80，onerror=redirect，format=auto/wp-content/uploads/2024/06/ szft-blog-f5.png 1262w&#34;sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;图 5：第一阶段：提供一组新的禁用二进制的多机架节点。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;55ba8202-8606-42db-a101-766aa2dad5f5&#34;,&#34;opacity&#34;:&#34;alpha 通道&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;a9d92e66-3feb-4b57-8e47-a956de997fd8&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-phase-2-data-sync-for-live-writes&#34;&gt;阶段 2：实时写入的数据同步&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;99451c2d-2a9a-47db-b1ad-89faaf1e6b05&#34;,&#34;dropCap&#34;:false}&#34;&gt;作为我们的结束目标是让新环取代旧环，我们需要复制所有数据并存在于两个环中。这包括实时写入的数据以及历史数据。对于来自实时写入的数据，我们需要将新环添加到所有键空间的复制设置中，以便借助 Cassandra 的跨 DC 复制，它们可以开始间接接收实时写入。&lt;/p&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;id&#34;:1090732,&#34;sizeSlug&#34;:&#34;large&#34;,&#34;linkDestination&#34;:&#34;none&#34;,&#34;align&#34;:&#34;中心”，“散列”：“b6d4f985-4d8b-4576-9d1b-0c5bc080432c”，“alt”：“”}“class =“aligncenter size-large”&gt;&lt;img加载=“惰性”解码=“异步”宽度= “1024”高度=“381”src=“https://blog.uber-cdn.com/cdn-cgi/image/width=2160，质量= 80，onerror=重定向，format=auto/wp-content/uploads /2024/06/alter-keyspace-3333-1024x381.png&#34; alt=&#34;&#34; class=&#34;wp-image-1090732&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width =1024，质量=80，onerror=重定向，格式=auto/wp-content/uploads/2024/06/alter-keyspace-3333.png 1024w，https://blog.uber-cdn.com/cdn-cgi/图片/宽度=300，质量=80，onerror=重定向，格式=auto/wp-content/uploads/2024/06/alter-keyspace-3333.png 300w，https://blog.uber-cdn.com/cdn -cgi/image/width=768，quality=80，onerror=redirect，format=auto/wp-content/uploads/2024/06/alter-keyspace-3333.png 768w，https://blog.uber-cdn。 com/cdn-cgi/image/width=1118,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/alter-keyspace-3333.png 1118w&#34; 尺寸=&#34;(最大宽度: 1024px) 100vw, 1024px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&lt;/div&gt;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;id&#34;:1090557,&#34;sizeSlug&#34;:&#34;large&#34;,&#34;linkDestination&#34;:&#34;none&#34;,&#34;align&#34;:&#34;中心”，“散列”：“9135df85-dfb1-4042-81d1-613a49c2b509”，“alt”：“”}“类=“aligncenter size-large”&gt;&lt;img加载=“惰性”解码=“异步”宽度= “1024”高度=“720”src=“https://blog.uber-cdn.com/cdn-cgi/image/width=2160，质量= 80，onerror=重定向，format=auto/wp-content/uploads /2024/06/szft-blog-f6-1024x720.png&#34; alt=&#34;&#34; class=&#34;wp-image-1090557&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width =1024，质量=80，onerror=重定向，格式=auto/wp-content/uploads/2024/06/szft-blog-f6.png 1024w，https://blog.uber-cdn.com/cdn-cgi/图片/宽度=300，质量=80，onerror=重定向，格式=auto/wp-content/uploads/2024/06/szft-blog-f6.png 300w，https://blog.uber-cdn.com/cdn -cgi/image/width=768，quality=80，onerror=redirect，format=auto/wp-content/uploads/2024/06/szft-blog-f6.png 768w，https://blog.uber-cdn。 com/cdn-cgi/image/width=1253,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f6.png 1253w&#34; 尺寸=&#34;(最大宽度: 1024px) 100vw, 1024px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;图 6：第 2 阶段：在复制中包含新的节点集。&lt;/figcaption&gt;&lt;/figure&gt; &lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;d1bd50b8-60b7-41eb-b01a-d6e5c6419802&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;59ce3e71-3b3d-4137-ab38-44de16f17590&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-phase-3-data-sync-for-historical-data&#34;&gt;第 3 阶段：历史数据的数据同步&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;f59b9c48-c2f1-41c7-b67e-e58b7332b54d&#34;,&#34;dropCap&#34;:false}&#34;&gt;用于历史数据，我们需要让新环从旧环中传输它。尽管新节点现在正在接收实时写入，但它们仍然缺少过去的所有数据。 Cassandra 提供了一个工具，可以使用 nodetool重建命令来流式传输此类数据。需要在 &lt;em&gt;region1_new&lt;/em&gt; 的每个新节点上运行以下命令，以传输来自 &lt;em&gt;region1&lt;/em&gt; 的数据：&lt;/p&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;id&#34;:1090734,&#34;sizeSlug&#34;:&#34;large&#34;,&#34;linkDestination&#34;:&#34;none&#34;,&#34;align&#34;:&#34;中心”，“散列”：“5b44bf2e-a523-43d6-a2ca-de30b10f1fbc”，“alt”：“”}“类=“aligncenter size-large”&gt;&lt;img加载=“惰性”解码=“异步”宽度= “1024”高度=“138”src=“https://blog.uber-cdn.com/cdn-cgi/image/width=2160，质量= 80，onerror=重定向，format=auto/wp-content/uploads /2024/06/nodetool-rebuild-1024x138.png&#34; alt=&#34;&#34; class=&#34;wp-image-1090734&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/ nodetool-rebuild.png 1024w，https://blog.uber-cdn.com/cdn-cgi/image/width=300，quality=80，onerror=redirect，format=auto/wp-content/uploads/2024/06 /nodetool-rebuild.png 300w，https://blog.uber-cdn.com/cdn-cgi/image/width=768，quality=80，onerror=redirect，format=auto/wp-content/uploads/2024/ 06/nodetool-rebuild.png 768w，https://blog.uber-cdn.com/cdn-cgi/image/width=1112，quality=80，onerror=redirect，format=auto/wp-content/uploads/2024 /06/nodetool-rebuild.png 1112w“尺寸=”（最大宽度：1024px）100vw，1024px“referrerpolicy=“no-referrer”&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;align&#34;:&#34;center&#34;,&#34;hash&#34;:&#34;0d7b769d-7498-4d2c-b195-9804f3f9a1bd&#34;,&#34;alt&#34; :&#34;&#34;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img 解码=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXft9Qy90P61zHHyDGRk1L-IrXN866dHr8WMyGbEe-_05rtLUdE_171HSBDlkFowzOnG9Ka40w79XsIiT91h2md32ikN ehFv86ncC0xmN-G6aDa7S5yUS1eRhB_-sfHRy7veOzNTt0lSRc9FjuzEMpFDDD9D?key=AZe-MVriCM2tBK0R_Gauew &#34; alt=&#34;&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;图 7：第 3 阶段：同步旧数据。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;c85a1994-e788-449e-b314-f2d43b9ce04c&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;e2d1ad85-f797-4d28-a4b1-c8501a92d9b6&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-phase-4-traffic-switch&#34;&gt;第 4 阶段：流量切换&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;9be925b3-a119-4af6-bb79-ece136ee2b52&#34;,&#34;dropCap&#34;:false}&#34;&gt;历史之后数据已经流式传输，我们准备让 Cassandra 客户端连接到新的节点环并停止连接到旧的节点环。这是通过&lt;a href=&#34;https://cassandra.apache.org/doc/stable/cassandra/tools/nodetool/enablebinary.html&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;启用本机传输&lt;/ a&gt; 在新环中的所有节点上，然后 &lt;a href=&#34;https://cassandra.apache.org/doc/stable/cassandra/tools/nodetool/disablebinary.html&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;禁用旧环中所有节点上的本机传输&lt;/a&gt;。我们已经不再需要在客户端执行任何操作，其原因将在下一节中讨论，我们将看到我们在 Uber 所做的 Cassandra 客户端增强。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;e786234e-2d54-41ba-9ff9-510533cf9c09&#34;,&#34;opacity&#34;:&#34;alpha 通道&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;co重新/图像”data-wp-block=”{“宽度”：“700px”，“高度”：“自动”，“对齐”：“中心”，“散列”：“11e99c4b-be82-4521-9ac8-9640150d0621 &#34;,&#34;alt&#34;:&#34;&#34;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img 解码=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXf6wcyJD06iUE8_JWw81JUucwUyHl-xEeQRmUNftN2rLvtBeU0vgE53GWTIYQvWhGvMFM7Stbz4hUuu BGTpQX1qBDikqwrHNa__Y3tkcvdnoRk3MA3f97eyOHW0sXJahDq2I1PaxzPxcNet7SNYvVGpoNiP?key=AZe -MVriCM2tBK0R_Gauew&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;图 8：第 4 阶段：流量切换。&lt;/figcaption &gt;&lt;/图&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;06b8cced-4362-435e-bae3-a26771b778a2&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;c65f13f4-e2c6-4605-bf58-b71a9a56a80c&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-phase-5-remove-old-nodes&#34;&gt;第 5 阶段：删除旧节点&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;6aabb217-a3d9-4462-bf23-982607dbff4c&#34;,&#34;dropCap&#34;:false}&#34;&gt;首先，需要更改所有键空间的复制设置，以便旧环不再是数据复制的一部分。&lt;/p&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;id&#34;:1090735,&#34;sizeSlug&#34;:&#34;large&#34;,&#34;linkDestination&#34;:&#34;none&#34;,&#34;align&#34;:&#34;中心”，“散列”：“e5955543-fc53-4e83-8345-b7f3075c17c1”，“alt”：“”}“class =“aligncenter size-large”&gt;&lt;img加载=“惰性”解码=“异步”宽度= “1024”高度=“339”src=“https://blog.uber-cdn.com/cdn-cgi/image/width=2160，质量= 80，onerror=重定向，format=auto/wp-content/uploads /2024/06/Alter-keyspace-333-1024x339.png&#34; alt=&#34;&#34; class=&#34;wp-image-1090735&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width =1024，质量=80，onerror=重定向，格式=auto/wp-content/uploads/2024/06/Alter-keyspace-333.png 1024w，https://blog.uber-cdn.com/cdn-cgi/图片/宽度=300，质量=80，onerror=重定向，格式=auto/wp-content/uploads/2024/06/Alter-keyspace-333.png 300w，https://blog.uber-cdn.com/cdn -cgi/image/width=768，quality=80，onerror=redirect，format=auto/wp-content/uploads/2024/06/Alter-keyspace-333.png 768w，https://blog.uber-cdn。 com/cdn-cgi/image/width=1196,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Alter-keyspace-333.png 1196w&#34; 尺寸=&#34;(最大宽度: 1024px) 100vw, 1024px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;918a3fa8-869a-4608-84f5-6ea3614dd859&#34;,&#34;dropCap&#34;:false}&#34;&gt;一旦这是完成后，旧环中的节点退役。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;核心/分隔符&#34;data-wp-block=&#34;{&#34;hash&#34;:&#34;b9a9e310-db11-4ed5-9360-7697535fc833&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity ” &gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;width&#34;:&#34;700px&#34;,&#34;height&#34;:&#34;auto&#34;,&#34;align&#34;:&#34;center&#34;,&#34;hash&#34; :&#34;5a00a491-e698-481f-b0d5-f467b6dc803c&#34;,&#34;alt&#34;:&#34;&#34;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img 解码=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent. com/docsz/AD_4nXcDvHs74P1MCQgreqSpD_eOglh3jidW2ydJN4TthFJGd5BOMq6tTk-FE04jLk-LFacE1cRXKQGH6nvmXzP1FDpO7TiQefYYl8dhEV34zSMIZ1uPfQZu66743WCZrHkz3aloD sPF8qVOs_fZhgUM_TyoncnY?key=AZe-MVriCM2tBK0R_Gauew&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34; &gt;图 9：第 5 阶段：删除旧的节点集。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;2bb0dfc4-90fd-4d9d-93cb-0911117b0dc2&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;8c10f5cd-7b7e-4079-8526-49f4f2d7b3a3&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-phase-6-repeat-for-the-other-regions&#34;&gt;第 6 阶段：对其他区域重复&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;b6d9edbf-0438-41f0-bf95-5ed8b9965802&#34;,&#34;dropCap&#34;:false}&#34;&gt;Cassandra 集群所选区域现在是 SZFT。其他区域需要重复相同的过程。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;e083bdef-556a-48f0-98aa-5a89b24bb74d&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;171cb21c-d216-4dfe-9660-cf05b6590cbc&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-cassandra-client-enhancement&#34;&gt;Cassandra 客户端增强&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;1dca4857-15d6-43db-adce-9e74a2876528&#34;,&#34;dropCap&#34;:false}&#34;&gt;在上述期间过程中，不涉及客户端操作。这是因为在 Uber，我们有一个 GoCQL 和 Java 驱动程序的分支，我们对它们进行了增强，使其能够动态地将流量从一个环切换到另一个环，而无需重新启动。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;8023f66f-9c9c-4197-8940-3aa9f7b23f02&#34;,&#34;dropCap&#34;:false}&#34;&gt;为了实现无缝流量切换，对 Cassandra 客户端的期望是：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;ordered&#34;:true,&#34;hash&#34;:&#34;5afa16f1-8c7d-4306-b970-2b77b6776b4a&#34;,&#34;值&amp;quot;:&#34;&#34;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;始终从以下位置获得初始 Cassandra 接触点（即用于初始拓扑发现的 Cassandra 节点）：客户所在区域相同。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;始终从客户端所在的同一区域选择协调器节点。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;在启用本机传输并在新环上禁用本机传输后，自动连接到新环的节点旧环的节点，如重建过程的第 4 阶段。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;cb8bdfe0-6a4b-4bb0-b12c-1bde36b71eea&#34;,&#34;dropCap&#34;:false}&#34;&gt;要求 #1是通过一个新的微服务实现的，该服务致力于发布 Cassandra 集群的联系信息。它与我们的 Cassandra 控制平面集成，从而了解每个 Cassandra 集群的拓扑。该服务的使用者（在本例中为 Cassandra 客户端）发送仅包含目标 Cassandra 集群名称的请求。该服务返回属于集群&lt;strong&gt;且与消费者位于同一区域&lt;/strong&gt;的所有节点的联系信息（例如，IP 和端口）。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;53df3941-e5cd-4cf5-a1da-83eb75c79101&#34;,&#34;dropCap&#34;:false}&#34;&gt;以上逻辑对客户端 API 是隐藏的，我们的 Cassandra 用户只需更改为客户端提供联系点的方式，如下所示：&lt;/p&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;id&#34;:1090736,&#34;sizeSlug&#34;:&#34;large&#34;,&#34;linkDestination&#34;:&#34;none&#34;,&#34;align&#34;:&#34;中心”，“散列”：“699f2caf-abaa-4db0-a1f2-d9a3f415dc64”，“alt”：“”}“类=“aligncenter size-large”&gt;&lt;img加载=“惰性”解码=“异步”宽度= “1024”高度=“91”src=“https://blog.uber-cdn.com/cdn-cgi/image/width=2160，质量= 80，onerror=重定向，format=auto/wp-content/uploads /2024/06/Cluster-builder-1024x91.png&#34; alt=&#34;&#34; class=&#34;wp-image-1090736&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024 ，quality=80，onerror=redirect，format=auto/wp-content/uploads/2024/06/Cluster-builder.png 1024w，https://blog.uber-cdn.com/cdn-cgi/image/width= 300，质量= 80，onerror =重定向，格式= auto/wp-content/uploads/2024/06/Cluster-builder.png 300w，https://blog.uber-cdn.com/cdn-cgi/image/width =768，质量=80，onerror=重定向，格式=auto/wp-content/uploads/2024/06/Cluster-builder.png 768w，https://blog.uber-cdn.com/cdn-cgi/image/宽度=1302，质量=80，onerror=重定向，格式=自动/wp-content/uploads/2024/06/Cluster-builder.png 1302w“尺寸=”（最大宽度：1024px）100vw，1024px“referrerpolicy=”无推荐人&#34;&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;核心/段落&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;53df3941-e5cd-4cf5-a1da-83eb75c79101&#34;,&#34;dropCap&#34;:false}&#34;&gt;要求 2 是通过我们在 Uber 在 Cassandra 客户端中实施的新主机过滤器完成的。这个新的主机过滤器排除了位于客户端远程区域的所有协调器节点。&lt;/p&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;id&#34;:1090737,&#34;sizeSlug&#34;:&#34;large&#34;,&#34;linkDestination&#34;:&#34;none&#34;,&#34;align&#34;:&#34;中心”，“散列”：“a830e016-1133-47a6-bf87-9d28e3b6ec7b”，“alt”：“”}“类=“aligncenter size-large”&gt;&lt;img加载=“惰性”解码=“异步”宽度= “1024”高度=“105”src=“https://blog.uber-cdn.com/cdn-cgi/image/width=2160，质量= 80，onerror=重定向，format=auto/wp-content/uploads /2024/06/HostFilterPolicy-1024x105.png&#34; alt=&#34;&#34; class=&#34;wp-image-1090737&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality =80，onerror=重定向，format=auto/wp-content/uploads/2024/06/HostFilterPolicy.png 1024w，https://blog.uber-cdn.com/cdn-cgi/image/width=300，quality= 80，onerror=重定向，format=auto/wp-content/uploads/2024/06/HostFilterPolicy.png 300w，https://blog.uber-cdn.com/cdn-cgi/image/width=768，quality=80 ,onerror=重定向,format=auto/wp-content/uploads/2024/06/HostFilterPolicy.png 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1290,quality=80, onerror=redirect,format=auto/wp-content/uploads/2024/06/HostFilterPolicy.png 1290w&#34;sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&lt; /div&gt;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;64649522-f053-4d5c-8da2-601abe88fa8e&#34;,&#34;dropCap&#34;:false}&#34;&gt;要求 #3通过指定负载均衡策略为TokenAware + RoundRobin来实现。真正重要的不是这些策略的使用，而是消除 DCAwarePolicy 的使用。 DCAwarePolicy 曾经出现在 Uber 的许多 Cassandra 应用程序中，它将协调器节点选择固定到旧环。开源客户端已经能够及时捕获与本机传输相关的更改，自动断开与禁用本机传输的节点的连接并自动连接到新启用本机传输的节点。因此，我们需要做的就是允许客户端连接到同一区域中的任何环。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;f63648b9-e4f6-4c52-bfd8-ed8ac6de4cb8&#34;,&#34;dropCap&#34;:false}&#34;&gt;最后，我们在 Uber 标准化了 Cassandra 客户端配置，如下所示：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;id&#34;:1090738,&#34;sizeSlug&#34;:&#34;large&#34;,&#34;linkDestination&#34;:&#34;none&#34;,&#34;hash&#34;:&#34; afa165bc-ce7b-40fc-8755-707011ddc4c7&#34;,&#34;alt&#34;:&#34;&#34;}&#34; class=&#34;wp-block-image size-large&#34;&gt;&lt;img 加载=&#34;lazy&#34; 解码=&#34;a同步”宽度=“1024”高度=“337”src=“https://blog.uber-cdn.com/cdn-cgi/image/width=2160，质量= 80，onerror=重定向，format=auto/wp -content/uploads/2024/06/HostFilter-and-Clusterbuilder-1024x337.png&#34; alt=&#34;&#34; class=&#34;wp-image-1090738&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi /image/width=1024，quality=80，onerror=redirect，format=auto/wp-content/uploads/2024/06/HostFilter-and-Clusterbuilder.png 1024w，https://blog.uber-cdn.com/ cdn-cgi/image/width=300，quality=80，onerror=redirect，format=auto/wp-content/uploads/2024/06/HostFilter-and-Clusterbuilder.png 300w，https://blog.uber-cdn .com/cdn-cgi/image/width=768，quality=80，onerror=redirect，format=auto/wp-content/uploads/2024/06/HostFilter-and-Clusterbuilder.png 768w，https://blog。 uber-cdn.com/cdn-cgi/image/width=1308，quality=80，onerror=redirect，format=auto/wp-content/uploads/2024/06/HostFilter-and-Clusterbuilder.png 1308w“尺寸=” （最大宽度：1024px）100vw，1024px“referrerpolicy =“no-referrer”&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;d13ccf86-6323-4320-a12f-38966090aea7&#34;,&#34;dropCap&#34;:false}&#34;&gt;这些增强功能客户端优雅地将用户与 Cassandra 集群的低级拓扑细节分离，例如 IP、端口、dc（如 NetworkTopologyStrategy 中）等。它为重建过程第 4 阶段的无缝流量切换铺平了道路。此外，基于区域的协调器选择与“LOCAL_QUORUM”读写相结合，可确保在一个区域的重建过程中，其他区域的 Cassandra 客户端不会受到任何影响，因为它们始终直接与其他区域的 Cassandra 节点交换数据。他们当地的区域，允许逐个区域的 SZFT 过渡。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;e6638124-5a65-43fb-960c-4dcd83b0d3c5&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:1,&#34;hash&#34;:&#34;21ab4486-37ee-4594-a963-77246bfe6045&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-challenge-2-nbsp-lack-of-uniform-spare-server-capacity-across-zones&#34;&gt;挑战 2：跨区域缺乏统一的备用服务器容量&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;8d569cb2-ac03-4406-92cc-a7cdf09cfa9f&#34;,&#34;dropCap&#34;:false}&#34;&gt;对于多- 机架设置，其中每个 Cassandra 机架都是一个区域，我们需要确保始终有足够的可用区域（即区域数量≥replication_factor）。另外，集群扩容时，各个可用区的备用容量需要统一，以便各个机架等量扩容。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;c53bdf23-33c3-45aa-851c-2b1285a00629&#34;,&#34;dropCap&#34;:false}&#34;&gt;这可能会出现在集群规模较小且缩放量较小的情况下，挑战性较小需求量很小，或者所有区域的闲置产能都有更强有力的保证。然而在实践中，可用容量很可能不均匀地分布在各个区域中。在这种情况下，执行集群的潜在紧急水平扩展将不可避免地导致牺牲集群的 SZFT 属性。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;9da57313-7bdd-4177-a093-d742ceb324e8&#34;,&#34;dropCap&#34;:false}&#34;&gt;无论容量情况下，我们应该做好处理这种情况的准备。当SZFT属性和对水平扩展的迫切需求无法同时满足时，我们必须通过水平扩展来优先考虑集群的即时性能需求。重要的是要记住，一旦额外的容量最终到达其他区域，我们应该能够以最少的节点替换数量将扩展过程中添加的节点“重新定位”到所需的区域，最终实现 SZFT。整个流程对操作要求很高，需要精细化的自动化来大幅减少人工。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;4ea136ad-bb51-4dbd-bb80-9dd7b1a25a13&#34;,&#34;dropCap&#34;:false}&#34;&gt;我们不是我们将在本博客中详细阐述这一挑战，因为它涉及服务器容量管理方面。得益于运行我们底层存储管理和控制平面平台的&lt;em&gt;有状态平台&lt;/em&gt;团队，Uber 确保准备好以完全自动化的方式应对此类场景。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;644a0056-674f-4a88-a1e9-25b7190d63b3&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;8fec6c26-c92d-4819-aebc-6b735d32f312&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-highlights&#34;&gt;亮点&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;ec4afdb3-1091-4066-9ee9-3f0d9292df3e&#34;,&#34;dropCap&#34;:false}&#34;&gt;成功该关键项目的衡量标准如下：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;ordered&#34;:true,&#34;hash&#34;:&#34;2e3f35e9-e450-4b32-bf05-d9242d9ebe4a&#34;,&#34;values&#34;:&#34; “}”&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;绝大多数 Cassandra 队列已完成部署。推出后的几个月里，没有发现任何问题。 &lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;推出期间未发生重大事件。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;整个过程对我们的利益相关者来说是完全透明的。 &lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;我们进行了多次测试，几乎瘫痪了整个生产区，而 Cassandra 的利益相关者没有受到影响！&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;8f01d5e8-18b4-42ab-88e9-e8f5889107a9&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:1,&#34;hash&#34;:&#34;01a2d6cf-39f7-4607-8f6a-4e30019cc229&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-conclusion&#34;&gt;结论&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;3cfe4f93-9652-4f6d-9bc0-0d4eedc7c3c2&#34;,&#34;dropCap&#34;:false}&#34;&gt;在本文中，我们展示了 Cassandra 在 Uber 的部署。我们还强调了实现单区容错的挑战，并深入研究了解决方案。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;fontSize&#34;:&#34;小&#34;,&#34;hash&#34;:&#34;c67767ae-c3de-43f5-b72e-4960a271ebf5&#34;,&#34;dropCap&#34; :false}&#34; class=&#34;has-small-font-size&#34;&gt;&lt;strong&gt;封面照片归属&lt;/strong&gt;：此图片是使用 ChatGPT 生成的。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;fontSize&#34;:&#34;小&#34;,&#34;hash&#34;:&#34;6fd34c76-0a77-427f-b89c-eb366e6d8379&#34;,&#34;dropCap&#34; :false}&#34; class=&#34;has-small-font-size&#34;&gt;Apache® 和 Apache Cassandra® 是 Apache Software Foundation 在美国和/或其他国家/地区的注册商标或商标。使用这些标记并不暗示 Apache 软件基金会的认可。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;fontSize&#34;:&#34;小&#34;,&#34;hash&#34;:&#34;bc71ef0b-63c9-4699-b17a-379b441aabb7&#34;,&#34;dropCap&#34; :false}&#34; class=&#34;has-small-font-size&#34;&gt;Oracle、Java、MySQL 和 NetSuite 是 Oracle 和/或其附属公司的注册商标。其他名称可能是其各自所有者的商标。&lt;/p&gt;</description>
      <pubDate>Thu, 20 Jun 2024 07:33:46 +0000</pubDate>
    </item>
    <item>
      <title>【Flaky Tests Overhaul at Uber】Uber 的不稳定测试大修</title>
      <link>https://www.uber.com/blog/flaky-tests-overhaul/</link>
      <description>【&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;5b1d7fc2-0941-47d4-b05f-3f7ece51b42b&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-introduction&#34;&gt;Introduction&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a42c8831-8676-46cf-ad64-9036fad21220&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;A few years ago, we started &lt;a href=&#34;https://www.uber.com/en-US/blog/handling-flaky-tests-java/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;tackling flaky tests&lt;/a&gt; in an effort to stabilize CI experience across our monorepos. The project first debuted in our Java monorepo and received good results in driving down frictions in developers’ workflow. However, as we evolved our CI infrastructure and started onboarding it to our largest repository with the most users, &lt;a href=&#34;https://www.uber.com/blog/how-we-halved-go-monorepo-ci-build-time/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Go Monorepo&lt;/a&gt;, the stop-gap solution became increasingly challenging to scale to the scope.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;4d9e159d-c250-40a5-a4cf-590ce4ee5a4c&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-visibility&#34;&gt;&lt;strong&gt;Visibility&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;67dd1537-7100-4d7b-ba4f-bb1a680c9f61&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;201aa385-5e2f-455f-b51a-0c7d17cad286&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The legacy service had an analyzer built-in, which categorizes tests based on a window of historical test runs. However, most of the time it works in a sandbox with little visibility into details, like what history it has examined for a test, what the reason was behind a decision, or additional information about a test. Thus, often some tests were miscategorized but we didn’t know why and had to manually recategorize.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;b2e7d91b-b0b6-408b-97d9-a63b5b40caf4&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-customization&#34;&gt;&lt;strong&gt;Customization&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;07ee5689-fa0c-4e7f-8b0c-6f92371b51a8&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;aa80c6ff-59a6-41d3-829e-28cce84d3de0&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;It also has little extensibility of supporting different strategies to categorize tests. It only supports the sliding window strategy to categorize tests. The legacy test model is specifically tailored to Java, assuming inputs like test suites, parameters, annotations, etc., which are not always available in other languages.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;962ac64d-c01e-4074-9e38-5807e8273eac&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-complexity&#34;&gt;&lt;strong&gt;Complexity&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;88c5370b-4301-4808-a021-0ebc6e3119a6&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2348812e-5754-484d-9822-c2a57b61d50d&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The “serial” and “parallel” concepts add additional logic on each monorepo’s CI side to respond differently. Also, because it encapsulates many scenarios–categorize, transition, recover in CI, notifications, etc. – complexity greatly increases when it needs to be both generic enough to accommodate each repo and effective enough to not miss any flakiness.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;e4ccc2b6-3d69-4e9d-9b4b-932dfd327a69&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-actionability&#34;&gt;&lt;strong&gt;Actionability&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8f430a58-09d6-4e9e-a17d-b2db0ccfe354&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a7be3b0d-9c65-46f4-a77a-7e6f9a389de6&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;At the time we hadn’t reached consensus as to how ownership was defined across repositories. So we ended up with a lot of flaky tests being ignored in CI, but with no accountable tracking.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d734d4df-7598-4736-a946-e3ffc2cc6abb&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;070ae3cd-03c6-46bc-9a1b-28e23b9b68ba&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-the-big-picture&#34;&gt;The Big Picture&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c3fcafa2-59dc-4e77-9d4a-0bb2a76aa3d0&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;At Uber, we run extensive sets of tests in our CI pipelines at various development stages. On a typical day, we validate 2,500+ diffs (code changes, a.k.a. pull requests) per day and run over 10k+ tests per diff on average. Our ultimate goal is to make sure developers have confidence in the main branch by &lt;a href=&#34;https://www.uber.com/blog/research/keeping-master-green-at-scale/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;keeping it always green&lt;/a&gt;. Flaky tests undermine the reliability of our CI pipeline, leading to chaos in developer experience–one bug becomes more bugs.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f2c986c7-44c3-4e21-9240-b3d59c0b4f33&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Furthermore, with our &lt;a href=&#34;https://www.uber.com/blog/bypassing-large-diffs-in-submitqueue/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;SubmitQueue speculation&lt;/a&gt; architecture, failing a revision can have cascading effects invalidating other revisions in the queue and causing blockage. This gets worse when there’s cross-cutting change that affects the entire repository and triggers all tests, which will be a nightmare to land a code change. This may lead to developers constantly retrying their builds until the build becomes green, wasting engineering hours and CI resources.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1f7300c8-63c1-4c0b-b63e-589e3dfaf376&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;It became an urgent need to develop an effective, scalable, and configurable system that can be easily adopted and responsive to thousands of tests’ state changes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b12b6b0d-9d0e-4e1d-a86b-ed3e86680e04&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a6d1f0dc-48f2-4538-b83e-1278aac25e13&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-introducing-testopedia&#34;&gt;Introducing Testopedia&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0765bf8a-e41f-4629-adef-5262b70747db&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We need to obtain visibility over all the tests that we run in Uber to validate users’ changes. This visibility includes reliability characteristics (i.e., flakiness control) and performance characteristics (i.e., latency control). Thus we need a centralized system to track all our tests and provide enough context to CI or any other consumers to make decisions with regard to these tests. We isolated these responsibilities to a standalone service, Testopedia.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;a8ab55a4-6796-4a48-bda1-0d4edeeae189&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-design-overview&#34;&gt;Design Overview&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6964c0e2-c3ac-4238-b231-7e4f98fa0ec7&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Testopedia sits in our CI infrastructure between reporting and consumers, as below:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5962396c-b43c-4c26-9cf4-489a5fc546eb&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;0a694a21-5c73-49c7-b534-18179b888cca&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXfgB7JBfGgSObLdUa7d6nIlquv_YK9ctd5SfEZbKGIsvHozIPyvlh4Tt3vZAQSW5WmiH4xkalc01ZcY_cOTyFHtbFa2gcuyIp-oWqoWRcLQ-5vlSW-rjSFBJyh4u2YqUmd_LItqVcMO_-WekoYw0-sTqTua?key=6gZ2dLlV7xzsqb0CRMkSGA&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 1: Example Pipeline.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5a86a100-3f44-4e82-af3a-9c03d392b981&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;eda85819-74c8-4688-9583-79bf035af068&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-what-it-does&#34;&gt;What it does&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;758ab9c3-3078-4003-a0c7-edf4638d7840&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Instead of having Testopedia handle all aspects of flaky tests, we decided to make it language/repo-agnostic. This means the service doesn’t care what kind of test it is, whether it’s a test suite or test case, how the name is formatted, how it’s reported, how it’s handled in CI, etc. It simply operates on “test entity,” which is the minimal fundamental unit in the system and is uniquely identified by a “fully qualified name” (FQN). Additionally we introduced a grouping concept for the FQNs–realm, which encapsulates all tests under a specific usage domain, such as Golang unit tests, Java unit tests, Docker integration tests, etc. Realms are owned by specific platform teams and each team can construct FQN to their own liking.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;56506c54-9463-4fdc-8369-435b41594c0b&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Next, on a high level, we assign 3 function domains to the service:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2f1571b6-f23e-468a-9389-387fea6e0f63&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Read&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;946fc163-8194-468a-9de8-1f15edf9180d&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Retrieve individual test’s stats, including flakiness state, reliability, staleness, aggregated execution time, historical run stats and other metadata if any.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Retrieve a groups tests’ stats, a list of the above.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Retrieve the state changes for a test.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b1454898-28cc-42a1-b6de-f3e7616a2821&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Write&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;14f17714-3c2b-4124-bab2-24fcc7175cf9&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Upload the test running results to the system.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;It could be in a form of file or streaming but need to follow a predefined schema.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Administrative operations to disable/enable/delete certain tests in the system.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;49cae938-ade8-400f-9766-28c1241983c8&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Notify&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;bfd428e6-a496-490b-8a5f-54e94a17e8f2&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Whenever a test becomes unhealthy, we need to trigger a JIRA ticket with deadline assigning to the owning team.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b1a9e321-30e0-45b3-856e-2ac7813fa207&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;30132e1f-3999-49c9-81dd-8368e6e91914&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;c2c8d4b6-d229-4825-8490-912d254eb357&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-how-it-works&#34;&gt;How it works&lt;/h3&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;width&amp;quot;:&amp;quot;700px&amp;quot;,&amp;quot;height&amp;quot;:&amp;quot;auto&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;1c81923a-4178-4db3-bc7e-08e62953b17c&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXdQvxdjfAvik1VtI7t-b2HiGn1Wk5CeNvZFhe2QBoHN7S_Bsid3wZV-fKRW3SLudKuP0KfcIA4vQDi0zd8txYN95hqLVktKT7tMjp2tcIS5Pg8-XCT_yaM5Vef7MeQm0_Wh8mnXKySoP93kE0Hxm-DKKe4?key=6gZ2dLlV7xzsqb0CRMkSGA&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 2: Testopedia Architecture Diagram.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8436349b-0d8c-42f0-bff7-724b3ce01180&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;dc4cf4a0-f6b9-4ae3-8a0a-f15eb4eaafed&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Testopedia works over historical data to infer if a test is healthy or not. But rather than fixating on the periodic job, Testopedia accepts all test data sources, regardless of whether it’s from periodic or regular validation jobs. Each report will be tagged with their source accordingly. Then every analyzer will have access to all this information and will take different strategies to respond to them (more on “analyzer” later).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;be1766aa-1ee4-4beb-8201-bd9cfb56264a&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;After analyzer is done with running analysis on a test, a result is materialized into storage for querying later and depending on the result, a ticket will be filed to the test’s owning team, following the realm’s grouping rule (more about this in Notification).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e7381254-3570-4921-9604-70bfac13b4de&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Note that from analyzer to ticketing, every strategy is extensible and configurable outside of Testopedia’s core logic, granting maximum customizability to realm owners.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a1395b47-041d-43a6-96dc-961f52ae0914&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3053ee68-48f9-4368-bb05-93127327e049&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-implementation-highlights&#34;&gt;Implementation Highlights&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;d4d593dc-2acb-4865-a56b-5bb85f3e3b72&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-fully-qualified-name-fqn&#34;&gt;&lt;strong&gt;Fully Qualified Name (FQN)&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6896c21e-14dd-476f-9d1f-23d0e4a032f5&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e81252e0-0ca8-4da8-9ae1-26e84aeb7479&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The key part of Testopedia design is the ability to address every test we execute at Uber with a unique string identifier named Fully Qualified Name, or short FQN. The system only needs to focus on analysis and bookkeeping of FQNs and leave handling implementation to each platform of their own, without having to know any details of each testing framework.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;871b59f7-c060-4d91-ac71-0850528f4475&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;All tests are grouped into &lt;em&gt;realms&lt;/em&gt;. Realm name starts the FQN string and represents a broader domain which tests belong to. An example of a realm is “golang.unit_test” or “android.integration_test”.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;26c67707-464c-43f4-92a7-273e5b1d0882&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;As an example of a valid FQN under the “Golang unit test” realm, we can put together a string that looks like this:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2d6e29bd-e362-401a-a0a1-7e6bb195396c&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;eaf64e5e-f666-4ef8-9163-02ae120b31b5&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXdwZlzY61MzQ6qnqQP7nlyAoUcTSIcRFIUVgDPADDe9qg0Z6o2zvD-N2KVItlya7T7SAA7KlAUouQJ0p6gGVIyWmw1wyM5DyfFtIQPggGE8hUtL9za1BNIT9WjvH32gPt4yWoNyBo5tiSs3DLsyXtyBqCM?key=6gZ2dLlV7xzsqb0CRMkSGA&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 3: Example of a Fully Qualified Name.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6fa34453-30c1-44a3-8c8c-d9c9952bfa7f&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c24c8da4-49d2-4bb0-b5ec-3d407b4351af&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The entire FQN can be customized to whatever format by the realm owner. It is typical to model the identifier after the file system structure where the test code is located. Not surprisingly, FQN looks very much like an Internet URL as it serves the similar purpose of identifying the resource uniquely.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;58aad72f-ed36-411a-af12-950dd6158c27&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-finite-state-machine-fsm-model&#34;&gt;&lt;strong&gt;Finite State Machine (FSM) model&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0fade6a9-f16e-434a-b939-0d73cbf09613&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;152a4ee0-9f7a-44a5-8499-cf4138769350&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Testopedia leverages a robust finite state machine implementation to capture and record the transactional states of tests. A test entity is permitted to transact between the following states: new, stable, unstable, disabled, and deleted.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;490e20b6-f7ca-4aeb-9544-f06b16c9fa9c&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;0be4f426-2ef8-4709-b005-04e98f23bfc9&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXcXC3fSUSBxx6UimzGX5-eCWvAIxT8GjmpP1o7M-BtFAxVQaTipK4mEkvNUNglokw3lhVe07hG2qNVUy2t5OlVE8FpsrTj2bkmOaF2aj977cXflVwvBBCTFOONK_VLgejYZVyHmY4783oVBCRbyLd1kBNPf?key=6gZ2dLlV7xzsqb0CRMkSGA&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 4: Testopedia State Machine.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4de603cd-95fd-49f2-8fca-c927c925fb6c&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b3e8dbf0-22a2-4743-b29a-f98773239481&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Each state can customize its own enter and exit action. For example, when FSM enters an unstable state, an action is fired to file a JIRA ticket; when FSM enters a stable or deleted state, the associated JIRA ticket is closed.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5dba5a5f-7980-4a75-9cdc-d5355bff14d1&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Sticking with FSM design, we were able to save on boilerplate code which we otherwise would have to write and support.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6c7a447d-5211-4353-a186-8eb9e477533d&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;6fb31f02-f9f5-4cea-ba27-477f089995bf&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-scalability&#34;&gt;&lt;strong&gt;Scalability&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f0f7ff33-ea10-45d0-b527-b7020c8c165b&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;1fe1c6c2-e4b4-48aa-b4e7-dc000192db31&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXf_fs9-Fg36HOnQqalDoe134ZcOVaRT4vbMCEdBG1aRd7-OZ8Sff4CP9oRkvptXWULIw2gbhfg4QHiw4R2hBBHXZ_U_Qh6wV4-iKvi9GOofM0jaoKSAxwSJ1FGEl8KWd9u-OP9QyO4N5qudDX_U7EMzxBgJ?key=6gZ2dLlV7xzsqb0CRMkSGA&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 5: Example of Data Streaming Through the Thread Pool.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d8e1dbf9-42fa-4400-996f-b494f3b91231&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e5743409-1159-40d1-9faa-19e7d97b7f66&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In order to maximize efficiency, we opted to implement the import API using gRPC streaming instead of asking users to upload large chunks of data. On top of this, we also implemented thread pooling to consume the data stream. This not only allows for more manageable data transmission over long-lived connections, but also ensures better resource utilization through parallel processing on both client and server sides.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;11524d4f-88ec-4aeb-b71f-5e58068dfbf8&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Furthermore, we designed the backend database with scalability in mind, by allowing flexible partitioning, so that more complex read scenarios are supported (more about this in the next section).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;e6556bc4-f4f5-4fd9-922e-f00fe7e46ba8&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-cone-queries-and-dynamic-partitioning&#34;&gt;&lt;strong&gt;Cone queries and dynamic partitioning&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;81a75136-8e93-4f9f-b087-e198c5e47784&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;52f1cedc-a851-4aed-8725-37cc54968ee7&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Because flaky tests will be heavily queried by CI, it’s a natural requirement to support query by prefix, such as “golang.unit/src/uber.com/infrastructure/*”, which in the Testopedia API model is called a &lt;em&gt;cone query&lt;/em&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;efabc307-ec24-4b55-8f26-dcad36807474&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In a very common Monorepo setup, CI builds are executed as multiple parallel jobs, divided by similar path prefixes. Thus each CI job is only interested to know about flaky tests under a specific repository folder, but not all of them.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d0e8a448-ece6-43a1-bbfd-aff69e75300f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;As we track millions of tests, iterating through the entire database to find a prefix match is not performant. We naturally think of sharding, however, we don’t want to just shard on a fixed length of prefix, because the cone query can come with any length, such as “golang.unit/a/b/c/*”, “golang.unit/a/b/*”, “golang.unit/a/*”, etc. To do this efficiently, we implemented a flexible bucketing algorithm:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2bf1e890-4170-4c21-a511-fa1e4b770e95&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;bc9324ad-c4e4-44f8-9834-ac8efbe48b83&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;WRITE:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;834e6d2b-87be-4028-870a-258cbb825418&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;When a new FQN arrives in the system, say “golang.unit/a/b/c/d:test”,&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;First we randomly generate an integer bucket ID for it, say 10&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Then we strip the realm and identify the first 3 prefixes: &#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;[a/b/c, a/b, a]&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;(3 here is a configurable value for depth, just an example)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;dabcc505-21fc-4771-9af2-07df19f0d81a&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Next we store the bucket ID along with all prefixes in a separate table by appending it:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8160c0c9-ec4b-466a-8533-95b9c5a994bc&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure data-wp-block-name=&#34;core/table&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ed05e1a0-3d3e-4cb6-868b-f723e9e7a786&amp;quot;,&amp;quot;hasFixedLayout&amp;quot;:false,&amp;quot;head&amp;quot;:[],&amp;quot;body&amp;quot;:[],&amp;quot;foot&amp;quot;:[]}&#34; class=&#34;wp-block-table&#34;&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;Prefix table&lt;/td&gt;&lt;td&gt;Before inserting (existing bucket IDs created by other FQN)&lt;/td&gt;&lt;td&gt;After inserting&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;a/b/c&lt;/td&gt;&lt;td&gt;[]&lt;/td&gt;&lt;td&gt;[&lt;strong&gt;10&lt;/strong&gt;]&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;a/b&lt;/td&gt;&lt;td&gt;[2]&lt;/td&gt;&lt;td&gt;[2, &lt;strong&gt;10&lt;/strong&gt;]&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;a&lt;/td&gt;&lt;td&gt;[2, 3]&lt;/td&gt;&lt;td&gt;[2, 3, &lt;strong&gt;10&lt;/strong&gt;]&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;In the above example FQNs prefixed with “a/b” must be under bucket 2 or 10.&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3d90f91a-ae11-4915-a96a-f425fcdda7f6&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;becdd565-7f4f-48c6-93ba-fb4dae60b936&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Finally we store the bucket ID along with the FQN itself in a separate FQN table that’s partitioned by bucket ID&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote data-wp-block-name=&#34;core/quote&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5a3eedb8-b433-451f-a60f-96de47fed1a5&amp;quot;,&amp;quot;value&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;wp-block-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;# FQN table&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;golang.unit/a/b/c/d:test, 10&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;054baf9c-c398-4bb9-803c-937393057a5c&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Potentially different buckets can persist into different database servers, making the setup almost infinitely scalable&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e0fb0567-a706-4231-8360-5e97cf6904d9&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;51cfbdc1-1b53-43bf-be3d-e2fadcfed45f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;READ:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;faa0f070-0ad4-406a-a70a-7b35e1ac4fca&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;When we issue a cone query, say “golang.unit/a/b/*”&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;We first locate the realm “golang.unit” then locate the prefix “a/b”&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Then we refer the the partitions table and get all the bucket IDs [2, 10]&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Then we can quickly look up FQN table for records with bucket ID 2 or 10; the read should be very fast since it’s partition key; we can also execute such lookups in parallel&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Finally we iterate through selected records and filter our those that meet query requirement&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9033570a-122a-4183-bb96-5285b9716b96&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b5e8477d-578e-4541-ba29-20933415487b&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Note that the depth of path for which we keep track of bucket IDs is a predefined value in config. So that for longer queries, such as “golang.unit/a/b/c/d/e/*”, we stop at the maximum depth “a/b/c” and read all records with bucket ID 10.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d0f63b8a-f840-406b-b9e5-310800b9ffc3&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;This way we can significantly reduce the number of records to read from DB. Furthermore, each realm can configure their own depth and number of buckets according to their query patterns. Because bucket IDs are dynamically generated rather than dependent on static input, it helps with distributing the data more evenly across buckets, regardless of their physical location in the repository.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;df4f36fd-5e26-4953-a8eb-9f17c17ff051&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;This design realizes an important benefit: a very traditional relational database, like MySQL in multi-sharded configuration, can be used to power the storage backend and execute complex cone queries with sub-second latency.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;f74a3378-7798-47fa-822e-eaf57a6762f9&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-data-agnostic-ingestion&#34;&gt;&lt;strong&gt;Data-agnostic ingestion&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;039f4caf-8410-4970-b7be-912c87ee378f&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;70621593-6bc0-4864-83a8-1a645c6cc544&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Currently Uber hosts a monorepo for each primary language, each with its own dedicated CI pipeline. Our vision for Testopedia is to create a language-agnostic platform that can benefit all CI pipelines. Each language repository owns a realm, defines their own FQN format, and is responsible to initiate monitoring jobs, which sends streams of test history data to Testopedia. The data must follow a predefined universal schema, which is the only protocol between reporter and the service.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e5f607d9-33c8-42ee-8120-e292f0219615&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Consumers are free to determine how to consume from Testopedia. This approach effectively decouples the system’s logic from any language-specific concepts, such as test suites in Java or subtests in Go, ensuring adaptability regardless of the format. As a result, developers can seamlessly integrate this service into their CI infrastructure.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;ebf199ae-c9b3-4410-b1b4-ebaf6a3e0f2e&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-configurable-analyzers&#34;&gt;&lt;strong&gt;Configurable analyzers&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b841cde3-5275-4285-802a-442cf593f596&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b9c442b9-566c-4c02-861c-238e412073dd&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The Analysis module in Testopedia is also highly configurable. It provides a common interface and the owner of each realm can either use our default linear analyzer or submit their own implementation that’s tailored to their specific requirements of detection.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;70d18883-b8f8-4f11-84c3-fcf74d231656&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;bbd33b5a-a448-41f5-a650-0056ad64ab37&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXfXR6FbFHBhtN50OQzqS604yTm6dfdZqED0A7D0igC6a4VR9ZS9OTznHMl831T1H7H1T41bE_iKk7-D5Fh5il6LK-gb9COoe8JMdXRsU4hvxQj7UzLcG92tC33Pv0YY6TXcG7pQpmOV3Y3KUt16oHb1_5Ns?key=6gZ2dLlV7xzsqb0CRMkSGA&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 6: Analyzer Interface.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;dedb510a-792a-4465-9111-60352bfa6003&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2efb385b-34ae-4133-8b55-df546c96338b&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Furthermore, users can reuse any analyzer implementations and define rules based on results, lookback window, thresholds, states patterns to identify flaky tests efficiently specific to their own realm (more about this in the next section).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;49029b53-eb73-4aeb-9354-6927f75f794f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;This customization strikes the right balance between minimizing false positives and capturing genuine flaky tests.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;496e7096-ef26-452c-b199-c8dccdbebacb&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-configurable-ticketing-system-and-storage&#34;&gt;&lt;strong&gt;Configurable ticketing system and storage&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1cba52cc-49c3-402f-a656-0df23824f03b&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;992a94fc-b6a7-4dc2-8562-2f34386eac04&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We also modularized the system to accommodate our ever-evolving infrastructure at Uber. So that users can hook up other scrum solutions such as JIRA, Phabricator, and various DB solutions for storing the tests and histories. More on this in the “Managing Flaky Tests” section.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;862b3218-642c-41df-a4fc-3e44f1e36e47&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-visibility-and-usage&#34;&gt;&lt;strong&gt;Visibility and usage&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4b7023e4-880e-4b13-be2a-37e89424e80c&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5c7f83e8-baf5-46c5-9e11-c7dff9618fc9&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;One of the key features of Testopedia is its ability to offer comprehensive visibility into test history. Every state transition, along with associated job and metadata is recorded, creating a transparent audit trail for test owners to debug and investigate when and where the flakiness happens, what the error is, how frequent it is, at which commit, etc. Furthermore, we also build CLI and web UI on top of it, so that everyone can easily inspect their tests.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b85afc96-16b3-452d-95fd-8a6120cd7843&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8b9fc839-84ad-428e-a61f-d91c0ba739c1&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-analyzing-flaky-tests&#34;&gt;Analyzing Flaky Tests&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f6c785af-95b8-4fa4-8595-326cd5946933&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;While identifying flakiness in a monorepo setup, we want to be both accurate enough that we catch them on time thus preventing their blast radius from expanding to other engineers’ workflows, and tolerant enough that we don’t ignore them all and still have sufficient coverage guard in our code.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7aa941bb-597f-4080-9662-8ef854aa0007&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In the Go Monorepo we execute all the tests under the main branch periodically with limited resources. This way we can expose more flakiness in tests that are resource-intensive. Then we send the results as-is to Testopedia, which runs them through a linear analyzer to determine the state of the test based on their histories.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f3603f2e-7d88-4d7e-84fe-eb2dbb1acff9&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;If a test fails once in the last X window of runs, it is classified as unstable. On the other hand, because resources on the machine are compromised on purpose, some tests might tend to timeout more often, but it’s not their fault. In this case, the analyzer also grants each test a threshold M to timeout. For a test to be classified as stable, the test must pass N times consecutively. We also recognize that a test can become consistently failing due to a bug and mark it accordingly, so users will be notified of this change later.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;bdb5024a-a33b-4864-bbe3-a117894cc7e4&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Additionally, we also send results data from our regular landing CI pipeline. Because we have retry logic there, if a test fails for the first time but passes an identical retry, we know that this test is flaky. We label the import stream differently and make analyzer Testopedia aware, so they don’t interfere with each other.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3c943dd8-d50e-4890-b1ab-66a77caaec87&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;With all of the above described, we would have a config that looks like this:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3b548a2d-9a4b-4eb7-a289-4fd10494a1b7&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;b9afba35-6457-4972-ae5c-69c5d2c54c46&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXeMCzGfKOmguHaw5yyslTacjboR8yIY7TytrD8OqSdyd4Q44BVTCPSWFg9HTJ4oTmCDsxBwr5aq_QVf3rMci0ZsIfv87RJh4fzZKT-b1wIRmhXWEp99gwMoroFjGaMonto9_TVxoY99CN6Dz1-5wPpMjKc?key=6gZ2dLlV7xzsqb0CRMkSGA&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 7: Analyzer config.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ce246c06-496e-4f10-b79e-7f9031abdbd8&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;daa7cebc-c57c-4883-a209-4e08fd410821&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;As aforementioned, all these behaviors of analyzers are highly extensible. For example, integration tests may be more prone to timeout and flakiness. The standard linear analyzer is not a good fit. In this case, a different percentage-based analyzer is implemented for them. It categorizes a test as flaky if the failure percentage in the last N runs exceeds a certain threshold. Other analyzers can also be easily plugged in. These might include analyzers designed to inspect specific error messages, those sensitive to timeouts, or those prioritizing the detection of failure trends, among others.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b20ab5fc-46fd-48b2-beae-df64570fd787&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;860a6fbe-151e-4a80-b4df-173c112cf57a&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-managing-flaky-tests-nbsp&#34;&gt;Managing Flaky Tests&amp;nbsp;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5cde7751-2227-4012-8a17-070fcfb26131&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;After finding those flaky tests, we need to treat them and notify the owning teams.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;c639cd66-6722-4978-8784-efb47d0dec90&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-treating-flaky-tests&#34;&gt;Treating Flaky Tests&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a259fdc9-641e-49a5-a13a-2a68bb5b129b&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In a Monorepo setup, landing large diffs that affect many libraries and their tests can be very challenging, and worse, when they have flaky tests. One flaky failure that’s not caused by the diff itself could result in a full rebuild of the entire Job.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7c4cb204-64b8-4763-ae46-c161528a28f0&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Our general guidance is to avoid running flaky tests in CI. However, issues quickly arise when the engineer tries to fix a flaky test and submits the diff. If it’s still ignored in CI, then we have no idea whether that fix works or not. Or even worse, it may completely break the test, but because CI doesn’t validate it, we never know it’s broken.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1fd1fc8e-dbcf-4235-a0ca-5e5e426879d9&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Thus, we have implemented several strategies around this:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;62b6b7d9-27cc-41a7-be02-48da9040618c&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Tests that are specifically marked “critical” will be run on CI jobs regardless of flakiness&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Engineers can specifically added tags or keywords in diffs to opt out of that behavior&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Other flaky tests, such as integration tests, are run in non-blocking mode as FYI only&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;d6dacd11-3219-4579-8755-3ae4c28f4621&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-reducing-impact-of-flaky-tests&#34;&gt;Reducing Impact of Flaky Tests&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6c74df2d-0ef8-43a6-94bb-9c7487224518&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Strategy to skip flaky tests during CI phase is implemented by each realm owner. For example, Golang and Java may have very different test runner patterns, and hence use different test filter mechanisms.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c425d55d-13c9-4bc9-9a9c-d692b061ad24&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In the Go Monorepo, for example, we have different methods to skip test cases and test targets. To skip test targets, we exclude running flaky test targets directly in CI, but still ensure the target is buildable. What if the target only contains certain flaky test cases and the other test cases are still useful? We implemented a feature in &lt;a href=&#34;https://github.com/bazelbuild/rules_go/blob/master/docs/go/core/rules.md#go_test&#34;&gt;rules_go&lt;/a&gt; to skip test cases by the &lt;a href=&#34;https://tip.golang.org/doc/go1.20#go-command&#34;&gt;Go 1.20 -skip&lt;/a&gt; tests flag and parsing &lt;a href=&#34;https://github.com/bazelbuild/rules_go/pull/3618&#34;&gt;TESTBRIDGET_TEST_ONLY&lt;/a&gt; environment variable. This way, the information about flaky tests is isolated from the input of the Bazel rule, and the tests cache can stay stable regardless of flakiness.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;7b1dc38f-fc86-4eb5-b876-566d830c0892&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-accountability&#34;&gt;Accountability&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8c7b0d34-65bc-498b-a4ef-4971b61db541&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Now we have found some flaky tests and acted accordingly in CI. What’s next?&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7b3d4289-d442-469c-95d1-a7e45ed60919&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We need to notify test authors of such findings and encourage them to fix the tests as soon as possible. We can do this by immediately calling ticketing modules such as JIRA, Slack, etc. However, there are thousands of tests in even the smallest realm at Uber, and obviously we can’t afford the latency and cost of waiting for an external system to respond or file tickets for every single one. Thus we designed an asynchronous system within Testopedia that can file tickets based on grouping rules.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d9243171-5187-4b6f-bc38-e0be649c722b&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;8580d91a-7318-435b-9657-c22f64d7a2b3&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXefNJ-bMu_P-R7GsX8K7fqdWfWwcOMx8HDY1RZom-bf92pEGA9FSKufI5KEuoPsq6ZCnLR_pokvWi8i45Vg9q9Ta9fS8plpLT_mNbXDlq4O7uXQP7SqdwYuD-hmK4tItY_XEc73ucAql6xJIoxwjncBwLNl?key=6gZ2dLlV7xzsqb0CRMkSGA&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 8: Ticket filing diagram.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;882b59d5-3722-4d97-954c-132783948075&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;af0318e1-7967-49ae-a68f-42cbec887322&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;When a test is determined to be unhealthy by the analyzer, in addition to being updated in the database, it’s also inserted into a queue of messages. The queue is then poked by a cadence workflow to examine these tests again and call into JIRA to file tickets to the owning team. A Bazel test target can have multiple test cases, we track each of them as an FQN, but we only want to file one ticket per group of similar tests to reduce noise. Thus we came up with a grouping concept that put all unhealthy FQNs in one ticket per their group–either by build target or by regex.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ad540953-fb38-4b16-8a00-bd112e0573cb&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We also made the entire module customizable, that a user can customize the grouping rule, ticket types, priority, and even the ticket description template. A typical task config looks like this:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0dd3bc99-5289-4056-92cc-41b1efc92745&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;89573d15-7a58-40cc-be19-acc9f36c50b8&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXcOx9cAS4GShBGqQ2zpaS0C0nOYLfRj6oITaJzZS1zphl94Xa8Yh_F3CgcWaiiCgVe5PmdjrwZdkjG-XhDHvqzymBqPDBp6oPS1bm7dtuNKJje1tSzcv_e-JttdXGfhtrTimkxGKj-nP3mbUNjavDYVeSAB?key=6gZ2dLlV7xzsqb0CRMkSGA&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 9: Ticket filing config.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;38f70198-b6a3-430c-a37c-a87da2a113ad&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;445a5cc8-33ba-45e5-bb5f-fa8e7c3b9910&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;This way teams will have different test structures and define their own notification strategy tailored to their users’ experience.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;33d2efc9-9966-4fd1-be74-3909cef2a575&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8689adb6-39e5-44f8-a8c1-f4ebd1d15f5f&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-future-plans&#34;&gt;Future Plans&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7461339c-0fd9-4f32-835e-82ea172ea659&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Uber is actively &lt;a href=&#34;https://www.uber.com/blog/generative-ai-for-high-quality-mobile-testing/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;developing various LLMs&lt;/a&gt; to improve our developer experience. We envision incorporating these cutting-edge technologies in to the system in the future:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;e65a2e04-4d32-4151-b68f-f3125ab85042&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-integrate-genai-for-automated-flaky-tests-resolution&#34;&gt;&lt;strong&gt;Integrate GenAI for automated flaky tests resolution&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;90165264-95ca-4093-ab1a-2692e488aca3&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;89e4f0ed-c7cf-4f0d-813b-a588c699d901&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;After an FQN is imported and analyzed, with access to all its historical data and other tests failing patterns, we could use GenAI to auto-generate fixes for that test. We are exploring GenAI integrations built in-house at Uber to help centrally drive down the number of unsound tests in our Monorepos with minimal input from test owners.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;1a8d12f3-9a7d-486e-be97-aa4095c39440&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-more-granular-failure-categorization-and-sub-categorization&#34;&gt;&lt;strong&gt;More granular failure categorization and sub-categorization&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a5652f35-a04c-4bef-810a-6c3d8ed466a2&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0cbdb05f-4946-48db-8909-cd6a025caf85&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The current FSM model provides generic buckets of categorization, however, not all test failures are the same. Sub-categorizations are done explicitly at the realm level. By leveraging AI to analyze failure patterns, we could automatically categorize test failures into more specific subgroups based on factors such as error logs and types, test environments, or code context of failure. This enhanced classification system would enable us to conduct more efficient troubleshooting and resolutions.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6d81cf93-e710-4a1b-bf30-f77e0da1644b&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;e582e269-4a27-4b1c-bf1d-1509cf36cc4d&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-conclusion&#34;&gt;Conclusion&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;02683e3d-8852-43ba-be66-3d6fad03205d&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Now that all of the major Monorepos at Uber are onboarded to Testopedia, and along with numerous optimizations in both the internal algorithm and infrastructure components, it has been more stable than ever. In the Go Monorepo, we are steadily detecting around 1000 flaky tests out of 600K in total and 1K/350K in Java. We also observed significant improvement in reliability of CI and huge reduction of retries. Nagging developers with Jira tickets containing the right information helped tremendously to reverse the trend of an ever-growing number of unstable tests.&lt;/p&gt;】&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:1,&#34;hash&#34;:&#34;5b1d7fc2-0941-47d4-b05f-3f7ece51b42b&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-introduction&#34;&gt;简介&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;a42c8831-8676-46cf-ad64-9036fad21220&#34;,&#34;dropCap&#34;:false}&#34;&gt;几年之前，我们开始&lt;a href=&#34;https://www.uber.com/en-US/blog/handling-flaky-tests-java/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;解决片状测试&lt; /a&gt; 努力稳定我们单一存储库中的 CI 体验。该项目首先在我们的 Java monorepo 中首次亮相，并在减少开发人员工作流程中的摩擦方面取得了良好的效果。然而，随着我们发展 CI 基础设施并开始将其加入我们拥有最多用户的最大存储库，&lt;a href=&#34;https://www.uber.com/blog/how-we-halved-go-monorepo-ci- build-time/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Go Monorepo&lt;/a&gt;，权宜之计的解决方案在扩展到范围时变得越来越具有挑战性。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;4d9e159d-c250-40a5-a4cf-590ce4ee5a4c&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-visibility&#34;&gt;&lt;strong&gt;可见性&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;67dd1537-7100-4d7b-ba4f-bb1a680c9f61&#34;,&#34;ordered&#34;:false,&#34;values&#34;:&#34; &#34;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;201aa385-5e2f-455f-b51a-0c7d17cad286&#34;,&#34;dropCap&#34;:false}&#34;&gt;旧服务有一个内置分析器，它根据历史测试运行的窗口对测试进行分类。然而，大多数时候它在沙箱中工作，几乎无法了解细节，例如它检查了测试的历史记录、决策背后的原因是什么或有关测试的其他信息。因此，经常有一些测试被错误分类，但我们不知道为什么，不得不手动重新分类。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;b2e7d91b-b0b6-408b-97d9-a63b5b40caf4&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-customization&#34;&gt;&lt;strong&gt;自定义&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;07ee5689-fa0c-4e7f-8b0c-6f92371b51a8&#34;,&#34;ordered&#34;:false,&#34;values&#34;:&#34; &#34;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;aa80c6ff-59a6-41d3-829e-28cce84d3de0&#34;,&#34;dropCap&#34;:false}&#34;&gt;它还有支持不同策略对测试进行分类的可扩展性很小。它仅支持滑动窗口策略对测试进行分类。遗留测试模型是专门为 Java 定制的，假设有测试套件、参数、注释等输入，而这些输入在其他语言中并不总是可用。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&amp;quot;:3,&#34;hash&#34;:&#34;962ac64d-c01e-4074-9e38-5807e8273eac&#34;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-complexity&#34;&gt;&lt;strong&gt;复杂性&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;88c5370b-4301-4808-a021-0ebc6e3119a6&#34;,&#34;ordered&#34;:false,&#34;values&#34;:&#34; &#34;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;2348812e-5754-484d-9822-c2a57b61d50d&#34;,&#34;dropCap&#34;:false}&#34;&gt;“串行” ”和“并行”概念在每个 monorepo 的 CI 端添加了额外的逻辑，以做出不同的响应。此外，因为它封装了许多场景——分类、转换、CI 中的恢复、通知等——当它需要足够通用以容纳每个存储库并且足够有效以不错过任何脆弱性时，复杂性会大大增加。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;e4ccc2b6-3d69-4e9d-9b4b-932dfd327a69&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-actionability&#34;&gt;&lt;strong&gt;可操作性&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;8f430a58-09d6-4e9e-a17d-b2db0ccfe354&#34;,&#34;ordered&#34;:false,&#34;values&#34;:&#34; &#34;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;a7be3b0d-9c65-46f4-a77a-7e6f9a389de6&#34;,&#34;dropCap&#34;:false}&#34;&gt;当时我们尚未就如何定义跨存储库的所有权达成共识。因此，我们最终在 CI 中忽略了许多不稳定的测试，但没有负责任的跟踪。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;d734d4df-7598-4736-a946-e3ffc2cc6abb&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;070ae3cd-03c6-46bc-9a1b-28e23b9b68ba&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-the-big-picture&#34;&gt;大局&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;c3fcafa2-59dc-4e77-9d4a-0bb2a76aa3d0&#34;,&#34;dropCap&#34;:false}&#34;&gt;在 Uber，我们在不同的开发阶段在 CI 管道中运行了大量的测试。通常，我们每天会验证 2,500 多个差异（代码更改，又名拉取请求），并且平均每个差异运行超过 10k 次测试。我们的最终目标是通过 &lt;a href=&#34;https://www.uber.com/blog/research/keeping-master-green-at-scale/&#34; target=&#34;_blank&#34; 确保开发人员对主分支有信心rel=&#34;noreferrer noopener&#34;&gt;保持始终绿色&lt;/a&gt;。不稳定的测试破坏了 CI 管道的可靠性，导致开发人员体验混乱——一个错误会变成更多错误。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;f2c986c7-44c3-4e21-9240-b3d59c0b4f33&#34;,&#34;dropCap&#34;:false}&#34;&gt;此外，我们的 &lt;a href=&#34;https://www.uber.com/blog/bypassing-large-diffs-in-submitqueue/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;SubmitQueue 推测&lt;/a&gt; 体系结构，失败的修订可能会产生级联效应，使其他修订无效当存在影响整个存储库并触发所有测试的横切更改时，情况会变得更糟，这将导致代码更改成为一场噩梦，这可能会导致开发人员不断重试他们的构建，直到构建变为绿色。浪费工程时间和 CI 资源。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;1f7300c8-63c1-4c0b-b63e-589e3dfaf376&#34;,&#34;dropCap&#34;:false}&#34;&gt;它变成了迫切需要开发一个有效的、可扩展的、可配置的系统，可以轻松采用并响应数千个测试的状态变化。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;b12b6b0d-9d0e-4e1d-a86b-ed3e86680e04&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;a6d1f0dc-48f2-4538-b83e-1278aac25e13&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-introducing-testopedia&#34;&gt;Testopedia 简介&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;0765bf8a-e41f-4629-adef-5262b70747db&#34;,&#34;dropCap&#34;:false}&#34;&gt;我们需要获取我们在 Uber 中运行的所有测试的可见性，以验证用户的更改。这种可见性包括可靠性特征（即不稳定控制）和性能特征（即延迟控制）。因此，我们需要一个集中式系统来跟踪所有测试，并为 CI 或任何其他消费者提供足够的背景信息，以便就这些测试做出决策。我们将这些职责分离到一个独立的服务 Testopedia 中。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;a8ab55a4-6796-4a48-bda1-0d4edeeae189&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-design-overview&#34;&gt;设计概述&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;6964c0e2-c3ac-4238-b231-7e4f98fa0ec7&#34;,&#34;dropCap&#34;:false}&#34;&gt;Testopedia 位于我们的报告和消费者之间的 CI 基础设施如下：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;5962396c-b43c-4c26-9cf4-489a5fc546eb&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;align&#34;:&#34;center&#34;,&#34;hash&#34;:&#34;0a694a21-5c73-49c7-b534-18179b888cca&#34;,&#34;alt&#34; ：&#34;&#34;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img 解码=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXfgB7JBfGgSObLdUa7d6nIlquv_YK9ctd5SfEZbKGIsvHozIPyvlh4Tt3vZAQSW5WmiH4xkalc01ZcY_coTyFHtbFa2gcuyIp-oWqoWRcLQ-5vlSW-rjSFBJyh4u2YqUmd_LItqVcMO_-WekoYw0-sTqTua?key=6gZ2dLlV7xzsqb0CRMkSGA&#34; alt=&#34;&#34; -referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;图 1：示例管道。&lt;/figcaption&gt; &lt;/图&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;5a86a100-3f44-4e82-af3a-9c03d392b981&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;eda85819-74c8-4688-9583-79bf035af068&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-what-it-does&#34;&gt;它的作用&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;758ab9c3-3078-4003-a0c7-edf4638d7840&#34;,&#34;dropCap&#34;:false}&#34;&gt;而不是Testopedia 处理片状测试的各个方面，我们决定使其与语言/存储库无关。这意味着该服务不关心它是什么类型的测试，是测试套件还是测试用例，名称的格式如何，如何报告，如何在 CI 中处理等。它只是在“测试实体， ”，它是系统中的最小基本单元，由“完全限定名称”(FQN) 唯一标识。此外，我们还引入了 FQNs 的分组概念——realm，它封装了特定使用域下的所有测试，例如 Golang 单元测试、Java 单元测试、Docker 集成测试等。 Realms 属于特定平台团队所有，每个团队都可以构建根据自己的喜好进行 FQN。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;56506c54-9463-4fdc-8369-435b41594c0b&#34;,&#34;dropCap&#34;:false}&#34;&gt;下一步，上在较高级别上，我们为服务分配了 3 个功能域：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;2f1571b6-f23e-468a-9389-387fea6e0f63&#34;,&#34;dropCap&#34;:false}&#34;&gt;&lt;strong&gt;阅读&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;946fc163-8194-468a-9de8-1f15edf9180d&#34;,&#34;ordered&#34;:false,&#34;values&#34;:&#34; “}”&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;检索单个测试的统计信息，包括不稳定状态、可靠性、陈旧性、聚合执行时间、历史运行统计信息等元数据（如果有）。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;检索一组测试的统计信息，即上述列表。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;检索测试的状态更改。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;b1454898-28cc-42a1-b6de-f3e7616a2821&#34;,&#34;dropCap&#34;:false}&#34;&gt;&lt;strong&gt;写&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;14f17714-3c2b-4124-bab2-24fcc7175cf9&#34;,&#34;ordered&#34;:false,&#34;values&#34;:&#34;“}”&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;将测试运行结果上传到系统。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;它可以采用文件或流的形式，但需要遵循预定义的架构。&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;用于禁用/启用/删除系统中某些测试的管理操作。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;49cae938-ade8-400f-9766-28c1241983c8&#34;,&#34;dropCap&#34;:false}&#34;&gt;&lt;strong&gt;通知&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;bfd428e6-a496-490b-8a5f-54e94a17e8f2&#34;,&#34;ordered&#34;:false,&#34;values&#34;:&#34; “}”&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;每当测试变得不健康时，我们都需要触发 JIRA 票证，并将截止日期分配给所属团队。&lt; /里&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;b1a9e321-30e0-45b3-856e-2ac7813fa207&#34;,&#34;ordered&#34;:false,&#34;values&#34;:&#34; &#34;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;30132e1f-3999-49c9-81dd-8368e6e91914&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;c2c8d4b6-d229-4825-8490-912d254eb357&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-how-it-works&#34;&gt;它是如何工作的&lt;/h3&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;width&#34;:&#34;700px&#34;,&#34;height&#34;:&#34;auto&#34;,&#34;align&#34;:&#34;center&#34;,&#34;hash&#34; :&#34;1c81923a-4178-4db3-bc7e-08e62953b17c&#34;,&#34;alt&#34;:&#34;&#34;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img 解码=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent. com/docsz/AD_4nXdQvxdjfAvik1VtI7t-b2HiGn1Wk5CeNvZFhe2QBoHN7S_Bsid3wZV-fKRW3SLudKuP0KfcIA4vQDi0zd8txYN95hqLVktKT7tMjp2tcis5Pg8-XCT_yaM5Vef7MeQm0_ Wh8mnXKySoP93kE0Hxm-DKKe4?key=6gZ2dLlV7xzsqb0CRMkSGA&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element- title&#34;&gt;图 2：Testopedia 架构图。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;8436349b-0d8c-42f0-bff7-724b3ce01180&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;dc4cf4a0-f6b9-4ae3-8a0a-f15eb4eaafed&#34;,&#34;dropCap&#34;:false}&#34;&gt;Testopedia 工作结束历史数据来推断测试是否健康。但 Testopedia 并没有专注于定期作业，而是接受所有测试数据源，无论它是来自定期验证作业还是常规验证作业。每份报告都将标有其 s相应地来源。然后每个分析器都可以访问所有这些信息，并采取不同的策略来响应它们（稍后将详细介绍“分析器”）。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;be1766aa-1ee4-4beb-8201-bd9cfb56264a&#34;,&#34;dropCap&#34;:false}&#34;&gt;分析器之后完成对测试的运行分析后，结果将具体化到存储中以供稍后查询，并且根据结果，将按照领域的分组规则将票证提交给测试所属团队（更多信息请参阅通知）。&lt;/p &gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;e7381254-3570-4921-9604-70bfac13b4de&#34;,&#34;dropCap&#34;:false}&#34;&gt;请注意，从从分析器到票务，每个策略都可以在 Testopedia 的核心逻辑之外进行扩展和配置，从而为领域所有者提供最大的可定制性。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;a1395b47-041d-43a6-96dc-961f52ae0914&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;3053ee68-48f9-4368-bb05-93127327e049&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-implementation-highlights&#34;&gt;实施亮点&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;d4d593dc-2acb-4865-a56b-5bb85f3e3b72&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-filled-qualified-name-fqn&#34;&gt;&lt;strong&gt;完全限定名称 (FQN)&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;6896c21e-14dd-476f-9d1f-23d0e4a032f5&#34;,&#34;ordered&#34;:false,&#34;values&#34;:&#34; &#34;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;e81252e0-0ca8-4da8-9ae1-26e84aeb7479&#34;,&#34;dropCap&#34;:false}&#34;&gt;关键部分Testopedia 设计的核心是能够使用名为“完全限定名称”或简称 FQN 的唯一字符串标识符来处理我们在 Uber 执行的每个测试。系统只需关注FQN的分析和记账，将处理实现留给各个平台，无需了解各个测试框架的任何细节。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;871b59f7-c060-4d91-ac71-0850528f4475&#34;,&#34;dropCap&#34;:false}&#34;&gt;所有测试均分为&lt;em&gt;领域&lt;/em&gt;。领域名称以 FQN 字符串开头，代表测试所属的更广泛的域。领域的一个示例是“golang.unit_test”或“android.integration_test”。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;26c67707-464c-43f4-92a7-273e5b1d0882&#34;,&#34;dropCap&#34;:false}&#34;&gt;作为示例在“Golang 单元测试”领域下的有效 FQN，我们可以组合一个如下所示的字符串：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;小时天数ata-wp-block-name=&#34;核心/分隔符&#34; data-wp-block=&#34;{&#34;散列&#34;:&#34;2d6e29bd-e362-401a-a0a1-7e6bb195396c&#34;,&#34;不透明度&#34;:&#34;alpha 通道&#34;}&#34; 类= “wp-块分隔符具有-alpha-通道-不透明度”&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;align&#34;:&#34;center&#34;,&#34;hash&#34;:&#34;eaf64e5e-f666-4ef8-9163-02ae120b31b5&#34;,&#34;alt&#34; :&#34;&#34;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img 解码=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXdwZlzY61MzQ6qnqQP7nlyAoUcTSIcRFIUVgDPADDe9qg0Z6o2zvD-N2KVItlya7T7SAA7KlAUouQJ0p6gGVIyWmw1w yM5DyfFtIQPggGE8hUtL9za1BNIT9WjvH32gPt4yWoNyBo5tiSs3DLsyXtyBqCM?key=6gZ2dLlV7xzsqb0CRMkSGA&#34; alt=&#34;&#34;referrerpolicy=&#34; no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;图 3：完全限定名称示例。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;6fa34453-30c1-44a3-8c8c-d9c9952bfa7f&#34;,&#34;opacity&#34;:&#34;alpha 通道&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;c24c8da4-49d2-4bb0-b5ec-3d407b4351af&#34;,&#34;dropCap&#34;:false}&#34;&gt;整个 FQN领域所有者可以将其定制为任何格式。通常根据测试代码所在的文件系统结构来对标识符进行建模。毫不奇怪，FQN 看起来非常像 Internet URL，因为它具有唯一标识资源的类似目的。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;58aad72f-ed36-411a-af12-950dd6158c27&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-finite-state-machine-fsm-model&#34;&gt;&lt;strong&gt;有限状态机 (FSM) 模型&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;0fade6a9-f16e-434a-b939-0d73cbf09613&#34;,&#34;ordered&#34;:false,&#34;values&#34;:&#34; &#34;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;152a4ee0-9f7a-44a5-8499-cf4138769350&#34;,&#34;dropCap&#34;:false}&#34;&gt;Testopedia 利用强大的有限状态机实现来捕获和记录测试的事务状态。测试实体被允许在以下状态之间进行交易：新的、稳定的、不稳定的、禁用的和删除的。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;490e20b6-f7ca-4aeb-9544-f06b16c9fa9c&#34;,&#34;opacity&#34;:&#34;alpha 通道&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;align&#34;:&#34;center&#34;,&#34;hash&#34;:&#34;0be4f426-2ef8-4709-b005-04e98f23bfc9&#34;,&#34;alt&#34; :&#34;&#34;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img 解码=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXcXC3fSUSBxx6UimzGX5-eCWvAIxT8GjmpP1o7M-BtFAxVQaTipK4mEkvNUNglokw3lhVe07hG2qNVUy2t5OlVE8FpsrTj2bkmOaF2aj977cXflVwvBBCTFOONK_VLgejYZVyHmY4783oVBCRbyLd1kBNPf?key=6gZ2dLlV7xzsqb0CRMkSGA&#34; alt=&#34;&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34; wp-element-caption&#34;&gt;图 4：Testopedia 状态机。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;4de603cd-95fd-49f2-8fca-c927c925fb6c&#34;,&#34;opacity&#34;:&#34;alpha 通道&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;b3e8dbf0-22a2-4743-b29a-f98773239481&#34;,&#34;dropCap&#34;:false}&#34;&gt;每个状态都可以定制自己的进入和退出动作。例如，当 FSM 进入不稳定状态时，会触发一个操作来提交 JIRA 票证；当 FSM 进入稳定或已删除状态时，关联的 JIRA 票证将关闭。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;5dba5a5f-7980-4a75-9cdc-d5355bff14d1&#34;,&#34;dropCap&#34;:false}&#34;&gt;坚持使用 FSM设计，我们能够节省样板代码，否则我们必须编写和支持这些代码。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;6c7a447d-5211-4353-a186-8eb9e477533d&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;6fb31f02-f9f5-4cea-ba27-477f089995bf&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-scalability&#34;&gt;&lt;strong&gt;可扩展性&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;f0f7ff33-ea10-45d0-b527-b7020c8c165b&#34;,&#34;ordered&#34;:false,&#34;values&#34;:&#34; &#34;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;align&#34;:&#34;center&#34;,&#34;hash&#34;:&#34;1fe1c6c2-e4b4-48aa-b4e7-dc000192db31&#34;,&#34;alt&#34; ：&#34;&#34;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img 解码=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXf_fs9-Fg36HOnQqalDoe134ZcOVaRT4vbMCEdBG1aRd7-OZ8Sff4CP9oRkvptXWULIw2gbhfg4QHiw4R2hBBHXZ_U _Qh6wV4-iKvi9GOofM0jaoKSAxwSJ1FGEl8KWd9u-OP9QyO4N5qudDX_U7EMzxBgJ?key=6gZ2dLlV7xzsqb0CRMkSGA&#34;替代=&#34;&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;图 5：通过线程池进行数据流传输的示例。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;d8e1dbf9-42fa-4400-996f-b494f3b91231&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;e5743409-1159-40d1-9faa-19e7d97b7f66&#34;,&#34;dropCap&#34;:false}&#34;&gt;为了为了最大限度地提高效率，我们选择使用 gRPC 流来实现导入 API，而不是要求用户上传大块数据。除此之外，我们还实现使用线程池来消耗数据流。这不仅可以通过长期连接实现更易于管理的数据传输，还可以通过客户端和服务器端的并行处理确保更好的资源利用率。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;11524d4f-88ec-4aeb-b71f-5e58068dfbf8&#34;,&#34;dropCap&#34;:false}&#34;&gt;此外，我们设计后端数据库时考虑到了可扩展性，通过允许灵活的分区，以便支持更复杂的读取场景（下一节将详细介绍这一点）。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;e6556bc4-f4f5-4fd9-922e-f00fe7e46ba8&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-cone-queries-and-dynamic-partitioning&#34;&gt;&lt;strong&gt;锥体查询和动态分区&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;81a75136-8e93-4f9f-b087-e198c5e47784&#34;,&#34;ordered&#34;:false,&#34;values&#34;:&#34; &#34;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;52f1cedc-a851-4aed-8725-37cc54968ee7&#34;,&#34;dropCap&#34;:false}&#34;&gt;因为片状测试会被 CI 大量查询，支持按前缀查询是很自然的要求，例如“golang.unit/src/uber.com/infrastruct/*”，在 Testopedia API 模型中称为锥体查询&lt;em&gt; /em&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;efabc307-ec24-4b55-8f26-dcad36807474&#34;,&#34;dropCap&#34;:false}&#34;&gt;在一个非常常见的 Monorepo 设置，CI 构建作为多个并行作业执行，并按相似的路径前缀划分。因此，每个 CI 作业只对了解特定存储库文件夹下的片状测试感兴趣，而不是全部。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;d0e8a448-ece6-43a1-bbfd-aff69e75300f&#34;,&#34;dropCap&#34;:false}&#34;&gt;当我们跟踪时数百万次测试，迭代整个数据库来查找前缀匹配的性能并不好。我们自然会想到分片，但是，我们不想只在固定长度的前缀上进行分片，因为锥体查询可以是任意长度，例如“golang.unit/a/b/c/*”、“ golang.unit/a/b/*”、“golang.unit/a/*”等。为了有效地做到这一点，我们实现了灵活的分桶算法：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;2bf1e890-4170-4c21-a511-fa1e4b770e95&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;bc9324ad-c4e4-44f8-9834-ac8efbe48b83&#34;,&#34;dropCap&#34;:false}&#34;&gt;写入：&lt; /p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;834e6d2b-87be-4028-870a-258cbb825418&#34;,&#34;ordered&#34;:false,&#34;values&#34;:&#34; “}”&gt;&#xA;&lt;li 数据-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;当新的 FQN 到达系统时，说“golang.unit/a/b/c/d:test”，&lt;/李&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;首先我们为其随机生成一个整数存储桶 ID，比如 10&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;然后我们剥离领域并识别前 3 个前缀： &#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;ordered&#34;:false,&#34;values&#34;:&#34;&#34;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;[a/b/c、a/b、a]&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;（这里的 3 是深度的可配置值，只是一个示例）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;dabcc505-21fc-4771-9af2-07df19f0d81a&#34;,&#34;ordered&#34;:false,&#34;values&#34;:&#34; “}”&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;接下来，我们通过附加存储桶 ID 以及所有前缀将其存储在单独的表中：&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;8160c0c9-ec4b-466a-8533-95b9c5a994bc&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure data-wp-block-name=&#34;core/table&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;ed05e1a0-3d3e-4cb6-868b-f723e9e7a786&#34;,&#34;hasFixedLayout&#34;:false,&#34;head&#34;:[ ],&#34;body&#34;:[],&#34;foot&#34;:[]}&#34; class=&#34;wp-block-table&#34;&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;前缀表&lt;/td&gt;&lt;td&gt;插入前（其他FQN创建的现有存储桶ID）&lt;/td&gt;&lt;td&gt;插入后&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;a/b/c&lt;/td&gt;&lt;td&gt;[]&lt;/td&gt; &lt;td&gt;[&lt;strong&gt;10&lt;/strong&gt;]&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;a/b&lt;/td&gt;&lt;td&gt;[2]&lt;/td&gt;&lt;td&gt;[2, &lt;strong&gt;10&lt;/strong&gt;]&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;a&lt;/td&gt;&lt;td&gt;[2, 3]&lt;/td&gt;&lt;td&gt;[2, 3, &lt;strong &gt;10&lt;/strong&gt;]&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;在上面的示例中，前缀为“a/b”的 FQN 必须位于桶 2 或 10。&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;3d90f91a-ae11-4915-a96a-f425fcdda7f6&#34;,&#34;opacity&#34;:&#34;alpha 通道&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;becdd565-7f4f-48c6-93ba-fb4dae60b936&#34;,&#34;ordered&#34;:false,&#34;values&#34;:&#34; “}”&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;最后，我们将存储桶 ID 与 FQN 本身一起存储在按存储桶 ID 分区的单独 FQN 表中&lt; /里&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote data-wp-block-name=&#34;core/quote&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;5a3eedb8-b433-451f-a60f-96de47fed1a5&#34;,&#34;value&#34;:&#34;&#34;}&#34; class=&#34; wp-block-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;dropCap&#34;:false}&#34;&gt;# FQN 表&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;核心/段落&#34; data-wp-block=&#34;{&amp;quot;dropCap&#34;:false}&#34;&gt;golang.unit/a/b/c/d:测试，10&lt;/p&gt;&#xA;&lt;/块引用&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;054baf9c-c398-4bb9-803c-937393057a5c&#34;,&#34;ordered&#34;:false,&#34;values&#34;:&#34; “}”&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;潜在的不同存储桶可以保存到不同的数据库服务器中，从而使设置几乎可以无限扩展&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;e0fb0567-a706-4231-8360-5e97cf6904d9&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;51cfbdc1-1b53-43bf-be3d-e2facfed45f&#34;,&#34;dropCap&#34;:false}&#34;&gt;阅读：&lt; /p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;faa0f070-0ad4-406a-a70a-7b35e1ac4fca&#34;,&#34;ordered&#34;:false,&#34;values&#34;:&#34; “}”&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;当我们发出圆锥查询时，请说“golang.unit/a/b/*” &lt;/li &gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;我们首先找到领域“golang.unit”，然后找到前缀“a/b”&lt;/li &gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;然后我们引用分区表并获取所有存储桶 ID [2, 10]&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;然后我们可以快速查找FQN表中桶ID为2或10的记录；由于它是分区键，读取应该非常快；我们还可以并行执行此类查找&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;最后，我们迭代选定的记录并过滤那些满足查询要求的记录&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;9033570a-122a-4183-bb96-5285b9716b96&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;b5e8477d-578e-4541-ba29-20933415487b&#34;,&#34;dropCap&#34;:false}&#34;&gt;请注意我们跟踪存储桶 ID 的路径深度是 config.json 中的预定义值。因此，对于较长的查询，例如“golang.unit/a/b/c/d/e/*”，我们在最大深度“a/b/c”处停止并读取桶ID为10的所有记录。&lt;/ p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;d0f63b8a-f840-406b-b9e5-310800b9ffc3&#34;,&#34;dropCap&#34;:false}&#34;&gt;这样我们可以显着减少从数据库读取的记录数量。此外，每个领域都可以根据其查询模式配置自己的深度和存储桶数量。由于存储桶 ID 是动态生成的，而不是依赖于静态输入，因此它有助于在存储桶之间更均匀地分配数据，而不管它们在存储库中的物理位置如何。保守党。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;df4f36fd-5e26-4953-a8eb-9f17c17ff051&#34;,&#34;dropCap&#34;:false}&#34;&gt;这样的设计实现一个重要的好处是：非常传统的关系数据库（例如多分片配置中的 MySQL）可用于为存储后端提供动力并以亚秒级延迟执行复杂的锥形查询。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;f74a3378-7798-47fa-822e-eaf57a6762f9&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-data-agnostic-ingestion&#34;&gt;&lt;strong&gt;数据不可知摄取&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;039f4caf-8410-4970-b7be-912c87ee378f&#34;,&#34;ordered&#34;:false,&#34;values&#34;:&#34; &#34;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;70621593-6bc0-4864-83a8-1a645c6cc544&#34;,&#34;dropCap&#34;:false}&#34;&gt;目前为 Uber 主机每种主要语言的 monorepo，每种语言都有自己专用的 CI 管道。我们对 Testopedia 的愿景是创建一个与语言无关的平台，使所有 CI 管道受益。每个语言存储库都拥有一个领域，定义自己的 FQN 格式，并负责启动监视作业，该作业将测试历史数据流发送到 Testopedia。数据必须遵循预定义的通用模式，这是报告者和服务之间的唯一协议。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;e5f607d9-33c8-42ee-8120-e292f0219615&#34;,&#34;dropCap&#34;:false}&#34;&gt;消费者是免费的确定如何从 Testopedia 进行消费。这种方法有效地将系统的逻辑与任何特定于语言的概念（例如 Java 中的测试套件或 Go 中的子测试）解耦，从而确保无论格式如何，都具有适应性。因此，开发人员可以将此服务无缝集成到他们的 CI 基础设施中。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;ebf199ae-c9b3-4410-b1b4-ebaf6a3e0f2e&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-configurable-analyzers&#34;&gt;&lt;strong&gt;可配置分析器&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;b841cde3-5275-4285-802a-442cf593f596&#34;,&#34;ordered&#34;:false,&#34;values&#34;:&#34; &#34;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;b9c442b9-566c-4c02-861c-238e412073dd&#34;,&#34;dropCap&#34;:false}&#34;&gt;分析模块Testopedia 中的可配置性也很高。它提供了一个通用接口，每个领域的所有者可以使用我们的默认线性分析器或提交根据其特定检测要求定制的自己的实现。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;70d18883-b8f8-4f11-84c3-fcf74d231656&#34;,&#34;opacity&#34;:&#34;alpha 通道&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;align&#34;:&#34;center&#34;,&#34;hash&#34;:&#34;bbd33b5a-a448-41f5-a650-0056ad64ab37&#34;,&#34;alt&#34; :&#34;&#34;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img 解码=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXfXR6FbFHBhtN50OQzqS604yTm6dfdZqED0A7D0igC6a4VR9ZS9OTznHMl831T1H7H1T41bE_iKk7-D5Fh5il 6LK-gb9COoe8JMdXRsU4hvxQj7UzLcG92tC33Pv0YY6TXcG7pQpmOV3Y3KUt16oHb1_5Ns?key=6gZ2dLlV7xzsqb0CRMkSGA&#34; alt=&#34;&#34; 推荐策略=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;图 6：分析器界面。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;dedb510a-792a-4465-9111-60352bfa6003&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;2efb385b-34ae-4133-8b55-df546c96338b&#34;,&#34;dropCap&#34;:false}&#34;&gt;此外，用户可以重用任何分析器实现，并根据结果、回溯窗口、阈值、状态模式定义规则，以有效地识别特定于其自己领域的片状测试（下一节将详细介绍这一点）。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;49029b53-eb73-4aeb-9354-6927f75f794f&#34;,&#34;dropCap&#34;:false}&#34;&gt;此自定义会触发最大限度地减少误报和捕获真正的片状测试之间的适当平衡。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;496e7096-ef26-452c-b199-c8dccdbebacb&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-configurable-ticketing-system-and-storage&#34;&gt;&lt;strong&gt;可配置的票务系统和存储&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;1cba52cc-49c3-402f-a656-0df23824f03b&#34;,&#34;ordered&#34;:false,&#34;values&#34;:&#34; &#34;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;992a94fc-b6a7-4dc2-8562-2f34386eac04&#34;,&#34;dropCap&#34;:false}&#34;&gt;我们还模块化了该系统可适应 Uber 不断发展的基础设施。这样用户就可以连接其他 Scrum 解决方案，例如 JIRA、Phabricator 以及用于存储测试和历史记录的各种 DB 解决方案。有关此内容的更多信息，请参阅“管理不稳定测试”部分。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;862b3218-642c-41df-a4fc-3e44f1e36e47&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-visibility-and-usage&#34;&gt;&lt;strong&gt;可见性和使用情况&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;4b7023e4-880e-4b13-be2a-37e89424e80c&#34;,&#34;ordered&#34;:false,&#34;values&#34;:&#34; &#34;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;核心/段落&#34; data-wp-block=&#34;{&#34;哈希&#34;:&#34;5c7f83e8-baf5-46c5-9e11-c7dff9618fc9&#34;,&#34;dropCap&#34;:false}&#34;&gt;Testopedia 的主要功能之一是能够提供对测试历史记录的全面可见性。每个状态转换以及相关的作业和元数据都会被记录下来，为测试所有者创建透明的审计跟踪，以便调试和调查不稳定发生的时间和地点、错误是什么、错误发生的频率、提交的时间等。此外，我们还在其之上构建了 CLI 和 Web UI，以便每个人都可以轻松检查他们的测试。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;b85afc96-16b3-452d-95fd-8a6120cd7843&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;8b9fc839-84ad-428e-a61f-d91c0ba739c1&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-analyzing-flaky-tests&#34;&gt;分析不稳定测试&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;f6c785af-95b8-4fa4-8595-326cd5946933&#34;,&#34;dropCap&#34;:false}&#34;&gt;识别薄片时在 monorepo 设置中，我们希望足够准确，以便我们及时捕获它们，从而防止它们的爆炸半径扩展到其他工程师的工作流程，并且足够宽容，以便我们不会忽略它们，并且在我们的系统中仍然有足够的覆盖保护代码。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;7aa941bb-597f-4080-9662-8ef854aa0007&#34;,&#34;dropCap&#34;:false}&#34;&gt;在 Go 中Monorepo 我们用有限的资源定期执行主分支下的所有测试。通过这种方式，我们可以在资源密集型测试中暴露出更多的脆弱性。然后我们将结果按原样发送到 Testopedia，后者通过线性分析器运行它们，根据它们的历史确定测试的状态。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;f3603f2e-7d88-4d7e-84fe-eb2dbb1acff9&#34;,&#34;dropCap&#34;:false}&#34;&gt;如果测试在运行的最后一个 X 窗口中失败一次，它被归类为不稳定。另一方面，由于机器上的资源被故意破坏，某些测试可能会更频繁地超时，但这不是他们的错。在这种情况下，分析器还为每个测试授予超时阈值 M。要将测试分类为稳定，测试必须连续通过 N 次。我们还认识到，测试可能会因错误而持续失败，并相应地对其进行标记，以便稍后向用户通知此更改。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;bdb5024a-a33b-4864-bbe3-a117894cc7e4&#34;,&#34;dropCap&#34;:false}&#34;&gt;此外，我们还从我们的常规登陆 CI 管道发送结果数据。因为我们在那里有重试逻辑，如果测试第一次失败但通过了相同的重试，我们就知道这个测试是不稳定的。我们以不同方式标记导入流，并使分析器 Testopedia 感知，因此它们不会相互干扰。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;3c943dd8-d50e-4890-b1ab-66a77caaec87&#34;,&#34;dropCap&#34;:false}&#34;&gt;所有如上所述，我们将有一个如下所示的配置：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;3b548a2d-9a4b-4eb7-a289-4fd10494a1b7&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;align&#34;:&#34;center&#34;,&#34;hash&#34;:&#34;b9afba35-6457-4972-ae5c-69c5d2c54c46&#34;,&#34;alt&#34; :&#34;&#34;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img 解码=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXeMCzGfKOmguHaw5yyslTacjboR8yIY7TytrD8OqSdyd4Q44BVTCPSWFg9HTJ4oTmCDsxBwr5aq_QVf3rMci0ZsIfv87RJ h4fzZKT-b1wIRmhXWEp99gwMoroFjGaMonto9_TVxoY99CN6Dz1-5wPpMjKc?key=6gZ2dLlV7xzsqb0CRMkSGA&#34; alt=&#34;&#34;referrerpolicy =&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;图 7：分析器配置。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;ce246c06-496e-4f10-b79e-7f9031abdbd8&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;daa7cebc-c57c-4883-a209-4e08fd410821&#34;,&#34;dropCap&#34;:false}&#34;&gt;如上所述，分析器的所有这些行为都是高度可扩展的。例如，集成测试可能更容易出现超时和不稳定的情况。标准线性分析仪不太合适。在这种情况下，将为它们实施不同的基于百分比的分析器。如果最后 N 次运行的失败百分比超过特定阈值，它将测试归类为片状测试。其他分析器也可以轻松插入。其中可能包括旨在检查特定错误消息的分析器、对超时敏感的分析器或优先检测故障趋势的分析器等。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;b20ab5fc-46fd-48b2-beae-df64570fd787&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;860a6fbe-151e-4a80-b4df-173c112cf57a&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-managing-flaky-tests-nbsp&#34;&gt;管理不稳定测试&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;5cde7751-2227-4012-8a17-070fcfb26131&#34;,&#34;dropCap&#34;:false}&#34;&gt;找到这些后不稳定的测试，我们需要对其进行处理并通知所属团队。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;c639cd66-6722-4978-8784-efb47d0dec90&#34;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-treating-flaky-tests&#34;&gt;处理不稳定测试&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;a259fdc9-641e-49a5-a13a-2a68bb5b129b&#34;,&#34;dropCap&#34;:false}&#34;&gt;在 Monorepo 中设置、实现影响许多库及其测试的大差异可能非常具有挑战性，更糟糕的是，当它们的测试不稳定时。不是由差异本身引起的一种片状故障可能会导致整个作业的完全重建。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;7c4cb204-64b8-4763-ae46-c161528a28f0&#34;,&#34;dropCap&#34;:false}&#34;&gt;我们的一般指导是为了避免在 CI 中运行不稳定的测试。然而，当工程师尝试修复不稳定的测试并提交差异时，问题很快就会出现。如果它在 CI 中仍然被忽略，那么我们不知道该修复是否有效。或者更糟糕的是，它可能完全破坏了测试，但因为 CI 不验证它，所以我们永远不知道它被破坏了。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;1fd1fc8e-dbcf-4235-a0ca-5e5e426879d9&#34;,&#34;dropCap&#34;:false}&#34;&gt;因此，我们围绕此实施了多种策略：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;62b6b7d9-27cc-41a7-be02-48da9040618c&#34;,&#34;ordered&#34;:false,&#34;values&#34;:&#34; “}”&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;无论是否不稳定，专门标记为“关键”的测试都将在 CI 作业上运行&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;工程师可以在差异中专门添加标签或关键字来选择退出该行为&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;其他片状测试（例如集成测试）以非阻塞模式运行，仅供参考&lt;/li &gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;d6dacd11-3219-4579-8755-3ae4c28f4621&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-reducing-impact-of-flaky-tests&#34;&gt;减少片状测试的影响&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;6c74df2d-0ef8-43a6-94bb-9c7487224518&#34;,&#34;dropCap&#34;:false}&#34;&gt;要跳过的策略CI 阶段的片状测试由每个领域所有者实施。例如，Golang 和 Java 可能有非常不同的测试运行器模式，因此使用不同的测试过滤器机制。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;c425d55d-13c9-4bc9-9a9c-d692b061ad24&#34;,&#34;dropCap&#34;:false}&#34;&gt;在 Go 中例如 Monorepo，我们有不同的方法来跳过测试用例和测试目标。为了跳过测试目标，我们排除直接在 CI 中运行片状测试目标，但仍然确保目标是可构建的。如果目标仅包含某些片状测试用例而其他测试用例仍然有用怎么办？我们是在 &lt;a href=&#34;https://github.com/bazelbuild/rules_go/blob/master/docs/go/core/rules.md#go_test&#34;&gt;rules_go&lt;/a&gt; 中实现了一项功能，以跳过测试用例 &lt; a href=&#34;https://tip.golang.org/doc/go1.20#go-command&#34;&gt;Go 1.20 -skip&lt;/a&gt; 测试标志和解析 &lt;a href=&#34;https://github.com/ bazelbuild/rules_go/pull/3618&#34;&gt;TESTBRIDGET_TEST_ONLY&lt;/a&gt; 环境变量。这样，有关片状测试的信息与 Bazel 规则的输入隔离，并且无论片状如何，测试缓存都可以保持稳定。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;7b1dc38f-fc86-4eb5-b876-566d830c0892&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-accountability&#34;&gt;责任&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;8c7b0d34-65bc-498b-a4ef-4971b61db541&#34;,&#34;dropCap&#34;:false}&#34;&gt;现在我们有发现了一些不稳定的测试并在 CI 中采取了相应的行动。下一步是什么？ &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;7b3d4289-d442-469c-95d1-a7e45ed60919&#34;,&#34;dropCap&#34;:false}&#34;&gt;我们需要将此类发现通知测试作者，并鼓励他们尽快修复测试。我们可以通过立即调用 JIRA、Slack 等票务模块来做到这一点。然而，在 Uber，即使是最小的领域也有数千次测试，显然我们无法承受等待外部系统的延迟和成本。为每一个人做出回应或提交票据。因此，我们在 Testopedia 中设计了一个异步系统，可以根据分组规则提交票证。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;d9243171-5187-4b6f-bc38-e0be649c722b&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;align&#34;:&#34;center&#34;,&#34;hash&#34;:&#34;8580d91a-7318-435b-9657-c22f64d7a2b3&#34;,&#34;alt&#34; :&#34;&#34;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img 解码=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXefNJ-bMu_P-R7GsX8K7fqdWfWwcOMx8HDY1RZom-bf92pEGA9FSKufI5KEuoPsq6ZCnLR_pokvWi8i45Vg9q9Ta9fS8 plpLT_mNbXDlq4O7uXQP7SqdwYuD-hmK4tItY_XEc73ucAql6xJIoxwjncBwLNl?key=6gZ2dLlV7xzsqb0CRMkSGA&#34; 替代=&#34;&#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;图 8：票据归档图。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;882b59d5-3722-4d97-954c-132783948075&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;af0318e1-7967-49ae-a68f-42cbec887322&#34;,&#34;dropCap&#34;:false}&#34;&gt;测试时被分析器判定为不健康，除了在数据库中更新外，还会插入到消息队列。然后，节奏工作流程会触发队列，再次检查这些测试，并调用 JIRA 向所属团队提交票据。 Bazel 测试目标可以有多个测试用例，我们将每个测试用例作为 FQN 进行跟踪，但我们只想为每组类似测试提交一张票以减少噪音。因此，我们提出了一个分组概念，将所有不健康的 FQN 放入每个组的一张票据中 - 通过构建目标或通过正则表达式。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;ad540953-fb38-4b16-8a00-bd112e0573cb&#34;,&#34;dropCap&#34;:false}&#34;&gt;我们还制作了整个模块可定制，用户可以自定义分组规则、工单类型、优先级，甚至工单描述模板。典型的任务配置如下所示：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;0dd3bc99-5289-4056-92cc-41b1efc92745&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&#34;align&#34;:&#34;center&#34;,&#34;hash&#34;:&#34;89573d15-7a58-40cc-be19-acc9f36c50b8&#34;,&#34;alt&#34; :&#34;&#34;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img 解码=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXcOx9cAS4GShBGqQ2zpaS0C0nOYLfRj6oITaJzZS1zphl94Xa8Yh_F3CgcWaiiCgVe5PmdjrwZdkjG-XhDHvqzy mBqPDBp6oPS1bm7dtuNKJje1tSzcv_e-JttdXGfhtrTimkxGKj-nP3mbUNjavDYVeSAB?key=6gZ2dLlV7xzsqb0CRMkSGA&#34; alt=&#34; &#34;referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;图 9：工单归档配置。&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;38f70198-b6a3-430c-a37c-a87da2a113ad&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;445a5cc8-33ba-45e5-bb5f-fa8e7c3b9910&#34;,&#34;dropCap&#34;:false}&#34;&gt;这样团队将具有不同的测试结构，并根据用户体验定义自己的通知策略。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;33d2efc9-9966-4fd1-be74-3909cef2a575&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;8689adb6-39e5-44f8-a8c1-f4ebd1d15f5f&#34;,&#34;level&#34;:2}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-future-plans&#34;&gt;未来计划&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;7461339c-0fd9-4f32-835e-82ea172ea659&#34;,&#34;dropCap&#34;:false}&#34;&gt;Uber 正在积极进行&lt;a href=&#34;https://www.uber.com/blog/generative-ai-for-high-quality-mobile-testing/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;开发各种法学硕士&lt;/a &gt; 改善我们的开发者体验。我们设想合并未来将这些尖端技术融入到系统中：&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;e65a2e04-4d32-4151-b68f-f3125ab85042&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-integrate-genai-for-automated-flaky-tests-resolution&#34;&gt;&lt;strong&gt;集成 GenAI 以实现自动化片状测试分辨率&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;90165264-95ca-4093-ab1a-2692e488aca3&#34;,&#34;ordered&#34;:false,&#34;values&#34;:&#34; &#34;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;89e4f0ed-c7cf-4f0d-813b-a588c699d901&#34;,&#34;dropCap&#34;:false}&#34;&gt;在 FQN 之后导入并分析后，可以访问其所有历史数据和其他测试失败模式，我们可以使用 GenAI 自动生成该测试的修复程序。我们正在探索 Uber 内部构建的 GenAI 集成，以帮助集中减少 Monorepos 中不健全测试的数量，而测试负责人的投入最少。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:3,&#34;hash&#34;:&#34;1a8d12f3-9a7d-486e-be97-aa4095c39440&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-more-grinar-failure-categorization-and-sub-categorization&#34;&gt;&lt;strong&gt;更细粒度的故障分类和子分类&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;a5652f35-a04c-4bef-810a-6c3d8ed466a2&#34;,&#34;ordered&#34;:false,&#34;values&#34;:&#34; &#34;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;0cbdb05f-4946-48db-8909-cd6a025caf85&#34;,&#34;dropCap&#34;:false}&#34;&gt;当前 FSM模型提供了通用的分类桶，但是，并非所有测试失败都是相同的。子分类是在领域级别明确完成的。通过利用人工智能分析故障模式，我们可以根据错误日志和类型、测试环境或故障代码上下文等因素自动将测试故障分类为更具体的子组。这种增强的分类系统将使我们能够更有效地进行故障排除和解决。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;6d81cf93-e710-4a1b-bf30-f77e0da1644b&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&#34;level&#34;:1,&#34;hash&#34;:&#34;e582e269-4a27-4b1c-bf1d-1509cf36cc4d&#34;}&#34; class=&#34;wp -block-heading&#34; id=&#34;h-conclusion&#34;&gt;结论&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;02683e3d-8852-43ba-be66-3d6fad03205d&#34;,&#34;dropCap&#34;:false}&#34;&gt;现在所有Uber 的主要 Monorepos 已加入 Testopedia，并且随着内部算法和基础设施组件的大量优化，它比曾经。在 Go Monorepo 中，我们在总共 600K 测试中稳定地检测到大约 1000 个片状测试，其中 Java 测试中有 1K/350K。我们还观察到 CI 可靠性显着提高，重试次数大幅减少。使用包含正确信息的 Jira 票据来烦扰开发人员，极大地帮助扭转了不稳定测试数量不断增加的趋势。&lt;/p&gt;</description>
      <pubDate>Tue, 04 Jun 2024 07:25:02 +0000</pubDate>
    </item>
  </channel>
</rss>