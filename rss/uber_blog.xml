<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Uber Engineering Blog</title>
    <link>http://rsshub.rssforever.com/uber/blog</link>
    <description>The technology behind Uber Engineering - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)</description>
    <managingEditor>i@diygod.me (DIYgod)</managingEditor>
    <item>
      <title>【Introduction to Kafka Tiered Storage at Uber】Uber 的 Kafka 分层存储简介</title>
      <link>https://www.uber.com/blog/kafka-tiered-storage/</link>
      <description>【&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;433c69f8-24e4-4e25-8a58-c3011be3d1bb&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-introduction&#34;&gt;Introduction&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b3315f9e-7720-4fae-a737-4602be48fcf0&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Apache Kafka® is the cornerstone of Uber’s tech stack. It plays an important role in powering several critical use cases and is the foundation for batch and real-time systems at Uber.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;bae21b7b-4f98-483f-92f9-60ab827ef689&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;5fd7c743-bdd7-40d7-9e81-86f4e342f1a4&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXePSpSp72unfaVqK7tofbbbOpMaZLJ7qYJ2Es-Chg3CHBeZ9kcJDZ9ouvPRYs-CarI8bAqXs2459rJ0_QrsgBaUwqikE5fwYSianNkl1u6Ehbjz_yH6XuWJGn54P5kCaRSaBrCgeVPN4q2QC_RDu9ag1YgU?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 1: Uber’s Data Pipeline.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;bba04fc7-d627-4e13-97a1-c1511775c833&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;213c11a1-ab13-4d60-a5f8-2bf22f25ae86&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Kafka stores the messages in append-only log segments on the broker’s local storage. Each topic can be configured with the targeted retention based on size or time. It gives guarantees for users to consume the data within the retention period or size even when the respective consuming applications fail or become slow for several reasons. Total storage on a cluster depends upon factors like the total number of topic partitions, produce throughput, and retention configuration. A Kafka broker typically needs to have larger storage to support the required topic partitions hosted on a broker.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;f27d9aad-98e4-44d8-8c39-d27574431a59&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-motivation-background-behind-project&#34;&gt;Motivation/Background Behind Project&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2acf6879-58ec-4dc2-9411-023216a9e7e4&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Kafka cluster storage is typically scaled by adding more broker nodes to the cluster. But this also adds needless memory and CPUs to the cluster, making overall storage cost less efficient compared to storing the older data in external storage. A larger cluster with more nodes also adds to the deployment complexity and increases operational costs because of the tight coupling of storage and processing. So, it brings several issues related to scalability, efficiency, and operations.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0657efab-21dc-423f-b42f-c4dc1ed5da8d&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We proposed Kafka Tiered Storage (&lt;a href=&#34;https://cwiki.apache.org/confluence/display/KAFKA/KIP-405%3A+Kafka+Tiered+Storage&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;KIP-405&lt;/a&gt;) to avoid tight coupling of storage and processing in a broker. It provides two tiers of storage, called local and remote. These two tiers can have respective retention policies based on the respective use cases.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7bb99c16-9f01-4606-9393-18634deb8b8c&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;width&amp;quot;:&amp;quot;700px&amp;quot;,&amp;quot;height&amp;quot;:&amp;quot;auto&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;e25cccec-32e4-4c15-976a-4a4725861800&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXdrkDm5z8lSbIzR0Xure8R4qrXa8JqczXMcNyQs17yede4tKZScrbVWTc4PjScxs-k_qrcks2cLmf2nOJi9x4tf2Zyzyql2Ql7jA3Ty4qNQoth7NeTL9itjkQnaJKIwm3zZVYUgYXx_2yr4lgyAF-9eLr-i?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 2: End to end interaction of Kafka broker with tiered storage.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d3f58e6f-e3fc-4df8-84f2-247071e699aa&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;00272d69-19b6-4d44-b7f1-ab451bbd36af&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-goals&#34;&gt;Goals&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f8ada8a4-3425-4352-bd37-c99f0a8e6291&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Below are the main goals that we set for tiered storage:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3cd3f2c9-a5d0-44a3-8335-ca7b05d03d38&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Extend the storage beyond the broker&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Memory/PageCache&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Local storage&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Remote storage support (including cloud/object stores like S3/GCS/Azure)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Durability and Consistency semantics similar to local storage&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Isolation of reading latest and historical data&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;No changes are required from clients&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Easy tuning and provisioning of clusters&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Improve operational and cost efficiency&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f96a808a-53f5-4733-a618-0ed612929034&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;87df347d-17d7-42dc-b9b6-856160fbd93e&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-architecture&#34;&gt;Architecture&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f6ceb13c-20bc-44d2-be91-a3cc6b3523ae&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Kafka cluster enabled with tiered storage is configured with two tiers of storage called local and remote. The local tier is the broker’s local storage where the segments are stored currently. The new remote tier is the extended storage, such as HDFS/S3/GCS/Azure. Both these tiers will have respective retention configurations based on size and time. The retention period for the local tier can be significantly reduced from days to a few hours. The retention period for the remote tier can be much longer–days, or even months. Applications sensitive to latency conduct tail reads and are catered to from the local tier, utilizing Kafka’s efficient page cache utilization for data retrieval. On the other hand, applications such as backfill or those recovering from failures requiring older data than what’s locally available, are served from the remote tier.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;99e485ed-bfbb-4a06-83f3-7781b0ccb009&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;This approach enables the scalability of storage in a Kafka cluster without being tied to memory and CPU resources, thus transforming Kafka into a viable long-term storage option. Moreover, it decreases the local storage burden on Kafka brokers, consequently reducing the data to be transferred during recovery and rebalancing. Log segments accessible in the remote tier don’t require restoration on the broker and can be accessed directly from the remote tier. It eliminates the necessity to expand the Kafka cluster storage and add new nodes when extending the retention period. Additionally, it allows for significantly longer data retention without the requirement for separate data pipelines to transfer data from Kafka to external storage (a common practice in many current setups).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;285c094f-9538-44de-9270-4721f1bf1133&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Tiered storage divides a topic partition’s log into two different logical components called local log and remote log. Local log contains a list of local log segments and remote log contains a list of remote log segments. The remote log subsystem copies each topic partition’s eligible segments from local storage to the remote storage. A segment is eligible to be copied when its end offset is less than &lt;em&gt;LastStableOffset&lt;/em&gt; of a partition.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2d6d304d-aba7-46d5-aa43-bad98a0e13d3&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;bf09d07e-1d0f-4647-8465-310196ef72ff&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXdDJEudzpCrGDSR9yN0sNZ5YU_AM1ExXihNssXH0d5SGi01nOJ4R6xY0yY7frm6ESriC5o6XFiqQMVSCVDWpRK0l6nFxaF8CBCdY0ZpN1beZUsmqpSe4VragjX8kjUjh5VXGKMD-g2i9GMOaIJ99if2dJkj?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 3: Local log offsets and remote log offsets.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;656259a5-41ec-4162-a1a8-fa9680404f3d&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure data-wp-block-name=&#34;core/table&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;970a47e8-729d-4286-a17f-307c713c9f18&amp;quot;,&amp;quot;hasFixedLayout&amp;quot;:false,&amp;quot;head&amp;quot;:[],&amp;quot;body&amp;quot;:[],&amp;quot;foot&amp;quot;:[]}&#34; class=&#34;wp-block-table&#34;&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt; Lz&amp;nbsp; = Local log end offset&amp;nbsp;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;Lx&amp;nbsp; = Local log start offset &amp;nbsp;&lt;/td&gt;&lt;td&gt;Ly&amp;nbsp; = Last stable offset(LSO)&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure data-wp-block-name=&#34;core/table&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c7fa71b6-1b3f-414b-9d7d-8967a9a41e7a&amp;quot;,&amp;quot;hasFixedLayout&amp;quot;:false,&amp;quot;head&amp;quot;:[],&amp;quot;body&amp;quot;:[],&amp;quot;foot&amp;quot;:[]}&#34; class=&#34;wp-block-table&#34;&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;Ry&amp;nbsp; = Remote log end offset &lt;/td&gt;&lt;td&gt;Rx&amp;nbsp; = Remote log start offset&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;em&gt;Lz &amp;gt;= Ly &amp;gt;= Lx and Ly &amp;gt;= Ry &amp;gt;= Rx&lt;/em&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;cdfcf4f5-b74b-4219-ab12-4bb78c78a00a&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a1242f90-4a1d-4f87-9dc7-e49627a2062a&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Apache Kafka storage subsystem maintains the above offset constraints for local and remote log segments of a topic partition.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b4c968f9-e76a-4c83-a966-e0dae7131168&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;width&amp;quot;:&amp;quot;700px&amp;quot;,&amp;quot;height&amp;quot;:&amp;quot;auto&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;f687a646-355f-4412-9ad8-f793d9942d75&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXcnNa5SMjEkpYEOgrEV8WQaKzXNhUFy5I1iuFKcHifODuPUg26arhCP8wvWpPsm7onOA8jTn2IS7_tTF9VXmg2NHC2p5IPSFLXw39fP8b4c47ksowG9dYI-iyFHE2szvRfNMn-QBQc4s_lgOg0tMYH3sKw?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 4: High level architecture of Kafka tiered storage components.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a7ef1ee3-e8df-4942-b3ac-a88b2ec5feca&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d568d925-c3a2-4eed-ab17-976503458642&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The above diagram gives a high-level overview of the new architecture with newly introduced components:&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9c25ec3d-7751-4e49-9a9d-183df57a2782&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;RemoteStorageManager&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;RemoteLogMetadataManager&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;RemoteLogManager&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6ffe5286-c491-4dd9-9573-0439c7790602&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We introduced two pluggable components within the storage layer called &lt;em&gt;RemoteStorageManager&lt;/em&gt; and &lt;em&gt;RemoteLogMetadataManager&lt;/em&gt;. These can be implemented by developers based on their targeted storage systems and plugged into their Kafka environments.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c3bb416c-1811-4b68-bd52-f28cc63a8d4f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;em&gt;RemoteStorageManager&lt;/em&gt; interface provides the actions for remote log segments that include copy, fetch, and delete from remote storage.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7c9686e1-1c96-4cd4-81fc-4e4651a9ca6e&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;em&gt;RemoteLogMetadataManager&lt;/em&gt; interface provides the lifecycle operations of metadata about remote log segments with strongly consistent semantics. There is a default implementation that uses an internal topic. Users can plugin their implementation if they intend to use another system to store remote log segment metadata.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;10f1a733-e2e1-4da9-9e2b-f0575b8179ce&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;em&gt;RemoteLogManager&lt;/em&gt; is a logical layer responsible for managing the life cycle of remote log segments. That includes:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;cfbe1efc-e968-4d3c-a129-657cab42d2c5&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Copying segments to the remote storage&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Cleaning up of expired segments in the remote storage&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Fetching the data from remote storage&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6085e748-3614-425e-a85e-1814e32e68d3&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;It also uses the pluggable remote storage components as and when needed. Each remote log segment is identified with a unique identifier called &lt;em&gt;RemoteLogSegmentId&lt;/em&gt;, even for the same topic partition and offsets.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1b79721a-afd5-45be-aa53-a361a4db4016&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;f9f19038-588b-4ba3-b4f1-61bf5bd2c67e&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-copying-segments-to-remote-storage&#34;&gt;Copying Segments to Remote Storage&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6501289f-c0a1-44f9-8bd8-c47cc0d57d36&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Each topic partition stores data in a logical log, which contains a sequence of physical log segments with the respective auxiliary files like segment indexes, producer state snapshots, and leader epoch checkpoints. Each partition replica creates these log segments, flushes them to disk and rolls over the segment based on segment roll configurations based on size or time. A log segment is eligible if its end offset is less than the &lt;em&gt;last-stable-offset&lt;/em&gt; of the partition. The broker acting as a leader for a topic partition is responsible for copying the eligible log segments to the remote storage. It copies the log segments from the earliest segment to the latest segment in a sequence. It uses &lt;em&gt;RemoteStorageManager&lt;/em&gt; for copying the segment with its indexes like offset, timestamp, producer snapshot, and its respective leader epoch cache. It also adds and updates entries in &lt;em&gt;RemoteLogMetadataManager&lt;/em&gt; with respective states for each copied segment.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;595ecbe5-36d6-43dc-9fe1-0c740e87c7e5&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The below diagram shows the sequence of copying the segments by maintaining local and remote log segments:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;db6e0950-4607-4d3f-9176-15c6f1f3552e&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;9e0b7194-32dc-4f35-96f9-3c9aea1767ac&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXcf2ufqsgcmWb4xf9M4813H55wCn9NC_n8HxCRK5nOT12LvqY5GNmRP_Rh4fqfiDk0SYdJ-63XaxZU5bTrleU-Ap77XBl0eyvjYc1_RIME_6AxlIGXWu9oLOoa3j9PQWyICHXjeOqISivV5Rcx2AhuAHGaU?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 5: The above diagram depicts a topic partition’s log segments with their respective start offsets. Before tiered storage is enabled, there will not be any segments in the remote storage.&amp;nbsp;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8578077d-7ecc-44cf-b2f0-ee21c603f836&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;c14dd36f-9fea-4da5-902f-1e4de0392748&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXc26wPlPeq7XR91GrM_6-QfWh0y6rKGCpGvA1islRticBFGAx33pR0Wm5cMl8OZSoDFm1RNKtpNcRKlj6Bcvuke-cdXBhNEGImxFphNDUBYoI3zb0XTYUek87oPOzV7OfcLoO86FkTeqyFrgFZpfzmAKT0?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 6: The above diagram depicts the eligible segments started copying to remote storage after tiered storage is enabled for that topic.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a33e00c6-209c-44cb-91ac-5222d96c8ab9&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1091633,&amp;quot;sizeSlug&amp;quot;:&amp;quot;full&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;055f601e-69cd-4a34-b281-14623b69c018&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;899&#34; height=&#34;333&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/07/Figure7.png&#34; alt=&#34;&#34; class=&#34;wp-image-1091633&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=899,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/07/Figure7.png 899w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/07/Figure7.png 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/07/Figure7.png 768w&#34; sizes=&#34;(max-width: 899px) 100vw, 899px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 7: The above diagram depicts some of the segments in the local storage were deleted based on the local retention configuration. We can see that segments earlier to offset 300 were deleted, but those segments are available in remote storage.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;47e9b3a2-d752-4c0a-b5b3-c66e7a0fcbf4&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;1058e67b-5adb-4dac-9629-89c807ae2bc7&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-cleaning-up-of-remote-segments&#34;&gt;Cleaning up of Remote Segments&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;035f67ed-dda2-4d78-bbf0-cbf76a605f64&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;As mentioned earlier, each topic will have a retention configuration based on size and time for both local data and remote data. Remote data is cleaned up at regular intervals by computing the eligible segments by a dedicated thread pool. This is different from the asynchronous cleaning up of the local log segments. When a topic is deleted, cleaning up of remote log segments is done asynchronously and it will not block the existing delete operation or recreate a new topic.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9d0dbe68-efc5-4c44-93c5-b07b115f3954&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;990b7b23-7491-49d7-a00a-1d9f3469b53b&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXczW4_RY_MyEEv6A1X0Rw2k7Yr-bPzt139veWuSaeGKqD_27xKyhqivZW609v4GUADtafNrZBmdzC9S9xj72tOTtqbKl9n_ivg9vkIdTJb4Lt7sK7I6UNt20kjrDUP2dwODaVr7rERXZgMfeazr9nxKJhe8?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 8: The above diagram depicts the cleaning up of remote log segments based on the complete log retention configuration. Here, segments earlier to offset 200 were deleted.&amp;nbsp;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c74af8b0-ee98-426a-893e-788c5b3562cc&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;9df2b72c-e610-471d-a7bb-752f19e9e225&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-fetching-segments-from-remote-storage&#34;&gt;Fetching Segments from Remote Storage&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1139aefd-e5bd-423e-9902-ebc767f49ba0&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;When a consumer fetch request is received and it is only available only in remote storage, then it is served using a dedicated thread pool. If the targeted offset is available in the broker’s local storage, then it is served using the existing local fetch mechanism. So, a broker separates the local reads from remote reads and they will not block each other.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4d905c15-c255-49f9-b98c-2fd8fb2e2d4a&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;em&gt;RemoteLogManager&lt;/em&gt; determines the targeted remote segment based on the desired offset and leader epoch by looking into the metadata store using &lt;em&gt;RemoteLogMetadataManager&lt;/em&gt;. It uses &lt;em&gt;RemoteStorageManager&lt;/em&gt; to find the position within the segment and start fetching the desired data.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0af941c5-ea10-4ee5-9180-0fa2f7d5be33&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;width&amp;quot;:&amp;quot;700px&amp;quot;,&amp;quot;height&amp;quot;:&amp;quot;auto&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;9289e088-db11-4e29-86df-02a1996c879d&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXfCCN3aludPERABf77NGITGxCPFcslvI11RammENhBCFoxUSl4XtWKzILkalB2GRWE4MO6WxBxw0QWLV8shK8Y1IVbUKUAQueS3mnZLbVx1E-T_rq_udar088WHjkWVIEt7xhf2xq5tCNBwZrsk4PuzIli8?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 9: Remote fetch path.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e8bfa664-6413-43d2-ac3c-06d4c632a8d8&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;02f4064f-5abd-43a4-a24e-9ac92c32faa2&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-follower-replication&#34;&gt;Follower Replication&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8a9f7dc7-6191-48fc-8184-b987a9abfde7&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Followers replicate the data from a leader to become an in-sync replica. They need to maintain the message lineage across a sequence of log segments as the leader. They may also do truncation of the segments if needed to maintain the message ordering.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;26775e4f-0ecd-4026-b6bb-79139de3d112&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;With tiered storage, follower replicas need to replicate the segments that are available on the leader’s local storage. Each log also needs auxiliary data like leader epoch state and producer-ID snapshots. So, a follower needs to build this auxiliary data before it starts fetching any messages from the leader. The follower fetch protocol makes sure to maintain the consistency and ordering of messages across all the replicas irrespective of changes in the cluster like broker replacements, failures, etc. If you are interested in understanding the inner workings of the enhanced follower fetch protocol, you can read it in the &lt;a href=&#34;https://cwiki.apache.org/confluence/display/KAFKA/KIP-405%3A+Kafka+Tiered+Storage#KIP405:KafkaTieredStorage-FollowerReplication&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;original document&lt;/a&gt; to understand the detailed design and how it handles several scenarios.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;5cf5ae52-b9e7-4d38-b2a6-d2346e2d9e75&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-conclusion&#34;&gt;Conclusion&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ed0dbc6e-6b12-4836-b874-e1a7425c4815&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In this blog, we covered an introduction and high-level architecture of tiered storage at Uber. If you are interested in more details, you can read the detailed design in &lt;a href=&#34;https://cwiki.apache.org/confluence/display/KAFKA/KIP-405%3A+Kafka+Tiered+Storage&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;KIP-405&lt;/a&gt;. Most of this work was done collaborating with the Apache Kafka community. The major part of this feature is available as early access in Apache Kafka 3.6.0.&amp;nbsp; This feature has been running in production for ~1-2 years in different workloads respectively. In the next part of this blog series we will cover our production experience and how it helped with better reliability, scalability, and efficiency of our clusters.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;fontSize&amp;quot;:&amp;quot;small&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;3b7d71e6-2de6-46a6-8a92-a754b708a278&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34; class=&#34;has-small-font-size&#34;&gt;Apache®, Apache Kafka™, and Kafka™ are either registered trademarks or trademarks of the Apache Software Foundation in the United States and/or other countries. No endorsement by The Apache Software Foundation is implied by the use of these marks.&lt;/p&gt;】&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;433c69f8-24e4-4e25-8a58-c3011be3d1bb&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-introduction&#34;&gt;Introduction&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b3315f9e-7720-4fae-a737-4602be48fcf0&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Apache Kafka® is the cornerstone of Uber’s tech stack. It plays an important role in powering several critical use cases and is the foundation for batch and real-time systems at Uber.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;bae21b7b-4f98-483f-92f9-60ab827ef689&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;5fd7c743-bdd7-40d7-9e81-86f4e342f1a4&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXePSpSp72unfaVqK7tofbbbOpMaZLJ7qYJ2Es-Chg3CHBeZ9kcJDZ9ouvPRYs-CarI8bAqXs2459rJ0_QrsgBaUwqikE5fwYSianNkl1u6Ehbjz_yH6XuWJGn54P5kCaRSaBrCgeVPN4q2QC_RDu9ag1YgU?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 1: Uber’s Data Pipeline.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;bba04fc7-d627-4e13-97a1-c1511775c833&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;213c11a1-ab13-4d60-a5f8-2bf22f25ae86&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Kafka stores the messages in append-only log segments on the broker’s local storage. Each topic can be configured with the targeted retention based on size or time. It gives guarantees for users to consume the data within the retention period or size even when the respective consuming applications fail or become slow for several reasons. Total storage on a cluster depends upon factors like the total number of topic partitions, produce throughput, and retention configuration. A Kafka broker typically needs to have larger storage to support the required topic partitions hosted on a broker.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;f27d9aad-98e4-44d8-8c39-d27574431a59&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-motivation-background-behind-project&#34;&gt;Motivation/Background Behind Project&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2acf6879-58ec-4dc2-9411-023216a9e7e4&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Kafka cluster storage is typically scaled by adding more broker nodes to the cluster. But this also adds needless memory and CPUs to the cluster, making overall storage cost less efficient compared to storing the older data in external storage. A larger cluster with more nodes also adds to the deployment complexity and increases operational costs because of the tight coupling of storage and processing. So, it brings several issues related to scalability, efficiency, and operations.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0657efab-21dc-423f-b42f-c4dc1ed5da8d&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We proposed Kafka Tiered Storage (&lt;a href=&#34;https://cwiki.apache.org/confluence/display/KAFKA/KIP-405%3A+Kafka+Tiered+Storage&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;KIP-405&lt;/a&gt;) to avoid tight coupling of storage and processing in a broker. It provides two tiers of storage, called local and remote. These two tiers can have respective retention policies based on the respective use cases.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7bb99c16-9f01-4606-9393-18634deb8b8c&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;width&amp;quot;:&amp;quot;700px&amp;quot;,&amp;quot;height&amp;quot;:&amp;quot;auto&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;e25cccec-32e4-4c15-976a-4a4725861800&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXdrkDm5z8lSbIzR0Xure8R4qrXa8JqczXMcNyQs17yede4tKZScrbVWTc4PjScxs-k_qrcks2cLmf2nOJi9x4tf2Zyzyql2Ql7jA3Ty4qNQoth7NeTL9itjkQnaJKIwm3zZVYUgYXx_2yr4lgyAF-9eLr-i?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 2: End to end interaction of Kafka broker with tiered storage.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d3f58e6f-e3fc-4df8-84f2-247071e699aa&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;00272d69-19b6-4d44-b7f1-ab451bbd36af&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-goals&#34;&gt;Goals&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f8ada8a4-3425-4352-bd37-c99f0a8e6291&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Below are the main goals that we set for tiered storage:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3cd3f2c9-a5d0-44a3-8335-ca7b05d03d38&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Extend the storage beyond the broker&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Memory/PageCache&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Local storage&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Remote storage support (including cloud/object stores like S3/GCS/Azure)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Durability and Consistency semantics similar to local storage&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Isolation of reading latest and historical data&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;No changes are required from clients&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Easy tuning and provisioning of clusters&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Improve operational and cost efficiency&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f96a808a-53f5-4733-a618-0ed612929034&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;87df347d-17d7-42dc-b9b6-856160fbd93e&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-architecture&#34;&gt;Architecture&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f6ceb13c-20bc-44d2-be91-a3cc6b3523ae&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Kafka cluster enabled with tiered storage is configured with two tiers of storage called local and remote. The local tier is the broker’s local storage where the segments are stored currently. The new remote tier is the extended storage, such as HDFS/S3/GCS/Azure. Both these tiers will have respective retention configurations based on size and time. The retention period for the local tier can be significantly reduced from days to a few hours. The retention period for the remote tier can be much longer–days, or even months. Applications sensitive to latency conduct tail reads and are catered to from the local tier, utilizing Kafka’s efficient page cache utilization for data retrieval. On the other hand, applications such as backfill or those recovering from failures requiring older data than what’s locally available, are served from the remote tier.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;99e485ed-bfbb-4a06-83f3-7781b0ccb009&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;This approach enables the scalability of storage in a Kafka cluster without being tied to memory and CPU resources, thus transforming Kafka into a viable long-term storage option. Moreover, it decreases the local storage burden on Kafka brokers, consequently reducing the data to be transferred during recovery and rebalancing. Log segments accessible in the remote tier don’t require restoration on the broker and can be accessed directly from the remote tier. It eliminates the necessity to expand the Kafka cluster storage and add new nodes when extending the retention period. Additionally, it allows for significantly longer data retention without the requirement for separate data pipelines to transfer data from Kafka to external storage (a common practice in many current setups).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;285c094f-9538-44de-9270-4721f1bf1133&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Tiered storage divides a topic partition’s log into two different logical components called local log and remote log. Local log contains a list of local log segments and remote log contains a list of remote log segments. The remote log subsystem copies each topic partition’s eligible segments from local storage to the remote storage. A segment is eligible to be copied when its end offset is less than &lt;em&gt;LastStableOffset&lt;/em&gt; of a partition.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2d6d304d-aba7-46d5-aa43-bad98a0e13d3&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;bf09d07e-1d0f-4647-8465-310196ef72ff&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXdDJEudzpCrGDSR9yN0sNZ5YU_AM1ExXihNssXH0d5SGi01nOJ4R6xY0yY7frm6ESriC5o6XFiqQMVSCVDWpRK0l6nFxaF8CBCdY0ZpN1beZUsmqpSe4VragjX8kjUjh5VXGKMD-g2i9GMOaIJ99if2dJkj?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 3: Local log offsets and remote log offsets.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;656259a5-41ec-4162-a1a8-fa9680404f3d&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure data-wp-block-name=&#34;core/table&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;970a47e8-729d-4286-a17f-307c713c9f18&amp;quot;,&amp;quot;hasFixedLayout&amp;quot;:false,&amp;quot;head&amp;quot;:[],&amp;quot;body&amp;quot;:[],&amp;quot;foot&amp;quot;:[]}&#34; class=&#34;wp-block-table&#34;&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt; Lz&amp;nbsp; = Local log end offset&amp;nbsp;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;Lx&amp;nbsp; = Local log start offset &amp;nbsp;&lt;/td&gt;&lt;td&gt;Ly&amp;nbsp; = Last stable offset(LSO)&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure data-wp-block-name=&#34;core/table&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c7fa71b6-1b3f-414b-9d7d-8967a9a41e7a&amp;quot;,&amp;quot;hasFixedLayout&amp;quot;:false,&amp;quot;head&amp;quot;:[],&amp;quot;body&amp;quot;:[],&amp;quot;foot&amp;quot;:[]}&#34; class=&#34;wp-block-table&#34;&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;Ry&amp;nbsp; = Remote log end offset &lt;/td&gt;&lt;td&gt;Rx&amp;nbsp; = Remote log start offset&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;em&gt;Lz &amp;gt;= Ly &amp;gt;= Lx and Ly &amp;gt;= Ry &amp;gt;= Rx&lt;/em&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;cdfcf4f5-b74b-4219-ab12-4bb78c78a00a&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a1242f90-4a1d-4f87-9dc7-e49627a2062a&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Apache Kafka storage subsystem maintains the above offset constraints for local and remote log segments of a topic partition.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b4c968f9-e76a-4c83-a966-e0dae7131168&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;width&amp;quot;:&amp;quot;700px&amp;quot;,&amp;quot;height&amp;quot;:&amp;quot;auto&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;f687a646-355f-4412-9ad8-f793d9942d75&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXcnNa5SMjEkpYEOgrEV8WQaKzXNhUFy5I1iuFKcHifODuPUg26arhCP8wvWpPsm7onOA8jTn2IS7_tTF9VXmg2NHC2p5IPSFLXw39fP8b4c47ksowG9dYI-iyFHE2szvRfNMn-QBQc4s_lgOg0tMYH3sKw?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 4: High level architecture of Kafka tiered storage components.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a7ef1ee3-e8df-4942-b3ac-a88b2ec5feca&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d568d925-c3a2-4eed-ab17-976503458642&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The above diagram gives a high-level overview of the new architecture with newly introduced components:&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9c25ec3d-7751-4e49-9a9d-183df57a2782&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;RemoteStorageManager&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;RemoteLogMetadataManager&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;RemoteLogManager&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6ffe5286-c491-4dd9-9573-0439c7790602&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We introduced two pluggable components within the storage layer called &lt;em&gt;RemoteStorageManager&lt;/em&gt; and &lt;em&gt;RemoteLogMetadataManager&lt;/em&gt;. These can be implemented by developers based on their targeted storage systems and plugged into their Kafka environments.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c3bb416c-1811-4b68-bd52-f28cc63a8d4f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;em&gt;RemoteStorageManager&lt;/em&gt; interface provides the actions for remote log segments that include copy, fetch, and delete from remote storage.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7c9686e1-1c96-4cd4-81fc-4e4651a9ca6e&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;em&gt;RemoteLogMetadataManager&lt;/em&gt; interface provides the lifecycle operations of metadata about remote log segments with strongly consistent semantics. There is a default implementation that uses an internal topic. Users can plugin their implementation if they intend to use another system to store remote log segment metadata.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;10f1a733-e2e1-4da9-9e2b-f0575b8179ce&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;em&gt;RemoteLogManager&lt;/em&gt; is a logical layer responsible for managing the life cycle of remote log segments. That includes:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;cfbe1efc-e968-4d3c-a129-657cab42d2c5&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Copying segments to the remote storage&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Cleaning up of expired segments in the remote storage&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Fetching the data from remote storage&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6085e748-3614-425e-a85e-1814e32e68d3&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;It also uses the pluggable remote storage components as and when needed. Each remote log segment is identified with a unique identifier called &lt;em&gt;RemoteLogSegmentId&lt;/em&gt;, even for the same topic partition and offsets.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1b79721a-afd5-45be-aa53-a361a4db4016&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;f9f19038-588b-4ba3-b4f1-61bf5bd2c67e&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-copying-segments-to-remote-storage&#34;&gt;Copying Segments to Remote Storage&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6501289f-c0a1-44f9-8bd8-c47cc0d57d36&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Each topic partition stores data in a logical log, which contains a sequence of physical log segments with the respective auxiliary files like segment indexes, producer state snapshots, and leader epoch checkpoints. Each partition replica creates these log segments, flushes them to disk and rolls over the segment based on segment roll configurations based on size or time. A log segment is eligible if its end offset is less than the &lt;em&gt;last-stable-offset&lt;/em&gt; of the partition. The broker acting as a leader for a topic partition is responsible for copying the eligible log segments to the remote storage. It copies the log segments from the earliest segment to the latest segment in a sequence. It uses &lt;em&gt;RemoteStorageManager&lt;/em&gt; for copying the segment with its indexes like offset, timestamp, producer snapshot, and its respective leader epoch cache. It also adds and updates entries in &lt;em&gt;RemoteLogMetadataManager&lt;/em&gt; with respective states for each copied segment.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;595ecbe5-36d6-43dc-9fe1-0c740e87c7e5&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The below diagram shows the sequence of copying the segments by maintaining local and remote log segments:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;db6e0950-4607-4d3f-9176-15c6f1f3552e&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;9e0b7194-32dc-4f35-96f9-3c9aea1767ac&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXcf2ufqsgcmWb4xf9M4813H55wCn9NC_n8HxCRK5nOT12LvqY5GNmRP_Rh4fqfiDk0SYdJ-63XaxZU5bTrleU-Ap77XBl0eyvjYc1_RIME_6AxlIGXWu9oLOoa3j9PQWyICHXjeOqISivV5Rcx2AhuAHGaU?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 5: The above diagram depicts a topic partition’s log segments with their respective start offsets. Before tiered storage is enabled, there will not be any segments in the remote storage.&amp;nbsp;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8578077d-7ecc-44cf-b2f0-ee21c603f836&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;c14dd36f-9fea-4da5-902f-1e4de0392748&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXc26wPlPeq7XR91GrM_6-QfWh0y6rKGCpGvA1islRticBFGAx33pR0Wm5cMl8OZSoDFm1RNKtpNcRKlj6Bcvuke-cdXBhNEGImxFphNDUBYoI3zb0XTYUek87oPOzV7OfcLoO86FkTeqyFrgFZpfzmAKT0?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 6: The above diagram depicts the eligible segments started copying to remote storage after tiered storage is enabled for that topic.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a33e00c6-209c-44cb-91ac-5222d96c8ab9&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1091633,&amp;quot;sizeSlug&amp;quot;:&amp;quot;full&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;055f601e-69cd-4a34-b281-14623b69c018&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;899&#34; height=&#34;333&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/07/Figure7.png&#34; alt=&#34;&#34; class=&#34;wp-image-1091633&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=899,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/07/Figure7.png 899w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/07/Figure7.png 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/07/Figure7.png 768w&#34; sizes=&#34;(max-width: 899px) 100vw, 899px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 7: The above diagram depicts some of the segments in the local storage were deleted based on the local retention configuration. We can see that segments earlier to offset 300 were deleted, but those segments are available in remote storage.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;47e9b3a2-d752-4c0a-b5b3-c66e7a0fcbf4&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;1058e67b-5adb-4dac-9629-89c807ae2bc7&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-cleaning-up-of-remote-segments&#34;&gt;Cleaning up of Remote Segments&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;035f67ed-dda2-4d78-bbf0-cbf76a605f64&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;As mentioned earlier, each topic will have a retention configuration based on size and time for both local data and remote data. Remote data is cleaned up at regular intervals by computing the eligible segments by a dedicated thread pool. This is different from the asynchronous cleaning up of the local log segments. When a topic is deleted, cleaning up of remote log segments is done asynchronously and it will not block the existing delete operation or recreate a new topic.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9d0dbe68-efc5-4c44-93c5-b07b115f3954&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;990b7b23-7491-49d7-a00a-1d9f3469b53b&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXczW4_RY_MyEEv6A1X0Rw2k7Yr-bPzt139veWuSaeGKqD_27xKyhqivZW609v4GUADtafNrZBmdzC9S9xj72tOTtqbKl9n_ivg9vkIdTJb4Lt7sK7I6UNt20kjrDUP2dwODaVr7rERXZgMfeazr9nxKJhe8?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 8: The above diagram depicts the cleaning up of remote log segments based on the complete log retention configuration. Here, segments earlier to offset 200 were deleted.&amp;nbsp;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c74af8b0-ee98-426a-893e-788c5b3562cc&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;9df2b72c-e610-471d-a7bb-752f19e9e225&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-fetching-segments-from-remote-storage&#34;&gt;Fetching Segments from Remote Storage&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1139aefd-e5bd-423e-9902-ebc767f49ba0&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;When a consumer fetch request is received and it is only available only in remote storage, then it is served using a dedicated thread pool. If the targeted offset is available in the broker’s local storage, then it is served using the existing local fetch mechanism. So, a broker separates the local reads from remote reads and they will not block each other.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4d905c15-c255-49f9-b98c-2fd8fb2e2d4a&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;em&gt;RemoteLogManager&lt;/em&gt; determines the targeted remote segment based on the desired offset and leader epoch by looking into the metadata store using &lt;em&gt;RemoteLogMetadataManager&lt;/em&gt;. It uses &lt;em&gt;RemoteStorageManager&lt;/em&gt; to find the position within the segment and start fetching the desired data.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0af941c5-ea10-4ee5-9180-0fa2f7d5be33&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;width&amp;quot;:&amp;quot;700px&amp;quot;,&amp;quot;height&amp;quot;:&amp;quot;auto&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;9289e088-db11-4e29-86df-02a1996c879d&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXfCCN3aludPERABf77NGITGxCPFcslvI11RammENhBCFoxUSl4XtWKzILkalB2GRWE4MO6WxBxw0QWLV8shK8Y1IVbUKUAQueS3mnZLbVx1E-T_rq_udar088WHjkWVIEt7xhf2xq5tCNBwZrsk4PuzIli8?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 9: Remote fetch path.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e8bfa664-6413-43d2-ac3c-06d4c632a8d8&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;02f4064f-5abd-43a4-a24e-9ac92c32faa2&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-follower-replication&#34;&gt;Follower Replication&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8a9f7dc7-6191-48fc-8184-b987a9abfde7&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Followers replicate the data from a leader to become an in-sync replica. They need to maintain the message lineage across a sequence of log segments as the leader. They may also do truncation of the segments if needed to maintain the message ordering.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;26775e4f-0ecd-4026-b6bb-79139de3d112&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;With tiered storage, follower replicas need to replicate the segments that are available on the leader’s local storage. Each log also needs auxiliary data like leader epoch state and producer-ID snapshots. So, a follower needs to build this auxiliary data before it starts fetching any messages from the leader. The follower fetch protocol makes sure to maintain the consistency and ordering of messages across all the replicas irrespective of changes in the cluster like broker replacements, failures, etc. If you are interested in understanding the inner workings of the enhanced follower fetch protocol, you can read it in the &lt;a href=&#34;https://cwiki.apache.org/confluence/display/KAFKA/KIP-405%3A+Kafka+Tiered+Storage#KIP405:KafkaTieredStorage-FollowerReplication&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;original document&lt;/a&gt; to understand the detailed design and how it handles several scenarios.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;5cf5ae52-b9e7-4d38-b2a6-d2346e2d9e75&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-conclusion&#34;&gt;Conclusion&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ed0dbc6e-6b12-4836-b874-e1a7425c4815&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In this blog, we covered an introduction and high-level architecture of tiered storage at Uber. If you are interested in more details, you can read the detailed design in &lt;a href=&#34;https://cwiki.apache.org/confluence/display/KAFKA/KIP-405%3A+Kafka+Tiered+Storage&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;KIP-405&lt;/a&gt;. Most of this work was done collaborating with the Apache Kafka community. The major part of this feature is available as early access in Apache Kafka 3.6.0.&amp;nbsp; This feature has been running in production for ~1-2 years in different workloads respectively. In the next part of this blog series we will cover our production experience and how it helped with better reliability, scalability, and efficiency of our clusters.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;fontSize&amp;quot;:&amp;quot;small&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;3b7d71e6-2de6-46a6-8a92-a754b708a278&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34; class=&#34;has-small-font-size&#34;&gt;Apache®, Apache Kafka™, and Kafka™ are either registered trademarks or trademarks of the Apache Software Foundation in the United States and/or other countries. No endorsement by The Apache Software Foundation is implied by the use of these marks.&lt;/p&gt;</description>
      <pubDate>Mon, 01 Jul 2024 10:58:33 +0000</pubDate>
    </item>
  </channel>
</rss>