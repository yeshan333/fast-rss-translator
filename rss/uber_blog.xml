<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Uber Engineering Blog</title>
    <link>http://rsshub.rssforever.com/uber/blog</link>
    <description>The technology behind Uber Engineering - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)</description>
    <managingEditor>i@diygod.me (DIYgod)</managingEditor>
    <item>
      <title>【Modernizing Uber’s Batch Data Infrastructure with Google Cloud Platform】使用 Google Cloud Platform 实现 Uber 批量数据基础设施的现代化</title>
      <link>https://www.uber.com/blog/modernizing-ubers-data-infrastructure-with-gcp/</link>
      <description>【&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;3b346459-b64f-4a7c-a4fd-74c5e5ccd06a&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-introduction&#34;&gt;Introduction&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;21359d5b-ec8c-44c1-b5c0-2f24d053f635&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Uber runs one of the largest Hadoop installations in the world. Our &lt;a href=&#34;https://www.uber.com/blog/uber-big-data-platform/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Hadoop ecosystem&lt;/a&gt; hosts more than 1 exabyte of data across tens of thousands of servers in each of our two regions. The open source data ecosystem, including the Hadoop ecosystem discussed in previous &lt;a href=&#34;https://www.uber.com/blog/engineering/data/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;engineering blogs&lt;/a&gt;, has been the core of our data platform. &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6b7695fe-0b3d-44f8-9c71-a4591d18a7bf&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Over the past few months, we have been assessing our platform and infrastructure needs to make sure we are well positioned to modernize our big data infrastructure to keep up with the growing needs of Uber.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;dc6a6591-ea0b-4c63-976b-6ae8b92810cf&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Today, we are excited to announce that we are working with Google Cloud Platform (GCP) to move our batch data analytics and ML training stack to GCP.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;16e72208-638d-4350-b32a-959e0b8b5b36&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Uber Data Platform’s mission is to democratize data-driven business decisions through intuitive, reliable, and efficient data products. Modernizing with GCP will enable big gains in user productivity, engineering velocity, improved cost efficiency, access to new innovation, and expanded data governance.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;84304abb-8844-4204-9732-ab2a99b269f2&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-strategy&#34;&gt;Strategy&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;36694de4-6854-49b0-8deb-0fb1916561eb&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Our strategy for the initial migration to GCP is to leverage cloud’s object store for the data lake storage while migrating the rest of the data stack to cloud IaaS (Infrastructure as a Service). This approach facilitates a fast migration path with minimum disruption to existing jobs and pipelines as we can replicate the exact versions of our on-prem software stack, engines, and security model on IaaS. We plan to adopt applicable PaaS (Platform as a Service) offerings, for example GCP Dataproc or BigQuery, after the initial migration to GCP to take full advantage of the elasticity and performance benefits cloud native services provide. Our plan is to execute on this strategy over the next several quarters, documenting our progress and sharing our learnings through a series of blog posts, of which this is the first. So bookmark this blog and stay tuned!&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;cddfe6e6-7861-40ea-8e12-fc924d6993da&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;709d0c51-5f63-4349-8d7f-2ff58cf91f10&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/Wx5iHeuUr_MaCochwvxq39y6wvy3aP3z8euxLBVPwOIujVTJ7GPvI8jyKFH4-JhfSps-0dQeWb9PJ7-fMn2Qgs1LXnmnOfxg8XeodrfTcnrrj8S8OZLEx_taJfS1JTrJ0c2_MZ27nPTq_6JfxFk6BWc&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;dd6b5e59-c9f1-4673-9cee-9bd91a4f8aa2&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;b2c01abd-5e77-4f02-b18d-070ee57e1cd9&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/vJcumVtF5yY4yqe5-7chOwkB6uyypCxfeuj9YVNhO3Xyi3YBjdig7sYRDC4RAU5IUh9XWbcWH-1D8KJs9ilaWkwsOAPKKmsbpV23AR5mxSGPRYXbSlREjembU5CMm4FLq_1RYHvloRng1Jz7xADjq6E&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;92883264-370f-48d3-80a1-e55e4346626d&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;bd32953e-1a1a-4194-868b-ac11b928d137&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-migration-principles&#34;&gt;Migration Principles&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;84911e7f-af9e-4cd7-a019-71245f11848f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Here are the core principles that we are keeping in mind for this daunting migration:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;c3c28e67-c28f-4fe3-947a-2da697212828&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-avoid-painful-migrations-for-data-users&#34;&gt;Avoid painful migrations for data users&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;08732ab0-c663-492a-b4a3-5cd31af4046e&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;By moving the majority of the batch data stack onto cloud IaaS as-is, we expect to shield our users such as dashboard owners, pipelines authors, ML practitioners, etc., from needing any changes to their artifacts or services. We’ll leverage well-known abstractions and open standards to make the migration as transparent as possible to data users.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2d7e5b84-0f3f-4401-89f2-a924cca00592&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We will be relying heavily on a cloud storage connector that implements the Hadoop FileSystem interface to Google Cloud Storage, providing HDFS compatibility. We will leverage open standards such as &lt;a href=&#34;https://parquet.apache.org/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Apache Parquet&lt;/a&gt;™ file format, &lt;a href=&#34;https://hudi.apache.org/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Apache Hudi&lt;/a&gt;™ table format, &lt;a href=&#34;https://spark.apache.org/&#34;&gt;Apache Spark&lt;/a&gt;™, &lt;a href=&#34;https://prestodb.io/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Presto’s&lt;/a&gt; SQL dialect, &lt;a href=&#34;https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/YARN.html&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Apache Hadoop YARN&lt;/a&gt;™, and &lt;a href=&#34;https://kubernetes.io/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;K8s&lt;/a&gt; to minimize the migration challenges even for the teams within the data platform organization. We will standardize our &lt;a href=&#34;https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Apache Hadoop HDFS&lt;/a&gt;™ clients to abstract the on-prem HDFS implementation specifics. Therefore, all the services that access HDFS on-prem today will seamlessly integrate with the GCP-hosted object store based storage layer without any changes. The standardized HDFS client will be modified to translate the HDFS paths to Object store based paths via a “Path Translation Service.” We will share more details on this in a future blog post.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;ec154e3d-fa37-4bdf-b3c1-b3cf99193a6c&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-enhance-data-access-proxies-to-federate-traffic-across-on-prem-or-cloud&#34;&gt;Enhance data access proxies to federate traffic across on-prem or cloud&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;fbee9041-cce0-42e4-8e2c-9d245810815a&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We have developed data access proxies (for &lt;a href=&#34;https://www.uber.com/blog/presto/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Presto&lt;/a&gt;, &lt;a href=&#34;https://www.uber.com/blog/uscs-apache-spark/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Spark&lt;/a&gt;, and Hive) that abstract out the details of the underlying physical compute clusters. During the testing phase, these proxies will support selectively routing test traffic toward the corresponding cloud-based Presto or YARN (for Spark and Hive) clusters. During full migration, all queries or jobs submitted to these proxies will be routed to the cloud-based stack.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;08214700-ac04-41bc-b154-05d11b0250ef&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-leverage-uber-s-existing-cloud-agnostic-container-and-deployment-infrastructure&#34;&gt;Leverage Uber’s existing cloud-agnostic container and deployment infrastructure&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;75d203f7-c3db-4d2e-905f-40e88fe01bb3&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The batch data stack sits on top of Uber’s infrastructure building blocks such as Uber’s &lt;a href=&#34;https://www.uber.com/blog/hadoop-container-blog/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;container environment&lt;/a&gt;, compute platform, and deployment tools which are built to be &lt;a href=&#34;https://www.uber.com/blog/crane-ubers-next-gen-infrastructure-stack/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;agnostic between cloud and on-prem&lt;/a&gt;. These platforms easily allow us to expand the batch data ecosystem microservices onto the cloud IaaS.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;af42a770-69b0-40af-817d-5362cdbebab4&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-forecast-potential-data-governance-issues-from-cloud-services&#34;&gt;Forecast potential data governance issues from cloud services&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;db3817d2-67a0-420e-a3c3-e3b4916c6eba&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;As a platform team we will build and enhance existing data management services to only support selected and approved data services from the cloud vendor’s portfolio to avoid data governance complexities moving forward.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3afca685-ea51-43d4-a886-aa783383b1b0&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;dac5769f-563e-416c-b583-35ed277e3ea6&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-major-workstreams&#34;&gt;Major Workstreams&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;9e276b5e-0bcb-42c1-8678-b168dbd7c5cc&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-bucket-mapping-and-cloud-resources-layout&#34;&gt;Bucket mapping and cloud resources layout&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;14080aa3-0e0b-4725-b862-6ed89dda2dd1&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;While migrating data, we need to map HDFS files and directories from the source cluster to cloud objects, which reside in one or more buckets. We also need to apply IAM policies at varying levels of granularity such as bucket, prefix or object level. Common constraints on buckets and objects include number of buckets per organization, read/write throughput from/to a bucket, IOPS throttling, and the number of ACLs, which can be applied via bucket policies.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3d023652-9af2-4b74-88b0-717034b0b63d&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The goal of this workstream is to formulate a mapping algorithm that satisfies these constraints and creates the corresponding cloud buckets. We also plan to incorporate &lt;a href=&#34;https://martinfowler.com/articles/data-mesh-principles.html&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;data mesh principles&lt;/a&gt; to organize these data resources in an organization-centric hierarchical manner, allowing for better data administration and management.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;0a5d9986-5494-4535-bf0f-03b29145c949&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-security-integration&#34;&gt;Security integration&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;aa77e826-c57c-424b-8959-9f427859b64d&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Our existing, Kerberos-based tokens and Hadoop Delegation tokens will not directly work with cloud PaaS, specifically GCS object storage. Cloud providers generally don’t have a ready-to-use PaaS solution for such interoperability.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e16b3e10-5ab3-45c8-90ba-8378443006e3&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The goal of this workstream is to enable a seamless support for all users, groups, and service accounts to continue to be &lt;a href=&#34;https://www.uber.com/blog/scaling-adoption-of-kerberos-at-uber/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;authenticated&lt;/a&gt; against the object store data lake and any other cloud PaaS. Also to maintain the same levels of authorized access as on-prem from there on.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;115cf99b-bca7-4a45-ba32-33df68a63d07&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-data-replication&#34;&gt;Data replication&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2a1f5933-a393-4d84-b5ac-a171a6c88279&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;HiveSync is a permissions-aware, bi-directional data replication service built at Uber (based on &lt;a href=&#34;https://github.com/airbnb/reair&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;ReAir&lt;/a&gt;/&lt;a href=&#34;https://hadoop.apache.org/docs/stable/hadoop-distcp/DistCp.html&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;distcp&lt;/a&gt;). HiveSync allows us to operate in an active-active mode with the batch and incremental replication features keeping our data lakes in the two regions in sync.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7c3b84fb-37c7-4908-af88-39606ae0e825&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The goal of this workstream is to extend HiveSync’s capabilities and Hudi library capabilities to replicate the on-prem data lake’s data into the cloud-based data lake and corresponding Hive Metastore. This includes the one time bootstrap (bulk migration)&amp;nbsp; and then ongoing incremental updates till the cloud-based stack is the primary.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;5790e635-cb93-4200-af60-bed2f3e4f68f&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-yarn-and-presto-clusters&#34;&gt;YARN and Presto clusters&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2e47faa7-17a5-45bd-a458-4f9650cf3636&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We would provision new YARN and Presto clusters on IaaS from the GCP. The existing data access proxies which federate query and job traffic to these clusters will then route traffic to the cloud-based stack through the migration.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;94d1060d-c08d-414f-b477-78ad7e615915&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;db8d825b-21f5-451a-a842-eb6506bdb03a&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-challenges-and-initiatives&#34;&gt;Challenges and Initiatives&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4fdf7398-74eb-4fab-966a-dde691f38eb9&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;This migration is a formidable undertaking and we are aware of the typical challenges that we&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;14970a1d-a79e-4991-99a8-742a44d28809&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;might face. Here are some of the large categories of challenges we are anticipating along with the mitigations and initiatives to handle them:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;23bed934-f004-4692-8bb0-71b400526ef5&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;Performance&lt;/strong&gt;: There are several well-known differences in features and performance characteristics between Object Store and HDFS. (e.g., atomic renames, file listing performance, etc.). We would leverage the Hadoop connectors from open source and help evolve them to maximize performance.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;Usage governance&lt;/strong&gt;: Cloud-related usage costs can balloon out of control if we don’t&amp;nbsp; &lt;a href=&#34;https://www.uber.com/blog/cost-efficient-big-data-platform/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;effectively&lt;/a&gt; and proactively manage them. We would leverage cloud’s elasticity to offset these costs. We will also partner with our internal capacity engineering team to build a finer attribution mechanism and tracking.&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;Non-analytics/ML specific usage of HDFS&lt;/strong&gt; &lt;strong&gt;by applications&lt;/strong&gt;: Over the years, teams have also started to use HDFS as a generic file store. We would be proactively migrating these use cases to other internal blob stores while also providing a transparent migration path to avoid disruptions.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;Unknown unknowns&lt;/strong&gt;: Finally, with a ~7 year old on-prem stack, we will definitely face unanticipated challenges. We hope to proactively uncover issues with early end-to-end integrations, refine proposed abstractions with customers, deprecate legacy use cases aggressively rather than carry them forward, etc., to stay ahead of these challenges.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3567e764-ec2c-490d-9270-12b5534db563&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Stay tuned on our journey as we will share our detailed designs, execution progress, and the lessons learned along the way!&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;fontSize&amp;quot;:&amp;quot;small&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;08f9da88-7d7c-4c43-9e5d-d526dbbab62f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34; class=&#34;has-small-font-size&#34;&gt;&lt;em&gt;Apache&lt;sup&gt;®&lt;/sup&gt;, Apache Parquet™, Apache Hudi™, Apache Spark™, &lt;em&gt;Apache Hadoop YARN™&lt;/em&gt; are registered trademarks or trademarks of the&amp;nbsp;&lt;/em&gt;&lt;a href=&#34;http://www.apache.org/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;&lt;em&gt;Apache Software Foundation&lt;/em&gt;&lt;/a&gt;&lt;em&gt;&amp;nbsp;in the United States and/or other countries. No endorsement by The Apache Software Foundation is implied by the use of these marks.&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;fontSize&amp;quot;:&amp;quot;small&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;9cd655f7-4966-44c6-aac8-82788b4fd2e9&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34; class=&#34;has-small-font-size&#34;&gt;Cover Photo Attribution: “&lt;a href=&#34;https://www.flickr.com/photos/55856449@N04/17510835551&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Country road and yellow field&lt;/a&gt;” by&amp;nbsp;&lt;a href=&#34;https://www.flickr.com/photos/55856449@N04&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Infomastern&lt;/a&gt;&amp;nbsp;is licensed under&amp;nbsp;&lt;a href=&#34;https://creativecommons.org/licenses/by-sa/2.0/?ref=openverse&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;CC BY-SA 2.0&lt;/a&gt;.&lt;/p&gt;】&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;3b346459-b64f-4a7c-a4fd-74c5e5ccd06a&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-introduction&#34;&gt;Introduction&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;21359d5b-ec8c-44c1-b5c0-2f24d053f635&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Uber runs one of the largest Hadoop installations in the world. Our &lt;a href=&#34;https://www.uber.com/blog/uber-big-data-platform/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Hadoop ecosystem&lt;/a&gt; hosts more than 1 exabyte of data across tens of thousands of servers in each of our two regions. The open source data ecosystem, including the Hadoop ecosystem discussed in previous &lt;a href=&#34;https://www.uber.com/blog/engineering/data/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;engineering blogs&lt;/a&gt;, has been the core of our data platform. &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6b7695fe-0b3d-44f8-9c71-a4591d18a7bf&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Over the past few months, we have been assessing our platform and infrastructure needs to make sure we are well positioned to modernize our big data infrastructure to keep up with the growing needs of Uber.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;dc6a6591-ea0b-4c63-976b-6ae8b92810cf&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Today, we are excited to announce that we are working with Google Cloud Platform (GCP) to move our batch data analytics and ML training stack to GCP.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;16e72208-638d-4350-b32a-959e0b8b5b36&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Uber Data Platform’s mission is to democratize data-driven business decisions through intuitive, reliable, and efficient data products. Modernizing with GCP will enable big gains in user productivity, engineering velocity, improved cost efficiency, access to new innovation, and expanded data governance.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;84304abb-8844-4204-9732-ab2a99b269f2&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-strategy&#34;&gt;Strategy&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;36694de4-6854-49b0-8deb-0fb1916561eb&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Our strategy for the initial migration to GCP is to leverage cloud’s object store for the data lake storage while migrating the rest of the data stack to cloud IaaS (Infrastructure as a Service). This approach facilitates a fast migration path with minimum disruption to existing jobs and pipelines as we can replicate the exact versions of our on-prem software stack, engines, and security model on IaaS. We plan to adopt applicable PaaS (Platform as a Service) offerings, for example GCP Dataproc or BigQuery, after the initial migration to GCP to take full advantage of the elasticity and performance benefits cloud native services provide. Our plan is to execute on this strategy over the next several quarters, documenting our progress and sharing our learnings through a series of blog posts, of which this is the first. So bookmark this blog and stay tuned!&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;cddfe6e6-7861-40ea-8e12-fc924d6993da&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;709d0c51-5f63-4349-8d7f-2ff58cf91f10&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/Wx5iHeuUr_MaCochwvxq39y6wvy3aP3z8euxLBVPwOIujVTJ7GPvI8jyKFH4-JhfSps-0dQeWb9PJ7-fMn2Qgs1LXnmnOfxg8XeodrfTcnrrj8S8OZLEx_taJfS1JTrJ0c2_MZ27nPTq_6JfxFk6BWc&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;dd6b5e59-c9f1-4673-9cee-9bd91a4f8aa2&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;b2c01abd-5e77-4f02-b18d-070ee57e1cd9&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/vJcumVtF5yY4yqe5-7chOwkB6uyypCxfeuj9YVNhO3Xyi3YBjdig7sYRDC4RAU5IUh9XWbcWH-1D8KJs9ilaWkwsOAPKKmsbpV23AR5mxSGPRYXbSlREjembU5CMm4FLq_1RYHvloRng1Jz7xADjq6E&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;92883264-370f-48d3-80a1-e55e4346626d&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;bd32953e-1a1a-4194-868b-ac11b928d137&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-migration-principles&#34;&gt;Migration Principles&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;84911e7f-af9e-4cd7-a019-71245f11848f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Here are the core principles that we are keeping in mind for this daunting migration:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;c3c28e67-c28f-4fe3-947a-2da697212828&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-avoid-painful-migrations-for-data-users&#34;&gt;Avoid painful migrations for data users&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;08732ab0-c663-492a-b4a3-5cd31af4046e&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;By moving the majority of the batch data stack onto cloud IaaS as-is, we expect to shield our users such as dashboard owners, pipelines authors, ML practitioners, etc., from needing any changes to their artifacts or services. We’ll leverage well-known abstractions and open standards to make the migration as transparent as possible to data users.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2d7e5b84-0f3f-4401-89f2-a924cca00592&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We will be relying heavily on a cloud storage connector that implements the Hadoop FileSystem interface to Google Cloud Storage, providing HDFS compatibility. We will leverage open standards such as &lt;a href=&#34;https://parquet.apache.org/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Apache Parquet&lt;/a&gt;™ file format, &lt;a href=&#34;https://hudi.apache.org/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Apache Hudi&lt;/a&gt;™ table format, &lt;a href=&#34;https://spark.apache.org/&#34;&gt;Apache Spark&lt;/a&gt;™, &lt;a href=&#34;https://prestodb.io/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Presto’s&lt;/a&gt; SQL dialect, &lt;a href=&#34;https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/YARN.html&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Apache Hadoop YARN&lt;/a&gt;™, and &lt;a href=&#34;https://kubernetes.io/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;K8s&lt;/a&gt; to minimize the migration challenges even for the teams within the data platform organization. We will standardize our &lt;a href=&#34;https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Apache Hadoop HDFS&lt;/a&gt;™ clients to abstract the on-prem HDFS implementation specifics. Therefore, all the services that access HDFS on-prem today will seamlessly integrate with the GCP-hosted object store based storage layer without any changes. The standardized HDFS client will be modified to translate the HDFS paths to Object store based paths via a “Path Translation Service.” We will share more details on this in a future blog post.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;ec154e3d-fa37-4bdf-b3c1-b3cf99193a6c&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-enhance-data-access-proxies-to-federate-traffic-across-on-prem-or-cloud&#34;&gt;Enhance data access proxies to federate traffic across on-prem or cloud&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;fbee9041-cce0-42e4-8e2c-9d245810815a&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We have developed data access proxies (for &lt;a href=&#34;https://www.uber.com/blog/presto/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Presto&lt;/a&gt;, &lt;a href=&#34;https://www.uber.com/blog/uscs-apache-spark/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Spark&lt;/a&gt;, and Hive) that abstract out the details of the underlying physical compute clusters. During the testing phase, these proxies will support selectively routing test traffic toward the corresponding cloud-based Presto or YARN (for Spark and Hive) clusters. During full migration, all queries or jobs submitted to these proxies will be routed to the cloud-based stack.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;08214700-ac04-41bc-b154-05d11b0250ef&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-leverage-uber-s-existing-cloud-agnostic-container-and-deployment-infrastructure&#34;&gt;Leverage Uber’s existing cloud-agnostic container and deployment infrastructure&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;75d203f7-c3db-4d2e-905f-40e88fe01bb3&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The batch data stack sits on top of Uber’s infrastructure building blocks such as Uber’s &lt;a href=&#34;https://www.uber.com/blog/hadoop-container-blog/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;container environment&lt;/a&gt;, compute platform, and deployment tools which are built to be &lt;a href=&#34;https://www.uber.com/blog/crane-ubers-next-gen-infrastructure-stack/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;agnostic between cloud and on-prem&lt;/a&gt;. These platforms easily allow us to expand the batch data ecosystem microservices onto the cloud IaaS.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;af42a770-69b0-40af-817d-5362cdbebab4&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-forecast-potential-data-governance-issues-from-cloud-services&#34;&gt;Forecast potential data governance issues from cloud services&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;db3817d2-67a0-420e-a3c3-e3b4916c6eba&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;As a platform team we will build and enhance existing data management services to only support selected and approved data services from the cloud vendor’s portfolio to avoid data governance complexities moving forward.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3afca685-ea51-43d4-a886-aa783383b1b0&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;dac5769f-563e-416c-b583-35ed277e3ea6&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-major-workstreams&#34;&gt;Major Workstreams&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;9e276b5e-0bcb-42c1-8678-b168dbd7c5cc&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-bucket-mapping-and-cloud-resources-layout&#34;&gt;Bucket mapping and cloud resources layout&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;14080aa3-0e0b-4725-b862-6ed89dda2dd1&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;While migrating data, we need to map HDFS files and directories from the source cluster to cloud objects, which reside in one or more buckets. We also need to apply IAM policies at varying levels of granularity such as bucket, prefix or object level. Common constraints on buckets and objects include number of buckets per organization, read/write throughput from/to a bucket, IOPS throttling, and the number of ACLs, which can be applied via bucket policies.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3d023652-9af2-4b74-88b0-717034b0b63d&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The goal of this workstream is to formulate a mapping algorithm that satisfies these constraints and creates the corresponding cloud buckets. We also plan to incorporate &lt;a href=&#34;https://martinfowler.com/articles/data-mesh-principles.html&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;data mesh principles&lt;/a&gt; to organize these data resources in an organization-centric hierarchical manner, allowing for better data administration and management.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;0a5d9986-5494-4535-bf0f-03b29145c949&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-security-integration&#34;&gt;Security integration&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;aa77e826-c57c-424b-8959-9f427859b64d&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Our existing, Kerberos-based tokens and Hadoop Delegation tokens will not directly work with cloud PaaS, specifically GCS object storage. Cloud providers generally don’t have a ready-to-use PaaS solution for such interoperability.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e16b3e10-5ab3-45c8-90ba-8378443006e3&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The goal of this workstream is to enable a seamless support for all users, groups, and service accounts to continue to be &lt;a href=&#34;https://www.uber.com/blog/scaling-adoption-of-kerberos-at-uber/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;authenticated&lt;/a&gt; against the object store data lake and any other cloud PaaS. Also to maintain the same levels of authorized access as on-prem from there on.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;115cf99b-bca7-4a45-ba32-33df68a63d07&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-data-replication&#34;&gt;Data replication&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2a1f5933-a393-4d84-b5ac-a171a6c88279&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;HiveSync is a permissions-aware, bi-directional data replication service built at Uber (based on &lt;a href=&#34;https://github.com/airbnb/reair&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;ReAir&lt;/a&gt;/&lt;a href=&#34;https://hadoop.apache.org/docs/stable/hadoop-distcp/DistCp.html&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;distcp&lt;/a&gt;). HiveSync allows us to operate in an active-active mode with the batch and incremental replication features keeping our data lakes in the two regions in sync.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7c3b84fb-37c7-4908-af88-39606ae0e825&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The goal of this workstream is to extend HiveSync’s capabilities and Hudi library capabilities to replicate the on-prem data lake’s data into the cloud-based data lake and corresponding Hive Metastore. This includes the one time bootstrap (bulk migration)&amp;nbsp; and then ongoing incremental updates till the cloud-based stack is the primary.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;5790e635-cb93-4200-af60-bed2f3e4f68f&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-yarn-and-presto-clusters&#34;&gt;YARN and Presto clusters&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2e47faa7-17a5-45bd-a458-4f9650cf3636&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We would provision new YARN and Presto clusters on IaaS from the GCP. The existing data access proxies which federate query and job traffic to these clusters will then route traffic to the cloud-based stack through the migration.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;94d1060d-c08d-414f-b477-78ad7e615915&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;db8d825b-21f5-451a-a842-eb6506bdb03a&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-challenges-and-initiatives&#34;&gt;Challenges and Initiatives&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4fdf7398-74eb-4fab-966a-dde691f38eb9&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;This migration is a formidable undertaking and we are aware of the typical challenges that we&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;14970a1d-a79e-4991-99a8-742a44d28809&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;might face. Here are some of the large categories of challenges we are anticipating along with the mitigations and initiatives to handle them:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;23bed934-f004-4692-8bb0-71b400526ef5&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;Performance&lt;/strong&gt;: There are several well-known differences in features and performance characteristics between Object Store and HDFS. (e.g., atomic renames, file listing performance, etc.). We would leverage the Hadoop connectors from open source and help evolve them to maximize performance.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;Usage governance&lt;/strong&gt;: Cloud-related usage costs can balloon out of control if we don’t&amp;nbsp; &lt;a href=&#34;https://www.uber.com/blog/cost-efficient-big-data-platform/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;effectively&lt;/a&gt; and proactively manage them. We would leverage cloud’s elasticity to offset these costs. We will also partner with our internal capacity engineering team to build a finer attribution mechanism and tracking.&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;Non-analytics/ML specific usage of HDFS&lt;/strong&gt; &lt;strong&gt;by applications&lt;/strong&gt;: Over the years, teams have also started to use HDFS as a generic file store. We would be proactively migrating these use cases to other internal blob stores while also providing a transparent migration path to avoid disruptions.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;Unknown unknowns&lt;/strong&gt;: Finally, with a ~7 year old on-prem stack, we will definitely face unanticipated challenges. We hope to proactively uncover issues with early end-to-end integrations, refine proposed abstractions with customers, deprecate legacy use cases aggressively rather than carry them forward, etc., to stay ahead of these challenges.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3567e764-ec2c-490d-9270-12b5534db563&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Stay tuned on our journey as we will share our detailed designs, execution progress, and the lessons learned along the way!&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;fontSize&amp;quot;:&amp;quot;small&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;08f9da88-7d7c-4c43-9e5d-d526dbbab62f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34; class=&#34;has-small-font-size&#34;&gt;&lt;em&gt;Apache&lt;sup&gt;®&lt;/sup&gt;, Apache Parquet™, Apache Hudi™, Apache Spark™, &lt;em&gt;Apache Hadoop YARN™&lt;/em&gt; are registered trademarks or trademarks of the&amp;nbsp;&lt;/em&gt;&lt;a href=&#34;http://www.apache.org/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;&lt;em&gt;Apache Software Foundation&lt;/em&gt;&lt;/a&gt;&lt;em&gt;&amp;nbsp;in the United States and/or other countries. No endorsement by The Apache Software Foundation is implied by the use of these marks.&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;fontSize&amp;quot;:&amp;quot;small&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;9cd655f7-4966-44c6-aac8-82788b4fd2e9&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34; class=&#34;has-small-font-size&#34;&gt;Cover Photo Attribution: “&lt;a href=&#34;https://www.flickr.com/photos/55856449@N04/17510835551&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Country road and yellow field&lt;/a&gt;” by&amp;nbsp;&lt;a href=&#34;https://www.flickr.com/photos/55856449@N04&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Infomastern&lt;/a&gt;&amp;nbsp;is licensed under&amp;nbsp;&lt;a href=&#34;https://creativecommons.org/licenses/by-sa/2.0/?ref=openverse&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;CC BY-SA 2.0&lt;/a&gt;.&lt;/p&gt;</description>
      <pubDate>Thu, 30 May 2024 07:21:12 +0000</pubDate>
    </item>
    <item>
      <title>【Introduction to Kafka Tiered Storage at Uber】Uber 的 Kafka 分层存储简介</title>
      <link>https://www.uber.com/blog/kafka-tiered-storage/</link>
      <description>【&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;433c69f8-24e4-4e25-8a58-c3011be3d1bb&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-introduction&#34;&gt;Introduction&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b3315f9e-7720-4fae-a737-4602be48fcf0&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Apache Kafka® is the cornerstone of Uber’s tech stack. It plays an important role in powering several critical use cases and is the foundation for batch and real-time systems at Uber.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;bae21b7b-4f98-483f-92f9-60ab827ef689&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;5fd7c743-bdd7-40d7-9e81-86f4e342f1a4&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXePSpSp72unfaVqK7tofbbbOpMaZLJ7qYJ2Es-Chg3CHBeZ9kcJDZ9ouvPRYs-CarI8bAqXs2459rJ0_QrsgBaUwqikE5fwYSianNkl1u6Ehbjz_yH6XuWJGn54P5kCaRSaBrCgeVPN4q2QC_RDu9ag1YgU?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 1: Uber’s Data Pipeline.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;bba04fc7-d627-4e13-97a1-c1511775c833&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;213c11a1-ab13-4d60-a5f8-2bf22f25ae86&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Kafka stores the messages in append-only log segments on the broker’s local storage. Each topic can be configured with the targeted retention based on size or time. It gives guarantees for users to consume the data within the retention period or size even when the respective consuming applications fail or become slow for several reasons. Total storage on a cluster depends upon factors like the total number of topic partitions, produce throughput, and retention configuration. A Kafka broker typically needs to have larger storage to support the required topic partitions hosted on a broker.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;f27d9aad-98e4-44d8-8c39-d27574431a59&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-motivation-background-behind-project&#34;&gt;Motivation/Background Behind Project&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2acf6879-58ec-4dc2-9411-023216a9e7e4&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Kafka cluster storage is typically scaled by adding more broker nodes to the cluster. But this also adds needless memory and CPUs to the cluster, making overall storage cost less efficient compared to storing the older data in external storage. A larger cluster with more nodes also adds to the deployment complexity and increases operational costs because of the tight coupling of storage and processing. So, it brings several issues related to scalability, efficiency, and operations.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0657efab-21dc-423f-b42f-c4dc1ed5da8d&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We proposed Kafka Tiered Storage (&lt;a href=&#34;https://cwiki.apache.org/confluence/display/KAFKA/KIP-405%3A+Kafka+Tiered+Storage&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;KIP-405&lt;/a&gt;) to avoid tight coupling of storage and processing in a broker. It provides two tiers of storage, called local and remote. These two tiers can have respective retention policies based on the respective use cases.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7bb99c16-9f01-4606-9393-18634deb8b8c&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;width&amp;quot;:&amp;quot;700px&amp;quot;,&amp;quot;height&amp;quot;:&amp;quot;auto&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;e25cccec-32e4-4c15-976a-4a4725861800&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXdrkDm5z8lSbIzR0Xure8R4qrXa8JqczXMcNyQs17yede4tKZScrbVWTc4PjScxs-k_qrcks2cLmf2nOJi9x4tf2Zyzyql2Ql7jA3Ty4qNQoth7NeTL9itjkQnaJKIwm3zZVYUgYXx_2yr4lgyAF-9eLr-i?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 2: End to end interaction of Kafka broker with tiered storage.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d3f58e6f-e3fc-4df8-84f2-247071e699aa&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;00272d69-19b6-4d44-b7f1-ab451bbd36af&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-goals&#34;&gt;Goals&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f8ada8a4-3425-4352-bd37-c99f0a8e6291&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Below are the main goals that we set for tiered storage:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3cd3f2c9-a5d0-44a3-8335-ca7b05d03d38&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Extend the storage beyond the broker&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Memory/PageCache&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Local storage&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Remote storage support (including cloud/object stores like S3/GCS/Azure)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Durability and Consistency semantics similar to local storage&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Isolation of reading latest and historical data&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;No changes are required from clients&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Easy tuning and provisioning of clusters&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Improve operational and cost efficiency&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f96a808a-53f5-4733-a618-0ed612929034&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;87df347d-17d7-42dc-b9b6-856160fbd93e&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-architecture&#34;&gt;Architecture&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f6ceb13c-20bc-44d2-be91-a3cc6b3523ae&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Kafka cluster enabled with tiered storage is configured with two tiers of storage called local and remote. The local tier is the broker’s local storage where the segments are stored currently. The new remote tier is the extended storage, such as HDFS/S3/GCS/Azure. Both these tiers will have respective retention configurations based on size and time. The retention period for the local tier can be significantly reduced from days to a few hours. The retention period for the remote tier can be much longer–days, or even months. Applications sensitive to latency conduct tail reads and are catered to from the local tier, utilizing Kafka’s efficient page cache utilization for data retrieval. On the other hand, applications such as backfill or those recovering from failures requiring older data than what’s locally available, are served from the remote tier.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;99e485ed-bfbb-4a06-83f3-7781b0ccb009&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;This approach enables the scalability of storage in a Kafka cluster without being tied to memory and CPU resources, thus transforming Kafka into a viable long-term storage option. Moreover, it decreases the local storage burden on Kafka brokers, consequently reducing the data to be transferred during recovery and rebalancing. Log segments accessible in the remote tier don’t require restoration on the broker and can be accessed directly from the remote tier. It eliminates the necessity to expand the Kafka cluster storage and add new nodes when extending the retention period. Additionally, it allows for significantly longer data retention without the requirement for separate data pipelines to transfer data from Kafka to external storage (a common practice in many current setups).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;285c094f-9538-44de-9270-4721f1bf1133&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Tiered storage divides a topic partition’s log into two different logical components called local log and remote log. Local log contains a list of local log segments and remote log contains a list of remote log segments. The remote log subsystem copies each topic partition’s eligible segments from local storage to the remote storage. A segment is eligible to be copied when its end offset is less than &lt;em&gt;LastStableOffset&lt;/em&gt; of a partition.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2d6d304d-aba7-46d5-aa43-bad98a0e13d3&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;bf09d07e-1d0f-4647-8465-310196ef72ff&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXdDJEudzpCrGDSR9yN0sNZ5YU_AM1ExXihNssXH0d5SGi01nOJ4R6xY0yY7frm6ESriC5o6XFiqQMVSCVDWpRK0l6nFxaF8CBCdY0ZpN1beZUsmqpSe4VragjX8kjUjh5VXGKMD-g2i9GMOaIJ99if2dJkj?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 3: Local log offsets and remote log offsets.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;656259a5-41ec-4162-a1a8-fa9680404f3d&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure data-wp-block-name=&#34;core/table&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;970a47e8-729d-4286-a17f-307c713c9f18&amp;quot;,&amp;quot;hasFixedLayout&amp;quot;:false,&amp;quot;head&amp;quot;:[],&amp;quot;body&amp;quot;:[],&amp;quot;foot&amp;quot;:[]}&#34; class=&#34;wp-block-table&#34;&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt; Lz&amp;nbsp; = Local log end offset&amp;nbsp;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;Lx&amp;nbsp; = Local log start offset &amp;nbsp;&lt;/td&gt;&lt;td&gt;Ly&amp;nbsp; = Last stable offset(LSO)&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure data-wp-block-name=&#34;core/table&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c7fa71b6-1b3f-414b-9d7d-8967a9a41e7a&amp;quot;,&amp;quot;hasFixedLayout&amp;quot;:false,&amp;quot;head&amp;quot;:[],&amp;quot;body&amp;quot;:[],&amp;quot;foot&amp;quot;:[]}&#34; class=&#34;wp-block-table&#34;&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;Ry&amp;nbsp; = Remote log end offset &lt;/td&gt;&lt;td&gt;Rx&amp;nbsp; = Remote log start offset&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;em&gt;Lz &amp;gt;= Ly &amp;gt;= Lx and Ly &amp;gt;= Ry &amp;gt;= Rx&lt;/em&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;cdfcf4f5-b74b-4219-ab12-4bb78c78a00a&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a1242f90-4a1d-4f87-9dc7-e49627a2062a&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Apache Kafka storage subsystem maintains the above offset constraints for local and remote log segments of a topic partition.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b4c968f9-e76a-4c83-a966-e0dae7131168&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;width&amp;quot;:&amp;quot;700px&amp;quot;,&amp;quot;height&amp;quot;:&amp;quot;auto&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;f687a646-355f-4412-9ad8-f793d9942d75&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXcnNa5SMjEkpYEOgrEV8WQaKzXNhUFy5I1iuFKcHifODuPUg26arhCP8wvWpPsm7onOA8jTn2IS7_tTF9VXmg2NHC2p5IPSFLXw39fP8b4c47ksowG9dYI-iyFHE2szvRfNMn-QBQc4s_lgOg0tMYH3sKw?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 4: High level architecture of Kafka tiered storage components.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a7ef1ee3-e8df-4942-b3ac-a88b2ec5feca&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d568d925-c3a2-4eed-ab17-976503458642&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The above diagram gives a high-level overview of the new architecture with newly introduced components:&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9c25ec3d-7751-4e49-9a9d-183df57a2782&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;RemoteStorageManager&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;RemoteLogMetadataManager&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;RemoteLogManager&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6ffe5286-c491-4dd9-9573-0439c7790602&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We introduced two pluggable components within the storage layer called &lt;em&gt;RemoteStorageManager&lt;/em&gt; and &lt;em&gt;RemoteLogMetadataManager&lt;/em&gt;. These can be implemented by developers based on their targeted storage systems and plugged into their Kafka environments.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c3bb416c-1811-4b68-bd52-f28cc63a8d4f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;em&gt;RemoteStorageManager&lt;/em&gt; interface provides the actions for remote log segments that include copy, fetch, and delete from remote storage.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7c9686e1-1c96-4cd4-81fc-4e4651a9ca6e&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;em&gt;RemoteLogMetadataManager&lt;/em&gt; interface provides the lifecycle operations of metadata about remote log segments with strongly consistent semantics. There is a default implementation that uses an internal topic. Users can plugin their implementation if they intend to use another system to store remote log segment metadata.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;10f1a733-e2e1-4da9-9e2b-f0575b8179ce&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;em&gt;RemoteLogManager&lt;/em&gt; is a logical layer responsible for managing the life cycle of remote log segments. That includes:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;cfbe1efc-e968-4d3c-a129-657cab42d2c5&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Copying segments to the remote storage&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Cleaning up of expired segments in the remote storage&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Fetching the data from remote storage&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6085e748-3614-425e-a85e-1814e32e68d3&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;It also uses the pluggable remote storage components as and when needed. Each remote log segment is identified with a unique identifier called &lt;em&gt;RemoteLogSegmentId&lt;/em&gt;, even for the same topic partition and offsets.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1b79721a-afd5-45be-aa53-a361a4db4016&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;f9f19038-588b-4ba3-b4f1-61bf5bd2c67e&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-copying-segments-to-remote-storage&#34;&gt;Copying Segments to Remote Storage&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6501289f-c0a1-44f9-8bd8-c47cc0d57d36&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Each topic partition stores data in a logical log, which contains a sequence of physical log segments with the respective auxiliary files like segment indexes, producer state snapshots, and leader epoch checkpoints. Each partition replica creates these log segments, flushes them to disk and rolls over the segment based on segment roll configurations based on size or time. A log segment is eligible if its end offset is less than the &lt;em&gt;last-stable-offset&lt;/em&gt; of the partition. The broker acting as a leader for a topic partition is responsible for copying the eligible log segments to the remote storage. It copies the log segments from the earliest segment to the latest segment in a sequence. It uses &lt;em&gt;RemoteStorageManager&lt;/em&gt; for copying the segment with its indexes like offset, timestamp, producer snapshot, and its respective leader epoch cache. It also adds and updates entries in &lt;em&gt;RemoteLogMetadataManager&lt;/em&gt; with respective states for each copied segment.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;595ecbe5-36d6-43dc-9fe1-0c740e87c7e5&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The below diagram shows the sequence of copying the segments by maintaining local and remote log segments:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;db6e0950-4607-4d3f-9176-15c6f1f3552e&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;9e0b7194-32dc-4f35-96f9-3c9aea1767ac&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXcf2ufqsgcmWb4xf9M4813H55wCn9NC_n8HxCRK5nOT12LvqY5GNmRP_Rh4fqfiDk0SYdJ-63XaxZU5bTrleU-Ap77XBl0eyvjYc1_RIME_6AxlIGXWu9oLOoa3j9PQWyICHXjeOqISivV5Rcx2AhuAHGaU?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 5: The above diagram depicts a topic partition’s log segments with their respective start offsets. Before tiered storage is enabled, there will not be any segments in the remote storage.&amp;nbsp;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8578077d-7ecc-44cf-b2f0-ee21c603f836&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;c14dd36f-9fea-4da5-902f-1e4de0392748&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXc26wPlPeq7XR91GrM_6-QfWh0y6rKGCpGvA1islRticBFGAx33pR0Wm5cMl8OZSoDFm1RNKtpNcRKlj6Bcvuke-cdXBhNEGImxFphNDUBYoI3zb0XTYUek87oPOzV7OfcLoO86FkTeqyFrgFZpfzmAKT0?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 6: The above diagram depicts the eligible segments started copying to remote storage after tiered storage is enabled for that topic.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a33e00c6-209c-44cb-91ac-5222d96c8ab9&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1091633,&amp;quot;sizeSlug&amp;quot;:&amp;quot;full&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;055f601e-69cd-4a34-b281-14623b69c018&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;899&#34; height=&#34;333&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/07/Figure7.png&#34; alt=&#34;&#34; class=&#34;wp-image-1091633&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=899,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/07/Figure7.png 899w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/07/Figure7.png 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/07/Figure7.png 768w&#34; sizes=&#34;(max-width: 899px) 100vw, 899px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 7: The above diagram depicts some of the segments in the local storage were deleted based on the local retention configuration. We can see that segments earlier to offset 300 were deleted, but those segments are available in remote storage.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;47e9b3a2-d752-4c0a-b5b3-c66e7a0fcbf4&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;1058e67b-5adb-4dac-9629-89c807ae2bc7&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-cleaning-up-of-remote-segments&#34;&gt;Cleaning up of Remote Segments&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;035f67ed-dda2-4d78-bbf0-cbf76a605f64&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;As mentioned earlier, each topic will have a retention configuration based on size and time for both local data and remote data. Remote data is cleaned up at regular intervals by computing the eligible segments by a dedicated thread pool. This is different from the asynchronous cleaning up of the local log segments. When a topic is deleted, cleaning up of remote log segments is done asynchronously and it will not block the existing delete operation or recreate a new topic.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9d0dbe68-efc5-4c44-93c5-b07b115f3954&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;990b7b23-7491-49d7-a00a-1d9f3469b53b&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXczW4_RY_MyEEv6A1X0Rw2k7Yr-bPzt139veWuSaeGKqD_27xKyhqivZW609v4GUADtafNrZBmdzC9S9xj72tOTtqbKl9n_ivg9vkIdTJb4Lt7sK7I6UNt20kjrDUP2dwODaVr7rERXZgMfeazr9nxKJhe8?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 8: The above diagram depicts the cleaning up of remote log segments based on the complete log retention configuration. Here, segments earlier to offset 200 were deleted.&amp;nbsp;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c74af8b0-ee98-426a-893e-788c5b3562cc&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;9df2b72c-e610-471d-a7bb-752f19e9e225&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-fetching-segments-from-remote-storage&#34;&gt;Fetching Segments from Remote Storage&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1139aefd-e5bd-423e-9902-ebc767f49ba0&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;When a consumer fetch request is received and it is only available only in remote storage, then it is served using a dedicated thread pool. If the targeted offset is available in the broker’s local storage, then it is served using the existing local fetch mechanism. So, a broker separates the local reads from remote reads and they will not block each other.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4d905c15-c255-49f9-b98c-2fd8fb2e2d4a&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;em&gt;RemoteLogManager&lt;/em&gt; determines the targeted remote segment based on the desired offset and leader epoch by looking into the metadata store using &lt;em&gt;RemoteLogMetadataManager&lt;/em&gt;. It uses &lt;em&gt;RemoteStorageManager&lt;/em&gt; to find the position within the segment and start fetching the desired data.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0af941c5-ea10-4ee5-9180-0fa2f7d5be33&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;width&amp;quot;:&amp;quot;700px&amp;quot;,&amp;quot;height&amp;quot;:&amp;quot;auto&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;9289e088-db11-4e29-86df-02a1996c879d&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXfCCN3aludPERABf77NGITGxCPFcslvI11RammENhBCFoxUSl4XtWKzILkalB2GRWE4MO6WxBxw0QWLV8shK8Y1IVbUKUAQueS3mnZLbVx1E-T_rq_udar088WHjkWVIEt7xhf2xq5tCNBwZrsk4PuzIli8?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 9: Remote fetch path.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e8bfa664-6413-43d2-ac3c-06d4c632a8d8&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;02f4064f-5abd-43a4-a24e-9ac92c32faa2&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-follower-replication&#34;&gt;Follower Replication&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8a9f7dc7-6191-48fc-8184-b987a9abfde7&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Followers replicate the data from a leader to become an in-sync replica. They need to maintain the message lineage across a sequence of log segments as the leader. They may also do truncation of the segments if needed to maintain the message ordering.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;26775e4f-0ecd-4026-b6bb-79139de3d112&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;With tiered storage, follower replicas need to replicate the segments that are available on the leader’s local storage. Each log also needs auxiliary data like leader epoch state and producer-ID snapshots. So, a follower needs to build this auxiliary data before it starts fetching any messages from the leader. The follower fetch protocol makes sure to maintain the consistency and ordering of messages across all the replicas irrespective of changes in the cluster like broker replacements, failures, etc. If you are interested in understanding the inner workings of the enhanced follower fetch protocol, you can read it in the &lt;a href=&#34;https://cwiki.apache.org/confluence/display/KAFKA/KIP-405%3A+Kafka+Tiered+Storage#KIP405:KafkaTieredStorage-FollowerReplication&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;original document&lt;/a&gt; to understand the detailed design and how it handles several scenarios.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;5cf5ae52-b9e7-4d38-b2a6-d2346e2d9e75&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-conclusion&#34;&gt;Conclusion&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ed0dbc6e-6b12-4836-b874-e1a7425c4815&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In this blog, we covered an introduction and high-level architecture of tiered storage at Uber. If you are interested in more details, you can read the detailed design in &lt;a href=&#34;https://cwiki.apache.org/confluence/display/KAFKA/KIP-405%3A+Kafka+Tiered+Storage&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;KIP-405&lt;/a&gt;. Most of this work was done collaborating with the Apache Kafka community. The major part of this feature is available as early access in Apache Kafka 3.6.0.&amp;nbsp; This feature has been running in production for ~1-2 years in different workloads respectively. In the next part of this blog series we will cover our production experience and how it helped with better reliability, scalability, and efficiency of our clusters.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;fontSize&amp;quot;:&amp;quot;small&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;3b7d71e6-2de6-46a6-8a92-a754b708a278&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34; class=&#34;has-small-font-size&#34;&gt;Apache®, Apache Kafka™, and Kafka™ are either registered trademarks or trademarks of the Apache Software Foundation in the United States and/or other countries. No endorsement by The Apache Software Foundation is implied by the use of these marks.&lt;/p&gt;】&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;433c69f8-24e4-4e25-8a58-c3011be3d1bb&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-introduction&#34;&gt;Introduction&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b3315f9e-7720-4fae-a737-4602be48fcf0&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Apache Kafka® is the cornerstone of Uber’s tech stack. It plays an important role in powering several critical use cases and is the foundation for batch and real-time systems at Uber.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;bae21b7b-4f98-483f-92f9-60ab827ef689&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;5fd7c743-bdd7-40d7-9e81-86f4e342f1a4&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXePSpSp72unfaVqK7tofbbbOpMaZLJ7qYJ2Es-Chg3CHBeZ9kcJDZ9ouvPRYs-CarI8bAqXs2459rJ0_QrsgBaUwqikE5fwYSianNkl1u6Ehbjz_yH6XuWJGn54P5kCaRSaBrCgeVPN4q2QC_RDu9ag1YgU?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 1: Uber’s Data Pipeline.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;bba04fc7-d627-4e13-97a1-c1511775c833&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;213c11a1-ab13-4d60-a5f8-2bf22f25ae86&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Kafka stores the messages in append-only log segments on the broker’s local storage. Each topic can be configured with the targeted retention based on size or time. It gives guarantees for users to consume the data within the retention period or size even when the respective consuming applications fail or become slow for several reasons. Total storage on a cluster depends upon factors like the total number of topic partitions, produce throughput, and retention configuration. A Kafka broker typically needs to have larger storage to support the required topic partitions hosted on a broker.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;f27d9aad-98e4-44d8-8c39-d27574431a59&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-motivation-background-behind-project&#34;&gt;Motivation/Background Behind Project&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2acf6879-58ec-4dc2-9411-023216a9e7e4&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Kafka cluster storage is typically scaled by adding more broker nodes to the cluster. But this also adds needless memory and CPUs to the cluster, making overall storage cost less efficient compared to storing the older data in external storage. A larger cluster with more nodes also adds to the deployment complexity and increases operational costs because of the tight coupling of storage and processing. So, it brings several issues related to scalability, efficiency, and operations.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0657efab-21dc-423f-b42f-c4dc1ed5da8d&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We proposed Kafka Tiered Storage (&lt;a href=&#34;https://cwiki.apache.org/confluence/display/KAFKA/KIP-405%3A+Kafka+Tiered+Storage&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;KIP-405&lt;/a&gt;) to avoid tight coupling of storage and processing in a broker. It provides two tiers of storage, called local and remote. These two tiers can have respective retention policies based on the respective use cases.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7bb99c16-9f01-4606-9393-18634deb8b8c&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;width&amp;quot;:&amp;quot;700px&amp;quot;,&amp;quot;height&amp;quot;:&amp;quot;auto&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;e25cccec-32e4-4c15-976a-4a4725861800&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXdrkDm5z8lSbIzR0Xure8R4qrXa8JqczXMcNyQs17yede4tKZScrbVWTc4PjScxs-k_qrcks2cLmf2nOJi9x4tf2Zyzyql2Ql7jA3Ty4qNQoth7NeTL9itjkQnaJKIwm3zZVYUgYXx_2yr4lgyAF-9eLr-i?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 2: End to end interaction of Kafka broker with tiered storage.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d3f58e6f-e3fc-4df8-84f2-247071e699aa&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;00272d69-19b6-4d44-b7f1-ab451bbd36af&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-goals&#34;&gt;Goals&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f8ada8a4-3425-4352-bd37-c99f0a8e6291&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Below are the main goals that we set for tiered storage:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3cd3f2c9-a5d0-44a3-8335-ca7b05d03d38&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Extend the storage beyond the broker&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Memory/PageCache&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Local storage&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Remote storage support (including cloud/object stores like S3/GCS/Azure)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Durability and Consistency semantics similar to local storage&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Isolation of reading latest and historical data&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;No changes are required from clients&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Easy tuning and provisioning of clusters&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Improve operational and cost efficiency&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f96a808a-53f5-4733-a618-0ed612929034&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;87df347d-17d7-42dc-b9b6-856160fbd93e&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-architecture&#34;&gt;Architecture&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f6ceb13c-20bc-44d2-be91-a3cc6b3523ae&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Kafka cluster enabled with tiered storage is configured with two tiers of storage called local and remote. The local tier is the broker’s local storage where the segments are stored currently. The new remote tier is the extended storage, such as HDFS/S3/GCS/Azure. Both these tiers will have respective retention configurations based on size and time. The retention period for the local tier can be significantly reduced from days to a few hours. The retention period for the remote tier can be much longer–days, or even months. Applications sensitive to latency conduct tail reads and are catered to from the local tier, utilizing Kafka’s efficient page cache utilization for data retrieval. On the other hand, applications such as backfill or those recovering from failures requiring older data than what’s locally available, are served from the remote tier.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;99e485ed-bfbb-4a06-83f3-7781b0ccb009&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;This approach enables the scalability of storage in a Kafka cluster without being tied to memory and CPU resources, thus transforming Kafka into a viable long-term storage option. Moreover, it decreases the local storage burden on Kafka brokers, consequently reducing the data to be transferred during recovery and rebalancing. Log segments accessible in the remote tier don’t require restoration on the broker and can be accessed directly from the remote tier. It eliminates the necessity to expand the Kafka cluster storage and add new nodes when extending the retention period. Additionally, it allows for significantly longer data retention without the requirement for separate data pipelines to transfer data from Kafka to external storage (a common practice in many current setups).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;285c094f-9538-44de-9270-4721f1bf1133&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Tiered storage divides a topic partition’s log into two different logical components called local log and remote log. Local log contains a list of local log segments and remote log contains a list of remote log segments. The remote log subsystem copies each topic partition’s eligible segments from local storage to the remote storage. A segment is eligible to be copied when its end offset is less than &lt;em&gt;LastStableOffset&lt;/em&gt; of a partition.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2d6d304d-aba7-46d5-aa43-bad98a0e13d3&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;bf09d07e-1d0f-4647-8465-310196ef72ff&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXdDJEudzpCrGDSR9yN0sNZ5YU_AM1ExXihNssXH0d5SGi01nOJ4R6xY0yY7frm6ESriC5o6XFiqQMVSCVDWpRK0l6nFxaF8CBCdY0ZpN1beZUsmqpSe4VragjX8kjUjh5VXGKMD-g2i9GMOaIJ99if2dJkj?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 3: Local log offsets and remote log offsets.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;656259a5-41ec-4162-a1a8-fa9680404f3d&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure data-wp-block-name=&#34;core/table&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;970a47e8-729d-4286-a17f-307c713c9f18&amp;quot;,&amp;quot;hasFixedLayout&amp;quot;:false,&amp;quot;head&amp;quot;:[],&amp;quot;body&amp;quot;:[],&amp;quot;foot&amp;quot;:[]}&#34; class=&#34;wp-block-table&#34;&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt; Lz&amp;nbsp; = Local log end offset&amp;nbsp;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;Lx&amp;nbsp; = Local log start offset &amp;nbsp;&lt;/td&gt;&lt;td&gt;Ly&amp;nbsp; = Last stable offset(LSO)&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure data-wp-block-name=&#34;core/table&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c7fa71b6-1b3f-414b-9d7d-8967a9a41e7a&amp;quot;,&amp;quot;hasFixedLayout&amp;quot;:false,&amp;quot;head&amp;quot;:[],&amp;quot;body&amp;quot;:[],&amp;quot;foot&amp;quot;:[]}&#34; class=&#34;wp-block-table&#34;&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;Ry&amp;nbsp; = Remote log end offset &lt;/td&gt;&lt;td&gt;Rx&amp;nbsp; = Remote log start offset&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;em&gt;Lz &amp;gt;= Ly &amp;gt;= Lx and Ly &amp;gt;= Ry &amp;gt;= Rx&lt;/em&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;cdfcf4f5-b74b-4219-ab12-4bb78c78a00a&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a1242f90-4a1d-4f87-9dc7-e49627a2062a&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Apache Kafka storage subsystem maintains the above offset constraints for local and remote log segments of a topic partition.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b4c968f9-e76a-4c83-a966-e0dae7131168&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;width&amp;quot;:&amp;quot;700px&amp;quot;,&amp;quot;height&amp;quot;:&amp;quot;auto&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;f687a646-355f-4412-9ad8-f793d9942d75&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXcnNa5SMjEkpYEOgrEV8WQaKzXNhUFy5I1iuFKcHifODuPUg26arhCP8wvWpPsm7onOA8jTn2IS7_tTF9VXmg2NHC2p5IPSFLXw39fP8b4c47ksowG9dYI-iyFHE2szvRfNMn-QBQc4s_lgOg0tMYH3sKw?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 4: High level architecture of Kafka tiered storage components.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a7ef1ee3-e8df-4942-b3ac-a88b2ec5feca&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d568d925-c3a2-4eed-ab17-976503458642&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The above diagram gives a high-level overview of the new architecture with newly introduced components:&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9c25ec3d-7751-4e49-9a9d-183df57a2782&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;RemoteStorageManager&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;RemoteLogMetadataManager&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;RemoteLogManager&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6ffe5286-c491-4dd9-9573-0439c7790602&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We introduced two pluggable components within the storage layer called &lt;em&gt;RemoteStorageManager&lt;/em&gt; and &lt;em&gt;RemoteLogMetadataManager&lt;/em&gt;. These can be implemented by developers based on their targeted storage systems and plugged into their Kafka environments.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c3bb416c-1811-4b68-bd52-f28cc63a8d4f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;em&gt;RemoteStorageManager&lt;/em&gt; interface provides the actions for remote log segments that include copy, fetch, and delete from remote storage.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7c9686e1-1c96-4cd4-81fc-4e4651a9ca6e&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;em&gt;RemoteLogMetadataManager&lt;/em&gt; interface provides the lifecycle operations of metadata about remote log segments with strongly consistent semantics. There is a default implementation that uses an internal topic. Users can plugin their implementation if they intend to use another system to store remote log segment metadata.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;10f1a733-e2e1-4da9-9e2b-f0575b8179ce&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;em&gt;RemoteLogManager&lt;/em&gt; is a logical layer responsible for managing the life cycle of remote log segments. That includes:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;cfbe1efc-e968-4d3c-a129-657cab42d2c5&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Copying segments to the remote storage&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Cleaning up of expired segments in the remote storage&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Fetching the data from remote storage&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6085e748-3614-425e-a85e-1814e32e68d3&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;It also uses the pluggable remote storage components as and when needed. Each remote log segment is identified with a unique identifier called &lt;em&gt;RemoteLogSegmentId&lt;/em&gt;, even for the same topic partition and offsets.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1b79721a-afd5-45be-aa53-a361a4db4016&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;f9f19038-588b-4ba3-b4f1-61bf5bd2c67e&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-copying-segments-to-remote-storage&#34;&gt;Copying Segments to Remote Storage&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6501289f-c0a1-44f9-8bd8-c47cc0d57d36&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Each topic partition stores data in a logical log, which contains a sequence of physical log segments with the respective auxiliary files like segment indexes, producer state snapshots, and leader epoch checkpoints. Each partition replica creates these log segments, flushes them to disk and rolls over the segment based on segment roll configurations based on size or time. A log segment is eligible if its end offset is less than the &lt;em&gt;last-stable-offset&lt;/em&gt; of the partition. The broker acting as a leader for a topic partition is responsible for copying the eligible log segments to the remote storage. It copies the log segments from the earliest segment to the latest segment in a sequence. It uses &lt;em&gt;RemoteStorageManager&lt;/em&gt; for copying the segment with its indexes like offset, timestamp, producer snapshot, and its respective leader epoch cache. It also adds and updates entries in &lt;em&gt;RemoteLogMetadataManager&lt;/em&gt; with respective states for each copied segment.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;595ecbe5-36d6-43dc-9fe1-0c740e87c7e5&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The below diagram shows the sequence of copying the segments by maintaining local and remote log segments:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;db6e0950-4607-4d3f-9176-15c6f1f3552e&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;9e0b7194-32dc-4f35-96f9-3c9aea1767ac&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXcf2ufqsgcmWb4xf9M4813H55wCn9NC_n8HxCRK5nOT12LvqY5GNmRP_Rh4fqfiDk0SYdJ-63XaxZU5bTrleU-Ap77XBl0eyvjYc1_RIME_6AxlIGXWu9oLOoa3j9PQWyICHXjeOqISivV5Rcx2AhuAHGaU?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 5: The above diagram depicts a topic partition’s log segments with their respective start offsets. Before tiered storage is enabled, there will not be any segments in the remote storage.&amp;nbsp;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8578077d-7ecc-44cf-b2f0-ee21c603f836&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;c14dd36f-9fea-4da5-902f-1e4de0392748&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXc26wPlPeq7XR91GrM_6-QfWh0y6rKGCpGvA1islRticBFGAx33pR0Wm5cMl8OZSoDFm1RNKtpNcRKlj6Bcvuke-cdXBhNEGImxFphNDUBYoI3zb0XTYUek87oPOzV7OfcLoO86FkTeqyFrgFZpfzmAKT0?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 6: The above diagram depicts the eligible segments started copying to remote storage after tiered storage is enabled for that topic.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a33e00c6-209c-44cb-91ac-5222d96c8ab9&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1091633,&amp;quot;sizeSlug&amp;quot;:&amp;quot;full&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;055f601e-69cd-4a34-b281-14623b69c018&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;899&#34; height=&#34;333&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/07/Figure7.png&#34; alt=&#34;&#34; class=&#34;wp-image-1091633&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=899,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/07/Figure7.png 899w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/07/Figure7.png 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/07/Figure7.png 768w&#34; sizes=&#34;(max-width: 899px) 100vw, 899px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 7: The above diagram depicts some of the segments in the local storage were deleted based on the local retention configuration. We can see that segments earlier to offset 300 were deleted, but those segments are available in remote storage.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;47e9b3a2-d752-4c0a-b5b3-c66e7a0fcbf4&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;1058e67b-5adb-4dac-9629-89c807ae2bc7&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-cleaning-up-of-remote-segments&#34;&gt;Cleaning up of Remote Segments&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;035f67ed-dda2-4d78-bbf0-cbf76a605f64&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;As mentioned earlier, each topic will have a retention configuration based on size and time for both local data and remote data. Remote data is cleaned up at regular intervals by computing the eligible segments by a dedicated thread pool. This is different from the asynchronous cleaning up of the local log segments. When a topic is deleted, cleaning up of remote log segments is done asynchronously and it will not block the existing delete operation or recreate a new topic.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9d0dbe68-efc5-4c44-93c5-b07b115f3954&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;990b7b23-7491-49d7-a00a-1d9f3469b53b&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXczW4_RY_MyEEv6A1X0Rw2k7Yr-bPzt139veWuSaeGKqD_27xKyhqivZW609v4GUADtafNrZBmdzC9S9xj72tOTtqbKl9n_ivg9vkIdTJb4Lt7sK7I6UNt20kjrDUP2dwODaVr7rERXZgMfeazr9nxKJhe8?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 8: The above diagram depicts the cleaning up of remote log segments based on the complete log retention configuration. Here, segments earlier to offset 200 were deleted.&amp;nbsp;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c74af8b0-ee98-426a-893e-788c5b3562cc&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;9df2b72c-e610-471d-a7bb-752f19e9e225&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-fetching-segments-from-remote-storage&#34;&gt;Fetching Segments from Remote Storage&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1139aefd-e5bd-423e-9902-ebc767f49ba0&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;When a consumer fetch request is received and it is only available only in remote storage, then it is served using a dedicated thread pool. If the targeted offset is available in the broker’s local storage, then it is served using the existing local fetch mechanism. So, a broker separates the local reads from remote reads and they will not block each other.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4d905c15-c255-49f9-b98c-2fd8fb2e2d4a&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;em&gt;RemoteLogManager&lt;/em&gt; determines the targeted remote segment based on the desired offset and leader epoch by looking into the metadata store using &lt;em&gt;RemoteLogMetadataManager&lt;/em&gt;. It uses &lt;em&gt;RemoteStorageManager&lt;/em&gt; to find the position within the segment and start fetching the desired data.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0af941c5-ea10-4ee5-9180-0fa2f7d5be33&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;width&amp;quot;:&amp;quot;700px&amp;quot;,&amp;quot;height&amp;quot;:&amp;quot;auto&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;9289e088-db11-4e29-86df-02a1996c879d&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXfCCN3aludPERABf77NGITGxCPFcslvI11RammENhBCFoxUSl4XtWKzILkalB2GRWE4MO6WxBxw0QWLV8shK8Y1IVbUKUAQueS3mnZLbVx1E-T_rq_udar088WHjkWVIEt7xhf2xq5tCNBwZrsk4PuzIli8?key=kis14CJAvWJjUiCdmN0jHg&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 9: Remote fetch path.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e8bfa664-6413-43d2-ac3c-06d4c632a8d8&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;02f4064f-5abd-43a4-a24e-9ac92c32faa2&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-follower-replication&#34;&gt;Follower Replication&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8a9f7dc7-6191-48fc-8184-b987a9abfde7&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Followers replicate the data from a leader to become an in-sync replica. They need to maintain the message lineage across a sequence of log segments as the leader. They may also do truncation of the segments if needed to maintain the message ordering.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;26775e4f-0ecd-4026-b6bb-79139de3d112&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;With tiered storage, follower replicas need to replicate the segments that are available on the leader’s local storage. Each log also needs auxiliary data like leader epoch state and producer-ID snapshots. So, a follower needs to build this auxiliary data before it starts fetching any messages from the leader. The follower fetch protocol makes sure to maintain the consistency and ordering of messages across all the replicas irrespective of changes in the cluster like broker replacements, failures, etc. If you are interested in understanding the inner workings of the enhanced follower fetch protocol, you can read it in the &lt;a href=&#34;https://cwiki.apache.org/confluence/display/KAFKA/KIP-405%3A+Kafka+Tiered+Storage#KIP405:KafkaTieredStorage-FollowerReplication&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;original document&lt;/a&gt; to understand the detailed design and how it handles several scenarios.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;5cf5ae52-b9e7-4d38-b2a6-d2346e2d9e75&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-conclusion&#34;&gt;Conclusion&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ed0dbc6e-6b12-4836-b874-e1a7425c4815&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In this blog, we covered an introduction and high-level architecture of tiered storage at Uber. If you are interested in more details, you can read the detailed design in &lt;a href=&#34;https://cwiki.apache.org/confluence/display/KAFKA/KIP-405%3A+Kafka+Tiered+Storage&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;KIP-405&lt;/a&gt;. Most of this work was done collaborating with the Apache Kafka community. The major part of this feature is available as early access in Apache Kafka 3.6.0.&amp;nbsp; This feature has been running in production for ~1-2 years in different workloads respectively. In the next part of this blog series we will cover our production experience and how it helped with better reliability, scalability, and efficiency of our clusters.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;fontSize&amp;quot;:&amp;quot;small&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;3b7d71e6-2de6-46a6-8a92-a754b708a278&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34; class=&#34;has-small-font-size&#34;&gt;Apache®, Apache Kafka™, and Kafka™ are either registered trademarks or trademarks of the Apache Software Foundation in the United States and/or other countries. No endorsement by The Apache Software Foundation is implied by the use of these marks.&lt;/p&gt;</description>
      <pubDate>Mon, 01 Jul 2024 10:58:33 +0000</pubDate>
    </item>
    <item>
      <title>【Odin: Uber’s Stateful Platform】Odin：Uber 的有状态平台</title>
      <link>https://www.uber.com/blog/odin-stateful-platform/</link>
      <description>【&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;90695143-31cf-483d-b85f-7ce1334bb6f8&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-introduction&#34;&gt;Introduction&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;548c2e1c-75fa-4ffa-905e-ca342260c0d0&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Uber employs various technologies for data storage, including well-known open-source products such as Kafka, Cassandra, and MySQL, alongside internally developed solutions. In 2014, Uber underwent rapid expansion. Like many startups, the technology teams manually performed provisioning and maintenance operations using runbooks. This approach led to operational toil as storage demands rapidly increased. Uber created a technology-agnostic management platform called Odin to uplevel operational throughput through automation and allow the teams to manage thousands of databases effortlessly.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8cf61d25-9d6d-40de-a187-c932da9d9811&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The Odin platform aims to provide a unified operational experience by encompassing all aspects of managing stateful workloads. These aspects include host lifecycle, workload scheduling, cluster management, monitoring, state propagation, operational user interfaces, alerting, auto-scaling, and automation. Uber deploys stateful systems at global, regional, and zonal levels, and Odin is designed to manage these systems consistently and in a technology-agnostic manner. Moreover, Odin supports co-location to increase hardware cost efficiency. All stateful workloads must be fully containerized, a relatively novel and &lt;a href=&#34;https://news.ycombinator.com/item?id=13054793&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;controversial&lt;/a&gt; concept when the platform was created.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6f97caa1-0a1f-46ab-8261-61b142951e9f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;This blog post is the first of a series on Uber’s stateful platform. The series aims to be accessible and engaging for readers with no prior knowledge of building container platforms and those with extensive expertise. This post provides an overview of Odin’s origins, the fundamental principles, and the challenges encountered early on. The next post will explore how we have safely scaled operational throughput, significantly improving our handling of large-scale, fleet-wide operations and up-leveling runbooks through workflows. Stay tuned for more posts in the series.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5d8805b0-a807-4ce6-b495-7e2138a76eba&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0e529716-5369-49b9-a516-66e71fa92691&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-the-scale-of-the-platform&#34;&gt;The Scale of the Platform&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c7275b4e-2c3a-465d-ae42-598f1e28f875&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Since 2014, Uber’s storage and data infrastructure has grown dramatically, from a few hundred hosts to over 100,000 today. These hosts support the operation of 300,000 workloads across various storage clusters. Each workload on the Odin platform is similar to a Kubernetes® pod, comprising a collection of containers. Currently, the platform manages 3.8 million individual containers. The fleet of hosts collectively boasts a storage capacity of multiple exbibytes and millions of compute cores.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;70705850-6138-44c0-b04f-cfc5d407b5a5&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The platform supports 23 technologies, ranging from traditional online databases such as MySQL® and Cassandra® to advanced data platform technologies, including HDFS™, Presto™, and Kafka®. It also integrates resource scheduling frameworks like Yarn™ and Buildkite™, primarily due to the platform’s robust capacity management and scaling solutions.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;bc701c08-c47b-4395-bee9-06a97e004924&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The platform is heavily colocated to leverage the resources available on the hosts best. Uber uses locally attached drives for all stateful workloads for performance. Our scheduler, therefore, has to optimize to keep allocation rates high across all three dimensions (i.e., CPU, memory, and disk) to be efficient. We boast a very high allocation rate of +95% on the bottlenecked resource, and we have hosts with +100 databases.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a952ccc3-67f4-44c4-8ebd-c3867d80f3cd&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The Odin platform is both technology-agnostic and cloud-agnostic through &lt;a href=&#34;https://www.uber.com/en-SE/blog/crane-ubers-next-gen-infrastructure-stack/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Uber’s cloud abstraction&lt;/a&gt; and currently runs across OCI, GCP, and Uber’s on-prem fleet.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0aba77a1-cb2f-4642-93ee-48c85afed8ba&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;49ba8eed-f6b5-48d7-9472-a225618b4db4&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-a-self-healing-platform&#34;&gt;A Self-Healing Platform&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;578c4714-ae37-4b95-94aa-7902076a06d7&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Odin is built to be fully declarative and intent-based. This results in properties such as failure tolerance, scalability, and self-healing. The desired state is expressed as the goal state, which the platform uses to converge the actual state automatically. We accomplish this by using an extensive collection of small, autonomous remediation loops designed to ensure the system’s actual state converges with the declared goal state by continuously nudging the system in the “right direction.”&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7df9c643-7221-4e50-99b6-e7223356e28f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Today, Odin and Kubernetes® share many similarities. This mental model will be helpful as you read through the blog series.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;fe74b631-4317-499c-a507-32164ec308bc&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The example below illustrates the anatomy of a remediation loop. A remediation loop starts by inspecting the goal state. It then collects the actual state, identifies discrepancies between the two, and uses &lt;a href=&#34;https://cadenceworkflow.io/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Cadence™ workflows&lt;/a&gt; to adjust the system state to close the gap. This is similar to how Kubernetes controllers work–except they directly manipulate the state through the APIServer.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f6ae9904-86ac-423f-95e2-a04e0f831377&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;4743a97f-d970-4b9e-bcc7-60029013f43b&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXfrbiVvJh6xCuhP9K9RQRFzpiFd5uwiRBFOOtPiMfB7iRYc_z-MMSXNB34iLdfE_-mIIx2HbQz08pY1IRYeuaaa_W6JlTy2IvK3owVsrkDSPqnwXAXAvy9LX3zySlsEbvmUXL3AcAaXGIMgzpvf0RwXAeP-?key=0kVK3UHY5mqh0YpEHEfxHw&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 1: High-level overview of an Odin remediation loop.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;79575b6a-b658-4b7e-adff-72767d32195f&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8b602db4-cbe7-46fb-8ce3-a60810a26396&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Our remediation loops prioritize modularity and loose coupling. This facilitates horizontal scaling and ease of development so that each loop can be developed as an independent microservice.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2397929c-c8f4-432b-ba9d-96439c194265&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;On the Odin platform, we have streamlined the development of these loops by providing an up-to-date view of the global system state through our data integration platform, &lt;a href=&#34;https://eng.uber.com/grail&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Grail&lt;/a&gt;. Grail delivers a unified data model that spans all technologies and provides an up-to-date view of the platform’s goal and actual states, including hosts, containers, and even the technology-specific internal state. Our Grail setup also allows performing queries with a global scope, fetching data provided in all the data centers and regions around the globe where Uber operates. In essence, think of Grail as the resource model in the Kubernetes APIServer on steroids.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e0b4f9d7-27e9-4f5a-b0be-32ff310cbbe9&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The platform’s control plane focuses solely on high-level decisions, such as scheduling workloads and managing cluster topology.&amp;nbsp; The API for manipulating the goal state is the execution of a workflow. Both remediation loops and human operators start workflows. The platform provides a UI that allows operators to quickly overview the state of their databases and apply operations when needed.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;141a1dce-0b34-4801-b240-c434901bc5ec&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Workflows are incredibly valuable because of the insights they provide. A workflow for updating goal state usually consists of two steps. First, the goal state is updated, and then the workflow will monitor the actual state until it converges on the specified goal state. So when it doesn’t, it is clear which operations didn’t converge, including the context of why that operation was performed in the first place. As the actual state is not expected to converge immediately, the system must prevent the remediation loops from continuously starting workflows that attempt to fix the same issues.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;cf949352-02eb-4d3b-a249-178fe472a2a3&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;271afd88-96a7-4bd9-849c-7e5886fc5d50&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXfkpBCcYU1h2PhNjamcT3aGcIQWIAr7wn-77iP7vY861TcFRrSJ9b4oayn5Brm7MgSzS3nqJqB0J9Qys0t6CnYtHWgIYckWP64HUxy-8LKxmnHBgC-DJU2zkpCZpmTZiLEJ4GP08aLD5yqOgOuk6S4KDsc4?key=0kVK3UHY5mqh0YpEHEfxHw&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 2: A 10.000ft view of Odin’s architecture.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;56db4950-7d76-45b8-819e-0dd0fa247fdd&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2acecab1-597e-464e-a287-66bd80786482&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-managing-generic-storage-clusters&#34;&gt;Managing Generic Storage Clusters&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d0ffd8b7-98aa-4deb-94ae-15aee37e8492&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Odin is built on a technology-agnostic cluster model that provides generic operations for managing clusters of workloads of any kind. This model supports generic operations such as adding or removing workloads, upgrading container images, and handling other cluster-related tasks uniformly across technologies. As the model and operations are technology-agnostic, the technology is required to extend the platform through a collection of plugins to tailor various aspects of cluster management according to their specific needs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;cda4e095-7482-482f-b6b2-a05a92a267d6&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-two-host-agents&#34;&gt;Two Host Agents&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;dd82e5e7-cf72-4e2e-ab87-2d536dd42dbe&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The Odin control plane is divided into two parts. So far, we have only discussed the global part. At the host level, there are two agents. One is shared among all workloads on the host and is technology-agnostic. We simply refer to this as the &lt;em&gt;odin-agent&lt;/em&gt;. The other agent is technology-specific and runs containerized as part of the workload. These two agents, when combined, serve the same functionality as the &lt;em&gt;kubelet&lt;/em&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;65a90e51-2220-4720-94ac-84668c27dbbd&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;a12eed6c-d521-456b-8c52-de1b38e4bec2&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXdSePHcS8Ijkt17F1dBAJtAyQ4DANP0C3CoVQdZFqpTDNdMg6oUZLrPRUgoTrTUC_3ukppykFnZiFLkJkfTrH_iV_OW5XdhajSi6fKC9z7fSq9Yw6x8l0XgDvomdfCgZqe5Z5ZZYeHvmvAwoeaMPNZEyoHs?key=0kVK3UHY5mqh0YpEHEfxHw&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 3: The anatomy of an Odin host with the two host-level agents communicating with the global control plane.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e0817d94-ec97-4063-9a8c-4e9904175475&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1621dd43-a4be-45da-b5d6-0d17c0c5bb08&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The host agent communicates the latest goal and actual states with the global control plane. Its primary responsibility is managing host-level resource allocation, such as scheduling cores for workloads, creating and managing disk volumes/cgroups, and bootstrapping the workloads when assigned to the host.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8fa5a88e-540a-4c48-b1cc-ed7df86a3a00&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The technology-specific agent is known as the &lt;em&gt;worker&lt;/em&gt;. The worker is a supervisor running alongside each workload in a side container. Its primary role is to ensure that the running containers align with the goal state and to collect health and other relevant data for reporting to the global part of the control plane. The worker’s generic functionality includes starting and stopping containers. You can think of the worker as the translator between the generic cluster state the platform understands and the running database containers in the workload.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9965fa47-2eb1-4626-b1d3-dc518449f76a&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The technology team can customize the worker to collect the technology-specific actual state and apply the goal state to the workload. For instance, the MySQL worker is tasked with ensuring that MySQL masters and replicas maintain their roles and report the current state for consumption to the global control plane. This allows the team to write new workflows for operating the cluster based on the actual state of the cluster. Many technologies have extended their workers to perform self-healing cluster operations in their workers. Examples could be coordinating leader elections or data replication when the cluster topology changes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;5598ca20-758c-4080-b97b-81afc4cffece&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-optimizing-for-robustness-and-resilience&#34;&gt;Optimizing for Robustness and Resilience&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;26972dfb-89dd-40ce-906d-ca16199626d9&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Separating the control plane into a host-local and a global component allows us to deploy worker changes per workload, limiting the potential blast radius of bad changes to the smallest possible unit. The same applies to each container in a workload, as the platform allows in-place upgrading containers individually.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;138c489d-3c9f-4892-84e1-6387f9265a64&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;For both agents, a rule is that the goal state must first be written to disk before any changes to the running workloads are made. This approach guarantees self-sufficient clusters that can be initialized without an active control plane, effectively addressing the bootstrap issue. Furthermore, it offers robust failure resilience, allowing workloads to function during control plane degradations and simplifying writing emergency tooling.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;f07917a0-558e-42cb-b46f-c7a20196c247&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-transitioning-identities&#34;&gt;Transitioning Identities&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1eef1f47-896d-478c-9dfe-b43cd5b83885&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;As we continuously optimize for efficiency and modernize our host fleet, moving a workload from one host to another has become one of the most common operations on the platform. To date, we reschedule up to 60% of our stateful workloads per month. A crucial requirement of stateful workloads is maintaining the workload identity across rescheduling. This capability allows, for example, the replacement of one workload serving a shard with another serving the same shard. In Kubernetes, this is managed through StatefulSets by assigning a stable pod identity that persists across rescheduling. When a pod is deleted, a new one is provisioned with the same identity. Let us explore why this model does not suit Uber’s use case well.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1bbb811d-86a9-4cd2-b96b-21285d91dabe&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;As mentioned, Uber uses locally attached drives for all stateful workloads for performance. This setup requires that data on a host be replicated and made available elsewhere before the corresponding workload can be terminated. The cluster becomes temporarily under-provisioned if a workload is shut down before its replacement is fully ready. This delay, which is not negligible with a median time of 1 hour, exposes the cluster to an increased risk of data loss or availability issues. Moreover, this delay also diminishes the cluster’s overall capacity to handle requests.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;3b6e5f94-d8c1-4822-aff4-a93c79b744c9&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-replacing-workloads&#34;&gt;“Replacing” Workloads&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;aa7ad1d4-ea62-4c1c-910d-8286f06a3711&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Consequently, the most essential operation on Odin is migrating a workload from one host to another–or, in Odin terms, “replacing” the workload. A replace operation is purposely designed to &lt;em&gt;make-before-break&lt;/em&gt;. This means it creates a new workload that can carry the identity and data of the workload it replaces &lt;em&gt;before&lt;/em&gt; the old workload is shut down, wherever possible. The technology integrations can choose which parts of the goal state to propagate between workloads. The goal state model makes the two workloads explicitly aware of each other’s existence. This is essential because it allows the respective workers to coordinate the process for data replication and other things. In rare cases, when &lt;em&gt;make-before-break&lt;/em&gt; semantics are impossible (e.g., the old workload is on a failed host), the old workload is deleted simultaneously with the replacement workload being created.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f2c8a1a1-fe85-4656-bbd8-381c24da7641&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Using make-before-break also has an efficiency benefit, as the alternative would require us to run the clusters overprovisioned continuously. In our model, we only temporarily overprovision when we have to.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;de1ed6fc-1a1e-4666-b2e9-c58224a32d9e&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c29e483c-a48a-4924-a033-ef8503c36fe1&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-growing-pains&#34;&gt;Growing Pains&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;dad7f7a3-0ea3-479b-a1fe-9bfa5af38d18&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The first iteration of the Odin platform was a giant leap forward concerning the teams’ ability to operate their storage clusters. Storage teams could converge all their operations and insights on a single platform with a shared operational model. However, the platform was still very much human-centered. Humans were the principal actors initiating changes on the platform, and, crucially, they were the ones vouching for the safety and the fit of the operations performed. The role of the remediation loops was confined to operations with a relatively small scope, such as a single replace workflow&lt;em&gt;.&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;fad8c154-683f-4e0d-ba9b-d1d4b7157cb8&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Operational overhead started to grow as the business continued to scale to the point where fleet-wide operations spanning technologies were not practically possible for human operators to do. Examples of complex, fleet-wide, cross-technology operations that require us to move workloads are:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0c6b29b5-a3b0-4770-b81e-5374de15e4b5&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Optimizing workload placement for resiliency against infrastructural failures like rack or zone failures&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Host bin-packing to improve cost-efficiency&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Fleet-wide host upgrades like new kernels, firmware, or functionality like LVM/cgroupv2&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Facilitating the bringing up of new data centers or decommissioning existing data centers&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;668aa557-dc41-41b6-a40a-29371389096e&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Furthermore, the large number of databases on a single host makes handling host failures daunting. These limitations indicated that we had to double down on automation by developing new remediation loops with much broader scopes than we used to.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;56f8fe34-2ef2-4a3f-bb0d-4f69c90b960c&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-coordination-required&#34;&gt;Coordination Required&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8036e749-8a7a-4c7f-b617-1321eac2cf8f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The increased operational load could quickly result in outages if not carefully coordinated. Imagine a situation where a workload in a 3-node consensus-based storage cluster is taken down to perform a container upgrade. Now imagine another remediation loop that has identified that one of the other workloads in the cluster would benefit from being moved for efficiency reasons. If allowed, this would result in the storage cluster losing quorum, impacting the write availability.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;44963a9c-9e27-4921-91da-42d031dd81be&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Initially, we started augmenting the remediation loops to perform concurrency control internally (Figure 3). This way, they could prevent operations of the same type from creating problems for the storage clusters. For instance, the container upgrade loop would block overlapping upgrades. However, this approach fell short as it didn’t solve the issue of conflicting operations started by different remediation loops. Figure 3 shows a case where two independent operations can operate two workloads in the same storage cluster, resulting in an availability loss.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;37267e15-3898-4883-b5d5-6617d00f67ce&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;d131b897-0c2b-4684-8052-d5db42a85208&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXd4i6HPr3ZkL1WFmR1Kd-mkiLceVO0Liik1jb6NR51eaucwSAjFss_8QW_m-doDIHsbCW9kv5TJwgPukhH3rPiaE1o0lWbpvtlwSliGofFpGiD68jS5NGuxR1V3HZs6HxnZYsScd9vpweh0ouKSHRF0RlbN?key=0kVK3UHY5mqh0YpEHEfxHw&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 4: Internal concurrency control does not protect storage clusters against overlapping operations and can compromise availability.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4ab49524-3b00-4ca5-b966-d2a03569fdc2&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5304b888-d27b-4d5c-8703-a262a8183b7f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Different technologies exhibit widely varying tolerances for safe cluster operations. For some technologies, the specific workloads being operated are crucial, while all workloads are treated equally for others. Some technologies focus solely on ensuring that a certain number of workloads are always available within the cluster. This diversity in requirements made it such that we had to support customizing cluster management strategies to the specific needs of each technology.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d2d9eb70-3d33-4f06-a09d-71c7ba530c6c&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We needed to ensure global, cross-type coordination of operations using a system that could guarantee to preserve the cluster availability by leveraging technology-specific limits based on the current workload health and disruption budget. Furthermore, it should protect against engineering mistakes and overload of the internal platform systems by enforcing platform-wide global concurrency and rate limits.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;573fa4c8-a71a-4934-bdd2-6e76c64ce602&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;4b05fc1f-55a2-498f-8240-0bbc9d986ea0&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-summary&#34;&gt;Summary&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;cd8543d3-0d20-4857-97d7-92d0f10392a5&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In this introductory post of our series, we explored the background and foundational principles of Uber’s stateful platform, Odin. Odin stands out as a generic, technology-agnostic platform capable of managing various technologies with special demands on how databases are operated.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b162d0bd-d1af-4e18-bad6-01cf9829155e&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We discussed how Uber’s databases use locally attached disks for enhanced performance and cost-efficiency and the challenges this presents, as the stored data must follow the workload identity.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a6a3e2b0-f102-45ac-8dab-4f45887f56c1&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We also examined how the platform is inherently intent-based, with disparate remediation loops continuously striving to align the actual state of the managed workloads with their intended goal states. These loops initiate Cadence workflows to update the goal state and wait for convergence—a process that, at scale, requires careful coordination to safely manage without compromising the availability of the managed databases.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;89518bc2-03a8-452f-a779-fab4eb21f534&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In the next blog post, we will discuss how we centralized the coordination of all operations and leveraged it to significantly improve Uber’s ability to operate the fleet at scale.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;74b918d1-e0a6-4dd8-adb0-261d96dcccdb&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-acknowledgments&#34;&gt;Acknowledgments&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;114640af-7176-4346-87ab-dd430c350a03&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The Odin platform was only possible with the effort of many contributors through the years. The authors would like to thank all the teams working on the platform or contributing integrations and to previous team members who helped make the platform great.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;fontSize&amp;quot;:&amp;quot;small&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;5ad1e8e8-0a5d-4299-8c12-36015f6ef911&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34; class=&#34;has-small-font-size&#34;&gt;The cover photo was generated using OpenAI’s ChatCPT Enterprise and edited using Pixlr.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;fontSize&amp;quot;:&amp;quot;small&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;44181acd-1a06-48b7-97b3-2538dfbffe59&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34; class=&#34;has-small-font-size&#34;&gt;Kubernetes® is a registered trademark of the Linux Foundation in the United States and other countries.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;fontSize&amp;quot;:&amp;quot;small&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;a3a471c0-0118-4ea6-840b-90e764c1ea0e&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34; class=&#34;has-small-font-size&#34;&gt;MySQL® is a registered trademark of Oracle Corporation and/or its affiliates.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;fontSize&amp;quot;:&amp;quot;small&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;3827feed-6951-4e20-bd15-7fb796002361&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34; class=&#34;has-small-font-size&#34;&gt;Apache Cassandra®, Apache HDFS™, Apache Kafka®, Apache Yarn™, and Apache Presto™ are registered trademarks or trademarks of the Apache Software Foundation in the United States and/or other countries. The use of these marks does not imply endorsement by the Apache Software Foundation.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;fontSize&amp;quot;:&amp;quot;small&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;06d69f2b-38ee-4898-946e-02588d178a99&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34; class=&#34;has-small-font-size&#34;&gt;Buildkite™ is a trademark of Buildkite Pty Ltd.&lt;/p&gt;】&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;90695143-31cf-483d-b85f-7ce1334bb6f8&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-introduction&#34;&gt;Introduction&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;548c2e1c-75fa-4ffa-905e-ca342260c0d0&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Uber employs various technologies for data storage, including well-known open-source products such as Kafka, Cassandra, and MySQL, alongside internally developed solutions. In 2014, Uber underwent rapid expansion. Like many startups, the technology teams manually performed provisioning and maintenance operations using runbooks. This approach led to operational toil as storage demands rapidly increased. Uber created a technology-agnostic management platform called Odin to uplevel operational throughput through automation and allow the teams to manage thousands of databases effortlessly.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8cf61d25-9d6d-40de-a187-c932da9d9811&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The Odin platform aims to provide a unified operational experience by encompassing all aspects of managing stateful workloads. These aspects include host lifecycle, workload scheduling, cluster management, monitoring, state propagation, operational user interfaces, alerting, auto-scaling, and automation. Uber deploys stateful systems at global, regional, and zonal levels, and Odin is designed to manage these systems consistently and in a technology-agnostic manner. Moreover, Odin supports co-location to increase hardware cost efficiency. All stateful workloads must be fully containerized, a relatively novel and &lt;a href=&#34;https://news.ycombinator.com/item?id=13054793&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;controversial&lt;/a&gt; concept when the platform was created.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6f97caa1-0a1f-46ab-8261-61b142951e9f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;This blog post is the first of a series on Uber’s stateful platform. The series aims to be accessible and engaging for readers with no prior knowledge of building container platforms and those with extensive expertise. This post provides an overview of Odin’s origins, the fundamental principles, and the challenges encountered early on. The next post will explore how we have safely scaled operational throughput, significantly improving our handling of large-scale, fleet-wide operations and up-leveling runbooks through workflows. Stay tuned for more posts in the series.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5d8805b0-a807-4ce6-b495-7e2138a76eba&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0e529716-5369-49b9-a516-66e71fa92691&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-the-scale-of-the-platform&#34;&gt;The Scale of the Platform&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c7275b4e-2c3a-465d-ae42-598f1e28f875&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Since 2014, Uber’s storage and data infrastructure has grown dramatically, from a few hundred hosts to over 100,000 today. These hosts support the operation of 300,000 workloads across various storage clusters. Each workload on the Odin platform is similar to a Kubernetes® pod, comprising a collection of containers. Currently, the platform manages 3.8 million individual containers. The fleet of hosts collectively boasts a storage capacity of multiple exbibytes and millions of compute cores.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;70705850-6138-44c0-b04f-cfc5d407b5a5&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The platform supports 23 technologies, ranging from traditional online databases such as MySQL® and Cassandra® to advanced data platform technologies, including HDFS™, Presto™, and Kafka®. It also integrates resource scheduling frameworks like Yarn™ and Buildkite™, primarily due to the platform’s robust capacity management and scaling solutions.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;bc701c08-c47b-4395-bee9-06a97e004924&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The platform is heavily colocated to leverage the resources available on the hosts best. Uber uses locally attached drives for all stateful workloads for performance. Our scheduler, therefore, has to optimize to keep allocation rates high across all three dimensions (i.e., CPU, memory, and disk) to be efficient. We boast a very high allocation rate of +95% on the bottlenecked resource, and we have hosts with +100 databases.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a952ccc3-67f4-44c4-8ebd-c3867d80f3cd&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The Odin platform is both technology-agnostic and cloud-agnostic through &lt;a href=&#34;https://www.uber.com/en-SE/blog/crane-ubers-next-gen-infrastructure-stack/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Uber’s cloud abstraction&lt;/a&gt; and currently runs across OCI, GCP, and Uber’s on-prem fleet.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0aba77a1-cb2f-4642-93ee-48c85afed8ba&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;49ba8eed-f6b5-48d7-9472-a225618b4db4&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-a-self-healing-platform&#34;&gt;A Self-Healing Platform&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;578c4714-ae37-4b95-94aa-7902076a06d7&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Odin is built to be fully declarative and intent-based. This results in properties such as failure tolerance, scalability, and self-healing. The desired state is expressed as the goal state, which the platform uses to converge the actual state automatically. We accomplish this by using an extensive collection of small, autonomous remediation loops designed to ensure the system’s actual state converges with the declared goal state by continuously nudging the system in the “right direction.”&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7df9c643-7221-4e50-99b6-e7223356e28f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Today, Odin and Kubernetes® share many similarities. This mental model will be helpful as you read through the blog series.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;fe74b631-4317-499c-a507-32164ec308bc&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The example below illustrates the anatomy of a remediation loop. A remediation loop starts by inspecting the goal state. It then collects the actual state, identifies discrepancies between the two, and uses &lt;a href=&#34;https://cadenceworkflow.io/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Cadence™ workflows&lt;/a&gt; to adjust the system state to close the gap. This is similar to how Kubernetes controllers work–except they directly manipulate the state through the APIServer.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f6ae9904-86ac-423f-95e2-a04e0f831377&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;4743a97f-d970-4b9e-bcc7-60029013f43b&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXfrbiVvJh6xCuhP9K9RQRFzpiFd5uwiRBFOOtPiMfB7iRYc_z-MMSXNB34iLdfE_-mIIx2HbQz08pY1IRYeuaaa_W6JlTy2IvK3owVsrkDSPqnwXAXAvy9LX3zySlsEbvmUXL3AcAaXGIMgzpvf0RwXAeP-?key=0kVK3UHY5mqh0YpEHEfxHw&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 1: High-level overview of an Odin remediation loop.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;79575b6a-b658-4b7e-adff-72767d32195f&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8b602db4-cbe7-46fb-8ce3-a60810a26396&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Our remediation loops prioritize modularity and loose coupling. This facilitates horizontal scaling and ease of development so that each loop can be developed as an independent microservice.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2397929c-c8f4-432b-ba9d-96439c194265&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;On the Odin platform, we have streamlined the development of these loops by providing an up-to-date view of the global system state through our data integration platform, &lt;a href=&#34;https://eng.uber.com/grail&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Grail&lt;/a&gt;. Grail delivers a unified data model that spans all technologies and provides an up-to-date view of the platform’s goal and actual states, including hosts, containers, and even the technology-specific internal state. Our Grail setup also allows performing queries with a global scope, fetching data provided in all the data centers and regions around the globe where Uber operates. In essence, think of Grail as the resource model in the Kubernetes APIServer on steroids.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e0b4f9d7-27e9-4f5a-b0be-32ff310cbbe9&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The platform’s control plane focuses solely on high-level decisions, such as scheduling workloads and managing cluster topology.&amp;nbsp; The API for manipulating the goal state is the execution of a workflow. Both remediation loops and human operators start workflows. The platform provides a UI that allows operators to quickly overview the state of their databases and apply operations when needed.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;141a1dce-0b34-4801-b240-c434901bc5ec&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Workflows are incredibly valuable because of the insights they provide. A workflow for updating goal state usually consists of two steps. First, the goal state is updated, and then the workflow will monitor the actual state until it converges on the specified goal state. So when it doesn’t, it is clear which operations didn’t converge, including the context of why that operation was performed in the first place. As the actual state is not expected to converge immediately, the system must prevent the remediation loops from continuously starting workflows that attempt to fix the same issues.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;cf949352-02eb-4d3b-a249-178fe472a2a3&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;271afd88-96a7-4bd9-849c-7e5886fc5d50&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXfkpBCcYU1h2PhNjamcT3aGcIQWIAr7wn-77iP7vY861TcFRrSJ9b4oayn5Brm7MgSzS3nqJqB0J9Qys0t6CnYtHWgIYckWP64HUxy-8LKxmnHBgC-DJU2zkpCZpmTZiLEJ4GP08aLD5yqOgOuk6S4KDsc4?key=0kVK3UHY5mqh0YpEHEfxHw&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 2: A 10.000ft view of Odin’s architecture.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;56db4950-7d76-45b8-819e-0dd0fa247fdd&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2acecab1-597e-464e-a287-66bd80786482&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-managing-generic-storage-clusters&#34;&gt;Managing Generic Storage Clusters&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d0ffd8b7-98aa-4deb-94ae-15aee37e8492&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Odin is built on a technology-agnostic cluster model that provides generic operations for managing clusters of workloads of any kind. This model supports generic operations such as adding or removing workloads, upgrading container images, and handling other cluster-related tasks uniformly across technologies. As the model and operations are technology-agnostic, the technology is required to extend the platform through a collection of plugins to tailor various aspects of cluster management according to their specific needs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;cda4e095-7482-482f-b6b2-a05a92a267d6&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-two-host-agents&#34;&gt;Two Host Agents&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;dd82e5e7-cf72-4e2e-ab87-2d536dd42dbe&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The Odin control plane is divided into two parts. So far, we have only discussed the global part. At the host level, there are two agents. One is shared among all workloads on the host and is technology-agnostic. We simply refer to this as the &lt;em&gt;odin-agent&lt;/em&gt;. The other agent is technology-specific and runs containerized as part of the workload. These two agents, when combined, serve the same functionality as the &lt;em&gt;kubelet&lt;/em&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;65a90e51-2220-4720-94ac-84668c27dbbd&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;a12eed6c-d521-456b-8c52-de1b38e4bec2&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXdSePHcS8Ijkt17F1dBAJtAyQ4DANP0C3CoVQdZFqpTDNdMg6oUZLrPRUgoTrTUC_3ukppykFnZiFLkJkfTrH_iV_OW5XdhajSi6fKC9z7fSq9Yw6x8l0XgDvomdfCgZqe5Z5ZZYeHvmvAwoeaMPNZEyoHs?key=0kVK3UHY5mqh0YpEHEfxHw&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 3: The anatomy of an Odin host with the two host-level agents communicating with the global control plane.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e0817d94-ec97-4063-9a8c-4e9904175475&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1621dd43-a4be-45da-b5d6-0d17c0c5bb08&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The host agent communicates the latest goal and actual states with the global control plane. Its primary responsibility is managing host-level resource allocation, such as scheduling cores for workloads, creating and managing disk volumes/cgroups, and bootstrapping the workloads when assigned to the host.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8fa5a88e-540a-4c48-b1cc-ed7df86a3a00&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The technology-specific agent is known as the &lt;em&gt;worker&lt;/em&gt;. The worker is a supervisor running alongside each workload in a side container. Its primary role is to ensure that the running containers align with the goal state and to collect health and other relevant data for reporting to the global part of the control plane. The worker’s generic functionality includes starting and stopping containers. You can think of the worker as the translator between the generic cluster state the platform understands and the running database containers in the workload.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9965fa47-2eb1-4626-b1d3-dc518449f76a&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The technology team can customize the worker to collect the technology-specific actual state and apply the goal state to the workload. For instance, the MySQL worker is tasked with ensuring that MySQL masters and replicas maintain their roles and report the current state for consumption to the global control plane. This allows the team to write new workflows for operating the cluster based on the actual state of the cluster. Many technologies have extended their workers to perform self-healing cluster operations in their workers. Examples could be coordinating leader elections or data replication when the cluster topology changes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;5598ca20-758c-4080-b97b-81afc4cffece&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-optimizing-for-robustness-and-resilience&#34;&gt;Optimizing for Robustness and Resilience&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;26972dfb-89dd-40ce-906d-ca16199626d9&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Separating the control plane into a host-local and a global component allows us to deploy worker changes per workload, limiting the potential blast radius of bad changes to the smallest possible unit. The same applies to each container in a workload, as the platform allows in-place upgrading containers individually.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;138c489d-3c9f-4892-84e1-6387f9265a64&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;For both agents, a rule is that the goal state must first be written to disk before any changes to the running workloads are made. This approach guarantees self-sufficient clusters that can be initialized without an active control plane, effectively addressing the bootstrap issue. Furthermore, it offers robust failure resilience, allowing workloads to function during control plane degradations and simplifying writing emergency tooling.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;f07917a0-558e-42cb-b46f-c7a20196c247&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-transitioning-identities&#34;&gt;Transitioning Identities&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1eef1f47-896d-478c-9dfe-b43cd5b83885&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;As we continuously optimize for efficiency and modernize our host fleet, moving a workload from one host to another has become one of the most common operations on the platform. To date, we reschedule up to 60% of our stateful workloads per month. A crucial requirement of stateful workloads is maintaining the workload identity across rescheduling. This capability allows, for example, the replacement of one workload serving a shard with another serving the same shard. In Kubernetes, this is managed through StatefulSets by assigning a stable pod identity that persists across rescheduling. When a pod is deleted, a new one is provisioned with the same identity. Let us explore why this model does not suit Uber’s use case well.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1bbb811d-86a9-4cd2-b96b-21285d91dabe&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;As mentioned, Uber uses locally attached drives for all stateful workloads for performance. This setup requires that data on a host be replicated and made available elsewhere before the corresponding workload can be terminated. The cluster becomes temporarily under-provisioned if a workload is shut down before its replacement is fully ready. This delay, which is not negligible with a median time of 1 hour, exposes the cluster to an increased risk of data loss or availability issues. Moreover, this delay also diminishes the cluster’s overall capacity to handle requests.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;3b6e5f94-d8c1-4822-aff4-a93c79b744c9&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-replacing-workloads&#34;&gt;“Replacing” Workloads&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;aa7ad1d4-ea62-4c1c-910d-8286f06a3711&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Consequently, the most essential operation on Odin is migrating a workload from one host to another–or, in Odin terms, “replacing” the workload. A replace operation is purposely designed to &lt;em&gt;make-before-break&lt;/em&gt;. This means it creates a new workload that can carry the identity and data of the workload it replaces &lt;em&gt;before&lt;/em&gt; the old workload is shut down, wherever possible. The technology integrations can choose which parts of the goal state to propagate between workloads. The goal state model makes the two workloads explicitly aware of each other’s existence. This is essential because it allows the respective workers to coordinate the process for data replication and other things. In rare cases, when &lt;em&gt;make-before-break&lt;/em&gt; semantics are impossible (e.g., the old workload is on a failed host), the old workload is deleted simultaneously with the replacement workload being created.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f2c8a1a1-fe85-4656-bbd8-381c24da7641&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Using make-before-break also has an efficiency benefit, as the alternative would require us to run the clusters overprovisioned continuously. In our model, we only temporarily overprovision when we have to.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;de1ed6fc-1a1e-4666-b2e9-c58224a32d9e&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c29e483c-a48a-4924-a033-ef8503c36fe1&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-growing-pains&#34;&gt;Growing Pains&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;dad7f7a3-0ea3-479b-a1fe-9bfa5af38d18&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The first iteration of the Odin platform was a giant leap forward concerning the teams’ ability to operate their storage clusters. Storage teams could converge all their operations and insights on a single platform with a shared operational model. However, the platform was still very much human-centered. Humans were the principal actors initiating changes on the platform, and, crucially, they were the ones vouching for the safety and the fit of the operations performed. The role of the remediation loops was confined to operations with a relatively small scope, such as a single replace workflow&lt;em&gt;.&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;fad8c154-683f-4e0d-ba9b-d1d4b7157cb8&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Operational overhead started to grow as the business continued to scale to the point where fleet-wide operations spanning technologies were not practically possible for human operators to do. Examples of complex, fleet-wide, cross-technology operations that require us to move workloads are:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0c6b29b5-a3b0-4770-b81e-5374de15e4b5&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Optimizing workload placement for resiliency against infrastructural failures like rack or zone failures&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Host bin-packing to improve cost-efficiency&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Fleet-wide host upgrades like new kernels, firmware, or functionality like LVM/cgroupv2&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Facilitating the bringing up of new data centers or decommissioning existing data centers&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;668aa557-dc41-41b6-a40a-29371389096e&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Furthermore, the large number of databases on a single host makes handling host failures daunting. These limitations indicated that we had to double down on automation by developing new remediation loops with much broader scopes than we used to.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;56f8fe34-2ef2-4a3f-bb0d-4f69c90b960c&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-coordination-required&#34;&gt;Coordination Required&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8036e749-8a7a-4c7f-b617-1321eac2cf8f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The increased operational load could quickly result in outages if not carefully coordinated. Imagine a situation where a workload in a 3-node consensus-based storage cluster is taken down to perform a container upgrade. Now imagine another remediation loop that has identified that one of the other workloads in the cluster would benefit from being moved for efficiency reasons. If allowed, this would result in the storage cluster losing quorum, impacting the write availability.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;44963a9c-9e27-4921-91da-42d031dd81be&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Initially, we started augmenting the remediation loops to perform concurrency control internally (Figure 3). This way, they could prevent operations of the same type from creating problems for the storage clusters. For instance, the container upgrade loop would block overlapping upgrades. However, this approach fell short as it didn’t solve the issue of conflicting operations started by different remediation loops. Figure 3 shows a case where two independent operations can operate two workloads in the same storage cluster, resulting in an availability loss.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;37267e15-3898-4883-b5d5-6617d00f67ce&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;d131b897-0c2b-4684-8052-d5db42a85208&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXd4i6HPr3ZkL1WFmR1Kd-mkiLceVO0Liik1jb6NR51eaucwSAjFss_8QW_m-doDIHsbCW9kv5TJwgPukhH3rPiaE1o0lWbpvtlwSliGofFpGiD68jS5NGuxR1V3HZs6HxnZYsScd9vpweh0ouKSHRF0RlbN?key=0kVK3UHY5mqh0YpEHEfxHw&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 4: Internal concurrency control does not protect storage clusters against overlapping operations and can compromise availability.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4ab49524-3b00-4ca5-b966-d2a03569fdc2&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5304b888-d27b-4d5c-8703-a262a8183b7f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Different technologies exhibit widely varying tolerances for safe cluster operations. For some technologies, the specific workloads being operated are crucial, while all workloads are treated equally for others. Some technologies focus solely on ensuring that a certain number of workloads are always available within the cluster. This diversity in requirements made it such that we had to support customizing cluster management strategies to the specific needs of each technology.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d2d9eb70-3d33-4f06-a09d-71c7ba530c6c&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We needed to ensure global, cross-type coordination of operations using a system that could guarantee to preserve the cluster availability by leveraging technology-specific limits based on the current workload health and disruption budget. Furthermore, it should protect against engineering mistakes and overload of the internal platform systems by enforcing platform-wide global concurrency and rate limits.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;573fa4c8-a71a-4934-bdd2-6e76c64ce602&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;4b05fc1f-55a2-498f-8240-0bbc9d986ea0&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-summary&#34;&gt;Summary&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;cd8543d3-0d20-4857-97d7-92d0f10392a5&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In this introductory post of our series, we explored the background and foundational principles of Uber’s stateful platform, Odin. Odin stands out as a generic, technology-agnostic platform capable of managing various technologies with special demands on how databases are operated.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b162d0bd-d1af-4e18-bad6-01cf9829155e&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We discussed how Uber’s databases use locally attached disks for enhanced performance and cost-efficiency and the challenges this presents, as the stored data must follow the workload identity.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a6a3e2b0-f102-45ac-8dab-4f45887f56c1&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We also examined how the platform is inherently intent-based, with disparate remediation loops continuously striving to align the actual state of the managed workloads with their intended goal states. These loops initiate Cadence workflows to update the goal state and wait for convergence—a process that, at scale, requires careful coordination to safely manage without compromising the availability of the managed databases.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;89518bc2-03a8-452f-a779-fab4eb21f534&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In the next blog post, we will discuss how we centralized the coordination of all operations and leveraged it to significantly improve Uber’s ability to operate the fleet at scale.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;74b918d1-e0a6-4dd8-adb0-261d96dcccdb&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-acknowledgments&#34;&gt;Acknowledgments&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;114640af-7176-4346-87ab-dd430c350a03&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The Odin platform was only possible with the effort of many contributors through the years. The authors would like to thank all the teams working on the platform or contributing integrations and to previous team members who helped make the platform great.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;fontSize&amp;quot;:&amp;quot;small&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;5ad1e8e8-0a5d-4299-8c12-36015f6ef911&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34; class=&#34;has-small-font-size&#34;&gt;The cover photo was generated using OpenAI’s ChatCPT Enterprise and edited using Pixlr.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;fontSize&amp;quot;:&amp;quot;small&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;44181acd-1a06-48b7-97b3-2538dfbffe59&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34; class=&#34;has-small-font-size&#34;&gt;Kubernetes® is a registered trademark of the Linux Foundation in the United States and other countries.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;fontSize&amp;quot;:&amp;quot;small&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;a3a471c0-0118-4ea6-840b-90e764c1ea0e&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34; class=&#34;has-small-font-size&#34;&gt;MySQL® is a registered trademark of Oracle Corporation and/or its affiliates.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;fontSize&amp;quot;:&amp;quot;small&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;3827feed-6951-4e20-bd15-7fb796002361&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34; class=&#34;has-small-font-size&#34;&gt;Apache Cassandra®, Apache HDFS™, Apache Kafka®, Apache Yarn™, and Apache Presto™ are registered trademarks or trademarks of the Apache Software Foundation in the United States and/or other countries. The use of these marks does not imply endorsement by the Apache Software Foundation.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;fontSize&amp;quot;:&amp;quot;small&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;06d69f2b-38ee-4898-946e-02588d178a99&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34; class=&#34;has-small-font-size&#34;&gt;Buildkite™ is a trademark of Buildkite Pty Ltd.&lt;/p&gt;</description>
      <pubDate>Thu, 18 Jul 2024 06:12:33 +0000</pubDate>
    </item>
    <item>
      <title>【Navigating the LLM Landscape: Uber’s Innovation with GenAI Gateway】驾驭 LLM 格局：Uber 通过 GenAI Gateway 进行创新</title>
      <link>https://www.uber.com/blog/genai-gateway/</link>
      <description>【&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;639e6d58-1937-4773-a697-02436d75c659&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-introduction&#34;&gt;&lt;strong&gt;Introduction&lt;/strong&gt;&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a4ced9b4-63a9-4d41-995b-c471a659eed4&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Large Language Models (LLMs) have emerged as pivotal instruments in the tech industry, unlocking new avenues for innovation and progress across various sectors. At Uber, the impact of LLMs is particularly noticeable, with over 60 distinct use cases being identified in diverse domains, ranging from process automation to customer support and content generation. As teams at Uber embark on the journey of integrating LLMs into their products, several challenges have surfaced. Notably, the disparate integration strategies adopted by different teams have led to inefficiencies and redundant efforts.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;83d057b4-73ce-417e-bd02-f91cc428a2a9&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;To address these challenges and harness the growing demand for LLMs, Uber’s Michelangelo team has innovated a solution: the GenAI Gateway. The GenAI Gateway serves as a unified platform for all LLM use cases within Uber, offering seamless access to models from various vendors like OpenAI and Vertex AI, as well as Uber-hosted models, through a consistent and efficient interface. The GenAI Gateway is designed to simplify the integration process for teams looking to leverage LLMs in their projects. Its easy onboarding process reduces the effort required by teams, providing a clear and straightforward path to harness the power of LLMs. In addition, a standardized review process, managed by the Engineering Security team, reviews use cases against Uber’s data handling standard before use cases are granted access to the gateway.&amp;nbsp; If testing is successful these projects go through our standard, cross-functional software development process. The centralized nature of the gateway also streamlines the management of usage and budgeting across various teams, promoting greater control and operational efficiency in the integration of LLMs across the company.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8f5812a9-767d-43f3-915e-0de639f58afc&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;271006ea-850d-4aaa-9b12-649b7fd88696&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-design-amp-architecture&#34;&gt;&lt;strong&gt;Design &amp;amp; Architecture&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e3d75695-952c-4dcf-aa1b-c4a1f2346c22&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;A pivotal design decision was to mirror the HTTP/JSON interface of the OpenAI API. This strategic choice is rooted in OpenAI’s widespread adoption and thriving open-source ecosystem highlighted by libraries like LangChain and LlamaIndex. This alignment fosters seamless interoperability, ensuring GenAI Gateway’s compatibility with existing open-source tools and libraries while minimizing the need for adjustments. Given the rapid evolution of the open-source community, a proprietary interface would risk becoming quickly outdated. By aligning with OpenAI’s interface, GenAI Gateway stays in step with cutting-edge advancements. This approach not only streamlines the onboarding process for developers but also extends GenAI Gateway’s reach, allowing users to access LLMs from various vendors, like Vertex AI, through a familiar OpenAI API framework. See Figure 1 below for the high-level architecture diagram.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6d3618fd-55dd-44d8-b957-838a8b5dec19&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The following code snippets demonstrate how to use GenAI Gateway to access LLMs from different vendors with unified interface:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6963d647-7655-44b0-9310-a7d510ddb789&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;681fd513-bcc0-4e80-8715-d6e834a589a2&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXeSeRL_lT222k2UnrRa4Ywx8XbtT5alPHmZjCu_7-_RJvRPf-p7TZlT8Lsbm-ysathYSSxqVVCXBE_ALt1IfTeY_Z6CAuCcPuVas1vxly9HbguZ0si1KR0eZ_-9OOlfy3kAmmTSXUrU8SkD5Ct34F2hJB0?key=5egmPsUgOM1kuqOeYjTalA&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2d022d50-550a-4c3c-96f3-5e2b4a27e6d5&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote data-wp-block-name=&#34;core/quote&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;da9b9046-5685-4270-95e5-f47d4210332a&amp;quot;,&amp;quot;value&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;wp-block-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Answer from gpt-4:&amp;nbsp;&lt;/strong&gt;The capital of the USA is Washington D.C.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Answer from chat-bison:&amp;nbsp;&lt;/strong&gt;&amp;nbsp;Washington, D.C. is the capital of the USA.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Answer from llama-2-70b-chat-hf-0:&amp;nbsp;&lt;/strong&gt;The capital of the United States of America is Washington, D.C.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d3cfdec3-78b6-45e0-a99f-228020ce7900&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;As can be seen from above, developers write code as if they’re using native OpenAI client, while being able to access LLMs from different vendors.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;fac9714d-4d09-45e5-a474-501a4df1f5f0&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Architecture-wise, GenAI Gateway is a Go service that acts as an encompassing layer around the clients for third-party vendors, complemented by the in-house serving stacks tailored for Uber’s LLMs.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;35331a76-20eb-4ee4-96cb-06d88b4940d5&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Our approach to integrating with OpenAI involved developing an internal fork of the Go client implementation sourced from &lt;a href=&#34;https://github.com/sashabaranov/go-openai&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;the GitHub repository&lt;/a&gt;. When it came to integrating Vertex AI, specifically for accessing PaLM2, we faced a challenge: the absence of a suitable Go implementation at that time. We took the lead in developing our version and subsequently &lt;a href=&#34;https://github.com/uber/go-vertex-ai&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;open-sourced&lt;/a&gt; it, contributing to the broader community. We encourage community engagement, inviting contributions ranging from bug reports to feature requests. This library mainly focused on features like text generation, chat generation, and embeddings. At the time of writing this blog, Google has also published their &lt;a href=&#34;https://pkg.go.dev/cloud.google.com/go/aiplatform@v1.58.0/apiv1#PredictionClient&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Vertex AI Prediction Client&lt;/a&gt; but we will continue to support our library because of its ease of use.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;08e977a6-95bc-4fea-9bec-77963803511a&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;For Uber-hostedLLMs, we’ve engineered a robust serving stack built upon the STOA inference libraries, to optimize performance and efficiency. This blend of external integration and internal innovation reflects our commitment to staying at the forefront of LLM technology and contributing to its evolving ecosystem.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;dd0f0e30-74ee-4cb0-88cf-849b7182a21c&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;de64298b-1d41-4f31-94dd-8efe0c3fd1f4&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXdm1yQEGqJOKLbzBDtbpKf9DxKGFweuXueR8Din4Z1dKCy1nB2RZgD1OnrxROhyEQlogzt4fLUijzaLvIqkpRwZsNxK9h-tDI9LhoAeKrZDG2fo5j8ThIVw-DQ-XJ234XQIMpDH9k2G0REM6Mdqjsb-dsE?key=5egmPsUgOM1kuqOeYjTalA&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2e53726b-6bc9-4d35-86ab-73767c4c9764&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;25fc1db6-aa70-49af-8770-af946ab52ae8&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Beyond its serving component, an integral facet of GenAI Gateway is the incorporation of a Personal Identifiable Information (PII) redactor. Numerous studies have underscored the susceptibility of LLMs to potential data breaches, presenting significant security concerns for Uber. In response, GenAI Gateway incorporates a PII redactor that anonymizes sensitive information within requests before forwarding them to third-party vendors. Upon receiving responses from these external LLMs, the redacted entities are restored through an un-redaction process. The goal of this redaction/un-redaction process is to minimize the risk of exposing sensitive data.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c6a305fc-df19-4b59-855f-81e55b619b53&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Complementing its core functionalities, GenAI Gateway incorporates additional components designed for authentication and authorization, metrics emission to facilitate reporting and alerting, and the generation of audit logs for comprehensive cost attribution, security audit purposes, quality evaluation, and so on. All these components are seamlessly integrated into Uber’s in-house ecosystem, ensuring a cohesive and synergistic integration that aligns with the organization’s broader technological framework. This strategic alignment underscores GenAI Gateway’s commitment to not only meeting immediate needs, but also seamlessly integrating with Uber’s established infrastructure for enhanced efficiency and compatibility.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e465a37b-3942-438f-b401-047964f7ea17&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Today, GenAI Gateway is used by close to 30 customer teams and serves 16 million queries per month, with a peak QPS of 25.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;c39f3924-1f0f-4622-8415-aff024774735&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-comparison-to-similar-offering&#34;&gt;&lt;strong&gt;Comparison to similar offering&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;dd5d024c-69af-4884-8d0f-693d06a660f3&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Although Databricks recently introduced the &lt;a href=&#34;https://www.databricks.com/blog/announcing-mlflow-ai-gateway&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;MLflow AI Gateway&lt;/a&gt; that shares several features with our GenAI Gateway, GenAI Gateway stands apart in key ways from the MLflow AI Gateway. Our GenAI Gateway closely mirrors OpenAI’s interface, offering benefits not found in the MLflow AI Gateway, which has adopted a unique syntax for LLM access (create_route and query). In addition to aligning with OpenAI’s interface, GenAI Gateway enables a consistent approach to data security and privacy across all use cases. Furthermore, our platform extends beyond Python, providing support for Java and Go, which are the primary programming languages used in Uber’s backend infrastructure. This multi-language support, combined with our focus on security and alignment with OpenAI’s familiar interface, underscores GenAI Gateway’s unique position in the realm of LLM platforms.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7522f8ea-645f-421f-8016-c4ed75c83a03&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;802ff089-59a7-495a-9ff4-6f8b132bc26c&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-challenges&#34;&gt;&lt;strong&gt;Challenges&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7620ca6d-1028-4428-990e-21fa9481b986&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The aim is for this platform to emulate the performance and quality of the native OpenAI API so closely that the transition is imperceptible. In this section of our blog, we will delve into the challenges encountered in achieving this seamless integration, particularly through the lens of handling PII.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;c6009cac-ddc0-4bce-9bd5-312707413fe7&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-pii-redactor&#34;&gt;&lt;strong&gt;PII Redactor&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f3b7ab62-f0d5-4785-9b6b-e777a175b9ea&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The PII redactor, while essential for privacy and security, introduces challenges to both latency and result quality. To understand how PII redactor introduces these challenges, we first need to understand how PII redaction works.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5f946373-3a8b-4878-8264-377734a7ac83&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The PII redactor scans input data, identifying and replacing all instances of PII with anonymized placeholders. Its sophisticated algorithm adeptly recognizes a wide range of PII categories. Each type of PII is substituted with a unique placeholder–for example, names are converted to ANONYMIZED_NAME_, while phone numbers are changed to ANONYMIZED_PHONE_NUMBER_. To maintain distinctiveness, these placeholders are assigned sequential numbers, creating unique identifiers for each occurrence: the first name in a dataset is labeled as ANONYMIZED_NAME_0, followed by ANONYMIZED_NAME_1 for the second, and so forth. The following example illustrates this process in action:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;494420ae-568d-437b-b3c1-d52afd067ab9&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;div data-wp-block-name=&#34;core/columns&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1cac3655-b6a7-4699-9a1a-0258a84f8f74&amp;quot;,&amp;quot;isStackedOnMobile&amp;quot;:true}&#34; class=&#34;wp-block-columns is-layout-flex wp-container-core-columns-is-layout-1 wp-block-columns-is-layout-flex&#34;&gt;&#xA;&lt;div data-wp-block-name=&#34;core/column&#34; data-wp-block=&#34;[]&#34; class=&#34;wp-block-column is-layout-flow wp-block-column-is-layout-flow&#34;&gt;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Original Text&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;George Washington is the first president of the United States. Abraham Lincoln is known for his leadership during the Civil War and the Emancipation Proclamation.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div data-wp-block-name=&#34;core/column&#34; data-wp-block=&#34;[]&#34; class=&#34;wp-block-column is-layout-flow wp-block-column-is-layout-flow&#34;&gt;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Anonymized Text&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;mark class=&#34;has-inline-color has-276-ef-1-color&#34;&gt;ANONYMIZED_NAME_0&lt;/mark&gt; is the first president of the United States. &lt;mark class=&#34;has-inline-color has-276-ef-1-color&#34;&gt;ANONYMIZED_NAME_1&lt;/mark&gt; is known for his leadership during the Civil War and the Emancipation Proclamation.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a390ee88-0d87-45ea-9e39-ef9714ef0190&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1bd16342-68ba-447b-b1e9-58dc0f417e92&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The mapping of PII data to anonymized placeholders is used in the un-redaction process that restores PII data from anonymized placeholders back to its original form, before returning the result to users.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4b0a9f7f-be47-4c51-8207-4f666854ec06&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Depending on the location the PII data is in the input, the same word can be redacted to different anonymized placeholders as it will be appended with different sequential numbers:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6da4648d-9005-47d8-9c1b-457872f11f9f&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;div data-wp-block-name=&#34;core/columns&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2a7aa4dd-5804-45ff-b42d-dce68e393123&amp;quot;,&amp;quot;isStackedOnMobile&amp;quot;:true}&#34; class=&#34;wp-block-columns is-layout-flex wp-container-core-columns-is-layout-2 wp-block-columns-is-layout-flex&#34;&gt;&#xA;&lt;div data-wp-block-name=&#34;core/column&#34; data-wp-block=&#34;[]&#34; class=&#34;wp-block-column is-layout-flow wp-block-column-is-layout-flow&#34;&gt;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Original Text&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Abraham Lincoln is known for his leadership during the Civil War and the Emancipation Proclamation. George Washington is the first president of the United States.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div data-wp-block-name=&#34;core/column&#34; data-wp-block=&#34;[]&#34; class=&#34;wp-block-column is-layout-flow wp-block-column-is-layout-flow&#34;&gt;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Anonymized Text&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;mark class=&#34;has-inline-color has-276-ef-1-color&#34;&gt;ANONYMIZED_NAME_0&lt;/mark&gt; is known for his leadership during the Civil War and the Emancipation Proclamation. &lt;mark class=&#34;has-inline-color has-276-ef-1-color&#34;&gt;ANONYMIZED_NAME_1&lt;/mark&gt; is the first president of the United States.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b782d3a7-95b8-4f93-bfdc-f6fac2dea047&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:4,&amp;quot;hash&amp;quot;:&amp;quot;c80b26e7-853a-4bfd-a948-197d4519ed46&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-latency&#34;&gt;&lt;strong&gt;Latency&lt;/strong&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1470fed1-1c5b-404c-bb90-d42067674e3b&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;While most additional components in GenAI Gateway are lightweight, the PII redactor, by nature of scanning and anonymizing entire requests, incurs added latency proportional to the length of the input request. In cases where the input request is notably large, such as a few thousand tokens, the PII redactor alone can introduce a latency of several seconds. To address this, we’ve transitioned to a CPU-optimized model, resulting in a substantial 80%+ reduction in latency, without compromising accuracy. Furthermore, we are in the process of assessing more advanced models, including one that leverages GPU technology, to further enhance the processing speed and overall efficiency of the PII redactor.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:4,&amp;quot;hash&amp;quot;:&amp;quot;087365ba-af49-4fff-916f-f0fbfa2998ee&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-quality&#34;&gt;&lt;strong&gt;Quality&lt;/strong&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0e2e3c69-1d74-47d1-8e92-34988bac8b83&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The PII redactor can inadvertently impact the quality of results. Its process of anonymizing sensitive data, while safeguarding user information, sometimes strips away crucial context, thereby affecting the response quality of LLMs. For example, a query like “Who is George Washington?” is transformed into “Who is ANONYMIZED_NAME_0” for LLM processing. This anonymization can hinder LLMs’ ability to generate relevant responses due to the loss of specific contextual information.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9fdb0ac0-6a2a-44cb-a471-14462165dd91&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Furthermore, the PII redactor’s mechanism presents unique challenges in scenarios like LLM caching and Retrieval Augmented Generation (RAG). LLM caching, which stores responses for frequently asked questions to facilitate quick retrieval, faces a dilemma. Anonymized queries, such as “Who is George Washington?” and “Who is Abraham Lincoln?”, become indistinguishable post-redaction, leading to potential inaccuracies in cached responses. Similarly, RAG, which relies on fetching pertinent documents to aid LLMs in response generation, struggles with the inconsistencies introduced by anonymization. For instance, embedding a historical article about the American Revolutionary War might involve different anonymized placeholders for the same entity in offline and online contexts, leading to the retrieval of incorrect documents.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2f0c4eea-0d91-4bbb-80ba-cbf460e06a0b&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;These challenges highlight a fundamental issue: the difficulty in linking anonymized placeholders back to their original entities, causing errors in cached results or document retrieval. While maintaining a global table mapping original entities to anonymized placeholders is impractical, we are exploring solutions:&amp;nbsp; One approach encourages customers to use Uber-hostedLLMs, which do not require PII redaction. Simultaneously, we are evaluating the security assurances of third-party vendors to consider the possibility of forgoing the PII redactor entirely, striving to balance privacy concerns with operational effectiveness.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;e1b6de5b-fe78-4d7c-bde0-04951bf725f2&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-other-challenges&#34;&gt;&lt;strong&gt;Other Challenges&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d0f6465d-4a72-4f92-988d-4f7b68bee7ac&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Beyond the previously mentioned difficulties with PII redaction, the GenAI Gateway encounters additional, diverse challenges. The ever-evolving landscape of Large Language Models (LLMs) in recent months has prompted us to dynamically adjust our priorities. For instance, the recent introduction of GPT-4V shook things up by altering the request interface to accommodate image URLs and base64-encoded images. Fortunately, the responsive open-source community swiftly proposed solutions to seamlessly adapt to this change.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;87fc3c4d-83a0-4ebf-9418-3b40fbf0a158&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Given that GenAI Gateway’s core functionality revolves around forwarding requests to relevant LLM vendors, its availability is closely tied to the operational status of these vendors. In the event of a vendor outage, effective communication with users is crucial to prevent any misattribution of issues to the gateway itself. To bolster resilience, we are actively exploring the possibility of incorporating Uber-hostedLLMs as a fallback option when a third-party vendor encounters downtime.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e65b175f-48ce-4c6d-a292-db0227c90f3a&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4c72bb58-460c-4754-be32-ed051f246615&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-use-case-summarisation-of-chats-for-agents-resolution&#34;&gt;&lt;strong&gt;Use Case: Summarisation of Chats for Agents Resolution&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b1ed6027-0b3d-4a7e-a8ab-4e59ae013f4b&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In our continuous pursuit of enhancing customer support efficiency, Uber leverages large language models (LLMs) to streamline the process for our customer support agents. The primary focus is on swiftly summarizing user issues and suggesting potential resolution actions, significantly reducing the time it takes to address user queries. This not only expedites query resolutions but also contributes to an overall improved user experience. We leverage LLMs internally for following&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;ordered&amp;quot;:true,&amp;quot;hash&amp;quot;:&amp;quot;0aee051c-93e7-4bbf-a71b-afb5c6d71f45&amp;quot;,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Enhance chatbot-to-agent transitions, providing agents with concise summaries of prior interactions for improved understanding, faster resolution and addressing key challenges&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Furnish agents with crucial background information and user sentiments, enabling empathetic and contextually accurate support.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Implement automatic summarization of contact interactions, reducing manual summarization time by 80% and improving operational efficiency.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;d7dfbca3-3c84-4ee3-92e3-780a9377fe18&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-impact&#34;&gt;&lt;strong&gt;Impact&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c2da11cc-0927-4036-9dd7-500c408aa19a&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The implementation of LLMs has proven highly beneficial, with 97% of generated summaries found to be useful in resolving customer issues. Agents report significant time savings in reading and documentation, thereby enhancing their overall productivity. The agents are able to revert back to users 6 seconds faster than before. We are generating ~20 million summaries per week leveraging the LLMs, which we plan to expand to more regions and contact types in the future.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d87d11d4-8c61-4223-975e-5b8ee9b78de2&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In essence, our utilization of LLMs at Uber transcends mere automation–it’s a strategic enhancement focused on empowering our customer support agents to provide faster, more accurate, and empathetic resolutions.&amp;nbsp; All with the goal of delivering an unparalleled experience to our users.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;6f3fff59-4eda-4a9e-ba4e-e4d86dd0f080&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-how-gen-ai-gateway-is-used&#34;&gt;&lt;strong&gt;How Gen AI Gateway is used&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3c251dc5-8f76-4f63-8cf6-46b83d4617df&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Within Uber’s Customer Obsession organization, the CO Inference Gateway was initially employed to expose various ML Task-based API contracts internally to other services, abstracting out different ML Model hosts. For Summarization, we expanded this service to include a new Generation ML Task for Text, Chat, and Embedding Generation. This extension enables connections to both Open AI and Google Vertex AI models, fostering flexibility and adaptability.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6e9637f3-267e-49bc-8cbf-b2dbf1ce70e8&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;3a0a4eff-508a-450e-b7b6-d30abd888d73&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXe5_r9WXoElXeydaicgO-hAtPt5YOQr4MqZ3CKPRaVxgFWIkw1EnRrd9QKeEsmG-9SsHwbhGG-epfVUKYq6AGCli5guSvFn445zPBDxDkh6PLqYFzzwu4WE7yWr7f_4E7YOqYQ1z7o_WP3iO5Qyza27D7rI?key=5egmPsUgOM1kuqOeYjTalA&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;631b8d21-ba2a-4a6d-acc3-604bff6e1da1&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7e654ae5-5120-4e71-86fd-67fa18b95853&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;a href=&#34;https://drive.google.com/file/d/1mIgcSDvcFjzWO7H774u1ay20mF00sZEG/view?usp=drive_link&#34;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4c59483c-8bd4-4b50-9c4b-5f82c528ad7d&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Encountering challenges such as PII Redaction, Cost attribution, and the imperative for a centralized service at Uber to connect with any external Language Model (LLM), we made a strategic decision to leverage the Gen AI Gateway instead of directly calling external models. This decision was guided by the need for a comprehensive solution that not only addresses challenges effectively but also ensures a robust and secure integration. By doing so, we navigate complexities and optimize the utility of our AI-powered solutions, aligning with Uber’s commitment to innovation and excellence in customer support.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;85d40cc1-5690-4a43-9b85-98191edf7e4f&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;d8ba6985-0b79-4558-a5b8-078e0e381f63&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXcfFXsQPWf1S4ppo-vik3bFc867WLviUl182cHDZ-K7JZNaut0dfHXU5kKhFpVHJX9KERz4NVNwQS9un8lHVCwt74uD4MJ0sINAUrcyQwifX3COr4k3ZiJwdE338BFLKxROhBOSxwNKAqntSNFWi6-zNTxu?key=5egmPsUgOM1kuqOeYjTalA&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ee250d3c-364e-42b1-bde5-b5d81c1e3f20&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;c5f5f108-19fa-4345-b0bd-99044df1648e&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-prompt&#34;&gt;&lt;strong&gt;Prompt&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ec567b34-0b9f-453d-8864-911845c39aa5&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Following is a sample Prompt for the summarisation of contact tickets. We provide a few examples in the prompt context for few-shot learning.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote data-wp-block-name=&#34;core/quote&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;01b04911-552d-4e9d-b786-8ecb2b12562c&amp;quot;,&amp;quot;value&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;wp-block-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The following is a conversation between an Uber Customer support Bot called BOT, possibly a customer support agent called AGENT and an Uber Eats Customer called USER. Provide a detailed breakdown of the conversation. Identify all issues or intents and associated sentiments from the user. Extract the most pertinent part of user utterances and agent responses for each identified problem.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;input:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;{{conversation_log}} // Conversation log is the actual message history between customers, chatbots and agents.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f23b1fbe-c359-4c05-95ae-1a952fe7008f&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;316cdf49-3163-4cda-b13f-79fc13d055b3&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-learnings&#34;&gt;&lt;strong&gt;Learnings&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;885e8612-3fc7-4e44-b412-044519b57ea9&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In reflecting on our journey with LLMs, a fundamental lesson stands out: the critical need for adaptability in the face of the rapidly evolving LLM landscape. As we delve deeper into the realm of advanced LLM applications, the importance of skillfully managing the interplay between ever-changing technologies, user privacy, and efficiency becomes increasingly evident. This landscape is constantly shifting, and our dedication to continuous improvement is more crucial than ever. Navigating these dynamics with agility and foresight is pivotal to our mission, ensuring that we not only keep pace with technological advancements but also uphold our commitment to user privacy and system efficiency.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;daca159f-1260-4b21-b095-be3639656066&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;314ead02-2022-4b7f-9bb3-a3dc6eb8e93c&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-future-works&#34;&gt;&lt;strong&gt;Future Works&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1ac48011-3d5a-40e7-8c50-8c1736fb0fbe&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Looking ahead, our vision for the GenAI Gateway is to elevate and refine its capabilities to better serve our users. A key focus is on enhancing the onboarding process for new models. Whether these are bespoke, fine-tuned models tailored to specific needs or those sourced from the vibrant open-source community, our goal is to make their integration as fluid and user-friendly as possible. Moreover, we are keen on augmenting the gateway with advanced features that address the dynamic challenges of working with Large Language Models. This includes implementing intelligent LLM caching mechanisms, developing robust fallback logic, and introducing sophisticated hallucination detection. Safety and policy guardrails are also on our agenda to ensure that our platform remains secure and compliant with evolving standards.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c896442c-5abb-420b-85b5-898882f48a1e&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In our journey to expand the gateway’s capabilities, we also recognize the importance of tapping into the vast potential of the open-source ecosystem. To this end, we are actively working towards integrating with libraries. This will not only enhance the functional breadth of our system, but also make it more versatile, enabling our users to explore and leverage a broader range of solutions. These future endeavors underscore our commitment to continually evolve the GenAI Gateway, ensuring it remains a cutting-edge, versatile, and secure platform for harnessing the power of LLMs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;62803538-f24d-48ec-971e-28ba28c745cc&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;c312f523-db66-494c-9407-311cee6c8b60&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-conclusion&#34;&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ad1f31f3-01c4-475c-b839-51e7dd25b3cf&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;LLMs have become a transformative force. The integration of LLMs at Uber, however, has not been without challenges. Inconsistent integration strategies and the absence of a standardized approach have led to inefficiencies and difficulties in monitoring costs and vendor usage.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8def3e9e-3285-449e-9694-e7fcfe114573&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Addressing these issues, Uber’s Michelangelo team developed the GenAI Gateway, a unified platform facilitating access to LLMs from multiple providers, including OpenAI and Vertex AI, as well as Uber’s in-house models. This platform streamlines the integration process, ensuring compliance with privacy and security standards and efficient usage management. GenAI Gateway’s design, mirroring the OpenAI API, ensures compatibility with existing tools and maintains pace with the evolving open-source community. It also features a PII redactor, enhancing security. This strategic development of the GenAI Gateway, coupled with its focus on operational efficiency and alignment with Uber’s broader technological framework, exemplifies Uber’s commitment to innovation while addressing the dynamic challenges of working with LLMs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d24118d6-acbf-4d50-959b-5337150cda8c&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-acknowledgments&#34;&gt;&lt;strong&gt;Acknowledgments&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ae51ea31-0c43-4ce0-9617-47822269b6e2&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We could not have accomplished the technical work outlined in this article without the help of various engineering teams, Uber AI, and the Uber Customer Obsession Team. We would also like to thank the various product teams working with us in adopting Gen AI Gateway.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;fontSize&amp;quot;:&amp;quot;small&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;afc6017c-684e-44ac-abcc-678a2031b044&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34; class=&#34;has-small-font-size&#34;&gt;Cover Photo Attribution: The “&lt;strong&gt;Artificial Intelligence, AI&lt;/strong&gt;” image is covered by a &lt;a href=&#34;https://creativecommons.org/licenses/by/2.0/&#34;&gt;CC BY 2.0&lt;/a&gt; license and is credited to &lt;a href=&#34;https://www.flickr.com/photos/152824664@N07&#34;&gt;mikemacmarketing&lt;/a&gt;. No changes have been made to the image (&lt;a href=&#34;https://openverse.org/image/49410795-b3ba-421b-918b-7f2cd9178f19?q=artificial%20intelligence&#34;&gt;source&lt;/a&gt;).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;fontSize&amp;quot;:&amp;quot;small&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;f526d83b-eb4f-49c3-9e7f-661ae12bcd4b&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34; class=&#34;has-small-font-size&#34;&gt;Vertex AI™, PaLM™, Google Dialogflow™&amp;nbsp; and Go™ are trademarks of Google LLC and this blog post is not endorsed by or affiliated with Google in any way.&lt;/p&gt;】&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;639e6d58-1937-4773-a697-02436d75c659&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-introduction&#34;&gt;&lt;strong&gt;Introduction&lt;/strong&gt;&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a4ced9b4-63a9-4d41-995b-c471a659eed4&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Large Language Models (LLMs) have emerged as pivotal instruments in the tech industry, unlocking new avenues for innovation and progress across various sectors. At Uber, the impact of LLMs is particularly noticeable, with over 60 distinct use cases being identified in diverse domains, ranging from process automation to customer support and content generation. As teams at Uber embark on the journey of integrating LLMs into their products, several challenges have surfaced. Notably, the disparate integration strategies adopted by different teams have led to inefficiencies and redundant efforts.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;83d057b4-73ce-417e-bd02-f91cc428a2a9&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;To address these challenges and harness the growing demand for LLMs, Uber’s Michelangelo team has innovated a solution: the GenAI Gateway. The GenAI Gateway serves as a unified platform for all LLM use cases within Uber, offering seamless access to models from various vendors like OpenAI and Vertex AI, as well as Uber-hosted models, through a consistent and efficient interface. The GenAI Gateway is designed to simplify the integration process for teams looking to leverage LLMs in their projects. Its easy onboarding process reduces the effort required by teams, providing a clear and straightforward path to harness the power of LLMs. In addition, a standardized review process, managed by the Engineering Security team, reviews use cases against Uber’s data handling standard before use cases are granted access to the gateway.&amp;nbsp; If testing is successful these projects go through our standard, cross-functional software development process. The centralized nature of the gateway also streamlines the management of usage and budgeting across various teams, promoting greater control and operational efficiency in the integration of LLMs across the company.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8f5812a9-767d-43f3-915e-0de639f58afc&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;271006ea-850d-4aaa-9b12-649b7fd88696&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-design-amp-architecture&#34;&gt;&lt;strong&gt;Design &amp;amp; Architecture&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e3d75695-952c-4dcf-aa1b-c4a1f2346c22&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;A pivotal design decision was to mirror the HTTP/JSON interface of the OpenAI API. This strategic choice is rooted in OpenAI’s widespread adoption and thriving open-source ecosystem highlighted by libraries like LangChain and LlamaIndex. This alignment fosters seamless interoperability, ensuring GenAI Gateway’s compatibility with existing open-source tools and libraries while minimizing the need for adjustments. Given the rapid evolution of the open-source community, a proprietary interface would risk becoming quickly outdated. By aligning with OpenAI’s interface, GenAI Gateway stays in step with cutting-edge advancements. This approach not only streamlines the onboarding process for developers but also extends GenAI Gateway’s reach, allowing users to access LLMs from various vendors, like Vertex AI, through a familiar OpenAI API framework. See Figure 1 below for the high-level architecture diagram.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6d3618fd-55dd-44d8-b957-838a8b5dec19&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The following code snippets demonstrate how to use GenAI Gateway to access LLMs from different vendors with unified interface:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6963d647-7655-44b0-9310-a7d510ddb789&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;681fd513-bcc0-4e80-8715-d6e834a589a2&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXeSeRL_lT222k2UnrRa4Ywx8XbtT5alPHmZjCu_7-_RJvRPf-p7TZlT8Lsbm-ysathYSSxqVVCXBE_ALt1IfTeY_Z6CAuCcPuVas1vxly9HbguZ0si1KR0eZ_-9OOlfy3kAmmTSXUrU8SkD5Ct34F2hJB0?key=5egmPsUgOM1kuqOeYjTalA&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2d022d50-550a-4c3c-96f3-5e2b4a27e6d5&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote data-wp-block-name=&#34;core/quote&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;da9b9046-5685-4270-95e5-f47d4210332a&amp;quot;,&amp;quot;value&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;wp-block-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Answer from gpt-4:&amp;nbsp;&lt;/strong&gt;The capital of the USA is Washington D.C.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Answer from chat-bison:&amp;nbsp;&lt;/strong&gt;&amp;nbsp;Washington, D.C. is the capital of the USA.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Answer from llama-2-70b-chat-hf-0:&amp;nbsp;&lt;/strong&gt;The capital of the United States of America is Washington, D.C.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d3cfdec3-78b6-45e0-a99f-228020ce7900&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;As can be seen from above, developers write code as if they’re using native OpenAI client, while being able to access LLMs from different vendors.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;fac9714d-4d09-45e5-a474-501a4df1f5f0&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Architecture-wise, GenAI Gateway is a Go service that acts as an encompassing layer around the clients for third-party vendors, complemented by the in-house serving stacks tailored for Uber’s LLMs.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;35331a76-20eb-4ee4-96cb-06d88b4940d5&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Our approach to integrating with OpenAI involved developing an internal fork of the Go client implementation sourced from &lt;a href=&#34;https://github.com/sashabaranov/go-openai&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;the GitHub repository&lt;/a&gt;. When it came to integrating Vertex AI, specifically for accessing PaLM2, we faced a challenge: the absence of a suitable Go implementation at that time. We took the lead in developing our version and subsequently &lt;a href=&#34;https://github.com/uber/go-vertex-ai&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;open-sourced&lt;/a&gt; it, contributing to the broader community. We encourage community engagement, inviting contributions ranging from bug reports to feature requests. This library mainly focused on features like text generation, chat generation, and embeddings. At the time of writing this blog, Google has also published their &lt;a href=&#34;https://pkg.go.dev/cloud.google.com/go/aiplatform@v1.58.0/apiv1#PredictionClient&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Vertex AI Prediction Client&lt;/a&gt; but we will continue to support our library because of its ease of use.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;08e977a6-95bc-4fea-9bec-77963803511a&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;For Uber-hostedLLMs, we’ve engineered a robust serving stack built upon the STOA inference libraries, to optimize performance and efficiency. This blend of external integration and internal innovation reflects our commitment to staying at the forefront of LLM technology and contributing to its evolving ecosystem.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;dd0f0e30-74ee-4cb0-88cf-849b7182a21c&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;de64298b-1d41-4f31-94dd-8efe0c3fd1f4&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXdm1yQEGqJOKLbzBDtbpKf9DxKGFweuXueR8Din4Z1dKCy1nB2RZgD1OnrxROhyEQlogzt4fLUijzaLvIqkpRwZsNxK9h-tDI9LhoAeKrZDG2fo5j8ThIVw-DQ-XJ234XQIMpDH9k2G0REM6Mdqjsb-dsE?key=5egmPsUgOM1kuqOeYjTalA&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2e53726b-6bc9-4d35-86ab-73767c4c9764&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;25fc1db6-aa70-49af-8770-af946ab52ae8&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Beyond its serving component, an integral facet of GenAI Gateway is the incorporation of a Personal Identifiable Information (PII) redactor. Numerous studies have underscored the susceptibility of LLMs to potential data breaches, presenting significant security concerns for Uber. In response, GenAI Gateway incorporates a PII redactor that anonymizes sensitive information within requests before forwarding them to third-party vendors. Upon receiving responses from these external LLMs, the redacted entities are restored through an un-redaction process. The goal of this redaction/un-redaction process is to minimize the risk of exposing sensitive data.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c6a305fc-df19-4b59-855f-81e55b619b53&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Complementing its core functionalities, GenAI Gateway incorporates additional components designed for authentication and authorization, metrics emission to facilitate reporting and alerting, and the generation of audit logs for comprehensive cost attribution, security audit purposes, quality evaluation, and so on. All these components are seamlessly integrated into Uber’s in-house ecosystem, ensuring a cohesive and synergistic integration that aligns with the organization’s broader technological framework. This strategic alignment underscores GenAI Gateway’s commitment to not only meeting immediate needs, but also seamlessly integrating with Uber’s established infrastructure for enhanced efficiency and compatibility.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e465a37b-3942-438f-b401-047964f7ea17&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Today, GenAI Gateway is used by close to 30 customer teams and serves 16 million queries per month, with a peak QPS of 25.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;c39f3924-1f0f-4622-8415-aff024774735&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-comparison-to-similar-offering&#34;&gt;&lt;strong&gt;Comparison to similar offering&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;dd5d024c-69af-4884-8d0f-693d06a660f3&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Although Databricks recently introduced the &lt;a href=&#34;https://www.databricks.com/blog/announcing-mlflow-ai-gateway&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;MLflow AI Gateway&lt;/a&gt; that shares several features with our GenAI Gateway, GenAI Gateway stands apart in key ways from the MLflow AI Gateway. Our GenAI Gateway closely mirrors OpenAI’s interface, offering benefits not found in the MLflow AI Gateway, which has adopted a unique syntax for LLM access (create_route and query). In addition to aligning with OpenAI’s interface, GenAI Gateway enables a consistent approach to data security and privacy across all use cases. Furthermore, our platform extends beyond Python, providing support for Java and Go, which are the primary programming languages used in Uber’s backend infrastructure. This multi-language support, combined with our focus on security and alignment with OpenAI’s familiar interface, underscores GenAI Gateway’s unique position in the realm of LLM platforms.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7522f8ea-645f-421f-8016-c4ed75c83a03&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;802ff089-59a7-495a-9ff4-6f8b132bc26c&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-challenges&#34;&gt;&lt;strong&gt;Challenges&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7620ca6d-1028-4428-990e-21fa9481b986&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The aim is for this platform to emulate the performance and quality of the native OpenAI API so closely that the transition is imperceptible. In this section of our blog, we will delve into the challenges encountered in achieving this seamless integration, particularly through the lens of handling PII.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;c6009cac-ddc0-4bce-9bd5-312707413fe7&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-pii-redactor&#34;&gt;&lt;strong&gt;PII Redactor&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f3b7ab62-f0d5-4785-9b6b-e777a175b9ea&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The PII redactor, while essential for privacy and security, introduces challenges to both latency and result quality. To understand how PII redactor introduces these challenges, we first need to understand how PII redaction works.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5f946373-3a8b-4878-8264-377734a7ac83&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The PII redactor scans input data, identifying and replacing all instances of PII with anonymized placeholders. Its sophisticated algorithm adeptly recognizes a wide range of PII categories. Each type of PII is substituted with a unique placeholder–for example, names are converted to ANONYMIZED_NAME_, while phone numbers are changed to ANONYMIZED_PHONE_NUMBER_. To maintain distinctiveness, these placeholders are assigned sequential numbers, creating unique identifiers for each occurrence: the first name in a dataset is labeled as ANONYMIZED_NAME_0, followed by ANONYMIZED_NAME_1 for the second, and so forth. The following example illustrates this process in action:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;494420ae-568d-437b-b3c1-d52afd067ab9&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;div data-wp-block-name=&#34;core/columns&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1cac3655-b6a7-4699-9a1a-0258a84f8f74&amp;quot;,&amp;quot;isStackedOnMobile&amp;quot;:true}&#34; class=&#34;wp-block-columns is-layout-flex wp-container-core-columns-is-layout-1 wp-block-columns-is-layout-flex&#34;&gt;&#xA;&lt;div data-wp-block-name=&#34;core/column&#34; data-wp-block=&#34;[]&#34; class=&#34;wp-block-column is-layout-flow wp-block-column-is-layout-flow&#34;&gt;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Original Text&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;George Washington is the first president of the United States. Abraham Lincoln is known for his leadership during the Civil War and the Emancipation Proclamation.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div data-wp-block-name=&#34;core/column&#34; data-wp-block=&#34;[]&#34; class=&#34;wp-block-column is-layout-flow wp-block-column-is-layout-flow&#34;&gt;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Anonymized Text&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;mark class=&#34;has-inline-color has-276-ef-1-color&#34;&gt;ANONYMIZED_NAME_0&lt;/mark&gt; is the first president of the United States. &lt;mark class=&#34;has-inline-color has-276-ef-1-color&#34;&gt;ANONYMIZED_NAME_1&lt;/mark&gt; is known for his leadership during the Civil War and the Emancipation Proclamation.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a390ee88-0d87-45ea-9e39-ef9714ef0190&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1bd16342-68ba-447b-b1e9-58dc0f417e92&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The mapping of PII data to anonymized placeholders is used in the un-redaction process that restores PII data from anonymized placeholders back to its original form, before returning the result to users.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4b0a9f7f-be47-4c51-8207-4f666854ec06&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Depending on the location the PII data is in the input, the same word can be redacted to different anonymized placeholders as it will be appended with different sequential numbers:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6da4648d-9005-47d8-9c1b-457872f11f9f&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;div data-wp-block-name=&#34;core/columns&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2a7aa4dd-5804-45ff-b42d-dce68e393123&amp;quot;,&amp;quot;isStackedOnMobile&amp;quot;:true}&#34; class=&#34;wp-block-columns is-layout-flex wp-container-core-columns-is-layout-2 wp-block-columns-is-layout-flex&#34;&gt;&#xA;&lt;div data-wp-block-name=&#34;core/column&#34; data-wp-block=&#34;[]&#34; class=&#34;wp-block-column is-layout-flow wp-block-column-is-layout-flow&#34;&gt;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Original Text&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Abraham Lincoln is known for his leadership during the Civil War and the Emancipation Proclamation. George Washington is the first president of the United States.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;div data-wp-block-name=&#34;core/column&#34; data-wp-block=&#34;[]&#34; class=&#34;wp-block-column is-layout-flow wp-block-column-is-layout-flow&#34;&gt;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Anonymized Text&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;mark class=&#34;has-inline-color has-276-ef-1-color&#34;&gt;ANONYMIZED_NAME_0&lt;/mark&gt; is known for his leadership during the Civil War and the Emancipation Proclamation. &lt;mark class=&#34;has-inline-color has-276-ef-1-color&#34;&gt;ANONYMIZED_NAME_1&lt;/mark&gt; is the first president of the United States.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b782d3a7-95b8-4f93-bfdc-f6fac2dea047&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:4,&amp;quot;hash&amp;quot;:&amp;quot;c80b26e7-853a-4bfd-a948-197d4519ed46&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-latency&#34;&gt;&lt;strong&gt;Latency&lt;/strong&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1470fed1-1c5b-404c-bb90-d42067674e3b&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;While most additional components in GenAI Gateway are lightweight, the PII redactor, by nature of scanning and anonymizing entire requests, incurs added latency proportional to the length of the input request. In cases where the input request is notably large, such as a few thousand tokens, the PII redactor alone can introduce a latency of several seconds. To address this, we’ve transitioned to a CPU-optimized model, resulting in a substantial 80%+ reduction in latency, without compromising accuracy. Furthermore, we are in the process of assessing more advanced models, including one that leverages GPU technology, to further enhance the processing speed and overall efficiency of the PII redactor.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:4,&amp;quot;hash&amp;quot;:&amp;quot;087365ba-af49-4fff-916f-f0fbfa2998ee&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-quality&#34;&gt;&lt;strong&gt;Quality&lt;/strong&gt;&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0e2e3c69-1d74-47d1-8e92-34988bac8b83&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The PII redactor can inadvertently impact the quality of results. Its process of anonymizing sensitive data, while safeguarding user information, sometimes strips away crucial context, thereby affecting the response quality of LLMs. For example, a query like “Who is George Washington?” is transformed into “Who is ANONYMIZED_NAME_0” for LLM processing. This anonymization can hinder LLMs’ ability to generate relevant responses due to the loss of specific contextual information.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9fdb0ac0-6a2a-44cb-a471-14462165dd91&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Furthermore, the PII redactor’s mechanism presents unique challenges in scenarios like LLM caching and Retrieval Augmented Generation (RAG). LLM caching, which stores responses for frequently asked questions to facilitate quick retrieval, faces a dilemma. Anonymized queries, such as “Who is George Washington?” and “Who is Abraham Lincoln?”, become indistinguishable post-redaction, leading to potential inaccuracies in cached responses. Similarly, RAG, which relies on fetching pertinent documents to aid LLMs in response generation, struggles with the inconsistencies introduced by anonymization. For instance, embedding a historical article about the American Revolutionary War might involve different anonymized placeholders for the same entity in offline and online contexts, leading to the retrieval of incorrect documents.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2f0c4eea-0d91-4bbb-80ba-cbf460e06a0b&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;These challenges highlight a fundamental issue: the difficulty in linking anonymized placeholders back to their original entities, causing errors in cached results or document retrieval. While maintaining a global table mapping original entities to anonymized placeholders is impractical, we are exploring solutions:&amp;nbsp; One approach encourages customers to use Uber-hostedLLMs, which do not require PII redaction. Simultaneously, we are evaluating the security assurances of third-party vendors to consider the possibility of forgoing the PII redactor entirely, striving to balance privacy concerns with operational effectiveness.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;e1b6de5b-fe78-4d7c-bde0-04951bf725f2&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-other-challenges&#34;&gt;&lt;strong&gt;Other Challenges&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d0f6465d-4a72-4f92-988d-4f7b68bee7ac&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Beyond the previously mentioned difficulties with PII redaction, the GenAI Gateway encounters additional, diverse challenges. The ever-evolving landscape of Large Language Models (LLMs) in recent months has prompted us to dynamically adjust our priorities. For instance, the recent introduction of GPT-4V shook things up by altering the request interface to accommodate image URLs and base64-encoded images. Fortunately, the responsive open-source community swiftly proposed solutions to seamlessly adapt to this change.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;87fc3c4d-83a0-4ebf-9418-3b40fbf0a158&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Given that GenAI Gateway’s core functionality revolves around forwarding requests to relevant LLM vendors, its availability is closely tied to the operational status of these vendors. In the event of a vendor outage, effective communication with users is crucial to prevent any misattribution of issues to the gateway itself. To bolster resilience, we are actively exploring the possibility of incorporating Uber-hostedLLMs as a fallback option when a third-party vendor encounters downtime.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e65b175f-48ce-4c6d-a292-db0227c90f3a&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4c72bb58-460c-4754-be32-ed051f246615&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-use-case-summarisation-of-chats-for-agents-resolution&#34;&gt;&lt;strong&gt;Use Case: Summarisation of Chats for Agents Resolution&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b1ed6027-0b3d-4a7e-a8ab-4e59ae013f4b&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In our continuous pursuit of enhancing customer support efficiency, Uber leverages large language models (LLMs) to streamline the process for our customer support agents. The primary focus is on swiftly summarizing user issues and suggesting potential resolution actions, significantly reducing the time it takes to address user queries. This not only expedites query resolutions but also contributes to an overall improved user experience. We leverage LLMs internally for following&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;ordered&amp;quot;:true,&amp;quot;hash&amp;quot;:&amp;quot;0aee051c-93e7-4bbf-a71b-afb5c6d71f45&amp;quot;,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Enhance chatbot-to-agent transitions, providing agents with concise summaries of prior interactions for improved understanding, faster resolution and addressing key challenges&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Furnish agents with crucial background information and user sentiments, enabling empathetic and contextually accurate support.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Implement automatic summarization of contact interactions, reducing manual summarization time by 80% and improving operational efficiency.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;d7dfbca3-3c84-4ee3-92e3-780a9377fe18&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-impact&#34;&gt;&lt;strong&gt;Impact&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c2da11cc-0927-4036-9dd7-500c408aa19a&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The implementation of LLMs has proven highly beneficial, with 97% of generated summaries found to be useful in resolving customer issues. Agents report significant time savings in reading and documentation, thereby enhancing their overall productivity. The agents are able to revert back to users 6 seconds faster than before. We are generating ~20 million summaries per week leveraging the LLMs, which we plan to expand to more regions and contact types in the future.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d87d11d4-8c61-4223-975e-5b8ee9b78de2&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In essence, our utilization of LLMs at Uber transcends mere automation–it’s a strategic enhancement focused on empowering our customer support agents to provide faster, more accurate, and empathetic resolutions.&amp;nbsp; All with the goal of delivering an unparalleled experience to our users.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;6f3fff59-4eda-4a9e-ba4e-e4d86dd0f080&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-how-gen-ai-gateway-is-used&#34;&gt;&lt;strong&gt;How Gen AI Gateway is used&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3c251dc5-8f76-4f63-8cf6-46b83d4617df&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Within Uber’s Customer Obsession organization, the CO Inference Gateway was initially employed to expose various ML Task-based API contracts internally to other services, abstracting out different ML Model hosts. For Summarization, we expanded this service to include a new Generation ML Task for Text, Chat, and Embedding Generation. This extension enables connections to both Open AI and Google Vertex AI models, fostering flexibility and adaptability.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6e9637f3-267e-49bc-8cbf-b2dbf1ce70e8&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;3a0a4eff-508a-450e-b7b6-d30abd888d73&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXe5_r9WXoElXeydaicgO-hAtPt5YOQr4MqZ3CKPRaVxgFWIkw1EnRrd9QKeEsmG-9SsHwbhGG-epfVUKYq6AGCli5guSvFn445zPBDxDkh6PLqYFzzwu4WE7yWr7f_4E7YOqYQ1z7o_WP3iO5Qyza27D7rI?key=5egmPsUgOM1kuqOeYjTalA&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;631b8d21-ba2a-4a6d-acc3-604bff6e1da1&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7e654ae5-5120-4e71-86fd-67fa18b95853&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;a href=&#34;https://drive.google.com/file/d/1mIgcSDvcFjzWO7H774u1ay20mF00sZEG/view?usp=drive_link&#34;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4c59483c-8bd4-4b50-9c4b-5f82c528ad7d&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Encountering challenges such as PII Redaction, Cost attribution, and the imperative for a centralized service at Uber to connect with any external Language Model (LLM), we made a strategic decision to leverage the Gen AI Gateway instead of directly calling external models. This decision was guided by the need for a comprehensive solution that not only addresses challenges effectively but also ensures a robust and secure integration. By doing so, we navigate complexities and optimize the utility of our AI-powered solutions, aligning with Uber’s commitment to innovation and excellence in customer support.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;85d40cc1-5690-4a43-9b85-98191edf7e4f&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;d8ba6985-0b79-4558-a5b8-078e0e381f63&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXcfFXsQPWf1S4ppo-vik3bFc867WLviUl182cHDZ-K7JZNaut0dfHXU5kKhFpVHJX9KERz4NVNwQS9un8lHVCwt74uD4MJ0sINAUrcyQwifX3COr4k3ZiJwdE338BFLKxROhBOSxwNKAqntSNFWi6-zNTxu?key=5egmPsUgOM1kuqOeYjTalA&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ee250d3c-364e-42b1-bde5-b5d81c1e3f20&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;c5f5f108-19fa-4345-b0bd-99044df1648e&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-prompt&#34;&gt;&lt;strong&gt;Prompt&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ec567b34-0b9f-453d-8864-911845c39aa5&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Following is a sample Prompt for the summarisation of contact tickets. We provide a few examples in the prompt context for few-shot learning.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote data-wp-block-name=&#34;core/quote&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;01b04911-552d-4e9d-b786-8ecb2b12562c&amp;quot;,&amp;quot;value&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;wp-block-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The following is a conversation between an Uber Customer support Bot called BOT, possibly a customer support agent called AGENT and an Uber Eats Customer called USER. Provide a detailed breakdown of the conversation. Identify all issues or intents and associated sentiments from the user. Extract the most pertinent part of user utterances and agent responses for each identified problem.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;input:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;{{conversation_log}} // Conversation log is the actual message history between customers, chatbots and agents.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f23b1fbe-c359-4c05-95ae-1a952fe7008f&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;316cdf49-3163-4cda-b13f-79fc13d055b3&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-learnings&#34;&gt;&lt;strong&gt;Learnings&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;885e8612-3fc7-4e44-b412-044519b57ea9&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In reflecting on our journey with LLMs, a fundamental lesson stands out: the critical need for adaptability in the face of the rapidly evolving LLM landscape. As we delve deeper into the realm of advanced LLM applications, the importance of skillfully managing the interplay between ever-changing technologies, user privacy, and efficiency becomes increasingly evident. This landscape is constantly shifting, and our dedication to continuous improvement is more crucial than ever. Navigating these dynamics with agility and foresight is pivotal to our mission, ensuring that we not only keep pace with technological advancements but also uphold our commitment to user privacy and system efficiency.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;daca159f-1260-4b21-b095-be3639656066&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;314ead02-2022-4b7f-9bb3-a3dc6eb8e93c&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-future-works&#34;&gt;&lt;strong&gt;Future Works&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1ac48011-3d5a-40e7-8c50-8c1736fb0fbe&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Looking ahead, our vision for the GenAI Gateway is to elevate and refine its capabilities to better serve our users. A key focus is on enhancing the onboarding process for new models. Whether these are bespoke, fine-tuned models tailored to specific needs or those sourced from the vibrant open-source community, our goal is to make their integration as fluid and user-friendly as possible. Moreover, we are keen on augmenting the gateway with advanced features that address the dynamic challenges of working with Large Language Models. This includes implementing intelligent LLM caching mechanisms, developing robust fallback logic, and introducing sophisticated hallucination detection. Safety and policy guardrails are also on our agenda to ensure that our platform remains secure and compliant with evolving standards.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c896442c-5abb-420b-85b5-898882f48a1e&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In our journey to expand the gateway’s capabilities, we also recognize the importance of tapping into the vast potential of the open-source ecosystem. To this end, we are actively working towards integrating with libraries. This will not only enhance the functional breadth of our system, but also make it more versatile, enabling our users to explore and leverage a broader range of solutions. These future endeavors underscore our commitment to continually evolve the GenAI Gateway, ensuring it remains a cutting-edge, versatile, and secure platform for harnessing the power of LLMs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;62803538-f24d-48ec-971e-28ba28c745cc&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;c312f523-db66-494c-9407-311cee6c8b60&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-conclusion&#34;&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ad1f31f3-01c4-475c-b839-51e7dd25b3cf&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;LLMs have become a transformative force. The integration of LLMs at Uber, however, has not been without challenges. Inconsistent integration strategies and the absence of a standardized approach have led to inefficiencies and difficulties in monitoring costs and vendor usage.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8def3e9e-3285-449e-9694-e7fcfe114573&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Addressing these issues, Uber’s Michelangelo team developed the GenAI Gateway, a unified platform facilitating access to LLMs from multiple providers, including OpenAI and Vertex AI, as well as Uber’s in-house models. This platform streamlines the integration process, ensuring compliance with privacy and security standards and efficient usage management. GenAI Gateway’s design, mirroring the OpenAI API, ensures compatibility with existing tools and maintains pace with the evolving open-source community. It also features a PII redactor, enhancing security. This strategic development of the GenAI Gateway, coupled with its focus on operational efficiency and alignment with Uber’s broader technological framework, exemplifies Uber’s commitment to innovation while addressing the dynamic challenges of working with LLMs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d24118d6-acbf-4d50-959b-5337150cda8c&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-acknowledgments&#34;&gt;&lt;strong&gt;Acknowledgments&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ae51ea31-0c43-4ce0-9617-47822269b6e2&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We could not have accomplished the technical work outlined in this article without the help of various engineering teams, Uber AI, and the Uber Customer Obsession Team. We would also like to thank the various product teams working with us in adopting Gen AI Gateway.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;fontSize&amp;quot;:&amp;quot;small&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;afc6017c-684e-44ac-abcc-678a2031b044&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34; class=&#34;has-small-font-size&#34;&gt;Cover Photo Attribution: The “&lt;strong&gt;Artificial Intelligence, AI&lt;/strong&gt;” image is covered by a &lt;a href=&#34;https://creativecommons.org/licenses/by/2.0/&#34;&gt;CC BY 2.0&lt;/a&gt; license and is credited to &lt;a href=&#34;https://www.flickr.com/photos/152824664@N07&#34;&gt;mikemacmarketing&lt;/a&gt;. No changes have been made to the image (&lt;a href=&#34;https://openverse.org/image/49410795-b3ba-421b-918b-7f2cd9178f19?q=artificial%20intelligence&#34;&gt;source&lt;/a&gt;).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;fontSize&amp;quot;:&amp;quot;small&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;f526d83b-eb4f-49c3-9e7f-661ae12bcd4b&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34; class=&#34;has-small-font-size&#34;&gt;Vertex AI™, PaLM™, Google Dialogflow™&amp;nbsp; and Go™ are trademarks of Google LLC and this blog post is not endorsed by or affiliated with Google in any way.&lt;/p&gt;</description>
      <pubDate>Thu, 11 Jul 2024 06:58:53 +0000</pubDate>
    </item>
    <item>
      <title>【Debugging with Production Neighbors – Powered by SLATE】与生产邻居一起调试 – 由 SLATE 提供支持</title>
      <link>https://www.uber.com/blog/debugging-with-production-neighbors/</link>
      <description>【&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;0277d5f7-0165-458e-a200-4057ec5939da&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-introduction&#34;&gt;Introduction&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d4256add-d86f-4f3f-825b-cbe635b737f3&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Software development is an iterative and staged process that needs validation and testing at function, component, and service levels. In the case of microservice-based architecture, it becomes far more important to develop in conjunction with dependent services. Microservice-based architecture provides distinct advantages that allow us to scale, maintain, and abstract responsibilities. The more abstraction, the easier it is for us to develop and define business logic.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9890ecf7-7a4e-43cb-a0ad-e736e521cba4&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;a href=&#34;https://www.uber.com/blog/simplifying-developer-testing-through-slate/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;SLATE&lt;/a&gt; is an E2E testing tool that bridges the gap by allowing services under test to be deployed and work along with production upstream and downstream services. This allows developers to generate test requests mirroring production call flow yet target services under test. Such functionality facilitates various use cases, including feature development within a production environment or replicating production bugs, which often entail troubleshooting both code and configuration. To aid or simplify the process of troubleshooting and make it nearer to the local experience we have developed features to enable debugging of services deployed in the SLATE environment.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;41d5de27-f980-4ed2-bd72-2950ff5f81ef&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In this blog we’ll explore different debugging options developed on SLATE that emulates the behavior of services under test with production upstream and downstream.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2cf8d798-d6c4-48b5-87be-02e7d6a16823&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Let us check the following three high-level options developed in detail:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;ordered&amp;quot;:true,&amp;quot;hash&amp;quot;:&amp;quot;12e47251-1926-462c-a4f0-3c9230f71035&amp;quot;,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Remote debugging a SLATE deployed instance&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Local Debugging in laptop/dev pod machine&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Debug issues by filtered monitoring&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;00a68086-a170-4640-a605-3b4d6bc61291&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f06b920f-d468-4d51-8c1b-347777a1ca08&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-debugging-until-now&#34;&gt;Debugging Until Now&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;87ca5e62-f730-45a5-8e9f-0d704ebdd0fa&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-debug-via-logs&#34;&gt;Debug via Logs&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4efff6dc-9fd1-4694-a31d-3e921bfdc295&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Debugging using logs is a fundamental practice that provides insights into a program’s execution. Logs enables developers to identify issues. However, inefficient logging can clutter the system with irrelevant information, leading to complicating rather than aiding the debugging process.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;599a8a54-9b98-46f2-95f4-5585f0ab7862&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-debug-via-staging&#34;&gt;Debug via Staging&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b39d20b2-4b5e-4644-b2ce-1e8ac406d13e&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Staging environment is developer controlled environment that mirrors the production setup.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;627706a3-02f5-4a44-811e-293c575ddeda&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;While staging environments are very beneficial, they may still differ from the live environment and provide false confidence with a longer turnaround time.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;b929c6e0-b520-4df1-90d9-74d0103175a0&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-debug-locally&#34;&gt;Debug Locally&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3e41d70e-4563-47d2-bcf2-6b877aa943cf&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Local debugging is essential for faster iteration to test service in isolation. However, debugging user scenarios can be challenging due to constraints in simultaneously debugging multiple services together.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7914ae72-a666-449c-ad31-f41539c33705&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;fc0ea531-43db-40bf-90d1-d317a803e196&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-remote-debugging-of-slate-instance&#34;&gt;Remote Debugging of SLATE Instance&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;27942760-eff9-41b9-bd96-9e3c144c1258&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Testing and debugging on SLATE relies on logs from the service being tested. Depending solely on logs for understanding complex processes isn’t practical. Additionally, adding new logs requires a new deployment, causing delays. Remote debugging can address these issues by letting developers step through statements and monitor variables, eliminating the need for commit and deployment iterations. Co-working with production infra, needs to balance security and developer experience.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1d9e79e3-9f82-4e8e-ac72-c867fd34a9da&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;This brings a need to enhance visibility into the code for runtime debugging, achieved through breakpoints, step-ins, or dynamic tracepoints. Remote debugging is limited to SLATE instances handling test requests to ensure production security.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;63b7af5d-5044-4ba8-91a4-2545b9afb999&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-high-level-goals&#34;&gt;High-level Goals&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ff345dd1-5e7e-46aa-93ba-9f2817dda43a&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Deploy a debuggable binary/code on a SLATE container&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Ability to add breakpoints and tracepoints to a service under test&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Ability to see values of different params on control hitting a breakpoint&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Create a seamless developer experience similar to remote debugging&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Design solutions to be compliant with security and privacy issues&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;ec951a18-fc82-418d-a4e4-3bc2e589ce07&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-design&#34;&gt;Design&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;13353fa3-de1c-4257-b72f-812657c19ed2&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;SLATE leverages the production infrastructure to generate containers, compile code, and execute services. However, modifications were required to the build and deployment infrastructure to facilitate debugging functionalities for services deployed on SLATE. This involved three significant enhancements. Firstly, enabling the generation of builds with integrated debugging tools and functionalities. Secondly, configuring software execution with remote debugging options. Thirdly, facilitating developer access to remote containers by allocating and exposing ports from said containers.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;0c2c17ea-868c-477f-a313-a4ca6375f5bb&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-debuggable-deployment&#34;&gt;Debuggable Deployment&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7f392d92-e347-44f8-9ca7-57adcbd6690b&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The current deployment pipeline is not flexible to support different options to generate both debuggable and production binaries. To be able to generate and deploy debuggable binary, multiple components of the pipeline should realize the type of binary and configure their features accordingly. This diagram indicates the components that would be involved during the feature development.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;22d95a33-f3a7-4c79-8a5d-f55dd55f4970&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090425,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;c1906e48-3b10-4623-b90f-4e766ba96054&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;285&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig2-1024x285.jpeg&#34; alt=&#34;&#34; class=&#34;wp-image-1090425&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig2.jpeg 1024w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig2.jpeg 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig2.jpeg 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1351,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig2.jpeg 1351w&#34; sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Fig 1: Modifications to the deployment pipeline to support debugging for SLATE.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;676b8b24-a254-49fe-8cda-95cfbff522a2&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;f6c802a6-f496-4294-bdee-b03c2e87bd28&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-allocating-ports&#34;&gt;Allocating Ports&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9079639d-492b-449c-8b76-306a451ba65b&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The SLATE Container gets created alongside the production host. To be able to connect to the debugger, we have to expose a new debug port, similar to a gRPC/HTTP port. Currently UP is responsible for allocating random ports and mapping the same to the host port. The exposure of the new port will be opened only for debuggable SLATE deployments and SLATE implicitly handles the test requests by design. This new port exposure needs a security review. The below diagram indicates the high-level interactions.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4ef1347e-9498-4398-84b9-482c926dc6a3&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b1b7007c-b1a8-4303-81c6-8baa95bbe208&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXfNB42pjNG_DCuxWPz9gEvHHrE9XBFFcsEvj1tsaIr7Hn2pTk6nl3ghqed81UCUzrhbtFUaWYoageTGPGBuZJXXTNq_Zx8lT-RoppYjT3hjsjxuViujT4oCun8CeDLuQqzNyIV2C8GjgTr6m1Hs73MActat?key=Ermx74NMIF5DAzxh8Wqoiw&#34; width=&#34;695.85121602289&#34; height=&#34;173.47872782612586&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090426,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;ef9e19b7-cc21-400f-a606-24c9066846b6&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;283&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig1-1024x283.jpeg&#34; alt=&#34;&#34; class=&#34;wp-image-1090426&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig1.jpeg 1024w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig1.jpeg 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig1.jpeg 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1080,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig1.jpeg 1080w, https://blog.uber-cdn.com/cdn-cgi/image/width=1087,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig1.jpeg 1087w&#34; sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Fig 2: Allocation and safely exposing debug ports.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;52c17921-426e-4cc2-bb49-84bb33b65068&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;1802af6b-beea-4b6a-9356-56770a6674e4&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-reaching-debuggable-service&#34;&gt;Reaching Debuggable Service&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d71b7b8d-1510-4c8a-aa45-1748e2bfa1d5&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;To improve the security and avoid malicious access, SLATE debugging needs to be access controlled. This would ensure that only the service owners would be able to connect the debugger. The diagram below indicates the access control that would limit access to only the LDAP users of the service.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f59e6d1b-ce89-46e1-a38a-e2ead87bf3d8&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090429,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;34c12c23-cdd9-453c-80ab-a1796c3cc5b6&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;357&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig3-1-1024x357.jpeg&#34; alt=&#34;&#34; class=&#34;wp-image-1090429&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig3-1.jpeg 1024w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig3-1.jpeg 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig3-1.jpeg 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1060,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig3-1.jpeg 1060w&#34; sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Fig 3: Password-based SSH tunneling to the remote host from the developer machines.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7f039f2a-0cfd-4404-b346-78190cf63b4c&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:4,&amp;quot;hash&amp;quot;:&amp;quot;76babcaa-cab0-4480-8507-b5b34963fcda&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-debugger-execution&#34;&gt;Debugger Execution&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;806a7025-1ec1-4126-982f-3bf7c83531b8&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;The debugger runs the application within a dedicated debugging server&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;The process blocks, awaiting attachment by the debugger client&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;The debugger process listens on a specific TCP/IP network port, referred to as a debug port&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:4,&amp;quot;hash&amp;quot;:&amp;quot;0e325adf-9b00-4e6b-b655-c8c1d1273cb7&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-controlling-program-execution&#34;&gt;Controlling Program Execution&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;bde0ef70-cfa0-47d4-8415-a94df60c277c&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Debugging clients (e.g., VSCode, GoLand, JetBrains) connect via the debug port. Clients issue commands for various debugging tasks like setting breakpoints, displaying local variables and function arguments, printing CPU register contents, etc.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:4,&amp;quot;hash&amp;quot;:&amp;quot;4e33b23b-99e7-47fb-965c-a4ad0c16148a&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-remote-debugging-with-debug-port&#34;&gt;Remote Debugging with Debug Port&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;bba71797-e7ac-45b7-9821-593be4f452a0&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Remote debugging enables debugging on diverse environments, configurations, or architectures. Useful for troubleshooting specific scenarios or hardware/software related issues that cannot be replicated locally.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6c156180-0c50-4e3a-a8a6-f528ffcecde0&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9cb16568-df09-423a-9620-06a015eec13f&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-access-control&#34;&gt;Access Control&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;4c8ec086-34cc-43f6-9859-7bb6234c0e8c&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-restricting-for-ldap-users&#34;&gt;Restricting for LDAP Users&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a273ae87-4c85-419a-817f-0039525eceef&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;During debugging sessions, users attach the debugger to the application to intervene in program execution and gather debug information. This would also mean trying to identify and resolve bugs in the program. This means to get access to some sensitive service information if allowed for every user. So restricting to LDAP users (service developers/owners) is important to ensure minimum security.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;599ec47d-a7c4-42dd-a781-b925786dc85f&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-secure-ssh-connection&#34;&gt;Secure SSH Connection&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;38427b55-698d-4f88-88a4-78f359534d9f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;For remote debugging, a secure SSH connection is established between local and remote systems. This will allow for local port forwarding and redirects debug requests through an SSH tunnel. This tunnel would ensure encrypted communication and secure data transmission.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;bb70ee8d-23cc-4787-be91-df79467c43d5&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-ssh-authorization&#34;&gt;SSH Authorization&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d20f9558-dc9c-4679-88b3-f14a328f9b18&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;To begin an SSH connection, users need the correct password linked to the “slatedev” account. This password is a randomly generated 16-digit code in the file within the service container. The password is generated during the container’s startup before the main service application runs. This Password is accessible only to the container access group, which is service owner LDAP. LDAP users can access the password through Compute CLI, enabling them to establish SSH connections and perform debugging tasks. Compute CLI ensures restricted access to Non-LDAP users, which doesn’t allow password access.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d2dcd9cb-9e60-4927-9709-437e6f52778a&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e4f7db46-498e-45ce-9a76-67083c5cd789&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-limitations&#34;&gt;Limitations&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3128df24-147b-4c41-8b29-e565ced347e4&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Remote debugging on production infra has limitations about dynamic modifications, so it’s limited to read-only&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Large iteration time, as each change involves build, deploy, and test&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9f25985c-b82e-493a-b23b-da0ee9452de6&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;877f5b6c-03ed-4e6d-b459-307eed84a616&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-local-debugging-using-slate-attach&#34;&gt;Local Debugging using SLATE Attach&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0b458a84-2d3d-45bc-8464-f0d2bed998fd&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Remote Debugging allows for read-only debugging on production infrastructure. Being in production infra allows for seamless connections with upstream and downstream services/tools. For a developer it’s very important to experience a debuggable environment with faster iteration to fix and test the same. This gap can be filled by creating a local debugging experience in connection with production upstream and downstream services. SLATE Attach fills this gap and allows for rapid development on attaching local environments.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;26b16577-aec0-4ede-b886-8e3dca0e20a7&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-high-level-goals-0&#34;&gt;High-level Goals&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;fab90a26-f7ff-4ba3-82c2-50b17f1338fa&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The main goal is to reduce the code-deploy-test cycle (and hence, the time to validate iterative changes), by providing E2E testing with local development instances (laptop or dev machine), ensuring production isolation and safety.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;2c391ff7-243f-46bf-a671-3db9d374c1b9&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-iteration-cycle&#34;&gt;Iteration Cycle&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8becb5e9-ce3d-486a-83eb-7d6a7c54f055&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The iteration cycle in this context is the time between making the code change and validating them. The smaller the iteration cycle, the more efficient the use of developers’ time for end-to-end validation of subsequent changes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8e50f42c-6c02-4846-8e0b-52e2012bda37&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090430,&amp;quot;sizeSlug&amp;quot;:&amp;quot;full&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;794ef73a-e926-428b-97fe-b11a0f4ed15e&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;820&#34; height=&#34;221&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig4.jpeg&#34; alt=&#34;&#34; class=&#34;wp-image-1090430&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=820,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig4.jpeg 820w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig4.jpeg 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig4.jpeg 768w&#34; sizes=&#34;(max-width: 820px) 100vw, 820px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Fig 4: Iteration steps for development using SLATE.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c7f6664e-80ae-48c8-8431-59dac8c806ee&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;5ed47996-ad37-4c32-921b-1d59850ed524&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-need-for-slate-attach&#34;&gt;Need for SLATE Attach&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5e842c0b-9224-423e-87d0-5b0498fefe01&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Iterative development generates a build binary at a faster pace&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Reduced code-deploy-test cycle&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Faster identification and resolution of local, E2E failures&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Faster setup time&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Avoid the need for service changes or onboarding&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ebecbddf-739b-4bf3-8027-63cc10028542&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2feec9ce-de38-4282-bd46-8f8ed6b46b64&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-design-0&#34;&gt;Design&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c0f6f7d6-1ae8-4a46-a3a9-2e6e569f3bfc&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;This design aims to introduce a SLATE proxy that handles all the test requests aimed at SLATE instances for local debugging. These requests will then be redirected to the appropriate local developer machine for debugging and development. This allows users to iterate faster and improve developers’ productivity.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ad3a7aa8-a42a-49e2-a3f7-0ec4812f3deb&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;This feature could be enabled mainly in 2 contexts in SLATE environment lifecycle:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;ordered&amp;quot;:true,&amp;quot;hash&amp;quot;:&amp;quot;d122ed7f-f7b0-49b6-9be0-cedaae60ec26&amp;quot;,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;SLATE Control plane&lt;/strong&gt; that maps local laptop/devpod to a slate environment&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;Test Request Data plane&lt;/strong&gt; that redirects the requests to developers’ laptops&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;879353b5-bf5f-4dbd-a4b6-a90907c4a437&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;fc0e575f-51cb-45c2-8ea1-2b00b9bd027c&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-control-plane&#34;&gt;Control Plane&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0a982fcd-aefc-447e-9ac7-9a83e9877ae9&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The main feature of the control plane is to enable services running in local laptops or devpods to attach to a SLATE environment. The local laptop/devpod that intends to run the service has to attach local environment credentials to a SLATE environment so that test requests are routed locally. The prerequisite for this attachment is to create a SLATE environment. This will allow mapping updates in routing control DB and local routing DB.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9f9c73ee-1938-4f29-8e82-827493504e86&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090431,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;a7fc2c6a-5999-43b2-b636-04ec980e468e&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;560&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig5-1024x560.jpg&#34; alt=&#34;&#34; class=&#34;wp-image-1090431&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig5.jpg 1024w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig5.jpg 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig5.jpg 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1036,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig5.jpg 1036w&#34; sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Fig 5: Request Call flow for testing code running on developer machines&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0fc0d21b-6a51-4ba0-912f-e4a1ece3b94a&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:4,&amp;quot;hash&amp;quot;:&amp;quot;68ef7376-005b-4c34-8ca9-8d91c2071b73&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-call-flow&#34;&gt;Call flow&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;ordered&amp;quot;:true,&amp;quot;hash&amp;quot;:&amp;quot;4d4c2d52-cb99-49a9-a1dc-22f53a3c5c2a&amp;quot;,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;User initiates SLATE attach from local laptop/devpod&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;The SLATE CLI calls Attach() API of SLATE Backend&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;SLATE Backend fetches the Proxy information (host:port) from SLATE Proxy&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;SLATE Backend updates the routing override in routing control DB using the fetched proxy info&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;User initiates the SSH Session using the Cerberus CLI&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Cerberus gateway adds the mapping of deputized tenancy/UUID to the laptop credentials in Flipr DB and creates a SSH session for the laptop&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:4,&amp;quot;hash&amp;quot;:&amp;quot;33cbd3ba-84e6-4fb7-b51f-c32368b85ec3&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-routing-control-db&#34;&gt;Routing Control DB&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3091a315-341a-4ac2-8c3d-aa18ad2dfa66&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Routing Control DB maps test tenancy to routing overrides and user account UUIDs to test tenancy. It stores the SLATE Proxy host:port against the service under test and ensures that all requests targeting a particular SLATE environment, reaches SLATE Proxy. SLATE Proxy finally routes the request to the development instance running in the user’s machine.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:4,&amp;quot;hash&amp;quot;:&amp;quot;1af3bcce-3d51-4a3b-af45-fd2f0aa37403&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-local-routing-db&#34;&gt;Local Routing DB&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;fa9af186-07d9-4578-9ab9-6352df586e83&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Local routing DB contains the development instance’s credentials that have been attached to the SLATE environment. SLATE Proxy interacts with the local routing DB to fetch routing credentials and finally routes the request to service-under-test running in local environment&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ae9e74db-9b41-4a46-ba9d-d600c0350856&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;714ae8c2-f980-4c03-9133-3981f34c4945&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-data-plane&#34;&gt;Data Plane&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3c12e2f9-9a26-4969-a929-e66e5b9a207d&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;This section mainly talks about the flow of test requests from different clients (mobile, studio, web, etc.). This data plane mainly involves 2 entities: routing override header and host tenancy mapping. The below diagram indicates how different test requests reach a local laptop through the SLATE proxy. The control plane ensures routing override and host mapping maintained in different databases.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0cc4187b-d85a-4b70-be55-c158994fefdb&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090432,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;5b649275-8ac1-4340-b0e8-a19be825d309&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;520&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig6-1024x520.jpeg&#34; alt=&#34;&#34; class=&#34;wp-image-1090432&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig6.jpeg 1024w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig6.jpeg 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig6.jpeg 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig6.jpeg 1300w&#34; sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Fig 6: Proxy setup for routing test requests to developer machines.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d0682e8a-4e5e-4860-bf0a-27125c9e134a&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d5a8b75c-9546-48e7-aeab-107b253f5169&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Above is the test request flow targeted for local laptop with production upstreams and downstreams:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;ordered&amp;quot;:true,&amp;quot;hash&amp;quot;:&amp;quot;4ea9f2b6-a6c3-452e-9629-1505324f32c8&amp;quot;,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Test account request originates from mobile client&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;E2E test proxy retrieves routing override and injects the routing header to the test request&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;The test request propagates through production services via Mutley until the request has service 3 target&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;The request redirects to SLATE proxy as the routing override has slate proxy host:port against service 3&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;SLATE proxy forwards the request to an open port on Cerberus-gateway based on a host:port config in the Cerberus-deputy Flipr namespace, set by the user when running the Cerberus CLI&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;The Cerberus-gateway forwards the request to the user’s local development machine for the user to debug&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;From the local laptop, the request will be finally forwarded to production downstreams through Cerberus&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;c1062a3f-701f-40f2-8416-7ccd43c088cb&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-limitations-0&#34;&gt;Limitations&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7d9da5c3-f6e2-4fb8-b038-71dbe8495dad&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Running a service locally may not be feasible for some complex services, as they need support for some dependencies like spanners that can only exist in production infra&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;This is limited to test requests as it enables dynamic changing of requests and in turn secures production traffic&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Requests timeout on longer wait for a debug request in local&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f205b844-fe96-41cf-a695-c12f79b9e330&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;86cb82b0-8d3f-4afe-b4a8-e46ab6edf12d&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-impact&#34;&gt;Impact&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4af528af-4339-4de0-b65a-ba6a68054d0e&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Plug-and-play development environment to improve developer productivity&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Ability to create local experiences that co-work with production for developers&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Increase Developer Velocity: Production debugging can help developers identify and fix issues more efficiently&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;db759f9c-b972-4bf3-85c6-106704f28b6c&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090433,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;f769cc84-59fb-4db5-b270-85f9cc38bc6c&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;280&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig7-1024x280.jpeg&#34; alt=&#34;&#34; class=&#34;wp-image-1090433&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig7.jpeg 1024w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig7.jpeg 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig7.jpeg 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1536,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig7.jpeg 1536w, https://blog.uber-cdn.com/cdn-cgi/image/width=1680,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig7.jpeg 1680w&#34; sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Fig 7. Impact figures for improving developer velocity using SLATE attach feature.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;92748031-56ec-41fe-af5f-e28c13872b72&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;089b91b9-e785-426b-9acc-98c513dbecb7&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-what-s-next&#34;&gt;What’s Next&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0fab3aae-e3c1-4f43-b6cd-31314da60b97&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;SLATE Sniffer to debug issues by monitoring&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;25ad3857-16be-4803-b58a-19203bd4ff77&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The remote and local debugging mainly allow for test requests to debug. There is a need for observability on production, beyond logs that come up in uMonitor Tool. We aim to create this observability precisely and on-demand using SLATE Sniffer.&amp;nbsp; The main goals of SLATE Sniffer include:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9512a824-5d47-4526-b7b9-a3da8258f058&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Capture the request and responses as a filter of a service and UUID&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Ability to support and filter on Production and Test requests&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f11a73c1-4e1a-40b2-96a4-987bfccd4683&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;a623f4dc-0808-4f1f-a5c6-a75a520f8f0e&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-conclusion&#34;&gt;Conclusion&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c06ce4bc-9946-41bd-95b1-37c27416e5ee&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Our objective is to enhance the SLATE platform, positioning it as the primary tool for debugging production issues. The debugging features integrated into SLATE strike a balance between security and developers’ requirements. SLATE has introduced a new paradigm for developers’ code-related activities and service bootstrapping. We are looking forward to collaborating with different teams to shift the quality left and create visibility on potential issues at the early stage of development.&lt;/p&gt;】&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;0277d5f7-0165-458e-a200-4057ec5939da&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-introduction&#34;&gt;Introduction&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d4256add-d86f-4f3f-825b-cbe635b737f3&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Software development is an iterative and staged process that needs validation and testing at function, component, and service levels. In the case of microservice-based architecture, it becomes far more important to develop in conjunction with dependent services. Microservice-based architecture provides distinct advantages that allow us to scale, maintain, and abstract responsibilities. The more abstraction, the easier it is for us to develop and define business logic.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9890ecf7-7a4e-43cb-a0ad-e736e521cba4&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;a href=&#34;https://www.uber.com/blog/simplifying-developer-testing-through-slate/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;SLATE&lt;/a&gt; is an E2E testing tool that bridges the gap by allowing services under test to be deployed and work along with production upstream and downstream services. This allows developers to generate test requests mirroring production call flow yet target services under test. Such functionality facilitates various use cases, including feature development within a production environment or replicating production bugs, which often entail troubleshooting both code and configuration. To aid or simplify the process of troubleshooting and make it nearer to the local experience we have developed features to enable debugging of services deployed in the SLATE environment.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;41d5de27-f980-4ed2-bd72-2950ff5f81ef&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In this blog we’ll explore different debugging options developed on SLATE that emulates the behavior of services under test with production upstream and downstream.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2cf8d798-d6c4-48b5-87be-02e7d6a16823&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Let us check the following three high-level options developed in detail:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;ordered&amp;quot;:true,&amp;quot;hash&amp;quot;:&amp;quot;12e47251-1926-462c-a4f0-3c9230f71035&amp;quot;,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Remote debugging a SLATE deployed instance&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Local Debugging in laptop/dev pod machine&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Debug issues by filtered monitoring&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;00a68086-a170-4640-a605-3b4d6bc61291&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f06b920f-d468-4d51-8c1b-347777a1ca08&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-debugging-until-now&#34;&gt;Debugging Until Now&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;87ca5e62-f730-45a5-8e9f-0d704ebdd0fa&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-debug-via-logs&#34;&gt;Debug via Logs&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4efff6dc-9fd1-4694-a31d-3e921bfdc295&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Debugging using logs is a fundamental practice that provides insights into a program’s execution. Logs enables developers to identify issues. However, inefficient logging can clutter the system with irrelevant information, leading to complicating rather than aiding the debugging process.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;599a8a54-9b98-46f2-95f4-5585f0ab7862&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-debug-via-staging&#34;&gt;Debug via Staging&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b39d20b2-4b5e-4644-b2ce-1e8ac406d13e&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Staging environment is developer controlled environment that mirrors the production setup.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;627706a3-02f5-4a44-811e-293c575ddeda&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;While staging environments are very beneficial, they may still differ from the live environment and provide false confidence with a longer turnaround time.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;b929c6e0-b520-4df1-90d9-74d0103175a0&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-debug-locally&#34;&gt;Debug Locally&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3e41d70e-4563-47d2-bcf2-6b877aa943cf&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Local debugging is essential for faster iteration to test service in isolation. However, debugging user scenarios can be challenging due to constraints in simultaneously debugging multiple services together.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7914ae72-a666-449c-ad31-f41539c33705&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;fc0ea531-43db-40bf-90d1-d317a803e196&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-remote-debugging-of-slate-instance&#34;&gt;Remote Debugging of SLATE Instance&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;27942760-eff9-41b9-bd96-9e3c144c1258&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Testing and debugging on SLATE relies on logs from the service being tested. Depending solely on logs for understanding complex processes isn’t practical. Additionally, adding new logs requires a new deployment, causing delays. Remote debugging can address these issues by letting developers step through statements and monitor variables, eliminating the need for commit and deployment iterations. Co-working with production infra, needs to balance security and developer experience.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1d9e79e3-9f82-4e8e-ac72-c867fd34a9da&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;This brings a need to enhance visibility into the code for runtime debugging, achieved through breakpoints, step-ins, or dynamic tracepoints. Remote debugging is limited to SLATE instances handling test requests to ensure production security.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;63b7af5d-5044-4ba8-91a4-2545b9afb999&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-high-level-goals&#34;&gt;High-level Goals&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ff345dd1-5e7e-46aa-93ba-9f2817dda43a&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Deploy a debuggable binary/code on a SLATE container&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Ability to add breakpoints and tracepoints to a service under test&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Ability to see values of different params on control hitting a breakpoint&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Create a seamless developer experience similar to remote debugging&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Design solutions to be compliant with security and privacy issues&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;ec951a18-fc82-418d-a4e4-3bc2e589ce07&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-design&#34;&gt;Design&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;13353fa3-de1c-4257-b72f-812657c19ed2&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;SLATE leverages the production infrastructure to generate containers, compile code, and execute services. However, modifications were required to the build and deployment infrastructure to facilitate debugging functionalities for services deployed on SLATE. This involved three significant enhancements. Firstly, enabling the generation of builds with integrated debugging tools and functionalities. Secondly, configuring software execution with remote debugging options. Thirdly, facilitating developer access to remote containers by allocating and exposing ports from said containers.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;0c2c17ea-868c-477f-a313-a4ca6375f5bb&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-debuggable-deployment&#34;&gt;Debuggable Deployment&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7f392d92-e347-44f8-9ca7-57adcbd6690b&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The current deployment pipeline is not flexible to support different options to generate both debuggable and production binaries. To be able to generate and deploy debuggable binary, multiple components of the pipeline should realize the type of binary and configure their features accordingly. This diagram indicates the components that would be involved during the feature development.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;22d95a33-f3a7-4c79-8a5d-f55dd55f4970&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090425,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;c1906e48-3b10-4623-b90f-4e766ba96054&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;285&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig2-1024x285.jpeg&#34; alt=&#34;&#34; class=&#34;wp-image-1090425&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig2.jpeg 1024w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig2.jpeg 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig2.jpeg 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1351,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig2.jpeg 1351w&#34; sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Fig 1: Modifications to the deployment pipeline to support debugging for SLATE.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;676b8b24-a254-49fe-8cda-95cfbff522a2&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;f6c802a6-f496-4294-bdee-b03c2e87bd28&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-allocating-ports&#34;&gt;Allocating Ports&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9079639d-492b-449c-8b76-306a451ba65b&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The SLATE Container gets created alongside the production host. To be able to connect to the debugger, we have to expose a new debug port, similar to a gRPC/HTTP port. Currently UP is responsible for allocating random ports and mapping the same to the host port. The exposure of the new port will be opened only for debuggable SLATE deployments and SLATE implicitly handles the test requests by design. This new port exposure needs a security review. The below diagram indicates the high-level interactions.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4ef1347e-9498-4398-84b9-482c926dc6a3&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b1b7007c-b1a8-4303-81c6-8baa95bbe208&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXfNB42pjNG_DCuxWPz9gEvHHrE9XBFFcsEvj1tsaIr7Hn2pTk6nl3ghqed81UCUzrhbtFUaWYoageTGPGBuZJXXTNq_Zx8lT-RoppYjT3hjsjxuViujT4oCun8CeDLuQqzNyIV2C8GjgTr6m1Hs73MActat?key=Ermx74NMIF5DAzxh8Wqoiw&#34; width=&#34;695.85121602289&#34; height=&#34;173.47872782612586&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/h2&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090426,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;ef9e19b7-cc21-400f-a606-24c9066846b6&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;283&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig1-1024x283.jpeg&#34; alt=&#34;&#34; class=&#34;wp-image-1090426&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig1.jpeg 1024w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig1.jpeg 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig1.jpeg 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1080,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig1.jpeg 1080w, https://blog.uber-cdn.com/cdn-cgi/image/width=1087,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig1.jpeg 1087w&#34; sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Fig 2: Allocation and safely exposing debug ports.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;52c17921-426e-4cc2-bb49-84bb33b65068&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;1802af6b-beea-4b6a-9356-56770a6674e4&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-reaching-debuggable-service&#34;&gt;Reaching Debuggable Service&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d71b7b8d-1510-4c8a-aa45-1748e2bfa1d5&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;To improve the security and avoid malicious access, SLATE debugging needs to be access controlled. This would ensure that only the service owners would be able to connect the debugger. The diagram below indicates the access control that would limit access to only the LDAP users of the service.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f59e6d1b-ce89-46e1-a38a-e2ead87bf3d8&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090429,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;34c12c23-cdd9-453c-80ab-a1796c3cc5b6&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;357&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig3-1-1024x357.jpeg&#34; alt=&#34;&#34; class=&#34;wp-image-1090429&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig3-1.jpeg 1024w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig3-1.jpeg 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig3-1.jpeg 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1060,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig3-1.jpeg 1060w&#34; sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Fig 3: Password-based SSH tunneling to the remote host from the developer machines.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7f039f2a-0cfd-4404-b346-78190cf63b4c&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:4,&amp;quot;hash&amp;quot;:&amp;quot;76babcaa-cab0-4480-8507-b5b34963fcda&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-debugger-execution&#34;&gt;Debugger Execution&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;806a7025-1ec1-4126-982f-3bf7c83531b8&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;The debugger runs the application within a dedicated debugging server&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;The process blocks, awaiting attachment by the debugger client&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;The debugger process listens on a specific TCP/IP network port, referred to as a debug port&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:4,&amp;quot;hash&amp;quot;:&amp;quot;0e325adf-9b00-4e6b-b655-c8c1d1273cb7&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-controlling-program-execution&#34;&gt;Controlling Program Execution&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;bde0ef70-cfa0-47d4-8415-a94df60c277c&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Debugging clients (e.g., VSCode, GoLand, JetBrains) connect via the debug port. Clients issue commands for various debugging tasks like setting breakpoints, displaying local variables and function arguments, printing CPU register contents, etc.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:4,&amp;quot;hash&amp;quot;:&amp;quot;4e33b23b-99e7-47fb-965c-a4ad0c16148a&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-remote-debugging-with-debug-port&#34;&gt;Remote Debugging with Debug Port&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;bba71797-e7ac-45b7-9821-593be4f452a0&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Remote debugging enables debugging on diverse environments, configurations, or architectures. Useful for troubleshooting specific scenarios or hardware/software related issues that cannot be replicated locally.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6c156180-0c50-4e3a-a8a6-f528ffcecde0&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9cb16568-df09-423a-9620-06a015eec13f&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-access-control&#34;&gt;Access Control&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;4c8ec086-34cc-43f6-9859-7bb6234c0e8c&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-restricting-for-ldap-users&#34;&gt;Restricting for LDAP Users&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a273ae87-4c85-419a-817f-0039525eceef&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;During debugging sessions, users attach the debugger to the application to intervene in program execution and gather debug information. This would also mean trying to identify and resolve bugs in the program. This means to get access to some sensitive service information if allowed for every user. So restricting to LDAP users (service developers/owners) is important to ensure minimum security.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;599ec47d-a7c4-42dd-a781-b925786dc85f&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-secure-ssh-connection&#34;&gt;Secure SSH Connection&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;38427b55-698d-4f88-88a4-78f359534d9f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;For remote debugging, a secure SSH connection is established between local and remote systems. This will allow for local port forwarding and redirects debug requests through an SSH tunnel. This tunnel would ensure encrypted communication and secure data transmission.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;bb70ee8d-23cc-4787-be91-df79467c43d5&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-ssh-authorization&#34;&gt;SSH Authorization&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d20f9558-dc9c-4679-88b3-f14a328f9b18&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;To begin an SSH connection, users need the correct password linked to the “slatedev” account. This password is a randomly generated 16-digit code in the file within the service container. The password is generated during the container’s startup before the main service application runs. This Password is accessible only to the container access group, which is service owner LDAP. LDAP users can access the password through Compute CLI, enabling them to establish SSH connections and perform debugging tasks. Compute CLI ensures restricted access to Non-LDAP users, which doesn’t allow password access.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d2dcd9cb-9e60-4927-9709-437e6f52778a&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e4f7db46-498e-45ce-9a76-67083c5cd789&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-limitations&#34;&gt;Limitations&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3128df24-147b-4c41-8b29-e565ced347e4&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Remote debugging on production infra has limitations about dynamic modifications, so it’s limited to read-only&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Large iteration time, as each change involves build, deploy, and test&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9f25985c-b82e-493a-b23b-da0ee9452de6&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;877f5b6c-03ed-4e6d-b459-307eed84a616&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-local-debugging-using-slate-attach&#34;&gt;Local Debugging using SLATE Attach&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0b458a84-2d3d-45bc-8464-f0d2bed998fd&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Remote Debugging allows for read-only debugging on production infrastructure. Being in production infra allows for seamless connections with upstream and downstream services/tools. For a developer it’s very important to experience a debuggable environment with faster iteration to fix and test the same. This gap can be filled by creating a local debugging experience in connection with production upstream and downstream services. SLATE Attach fills this gap and allows for rapid development on attaching local environments.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;26b16577-aec0-4ede-b886-8e3dca0e20a7&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-high-level-goals-0&#34;&gt;High-level Goals&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;fab90a26-f7ff-4ba3-82c2-50b17f1338fa&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The main goal is to reduce the code-deploy-test cycle (and hence, the time to validate iterative changes), by providing E2E testing with local development instances (laptop or dev machine), ensuring production isolation and safety.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;2c391ff7-243f-46bf-a671-3db9d374c1b9&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-iteration-cycle&#34;&gt;Iteration Cycle&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8becb5e9-ce3d-486a-83eb-7d6a7c54f055&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The iteration cycle in this context is the time between making the code change and validating them. The smaller the iteration cycle, the more efficient the use of developers’ time for end-to-end validation of subsequent changes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8e50f42c-6c02-4846-8e0b-52e2012bda37&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090430,&amp;quot;sizeSlug&amp;quot;:&amp;quot;full&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;794ef73a-e926-428b-97fe-b11a0f4ed15e&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-full&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;820&#34; height=&#34;221&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig4.jpeg&#34; alt=&#34;&#34; class=&#34;wp-image-1090430&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=820,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig4.jpeg 820w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig4.jpeg 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig4.jpeg 768w&#34; sizes=&#34;(max-width: 820px) 100vw, 820px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Fig 4: Iteration steps for development using SLATE.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c7f6664e-80ae-48c8-8431-59dac8c806ee&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;5ed47996-ad37-4c32-921b-1d59850ed524&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-need-for-slate-attach&#34;&gt;Need for SLATE Attach&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5e842c0b-9224-423e-87d0-5b0498fefe01&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Iterative development generates a build binary at a faster pace&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Reduced code-deploy-test cycle&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Faster identification and resolution of local, E2E failures&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Faster setup time&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Avoid the need for service changes or onboarding&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ebecbddf-739b-4bf3-8027-63cc10028542&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2feec9ce-de38-4282-bd46-8f8ed6b46b64&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-design-0&#34;&gt;Design&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c0f6f7d6-1ae8-4a46-a3a9-2e6e569f3bfc&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;This design aims to introduce a SLATE proxy that handles all the test requests aimed at SLATE instances for local debugging. These requests will then be redirected to the appropriate local developer machine for debugging and development. This allows users to iterate faster and improve developers’ productivity.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ad3a7aa8-a42a-49e2-a3f7-0ec4812f3deb&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;This feature could be enabled mainly in 2 contexts in SLATE environment lifecycle:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;ordered&amp;quot;:true,&amp;quot;hash&amp;quot;:&amp;quot;d122ed7f-f7b0-49b6-9be0-cedaae60ec26&amp;quot;,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;SLATE Control plane&lt;/strong&gt; that maps local laptop/devpod to a slate environment&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;Test Request Data plane&lt;/strong&gt; that redirects the requests to developers’ laptops&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;879353b5-bf5f-4dbd-a4b6-a90907c4a437&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;fc0e575f-51cb-45c2-8ea1-2b00b9bd027c&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-control-plane&#34;&gt;Control Plane&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0a982fcd-aefc-447e-9ac7-9a83e9877ae9&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The main feature of the control plane is to enable services running in local laptops or devpods to attach to a SLATE environment. The local laptop/devpod that intends to run the service has to attach local environment credentials to a SLATE environment so that test requests are routed locally. The prerequisite for this attachment is to create a SLATE environment. This will allow mapping updates in routing control DB and local routing DB.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9f9c73ee-1938-4f29-8e82-827493504e86&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090431,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;a7fc2c6a-5999-43b2-b636-04ec980e468e&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;560&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig5-1024x560.jpg&#34; alt=&#34;&#34; class=&#34;wp-image-1090431&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig5.jpg 1024w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig5.jpg 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig5.jpg 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1036,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig5.jpg 1036w&#34; sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Fig 5: Request Call flow for testing code running on developer machines&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0fc0d21b-6a51-4ba0-912f-e4a1ece3b94a&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:4,&amp;quot;hash&amp;quot;:&amp;quot;68ef7376-005b-4c34-8ca9-8d91c2071b73&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-call-flow&#34;&gt;Call flow&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;ordered&amp;quot;:true,&amp;quot;hash&amp;quot;:&amp;quot;4d4c2d52-cb99-49a9-a1dc-22f53a3c5c2a&amp;quot;,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;User initiates SLATE attach from local laptop/devpod&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;The SLATE CLI calls Attach() API of SLATE Backend&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;SLATE Backend fetches the Proxy information (host:port) from SLATE Proxy&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;SLATE Backend updates the routing override in routing control DB using the fetched proxy info&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;User initiates the SSH Session using the Cerberus CLI&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Cerberus gateway adds the mapping of deputized tenancy/UUID to the laptop credentials in Flipr DB and creates a SSH session for the laptop&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:4,&amp;quot;hash&amp;quot;:&amp;quot;33cbd3ba-84e6-4fb7-b51f-c32368b85ec3&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-routing-control-db&#34;&gt;Routing Control DB&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3091a315-341a-4ac2-8c3d-aa18ad2dfa66&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Routing Control DB maps test tenancy to routing overrides and user account UUIDs to test tenancy. It stores the SLATE Proxy host:port against the service under test and ensures that all requests targeting a particular SLATE environment, reaches SLATE Proxy. SLATE Proxy finally routes the request to the development instance running in the user’s machine.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h4 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:4,&amp;quot;hash&amp;quot;:&amp;quot;1af3bcce-3d51-4a3b-af45-fd2f0aa37403&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-local-routing-db&#34;&gt;Local Routing DB&lt;/h4&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;fa9af186-07d9-4578-9ab9-6352df586e83&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Local routing DB contains the development instance’s credentials that have been attached to the SLATE environment. SLATE Proxy interacts with the local routing DB to fetch routing credentials and finally routes the request to service-under-test running in local environment&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ae9e74db-9b41-4a46-ba9d-d600c0350856&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;714ae8c2-f980-4c03-9133-3981f34c4945&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-data-plane&#34;&gt;Data Plane&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3c12e2f9-9a26-4969-a929-e66e5b9a207d&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;This section mainly talks about the flow of test requests from different clients (mobile, studio, web, etc.). This data plane mainly involves 2 entities: routing override header and host tenancy mapping. The below diagram indicates how different test requests reach a local laptop through the SLATE proxy. The control plane ensures routing override and host mapping maintained in different databases.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0cc4187b-d85a-4b70-be55-c158994fefdb&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090432,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;5b649275-8ac1-4340-b0e8-a19be825d309&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;520&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig6-1024x520.jpeg&#34; alt=&#34;&#34; class=&#34;wp-image-1090432&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig6.jpeg 1024w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig6.jpeg 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig6.jpeg 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig6.jpeg 1300w&#34; sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Fig 6: Proxy setup for routing test requests to developer machines.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d0682e8a-4e5e-4860-bf0a-27125c9e134a&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d5a8b75c-9546-48e7-aeab-107b253f5169&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Above is the test request flow targeted for local laptop with production upstreams and downstreams:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;ordered&amp;quot;:true,&amp;quot;hash&amp;quot;:&amp;quot;4ea9f2b6-a6c3-452e-9629-1505324f32c8&amp;quot;,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Test account request originates from mobile client&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;E2E test proxy retrieves routing override and injects the routing header to the test request&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;The test request propagates through production services via Mutley until the request has service 3 target&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;The request redirects to SLATE proxy as the routing override has slate proxy host:port against service 3&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;SLATE proxy forwards the request to an open port on Cerberus-gateway based on a host:port config in the Cerberus-deputy Flipr namespace, set by the user when running the Cerberus CLI&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;The Cerberus-gateway forwards the request to the user’s local development machine for the user to debug&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;From the local laptop, the request will be finally forwarded to production downstreams through Cerberus&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;c1062a3f-701f-40f2-8416-7ccd43c088cb&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-limitations-0&#34;&gt;Limitations&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7d9da5c3-f6e2-4fb8-b038-71dbe8495dad&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Running a service locally may not be feasible for some complex services, as they need support for some dependencies like spanners that can only exist in production infra&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;This is limited to test requests as it enables dynamic changing of requests and in turn secures production traffic&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Requests timeout on longer wait for a debug request in local&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f205b844-fe96-41cf-a695-c12f79b9e330&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;86cb82b0-8d3f-4afe-b4a8-e46ab6edf12d&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-impact&#34;&gt;Impact&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4af528af-4339-4de0-b65a-ba6a68054d0e&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Plug-and-play development environment to improve developer productivity&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Ability to create local experiences that co-work with production for developers&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Increase Developer Velocity: Production debugging can help developers identify and fix issues more efficiently&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;db759f9c-b972-4bf3-85c6-106704f28b6c&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090433,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;f769cc84-59fb-4db5-b270-85f9cc38bc6c&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;280&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig7-1024x280.jpeg&#34; alt=&#34;&#34; class=&#34;wp-image-1090433&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig7.jpeg 1024w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig7.jpeg 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig7.jpeg 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1536,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig7.jpeg 1536w, https://blog.uber-cdn.com/cdn-cgi/image/width=1680,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Fig7.jpeg 1680w&#34; sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Fig 7. Impact figures for improving developer velocity using SLATE attach feature.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;92748031-56ec-41fe-af5f-e28c13872b72&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;089b91b9-e785-426b-9acc-98c513dbecb7&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-what-s-next&#34;&gt;What’s Next&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0fab3aae-e3c1-4f43-b6cd-31314da60b97&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;SLATE Sniffer to debug issues by monitoring&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;25ad3857-16be-4803-b58a-19203bd4ff77&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The remote and local debugging mainly allow for test requests to debug. There is a need for observability on production, beyond logs that come up in uMonitor Tool. We aim to create this observability precisely and on-demand using SLATE Sniffer.&amp;nbsp; The main goals of SLATE Sniffer include:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9512a824-5d47-4526-b7b9-a3da8258f058&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Capture the request and responses as a filter of a service and UUID&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Ability to support and filter on Production and Test requests&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f11a73c1-4e1a-40b2-96a4-987bfccd4683&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;a623f4dc-0808-4f1f-a5c6-a75a520f8f0e&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-conclusion&#34;&gt;Conclusion&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c06ce4bc-9946-41bd-95b1-37c27416e5ee&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Our objective is to enhance the SLATE platform, positioning it as the primary tool for debugging production issues. The debugging features integrated into SLATE strike a balance between security and developers’ requirements. SLATE has introduced a new paradigm for developers’ code-related activities and service bootstrapping. We are looking forward to collaborating with different teams to shift the quality left and create visibility on potential issues at the early stage of development.&lt;/p&gt;</description>
      <pubDate>Tue, 18 Jun 2024 07:21:37 +0000</pubDate>
    </item>
    <item>
      <title>【Uber Becomes Kotlin™ Foundation Silver Member】Uber 成为 Kotlin™ 基金会银牌会员</title>
      <link>https://www.uber.com/blog/kotlin-foundation-member/</link>
      <description>【&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;cd81ddf8-27e7-426b-b866-2d19a66fc3e1&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We’re delighted to share that Uber has joined the Kotlin&lt;sup&gt;™&lt;/sup&gt; Foundation as a Silver Member.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;dc1d204f-7133-45b2-96ff-7326758a23d7&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Uber’s commitment to Kotlin is evident in our codebase. We are actively contributing to the Kotlin ecosystem, including the development of integrations for Kotlin with build systems like Buck, Bazel, and Gradle. Uber has also contributed to Detekt’s development and initiated the creation of its compiler plugin version.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5d4fb310-7787-406c-a524-8145ce7ecae3&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote data-wp-block-name=&#34;core/quote&#34; data-wp-block=&#34;{&amp;quot;style&amp;quot;:{&amp;quot;elements&amp;quot;:{&amp;quot;link&amp;quot;:{&amp;quot;color&amp;quot;:{&amp;quot;text&amp;quot;:&amp;quot;var:preset|color|#000000&amp;quot;}}}},&amp;quot;backgroundColor&amp;quot;:&amp;quot;white&amp;quot;,&amp;quot;textColor&amp;quot;:&amp;quot;#000000&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;de75d915-c1c9-4c97-935d-bc15fa762908&amp;quot;,&amp;quot;value&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;wp-block-quote has-000000-color has-white-background-color has-text-color has-background has-link-color wp-elements-267bc928adce8748455de4dd6b36c501 is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;style&amp;quot;:{&amp;quot;elements&amp;quot;:{&amp;quot;link&amp;quot;:{&amp;quot;color&amp;quot;:{&amp;quot;text&amp;quot;:&amp;quot;var:preset|color|#000000&amp;quot;}}}},&amp;quot;textColor&amp;quot;:&amp;quot;#000000&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;e8c0dfde-0553-4ca2-9d27-ad30145ff700&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34; class=&#34;has-000000-color has-text-color has-link-color wp-elements-529663472951b895d728ed42ff0c690e&#34;&gt;“We are thrilled to join the Kotlin Foundation, underscoring our commitment to the Kotlin community and our belief in Kotlin as a core part of the tech stack that has helped make Uber successful. We have millions of lines of Kotlin code and hundreds of enthusiastic developers writing in it daily. As early adopters, starting back in 2018, and active contributors, we are proud to have helped mature the ecosystem and look forward to continued collaboration with this vibrant, friendly, and innovative community.” &lt;/p&gt;&#xA;&lt;cite&gt;Ty Smith, Principal Engineer at Uber&lt;/cite&gt;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;095b5ccb-f24d-4c9d-9529-fae2d34a27a0&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b82673f7-16fc-4ac0-b7a0-bccd3394b345&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Beyond contributing to Kotlin, Uber helped establish the enterprise Java-to-Kotlin working group, a collaboration among Meta, Google, JetBrains, and Uber, with the goal of providing companies with the tooling and expertise needed to migrate large legacy Java codebases to Kotlin.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0d0f569e-95d4-4f88-a09a-713508a90d86&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;As a Silver Member, Uber will play a crucial role in supporting the Foundation’s initiatives, including the Grants program for open-source library authors and the Kotlin Multiplatform Contest for students. We are excited to collaborate with the Kotlin Foundation on future projects.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;47f332a3-e5e8-4509-a511-fdfe6fd4438d&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Visit the Kotlin Foundation &lt;a href=&#34;http://kotlinfoundation.org/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;website&lt;/a&gt; to learn more about the important work being done in support of the Foundation’s mission.&lt;/p&gt;】&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;cd81ddf8-27e7-426b-b866-2d19a66fc3e1&#34;,&#34;dropCap&#34;:false}&#34;&gt;我们很高兴与大家分享，Uber 已作为银牌会员加入 Kotlin&lt;sup&gt;™&lt;/sup&gt; 基金会。 &lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;dc1d204f-7133-45b2-96ff-7326758a23d7&#34;,&#34;dropCap&#34;:false}&#34;&gt;Uber 的承诺Kotlin 在我们的代码库中很明显。我们正在积极为 Kotlin 生态系统做出贡献，包括开发 Kotlin 与 Buck、Bazel 和 Gradle 等构建系统的集成。 Uber 还为 Detekt 的开发做出了贡献，并发起了其编译器插件版本的创建。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;5d4fb310-7787-406c-a524-8145ce7ecae3&#34;,&#34;opacity&#34;:&#34;alpha 通道&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote data-wp-block-name=&#34;core/quote&#34; data-wp-block=&#34;{&#34;style&#34;:{&#34;elements&#34;:{&#34;link&#34;:{&#34;color&#34;:{&#34;text&#34;:&#34;var:预设|颜色|#000000&#34;}}}}，&#34;背景颜色&#34;：&#34;白色&#34;，&#34;文本颜色&#34;：&#34;#000000&#34;，&#34;哈希&#34;：&#34;de75d915-c1c9-4c97-935d-bc15fa762908&#34;，&#34;值&#34;：&#34; “}” class =“wp-block-quote has-000000-color has-white-background-color has-text-color has-background has-link-color wp-elements-267bc928adce8748455de4dd6b36c501 is-layout-flow wp-block-引用是布局流&#34;&gt;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;style&#34;:{&#34;elements&#34;:{&#34;link&#34;:{&#34;color&#34;:{&#34;text&#34;:&#34;var:预设|颜色|#000000&#34;}}}}，&#34;textColor&#34;：&#34;#000000&#34;，&#34;哈希&#34;：&#34;e8c0dfde-0553-4ca2-9d27-ad30145ff700&#34;，&#34;dropCap&#34;：false}&#34; class=&#34;has-000000 -color has-text-color has-link-color wp-elements-529663472951b895d728ed42ff0c690e&#34;&gt;“我们很高兴加入 Kotlin 基金会，强调了我们对 Kotlin 社区的承诺以及我们对 Kotlin 作为技术堆栈核心部分的信念：帮助 Uber 取得了成功。我们每天有数百万行 Kotlin 代码和数百名热情的开发人员使用它进行编写。作为从 2018 年开始的早期采用者和积极的贡献者，我们很自豪能够帮助成熟生态系统，并期待与这个充满活力、友好和创新的社区继续合作。” &lt;/p&gt;&#xA;&lt;cite&gt;Ty Smith，Uber 首席工程师&lt;/cite&gt;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;095b5ccb-f24d-4c9d-9529-fae2d34a27a0&#34;,&#34;opacity&#34;:&#34;alpha-channel&#34;}&#34;类=“wp-block-separator有-alpha-channel-opacity”&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;b82673f7-16fc-4ac0-b7a0-bccd3394b345&#34;,&#34;dropCap&#34;:false}&#34;&gt;超越贡献Kotlin、Uber 帮助建立了企业 Java 到 Kotlin 工作组，这是 Meta、Google、JetBrains 和 Uber 之间的合作，目标是为公司提供将大型遗留 Java 代码库迁移到 Kotlin 所需的工具和专业知识。&lt;/ p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;0d0f569e-95d4-4f88-a09a-713508a90d86&#34;,&#34;dropCap&#34;:false}&#34;&gt;作为银牌作为成员，Uber 将在支持基金会的举措方面发挥至关重要的作用，包括针对开源库作者的资助计划和针对学生的 Kotlin 多平台竞赛。我们很高兴能与 Kotlin 基金会在未来的项目上进行合作。&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&#34;hash&#34;:&#34;47f332a3-e5e8-4509-a511-fdfe6fd4438d&#34;,&#34;dropCap&#34;:false}&#34;&gt;访问 Kotlin基金会&lt;a href=&#34;http://kotlinfoundation.org/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;网站&lt;/a&gt;，详细了解为支持基金会使命而开展的重要工作。&lt;/ p&gt;</description>
      <pubDate>Wed, 22 May 2024 18:37:07 +0000</pubDate>
    </item>
    <item>
      <title>【Personalized Marketing at Scale: Uber’s Out-of-App Recommendation System】大规模个性化营销：Uber 的应用外推荐系统</title>
      <link>https://www.uber.com/blog/personalized-marketing-at-scale/</link>
      <description>【&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;ed846de2-1f8d-4c8a-ac75-16404c880b37&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-introduction&#34;&gt;Introduction&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;cceddfbd-0b50-4e8e-84be-d756460ae988&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Out-of-app (OOA) communication (such as email, push, and SMS) is an important growth lever at Uber. It allows marketers, product owners, and operation teams to connect with users on a plethora of topics, including user promotions, new and favorite restaurants, etc. Building a system to personalize these communications presents unique and exciting challenges. In this blog post, we walk through these challenges and our journey in tackling them.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;03e1b597-f2a8-4f0b-a775-851cd064f322&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9ebb35aa-f3b0-43a7-b17d-5cbfc2d79f7d&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-challenges-nbsp&#34;&gt;Challenges&amp;nbsp;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;67137cec-8a0f-490d-be5c-6cda7ac5f415&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-lack-of-recommendation-context&#34;&gt;Lack of Recommendation Context&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5d2b2ed0-45cf-47de-b769-f4fc911d0509&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The first challenge is the lack of user context in OOA communications. At the core of these personalized communications are restaurant recommendations and merchant offer recommendations. These recommendations are highly local (i.e., users can only order from nearby restaurants). In standard product recommendation systems, ‌users are shown recommendations as they enter the app. Both the user’s location and intentions are often known. On the other hand, recommendations in OOA communications are pushed proactively to ‌users for nondeterministic future viewing. Ensuring that recommendations stay relevant, even in the absence of critical user context, is a major challenge for our system.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;e874f2c8-2e58-4694-99e4-04ebe7da8e26&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-incorporating-campaign-objectives&#34;&gt;Incorporating Campaign Objectives&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0171d53d-19bd-4ce8-bdd2-eedae77753c6&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The second challenge is that recommendations in OOA communications need to be relevant to both the end users and the context of the communications. An email on membership benefits should include exclusive restaurant’s promotions, while an email celebrating the city’s neighborhoods should highlight locals’ favorite restaurants.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;27ee3c76-2839-4ca1-b5c6-5dc89a45f0c6&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-system-costs&#34;&gt;System Costs&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;eaab7c9d-c1d4-4a3d-b1e8-22bf8b90696d&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Lastly, being able to tackle the above challenges at scale and in a cost-effective manner is another challenge to us. The system is currently responsible for over 4 billion personalized messages to our users across all geographic areas and lines of business. There are three major cost areas for producing OOA recommendations:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;12156d58-31bd-4f26-b70f-02fd4aec1613&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;Online Feature Store&lt;/strong&gt;: This involves expenses related to the storage, retrieval, and management of features used in the recommendation system. The online feature store facilitates the quick access and processing of user, item, and interaction features, which is critical for real-time personalization. The costs here are driven by the need for scalable, high-performance databases that can handle large volumes of data with low latency.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;Online Prediction:&lt;/strong&gt; Running complex models for real-time predictions incurs significant costs. These models, which are more sophisticated than those in our previous architecture, require substantial computational resources for continuous data processing and analysis. The expenses associated with the computing power necessary to run these models, including server costs, and the maintenance and scaling of additional computational resources for experiment’s purpose.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;High Throughput and Broad Audiences:&lt;/strong&gt; The expansion to cater to a larger audience and handle higher message throughput further escalates costs. As the system scales to accommodate more users and a wider range of marketing scenarios, the infrastructure must also scale. To process the real-time personalization of more than billions of messages, the necessary throughput can reach 10 times that of in-app recommendation systems.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8a402395-ce3c-4ed9-98ae-d7400cb6667f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Managing these costs effectively is crucial for the sustainability of our new architecture, necessitating a balance between performance, scalability, and cost-efficiency. Techniques like optimizing algorithms for better performance, utilizing cost-effective auto-scaling infrastructure, and optimizing feature strategies can significantly aid controlling these expenses.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;bfe5520e-eb36-4acd-909b-47bde72db240&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0f440374-91eb-437a-8e22-4c19a2e4f18f&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-nbsp-architecture-overview-nbsp&#34;&gt;&amp;nbsp;Architecture Overview&amp;nbsp;&lt;/h2&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;width&amp;quot;:&amp;quot;700px&amp;quot;,&amp;quot;height&amp;quot;:&amp;quot;auto&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;2de9b098-7848-4076-afba-9713096e01a9&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXfgrQtPFPJjdzvNKpMosLG74j6oOD8dEA602cpHo6_OeMD6HJ-2NJBPXMWB5ApZFJASs1SRJCniWle1RK8JOjxusx10elXiP1mdX2oHl6sdV17iS2d-Ijaz4z4P0_QNXdyx5bPRRD-1FXDVhpS9ghLK0q8?key=DgmRI0YIzHZkraGCSk9ZeA&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 1: Marketing Personalizer Architecture.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;cbaa68b5-c46f-4152-b4e3-60f872581454&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5e2ff2bb-f82f-4eca-baf2-576608e00782&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Candidate Retrieval&lt;/strong&gt;: This process involves identifying a broad set of potential recommendations for each user. Using a first-pass ranking algorithm based on location, the system scans through a vast pool of items, considering various factors like user history, store popularity, and contextual data to retrieve a preliminary list of candidate recommendations.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;bb2430de-a4de-4de2-9c59-1f84d1443cfc&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;em&gt;Core technology: Local Graph (Uber’s Knowledge Graph)&amp;nbsp;&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;52036fc8-9616-431c-8e8e-15c6c21f16e4&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Blending&lt;/strong&gt;: Once candidates are retrieved, they undergo a filtering and blending process. The step weeds out less relevant or undesirable options based on predefined business rules and criteria. It ensures that the final recommendations align with both the user’s preferences and any business constraints.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a275add5-873c-42ee-882e-4e48760d38c6&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;em&gt;Core technology: &lt;/em&gt;&lt;a href=&#34;https://github.com/google/cel-spec&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;&lt;em&gt;CEL-based&lt;/em&gt;&lt;/a&gt;&lt;em&gt; rule engine&lt;/em&gt; (using &lt;a href=&#34;https://www.uber.com/blog/flipr/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Flipr&lt;/a&gt;)&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7bd3044a-9b81-4f15-8315-de39752a0266&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Ranking&lt;/strong&gt;: In the ranking stage, the candidates are ranked to determine their order of presentation to the user. This ranking is based on a full set of ranking features that evaluate the relevance of each item to the user’s context and preferences. The aim is to position the most pertinent and appealing recommendations at the top, maximizing the likelihood of user engagement.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5502e588-bf09-4ecc-a8ec-46a6c3a68349&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;em&gt;Core technology: &lt;a href=&#34;https://www.uber.com/blog/palette-meta-store-journey/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Palette Feature Store&lt;/a&gt;, &lt;a href=&#34;https://www.uber.com/blog/michelangelo-machine-learning-platform/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Michelangelo&lt;/a&gt;&amp;nbsp;&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3f34a9c3-40c0-40fa-b569-fd478055ea9c&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6163dfc0-f673-43d0-9ed3-6574b234f47e&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-solution-formulation-nbsp&#34;&gt;Solution Formulation&amp;nbsp;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7c96cb0a-f90f-422d-9ac1-b73cd0a32aef&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;To address our three primary challenges, we introduced enhancements to each portion of our architecture to provide relevant and thematically consistent content to users in an efficient and scalable system. We discuss each of these enhancements in detail below.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;49b01814-2a13-4341-b689-c32430a241a2&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;b74a42c6-e441-470f-94ca-0a009c268465&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-candidate-list-generation-nbsp&#34;&gt;Candidate List Generation&amp;nbsp;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ccdd7bcf-fca4-424d-8c0b-cb3d98a1d325&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;A unique portion of recommendations on Uber Eats is candidate lists that are highly localized to a user’s location. When users open the Uber Eats app, they are recommended restaurants, grocery, and retail stores that can deliver to either their current location or their most recent order location. For our OOA recommendation system, this crucial context is missing from our candidate list generation. We developed two solutions to overcome this impediment.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;867291d7-4276-4314-b997-9a97c187790f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;For general recommendation use cases, we developed an ML solution to determine which neighborhood a user was most likely to receive an order in next. As our system supports marketing campaigns for frequent, infrequent, and new Uber Eats users, this ML solution required integration of high and low throughput signals from both the Uber Eats and Uber apps over multiple-year time horizons. To ensure the scalability of this solution to the hundreds of millions of Uber users campaign owners communicate with, we focused on reducing these signals to a small set of ~10 features which the ML solution utilized to define a user’s next likely order location. With this likely location, user’s candidate lists are generated by finding all restaurants, grocery, or retail stores that deliver to this location.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;91c2b91c-36f0-4466-9d1f-cdc94dc0c322&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;While this base solution provides crucial context for our OOA recommendation system, it does not always provide the correct context for every campaign. In campaign settings where the user is likely traveling (e.g., Airport Trips, Uber Reserve, Uber for Business) the aforementioned ML solution will likely not have the necessary context to reflect the user’s recent behavioral changes. In this setting, we utilize an event-based override which updates the user’s candidate list to contain restaurants, grocery, and retail stores that deliver to their most recent neighborhood. By updating this candidate list, we increase the relevancy of communications for users and provide campaign owners the flexibility to control these candidate lists to ensure thematic consistency for their campaigns.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;22025f48-b703-42d4-8aa8-714960881c7d&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Together, these solutions inject critical user metadata into the user’s candidate list, ensuring our recommendations are relevant to users and reflect their recent behavior. By providing a general ML solution for all Uber users, campaign owners can have confidence that user’s candidate lists are accurate and can accommodate their campaign objectives.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e6acfcde-5908-47b1-9bed-44186846eb9d&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;bff409bf-2801-40e0-8fe2-15b13673bc25&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-first-pass-ranking&#34;&gt;First Pass Ranking&lt;/h3&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;width&amp;quot;:&amp;quot;700px&amp;quot;,&amp;quot;height&amp;quot;:&amp;quot;auto&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;7fc71338-1e9b-4a17-95d7-51cac79d83d0&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXcpvTCnINAXH7xDcMWM5D7jUOEVwOrEsKKugQ4byxZxyT47qLsOM8tcHZwRhy6n-0YCXX4AbYrvS80h2tFTkka94fyYIEZpYxFZ_rrFj5GuBBpvEZlgEkgWSC7Qnrawk0sHnUfLyH4p1OpyapRuYIsUI1IM?key=DgmRI0YIzHZkraGCSk9ZeA&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 2: first-pass ranking.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e19636ed-8eed-45bb-afa0-e4985aff33d0&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;eef1f569-4102-4907-ab17-00a4a866b0c7&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The primary goal of the first-pass ranking is to quickly reduce the set of all eligible candidate merchants to a smaller set of potential merchants for each user. This helps conserve system bandwidth and reduces machine learning-related costs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a404e10f-c69d-4d87-b450-ac79ced27b0f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;After retrieving all the candidates based on the user’s location, we initiate a preliminary filtering process. This phase excludes candidates based on criteria like unavailability and invalid deliverability (such as cross-border merchants).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7e45baef-353d-4708-825c-12ed9b7c08b7&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In certain campaigns, we display a variety of restaurant types. To refine our selection, candidates undergo additional filtering tailored to specific use cases. For example, our primary recommendation strategy is to assess the relevance of candidates based on the user’s past interactions with Uber Eats. We also introduce candidates that are offering promotions, and inspire users by recommending candidates from restaurants they haven’t ordered from but might find appealing.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7cf9b299-8d27-4a19-9152-32931102c91a&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;For each of these use cases, we apply a low-cost scoring function to all eligible candidate merchants. The function is a simple linear combination over a small set of features, including ‌past interactions between the user and merchant. The weights are tuned to maximize the recall metrics.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e1e9c760-cb6a-4e08-8376-d0fea6e5ad55&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Finally, to ensure a varied selection for the user, we run a deduplication process. This step removes candidates belonging to the same parent chain, avoiding repetitive recommendations.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6c9e32e6-116e-42a0-8948-12b945dc3946&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;6d33a86b-c8ea-4b12-a20d-5a727c70fa64&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-second-pass-ranking&#34;&gt;Second Pass Ranking&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;93cb1bfc-14c3-4bc1-a518-b4f4621b2526&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The objective of the second ranking stage is to rank the small set of merchants retrieved from the first-pass ranking to maximize the likelihood of user engagement. To do so, we utilize features that capture a user’s past order history, in-app and out-of-app engagement, and the merchant’s quality, reliability, and affordability. Many of these features are also utilized by the home feed ranking system and are shared via Uber’s Online Feature Store, &lt;a href=&#34;https://www.uber.com/blog/palette-meta-store-journey/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Palette&lt;/a&gt;. By sharing feature sets across recommendation services, we promote parity in the user experience across in-app and out-of-app surfaces. These features are utilized inside a learning-to-rank LTR modeling framework with custom relevancy weights to encourage desirable user behaviors.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9b9ade24-3b90-443e-b035-3ffd92252682&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;While ‌user-centric features are rich for frequent users, they are often not available for new and churned users. As the OOA system caters heavily to the infrequent user segment, we have to rely on long-dated user signals in order to provide good recommendations. Moreover, we need to be able to store and use such signals in a cost-efficient manner. To overcome this challenge with restaurant recommendations, we constructed a lightweight feature set summarizing a user’s cuisine preferences over the entirety of their Uber Eats history. At Uber, we label each restaurant with a set of cuisines that the merchant serves, which we utilize to create a feature vector summarizing the user’s cuisine preferences. We update this feature daily with a Bayesian update logic and upweight recent orders to reflect the user’s recent behavioral changes. Incorporating this feature in our second pass ranking system drove a 4% lift in email’s CTR in recent online experimentation.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a1c3dd21-e4c7-459a-9bab-9ab34e711597&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Many of the features utilized in our second pass ranking system effectively summarize a user’s past order behavior but do not reveal which restaurants a user may be interested in trying next. Due to the geographic constraints of orders on Uber Eats, it can be difficult for collaborative recommendation system techniques to learn restaurant similarity. For example, two restaurants in different neighborhoods may serve similar dishes at similar prices but have no common customers due to their geographic differences. While learning restaurant similarity is difficult through collaborative based approaches, utilizing content based recommendation approaches with the restaurant’s cuisine labels provides an opportunity to learn restaurant similarities and encourages users to explore new restaurants on Uber Eats. We posit that users will be interested in new restaurants that serve cuisines that are similar to cuisines they have ordered in the past. Building on this premise, we conducted an analysis to quantify the similarity between cuisines. We performed spectral clustering on a regularized cuisine co-occurrence matrix that captured which cuisines were frequently served by the same restaurant. From this clustering exercise we found that while there are hundreds of cuisines a merchant can serve, these cuisines fall into a small number of natural groupings. In Figure 3, we visualize the embedding vectors for each cuisine mapped to a two-dimensional space via t-SNE, which highlights these natural cuisine clusters.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e71ad85b-0f8f-447c-ab04-1b2d3ea03ede&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;0a0e33b5-6874-4c16-821a-0e174f469461&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXclTIOVrXS9GosD3MlTmw3WJ6vNDCKLZ5P8yDa5Fru2bv4mhA4sGVo29-KyGWF7GZpO8axvCO52o_w_Xs4IwW_wW3rYodhyYhan-2PRcl5NBdd6mBWGKWIQifmwnWmtHePk-5xBREjN3xNW10pp9C54_As?key=DgmRI0YIzHZkraGCSk9ZeA&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 3: Cuisine categorization based on similarity analysis.&amp;nbsp;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;33a54c0d-7108-4057-9705-1c9b550ca5df&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0f70a1cc-aae9-44d0-967e-6de3fbb43c43&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;These groupings motivated us to smooth each user’s cuisine preference feature according to these cuisine similarities. Utilizing this smoothed feature vector in our second pass ranking system provided our system an exploration lever, encouraging users to try new cuisines similar to cuisines they enjoy while maintaining recommendation relevancy. In addition to this exploration lever, these groupings also provided us an opportunity to reduce system costs. By embedding the cuisine preference feature according to these cuisine groupings, we reduced the size of this feature 10x, mitigating online storage costs while maintaining the majority of the feature’s signal. Moreover, by utilizing a lightweight embedding scheme, we are able to perform this feature embedding efficiently through simple distributed matrix multiplication, which can be carried out in any standard ETL pipeline framework.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;447774ed-d9f0-46fa-a859-0bac001d49ab&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;By building a lightweight feature set summarizing a user’s cuisine preferences across their entire Uber Eats history, we provide crucial context to our second pass ranking model. This context provides our recommendation system with an exploration lever, encouraging users to explore new cuisines and merchants, and ensures that infrequent Uber Eats users receive relevant restaurant recommendations. By embedding these cuisine preference features, we can greatly reduce online storage costs and ensure that the recommendation system can support campaigns targeting any cohort of the Uber user base.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a6cae821-5d45-41bf-aef6-48d4edfa98e3&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;76ebb488-7b65-40ac-ab1a-88f6b96ca159&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-re-ranking-amp-blending-nbsp&#34;&gt;Re-Ranking &amp;amp; Blending&amp;nbsp;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;06c7bba6-99f2-4105-9aee-e9f6225e38da&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;As CRM communication comes from different internal stakeholders, the system needs a mechanism to tailor ‌the embedded recommendations toward different brand strategies and marketing priorities. Hence, we introduce a re-ranking and blending layer post the ML-based second-pass ranking. For example, we allow stakeholders to enhance merchants’ visibility (Figure 4) based on specific marketing strategies.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a0b0297a-639f-4b7d-a344-c6d091834bf5&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;6a83af6f-44cb-45d0-af65-7b0e07253ba0&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXfaBCsP7f9PtQJIas64-wKhFJSRYAN7bn0uOjMvJfrKrAmIK-BN5YuVxqKTy2UWASUp8PwClRpu5GsXceUirADVn2Wpy_I-N3953rek6wl5T1Yxx_pmchFXQFMzWlvSp2EyzPa4ac565MAjz5TaPqNAujEa?key=DgmRI0YIzHZkraGCSk9ZeA&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 4: enhance the visibility of selected merchants.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;559a6e0f-bfa6-4a19-a49b-b94f12375893&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;67ed7887-a83c-41e8-986d-bb8688edef88&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Through our configuration engine, local marketing teams can define their own strategies flexibly and with minimal work. This is enabled by the automated hierarchical configuration merge and override at different geographical region levels. For example, New York City can inherit most of the re-ranking strategies with the US, but the NYC local marketing team can apply some partial overrides on specific parameters. Figure 5 demonstrates the configurations to enhance the selected merchants shown in Figure 4.&lt;/p&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;width&amp;quot;:&amp;quot;700px&amp;quot;,&amp;quot;height&amp;quot;:&amp;quot;auto&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;0873a777-dbb9-4b07-b267-6021290d2a47&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXdJ5NWHGLcrbj4jUtlNt2EQ5D2ZC11o_EJnaOArqzUgVf3-iKqGbyrULBZ5OpxAH_H7OrkQhFrFBn5sNlYOCtq6gW8elbCvzVAPLf7f42NxPVeqDomvf54fiS5myotklOMEPHLi15npddLftZtdb6pGmGrf?key=DgmRI0YIzHZkraGCSk9ZeA&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 5: configurations to enhance selected merchants with hierarchical overrides.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2dac800f-5bb4-4c8e-b06f-53580fd7858e&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;2f2886cd-1104-4288-9426-b09972626633&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-next-steps&#34;&gt;Next Steps&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;09b861ab-c5bc-4d76-8407-84817f05c3eb&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;While much of the early work focused on surfacing merchant recommendations, the need for personalized marketing at Uber extends beyond our delivery business. The next steps for our platform to bring the same personalization capabilities to the other lines of business, particularly Rider and Earner communications. To better serve these new business surfaces, the team has plans to expand, as well as sourcing from partner teams at Uber, our personalized content repository. The new developments include dynamic creatives to unify the personalized recommendations and other marketing creatives; personalized travel recommendations; and personalized earning opportunities to drive marketplace demand and supply.&amp;nbsp;&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a023a443-c2cb-4aa8-b211-d60c4cad2bba&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-acknowledgements&#34;&gt;Acknowledgements&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5084df9e-a3a4-4e68-af96-016201be90c0&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;This would not have been possible without the contribution of multiple Growth and Marketing teams. We’d like to thank the following folks for their contributions: Isabella Huang, Ajit Pawar, Apoorv Sharma, Jennifer Li, Hari Thadakamalla, Cameron Kalegi, Nikhil Anantharaman, Vladimir Schipunov, Denis Perino, Shelley Hatting, April Chu, Nora Murphy, Fernanda Gomes, Abby Blecker, Carolina Aprea, Marie Oquet, Ann Parden, Michael Tam.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;93180c87-77f2-4ab5-824d-f5fa7e71da01&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Special thanks to our tech partners on the LocalGraph team (Jiaxin Lin, Kaymyar Arbabifard, Santosh Golecha), Delivery Intelligence team (Yifan Ma, Tiejun Wang), Michelangelo team (Jin Sun, Paarth Chothani, Nicholas Marcott, Victoria Wu), and Offers &amp;amp; Affordability team (Shirley Ye, Boyang Li, Jun Yao) for helping us design the system and leverage Uber-wide AI building blocks.&lt;/p&gt;】&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;ed846de2-1f8d-4c8a-ac75-16404c880b37&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-introduction&#34;&gt;Introduction&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;cceddfbd-0b50-4e8e-84be-d756460ae988&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Out-of-app (OOA) communication (such as email, push, and SMS) is an important growth lever at Uber. It allows marketers, product owners, and operation teams to connect with users on a plethora of topics, including user promotions, new and favorite restaurants, etc. Building a system to personalize these communications presents unique and exciting challenges. In this blog post, we walk through these challenges and our journey in tackling them.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;03e1b597-f2a8-4f0b-a775-851cd064f322&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9ebb35aa-f3b0-43a7-b17d-5cbfc2d79f7d&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-challenges-nbsp&#34;&gt;Challenges&amp;nbsp;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;67137cec-8a0f-490d-be5c-6cda7ac5f415&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-lack-of-recommendation-context&#34;&gt;Lack of Recommendation Context&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5d2b2ed0-45cf-47de-b769-f4fc911d0509&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The first challenge is the lack of user context in OOA communications. At the core of these personalized communications are restaurant recommendations and merchant offer recommendations. These recommendations are highly local (i.e., users can only order from nearby restaurants). In standard product recommendation systems, ‌users are shown recommendations as they enter the app. Both the user’s location and intentions are often known. On the other hand, recommendations in OOA communications are pushed proactively to ‌users for nondeterministic future viewing. Ensuring that recommendations stay relevant, even in the absence of critical user context, is a major challenge for our system.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;e874f2c8-2e58-4694-99e4-04ebe7da8e26&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-incorporating-campaign-objectives&#34;&gt;Incorporating Campaign Objectives&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0171d53d-19bd-4ce8-bdd2-eedae77753c6&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The second challenge is that recommendations in OOA communications need to be relevant to both the end users and the context of the communications. An email on membership benefits should include exclusive restaurant’s promotions, while an email celebrating the city’s neighborhoods should highlight locals’ favorite restaurants.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;27ee3c76-2839-4ca1-b5c6-5dc89a45f0c6&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-system-costs&#34;&gt;System Costs&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;eaab7c9d-c1d4-4a3d-b1e8-22bf8b90696d&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Lastly, being able to tackle the above challenges at scale and in a cost-effective manner is another challenge to us. The system is currently responsible for over 4 billion personalized messages to our users across all geographic areas and lines of business. There are three major cost areas for producing OOA recommendations:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;12156d58-31bd-4f26-b70f-02fd4aec1613&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;Online Feature Store&lt;/strong&gt;: This involves expenses related to the storage, retrieval, and management of features used in the recommendation system. The online feature store facilitates the quick access and processing of user, item, and interaction features, which is critical for real-time personalization. The costs here are driven by the need for scalable, high-performance databases that can handle large volumes of data with low latency.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;Online Prediction:&lt;/strong&gt; Running complex models for real-time predictions incurs significant costs. These models, which are more sophisticated than those in our previous architecture, require substantial computational resources for continuous data processing and analysis. The expenses associated with the computing power necessary to run these models, including server costs, and the maintenance and scaling of additional computational resources for experiment’s purpose.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;High Throughput and Broad Audiences:&lt;/strong&gt; The expansion to cater to a larger audience and handle higher message throughput further escalates costs. As the system scales to accommodate more users and a wider range of marketing scenarios, the infrastructure must also scale. To process the real-time personalization of more than billions of messages, the necessary throughput can reach 10 times that of in-app recommendation systems.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8a402395-ce3c-4ed9-98ae-d7400cb6667f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Managing these costs effectively is crucial for the sustainability of our new architecture, necessitating a balance between performance, scalability, and cost-efficiency. Techniques like optimizing algorithms for better performance, utilizing cost-effective auto-scaling infrastructure, and optimizing feature strategies can significantly aid controlling these expenses.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;bfe5520e-eb36-4acd-909b-47bde72db240&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0f440374-91eb-437a-8e22-4c19a2e4f18f&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-nbsp-architecture-overview-nbsp&#34;&gt;&amp;nbsp;Architecture Overview&amp;nbsp;&lt;/h2&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;width&amp;quot;:&amp;quot;700px&amp;quot;,&amp;quot;height&amp;quot;:&amp;quot;auto&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;2de9b098-7848-4076-afba-9713096e01a9&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXfgrQtPFPJjdzvNKpMosLG74j6oOD8dEA602cpHo6_OeMD6HJ-2NJBPXMWB5ApZFJASs1SRJCniWle1RK8JOjxusx10elXiP1mdX2oHl6sdV17iS2d-Ijaz4z4P0_QNXdyx5bPRRD-1FXDVhpS9ghLK0q8?key=DgmRI0YIzHZkraGCSk9ZeA&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 1: Marketing Personalizer Architecture.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;cbaa68b5-c46f-4152-b4e3-60f872581454&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5e2ff2bb-f82f-4eca-baf2-576608e00782&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Candidate Retrieval&lt;/strong&gt;: This process involves identifying a broad set of potential recommendations for each user. Using a first-pass ranking algorithm based on location, the system scans through a vast pool of items, considering various factors like user history, store popularity, and contextual data to retrieve a preliminary list of candidate recommendations.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;bb2430de-a4de-4de2-9c59-1f84d1443cfc&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;em&gt;Core technology: Local Graph (Uber’s Knowledge Graph)&amp;nbsp;&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;52036fc8-9616-431c-8e8e-15c6c21f16e4&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Blending&lt;/strong&gt;: Once candidates are retrieved, they undergo a filtering and blending process. The step weeds out less relevant or undesirable options based on predefined business rules and criteria. It ensures that the final recommendations align with both the user’s preferences and any business constraints.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a275add5-873c-42ee-882e-4e48760d38c6&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;em&gt;Core technology: &lt;/em&gt;&lt;a href=&#34;https://github.com/google/cel-spec&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;&lt;em&gt;CEL-based&lt;/em&gt;&lt;/a&gt;&lt;em&gt; rule engine&lt;/em&gt; (using &lt;a href=&#34;https://www.uber.com/blog/flipr/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Flipr&lt;/a&gt;)&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7bd3044a-9b81-4f15-8315-de39752a0266&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Ranking&lt;/strong&gt;: In the ranking stage, the candidates are ranked to determine their order of presentation to the user. This ranking is based on a full set of ranking features that evaluate the relevance of each item to the user’s context and preferences. The aim is to position the most pertinent and appealing recommendations at the top, maximizing the likelihood of user engagement.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5502e588-bf09-4ecc-a8ec-46a6c3a68349&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;em&gt;Core technology: &lt;a href=&#34;https://www.uber.com/blog/palette-meta-store-journey/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Palette Feature Store&lt;/a&gt;, &lt;a href=&#34;https://www.uber.com/blog/michelangelo-machine-learning-platform/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Michelangelo&lt;/a&gt;&amp;nbsp;&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3f34a9c3-40c0-40fa-b569-fd478055ea9c&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6163dfc0-f673-43d0-9ed3-6574b234f47e&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-solution-formulation-nbsp&#34;&gt;Solution Formulation&amp;nbsp;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7c96cb0a-f90f-422d-9ac1-b73cd0a32aef&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;To address our three primary challenges, we introduced enhancements to each portion of our architecture to provide relevant and thematically consistent content to users in an efficient and scalable system. We discuss each of these enhancements in detail below.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;49b01814-2a13-4341-b689-c32430a241a2&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;b74a42c6-e441-470f-94ca-0a009c268465&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-candidate-list-generation-nbsp&#34;&gt;Candidate List Generation&amp;nbsp;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ccdd7bcf-fca4-424d-8c0b-cb3d98a1d325&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;A unique portion of recommendations on Uber Eats is candidate lists that are highly localized to a user’s location. When users open the Uber Eats app, they are recommended restaurants, grocery, and retail stores that can deliver to either their current location or their most recent order location. For our OOA recommendation system, this crucial context is missing from our candidate list generation. We developed two solutions to overcome this impediment.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;867291d7-4276-4314-b997-9a97c187790f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;For general recommendation use cases, we developed an ML solution to determine which neighborhood a user was most likely to receive an order in next. As our system supports marketing campaigns for frequent, infrequent, and new Uber Eats users, this ML solution required integration of high and low throughput signals from both the Uber Eats and Uber apps over multiple-year time horizons. To ensure the scalability of this solution to the hundreds of millions of Uber users campaign owners communicate with, we focused on reducing these signals to a small set of ~10 features which the ML solution utilized to define a user’s next likely order location. With this likely location, user’s candidate lists are generated by finding all restaurants, grocery, or retail stores that deliver to this location.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;91c2b91c-36f0-4466-9d1f-cdc94dc0c322&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;While this base solution provides crucial context for our OOA recommendation system, it does not always provide the correct context for every campaign. In campaign settings where the user is likely traveling (e.g., Airport Trips, Uber Reserve, Uber for Business) the aforementioned ML solution will likely not have the necessary context to reflect the user’s recent behavioral changes. In this setting, we utilize an event-based override which updates the user’s candidate list to contain restaurants, grocery, and retail stores that deliver to their most recent neighborhood. By updating this candidate list, we increase the relevancy of communications for users and provide campaign owners the flexibility to control these candidate lists to ensure thematic consistency for their campaigns.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;22025f48-b703-42d4-8aa8-714960881c7d&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Together, these solutions inject critical user metadata into the user’s candidate list, ensuring our recommendations are relevant to users and reflect their recent behavior. By providing a general ML solution for all Uber users, campaign owners can have confidence that user’s candidate lists are accurate and can accommodate their campaign objectives.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e6acfcde-5908-47b1-9bed-44186846eb9d&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;bff409bf-2801-40e0-8fe2-15b13673bc25&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-first-pass-ranking&#34;&gt;First Pass Ranking&lt;/h3&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;width&amp;quot;:&amp;quot;700px&amp;quot;,&amp;quot;height&amp;quot;:&amp;quot;auto&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;7fc71338-1e9b-4a17-95d7-51cac79d83d0&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXcpvTCnINAXH7xDcMWM5D7jUOEVwOrEsKKugQ4byxZxyT47qLsOM8tcHZwRhy6n-0YCXX4AbYrvS80h2tFTkka94fyYIEZpYxFZ_rrFj5GuBBpvEZlgEkgWSC7Qnrawk0sHnUfLyH4p1OpyapRuYIsUI1IM?key=DgmRI0YIzHZkraGCSk9ZeA&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 2: first-pass ranking.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e19636ed-8eed-45bb-afa0-e4985aff33d0&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;eef1f569-4102-4907-ab17-00a4a866b0c7&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The primary goal of the first-pass ranking is to quickly reduce the set of all eligible candidate merchants to a smaller set of potential merchants for each user. This helps conserve system bandwidth and reduces machine learning-related costs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a404e10f-c69d-4d87-b450-ac79ced27b0f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;After retrieving all the candidates based on the user’s location, we initiate a preliminary filtering process. This phase excludes candidates based on criteria like unavailability and invalid deliverability (such as cross-border merchants).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7e45baef-353d-4708-825c-12ed9b7c08b7&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In certain campaigns, we display a variety of restaurant types. To refine our selection, candidates undergo additional filtering tailored to specific use cases. For example, our primary recommendation strategy is to assess the relevance of candidates based on the user’s past interactions with Uber Eats. We also introduce candidates that are offering promotions, and inspire users by recommending candidates from restaurants they haven’t ordered from but might find appealing.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7cf9b299-8d27-4a19-9152-32931102c91a&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;For each of these use cases, we apply a low-cost scoring function to all eligible candidate merchants. The function is a simple linear combination over a small set of features, including ‌past interactions between the user and merchant. The weights are tuned to maximize the recall metrics.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e1e9c760-cb6a-4e08-8376-d0fea6e5ad55&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Finally, to ensure a varied selection for the user, we run a deduplication process. This step removes candidates belonging to the same parent chain, avoiding repetitive recommendations.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6c9e32e6-116e-42a0-8948-12b945dc3946&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;6d33a86b-c8ea-4b12-a20d-5a727c70fa64&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-second-pass-ranking&#34;&gt;Second Pass Ranking&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;93cb1bfc-14c3-4bc1-a518-b4f4621b2526&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The objective of the second ranking stage is to rank the small set of merchants retrieved from the first-pass ranking to maximize the likelihood of user engagement. To do so, we utilize features that capture a user’s past order history, in-app and out-of-app engagement, and the merchant’s quality, reliability, and affordability. Many of these features are also utilized by the home feed ranking system and are shared via Uber’s Online Feature Store, &lt;a href=&#34;https://www.uber.com/blog/palette-meta-store-journey/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Palette&lt;/a&gt;. By sharing feature sets across recommendation services, we promote parity in the user experience across in-app and out-of-app surfaces. These features are utilized inside a learning-to-rank LTR modeling framework with custom relevancy weights to encourage desirable user behaviors.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9b9ade24-3b90-443e-b035-3ffd92252682&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;While ‌user-centric features are rich for frequent users, they are often not available for new and churned users. As the OOA system caters heavily to the infrequent user segment, we have to rely on long-dated user signals in order to provide good recommendations. Moreover, we need to be able to store and use such signals in a cost-efficient manner. To overcome this challenge with restaurant recommendations, we constructed a lightweight feature set summarizing a user’s cuisine preferences over the entirety of their Uber Eats history. At Uber, we label each restaurant with a set of cuisines that the merchant serves, which we utilize to create a feature vector summarizing the user’s cuisine preferences. We update this feature daily with a Bayesian update logic and upweight recent orders to reflect the user’s recent behavioral changes. Incorporating this feature in our second pass ranking system drove a 4% lift in email’s CTR in recent online experimentation.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a1c3dd21-e4c7-459a-9bab-9ab34e711597&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Many of the features utilized in our second pass ranking system effectively summarize a user’s past order behavior but do not reveal which restaurants a user may be interested in trying next. Due to the geographic constraints of orders on Uber Eats, it can be difficult for collaborative recommendation system techniques to learn restaurant similarity. For example, two restaurants in different neighborhoods may serve similar dishes at similar prices but have no common customers due to their geographic differences. While learning restaurant similarity is difficult through collaborative based approaches, utilizing content based recommendation approaches with the restaurant’s cuisine labels provides an opportunity to learn restaurant similarities and encourages users to explore new restaurants on Uber Eats. We posit that users will be interested in new restaurants that serve cuisines that are similar to cuisines they have ordered in the past. Building on this premise, we conducted an analysis to quantify the similarity between cuisines. We performed spectral clustering on a regularized cuisine co-occurrence matrix that captured which cuisines were frequently served by the same restaurant. From this clustering exercise we found that while there are hundreds of cuisines a merchant can serve, these cuisines fall into a small number of natural groupings. In Figure 3, we visualize the embedding vectors for each cuisine mapped to a two-dimensional space via t-SNE, which highlights these natural cuisine clusters.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e71ad85b-0f8f-447c-ab04-1b2d3ea03ede&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;0a0e33b5-6874-4c16-821a-0e174f469461&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXclTIOVrXS9GosD3MlTmw3WJ6vNDCKLZ5P8yDa5Fru2bv4mhA4sGVo29-KyGWF7GZpO8axvCO52o_w_Xs4IwW_wW3rYodhyYhan-2PRcl5NBdd6mBWGKWIQifmwnWmtHePk-5xBREjN3xNW10pp9C54_As?key=DgmRI0YIzHZkraGCSk9ZeA&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 3: Cuisine categorization based on similarity analysis.&amp;nbsp;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;33a54c0d-7108-4057-9705-1c9b550ca5df&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0f70a1cc-aae9-44d0-967e-6de3fbb43c43&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;These groupings motivated us to smooth each user’s cuisine preference feature according to these cuisine similarities. Utilizing this smoothed feature vector in our second pass ranking system provided our system an exploration lever, encouraging users to try new cuisines similar to cuisines they enjoy while maintaining recommendation relevancy. In addition to this exploration lever, these groupings also provided us an opportunity to reduce system costs. By embedding the cuisine preference feature according to these cuisine groupings, we reduced the size of this feature 10x, mitigating online storage costs while maintaining the majority of the feature’s signal. Moreover, by utilizing a lightweight embedding scheme, we are able to perform this feature embedding efficiently through simple distributed matrix multiplication, which can be carried out in any standard ETL pipeline framework.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;447774ed-d9f0-46fa-a859-0bac001d49ab&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;By building a lightweight feature set summarizing a user’s cuisine preferences across their entire Uber Eats history, we provide crucial context to our second pass ranking model. This context provides our recommendation system with an exploration lever, encouraging users to explore new cuisines and merchants, and ensures that infrequent Uber Eats users receive relevant restaurant recommendations. By embedding these cuisine preference features, we can greatly reduce online storage costs and ensure that the recommendation system can support campaigns targeting any cohort of the Uber user base.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a6cae821-5d45-41bf-aef6-48d4edfa98e3&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;76ebb488-7b65-40ac-ab1a-88f6b96ca159&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-re-ranking-amp-blending-nbsp&#34;&gt;Re-Ranking &amp;amp; Blending&amp;nbsp;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;06c7bba6-99f2-4105-9aee-e9f6225e38da&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;As CRM communication comes from different internal stakeholders, the system needs a mechanism to tailor ‌the embedded recommendations toward different brand strategies and marketing priorities. Hence, we introduce a re-ranking and blending layer post the ML-based second-pass ranking. For example, we allow stakeholders to enhance merchants’ visibility (Figure 4) based on specific marketing strategies.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a0b0297a-639f-4b7d-a344-c6d091834bf5&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;6a83af6f-44cb-45d0-af65-7b0e07253ba0&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXfaBCsP7f9PtQJIas64-wKhFJSRYAN7bn0uOjMvJfrKrAmIK-BN5YuVxqKTy2UWASUp8PwClRpu5GsXceUirADVn2Wpy_I-N3953rek6wl5T1Yxx_pmchFXQFMzWlvSp2EyzPa4ac565MAjz5TaPqNAujEa?key=DgmRI0YIzHZkraGCSk9ZeA&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 4: enhance the visibility of selected merchants.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;559a6e0f-bfa6-4a19-a49b-b94f12375893&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;67ed7887-a83c-41e8-986d-bb8688edef88&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Through our configuration engine, local marketing teams can define their own strategies flexibly and with minimal work. This is enabled by the automated hierarchical configuration merge and override at different geographical region levels. For example, New York City can inherit most of the re-ranking strategies with the US, but the NYC local marketing team can apply some partial overrides on specific parameters. Figure 5 demonstrates the configurations to enhance the selected merchants shown in Figure 4.&lt;/p&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;width&amp;quot;:&amp;quot;700px&amp;quot;,&amp;quot;height&amp;quot;:&amp;quot;auto&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;0873a777-dbb9-4b07-b267-6021290d2a47&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXdJ5NWHGLcrbj4jUtlNt2EQ5D2ZC11o_EJnaOArqzUgVf3-iKqGbyrULBZ5OpxAH_H7OrkQhFrFBn5sNlYOCtq6gW8elbCvzVAPLf7f42NxPVeqDomvf54fiS5myotklOMEPHLi15npddLftZtdb6pGmGrf?key=DgmRI0YIzHZkraGCSk9ZeA&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 5: configurations to enhance selected merchants with hierarchical overrides.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2dac800f-5bb4-4c8e-b06f-53580fd7858e&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;2f2886cd-1104-4288-9426-b09972626633&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-next-steps&#34;&gt;Next Steps&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;09b861ab-c5bc-4d76-8407-84817f05c3eb&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;While much of the early work focused on surfacing merchant recommendations, the need for personalized marketing at Uber extends beyond our delivery business. The next steps for our platform to bring the same personalization capabilities to the other lines of business, particularly Rider and Earner communications. To better serve these new business surfaces, the team has plans to expand, as well as sourcing from partner teams at Uber, our personalized content repository. The new developments include dynamic creatives to unify the personalized recommendations and other marketing creatives; personalized travel recommendations; and personalized earning opportunities to drive marketplace demand and supply.&amp;nbsp;&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a023a443-c2cb-4aa8-b211-d60c4cad2bba&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-acknowledgements&#34;&gt;Acknowledgements&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5084df9e-a3a4-4e68-af96-016201be90c0&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;This would not have been possible without the contribution of multiple Growth and Marketing teams. We’d like to thank the following folks for their contributions: Isabella Huang, Ajit Pawar, Apoorv Sharma, Jennifer Li, Hari Thadakamalla, Cameron Kalegi, Nikhil Anantharaman, Vladimir Schipunov, Denis Perino, Shelley Hatting, April Chu, Nora Murphy, Fernanda Gomes, Abby Blecker, Carolina Aprea, Marie Oquet, Ann Parden, Michael Tam.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;93180c87-77f2-4ab5-824d-f5fa7e71da01&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Special thanks to our tech partners on the LocalGraph team (Jiaxin Lin, Kaymyar Arbabifard, Santosh Golecha), Delivery Intelligence team (Yifan Ma, Tiejun Wang), Michelangelo team (Jin Sun, Paarth Chothani, Nicholas Marcott, Victoria Wu), and Offers &amp;amp; Affordability team (Shirley Ye, Boyang Li, Jun Yao) for helping us design the system and leverage Uber-wide AI building blocks.&lt;/p&gt;</description>
      <pubDate>Thu, 13 Jun 2024 07:02:17 +0000</pubDate>
    </item>
    <item>
      <title>【Modernizing Logging at Uber with CLP (Part II)】使用 CLP 实现 Uber 日志记录现代化（第二部​​分）</title>
      <link>https://www.uber.com/blog/modernizing-logging-with-clp-ii/</link>
      <description>【&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;76db94ed-6b6e-49c2-98fe-3e96d67a8cc3&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-introduction&#34;&gt;Introduction&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6528f5e9-19a8-4ff7-9a1b-6bf9927f3b68&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;This is the second installment in our series detailing the modernization of Uber’s logging infrastructure using &lt;a href=&#34;https://github.com/y-scope/clp&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;CLP&lt;/a&gt;. &lt;a href=&#34;https://www.uber.com/en-US/blog/reducing-logging-cost-by-two-orders-of-magnitude-using-clp&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;In our last blog&lt;/a&gt;, we described how we split CLP’s compression algorithm into two phases: (1) distributed, row-based streaming compression that produces a compressed intermediate representation on each container or host, and (2) full columnar compression into more efficient archives. We developed a Log4j appender that uses the streaming compression and integrated it into our Spark platform. This resulted in a substantial compression ratio (169:1), which contributed to the resolution of the SSD burnouts caused by writing large amounts of log data while allowing us to extend our log retention period by 10x.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7a97a89e-3344-4301-9c90-c5dbea8fd781&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In collaboration with CLP’s developers, we have further developed an innovative end-to-end system to manage unstructured logs across Uber’s various data and ML platforms. Many log management systems, including the one described in a &lt;a href=&#34;https://www.uber.com/blog/logging/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;previous blog&lt;/a&gt;, tend to focus solely on search and aggregation, which are useful for developers to bootstrap a debugging session (e.g. locating an error event or detecting anomalies occurring at a certain point in time). However, to understand how and why the error occurred, developers need to further view the sequence of logs leading up to the event. Thus, search is only useful if integrated with convenient log-file viewing, a feature often overlooked by existing tools. Our new system includes advanced log viewing and programmable analytics directly on the compressed logs, unlocking the full potential of text logs using CLP.&amp;nbsp; Figure 1 below shows our current end-to-end deployment. Most of the core tools and basic features described in this blog are now &lt;a href=&#34;https://github.com/y-scope/clp&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;open source&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;41b1241d-7607-4a2f-ac57-6511ea24d7c0&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;91cc078d-a2f6-46d1-be6a-0cd1cd0915fa&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXfssVNYjd66JKnkJRxGEC8980IxP8rDsweshb_36DETnG5pGsONCOeY_BJeGEtc4pPq0XZRt7HXSfRmVnLxKn_7_ZkdsZFIJhn5DMsFKPSDxT2qZLPJ8oZEp37_5j2LZ9rs35_WMiWhU9L8pCWB1A2WmraD?key=6KS8UuwM_zrmkURjL-jcyQ&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 1: The Current CLP Ecosystem Deployed At Uber.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e6192bff-7988-4fe5-9610-17d9d528f9f9&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;66341d1f-30f6-4172-a003-f023ad4f5182&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-unstructured-amp-semi-structured-logs-their-role-and-associated-challenges&#34;&gt;Unstructured &amp;amp; Semi-structured Logs: Their Role and Associated Challenges&lt;/h2&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;fe3db487-e486-4e63-a936-0310ca7b8d2c&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXeND5RFoGztFr9Rw7LDu3h96JyG7BnwUrW5bSYIdonxvvbQdidi3IOtd3WaCjGemEh0U3zZsXlfil_8YjtnRdUWpUv6caVAI3gJwX7wUeh3GW79mVzmpcU5AqG0pYFIJZXH7BD0Ap5DvWoMkJu5vr-1E3PM?key=6KS8UuwM_zrmkURjL-jcyQ&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 2: The diversity of logs at Uber and the systems suitable to handle each type.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a64083f3-5338-4818-b252-5fd3ced40aef&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;44d0e2f6-f0ba-44c7-979c-ff24b1e6c2fc&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;At Uber, logs are diverse and exhibit varying degrees of structure, as shown in Figure 2 above. Each unstructured or semi-structured log event is dominated by a single string containing a message intertwined with variable values. Compared to various forms of structured logs, not only are free-text logs convenient with ubiquitous cultural acceptance, they are also used for different purposes. Developers typically use such logs to describe the sequential operation of a system in an effort to allow them to reconstruct the execution flow with some context. In contrast, most structured logs exhibit properties of a trace-point that is used to record certain metrics, significant singular events, and periodic statistical information. In general, structured log events are mostly independent from each other, whereas unstructured log events collectively record an execution based on the code paths that a developer wants to track. Therefore, structured logs are typically used for monitoring purposes (e.g., detecting system errors, whereas unstructured logs are used to debug &lt;strong&gt;why&lt;/strong&gt; the error occurred). This suggests the two types of logs require different types of management solutions.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;460ac7fa-214b-464b-889b-5cb52602ff28&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;When a system is small, it is not too difficult to debug using unstructured logs. Debugging can be done by simply SSH-ing into each node, viewing or grepping the logs, and diagnosing the root cause. However, as the system grows, SSH-ing into hundreds of thousands of nodes becomes unmanageable. Before our initiative, Apache Spark®, YARN®, Flink®, many Hadoop-ecosystem-based platforms, and many ML applications running on top of these platforms used the ancient MapReduce Job History Server to view their logs on each host directly. Uber also had a custom node-browsing interface (similar to SSH), but both of these tools are insufficient at Uber’s current scale. The Job History Server couldn’t scale effectively due to the sheer number of log files overwhelming the file limits of the underlying HDFS storage, coupled with a user interface that was too sluggish and unresponsive to handle the display of typical large log files. The latter method, while available and frequently used by platform maintainers, is cumbersome, insecure at best, and is not exposed to the application end-user. Thus, engineers need better tooling.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d6f453fd-c2c3-438b-9547-a0925ed53ada&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Unfortunately, there are a plethora of observability tools targeted at structured logs, but few targeted at unstructured logs. This is likely because structured logs lend themselves to being stored in a database-like backend where search and analytics can be performed and accelerated via indexing on top of tabular data (we use the term “database” to refer to any data management tool whose primary interface is search; this includes conventional RDBMSes, systems with native JSON support, NoSQL databases like Pinot, and reverse indexing tools such as Apache Lucene® that power a range of tools including Elasticsearch). As a result, developers often try to shoehorn their unstructured logs into the popular observability tool of the day; but since databases are not designed to store and analyze unstructured logs, developers are often left fighting more with the database than debugging their systems. For instance, when storing unstructured data, the database’s indices can quickly balloon in size, leading to a corresponding increase in on-disk storage and memory usage per query. In practice, retaining and searching all of Uber’s unstructured logs in such a tool would be exorbitantly costly. More importantly, it would take away the functionality that users are used to—namely, accessing and quickly viewing and analyzing individual log files.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1106bd23-a421-4d6e-bece-19fd2f33e312&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;42393c34-675c-4750-a146-fc327c4d2758&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-log-viewing&#34;&gt;Log Viewing&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d61ad8ac-0118-473d-8489-0d454515d8d3&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The ability to view and analyze the original log files remains an essential requirement—one that, regrettably, many existing observability tools overlook. To address this, we collaborated with the CLP development team to implement and customize a serverless log viewer that allows users to directly view the compressed logs by decompressing them on the fly, in their browser. Building on top of Microsoft Visual Studio Code’s high performance Monaco editor, the log viewer provides an intuitive and familiar interface for viewing compressed log files.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;528fd8bd-6771-4dd5-9ffc-9491d966cf76&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;9f3b1dd9-7e21-4098-b18a-2aef2df4e0ec&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXdbtS2LwlhA0rgmG8BvTEMHtOZwJQB4lCtLz_odrb-aJ9_4Bu2zISkgoAgXyIy-mzHaq4oD3NtLgO2_hDKn7raUfREPt46MpNbqVf6AFIpC-Kt3FKK2n7sYnLjbnOqxZetGWI37aAOdVU75Z-S2lQNlLL-W?key=6KS8UuwM_zrmkURjL-jcyQ&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 3: Using the log viewer to filter for critical (ERROR or below) log events.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6c8dab47-012f-41b2-99f6-9a3aa7f2b63c&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9b94a194-836e-4819-8a0a-673b6c225900&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;It also has many features specific to logs. For example:&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f2de87b7-9f86-4969-ba3a-2ec92a0de6ea&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;Smart Pagination&lt;/strong&gt; to handle large log files efficiently, ones that would be unwieldy in standard text editors or command-line tools like VIM. The pagination feature lowers the browser’s memory use while allowing other features such as search to work across pages.&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;Log-level Filtering&lt;/strong&gt; to allow engineers to easily hide logs above a certain level. For example, users initially focus on critical errors and then exploratively broaden their view to info-level logs to understand the surrounding context (the log viewer makes sure to keep the cursor on the same log event when toggling between log levels, even though the pagination will change).&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;Advanced Search&lt;/strong&gt; to allow quick queries of substrings or regular expressions (users can click on a result and quickly navigate to the corresponding log event), across the pages of the log file.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;Multi-line Support&lt;/strong&gt; to search and navigate between multi-line events (e.g., stack traces).&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;Synchronized Viewing&lt;/strong&gt; to allow viewing logs side by side, with synchronized scrolling by timestamp for cross-referencing events between different log files.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;Permanent Linking&lt;/strong&gt; where each log event in a compressed log file has a shareable and embeddable permanent link, eliminating the need to copy-paste logs or take screenshots, streamlining collaboration and issue tracking.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;Log Prettification &lt;/strong&gt;to automatically transform minified JSON strings, code snippets, and long lists within log events into a more readable format.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;Text Colorization&lt;/strong&gt; to support various language modes similar to those in Visual Studio Code, along with custom modes tailored to make typical Uber logs more readable.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6bb1a7ee-8736-4897-bec0-b57836512a6a&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The GIF above shows how a user can filter the logs by their log level, and the CLP log viewer correctly recognizes a multi-line ERROR log containing a stack trace as a single log event. The capability to offer these specialized log viewing features stems from the use of CLP to parse and compress the logs, since it automatically identifies the timestamp, log level, variable values, etc.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;bd471bdc-b58a-4cc6-bf29-fcbd3e08fb00&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d46beeef-88b9-4e01-93dc-c8dc740cec57&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-analytics-libraries&#34;&gt;Analytics Libraries&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ea9b9982-ff01-4700-9953-52fed4d6c5af&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In addition to log viewing, which satisfies users’ basic needs, we also offer libraries for users to perform programmable analytics. The core of these libraries is developed in C++ with native bindings for Python, Go, and Java. Since CLP parses the logs as they’re compressed, the library is able to provides users with direct access to structured data such as the Unix epoch timestamp, log type (i.e. the static text portion of a log message), variables within the message, and of course the decompressed log message itself. This approach relieves users from the burden of crafting extra text parsing logic for raw messages and mitigates the runtime performance costs associated with such parsing, particularly for multi-line log messages, allowing them to concentrate on the core logic of their log analytics programs. Today, a diverse set of users use the libraries for various purposes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6078c748-9ac1-4499-a14b-15527429657d&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;For platform maintainers, the analytics library streamlines complex programmatic queries, such as analyzing log types and the frequency of permission errors within a specific application over the past 30 days. Users often conduct substring searches and then apply further aggregation and deduplication logic to the results provided by the CLP analytics library. For instance, users can use the log type of each matching event as a means to identify duplicates, rather than using the decompressed message, which might change due to variable values. This facilitates the grouping of different unstructured log events with similar structures with ease.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;69440122-c73a-44e2-9d43-bfd38fa3a1d0&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;For on-call duties or root-cause analysis, users can create a scripted search that detects a series of specific known problematic log events or sequences of log events that meet user-defined criteria, assisting in swiftly and automatically narrowing down the scope of analysis. When a suspicious log event is identified, users can obtain its permanent link from the CLP log event object and clicking this link takes them directly to the specific matching event within the corresponding log file in the log viewer, for further in-depth analysis.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d302a707-d5dc-4bad-83fb-d7d3171f4d9c&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;For ML teams, the analytics library facilitates the quick extraction and processing of valuable training or inference data from logs, within various environments like Jupyter Notebooks, production scripts, or locally, on a user’s development laptop. Once the analytics results are available, the data can then be used as input for automated scripts, for instance, as part of the next training batch, or compiled into analytical reports for evaluation and decision-making purposes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a3cd1252-d276-4a01-9ef0-b2158def8901&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4c1772f3-4168-4665-82f0-7b15b3deb91e&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-ingesting-a-huge-number-of-log-files&#34;&gt;Ingesting a Huge Number of Log Files&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e95384e3-9a77-440d-9c52-a5ce486b0190&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The initial log ingestion pipeline, reliant on HDFS, had a few significant limitations for our logging workload. First, HDFS couldn’t scale to meet our log retention requirements due to the NameNode struggling to maintain an index of a huge number of small log files. In addition, data access, especially on developers’ laptops or development machines outside of a walled-off production environment, was primarily hindered by complex Kerberos authentication and other access barriers. In contrast, modern object storage solutions like S3 and GCS, designed for massive scalability, can accommodate petabytes of data and billions of objects. These platforms lessen our management load by obviating the need for HDFS cluster maintenance and offer enhanced security features such as encryption at rest and during transit, along with integrated ACLs and other access control features, automatic object lifecycle (i.e., retention time) management as well as providing a higher reliability and availability. We also benefit from the pay-as-you-go model, and the flexibility to significantly boost storage needs temporarily, for instance, extending log retention period following a major security incident. Thus, we switched from uploading and storing logs on HDFS to storing them in an object store.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;da78559c-f87a-4182-bd84-04dcaf2f998a&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;One key distinction between HDFS and common object stores is that HDFS employs a filesystem hierarchy whereas object stores function as flat key-value stores. Luckily, in large distributed systems, log files typically have a unique, unchanging filesystem path based on the logging entity’s hierarchy in the system, so this path works well as the key for the compressed logs. Furthermore, object stores offer APIs that facilitate key access in a manner akin to file system navigation, thereby maintaining a familiar log browsing experience.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6996a877-7091-47d2-b2c4-350475b1ed03&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;16491513-72b3-4ed5-a386-c5ef95924897&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-ensuring-and-guaranteeing-log-freshness&#34;&gt;Ensuring and Guaranteeing Log Freshness&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f49b6443-1f9a-4671-99e5-63f4c47d439d&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Services like YARN and streaming applications, including Flink jobs, are typically designed for prolonged execution and are only shut down infrequently, in the event of failures, hardware replacements, or upgrades. Consequently, log uploads can’t be deferred until the “end” of a job as was feasible in Phase I with shorter-duration Spark applications. Also, object storage systems typically lack support for append operations, posing a challenge for log freshness when dealing with the upload of large log files.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;62ee02cf-af7f-4001-a42b-b8cf16d449d1&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Our log management includes a rotation feature that segments extensive log files into smaller, more practical chunks. We trigger the creation of a new compressed log file when the existing file hits the 16MB mark. The chosen size is a strategic compromise for object stores, maximizing compression ratio, minimizing storage and synchronization overhead while only slightly raising API access costs. Note that despite the small compressed log file size, the high compression ratio means the 16MB chunk of compressed data represents a substantial amount of uncompressed data.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5ef299cc-97e8-4dbf-99f7-b9528e5ee0fa&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;To enhance log collection with near-real-time behavior and resilience, and at the same time minimize API costs associated with each upload request, our log library employs a tailored flush and upload policy specific to logging needs. We initially considered uploading logs every time they were flushed, but by default log libraries flush every time a log event is appended. This is too expensive. The libraries can also be configured to flush periodically, but this is too generic for logs. Ideally, we want an approach that changes depending on the characteristics of the logging workload. For instance, uploading sooner when important log events (e.g., ERROR-level) occur or uploading when there’s an absence of logs for a certain period of time.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;21525a1a-2bdf-4024-832e-ad8306c2cfdb&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Our uploading policy can be summarized as follows. Upon logging an event, the file should be uploaded after some delay 𝑆, but 𝑆 can be pushed to a later time if more log events occur before the delay expires. We call this a soft deadline. In contrast, we also maintain a hard deadline 𝐻 such that there is a guaranteed delay 𝐻 before the file is uploaded (𝐻 should be longer than 𝑆). For example, if 𝑆 is set to 10 seconds and 𝐻 is 300 seconds, it means when an event 𝐸 gets logged at time 𝑇 , it will be uploaded at 𝑇 + 10 if no other event arrives between [𝑇, 𝑇 + 10]. Otherwise, 𝐸’s upload will be delayed, but no later than 𝑇 + 300. These delays are configurable per log level, such that, for example, a user can set shorter deadlines for ERROR events than INFO ones. The delays also get reset once an upload occurs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;302ba9e4-c9a9-4820-98b1-f9a30fb54ffe&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ad9c3c07-702a-47bf-bd8b-49d59d5cabbf&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-effective-log-file-filtering-with-tags&#34;&gt;Effective Log File Filtering with Tags&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;11c30aa9-7b8e-4c8e-b484-5c898440a638&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Uber operates a huge number of internal services across various platforms, each of which has dozens of users running many jobs per day. Users often have advanced knowledge of system failures and their timing, thanks to comprehensive metrics and monitoring from integrated platform facilities or external monitoring tools. Therefore, in the majority of cases, users want to immediately limit their log search and viewing to a specific subset of compressed logs (e.g., those from a specific job, application, user, time slice, and their combination).&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2283eabd-3f10-4ead-a35e-a5a5f6067d09&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Our system enables flexible tagging of compressed logs with multiple identifiers, such as service ID, job ID, app ID, user ID, and timestamp range. Tags can be incorporated into object store file paths, recorded in external databases, or simply attached as object metadata and maintained by the object store. The user interface for searching and viewing logs leverages these tags allowing CLP to efficiently narrow down the log files relevant to each user’s search or viewing request.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4465a582-3b90-4aa0-9204-dd8936a0d444&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e43d1e1c-806e-4b05-86d1-9f6c6a8ff0c2&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-cross-platform-integration-of-clp&#34;&gt;Cross-platform Integration of CLP&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e0482a90-2fa8-4a25-bc62-36e165ce898a&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Our initial integration of CLP was with Spark, leveraging a re-implementation of CLP’s C++ code-base in Java for rapid integration with Spark’s default logging framework (Log4j). Its success, reliability, and user experience improvement led to integration requests from other platform teams and application end-users, including many Marketplace and ML teams. However, this integration path posed a challenge for adoption across different applications using other logging frameworks such as Logback and other programming languages, such as Python. Instead, we utilized Foreign Function Interface (FFI) libraries for various languages (including Java, Go, and Python) that interact with the CLP’s C++ library via native bindings. By integrating these into various logging libraries for each language, we were able to integrate CLP’s distributed streaming compression seamlessly into the platform team’s codebase without needing to change the application code.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;519717f8-0716-4280-9a05-ae71ccad20f3&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c4fcd6a9-5a0f-4416-b31d-b962a308fbb3&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-impact&#34;&gt;Impact&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;57736e6e-dc15-4f0c-b021-7c9722cfc1ef&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The cost-effective, distributed CLP compression and ingestion pipeline has become the preferred log ingestion and management solution for Uber’s Data team. As mentioned in our &lt;a href=&#34;https://www.uber.com/en-US/blog/reducing-logging-cost-by-two-orders-of-magnitude-using-clp&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;previous blog&lt;/a&gt;, this system has facilitated the effortless increase of our log retention period to the industry-standard 30 days, significantly reducing concerns over storage costs, maintenance complexity and availability. Furthermore, the log viewer and programmatic analysis features have gained popularity amongst end-users like the ML and Marketplace teams, as well as the platform maintained within Uber’s Data team. For example, the open-source Python CLP log analytics library has been downloaded 141,880 times, and the Python logging library plugin has seen 4,845 downloads in the last six months. The higher download rate of the analytics library reflects its wider use among engineers who analyze logs (“consumers”), compared to the number of service owners who implement the logging library plugin (“producers”).&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4dd9bc34-626e-4d42-9757-8c381d680bc0&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;73a1cf48-ddff-4d5c-9f5d-815d3d6ae174&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-next-steps&#34;&gt;Next Steps&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1b8044df-1dd5-484d-a4a7-f385671d60d0&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We aim to focus our future efforts on three key areas:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;db092b3d-8001-4283-8ca6-7bb9b6613f83&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Observability Platform Integration&lt;/strong&gt;:&amp;nbsp; Integrating CLP with the observability team’s existing log-collection infrastructure, which operates outside of application containers, reducing the severity of log loss during OOM scenarios and capturing logs not directly produced by applications (e.g., bash scripts). User experience can also be enhanced by unifying and streamlining access to both unstructured and structured logs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;502b9e40-7fbc-4a69-80ae-565ec013f0aa&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Migrate Suitable Cold Logs to CLP&lt;/strong&gt;: CLP excels with logs that don’t necessitate near-real-time search capabilities. While CLP is extremely efficient and offers fast search performance, it is not intended to replace existing online indexing-based solutions. Migrating suitable logs to the CLP platform should reduce cost and improve reliability and user experience.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e3f234c6-f2df-4dfc-a911-aa224ab678d3&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Structured Log Support&lt;/strong&gt;: CLP has introduced native support for structured logs, and its effectiveness is documented in an upcoming OSDI ’24 paper showcasing excellent compression and search capabilities for structured log data compared to existing solutions.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;8f0157b0-b2e9-421f-93c8-36572c18ae20&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-conclusion&#34;&gt;Conclusion&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5c5e569b-a21a-42dc-8337-54e3552ef396&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;By seamlessly integrating CLP with advanced features like log viewing, programmable analytics, and efficient log ingestion, Uber has revolutionized our unstructured log management. This comprehensive system not only addresses the challenges of scalability and debugging at Uber’s immense scale but also empowers engineers across various teams with tools that streamline their workflows. As a result, Uber has achieved significant cost savings, improved log retention, and enhanced developer productivity. The open-source availability of core tools and features further solidifies CLP’s impact, fostering broader adoption and innovation within the industry. With ongoing efforts focused on platform integration, log migration, and structured log support, Uber is poised to continue leading the way in efficient and effective log management.&lt;/p&gt;】&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;76db94ed-6b6e-49c2-98fe-3e96d67a8cc3&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-introduction&#34;&gt;Introduction&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6528f5e9-19a8-4ff7-9a1b-6bf9927f3b68&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;This is the second installment in our series detailing the modernization of Uber’s logging infrastructure using &lt;a href=&#34;https://github.com/y-scope/clp&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;CLP&lt;/a&gt;. &lt;a href=&#34;https://www.uber.com/en-US/blog/reducing-logging-cost-by-two-orders-of-magnitude-using-clp&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;In our last blog&lt;/a&gt;, we described how we split CLP’s compression algorithm into two phases: (1) distributed, row-based streaming compression that produces a compressed intermediate representation on each container or host, and (2) full columnar compression into more efficient archives. We developed a Log4j appender that uses the streaming compression and integrated it into our Spark platform. This resulted in a substantial compression ratio (169:1), which contributed to the resolution of the SSD burnouts caused by writing large amounts of log data while allowing us to extend our log retention period by 10x.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7a97a89e-3344-4301-9c90-c5dbea8fd781&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In collaboration with CLP’s developers, we have further developed an innovative end-to-end system to manage unstructured logs across Uber’s various data and ML platforms. Many log management systems, including the one described in a &lt;a href=&#34;https://www.uber.com/blog/logging/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;previous blog&lt;/a&gt;, tend to focus solely on search and aggregation, which are useful for developers to bootstrap a debugging session (e.g. locating an error event or detecting anomalies occurring at a certain point in time). However, to understand how and why the error occurred, developers need to further view the sequence of logs leading up to the event. Thus, search is only useful if integrated with convenient log-file viewing, a feature often overlooked by existing tools. Our new system includes advanced log viewing and programmable analytics directly on the compressed logs, unlocking the full potential of text logs using CLP.&amp;nbsp; Figure 1 below shows our current end-to-end deployment. Most of the core tools and basic features described in this blog are now &lt;a href=&#34;https://github.com/y-scope/clp&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;open source&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;41b1241d-7607-4a2f-ac57-6511ea24d7c0&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;91cc078d-a2f6-46d1-be6a-0cd1cd0915fa&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXfssVNYjd66JKnkJRxGEC8980IxP8rDsweshb_36DETnG5pGsONCOeY_BJeGEtc4pPq0XZRt7HXSfRmVnLxKn_7_ZkdsZFIJhn5DMsFKPSDxT2qZLPJ8oZEp37_5j2LZ9rs35_WMiWhU9L8pCWB1A2WmraD?key=6KS8UuwM_zrmkURjL-jcyQ&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 1: The Current CLP Ecosystem Deployed At Uber.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e6192bff-7988-4fe5-9610-17d9d528f9f9&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;66341d1f-30f6-4172-a003-f023ad4f5182&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-unstructured-amp-semi-structured-logs-their-role-and-associated-challenges&#34;&gt;Unstructured &amp;amp; Semi-structured Logs: Their Role and Associated Challenges&lt;/h2&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;fe3db487-e486-4e63-a936-0310ca7b8d2c&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXeND5RFoGztFr9Rw7LDu3h96JyG7BnwUrW5bSYIdonxvvbQdidi3IOtd3WaCjGemEh0U3zZsXlfil_8YjtnRdUWpUv6caVAI3gJwX7wUeh3GW79mVzmpcU5AqG0pYFIJZXH7BD0Ap5DvWoMkJu5vr-1E3PM?key=6KS8UuwM_zrmkURjL-jcyQ&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 2: The diversity of logs at Uber and the systems suitable to handle each type.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a64083f3-5338-4818-b252-5fd3ced40aef&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;44d0e2f6-f0ba-44c7-979c-ff24b1e6c2fc&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;At Uber, logs are diverse and exhibit varying degrees of structure, as shown in Figure 2 above. Each unstructured or semi-structured log event is dominated by a single string containing a message intertwined with variable values. Compared to various forms of structured logs, not only are free-text logs convenient with ubiquitous cultural acceptance, they are also used for different purposes. Developers typically use such logs to describe the sequential operation of a system in an effort to allow them to reconstruct the execution flow with some context. In contrast, most structured logs exhibit properties of a trace-point that is used to record certain metrics, significant singular events, and periodic statistical information. In general, structured log events are mostly independent from each other, whereas unstructured log events collectively record an execution based on the code paths that a developer wants to track. Therefore, structured logs are typically used for monitoring purposes (e.g., detecting system errors, whereas unstructured logs are used to debug &lt;strong&gt;why&lt;/strong&gt; the error occurred). This suggests the two types of logs require different types of management solutions.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;460ac7fa-214b-464b-889b-5cb52602ff28&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;When a system is small, it is not too difficult to debug using unstructured logs. Debugging can be done by simply SSH-ing into each node, viewing or grepping the logs, and diagnosing the root cause. However, as the system grows, SSH-ing into hundreds of thousands of nodes becomes unmanageable. Before our initiative, Apache Spark®, YARN®, Flink®, many Hadoop-ecosystem-based platforms, and many ML applications running on top of these platforms used the ancient MapReduce Job History Server to view their logs on each host directly. Uber also had a custom node-browsing interface (similar to SSH), but both of these tools are insufficient at Uber’s current scale. The Job History Server couldn’t scale effectively due to the sheer number of log files overwhelming the file limits of the underlying HDFS storage, coupled with a user interface that was too sluggish and unresponsive to handle the display of typical large log files. The latter method, while available and frequently used by platform maintainers, is cumbersome, insecure at best, and is not exposed to the application end-user. Thus, engineers need better tooling.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d6f453fd-c2c3-438b-9547-a0925ed53ada&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Unfortunately, there are a plethora of observability tools targeted at structured logs, but few targeted at unstructured logs. This is likely because structured logs lend themselves to being stored in a database-like backend where search and analytics can be performed and accelerated via indexing on top of tabular data (we use the term “database” to refer to any data management tool whose primary interface is search; this includes conventional RDBMSes, systems with native JSON support, NoSQL databases like Pinot, and reverse indexing tools such as Apache Lucene® that power a range of tools including Elasticsearch). As a result, developers often try to shoehorn their unstructured logs into the popular observability tool of the day; but since databases are not designed to store and analyze unstructured logs, developers are often left fighting more with the database than debugging their systems. For instance, when storing unstructured data, the database’s indices can quickly balloon in size, leading to a corresponding increase in on-disk storage and memory usage per query. In practice, retaining and searching all of Uber’s unstructured logs in such a tool would be exorbitantly costly. More importantly, it would take away the functionality that users are used to—namely, accessing and quickly viewing and analyzing individual log files.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1106bd23-a421-4d6e-bece-19fd2f33e312&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;42393c34-675c-4750-a146-fc327c4d2758&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-log-viewing&#34;&gt;Log Viewing&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d61ad8ac-0118-473d-8489-0d454515d8d3&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The ability to view and analyze the original log files remains an essential requirement—one that, regrettably, many existing observability tools overlook. To address this, we collaborated with the CLP development team to implement and customize a serverless log viewer that allows users to directly view the compressed logs by decompressing them on the fly, in their browser. Building on top of Microsoft Visual Studio Code’s high performance Monaco editor, the log viewer provides an intuitive and familiar interface for viewing compressed log files.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;528fd8bd-6771-4dd5-9ffc-9491d966cf76&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;9f3b1dd9-7e21-4098-b18a-2aef2df4e0ec&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXdbtS2LwlhA0rgmG8BvTEMHtOZwJQB4lCtLz_odrb-aJ9_4Bu2zISkgoAgXyIy-mzHaq4oD3NtLgO2_hDKn7raUfREPt46MpNbqVf6AFIpC-Kt3FKK2n7sYnLjbnOqxZetGWI37aAOdVU75Z-S2lQNlLL-W?key=6KS8UuwM_zrmkURjL-jcyQ&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 3: Using the log viewer to filter for critical (ERROR or below) log events.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6c8dab47-012f-41b2-99f6-9a3aa7f2b63c&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9b94a194-836e-4819-8a0a-673b6c225900&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;It also has many features specific to logs. For example:&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f2de87b7-9f86-4969-ba3a-2ec92a0de6ea&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;Smart Pagination&lt;/strong&gt; to handle large log files efficiently, ones that would be unwieldy in standard text editors or command-line tools like VIM. The pagination feature lowers the browser’s memory use while allowing other features such as search to work across pages.&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;Log-level Filtering&lt;/strong&gt; to allow engineers to easily hide logs above a certain level. For example, users initially focus on critical errors and then exploratively broaden their view to info-level logs to understand the surrounding context (the log viewer makes sure to keep the cursor on the same log event when toggling between log levels, even though the pagination will change).&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;Advanced Search&lt;/strong&gt; to allow quick queries of substrings or regular expressions (users can click on a result and quickly navigate to the corresponding log event), across the pages of the log file.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;Multi-line Support&lt;/strong&gt; to search and navigate between multi-line events (e.g., stack traces).&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;Synchronized Viewing&lt;/strong&gt; to allow viewing logs side by side, with synchronized scrolling by timestamp for cross-referencing events between different log files.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;Permanent Linking&lt;/strong&gt; where each log event in a compressed log file has a shareable and embeddable permanent link, eliminating the need to copy-paste logs or take screenshots, streamlining collaboration and issue tracking.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;Log Prettification &lt;/strong&gt;to automatically transform minified JSON strings, code snippets, and long lists within log events into a more readable format.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;&lt;strong&gt;Text Colorization&lt;/strong&gt; to support various language modes similar to those in Visual Studio Code, along with custom modes tailored to make typical Uber logs more readable.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6bb1a7ee-8736-4897-bec0-b57836512a6a&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The GIF above shows how a user can filter the logs by their log level, and the CLP log viewer correctly recognizes a multi-line ERROR log containing a stack trace as a single log event. The capability to offer these specialized log viewing features stems from the use of CLP to parse and compress the logs, since it automatically identifies the timestamp, log level, variable values, etc.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;bd471bdc-b58a-4cc6-bf29-fcbd3e08fb00&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d46beeef-88b9-4e01-93dc-c8dc740cec57&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-analytics-libraries&#34;&gt;Analytics Libraries&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ea9b9982-ff01-4700-9953-52fed4d6c5af&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In addition to log viewing, which satisfies users’ basic needs, we also offer libraries for users to perform programmable analytics. The core of these libraries is developed in C++ with native bindings for Python, Go, and Java. Since CLP parses the logs as they’re compressed, the library is able to provides users with direct access to structured data such as the Unix epoch timestamp, log type (i.e. the static text portion of a log message), variables within the message, and of course the decompressed log message itself. This approach relieves users from the burden of crafting extra text parsing logic for raw messages and mitigates the runtime performance costs associated with such parsing, particularly for multi-line log messages, allowing them to concentrate on the core logic of their log analytics programs. Today, a diverse set of users use the libraries for various purposes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6078c748-9ac1-4499-a14b-15527429657d&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;For platform maintainers, the analytics library streamlines complex programmatic queries, such as analyzing log types and the frequency of permission errors within a specific application over the past 30 days. Users often conduct substring searches and then apply further aggregation and deduplication logic to the results provided by the CLP analytics library. For instance, users can use the log type of each matching event as a means to identify duplicates, rather than using the decompressed message, which might change due to variable values. This facilitates the grouping of different unstructured log events with similar structures with ease.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;69440122-c73a-44e2-9d43-bfd38fa3a1d0&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;For on-call duties or root-cause analysis, users can create a scripted search that detects a series of specific known problematic log events or sequences of log events that meet user-defined criteria, assisting in swiftly and automatically narrowing down the scope of analysis. When a suspicious log event is identified, users can obtain its permanent link from the CLP log event object and clicking this link takes them directly to the specific matching event within the corresponding log file in the log viewer, for further in-depth analysis.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d302a707-d5dc-4bad-83fb-d7d3171f4d9c&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;For ML teams, the analytics library facilitates the quick extraction and processing of valuable training or inference data from logs, within various environments like Jupyter Notebooks, production scripts, or locally, on a user’s development laptop. Once the analytics results are available, the data can then be used as input for automated scripts, for instance, as part of the next training batch, or compiled into analytical reports for evaluation and decision-making purposes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a3cd1252-d276-4a01-9ef0-b2158def8901&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4c1772f3-4168-4665-82f0-7b15b3deb91e&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-ingesting-a-huge-number-of-log-files&#34;&gt;Ingesting a Huge Number of Log Files&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e95384e3-9a77-440d-9c52-a5ce486b0190&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The initial log ingestion pipeline, reliant on HDFS, had a few significant limitations for our logging workload. First, HDFS couldn’t scale to meet our log retention requirements due to the NameNode struggling to maintain an index of a huge number of small log files. In addition, data access, especially on developers’ laptops or development machines outside of a walled-off production environment, was primarily hindered by complex Kerberos authentication and other access barriers. In contrast, modern object storage solutions like S3 and GCS, designed for massive scalability, can accommodate petabytes of data and billions of objects. These platforms lessen our management load by obviating the need for HDFS cluster maintenance and offer enhanced security features such as encryption at rest and during transit, along with integrated ACLs and other access control features, automatic object lifecycle (i.e., retention time) management as well as providing a higher reliability and availability. We also benefit from the pay-as-you-go model, and the flexibility to significantly boost storage needs temporarily, for instance, extending log retention period following a major security incident. Thus, we switched from uploading and storing logs on HDFS to storing them in an object store.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;da78559c-f87a-4182-bd84-04dcaf2f998a&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;One key distinction between HDFS and common object stores is that HDFS employs a filesystem hierarchy whereas object stores function as flat key-value stores. Luckily, in large distributed systems, log files typically have a unique, unchanging filesystem path based on the logging entity’s hierarchy in the system, so this path works well as the key for the compressed logs. Furthermore, object stores offer APIs that facilitate key access in a manner akin to file system navigation, thereby maintaining a familiar log browsing experience.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6996a877-7091-47d2-b2c4-350475b1ed03&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;16491513-72b3-4ed5-a386-c5ef95924897&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-ensuring-and-guaranteeing-log-freshness&#34;&gt;Ensuring and Guaranteeing Log Freshness&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f49b6443-1f9a-4671-99e5-63f4c47d439d&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Services like YARN and streaming applications, including Flink jobs, are typically designed for prolonged execution and are only shut down infrequently, in the event of failures, hardware replacements, or upgrades. Consequently, log uploads can’t be deferred until the “end” of a job as was feasible in Phase I with shorter-duration Spark applications. Also, object storage systems typically lack support for append operations, posing a challenge for log freshness when dealing with the upload of large log files.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;62ee02cf-af7f-4001-a42b-b8cf16d449d1&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Our log management includes a rotation feature that segments extensive log files into smaller, more practical chunks. We trigger the creation of a new compressed log file when the existing file hits the 16MB mark. The chosen size is a strategic compromise for object stores, maximizing compression ratio, minimizing storage and synchronization overhead while only slightly raising API access costs. Note that despite the small compressed log file size, the high compression ratio means the 16MB chunk of compressed data represents a substantial amount of uncompressed data.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5ef299cc-97e8-4dbf-99f7-b9528e5ee0fa&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;To enhance log collection with near-real-time behavior and resilience, and at the same time minimize API costs associated with each upload request, our log library employs a tailored flush and upload policy specific to logging needs. We initially considered uploading logs every time they were flushed, but by default log libraries flush every time a log event is appended. This is too expensive. The libraries can also be configured to flush periodically, but this is too generic for logs. Ideally, we want an approach that changes depending on the characteristics of the logging workload. For instance, uploading sooner when important log events (e.g., ERROR-level) occur or uploading when there’s an absence of logs for a certain period of time.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;21525a1a-2bdf-4024-832e-ad8306c2cfdb&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Our uploading policy can be summarized as follows. Upon logging an event, the file should be uploaded after some delay 𝑆, but 𝑆 can be pushed to a later time if more log events occur before the delay expires. We call this a soft deadline. In contrast, we also maintain a hard deadline 𝐻 such that there is a guaranteed delay 𝐻 before the file is uploaded (𝐻 should be longer than 𝑆). For example, if 𝑆 is set to 10 seconds and 𝐻 is 300 seconds, it means when an event 𝐸 gets logged at time 𝑇 , it will be uploaded at 𝑇 + 10 if no other event arrives between [𝑇, 𝑇 + 10]. Otherwise, 𝐸’s upload will be delayed, but no later than 𝑇 + 300. These delays are configurable per log level, such that, for example, a user can set shorter deadlines for ERROR events than INFO ones. The delays also get reset once an upload occurs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;302ba9e4-c9a9-4820-98b1-f9a30fb54ffe&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ad9c3c07-702a-47bf-bd8b-49d59d5cabbf&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-effective-log-file-filtering-with-tags&#34;&gt;Effective Log File Filtering with Tags&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;11c30aa9-7b8e-4c8e-b484-5c898440a638&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Uber operates a huge number of internal services across various platforms, each of which has dozens of users running many jobs per day. Users often have advanced knowledge of system failures and their timing, thanks to comprehensive metrics and monitoring from integrated platform facilities or external monitoring tools. Therefore, in the majority of cases, users want to immediately limit their log search and viewing to a specific subset of compressed logs (e.g., those from a specific job, application, user, time slice, and their combination).&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2283eabd-3f10-4ead-a35e-a5a5f6067d09&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Our system enables flexible tagging of compressed logs with multiple identifiers, such as service ID, job ID, app ID, user ID, and timestamp range. Tags can be incorporated into object store file paths, recorded in external databases, or simply attached as object metadata and maintained by the object store. The user interface for searching and viewing logs leverages these tags allowing CLP to efficiently narrow down the log files relevant to each user’s search or viewing request.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4465a582-3b90-4aa0-9204-dd8936a0d444&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e43d1e1c-806e-4b05-86d1-9f6c6a8ff0c2&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-cross-platform-integration-of-clp&#34;&gt;Cross-platform Integration of CLP&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e0482a90-2fa8-4a25-bc62-36e165ce898a&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Our initial integration of CLP was with Spark, leveraging a re-implementation of CLP’s C++ code-base in Java for rapid integration with Spark’s default logging framework (Log4j). Its success, reliability, and user experience improvement led to integration requests from other platform teams and application end-users, including many Marketplace and ML teams. However, this integration path posed a challenge for adoption across different applications using other logging frameworks such as Logback and other programming languages, such as Python. Instead, we utilized Foreign Function Interface (FFI) libraries for various languages (including Java, Go, and Python) that interact with the CLP’s C++ library via native bindings. By integrating these into various logging libraries for each language, we were able to integrate CLP’s distributed streaming compression seamlessly into the platform team’s codebase without needing to change the application code.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;519717f8-0716-4280-9a05-ae71ccad20f3&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c4fcd6a9-5a0f-4416-b31d-b962a308fbb3&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-impact&#34;&gt;Impact&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;57736e6e-dc15-4f0c-b021-7c9722cfc1ef&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The cost-effective, distributed CLP compression and ingestion pipeline has become the preferred log ingestion and management solution for Uber’s Data team. As mentioned in our &lt;a href=&#34;https://www.uber.com/en-US/blog/reducing-logging-cost-by-two-orders-of-magnitude-using-clp&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;previous blog&lt;/a&gt;, this system has facilitated the effortless increase of our log retention period to the industry-standard 30 days, significantly reducing concerns over storage costs, maintenance complexity and availability. Furthermore, the log viewer and programmatic analysis features have gained popularity amongst end-users like the ML and Marketplace teams, as well as the platform maintained within Uber’s Data team. For example, the open-source Python CLP log analytics library has been downloaded 141,880 times, and the Python logging library plugin has seen 4,845 downloads in the last six months. The higher download rate of the analytics library reflects its wider use among engineers who analyze logs (“consumers”), compared to the number of service owners who implement the logging library plugin (“producers”).&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4dd9bc34-626e-4d42-9757-8c381d680bc0&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;73a1cf48-ddff-4d5c-9f5d-815d3d6ae174&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-next-steps&#34;&gt;Next Steps&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1b8044df-1dd5-484d-a4a7-f385671d60d0&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We aim to focus our future efforts on three key areas:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;db092b3d-8001-4283-8ca6-7bb9b6613f83&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Observability Platform Integration&lt;/strong&gt;:&amp;nbsp; Integrating CLP with the observability team’s existing log-collection infrastructure, which operates outside of application containers, reducing the severity of log loss during OOM scenarios and capturing logs not directly produced by applications (e.g., bash scripts). User experience can also be enhanced by unifying and streamlining access to both unstructured and structured logs.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;502b9e40-7fbc-4a69-80ae-565ec013f0aa&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Migrate Suitable Cold Logs to CLP&lt;/strong&gt;: CLP excels with logs that don’t necessitate near-real-time search capabilities. While CLP is extremely efficient and offers fast search performance, it is not intended to replace existing online indexing-based solutions. Migrating suitable logs to the CLP platform should reduce cost and improve reliability and user experience.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e3f234c6-f2df-4dfc-a911-aa224ab678d3&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Structured Log Support&lt;/strong&gt;: CLP has introduced native support for structured logs, and its effectiveness is documented in an upcoming OSDI ’24 paper showcasing excellent compression and search capabilities for structured log data compared to existing solutions.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;8f0157b0-b2e9-421f-93c8-36572c18ae20&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-conclusion&#34;&gt;Conclusion&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5c5e569b-a21a-42dc-8337-54e3552ef396&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;By seamlessly integrating CLP with advanced features like log viewing, programmable analytics, and efficient log ingestion, Uber has revolutionized our unstructured log management. This comprehensive system not only addresses the challenges of scalability and debugging at Uber’s immense scale but also empowers engineers across various teams with tools that streamline their workflows. As a result, Uber has achieved significant cost savings, improved log retention, and enhanced developer productivity. The open-source availability of core tools and features further solidifies CLP’s impact, fostering broader adoption and innovation within the industry. With ongoing efforts focused on platform integration, log migration, and structured log support, Uber is poised to continue leading the way in efficient and effective log management.&lt;/p&gt;</description>
      <pubDate>Thu, 27 Jun 2024 07:06:56 +0000</pubDate>
    </item>
    <item>
      <title>【Flaky Tests Overhaul at Uber】Uber 的不稳定测试大修</title>
      <link>https://www.uber.com/blog/flaky-tests-overhaul/</link>
      <description>【&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;5b1d7fc2-0941-47d4-b05f-3f7ece51b42b&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-introduction&#34;&gt;Introduction&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a42c8831-8676-46cf-ad64-9036fad21220&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;A few years ago, we started &lt;a href=&#34;https://www.uber.com/en-US/blog/handling-flaky-tests-java/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;tackling flaky tests&lt;/a&gt; in an effort to stabilize CI experience across our monorepos. The project first debuted in our Java monorepo and received good results in driving down frictions in developers’ workflow. However, as we evolved our CI infrastructure and started onboarding it to our largest repository with the most users, &lt;a href=&#34;https://www.uber.com/blog/how-we-halved-go-monorepo-ci-build-time/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Go Monorepo&lt;/a&gt;, the stop-gap solution became increasingly challenging to scale to the scope.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;4d9e159d-c250-40a5-a4cf-590ce4ee5a4c&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-visibility&#34;&gt;&lt;strong&gt;Visibility&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;67dd1537-7100-4d7b-ba4f-bb1a680c9f61&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;201aa385-5e2f-455f-b51a-0c7d17cad286&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The legacy service had an analyzer built-in, which categorizes tests based on a window of historical test runs. However, most of the time it works in a sandbox with little visibility into details, like what history it has examined for a test, what the reason was behind a decision, or additional information about a test. Thus, often some tests were miscategorized but we didn’t know why and had to manually recategorize.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;b2e7d91b-b0b6-408b-97d9-a63b5b40caf4&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-customization&#34;&gt;&lt;strong&gt;Customization&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;07ee5689-fa0c-4e7f-8b0c-6f92371b51a8&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;aa80c6ff-59a6-41d3-829e-28cce84d3de0&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;It also has little extensibility of supporting different strategies to categorize tests. It only supports the sliding window strategy to categorize tests. The legacy test model is specifically tailored to Java, assuming inputs like test suites, parameters, annotations, etc., which are not always available in other languages.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;962ac64d-c01e-4074-9e38-5807e8273eac&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-complexity&#34;&gt;&lt;strong&gt;Complexity&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;88c5370b-4301-4808-a021-0ebc6e3119a6&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2348812e-5754-484d-9822-c2a57b61d50d&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The “serial” and “parallel” concepts add additional logic on each monorepo’s CI side to respond differently. Also, because it encapsulates many scenarios–categorize, transition, recover in CI, notifications, etc. – complexity greatly increases when it needs to be both generic enough to accommodate each repo and effective enough to not miss any flakiness.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;e4ccc2b6-3d69-4e9d-9b4b-932dfd327a69&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-actionability&#34;&gt;&lt;strong&gt;Actionability&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8f430a58-09d6-4e9e-a17d-b2db0ccfe354&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a7be3b0d-9c65-46f4-a77a-7e6f9a389de6&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;At the time we hadn’t reached consensus as to how ownership was defined across repositories. So we ended up with a lot of flaky tests being ignored in CI, but with no accountable tracking.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d734d4df-7598-4736-a946-e3ffc2cc6abb&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;070ae3cd-03c6-46bc-9a1b-28e23b9b68ba&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-the-big-picture&#34;&gt;The Big Picture&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c3fcafa2-59dc-4e77-9d4a-0bb2a76aa3d0&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;At Uber, we run extensive sets of tests in our CI pipelines at various development stages. On a typical day, we validate 2,500+ diffs (code changes, a.k.a. pull requests) per day and run over 10k+ tests per diff on average. Our ultimate goal is to make sure developers have confidence in the main branch by &lt;a href=&#34;https://www.uber.com/blog/research/keeping-master-green-at-scale/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;keeping it always green&lt;/a&gt;. Flaky tests undermine the reliability of our CI pipeline, leading to chaos in developer experience–one bug becomes more bugs.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f2c986c7-44c3-4e21-9240-b3d59c0b4f33&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Furthermore, with our &lt;a href=&#34;https://www.uber.com/blog/bypassing-large-diffs-in-submitqueue/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;SubmitQueue speculation&lt;/a&gt; architecture, failing a revision can have cascading effects invalidating other revisions in the queue and causing blockage. This gets worse when there’s cross-cutting change that affects the entire repository and triggers all tests, which will be a nightmare to land a code change. This may lead to developers constantly retrying their builds until the build becomes green, wasting engineering hours and CI resources.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1f7300c8-63c1-4c0b-b63e-589e3dfaf376&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;It became an urgent need to develop an effective, scalable, and configurable system that can be easily adopted and responsive to thousands of tests’ state changes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b12b6b0d-9d0e-4e1d-a86b-ed3e86680e04&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a6d1f0dc-48f2-4538-b83e-1278aac25e13&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-introducing-testopedia&#34;&gt;Introducing Testopedia&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0765bf8a-e41f-4629-adef-5262b70747db&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We need to obtain visibility over all the tests that we run in Uber to validate users’ changes. This visibility includes reliability characteristics (i.e., flakiness control) and performance characteristics (i.e., latency control). Thus we need a centralized system to track all our tests and provide enough context to CI or any other consumers to make decisions with regard to these tests. We isolated these responsibilities to a standalone service, Testopedia.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;a8ab55a4-6796-4a48-bda1-0d4edeeae189&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-design-overview&#34;&gt;Design Overview&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6964c0e2-c3ac-4238-b231-7e4f98fa0ec7&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Testopedia sits in our CI infrastructure between reporting and consumers, as below:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5962396c-b43c-4c26-9cf4-489a5fc546eb&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;0a694a21-5c73-49c7-b534-18179b888cca&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXfgB7JBfGgSObLdUa7d6nIlquv_YK9ctd5SfEZbKGIsvHozIPyvlh4Tt3vZAQSW5WmiH4xkalc01ZcY_cOTyFHtbFa2gcuyIp-oWqoWRcLQ-5vlSW-rjSFBJyh4u2YqUmd_LItqVcMO_-WekoYw0-sTqTua?key=6gZ2dLlV7xzsqb0CRMkSGA&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 1: Example Pipeline.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5a86a100-3f44-4e82-af3a-9c03d392b981&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;eda85819-74c8-4688-9583-79bf035af068&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-what-it-does&#34;&gt;What it does&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;758ab9c3-3078-4003-a0c7-edf4638d7840&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Instead of having Testopedia handle all aspects of flaky tests, we decided to make it language/repo-agnostic. This means the service doesn’t care what kind of test it is, whether it’s a test suite or test case, how the name is formatted, how it’s reported, how it’s handled in CI, etc. It simply operates on “test entity,” which is the minimal fundamental unit in the system and is uniquely identified by a “fully qualified name” (FQN). Additionally we introduced a grouping concept for the FQNs–realm, which encapsulates all tests under a specific usage domain, such as Golang unit tests, Java unit tests, Docker integration tests, etc. Realms are owned by specific platform teams and each team can construct FQN to their own liking.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;56506c54-9463-4fdc-8369-435b41594c0b&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Next, on a high level, we assign 3 function domains to the service:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2f1571b6-f23e-468a-9389-387fea6e0f63&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Read&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;946fc163-8194-468a-9de8-1f15edf9180d&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Retrieve individual test’s stats, including flakiness state, reliability, staleness, aggregated execution time, historical run stats and other metadata if any.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Retrieve a groups tests’ stats, a list of the above.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Retrieve the state changes for a test.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b1454898-28cc-42a1-b6de-f3e7616a2821&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Write&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;14f17714-3c2b-4124-bab2-24fcc7175cf9&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Upload the test running results to the system.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;It could be in a form of file or streaming but need to follow a predefined schema.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Administrative operations to disable/enable/delete certain tests in the system.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;49cae938-ade8-400f-9766-28c1241983c8&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Notify&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;bfd428e6-a496-490b-8a5f-54e94a17e8f2&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Whenever a test becomes unhealthy, we need to trigger a JIRA ticket with deadline assigning to the owning team.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b1a9e321-30e0-45b3-856e-2ac7813fa207&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;30132e1f-3999-49c9-81dd-8368e6e91914&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;c2c8d4b6-d229-4825-8490-912d254eb357&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-how-it-works&#34;&gt;How it works&lt;/h3&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;width&amp;quot;:&amp;quot;700px&amp;quot;,&amp;quot;height&amp;quot;:&amp;quot;auto&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;1c81923a-4178-4db3-bc7e-08e62953b17c&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXdQvxdjfAvik1VtI7t-b2HiGn1Wk5CeNvZFhe2QBoHN7S_Bsid3wZV-fKRW3SLudKuP0KfcIA4vQDi0zd8txYN95hqLVktKT7tMjp2tcIS5Pg8-XCT_yaM5Vef7MeQm0_Wh8mnXKySoP93kE0Hxm-DKKe4?key=6gZ2dLlV7xzsqb0CRMkSGA&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 2: Testopedia Architecture Diagram.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8436349b-0d8c-42f0-bff7-724b3ce01180&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;dc4cf4a0-f6b9-4ae3-8a0a-f15eb4eaafed&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Testopedia works over historical data to infer if a test is healthy or not. But rather than fixating on the periodic job, Testopedia accepts all test data sources, regardless of whether it’s from periodic or regular validation jobs. Each report will be tagged with their source accordingly. Then every analyzer will have access to all this information and will take different strategies to respond to them (more on “analyzer” later).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;be1766aa-1ee4-4beb-8201-bd9cfb56264a&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;After analyzer is done with running analysis on a test, a result is materialized into storage for querying later and depending on the result, a ticket will be filed to the test’s owning team, following the realm’s grouping rule (more about this in Notification).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e7381254-3570-4921-9604-70bfac13b4de&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Note that from analyzer to ticketing, every strategy is extensible and configurable outside of Testopedia’s core logic, granting maximum customizability to realm owners.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a1395b47-041d-43a6-96dc-961f52ae0914&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3053ee68-48f9-4368-bb05-93127327e049&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-implementation-highlights&#34;&gt;Implementation Highlights&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;d4d593dc-2acb-4865-a56b-5bb85f3e3b72&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-fully-qualified-name-fqn&#34;&gt;&lt;strong&gt;Fully Qualified Name (FQN)&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6896c21e-14dd-476f-9d1f-23d0e4a032f5&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e81252e0-0ca8-4da8-9ae1-26e84aeb7479&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The key part of Testopedia design is the ability to address every test we execute at Uber with a unique string identifier named Fully Qualified Name, or short FQN. The system only needs to focus on analysis and bookkeeping of FQNs and leave handling implementation to each platform of their own, without having to know any details of each testing framework.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;871b59f7-c060-4d91-ac71-0850528f4475&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;All tests are grouped into &lt;em&gt;realms&lt;/em&gt;. Realm name starts the FQN string and represents a broader domain which tests belong to. An example of a realm is “golang.unit_test” or “android.integration_test”.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;26c67707-464c-43f4-92a7-273e5b1d0882&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;As an example of a valid FQN under the “Golang unit test” realm, we can put together a string that looks like this:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2d6e29bd-e362-401a-a0a1-7e6bb195396c&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;eaf64e5e-f666-4ef8-9163-02ae120b31b5&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXdwZlzY61MzQ6qnqQP7nlyAoUcTSIcRFIUVgDPADDe9qg0Z6o2zvD-N2KVItlya7T7SAA7KlAUouQJ0p6gGVIyWmw1wyM5DyfFtIQPggGE8hUtL9za1BNIT9WjvH32gPt4yWoNyBo5tiSs3DLsyXtyBqCM?key=6gZ2dLlV7xzsqb0CRMkSGA&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 3: Example of a Fully Qualified Name.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6fa34453-30c1-44a3-8c8c-d9c9952bfa7f&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c24c8da4-49d2-4bb0-b5ec-3d407b4351af&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The entire FQN can be customized to whatever format by the realm owner. It is typical to model the identifier after the file system structure where the test code is located. Not surprisingly, FQN looks very much like an Internet URL as it serves the similar purpose of identifying the resource uniquely.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;58aad72f-ed36-411a-af12-950dd6158c27&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-finite-state-machine-fsm-model&#34;&gt;&lt;strong&gt;Finite State Machine (FSM) model&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0fade6a9-f16e-434a-b939-0d73cbf09613&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;152a4ee0-9f7a-44a5-8499-cf4138769350&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Testopedia leverages a robust finite state machine implementation to capture and record the transactional states of tests. A test entity is permitted to transact between the following states: new, stable, unstable, disabled, and deleted.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;490e20b6-f7ca-4aeb-9544-f06b16c9fa9c&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;0be4f426-2ef8-4709-b005-04e98f23bfc9&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXcXC3fSUSBxx6UimzGX5-eCWvAIxT8GjmpP1o7M-BtFAxVQaTipK4mEkvNUNglokw3lhVe07hG2qNVUy2t5OlVE8FpsrTj2bkmOaF2aj977cXflVwvBBCTFOONK_VLgejYZVyHmY4783oVBCRbyLd1kBNPf?key=6gZ2dLlV7xzsqb0CRMkSGA&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 4: Testopedia State Machine.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4de603cd-95fd-49f2-8fca-c927c925fb6c&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b3e8dbf0-22a2-4743-b29a-f98773239481&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Each state can customize its own enter and exit action. For example, when FSM enters an unstable state, an action is fired to file a JIRA ticket; when FSM enters a stable or deleted state, the associated JIRA ticket is closed.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5dba5a5f-7980-4a75-9cdc-d5355bff14d1&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Sticking with FSM design, we were able to save on boilerplate code which we otherwise would have to write and support.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6c7a447d-5211-4353-a186-8eb9e477533d&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;6fb31f02-f9f5-4cea-ba27-477f089995bf&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-scalability&#34;&gt;&lt;strong&gt;Scalability&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f0f7ff33-ea10-45d0-b527-b7020c8c165b&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;1fe1c6c2-e4b4-48aa-b4e7-dc000192db31&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXf_fs9-Fg36HOnQqalDoe134ZcOVaRT4vbMCEdBG1aRd7-OZ8Sff4CP9oRkvptXWULIw2gbhfg4QHiw4R2hBBHXZ_U_Qh6wV4-iKvi9GOofM0jaoKSAxwSJ1FGEl8KWd9u-OP9QyO4N5qudDX_U7EMzxBgJ?key=6gZ2dLlV7xzsqb0CRMkSGA&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 5: Example of Data Streaming Through the Thread Pool.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d8e1dbf9-42fa-4400-996f-b494f3b91231&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e5743409-1159-40d1-9faa-19e7d97b7f66&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In order to maximize efficiency, we opted to implement the import API using gRPC streaming instead of asking users to upload large chunks of data. On top of this, we also implemented thread pooling to consume the data stream. This not only allows for more manageable data transmission over long-lived connections, but also ensures better resource utilization through parallel processing on both client and server sides.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;11524d4f-88ec-4aeb-b71f-5e58068dfbf8&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Furthermore, we designed the backend database with scalability in mind, by allowing flexible partitioning, so that more complex read scenarios are supported (more about this in the next section).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;e6556bc4-f4f5-4fd9-922e-f00fe7e46ba8&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-cone-queries-and-dynamic-partitioning&#34;&gt;&lt;strong&gt;Cone queries and dynamic partitioning&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;81a75136-8e93-4f9f-b087-e198c5e47784&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;52f1cedc-a851-4aed-8725-37cc54968ee7&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Because flaky tests will be heavily queried by CI, it’s a natural requirement to support query by prefix, such as “golang.unit/src/uber.com/infrastructure/*”, which in the Testopedia API model is called a &lt;em&gt;cone query&lt;/em&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;efabc307-ec24-4b55-8f26-dcad36807474&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In a very common Monorepo setup, CI builds are executed as multiple parallel jobs, divided by similar path prefixes. Thus each CI job is only interested to know about flaky tests under a specific repository folder, but not all of them.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d0e8a448-ece6-43a1-bbfd-aff69e75300f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;As we track millions of tests, iterating through the entire database to find a prefix match is not performant. We naturally think of sharding, however, we don’t want to just shard on a fixed length of prefix, because the cone query can come with any length, such as “golang.unit/a/b/c/*”, “golang.unit/a/b/*”, “golang.unit/a/*”, etc. To do this efficiently, we implemented a flexible bucketing algorithm:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2bf1e890-4170-4c21-a511-fa1e4b770e95&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;bc9324ad-c4e4-44f8-9834-ac8efbe48b83&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;WRITE:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;834e6d2b-87be-4028-870a-258cbb825418&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;When a new FQN arrives in the system, say “golang.unit/a/b/c/d:test”,&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;First we randomly generate an integer bucket ID for it, say 10&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Then we strip the realm and identify the first 3 prefixes: &#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;[a/b/c, a/b, a]&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;(3 here is a configurable value for depth, just an example)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;dabcc505-21fc-4771-9af2-07df19f0d81a&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Next we store the bucket ID along with all prefixes in a separate table by appending it:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8160c0c9-ec4b-466a-8533-95b9c5a994bc&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure data-wp-block-name=&#34;core/table&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ed05e1a0-3d3e-4cb6-868b-f723e9e7a786&amp;quot;,&amp;quot;hasFixedLayout&amp;quot;:false,&amp;quot;head&amp;quot;:[],&amp;quot;body&amp;quot;:[],&amp;quot;foot&amp;quot;:[]}&#34; class=&#34;wp-block-table&#34;&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;Prefix table&lt;/td&gt;&lt;td&gt;Before inserting (existing bucket IDs created by other FQN)&lt;/td&gt;&lt;td&gt;After inserting&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;a/b/c&lt;/td&gt;&lt;td&gt;[]&lt;/td&gt;&lt;td&gt;[&lt;strong&gt;10&lt;/strong&gt;]&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;a/b&lt;/td&gt;&lt;td&gt;[2]&lt;/td&gt;&lt;td&gt;[2, &lt;strong&gt;10&lt;/strong&gt;]&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;a&lt;/td&gt;&lt;td&gt;[2, 3]&lt;/td&gt;&lt;td&gt;[2, 3, &lt;strong&gt;10&lt;/strong&gt;]&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;In the above example FQNs prefixed with “a/b” must be under bucket 2 or 10.&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3d90f91a-ae11-4915-a96a-f425fcdda7f6&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;becdd565-7f4f-48c6-93ba-fb4dae60b936&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Finally we store the bucket ID along with the FQN itself in a separate FQN table that’s partitioned by bucket ID&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote data-wp-block-name=&#34;core/quote&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5a3eedb8-b433-451f-a60f-96de47fed1a5&amp;quot;,&amp;quot;value&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;wp-block-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;# FQN table&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;golang.unit/a/b/c/d:test, 10&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;054baf9c-c398-4bb9-803c-937393057a5c&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Potentially different buckets can persist into different database servers, making the setup almost infinitely scalable&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e0fb0567-a706-4231-8360-5e97cf6904d9&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;51cfbdc1-1b53-43bf-be3d-e2fadcfed45f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;READ:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;faa0f070-0ad4-406a-a70a-7b35e1ac4fca&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;When we issue a cone query, say “golang.unit/a/b/*”&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;We first locate the realm “golang.unit” then locate the prefix “a/b”&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Then we refer the the partitions table and get all the bucket IDs [2, 10]&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Then we can quickly look up FQN table for records with bucket ID 2 or 10; the read should be very fast since it’s partition key; we can also execute such lookups in parallel&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Finally we iterate through selected records and filter our those that meet query requirement&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9033570a-122a-4183-bb96-5285b9716b96&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b5e8477d-578e-4541-ba29-20933415487b&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Note that the depth of path for which we keep track of bucket IDs is a predefined value in config. So that for longer queries, such as “golang.unit/a/b/c/d/e/*”, we stop at the maximum depth “a/b/c” and read all records with bucket ID 10.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d0f63b8a-f840-406b-b9e5-310800b9ffc3&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;This way we can significantly reduce the number of records to read from DB. Furthermore, each realm can configure their own depth and number of buckets according to their query patterns. Because bucket IDs are dynamically generated rather than dependent on static input, it helps with distributing the data more evenly across buckets, regardless of their physical location in the repository.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;df4f36fd-5e26-4953-a8eb-9f17c17ff051&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;This design realizes an important benefit: a very traditional relational database, like MySQL in multi-sharded configuration, can be used to power the storage backend and execute complex cone queries with sub-second latency.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;f74a3378-7798-47fa-822e-eaf57a6762f9&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-data-agnostic-ingestion&#34;&gt;&lt;strong&gt;Data-agnostic ingestion&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;039f4caf-8410-4970-b7be-912c87ee378f&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;70621593-6bc0-4864-83a8-1a645c6cc544&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Currently Uber hosts a monorepo for each primary language, each with its own dedicated CI pipeline. Our vision for Testopedia is to create a language-agnostic platform that can benefit all CI pipelines. Each language repository owns a realm, defines their own FQN format, and is responsible to initiate monitoring jobs, which sends streams of test history data to Testopedia. The data must follow a predefined universal schema, which is the only protocol between reporter and the service.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e5f607d9-33c8-42ee-8120-e292f0219615&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Consumers are free to determine how to consume from Testopedia. This approach effectively decouples the system’s logic from any language-specific concepts, such as test suites in Java or subtests in Go, ensuring adaptability regardless of the format. As a result, developers can seamlessly integrate this service into their CI infrastructure.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;ebf199ae-c9b3-4410-b1b4-ebaf6a3e0f2e&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-configurable-analyzers&#34;&gt;&lt;strong&gt;Configurable analyzers&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b841cde3-5275-4285-802a-442cf593f596&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b9c442b9-566c-4c02-861c-238e412073dd&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The Analysis module in Testopedia is also highly configurable. It provides a common interface and the owner of each realm can either use our default linear analyzer or submit their own implementation that’s tailored to their specific requirements of detection.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;70d18883-b8f8-4f11-84c3-fcf74d231656&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;bbd33b5a-a448-41f5-a650-0056ad64ab37&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXfXR6FbFHBhtN50OQzqS604yTm6dfdZqED0A7D0igC6a4VR9ZS9OTznHMl831T1H7H1T41bE_iKk7-D5Fh5il6LK-gb9COoe8JMdXRsU4hvxQj7UzLcG92tC33Pv0YY6TXcG7pQpmOV3Y3KUt16oHb1_5Ns?key=6gZ2dLlV7xzsqb0CRMkSGA&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 6: Analyzer Interface.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;dedb510a-792a-4465-9111-60352bfa6003&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2efb385b-34ae-4133-8b55-df546c96338b&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Furthermore, users can reuse any analyzer implementations and define rules based on results, lookback window, thresholds, states patterns to identify flaky tests efficiently specific to their own realm (more about this in the next section).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;49029b53-eb73-4aeb-9354-6927f75f794f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;This customization strikes the right balance between minimizing false positives and capturing genuine flaky tests.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;496e7096-ef26-452c-b199-c8dccdbebacb&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-configurable-ticketing-system-and-storage&#34;&gt;&lt;strong&gt;Configurable ticketing system and storage&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1cba52cc-49c3-402f-a656-0df23824f03b&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;992a94fc-b6a7-4dc2-8562-2f34386eac04&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We also modularized the system to accommodate our ever-evolving infrastructure at Uber. So that users can hook up other scrum solutions such as JIRA, Phabricator, and various DB solutions for storing the tests and histories. More on this in the “Managing Flaky Tests” section.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;862b3218-642c-41df-a4fc-3e44f1e36e47&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-visibility-and-usage&#34;&gt;&lt;strong&gt;Visibility and usage&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4b7023e4-880e-4b13-be2a-37e89424e80c&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5c7f83e8-baf5-46c5-9e11-c7dff9618fc9&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;One of the key features of Testopedia is its ability to offer comprehensive visibility into test history. Every state transition, along with associated job and metadata is recorded, creating a transparent audit trail for test owners to debug and investigate when and where the flakiness happens, what the error is, how frequent it is, at which commit, etc. Furthermore, we also build CLI and web UI on top of it, so that everyone can easily inspect their tests.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b85afc96-16b3-452d-95fd-8a6120cd7843&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8b9fc839-84ad-428e-a61f-d91c0ba739c1&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-analyzing-flaky-tests&#34;&gt;Analyzing Flaky Tests&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f6c785af-95b8-4fa4-8595-326cd5946933&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;While identifying flakiness in a monorepo setup, we want to be both accurate enough that we catch them on time thus preventing their blast radius from expanding to other engineers’ workflows, and tolerant enough that we don’t ignore them all and still have sufficient coverage guard in our code.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7aa941bb-597f-4080-9662-8ef854aa0007&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In the Go Monorepo we execute all the tests under the main branch periodically with limited resources. This way we can expose more flakiness in tests that are resource-intensive. Then we send the results as-is to Testopedia, which runs them through a linear analyzer to determine the state of the test based on their histories.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f3603f2e-7d88-4d7e-84fe-eb2dbb1acff9&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;If a test fails once in the last X window of runs, it is classified as unstable. On the other hand, because resources on the machine are compromised on purpose, some tests might tend to timeout more often, but it’s not their fault. In this case, the analyzer also grants each test a threshold M to timeout. For a test to be classified as stable, the test must pass N times consecutively. We also recognize that a test can become consistently failing due to a bug and mark it accordingly, so users will be notified of this change later.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;bdb5024a-a33b-4864-bbe3-a117894cc7e4&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Additionally, we also send results data from our regular landing CI pipeline. Because we have retry logic there, if a test fails for the first time but passes an identical retry, we know that this test is flaky. We label the import stream differently and make analyzer Testopedia aware, so they don’t interfere with each other.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3c943dd8-d50e-4890-b1ab-66a77caaec87&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;With all of the above described, we would have a config that looks like this:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3b548a2d-9a4b-4eb7-a289-4fd10494a1b7&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;b9afba35-6457-4972-ae5c-69c5d2c54c46&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXeMCzGfKOmguHaw5yyslTacjboR8yIY7TytrD8OqSdyd4Q44BVTCPSWFg9HTJ4oTmCDsxBwr5aq_QVf3rMci0ZsIfv87RJh4fzZKT-b1wIRmhXWEp99gwMoroFjGaMonto9_TVxoY99CN6Dz1-5wPpMjKc?key=6gZ2dLlV7xzsqb0CRMkSGA&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 7: Analyzer config.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ce246c06-496e-4f10-b79e-7f9031abdbd8&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;daa7cebc-c57c-4883-a209-4e08fd410821&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;As aforementioned, all these behaviors of analyzers are highly extensible. For example, integration tests may be more prone to timeout and flakiness. The standard linear analyzer is not a good fit. In this case, a different percentage-based analyzer is implemented for them. It categorizes a test as flaky if the failure percentage in the last N runs exceeds a certain threshold. Other analyzers can also be easily plugged in. These might include analyzers designed to inspect specific error messages, those sensitive to timeouts, or those prioritizing the detection of failure trends, among others.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b20ab5fc-46fd-48b2-beae-df64570fd787&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;860a6fbe-151e-4a80-b4df-173c112cf57a&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-managing-flaky-tests-nbsp&#34;&gt;Managing Flaky Tests&amp;nbsp;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5cde7751-2227-4012-8a17-070fcfb26131&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;After finding those flaky tests, we need to treat them and notify the owning teams.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;c639cd66-6722-4978-8784-efb47d0dec90&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-treating-flaky-tests&#34;&gt;Treating Flaky Tests&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a259fdc9-641e-49a5-a13a-2a68bb5b129b&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In a Monorepo setup, landing large diffs that affect many libraries and their tests can be very challenging, and worse, when they have flaky tests. One flaky failure that’s not caused by the diff itself could result in a full rebuild of the entire Job.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7c4cb204-64b8-4763-ae46-c161528a28f0&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Our general guidance is to avoid running flaky tests in CI. However, issues quickly arise when the engineer tries to fix a flaky test and submits the diff. If it’s still ignored in CI, then we have no idea whether that fix works or not. Or even worse, it may completely break the test, but because CI doesn’t validate it, we never know it’s broken.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1fd1fc8e-dbcf-4235-a0ca-5e5e426879d9&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Thus, we have implemented several strategies around this:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;62b6b7d9-27cc-41a7-be02-48da9040618c&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Tests that are specifically marked “critical” will be run on CI jobs regardless of flakiness&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Engineers can specifically added tags or keywords in diffs to opt out of that behavior&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Other flaky tests, such as integration tests, are run in non-blocking mode as FYI only&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;d6dacd11-3219-4579-8755-3ae4c28f4621&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-reducing-impact-of-flaky-tests&#34;&gt;Reducing Impact of Flaky Tests&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6c74df2d-0ef8-43a6-94bb-9c7487224518&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Strategy to skip flaky tests during CI phase is implemented by each realm owner. For example, Golang and Java may have very different test runner patterns, and hence use different test filter mechanisms.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c425d55d-13c9-4bc9-9a9c-d692b061ad24&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In the Go Monorepo, for example, we have different methods to skip test cases and test targets. To skip test targets, we exclude running flaky test targets directly in CI, but still ensure the target is buildable. What if the target only contains certain flaky test cases and the other test cases are still useful? We implemented a feature in &lt;a href=&#34;https://github.com/bazelbuild/rules_go/blob/master/docs/go/core/rules.md#go_test&#34;&gt;rules_go&lt;/a&gt; to skip test cases by the &lt;a href=&#34;https://tip.golang.org/doc/go1.20#go-command&#34;&gt;Go 1.20 -skip&lt;/a&gt; tests flag and parsing &lt;a href=&#34;https://github.com/bazelbuild/rules_go/pull/3618&#34;&gt;TESTBRIDGET_TEST_ONLY&lt;/a&gt; environment variable. This way, the information about flaky tests is isolated from the input of the Bazel rule, and the tests cache can stay stable regardless of flakiness.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;7b1dc38f-fc86-4eb5-b876-566d830c0892&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-accountability&#34;&gt;Accountability&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8c7b0d34-65bc-498b-a4ef-4971b61db541&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Now we have found some flaky tests and acted accordingly in CI. What’s next?&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7b3d4289-d442-469c-95d1-a7e45ed60919&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We need to notify test authors of such findings and encourage them to fix the tests as soon as possible. We can do this by immediately calling ticketing modules such as JIRA, Slack, etc. However, there are thousands of tests in even the smallest realm at Uber, and obviously we can’t afford the latency and cost of waiting for an external system to respond or file tickets for every single one. Thus we designed an asynchronous system within Testopedia that can file tickets based on grouping rules.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d9243171-5187-4b6f-bc38-e0be649c722b&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;8580d91a-7318-435b-9657-c22f64d7a2b3&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXefNJ-bMu_P-R7GsX8K7fqdWfWwcOMx8HDY1RZom-bf92pEGA9FSKufI5KEuoPsq6ZCnLR_pokvWi8i45Vg9q9Ta9fS8plpLT_mNbXDlq4O7uXQP7SqdwYuD-hmK4tItY_XEc73ucAql6xJIoxwjncBwLNl?key=6gZ2dLlV7xzsqb0CRMkSGA&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 8: Ticket filing diagram.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;882b59d5-3722-4d97-954c-132783948075&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;af0318e1-7967-49ae-a68f-42cbec887322&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;When a test is determined to be unhealthy by the analyzer, in addition to being updated in the database, it’s also inserted into a queue of messages. The queue is then poked by a cadence workflow to examine these tests again and call into JIRA to file tickets to the owning team. A Bazel test target can have multiple test cases, we track each of them as an FQN, but we only want to file one ticket per group of similar tests to reduce noise. Thus we came up with a grouping concept that put all unhealthy FQNs in one ticket per their group–either by build target or by regex.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ad540953-fb38-4b16-8a00-bd112e0573cb&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We also made the entire module customizable, that a user can customize the grouping rule, ticket types, priority, and even the ticket description template. A typical task config looks like this:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0dd3bc99-5289-4056-92cc-41b1efc92745&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;89573d15-7a58-40cc-be19-acc9f36c50b8&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXcOx9cAS4GShBGqQ2zpaS0C0nOYLfRj6oITaJzZS1zphl94Xa8Yh_F3CgcWaiiCgVe5PmdjrwZdkjG-XhDHvqzymBqPDBp6oPS1bm7dtuNKJje1tSzcv_e-JttdXGfhtrTimkxGKj-nP3mbUNjavDYVeSAB?key=6gZ2dLlV7xzsqb0CRMkSGA&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 9: Ticket filing config.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;38f70198-b6a3-430c-a37c-a87da2a113ad&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;445a5cc8-33ba-45e5-bb5f-fa8e7c3b9910&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;This way teams will have different test structures and define their own notification strategy tailored to their users’ experience.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;33d2efc9-9966-4fd1-be74-3909cef2a575&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8689adb6-39e5-44f8-a8c1-f4ebd1d15f5f&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-future-plans&#34;&gt;Future Plans&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7461339c-0fd9-4f32-835e-82ea172ea659&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Uber is actively &lt;a href=&#34;https://www.uber.com/blog/generative-ai-for-high-quality-mobile-testing/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;developing various LLMs&lt;/a&gt; to improve our developer experience. We envision incorporating these cutting-edge technologies in to the system in the future:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;e65a2e04-4d32-4151-b68f-f3125ab85042&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-integrate-genai-for-automated-flaky-tests-resolution&#34;&gt;&lt;strong&gt;Integrate GenAI for automated flaky tests resolution&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;90165264-95ca-4093-ab1a-2692e488aca3&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;89e4f0ed-c7cf-4f0d-813b-a588c699d901&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;After an FQN is imported and analyzed, with access to all its historical data and other tests failing patterns, we could use GenAI to auto-generate fixes for that test. We are exploring GenAI integrations built in-house at Uber to help centrally drive down the number of unsound tests in our Monorepos with minimal input from test owners.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;1a8d12f3-9a7d-486e-be97-aa4095c39440&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-more-granular-failure-categorization-and-sub-categorization&#34;&gt;&lt;strong&gt;More granular failure categorization and sub-categorization&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a5652f35-a04c-4bef-810a-6c3d8ed466a2&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0cbdb05f-4946-48db-8909-cd6a025caf85&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The current FSM model provides generic buckets of categorization, however, not all test failures are the same. Sub-categorizations are done explicitly at the realm level. By leveraging AI to analyze failure patterns, we could automatically categorize test failures into more specific subgroups based on factors such as error logs and types, test environments, or code context of failure. This enhanced classification system would enable us to conduct more efficient troubleshooting and resolutions.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6d81cf93-e710-4a1b-bf30-f77e0da1644b&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;e582e269-4a27-4b1c-bf1d-1509cf36cc4d&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-conclusion&#34;&gt;Conclusion&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;02683e3d-8852-43ba-be66-3d6fad03205d&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Now that all of the major Monorepos at Uber are onboarded to Testopedia, and along with numerous optimizations in both the internal algorithm and infrastructure components, it has been more stable than ever. In the Go Monorepo, we are steadily detecting around 1000 flaky tests out of 600K in total and 1K/350K in Java. We also observed significant improvement in reliability of CI and huge reduction of retries. Nagging developers with Jira tickets containing the right information helped tremendously to reverse the trend of an ever-growing number of unstable tests.&lt;/p&gt;】&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;5b1d7fc2-0941-47d4-b05f-3f7ece51b42b&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-introduction&#34;&gt;Introduction&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a42c8831-8676-46cf-ad64-9036fad21220&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;A few years ago, we started &lt;a href=&#34;https://www.uber.com/en-US/blog/handling-flaky-tests-java/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;tackling flaky tests&lt;/a&gt; in an effort to stabilize CI experience across our monorepos. The project first debuted in our Java monorepo and received good results in driving down frictions in developers’ workflow. However, as we evolved our CI infrastructure and started onboarding it to our largest repository with the most users, &lt;a href=&#34;https://www.uber.com/blog/how-we-halved-go-monorepo-ci-build-time/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Go Monorepo&lt;/a&gt;, the stop-gap solution became increasingly challenging to scale to the scope.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;4d9e159d-c250-40a5-a4cf-590ce4ee5a4c&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-visibility&#34;&gt;&lt;strong&gt;Visibility&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;67dd1537-7100-4d7b-ba4f-bb1a680c9f61&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;201aa385-5e2f-455f-b51a-0c7d17cad286&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The legacy service had an analyzer built-in, which categorizes tests based on a window of historical test runs. However, most of the time it works in a sandbox with little visibility into details, like what history it has examined for a test, what the reason was behind a decision, or additional information about a test. Thus, often some tests were miscategorized but we didn’t know why and had to manually recategorize.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;b2e7d91b-b0b6-408b-97d9-a63b5b40caf4&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-customization&#34;&gt;&lt;strong&gt;Customization&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;07ee5689-fa0c-4e7f-8b0c-6f92371b51a8&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;aa80c6ff-59a6-41d3-829e-28cce84d3de0&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;It also has little extensibility of supporting different strategies to categorize tests. It only supports the sliding window strategy to categorize tests. The legacy test model is specifically tailored to Java, assuming inputs like test suites, parameters, annotations, etc., which are not always available in other languages.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;962ac64d-c01e-4074-9e38-5807e8273eac&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-complexity&#34;&gt;&lt;strong&gt;Complexity&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;88c5370b-4301-4808-a021-0ebc6e3119a6&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2348812e-5754-484d-9822-c2a57b61d50d&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The “serial” and “parallel” concepts add additional logic on each monorepo’s CI side to respond differently. Also, because it encapsulates many scenarios–categorize, transition, recover in CI, notifications, etc. – complexity greatly increases when it needs to be both generic enough to accommodate each repo and effective enough to not miss any flakiness.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;e4ccc2b6-3d69-4e9d-9b4b-932dfd327a69&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-actionability&#34;&gt;&lt;strong&gt;Actionability&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8f430a58-09d6-4e9e-a17d-b2db0ccfe354&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a7be3b0d-9c65-46f4-a77a-7e6f9a389de6&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;At the time we hadn’t reached consensus as to how ownership was defined across repositories. So we ended up with a lot of flaky tests being ignored in CI, but with no accountable tracking.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d734d4df-7598-4736-a946-e3ffc2cc6abb&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;070ae3cd-03c6-46bc-9a1b-28e23b9b68ba&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-the-big-picture&#34;&gt;The Big Picture&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c3fcafa2-59dc-4e77-9d4a-0bb2a76aa3d0&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;At Uber, we run extensive sets of tests in our CI pipelines at various development stages. On a typical day, we validate 2,500+ diffs (code changes, a.k.a. pull requests) per day and run over 10k+ tests per diff on average. Our ultimate goal is to make sure developers have confidence in the main branch by &lt;a href=&#34;https://www.uber.com/blog/research/keeping-master-green-at-scale/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;keeping it always green&lt;/a&gt;. Flaky tests undermine the reliability of our CI pipeline, leading to chaos in developer experience–one bug becomes more bugs.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f2c986c7-44c3-4e21-9240-b3d59c0b4f33&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Furthermore, with our &lt;a href=&#34;https://www.uber.com/blog/bypassing-large-diffs-in-submitqueue/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;SubmitQueue speculation&lt;/a&gt; architecture, failing a revision can have cascading effects invalidating other revisions in the queue and causing blockage. This gets worse when there’s cross-cutting change that affects the entire repository and triggers all tests, which will be a nightmare to land a code change. This may lead to developers constantly retrying their builds until the build becomes green, wasting engineering hours and CI resources.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1f7300c8-63c1-4c0b-b63e-589e3dfaf376&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;It became an urgent need to develop an effective, scalable, and configurable system that can be easily adopted and responsive to thousands of tests’ state changes.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b12b6b0d-9d0e-4e1d-a86b-ed3e86680e04&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a6d1f0dc-48f2-4538-b83e-1278aac25e13&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-introducing-testopedia&#34;&gt;Introducing Testopedia&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0765bf8a-e41f-4629-adef-5262b70747db&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We need to obtain visibility over all the tests that we run in Uber to validate users’ changes. This visibility includes reliability characteristics (i.e., flakiness control) and performance characteristics (i.e., latency control). Thus we need a centralized system to track all our tests and provide enough context to CI or any other consumers to make decisions with regard to these tests. We isolated these responsibilities to a standalone service, Testopedia.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;a8ab55a4-6796-4a48-bda1-0d4edeeae189&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-design-overview&#34;&gt;Design Overview&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6964c0e2-c3ac-4238-b231-7e4f98fa0ec7&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Testopedia sits in our CI infrastructure between reporting and consumers, as below:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5962396c-b43c-4c26-9cf4-489a5fc546eb&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;0a694a21-5c73-49c7-b534-18179b888cca&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXfgB7JBfGgSObLdUa7d6nIlquv_YK9ctd5SfEZbKGIsvHozIPyvlh4Tt3vZAQSW5WmiH4xkalc01ZcY_cOTyFHtbFa2gcuyIp-oWqoWRcLQ-5vlSW-rjSFBJyh4u2YqUmd_LItqVcMO_-WekoYw0-sTqTua?key=6gZ2dLlV7xzsqb0CRMkSGA&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 1: Example Pipeline.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5a86a100-3f44-4e82-af3a-9c03d392b981&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;eda85819-74c8-4688-9583-79bf035af068&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-what-it-does&#34;&gt;What it does&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;758ab9c3-3078-4003-a0c7-edf4638d7840&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Instead of having Testopedia handle all aspects of flaky tests, we decided to make it language/repo-agnostic. This means the service doesn’t care what kind of test it is, whether it’s a test suite or test case, how the name is formatted, how it’s reported, how it’s handled in CI, etc. It simply operates on “test entity,” which is the minimal fundamental unit in the system and is uniquely identified by a “fully qualified name” (FQN). Additionally we introduced a grouping concept for the FQNs–realm, which encapsulates all tests under a specific usage domain, such as Golang unit tests, Java unit tests, Docker integration tests, etc. Realms are owned by specific platform teams and each team can construct FQN to their own liking.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;56506c54-9463-4fdc-8369-435b41594c0b&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Next, on a high level, we assign 3 function domains to the service:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2f1571b6-f23e-468a-9389-387fea6e0f63&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Read&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;946fc163-8194-468a-9de8-1f15edf9180d&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Retrieve individual test’s stats, including flakiness state, reliability, staleness, aggregated execution time, historical run stats and other metadata if any.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Retrieve a groups tests’ stats, a list of the above.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Retrieve the state changes for a test.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b1454898-28cc-42a1-b6de-f3e7616a2821&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Write&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;14f17714-3c2b-4124-bab2-24fcc7175cf9&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Upload the test running results to the system.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;It could be in a form of file or streaming but need to follow a predefined schema.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Administrative operations to disable/enable/delete certain tests in the system.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;49cae938-ade8-400f-9766-28c1241983c8&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;Notify&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;bfd428e6-a496-490b-8a5f-54e94a17e8f2&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Whenever a test becomes unhealthy, we need to trigger a JIRA ticket with deadline assigning to the owning team.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b1a9e321-30e0-45b3-856e-2ac7813fa207&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;30132e1f-3999-49c9-81dd-8368e6e91914&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;c2c8d4b6-d229-4825-8490-912d254eb357&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-how-it-works&#34;&gt;How it works&lt;/h3&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;width&amp;quot;:&amp;quot;700px&amp;quot;,&amp;quot;height&amp;quot;:&amp;quot;auto&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;1c81923a-4178-4db3-bc7e-08e62953b17c&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXdQvxdjfAvik1VtI7t-b2HiGn1Wk5CeNvZFhe2QBoHN7S_Bsid3wZV-fKRW3SLudKuP0KfcIA4vQDi0zd8txYN95hqLVktKT7tMjp2tcIS5Pg8-XCT_yaM5Vef7MeQm0_Wh8mnXKySoP93kE0Hxm-DKKe4?key=6gZ2dLlV7xzsqb0CRMkSGA&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 2: Testopedia Architecture Diagram.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8436349b-0d8c-42f0-bff7-724b3ce01180&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;dc4cf4a0-f6b9-4ae3-8a0a-f15eb4eaafed&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Testopedia works over historical data to infer if a test is healthy or not. But rather than fixating on the periodic job, Testopedia accepts all test data sources, regardless of whether it’s from periodic or regular validation jobs. Each report will be tagged with their source accordingly. Then every analyzer will have access to all this information and will take different strategies to respond to them (more on “analyzer” later).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;be1766aa-1ee4-4beb-8201-bd9cfb56264a&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;After analyzer is done with running analysis on a test, a result is materialized into storage for querying later and depending on the result, a ticket will be filed to the test’s owning team, following the realm’s grouping rule (more about this in Notification).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e7381254-3570-4921-9604-70bfac13b4de&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Note that from analyzer to ticketing, every strategy is extensible and configurable outside of Testopedia’s core logic, granting maximum customizability to realm owners.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a1395b47-041d-43a6-96dc-961f52ae0914&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3053ee68-48f9-4368-bb05-93127327e049&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-implementation-highlights&#34;&gt;Implementation Highlights&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;d4d593dc-2acb-4865-a56b-5bb85f3e3b72&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-fully-qualified-name-fqn&#34;&gt;&lt;strong&gt;Fully Qualified Name (FQN)&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6896c21e-14dd-476f-9d1f-23d0e4a032f5&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e81252e0-0ca8-4da8-9ae1-26e84aeb7479&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The key part of Testopedia design is the ability to address every test we execute at Uber with a unique string identifier named Fully Qualified Name, or short FQN. The system only needs to focus on analysis and bookkeeping of FQNs and leave handling implementation to each platform of their own, without having to know any details of each testing framework.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;871b59f7-c060-4d91-ac71-0850528f4475&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;All tests are grouped into &lt;em&gt;realms&lt;/em&gt;. Realm name starts the FQN string and represents a broader domain which tests belong to. An example of a realm is “golang.unit_test” or “android.integration_test”.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;26c67707-464c-43f4-92a7-273e5b1d0882&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;As an example of a valid FQN under the “Golang unit test” realm, we can put together a string that looks like this:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2d6e29bd-e362-401a-a0a1-7e6bb195396c&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;eaf64e5e-f666-4ef8-9163-02ae120b31b5&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXdwZlzY61MzQ6qnqQP7nlyAoUcTSIcRFIUVgDPADDe9qg0Z6o2zvD-N2KVItlya7T7SAA7KlAUouQJ0p6gGVIyWmw1wyM5DyfFtIQPggGE8hUtL9za1BNIT9WjvH32gPt4yWoNyBo5tiSs3DLsyXtyBqCM?key=6gZ2dLlV7xzsqb0CRMkSGA&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 3: Example of a Fully Qualified Name.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6fa34453-30c1-44a3-8c8c-d9c9952bfa7f&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c24c8da4-49d2-4bb0-b5ec-3d407b4351af&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The entire FQN can be customized to whatever format by the realm owner. It is typical to model the identifier after the file system structure where the test code is located. Not surprisingly, FQN looks very much like an Internet URL as it serves the similar purpose of identifying the resource uniquely.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;58aad72f-ed36-411a-af12-950dd6158c27&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-finite-state-machine-fsm-model&#34;&gt;&lt;strong&gt;Finite State Machine (FSM) model&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0fade6a9-f16e-434a-b939-0d73cbf09613&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;152a4ee0-9f7a-44a5-8499-cf4138769350&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Testopedia leverages a robust finite state machine implementation to capture and record the transactional states of tests. A test entity is permitted to transact between the following states: new, stable, unstable, disabled, and deleted.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;490e20b6-f7ca-4aeb-9544-f06b16c9fa9c&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;0be4f426-2ef8-4709-b005-04e98f23bfc9&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXcXC3fSUSBxx6UimzGX5-eCWvAIxT8GjmpP1o7M-BtFAxVQaTipK4mEkvNUNglokw3lhVe07hG2qNVUy2t5OlVE8FpsrTj2bkmOaF2aj977cXflVwvBBCTFOONK_VLgejYZVyHmY4783oVBCRbyLd1kBNPf?key=6gZ2dLlV7xzsqb0CRMkSGA&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 4: Testopedia State Machine.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4de603cd-95fd-49f2-8fca-c927c925fb6c&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b3e8dbf0-22a2-4743-b29a-f98773239481&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Each state can customize its own enter and exit action. For example, when FSM enters an unstable state, an action is fired to file a JIRA ticket; when FSM enters a stable or deleted state, the associated JIRA ticket is closed.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5dba5a5f-7980-4a75-9cdc-d5355bff14d1&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Sticking with FSM design, we were able to save on boilerplate code which we otherwise would have to write and support.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6c7a447d-5211-4353-a186-8eb9e477533d&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;6fb31f02-f9f5-4cea-ba27-477f089995bf&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-scalability&#34;&gt;&lt;strong&gt;Scalability&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f0f7ff33-ea10-45d0-b527-b7020c8c165b&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;1fe1c6c2-e4b4-48aa-b4e7-dc000192db31&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXf_fs9-Fg36HOnQqalDoe134ZcOVaRT4vbMCEdBG1aRd7-OZ8Sff4CP9oRkvptXWULIw2gbhfg4QHiw4R2hBBHXZ_U_Qh6wV4-iKvi9GOofM0jaoKSAxwSJ1FGEl8KWd9u-OP9QyO4N5qudDX_U7EMzxBgJ?key=6gZ2dLlV7xzsqb0CRMkSGA&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 5: Example of Data Streaming Through the Thread Pool.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d8e1dbf9-42fa-4400-996f-b494f3b91231&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e5743409-1159-40d1-9faa-19e7d97b7f66&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In order to maximize efficiency, we opted to implement the import API using gRPC streaming instead of asking users to upload large chunks of data. On top of this, we also implemented thread pooling to consume the data stream. This not only allows for more manageable data transmission over long-lived connections, but also ensures better resource utilization through parallel processing on both client and server sides.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;11524d4f-88ec-4aeb-b71f-5e58068dfbf8&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Furthermore, we designed the backend database with scalability in mind, by allowing flexible partitioning, so that more complex read scenarios are supported (more about this in the next section).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;e6556bc4-f4f5-4fd9-922e-f00fe7e46ba8&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-cone-queries-and-dynamic-partitioning&#34;&gt;&lt;strong&gt;Cone queries and dynamic partitioning&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;81a75136-8e93-4f9f-b087-e198c5e47784&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;52f1cedc-a851-4aed-8725-37cc54968ee7&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Because flaky tests will be heavily queried by CI, it’s a natural requirement to support query by prefix, such as “golang.unit/src/uber.com/infrastructure/*”, which in the Testopedia API model is called a &lt;em&gt;cone query&lt;/em&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;efabc307-ec24-4b55-8f26-dcad36807474&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In a very common Monorepo setup, CI builds are executed as multiple parallel jobs, divided by similar path prefixes. Thus each CI job is only interested to know about flaky tests under a specific repository folder, but not all of them.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d0e8a448-ece6-43a1-bbfd-aff69e75300f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;As we track millions of tests, iterating through the entire database to find a prefix match is not performant. We naturally think of sharding, however, we don’t want to just shard on a fixed length of prefix, because the cone query can come with any length, such as “golang.unit/a/b/c/*”, “golang.unit/a/b/*”, “golang.unit/a/*”, etc. To do this efficiently, we implemented a flexible bucketing algorithm:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2bf1e890-4170-4c21-a511-fa1e4b770e95&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;bc9324ad-c4e4-44f8-9834-ac8efbe48b83&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;WRITE:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;834e6d2b-87be-4028-870a-258cbb825418&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;When a new FQN arrives in the system, say “golang.unit/a/b/c/d:test”,&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;First we randomly generate an integer bucket ID for it, say 10&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Then we strip the realm and identify the first 3 prefixes: &#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;[a/b/c, a/b, a]&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;(3 here is a configurable value for depth, just an example)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;dabcc505-21fc-4771-9af2-07df19f0d81a&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Next we store the bucket ID along with all prefixes in a separate table by appending it:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8160c0c9-ec4b-466a-8533-95b9c5a994bc&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure data-wp-block-name=&#34;core/table&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ed05e1a0-3d3e-4cb6-868b-f723e9e7a786&amp;quot;,&amp;quot;hasFixedLayout&amp;quot;:false,&amp;quot;head&amp;quot;:[],&amp;quot;body&amp;quot;:[],&amp;quot;foot&amp;quot;:[]}&#34; class=&#34;wp-block-table&#34;&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;Prefix table&lt;/td&gt;&lt;td&gt;Before inserting (existing bucket IDs created by other FQN)&lt;/td&gt;&lt;td&gt;After inserting&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;a/b/c&lt;/td&gt;&lt;td&gt;[]&lt;/td&gt;&lt;td&gt;[&lt;strong&gt;10&lt;/strong&gt;]&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;a/b&lt;/td&gt;&lt;td&gt;[2]&lt;/td&gt;&lt;td&gt;[2, &lt;strong&gt;10&lt;/strong&gt;]&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;a&lt;/td&gt;&lt;td&gt;[2, 3]&lt;/td&gt;&lt;td&gt;[2, 3, &lt;strong&gt;10&lt;/strong&gt;]&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;In the above example FQNs prefixed with “a/b” must be under bucket 2 or 10.&lt;/figcaption&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3d90f91a-ae11-4915-a96a-f425fcdda7f6&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;becdd565-7f4f-48c6-93ba-fb4dae60b936&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Finally we store the bucket ID along with the FQN itself in a separate FQN table that’s partitioned by bucket ID&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;blockquote data-wp-block-name=&#34;core/quote&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5a3eedb8-b433-451f-a60f-96de47fed1a5&amp;quot;,&amp;quot;value&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;wp-block-quote is-layout-flow wp-block-quote-is-layout-flow&#34;&gt;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;# FQN table&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;dropCap&amp;quot;:false}&#34;&gt;golang.unit/a/b/c/d:test, 10&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;054baf9c-c398-4bb9-803c-937393057a5c&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Potentially different buckets can persist into different database servers, making the setup almost infinitely scalable&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e0fb0567-a706-4231-8360-5e97cf6904d9&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;51cfbdc1-1b53-43bf-be3d-e2fadcfed45f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;READ:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;faa0f070-0ad4-406a-a70a-7b35e1ac4fca&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;When we issue a cone query, say “golang.unit/a/b/*”&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;We first locate the realm “golang.unit” then locate the prefix “a/b”&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Then we refer the the partitions table and get all the bucket IDs [2, 10]&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Then we can quickly look up FQN table for records with bucket ID 2 or 10; the read should be very fast since it’s partition key; we can also execute such lookups in parallel&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Finally we iterate through selected records and filter our those that meet query requirement&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9033570a-122a-4183-bb96-5285b9716b96&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b5e8477d-578e-4541-ba29-20933415487b&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Note that the depth of path for which we keep track of bucket IDs is a predefined value in config. So that for longer queries, such as “golang.unit/a/b/c/d/e/*”, we stop at the maximum depth “a/b/c” and read all records with bucket ID 10.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d0f63b8a-f840-406b-b9e5-310800b9ffc3&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;This way we can significantly reduce the number of records to read from DB. Furthermore, each realm can configure their own depth and number of buckets according to their query patterns. Because bucket IDs are dynamically generated rather than dependent on static input, it helps with distributing the data more evenly across buckets, regardless of their physical location in the repository.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;df4f36fd-5e26-4953-a8eb-9f17c17ff051&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;This design realizes an important benefit: a very traditional relational database, like MySQL in multi-sharded configuration, can be used to power the storage backend and execute complex cone queries with sub-second latency.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;f74a3378-7798-47fa-822e-eaf57a6762f9&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-data-agnostic-ingestion&#34;&gt;&lt;strong&gt;Data-agnostic ingestion&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;039f4caf-8410-4970-b7be-912c87ee378f&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;70621593-6bc0-4864-83a8-1a645c6cc544&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Currently Uber hosts a monorepo for each primary language, each with its own dedicated CI pipeline. Our vision for Testopedia is to create a language-agnostic platform that can benefit all CI pipelines. Each language repository owns a realm, defines their own FQN format, and is responsible to initiate monitoring jobs, which sends streams of test history data to Testopedia. The data must follow a predefined universal schema, which is the only protocol between reporter and the service.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e5f607d9-33c8-42ee-8120-e292f0219615&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Consumers are free to determine how to consume from Testopedia. This approach effectively decouples the system’s logic from any language-specific concepts, such as test suites in Java or subtests in Go, ensuring adaptability regardless of the format. As a result, developers can seamlessly integrate this service into their CI infrastructure.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;ebf199ae-c9b3-4410-b1b4-ebaf6a3e0f2e&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-configurable-analyzers&#34;&gt;&lt;strong&gt;Configurable analyzers&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b841cde3-5275-4285-802a-442cf593f596&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b9c442b9-566c-4c02-861c-238e412073dd&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The Analysis module in Testopedia is also highly configurable. It provides a common interface and the owner of each realm can either use our default linear analyzer or submit their own implementation that’s tailored to their specific requirements of detection.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;70d18883-b8f8-4f11-84c3-fcf74d231656&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;bbd33b5a-a448-41f5-a650-0056ad64ab37&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXfXR6FbFHBhtN50OQzqS604yTm6dfdZqED0A7D0igC6a4VR9ZS9OTznHMl831T1H7H1T41bE_iKk7-D5Fh5il6LK-gb9COoe8JMdXRsU4hvxQj7UzLcG92tC33Pv0YY6TXcG7pQpmOV3Y3KUt16oHb1_5Ns?key=6gZ2dLlV7xzsqb0CRMkSGA&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 6: Analyzer Interface.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;dedb510a-792a-4465-9111-60352bfa6003&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2efb385b-34ae-4133-8b55-df546c96338b&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Furthermore, users can reuse any analyzer implementations and define rules based on results, lookback window, thresholds, states patterns to identify flaky tests efficiently specific to their own realm (more about this in the next section).&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;49029b53-eb73-4aeb-9354-6927f75f794f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;This customization strikes the right balance between minimizing false positives and capturing genuine flaky tests.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;496e7096-ef26-452c-b199-c8dccdbebacb&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-configurable-ticketing-system-and-storage&#34;&gt;&lt;strong&gt;Configurable ticketing system and storage&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1cba52cc-49c3-402f-a656-0df23824f03b&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;992a94fc-b6a7-4dc2-8562-2f34386eac04&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We also modularized the system to accommodate our ever-evolving infrastructure at Uber. So that users can hook up other scrum solutions such as JIRA, Phabricator, and various DB solutions for storing the tests and histories. More on this in the “Managing Flaky Tests” section.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;862b3218-642c-41df-a4fc-3e44f1e36e47&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-visibility-and-usage&#34;&gt;&lt;strong&gt;Visibility and usage&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4b7023e4-880e-4b13-be2a-37e89424e80c&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5c7f83e8-baf5-46c5-9e11-c7dff9618fc9&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;One of the key features of Testopedia is its ability to offer comprehensive visibility into test history. Every state transition, along with associated job and metadata is recorded, creating a transparent audit trail for test owners to debug and investigate when and where the flakiness happens, what the error is, how frequent it is, at which commit, etc. Furthermore, we also build CLI and web UI on top of it, so that everyone can easily inspect their tests.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b85afc96-16b3-452d-95fd-8a6120cd7843&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8b9fc839-84ad-428e-a61f-d91c0ba739c1&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-analyzing-flaky-tests&#34;&gt;Analyzing Flaky Tests&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f6c785af-95b8-4fa4-8595-326cd5946933&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;While identifying flakiness in a monorepo setup, we want to be both accurate enough that we catch them on time thus preventing their blast radius from expanding to other engineers’ workflows, and tolerant enough that we don’t ignore them all and still have sufficient coverage guard in our code.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7aa941bb-597f-4080-9662-8ef854aa0007&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In the Go Monorepo we execute all the tests under the main branch periodically with limited resources. This way we can expose more flakiness in tests that are resource-intensive. Then we send the results as-is to Testopedia, which runs them through a linear analyzer to determine the state of the test based on their histories.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f3603f2e-7d88-4d7e-84fe-eb2dbb1acff9&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;If a test fails once in the last X window of runs, it is classified as unstable. On the other hand, because resources on the machine are compromised on purpose, some tests might tend to timeout more often, but it’s not their fault. In this case, the analyzer also grants each test a threshold M to timeout. For a test to be classified as stable, the test must pass N times consecutively. We also recognize that a test can become consistently failing due to a bug and mark it accordingly, so users will be notified of this change later.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;bdb5024a-a33b-4864-bbe3-a117894cc7e4&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Additionally, we also send results data from our regular landing CI pipeline. Because we have retry logic there, if a test fails for the first time but passes an identical retry, we know that this test is flaky. We label the import stream differently and make analyzer Testopedia aware, so they don’t interfere with each other.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3c943dd8-d50e-4890-b1ab-66a77caaec87&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;With all of the above described, we would have a config that looks like this:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3b548a2d-9a4b-4eb7-a289-4fd10494a1b7&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;b9afba35-6457-4972-ae5c-69c5d2c54c46&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXeMCzGfKOmguHaw5yyslTacjboR8yIY7TytrD8OqSdyd4Q44BVTCPSWFg9HTJ4oTmCDsxBwr5aq_QVf3rMci0ZsIfv87RJh4fzZKT-b1wIRmhXWEp99gwMoroFjGaMonto9_TVxoY99CN6Dz1-5wPpMjKc?key=6gZ2dLlV7xzsqb0CRMkSGA&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 7: Analyzer config.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ce246c06-496e-4f10-b79e-7f9031abdbd8&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;daa7cebc-c57c-4883-a209-4e08fd410821&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;As aforementioned, all these behaviors of analyzers are highly extensible. For example, integration tests may be more prone to timeout and flakiness. The standard linear analyzer is not a good fit. In this case, a different percentage-based analyzer is implemented for them. It categorizes a test as flaky if the failure percentage in the last N runs exceeds a certain threshold. Other analyzers can also be easily plugged in. These might include analyzers designed to inspect specific error messages, those sensitive to timeouts, or those prioritizing the detection of failure trends, among others.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b20ab5fc-46fd-48b2-beae-df64570fd787&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;860a6fbe-151e-4a80-b4df-173c112cf57a&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-managing-flaky-tests-nbsp&#34;&gt;Managing Flaky Tests&amp;nbsp;&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5cde7751-2227-4012-8a17-070fcfb26131&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;After finding those flaky tests, we need to treat them and notify the owning teams.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;c639cd66-6722-4978-8784-efb47d0dec90&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-treating-flaky-tests&#34;&gt;Treating Flaky Tests&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a259fdc9-641e-49a5-a13a-2a68bb5b129b&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In a Monorepo setup, landing large diffs that affect many libraries and their tests can be very challenging, and worse, when they have flaky tests. One flaky failure that’s not caused by the diff itself could result in a full rebuild of the entire Job.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7c4cb204-64b8-4763-ae46-c161528a28f0&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Our general guidance is to avoid running flaky tests in CI. However, issues quickly arise when the engineer tries to fix a flaky test and submits the diff. If it’s still ignored in CI, then we have no idea whether that fix works or not. Or even worse, it may completely break the test, but because CI doesn’t validate it, we never know it’s broken.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1fd1fc8e-dbcf-4235-a0ca-5e5e426879d9&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Thus, we have implemented several strategies around this:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;62b6b7d9-27cc-41a7-be02-48da9040618c&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Tests that are specifically marked “critical” will be run on CI jobs regardless of flakiness&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Engineers can specifically added tags or keywords in diffs to opt out of that behavior&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Other flaky tests, such as integration tests, are run in non-blocking mode as FYI only&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;d6dacd11-3219-4579-8755-3ae4c28f4621&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-reducing-impact-of-flaky-tests&#34;&gt;Reducing Impact of Flaky Tests&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6c74df2d-0ef8-43a6-94bb-9c7487224518&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Strategy to skip flaky tests during CI phase is implemented by each realm owner. For example, Golang and Java may have very different test runner patterns, and hence use different test filter mechanisms.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c425d55d-13c9-4bc9-9a9c-d692b061ad24&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In the Go Monorepo, for example, we have different methods to skip test cases and test targets. To skip test targets, we exclude running flaky test targets directly in CI, but still ensure the target is buildable. What if the target only contains certain flaky test cases and the other test cases are still useful? We implemented a feature in &lt;a href=&#34;https://github.com/bazelbuild/rules_go/blob/master/docs/go/core/rules.md#go_test&#34;&gt;rules_go&lt;/a&gt; to skip test cases by the &lt;a href=&#34;https://tip.golang.org/doc/go1.20#go-command&#34;&gt;Go 1.20 -skip&lt;/a&gt; tests flag and parsing &lt;a href=&#34;https://github.com/bazelbuild/rules_go/pull/3618&#34;&gt;TESTBRIDGET_TEST_ONLY&lt;/a&gt; environment variable. This way, the information about flaky tests is isolated from the input of the Bazel rule, and the tests cache can stay stable regardless of flakiness.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;7b1dc38f-fc86-4eb5-b876-566d830c0892&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-accountability&#34;&gt;Accountability&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8c7b0d34-65bc-498b-a4ef-4971b61db541&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Now we have found some flaky tests and acted accordingly in CI. What’s next?&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7b3d4289-d442-469c-95d1-a7e45ed60919&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We need to notify test authors of such findings and encourage them to fix the tests as soon as possible. We can do this by immediately calling ticketing modules such as JIRA, Slack, etc. However, there are thousands of tests in even the smallest realm at Uber, and obviously we can’t afford the latency and cost of waiting for an external system to respond or file tickets for every single one. Thus we designed an asynchronous system within Testopedia that can file tickets based on grouping rules.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d9243171-5187-4b6f-bc38-e0be649c722b&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;8580d91a-7318-435b-9657-c22f64d7a2b3&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXefNJ-bMu_P-R7GsX8K7fqdWfWwcOMx8HDY1RZom-bf92pEGA9FSKufI5KEuoPsq6ZCnLR_pokvWi8i45Vg9q9Ta9fS8plpLT_mNbXDlq4O7uXQP7SqdwYuD-hmK4tItY_XEc73ucAql6xJIoxwjncBwLNl?key=6gZ2dLlV7xzsqb0CRMkSGA&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 8: Ticket filing diagram.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;882b59d5-3722-4d97-954c-132783948075&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;af0318e1-7967-49ae-a68f-42cbec887322&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;When a test is determined to be unhealthy by the analyzer, in addition to being updated in the database, it’s also inserted into a queue of messages. The queue is then poked by a cadence workflow to examine these tests again and call into JIRA to file tickets to the owning team. A Bazel test target can have multiple test cases, we track each of them as an FQN, but we only want to file one ticket per group of similar tests to reduce noise. Thus we came up with a grouping concept that put all unhealthy FQNs in one ticket per their group–either by build target or by regex.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ad540953-fb38-4b16-8a00-bd112e0573cb&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We also made the entire module customizable, that a user can customize the grouping rule, ticket types, priority, and even the ticket description template. A typical task config looks like this:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0dd3bc99-5289-4056-92cc-41b1efc92745&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;89573d15-7a58-40cc-be19-acc9f36c50b8&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXcOx9cAS4GShBGqQ2zpaS0C0nOYLfRj6oITaJzZS1zphl94Xa8Yh_F3CgcWaiiCgVe5PmdjrwZdkjG-XhDHvqzymBqPDBp6oPS1bm7dtuNKJje1tSzcv_e-JttdXGfhtrTimkxGKj-nP3mbUNjavDYVeSAB?key=6gZ2dLlV7xzsqb0CRMkSGA&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 9: Ticket filing config.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;38f70198-b6a3-430c-a37c-a87da2a113ad&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;445a5cc8-33ba-45e5-bb5f-fa8e7c3b9910&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;This way teams will have different test structures and define their own notification strategy tailored to their users’ experience.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;33d2efc9-9966-4fd1-be74-3909cef2a575&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8689adb6-39e5-44f8-a8c1-f4ebd1d15f5f&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-future-plans&#34;&gt;Future Plans&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7461339c-0fd9-4f32-835e-82ea172ea659&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Uber is actively &lt;a href=&#34;https://www.uber.com/blog/generative-ai-for-high-quality-mobile-testing/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;developing various LLMs&lt;/a&gt; to improve our developer experience. We envision incorporating these cutting-edge technologies in to the system in the future:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;e65a2e04-4d32-4151-b68f-f3125ab85042&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-integrate-genai-for-automated-flaky-tests-resolution&#34;&gt;&lt;strong&gt;Integrate GenAI for automated flaky tests resolution&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;90165264-95ca-4093-ab1a-2692e488aca3&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;89e4f0ed-c7cf-4f0d-813b-a588c699d901&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;After an FQN is imported and analyzed, with access to all its historical data and other tests failing patterns, we could use GenAI to auto-generate fixes for that test. We are exploring GenAI integrations built in-house at Uber to help centrally drive down the number of unsound tests in our Monorepos with minimal input from test owners.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;1a8d12f3-9a7d-486e-be97-aa4095c39440&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-more-granular-failure-categorization-and-sub-categorization&#34;&gt;&lt;strong&gt;More granular failure categorization and sub-categorization&lt;/strong&gt;&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a5652f35-a04c-4bef-810a-6c3d8ed466a2&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;0cbdb05f-4946-48db-8909-cd6a025caf85&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The current FSM model provides generic buckets of categorization, however, not all test failures are the same. Sub-categorizations are done explicitly at the realm level. By leveraging AI to analyze failure patterns, we could automatically categorize test failures into more specific subgroups based on factors such as error logs and types, test environments, or code context of failure. This enhanced classification system would enable us to conduct more efficient troubleshooting and resolutions.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6d81cf93-e710-4a1b-bf30-f77e0da1644b&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;e582e269-4a27-4b1c-bf1d-1509cf36cc4d&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-conclusion&#34;&gt;Conclusion&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;02683e3d-8852-43ba-be66-3d6fad03205d&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Now that all of the major Monorepos at Uber are onboarded to Testopedia, and along with numerous optimizations in both the internal algorithm and infrastructure components, it has been more stable than ever. In the Go Monorepo, we are steadily detecting around 1000 flaky tests out of 600K in total and 1K/350K in Java. We also observed significant improvement in reliability of CI and huge reduction of retries. Nagging developers with Jira tickets containing the right information helped tremendously to reverse the trend of an ever-growing number of unstable tests.&lt;/p&gt;</description>
      <pubDate>Tue, 04 Jun 2024 07:25:02 +0000</pubDate>
    </item>
    <item>
      <title>【How Uber ensures Apache Cassandra®’s tolerance for single-zone failure】Uber 如何确保 Apache Cassandra® 对单区域故障的容忍度</title>
      <link>https://www.uber.com/blog/single-zone-failure-tolerance/</link>
      <description>【&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;5fc4fe6c-0737-484b-8ddf-2ca57c80d238&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-introduction&#34;&gt;Introduction&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f69c5f13-3615-4077-8d5f-3532e989de50&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;a href=&#34;https://www.uber.com/blog/how-uber-optimized-cassandra-operations-at-scale/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Uber has been running an open-source Apache Cassandra&lt;sup&gt;®&lt;/sup&gt; database as a service&lt;/a&gt; that powers a variety of mission-critical online transaction processing (OLTP) workloads for more than six years now at Uber scale, with millions of queries per second and petabytes of data. As Uber operates data centers in multiple zones across multiple regions, a Cassandra cluster at Uber typically has its nodes spread across multiple zones and regions. With high availability being essential for Uber’s business, we’d like to have Cassandra’s availability unaffected in the scenario of a single zone going down. This blog shows how we ensured the single-zone failure tolerance for Cassandra, and particularly how we converted the large Cassandra fleet in real-time with zero downtime from non-zone-failure-tolerant to single-zone-failure tolerant.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;8bf0dfb4-b39f-4171-a3a5-76b927541e21&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-terminology&#34;&gt;Terminology&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2431446b-d46b-46d1-baad-d718dcd4ef1e&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;SZFT&lt;/strong&gt;: Single Zone Failure Tolerant&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;24344de4-31a2-4468-a72d-66d5affba862&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d97f5b1b-c277-4496-9fa0-047ad05bcab4&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-background&#34;&gt;Background&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8de7f022-5e6c-4de1-b92b-82da803c634f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Cassandra naturally supports multiple copies of data. One of the biggest benefits of having multiple copies of data is high availability: if a minority of copies becomes unavailable, the majority of copies can still be accessed. When a Cassandra cluster is deployed across multiple availability zones, we would like to ideally have all the copies distributed evenly among the zones so that an impact to a zone does not impact user requests.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;31d3be95-4092-4049-b767-eb4c022744af&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;width&amp;quot;:&amp;quot;700px&amp;quot;,&amp;quot;height&amp;quot;:&amp;quot;auto&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;2cea3750-1b38-41c4-b6f8-8d34e8657bbf&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXcSTnDyAkLVo_Z0_2lEv-UqaswqOQAZup6hMZKsVASGPumgKy0uf5wCQdcYGmCaI2vFl0U-bVkUY8dz3hfPZATIx7Hzr-HbtdDc53mSvXCfAMUoWI8-kx3MghC73muhugYyr71fk18Au-vNl8eGN5W5uFm9?key=AZe-MVriCM2tBK0R_Gauew&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 1: Single Zone Failure and Availability Impact.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;20fb85c8-ac12-44fb-92b6-67da7927088a&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b16bb2b2-5305-4e3f-89b7-64e3a706b11b&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Figure 1 illustrates the problem. In this example, the replication factor is 3. A data record is considered available when the majority of its copies are available. When zone 1 is down, data record 1 becomes unavailable because it loses the majority (two) of its copies. Meanwhile however, data record 2 is still available because it happens to have a minority (only one) of its replicas placed in the failed zone. If all data records had their replicas placed in the same way as data record 2 where &lt;strong&gt;the&lt;/strong&gt; &lt;strong&gt;replicas are evenly distributed across the zones such that each zone contains only a minority of the copies&lt;/strong&gt;, then the failure of any single zone would have no impact on the overall availability.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3b088613-eab3-4e9c-924f-cab2781b86ca&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Cassandra inherently supports separating the replicas with a feature that logically groups the nodes. Replicas are then separated by the groups. The grouping is done via a file called &lt;em&gt;cassandra-rackdc.properties&lt;/em&gt;.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1a8f3002-e385-400c-9536-18440e038d5d&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In this feature, each Cassandra node is assigned with two properties: &lt;em&gt;dc&lt;/em&gt; and &lt;em&gt;rack&lt;/em&gt;. For example, a Cassandra node in region 1 would be configured as the following:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f7b444cf-2440-4ceb-9242-0cfb4f2192ef&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090731,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;2f30f93b-38f1-4da1-80a7-4ac554f07b0e&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;377&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/cassandra-rackdc-1-1024x377.png&#34; alt=&#34;&#34; class=&#34;wp-image-1090731&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/cassandra-rackdc-1.png 1024w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/cassandra-rackdc-1.png 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/cassandra-rackdc-1.png 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1152,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/cassandra-rackdc-1.png 1152w&#34; sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7fcbecf9-cedf-44b5-9198-1466c53822fe&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;141a0703-68ef-4756-a663-280c3f3e3923&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;When the replication strategy is &lt;a href=&#34;https://cassandra.apache.org/doc/4.1/cassandra/architecture/dynamo.html#network-topology-strategy&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;&lt;em&gt;NetworkTopologyStrategy&lt;/em&gt;&lt;/a&gt;, within a &lt;em&gt;dc&lt;/em&gt;, &lt;strong&gt;for any data record, Cassandra’s replica placement algorithm places replicas onto as many &lt;em&gt;racks&lt;/em&gt; as possible&lt;/strong&gt;. This is illustrated in the below figure:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;310ac262-65e9-42db-9af7-73869e5ed300&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;width&amp;quot;:&amp;quot;700px&amp;quot;,&amp;quot;height&amp;quot;:&amp;quot;auto&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;4b273450-10bf-4b79-9cc1-1d4aa7cd9015&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXegRc24Cr4H85C9-HrRQ-xwAG1MIjpD5JJssb_oLn96JwP4lqx631rWoB5Vq_0vzWcCJmrOmFx5fLvimGURLmBi18tWM_LyYbngSsFq9oEJopiGCtpi1BxEsrVDHC2UU_7ADVBMbc457vFs1rkOXj81_Co?key=AZe-MVriCM2tBK0R_Gauew&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 2: The Desired Setup: Grouping the Nodes by Zone.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7c873913-1e5d-4dbe-bb28-ee53f21efa1a&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f3d6bc04-a9db-4537-aa5e-fc29c32b97a4&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The setup in Figure 2, assuming replication factor is 3, is a desired setup that is SZFT (single zone failure tolerant). No matter which single zone goes down, there will still be two healthy replicas in the other zones serving reads and writes, for any data records.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;cee7de72-24a5-4715-820e-1105e9b512c8&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8001718d-3454-46d5-b978-672a211e47da&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-why-was-cassandra-at-uber-not-szft&#34;&gt;Why was Cassandra at Uber not SZFT&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5827de2f-ffb2-439f-90bd-b1a8b1824771&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Uber was not using the setup in Figure 3–we simply didn’t take advantage of the “rack” property. All the Cassandra nodes were assigned the same “default” value for the rack property, resulting in only one unique rack value in the region. Replicas failed to be properly separated because to separate replicas multiple values for the rack property are needed. As a result, a majority or potentially all replicas can be placed in the same zone, as illustrated in the below figure:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1ce859ad-c8d6-472d-a0e4-b27150790359&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;50737eb5-593e-4692-a938-17c34ea8122d&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXfHvNOqIU6eb_3TL4Xjq32UOYUMe-vrXXI-ZriBakzeWwFkn2FuW-BUakKJAIujnE3tS8zljn1XXGk9w9pVglzfMur7NB8PNxhlcGHGHRqQzy6ZeVFWoPG3QjRNZCoKlpHitu14LgFXiBSvIpNaClZ6qHsn?key=AZe-MVriCM2tBK0R_Gauew&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 3: Uber’s Old Setup: Single Unique Rack.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f9c291a4-b5d8-4b5f-833d-aa3fbc694b80&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a36f68e6-50aa-4c91-8139-248760bf08e4&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;At a high level, solving the problem for Uber essentially meant the transition from the single-rack setup (in Figure 3) to the multi-rack setup with a zone-based rack assignment strategy (in Figure 2). The transition posed multiple challenges. Let’s see what they are and how we overcame them at Uber.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;dcb7aee5-a584-4695-ae8e-e78756263a6c&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;803bbc14-466f-4232-945f-e3bd44f7f148&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-challenge-1-in-place-transition-not-an-option&#34;&gt;Challenge 1: In-Place Transition Not an Option&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b365319c-ad0d-4155-ac47-ea64d2e51119&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;It proved &lt;strong&gt;impractical&lt;/strong&gt; to transition &lt;strong&gt;in-place &lt;/strong&gt;the existing nodes in a region from the single-rack setup to the multi-rack setup. This is because if a node associated with a new rack is introduced to an existing single-rack node setup, it will immediately make the new member a hotspot. As already stated, Cassandra’s replica placement algorithm places replicas onto as many unique racks as possible. The moment a node brings a second rack to Cassandra, all the data records will each place a replica onto the new rack, even though there is only one node in it! Figure 4 well illustrates the problem:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;241bb4ac-9167-4202-b585-dc701823c298&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090555,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;43e1fb21-afc9-493b-bffd-0358b6422dcb&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1007&#34; height=&#34;1024&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f4-1007x1024.png&#34; alt=&#34;&#34; class=&#34;wp-image-1090555&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1007,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f4.png 1007w, https://blog.uber-cdn.com/cdn-cgi/image/width=295,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f4.png 295w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f4.png 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1510,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f4.png 1510w, https://blog.uber-cdn.com/cdn-cgi/image/width=1776,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f4.png 1776w&#34; sizes=&#34;(max-width: 1007px) 100vw, 1007px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 4: Hotspot Issue When Introducing a New Rack to a Single-Rack Setup.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c722bf2c-4ae7-413d-867e-35281af4e864&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f5b50da6-4305-482f-b65a-dc7c7dc5a5b0&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Due to the limitation of the replica placement algorithm, we are left with only one option which at a high level looks as follows:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;ordered&amp;quot;:true,&amp;quot;hash&amp;quot;:&amp;quot;8094ae43-e636-4409-b07e-96330ae4593b&amp;quot;,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Create a new Cassandra ring, or a new “dc” as in NetworkTopologyStrategy,&amp;nbsp; within the same region. The new ring is created with the multi-rack setup to meet the SZFT requirement.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Rebuild the newly created ring through &lt;a href=&#34;https://cassandra.apache.org/doc/stable/cassandra/tools/nodetool/rebuild.html&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;rebuild&lt;/a&gt; from the old live ring.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Transparently swap the new ring with the old ring by moving the customer traffic from one ring to another.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Remove the old ring.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7bc7bde9-ae24-4c8c-a6b7-7273321f4f32&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We set the following principles for this whole migration:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;fa1567e6-8471-40cb-ba85-3797dc9bfc06&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Zero customer involvement—our stakeholders must not be involved or exposed to the migration (e.g., changing service logic, client code, or routing)&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;High Availability—no down time during migration&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Maintaining pre-existing performance SLOs, such as latency&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Rollback capability so we can switch back and forth between the old ring and the new ring as an emergency measure&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d72209cb-bf37-4bba-bcb9-13bf56090f3e&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c05fd87f-a68f-420e-bc70-6eec86ab7dd2&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-the-rebuild-procedure&#34;&gt;The Rebuild Procedure&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;17273b8c-c1ad-4f02-b207-ec110a0acf91&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-phase-1-provision-a-new-set-of-offline-multi-rack-nodes-in-the-region&#34;&gt;Phase 1: Provision a new set of “offline” multi-rack nodes in the region&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c542c36c-5bac-4c84-a50a-4a13c99551dd&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In the selected region, add a new ring of nodes to the cluster. The hardware resource given to the new nodes (e.g., node count, CPU cores, memory, disk size) need to be the same as the existing ring in that region. Distribute the new nodes evenly across the zones. Group them with the zone-based strategy by configuring the &lt;em&gt;cassandra-rackdc.properties&lt;/em&gt; file of each node as following:&lt;/p&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;13351642-4379-4fca-ade3-76c075a1d3e5&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXcH74hsYf-WXgoNrypJz7LTOJWRLDvYZIIguWfE3jCblgpTyxzh28JN2ORfhR_odddRm1wXerjO-rUZj0A0qruZ6TXDxTHwvWHxBXnebkbT4fGIEfLhcEa5s9LsNCnzmWVoJ7gmv0t0MAhSgBAirKebyVxP?key=AZe-MVriCM2tBK0R_Gauew&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;dfd9890d-56d6-4ee5-93ea-961bb9ffddad&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Lastly, all the new nodes should be created with &lt;a href=&#34;https://cassandra.apache.org/doc/stable/cassandra/tools/nodetool/disablebinary.html&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;native transport disabled&lt;/a&gt; to prevent CQL connection to them. This is crucial for a seamless traffic switch later from the existing ring to the new one.&lt;/p&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090556,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;a093cbf1-7fb7-4aa4-b322-e097fb5623c9&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;729&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f5-1024x729.png&#34; alt=&#34;&#34; class=&#34;wp-image-1090556&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f5.png 1024w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f5.png 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f5.png 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1262,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f5.png 1262w&#34; sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 5: Phase 1: provision a new set of multi-rack nodes with binary disabled.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;55ba8202-8606-42db-a101-766aa2dad5f5&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;a9d92e66-3feb-4b57-8e47-a956de997fd8&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-phase-2-data-sync-for-live-writes&#34;&gt;Phase 2: Data Sync for Live Writes&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;99451c2d-2a9a-47db-b1ad-89faaf1e6b05&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;As our end goal is to have the new ring replace the old ring, we need to have all the data replicated and existing in both rings. This includes both the data from the live writes as well as the historical data. For the data from the live writes, we need to add the new ring to the replication setting of all the keyspaces such that they can start to indirectly receive live writes thanks to Cassandra’s cross-dc replication.&lt;/p&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090732,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;b6d4f985-4d8b-4576-9d1b-0c5bc080432c&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;381&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/alter-keyspace-3333-1024x381.png&#34; alt=&#34;&#34; class=&#34;wp-image-1090732&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/alter-keyspace-3333.png 1024w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/alter-keyspace-3333.png 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/alter-keyspace-3333.png 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1118,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/alter-keyspace-3333.png 1118w&#34; sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090557,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;9135df85-dfb1-4042-81d1-613a49c2b509&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;720&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f6-1024x720.png&#34; alt=&#34;&#34; class=&#34;wp-image-1090557&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f6.png 1024w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f6.png 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f6.png 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1253,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f6.png 1253w&#34; sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 6: Phase 2: include the new set of nodes in replication.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d1bd50b8-60b7-41eb-b01a-d6e5c6419802&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;59ce3e71-3b3d-4137-ab38-44de16f17590&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-phase-3-data-sync-for-historical-data&#34;&gt;Phase 3: Data Sync for Historical Data&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f59b9c48-c2f1-41c7-b67e-e58b7332b54d&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;For historical data, we need to have the new ring stream it from the old ring. Although the new nodes are now receiving live writes, they are still lacking all the data from the past. Cassandra provides a tool to stream such data using the nodetool rebuild command. The following command needs to be run on every new node of &lt;em&gt;region1_new&lt;/em&gt; to stream data from &lt;em&gt;region1&lt;/em&gt;:&lt;/p&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090734,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;5b44bf2e-a523-43d6-a2ca-de30b10f1fbc&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;138&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/nodetool-rebuild-1024x138.png&#34; alt=&#34;&#34; class=&#34;wp-image-1090734&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/nodetool-rebuild.png 1024w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/nodetool-rebuild.png 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/nodetool-rebuild.png 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1112,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/nodetool-rebuild.png 1112w&#34; sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;0d7b769d-7498-4d2c-b195-9804f3f9a1bd&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXft9Qy90P61zHHyDGRk1L-IrXN866dHr8WMyGbEe-_05rtLUdE_171HSBDlkFowzOnG9Ka40w79XsIiT91h2md32ikNehFv86ncC0xmN-G6aDa7S5yUS1eRhB_-sfHRy7veOzNTt0lSRc9FjuzEMpFDDD9D?key=AZe-MVriCM2tBK0R_Gauew&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 7: Phase 3: sync old data.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c85a1994-e788-449e-b314-f2d43b9ce04c&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;e2d1ad85-f797-4d28-a4b1-c8501a92d9b6&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-phase-4-traffic-switch&#34;&gt;Phase 4: Traffic Switch&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9be925b3-a119-4af6-bb79-ece136ee2b52&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;After the historical data has been streamed, we are ready to have the Cassandra client connect to the new ring of nodes and stop connecting to the old. This is done by &lt;a href=&#34;https://cassandra.apache.org/doc/stable/cassandra/tools/nodetool/enablebinary.html&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;enabling native transport&lt;/a&gt; on all the nodes in the new ring and then &lt;a href=&#34;https://cassandra.apache.org/doc/stable/cassandra/tools/nodetool/disablebinary.html&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;disabling native transport&lt;/a&gt; on all the nodes in the old ring. We’ve eliminated the need for any actions on the client side, the reason for which will be discussed in the next section where we are going to see the Cassandra client enhancement we’ve made at Uber.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e786234e-2d54-41ba-9ff9-510533cf9c09&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;width&amp;quot;:&amp;quot;700px&amp;quot;,&amp;quot;height&amp;quot;:&amp;quot;auto&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;11e99c4b-be82-4521-9ac8-9640150d0621&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXf6wcyJD06iUE8_JWw81JUucwUyHl-xEeQRmUNftN2rLvtBeU0vgE53GWTIYQvWhGvMFM7Stbz4hUuuBGTpQX1qBDikqwrHNa__Y3tkcvdnoRk3MA3f97eyOHW0sXJahDq2I1PaxzPxcNet7SNYvVGpoNiP?key=AZe-MVriCM2tBK0R_Gauew&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 8: Phase 4: traffic switch.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;06b8cced-4362-435e-bae3-a26771b778a2&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;c65f13f4-e2c6-4605-bf58-b71a9a56a80c&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-phase-5-remove-old-nodes&#34;&gt;Phase 5: Remove Old Nodes&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6aabb217-a3d9-4462-bf23-982607dbff4c&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Firstly, the replication setting of all the keyspaces needs to be altered so that the old ring is no longer part of the data replication.&lt;/p&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090735,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;e5955543-fc53-4e83-8345-b7f3075c17c1&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;339&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Alter-keyspace-333-1024x339.png&#34; alt=&#34;&#34; class=&#34;wp-image-1090735&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Alter-keyspace-333.png 1024w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Alter-keyspace-333.png 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Alter-keyspace-333.png 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1196,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Alter-keyspace-333.png 1196w&#34; sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;918a3fa8-869a-4608-84f5-6ea3614dd859&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Once this is done, the nodes in the old ring are decommissioned.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b9a9e310-db11-4ed5-9360-7697535fc833&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;width&amp;quot;:&amp;quot;700px&amp;quot;,&amp;quot;height&amp;quot;:&amp;quot;auto&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;5a00a491-e698-481f-b0d5-f467b6dc803c&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXcDvHs74P1MCQgreqSpD_eOglh3jidW2ydJN4TthFJGd5BOMq6tTk-FE04jLk-LFacE1cRXKQGH6nvmXzP1FDpO7TiQefYYl8dhEV34zSMIZ1uPfQZu66743WCZrHkz3aloDsPF8qVOs_fZhgUM_TyoncnY?key=AZe-MVriCM2tBK0R_Gauew&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 9: Phase 5: get rid of the old set of nodes.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2bb0dfc4-90fd-4d9d-93cb-0911117b0dc2&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;8c10f5cd-7b7e-4079-8526-49f4f2d7b3a3&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-phase-6-repeat-for-the-other-regions&#34;&gt;Phase 6: Repeat for the other regions&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b6d9edbf-0438-41f0-bf95-5ed8b9965802&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The Cassandra cluster in the selected region is now SZFT. The same procedure needs to be repeated for the other regions.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e083bdef-556a-48f0-98aa-5a89b24bb74d&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;171cb21c-d216-4dfe-9660-cf05b6590cbc&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-cassandra-client-enhancement&#34;&gt;Cassandra Client Enhancement&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1dca4857-15d6-43db-adce-9e74a2876528&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;During the above procedure, no client side actions are involved. This is because at Uber, we have a fork of GoCQL and Java drivers where we have enhanced them to be capable of dynamically switching traffic from one ring to another without a restart.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8023f66f-9c9c-4197-8940-3aa9f7b23f02&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In order to achieve a seamless traffic switch, the expectation on the Cassandra clients are to:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;ordered&amp;quot;:true,&amp;quot;hash&amp;quot;:&amp;quot;5afa16f1-8c7d-4306-b970-2b77b6776b4a&amp;quot;,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Always be provided with initial Cassandra contact points (i.e., the Cassandra nodes for the initial topology discovery) from the same region where the client is.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Always choose coordinator nodes from the same region where the client is.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Automatically connect to the nodes of the new ring, after native-transport is enabled on them and disabled on the nodes of the old ring, as in Phase 4 of the Rebuild Procedure.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;cb8bdfe0-6a4b-4bb0-b12c-1bde36b71eea&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Requirement #1 was fulfilled with a new micro-service that’s dedicated to publishing the contact information of Cassandra clusters. It has an integration with our Cassandra control plane and thus understands the topology of every Cassandra cluster. The consumer of this service (in this case a Cassandra client) sends a request containing only the name of the target Cassandra cluster. The service returns the contact information (e.g., IPs and ports) of all the nodes belonging to the cluster &lt;strong&gt;that are in the same region as the consumer&lt;/strong&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;53df3941-e5cd-4cf5-a1da-83eb75c79101&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The above logic is hidden from the client API, and our Cassandra users simply need to change their way of providing the client with contact points, as the following:&lt;/p&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090736,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;699f2caf-abaa-4db0-a1f2-d9a3f415dc64&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;91&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Cluster-builder-1024x91.png&#34; alt=&#34;&#34; class=&#34;wp-image-1090736&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Cluster-builder.png 1024w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Cluster-builder.png 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Cluster-builder.png 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1302,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Cluster-builder.png 1302w&#34; sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;53df3941-e5cd-4cf5-a1da-83eb75c79101&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Requirement #2 was done with a new host filter we implemented at Uber within the Cassandra clients. This new host filter excludes all the coordinator nodes that are located in regions remote to the client.&lt;/p&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090737,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;a830e016-1133-47a6-bf87-9d28e3b6ec7b&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;105&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/HostFilterPolicy-1024x105.png&#34; alt=&#34;&#34; class=&#34;wp-image-1090737&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/HostFilterPolicy.png 1024w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/HostFilterPolicy.png 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/HostFilterPolicy.png 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1290,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/HostFilterPolicy.png 1290w&#34; sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;64649522-f053-4d5c-8da2-601abe88fa8e&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Requirement #3 was achieved by specifying the load balance policy as TokenAware + RoundRobin. The thing that really matters is not the use of these policies, but the elimination of the use of DCAwarePolicy. DCAwarePolicy, which was once seen in many Cassandra applications at Uber, pins the coordinator node selection to the old ring. Open-source clients were already capable of capturing the native-transport-related changes in a timely fashion, automatically dropping connection to the native-transport-disabled nodes and automatically connecting to the newly-native-transport-enabled nodes. Therefore all we needed to do was allow clients to connect to any rings in the same region.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f63648b9-e4f6-4c52-bfd8-ed8ac6de4cb8&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In the end, we standardized the Cassandra client configuration at Uber like this:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090738,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;afa165bc-ce7b-40fc-8755-707011ddc4c7&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;wp-block-image size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;337&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/HostFilter-and-Clusterbuilder-1024x337.png&#34; alt=&#34;&#34; class=&#34;wp-image-1090738&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/HostFilter-and-Clusterbuilder.png 1024w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/HostFilter-and-Clusterbuilder.png 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/HostFilter-and-Clusterbuilder.png 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1308,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/HostFilter-and-Clusterbuilder.png 1308w&#34; sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d13ccf86-6323-4320-a12f-38966090aea7&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;These enhancements in the client elegantly decouple users from the low-level topology detail of the Cassandra cluster–e.g., IP, port, dc (as in NetworkTopologyStrategy), etc. It paves the way for a seamless traffic switch in Phase 4 of the rebuild procedure. Moreover, the region-based coordinator selection paired with “LOCAL_QUORUM” reads and writes ensures that during the rebuild procedure in one region, Cassandra clients in the other regions won’t see any impact, as they are always directly exchanging data with Cassandra nodes in their local region, allowing for region-by-region SZFT transition.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e6638124-5a65-43fb-960c-4dcd83b0d3c5&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;21ab4486-37ee-4594-a963-77246bfe6045&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-challenge-2-nbsp-lack-of-uniform-spare-server-capacity-across-zones&#34;&gt;Challenge 2:&amp;nbsp; Lack of uniform spare server capacity across Zones&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8d569cb2-ac03-4406-92cc-a7cdf09cfa9f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;For the multi-rack setup where each Cassandra rack is a zone, we need to ensure there are always enough zones available (i.e., number of zones ≥ replication_factor). In addition, the spare capacity in each of the zones needs to be uniform for each of the racks to be equally scaled when scaling the cluster.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c53bdf23-33c3-45aa-851c-2b1285a00629&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;This can appear less challenging in cases where the size of the clusters is small and hence the amount of scaling needed is small or if there are stronger guarantees of spare capacity in all zones. However in practice, it is very possible to have the available capacity spread non-uniformly across the zones. In such a scenario, performing a potentially urgent horizontal upscaling of the cluster would inevitably lead to sacrificing the SZFT property of the cluster.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9da57313-7bdd-4177-a093-d742ceb324e8&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Regardless of the capacity situation, we should be prepared for handling such a scenario. When both the SZFT property and the urgent need for horizontal scale can not be met at the same time, we have to prioritize the immediate performance needs of the cluster via the horizontal scale. It is important to keep in mind that, once additional capacity eventually arrives at the other zones, we should be able to “relocate” the nodes added during the scale to the desired zones with minimal number of node replacements, ultimately achieving SZFT. The entire process is quite operationally demanding, and we need refined automation to significantly reduce manual effort.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4ea136ad-bb51-4dbd-bb80-9dd7b1a25a13&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We are not going to expand on this challenge in this blog, as it pertains to the server capacity management aspect. We at Uber have ensured that we are prepared to tackle such a scenario in a fully automated manner, thanks to our &lt;em&gt;Stateful Platform&lt;/em&gt; team, which runs our underlying storage management and control plane platform.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;644a0056-674f-4a88-a1e9-25b7190d63b3&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8fec6c26-c92d-4819-aebc-6b735d32f312&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-highlights&#34;&gt;Highlights&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ec4afdb3-1091-4066-9ee9-3f0d9292df3e&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The success of this critical project is measured as follows:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;ordered&amp;quot;:true,&amp;quot;hash&amp;quot;:&amp;quot;2e3f35e9-e450-4b32-bf05-d9242d9ebe4a&amp;quot;,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;The rollout has completed on the vast majority of the Cassandra fleet. For months after the rollout, no issue has been seen.&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;During the rollout, no major incident was caused.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;The whole exercise was entirely transparent for our stakeholders.&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;We conducted multiple tests in which we virtually brought down an entire production zone, and Cassandra’s stakeholders were unaffected!&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8f01d5e8-18b4-42ab-88e9-e8f5889107a9&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;01a2d6cf-39f7-4607-8f6a-4e30019cc229&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-conclusion&#34;&gt;Conclusion&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3cfe4f93-9652-4f6d-9bc0-0d4eedc7c3c2&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In this article, we have showcased the Cassandra deployment at Uber. We have also highlighted the challenges of achieving single zone failure tolerance, and dived deep into the solutions.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;fontSize&amp;quot;:&amp;quot;small&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;c67767ae-c3de-43f5-b72e-4960a271ebf5&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34; class=&#34;has-small-font-size&#34;&gt;&lt;strong&gt;Cover Photo Attribution&lt;/strong&gt;: This image was generated using ChatGPT.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;fontSize&amp;quot;:&amp;quot;small&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;6fd34c76-0a77-427f-b89c-eb366e6d8379&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34; class=&#34;has-small-font-size&#34;&gt;Apache® and Apache Cassandra® are either registered trademarks or trademarks of the Apache Software Foundation in the United States and/or other countries. No endorsement by The Apache Software Foundation is implied by the use of these marks.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;fontSize&amp;quot;:&amp;quot;small&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;bc71ef0b-63c9-4699-b17a-379b441aabb7&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34; class=&#34;has-small-font-size&#34;&gt;Oracle, Java, MySQL, and NetSuite are registered trademarks of Oracle and/or its affiliates. Other names may be trademarks of their respective owners.&lt;/p&gt;】&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;5fc4fe6c-0737-484b-8ddf-2ca57c80d238&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-introduction&#34;&gt;Introduction&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f69c5f13-3615-4077-8d5f-3532e989de50&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;a href=&#34;https://www.uber.com/blog/how-uber-optimized-cassandra-operations-at-scale/&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;Uber has been running an open-source Apache Cassandra&lt;sup&gt;®&lt;/sup&gt; database as a service&lt;/a&gt; that powers a variety of mission-critical online transaction processing (OLTP) workloads for more than six years now at Uber scale, with millions of queries per second and petabytes of data. As Uber operates data centers in multiple zones across multiple regions, a Cassandra cluster at Uber typically has its nodes spread across multiple zones and regions. With high availability being essential for Uber’s business, we’d like to have Cassandra’s availability unaffected in the scenario of a single zone going down. This blog shows how we ensured the single-zone failure tolerance for Cassandra, and particularly how we converted the large Cassandra fleet in real-time with zero downtime from non-zone-failure-tolerant to single-zone-failure tolerant.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;8bf0dfb4-b39f-4171-a3a5-76b927541e21&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-terminology&#34;&gt;Terminology&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2431446b-d46b-46d1-baad-d718dcd4ef1e&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;&lt;strong&gt;SZFT&lt;/strong&gt;: Single Zone Failure Tolerant&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;24344de4-31a2-4468-a72d-66d5affba862&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d97f5b1b-c277-4496-9fa0-047ad05bcab4&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-background&#34;&gt;Background&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8de7f022-5e6c-4de1-b92b-82da803c634f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Cassandra naturally supports multiple copies of data. One of the biggest benefits of having multiple copies of data is high availability: if a minority of copies becomes unavailable, the majority of copies can still be accessed. When a Cassandra cluster is deployed across multiple availability zones, we would like to ideally have all the copies distributed evenly among the zones so that an impact to a zone does not impact user requests.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;31d3be95-4092-4049-b767-eb4c022744af&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;width&amp;quot;:&amp;quot;700px&amp;quot;,&amp;quot;height&amp;quot;:&amp;quot;auto&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;2cea3750-1b38-41c4-b6f8-8d34e8657bbf&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXcSTnDyAkLVo_Z0_2lEv-UqaswqOQAZup6hMZKsVASGPumgKy0uf5wCQdcYGmCaI2vFl0U-bVkUY8dz3hfPZATIx7Hzr-HbtdDc53mSvXCfAMUoWI8-kx3MghC73muhugYyr71fk18Au-vNl8eGN5W5uFm9?key=AZe-MVriCM2tBK0R_Gauew&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 1: Single Zone Failure and Availability Impact.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;20fb85c8-ac12-44fb-92b6-67da7927088a&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b16bb2b2-5305-4e3f-89b7-64e3a706b11b&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Figure 1 illustrates the problem. In this example, the replication factor is 3. A data record is considered available when the majority of its copies are available. When zone 1 is down, data record 1 becomes unavailable because it loses the majority (two) of its copies. Meanwhile however, data record 2 is still available because it happens to have a minority (only one) of its replicas placed in the failed zone. If all data records had their replicas placed in the same way as data record 2 where &lt;strong&gt;the&lt;/strong&gt; &lt;strong&gt;replicas are evenly distributed across the zones such that each zone contains only a minority of the copies&lt;/strong&gt;, then the failure of any single zone would have no impact on the overall availability.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3b088613-eab3-4e9c-924f-cab2781b86ca&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Cassandra inherently supports separating the replicas with a feature that logically groups the nodes. Replicas are then separated by the groups. The grouping is done via a file called &lt;em&gt;cassandra-rackdc.properties&lt;/em&gt;.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1a8f3002-e385-400c-9536-18440e038d5d&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In this feature, each Cassandra node is assigned with two properties: &lt;em&gt;dc&lt;/em&gt; and &lt;em&gt;rack&lt;/em&gt;. For example, a Cassandra node in region 1 would be configured as the following:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f7b444cf-2440-4ceb-9242-0cfb4f2192ef&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090731,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;2f30f93b-38f1-4da1-80a7-4ac554f07b0e&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;377&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/cassandra-rackdc-1-1024x377.png&#34; alt=&#34;&#34; class=&#34;wp-image-1090731&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/cassandra-rackdc-1.png 1024w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/cassandra-rackdc-1.png 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/cassandra-rackdc-1.png 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1152,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/cassandra-rackdc-1.png 1152w&#34; sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7fcbecf9-cedf-44b5-9198-1466c53822fe&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;141a0703-68ef-4756-a663-280c3f3e3923&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;When the replication strategy is &lt;a href=&#34;https://cassandra.apache.org/doc/4.1/cassandra/architecture/dynamo.html#network-topology-strategy&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;&lt;em&gt;NetworkTopologyStrategy&lt;/em&gt;&lt;/a&gt;, within a &lt;em&gt;dc&lt;/em&gt;, &lt;strong&gt;for any data record, Cassandra’s replica placement algorithm places replicas onto as many &lt;em&gt;racks&lt;/em&gt; as possible&lt;/strong&gt;. This is illustrated in the below figure:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;310ac262-65e9-42db-9af7-73869e5ed300&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;width&amp;quot;:&amp;quot;700px&amp;quot;,&amp;quot;height&amp;quot;:&amp;quot;auto&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;4b273450-10bf-4b79-9cc1-1d4aa7cd9015&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXegRc24Cr4H85C9-HrRQ-xwAG1MIjpD5JJssb_oLn96JwP4lqx631rWoB5Vq_0vzWcCJmrOmFx5fLvimGURLmBi18tWM_LyYbngSsFq9oEJopiGCtpi1BxEsrVDHC2UU_7ADVBMbc457vFs1rkOXj81_Co?key=AZe-MVriCM2tBK0R_Gauew&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 2: The Desired Setup: Grouping the Nodes by Zone.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7c873913-1e5d-4dbe-bb28-ee53f21efa1a&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f3d6bc04-a9db-4537-aa5e-fc29c32b97a4&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The setup in Figure 2, assuming replication factor is 3, is a desired setup that is SZFT (single zone failure tolerant). No matter which single zone goes down, there will still be two healthy replicas in the other zones serving reads and writes, for any data records.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;cee7de72-24a5-4715-820e-1105e9b512c8&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8001718d-3454-46d5-b978-672a211e47da&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-why-was-cassandra-at-uber-not-szft&#34;&gt;Why was Cassandra at Uber not SZFT&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;5827de2f-ffb2-439f-90bd-b1a8b1824771&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Uber was not using the setup in Figure 3–we simply didn’t take advantage of the “rack” property. All the Cassandra nodes were assigned the same “default” value for the rack property, resulting in only one unique rack value in the region. Replicas failed to be properly separated because to separate replicas multiple values for the rack property are needed. As a result, a majority or potentially all replicas can be placed in the same zone, as illustrated in the below figure:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1ce859ad-c8d6-472d-a0e4-b27150790359&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;50737eb5-593e-4692-a938-17c34ea8122d&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXfHvNOqIU6eb_3TL4Xjq32UOYUMe-vrXXI-ZriBakzeWwFkn2FuW-BUakKJAIujnE3tS8zljn1XXGk9w9pVglzfMur7NB8PNxhlcGHGHRqQzy6ZeVFWoPG3QjRNZCoKlpHitu14LgFXiBSvIpNaClZ6qHsn?key=AZe-MVriCM2tBK0R_Gauew&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 3: Uber’s Old Setup: Single Unique Rack.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f9c291a4-b5d8-4b5f-833d-aa3fbc694b80&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;a36f68e6-50aa-4c91-8139-248760bf08e4&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;At a high level, solving the problem for Uber essentially meant the transition from the single-rack setup (in Figure 3) to the multi-rack setup with a zone-based rack assignment strategy (in Figure 2). The transition posed multiple challenges. Let’s see what they are and how we overcame them at Uber.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;dcb7aee5-a584-4695-ae8e-e78756263a6c&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;803bbc14-466f-4232-945f-e3bd44f7f148&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-challenge-1-in-place-transition-not-an-option&#34;&gt;Challenge 1: In-Place Transition Not an Option&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b365319c-ad0d-4155-ac47-ea64d2e51119&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;It proved &lt;strong&gt;impractical&lt;/strong&gt; to transition &lt;strong&gt;in-place &lt;/strong&gt;the existing nodes in a region from the single-rack setup to the multi-rack setup. This is because if a node associated with a new rack is introduced to an existing single-rack node setup, it will immediately make the new member a hotspot. As already stated, Cassandra’s replica placement algorithm places replicas onto as many unique racks as possible. The moment a node brings a second rack to Cassandra, all the data records will each place a replica onto the new rack, even though there is only one node in it! Figure 4 well illustrates the problem:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;241bb4ac-9167-4202-b585-dc701823c298&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090555,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;43e1fb21-afc9-493b-bffd-0358b6422dcb&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1007&#34; height=&#34;1024&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f4-1007x1024.png&#34; alt=&#34;&#34; class=&#34;wp-image-1090555&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1007,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f4.png 1007w, https://blog.uber-cdn.com/cdn-cgi/image/width=295,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f4.png 295w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f4.png 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1510,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f4.png 1510w, https://blog.uber-cdn.com/cdn-cgi/image/width=1776,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f4.png 1776w&#34; sizes=&#34;(max-width: 1007px) 100vw, 1007px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 4: Hotspot Issue When Introducing a New Rack to a Single-Rack Setup.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c722bf2c-4ae7-413d-867e-35281af4e864&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f5b50da6-4305-482f-b65a-dc7c7dc5a5b0&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Due to the limitation of the replica placement algorithm, we are left with only one option which at a high level looks as follows:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;ordered&amp;quot;:true,&amp;quot;hash&amp;quot;:&amp;quot;8094ae43-e636-4409-b07e-96330ae4593b&amp;quot;,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Create a new Cassandra ring, or a new “dc” as in NetworkTopologyStrategy,&amp;nbsp; within the same region. The new ring is created with the multi-rack setup to meet the SZFT requirement.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Rebuild the newly created ring through &lt;a href=&#34;https://cassandra.apache.org/doc/stable/cassandra/tools/nodetool/rebuild.html&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;rebuild&lt;/a&gt; from the old live ring.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Transparently swap the new ring with the old ring by moving the customer traffic from one ring to another.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Remove the old ring.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;7bc7bde9-ae24-4c8c-a6b7-7273321f4f32&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We set the following principles for this whole migration:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ul data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;fa1567e6-8471-40cb-ba85-3797dc9bfc06&amp;quot;,&amp;quot;ordered&amp;quot;:false,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Zero customer involvement—our stakeholders must not be involved or exposed to the migration (e.g., changing service logic, client code, or routing)&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;High Availability—no down time during migration&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Maintaining pre-existing performance SLOs, such as latency&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Rollback capability so we can switch back and forth between the old ring and the new ring as an emergency measure&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d72209cb-bf37-4bba-bcb9-13bf56090f3e&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c05fd87f-a68f-420e-bc70-6eec86ab7dd2&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-the-rebuild-procedure&#34;&gt;The Rebuild Procedure&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;17273b8c-c1ad-4f02-b207-ec110a0acf91&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-phase-1-provision-a-new-set-of-offline-multi-rack-nodes-in-the-region&#34;&gt;Phase 1: Provision a new set of “offline” multi-rack nodes in the region&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c542c36c-5bac-4c84-a50a-4a13c99551dd&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In the selected region, add a new ring of nodes to the cluster. The hardware resource given to the new nodes (e.g., node count, CPU cores, memory, disk size) need to be the same as the existing ring in that region. Distribute the new nodes evenly across the zones. Group them with the zone-based strategy by configuring the &lt;em&gt;cassandra-rackdc.properties&lt;/em&gt; file of each node as following:&lt;/p&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;13351642-4379-4fca-ade3-76c075a1d3e5&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXcH74hsYf-WXgoNrypJz7LTOJWRLDvYZIIguWfE3jCblgpTyxzh28JN2ORfhR_odddRm1wXerjO-rUZj0A0qruZ6TXDxTHwvWHxBXnebkbT4fGIEfLhcEa5s9LsNCnzmWVoJ7gmv0t0MAhSgBAirKebyVxP?key=AZe-MVriCM2tBK0R_Gauew&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;dfd9890d-56d6-4ee5-93ea-961bb9ffddad&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Lastly, all the new nodes should be created with &lt;a href=&#34;https://cassandra.apache.org/doc/stable/cassandra/tools/nodetool/disablebinary.html&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;native transport disabled&lt;/a&gt; to prevent CQL connection to them. This is crucial for a seamless traffic switch later from the existing ring to the new one.&lt;/p&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090556,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;a093cbf1-7fb7-4aa4-b322-e097fb5623c9&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;729&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f5-1024x729.png&#34; alt=&#34;&#34; class=&#34;wp-image-1090556&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f5.png 1024w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f5.png 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f5.png 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1262,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f5.png 1262w&#34; sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 5: Phase 1: provision a new set of multi-rack nodes with binary disabled.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;55ba8202-8606-42db-a101-766aa2dad5f5&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;a9d92e66-3feb-4b57-8e47-a956de997fd8&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-phase-2-data-sync-for-live-writes&#34;&gt;Phase 2: Data Sync for Live Writes&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;99451c2d-2a9a-47db-b1ad-89faaf1e6b05&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;As our end goal is to have the new ring replace the old ring, we need to have all the data replicated and existing in both rings. This includes both the data from the live writes as well as the historical data. For the data from the live writes, we need to add the new ring to the replication setting of all the keyspaces such that they can start to indirectly receive live writes thanks to Cassandra’s cross-dc replication.&lt;/p&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090732,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;b6d4f985-4d8b-4576-9d1b-0c5bc080432c&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;381&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/alter-keyspace-3333-1024x381.png&#34; alt=&#34;&#34; class=&#34;wp-image-1090732&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/alter-keyspace-3333.png 1024w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/alter-keyspace-3333.png 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/alter-keyspace-3333.png 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1118,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/alter-keyspace-3333.png 1118w&#34; sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090557,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;9135df85-dfb1-4042-81d1-613a49c2b509&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;720&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f6-1024x720.png&#34; alt=&#34;&#34; class=&#34;wp-image-1090557&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f6.png 1024w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f6.png 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f6.png 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1253,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/szft-blog-f6.png 1253w&#34; sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 6: Phase 2: include the new set of nodes in replication.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d1bd50b8-60b7-41eb-b01a-d6e5c6419802&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;59ce3e71-3b3d-4137-ab38-44de16f17590&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-phase-3-data-sync-for-historical-data&#34;&gt;Phase 3: Data Sync for Historical Data&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f59b9c48-c2f1-41c7-b67e-e58b7332b54d&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;For historical data, we need to have the new ring stream it from the old ring. Although the new nodes are now receiving live writes, they are still lacking all the data from the past. Cassandra provides a tool to stream such data using the nodetool rebuild command. The following command needs to be run on every new node of &lt;em&gt;region1_new&lt;/em&gt; to stream data from &lt;em&gt;region1&lt;/em&gt;:&lt;/p&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090734,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;5b44bf2e-a523-43d6-a2ca-de30b10f1fbc&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;138&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/nodetool-rebuild-1024x138.png&#34; alt=&#34;&#34; class=&#34;wp-image-1090734&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/nodetool-rebuild.png 1024w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/nodetool-rebuild.png 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/nodetool-rebuild.png 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1112,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/nodetool-rebuild.png 1112w&#34; sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;0d7b769d-7498-4d2c-b195-9804f3f9a1bd&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXft9Qy90P61zHHyDGRk1L-IrXN866dHr8WMyGbEe-_05rtLUdE_171HSBDlkFowzOnG9Ka40w79XsIiT91h2md32ikNehFv86ncC0xmN-G6aDa7S5yUS1eRhB_-sfHRy7veOzNTt0lSRc9FjuzEMpFDDD9D?key=AZe-MVriCM2tBK0R_Gauew&#34; alt=&#34;&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 7: Phase 3: sync old data.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c85a1994-e788-449e-b314-f2d43b9ce04c&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;e2d1ad85-f797-4d28-a4b1-c8501a92d9b6&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-phase-4-traffic-switch&#34;&gt;Phase 4: Traffic Switch&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9be925b3-a119-4af6-bb79-ece136ee2b52&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;After the historical data has been streamed, we are ready to have the Cassandra client connect to the new ring of nodes and stop connecting to the old. This is done by &lt;a href=&#34;https://cassandra.apache.org/doc/stable/cassandra/tools/nodetool/enablebinary.html&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;enabling native transport&lt;/a&gt; on all the nodes in the new ring and then &lt;a href=&#34;https://cassandra.apache.org/doc/stable/cassandra/tools/nodetool/disablebinary.html&#34; target=&#34;_blank&#34; rel=&#34;noreferrer noopener&#34;&gt;disabling native transport&lt;/a&gt; on all the nodes in the old ring. We’ve eliminated the need for any actions on the client side, the reason for which will be discussed in the next section where we are going to see the Cassandra client enhancement we’ve made at Uber.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e786234e-2d54-41ba-9ff9-510533cf9c09&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;width&amp;quot;:&amp;quot;700px&amp;quot;,&amp;quot;height&amp;quot;:&amp;quot;auto&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;11e99c4b-be82-4521-9ac8-9640150d0621&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXf6wcyJD06iUE8_JWw81JUucwUyHl-xEeQRmUNftN2rLvtBeU0vgE53GWTIYQvWhGvMFM7Stbz4hUuuBGTpQX1qBDikqwrHNa__Y3tkcvdnoRk3MA3f97eyOHW0sXJahDq2I1PaxzPxcNet7SNYvVGpoNiP?key=AZe-MVriCM2tBK0R_Gauew&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 8: Phase 4: traffic switch.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;06b8cced-4362-435e-bae3-a26771b778a2&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;c65f13f4-e2c6-4605-bf58-b71a9a56a80c&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-phase-5-remove-old-nodes&#34;&gt;Phase 5: Remove Old Nodes&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;6aabb217-a3d9-4462-bf23-982607dbff4c&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Firstly, the replication setting of all the keyspaces needs to be altered so that the old ring is no longer part of the data replication.&lt;/p&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090735,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;e5955543-fc53-4e83-8345-b7f3075c17c1&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;339&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Alter-keyspace-333-1024x339.png&#34; alt=&#34;&#34; class=&#34;wp-image-1090735&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Alter-keyspace-333.png 1024w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Alter-keyspace-333.png 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Alter-keyspace-333.png 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1196,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Alter-keyspace-333.png 1196w&#34; sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;918a3fa8-869a-4608-84f5-6ea3614dd859&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Once this is done, the nodes in the old ring are decommissioned.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b9a9e310-db11-4ed5-9360-7697535fc833&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;width&amp;quot;:&amp;quot;700px&amp;quot;,&amp;quot;height&amp;quot;:&amp;quot;auto&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;5a00a491-e698-481f-b0d5-f467b6dc803c&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter is-resized&#34;&gt;&lt;img decoding=&#34;async&#34; src=&#34;https://lh7-us.googleusercontent.com/docsz/AD_4nXcDvHs74P1MCQgreqSpD_eOglh3jidW2ydJN4TthFJGd5BOMq6tTk-FE04jLk-LFacE1cRXKQGH6nvmXzP1FDpO7TiQefYYl8dhEV34zSMIZ1uPfQZu66743WCZrHkz3aloDsPF8qVOs_fZhgUM_TyoncnY?key=AZe-MVriCM2tBK0R_Gauew&#34; alt=&#34;&#34; style=&#34;width:700px;height:auto&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;figcaption class=&#34;wp-element-caption&#34;&gt;Figure 9: Phase 5: get rid of the old set of nodes.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;2bb0dfc4-90fd-4d9d-93cb-0911117b0dc2&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h3 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:3,&amp;quot;hash&amp;quot;:&amp;quot;8c10f5cd-7b7e-4079-8526-49f4f2d7b3a3&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-phase-6-repeat-for-the-other-regions&#34;&gt;Phase 6: Repeat for the other regions&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;b6d9edbf-0438-41f0-bf95-5ed8b9965802&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The Cassandra cluster in the selected region is now SZFT. The same procedure needs to be repeated for the other regions.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e083bdef-556a-48f0-98aa-5a89b24bb74d&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;171cb21c-d216-4dfe-9660-cf05b6590cbc&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-cassandra-client-enhancement&#34;&gt;Cassandra Client Enhancement&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;1dca4857-15d6-43db-adce-9e74a2876528&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;During the above procedure, no client side actions are involved. This is because at Uber, we have a fork of GoCQL and Java drivers where we have enhanced them to be capable of dynamically switching traffic from one ring to another without a restart.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8023f66f-9c9c-4197-8940-3aa9f7b23f02&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In order to achieve a seamless traffic switch, the expectation on the Cassandra clients are to:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;ordered&amp;quot;:true,&amp;quot;hash&amp;quot;:&amp;quot;5afa16f1-8c7d-4306-b970-2b77b6776b4a&amp;quot;,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Always be provided with initial Cassandra contact points (i.e., the Cassandra nodes for the initial topology discovery) from the same region where the client is.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Always choose coordinator nodes from the same region where the client is.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;Automatically connect to the nodes of the new ring, after native-transport is enabled on them and disabled on the nodes of the old ring, as in Phase 4 of the Rebuild Procedure.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;cb8bdfe0-6a4b-4bb0-b12c-1bde36b71eea&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Requirement #1 was fulfilled with a new micro-service that’s dedicated to publishing the contact information of Cassandra clusters. It has an integration with our Cassandra control plane and thus understands the topology of every Cassandra cluster. The consumer of this service (in this case a Cassandra client) sends a request containing only the name of the target Cassandra cluster. The service returns the contact information (e.g., IPs and ports) of all the nodes belonging to the cluster &lt;strong&gt;that are in the same region as the consumer&lt;/strong&gt;.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;53df3941-e5cd-4cf5-a1da-83eb75c79101&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The above logic is hidden from the client API, and our Cassandra users simply need to change their way of providing the client with contact points, as the following:&lt;/p&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090736,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;699f2caf-abaa-4db0-a1f2-d9a3f415dc64&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;91&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Cluster-builder-1024x91.png&#34; alt=&#34;&#34; class=&#34;wp-image-1090736&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Cluster-builder.png 1024w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Cluster-builder.png 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Cluster-builder.png 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1302,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/Cluster-builder.png 1302w&#34; sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;53df3941-e5cd-4cf5-a1da-83eb75c79101&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Requirement #2 was done with a new host filter we implemented at Uber within the Cassandra clients. This new host filter excludes all the coordinator nodes that are located in regions remote to the client.&lt;/p&gt;&#xA;&#xA;&#xA;&lt;div class=&#34;wp-block-image&#34;&gt;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090737,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;center&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;a830e016-1133-47a6-bf87-9d28e3b6ec7b&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;aligncenter size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;105&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/HostFilterPolicy-1024x105.png&#34; alt=&#34;&#34; class=&#34;wp-image-1090737&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/HostFilterPolicy.png 1024w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/HostFilterPolicy.png 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/HostFilterPolicy.png 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1290,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/HostFilterPolicy.png 1290w&#34; sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;64649522-f053-4d5c-8da2-601abe88fa8e&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Requirement #3 was achieved by specifying the load balance policy as TokenAware + RoundRobin. The thing that really matters is not the use of these policies, but the elimination of the use of DCAwarePolicy. DCAwarePolicy, which was once seen in many Cassandra applications at Uber, pins the coordinator node selection to the old ring. Open-source clients were already capable of capturing the native-transport-related changes in a timely fashion, automatically dropping connection to the native-transport-disabled nodes and automatically connecting to the newly-native-transport-enabled nodes. Therefore all we needed to do was allow clients to connect to any rings in the same region.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;f63648b9-e4f6-4c52-bfd8-ed8ac6de4cb8&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In the end, we standardized the Cassandra client configuration at Uber like this:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;figure data-wp-block-name=&#34;core/image&#34; data-wp-block=&#34;{&amp;quot;id&amp;quot;:1090738,&amp;quot;sizeSlug&amp;quot;:&amp;quot;large&amp;quot;,&amp;quot;linkDestination&amp;quot;:&amp;quot;none&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;afa165bc-ce7b-40fc-8755-707011ddc4c7&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;}&#34; class=&#34;wp-block-image size-large&#34;&gt;&lt;img loading=&#34;lazy&#34; decoding=&#34;async&#34; width=&#34;1024&#34; height=&#34;337&#34; src=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/HostFilter-and-Clusterbuilder-1024x337.png&#34; alt=&#34;&#34; class=&#34;wp-image-1090738&#34; srcset=&#34;https://blog.uber-cdn.com/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/HostFilter-and-Clusterbuilder.png 1024w, https://blog.uber-cdn.com/cdn-cgi/image/width=300,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/HostFilter-and-Clusterbuilder.png 300w, https://blog.uber-cdn.com/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/HostFilter-and-Clusterbuilder.png 768w, https://blog.uber-cdn.com/cdn-cgi/image/width=1308,quality=80,onerror=redirect,format=auto/wp-content/uploads/2024/06/HostFilter-and-Clusterbuilder.png 1308w&#34; sizes=&#34;(max-width: 1024px) 100vw, 1024px&#34; referrerpolicy=&#34;no-referrer&#34;&gt;&lt;/figure&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;d13ccf86-6323-4320-a12f-38966090aea7&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;These enhancements in the client elegantly decouple users from the low-level topology detail of the Cassandra cluster–e.g., IP, port, dc (as in NetworkTopologyStrategy), etc. It paves the way for a seamless traffic switch in Phase 4 of the rebuild procedure. Moreover, the region-based coordinator selection paired with “LOCAL_QUORUM” reads and writes ensures that during the rebuild procedure in one region, Cassandra clients in the other regions won’t see any impact, as they are always directly exchanging data with Cassandra nodes in their local region, allowing for region-by-region SZFT transition.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;e6638124-5a65-43fb-960c-4dcd83b0d3c5&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;21ab4486-37ee-4594-a963-77246bfe6045&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-challenge-2-nbsp-lack-of-uniform-spare-server-capacity-across-zones&#34;&gt;Challenge 2:&amp;nbsp; Lack of uniform spare server capacity across Zones&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8d569cb2-ac03-4406-92cc-a7cdf09cfa9f&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;For the multi-rack setup where each Cassandra rack is a zone, we need to ensure there are always enough zones available (i.e., number of zones ≥ replication_factor). In addition, the spare capacity in each of the zones needs to be uniform for each of the racks to be equally scaled when scaling the cluster.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;c53bdf23-33c3-45aa-851c-2b1285a00629&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;This can appear less challenging in cases where the size of the clusters is small and hence the amount of scaling needed is small or if there are stronger guarantees of spare capacity in all zones. However in practice, it is very possible to have the available capacity spread non-uniformly across the zones. In such a scenario, performing a potentially urgent horizontal upscaling of the cluster would inevitably lead to sacrificing the SZFT property of the cluster.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;9da57313-7bdd-4177-a093-d742ceb324e8&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;Regardless of the capacity situation, we should be prepared for handling such a scenario. When both the SZFT property and the urgent need for horizontal scale can not be met at the same time, we have to prioritize the immediate performance needs of the cluster via the horizontal scale. It is important to keep in mind that, once additional capacity eventually arrives at the other zones, we should be able to “relocate” the nodes added during the scale to the desired zones with minimal number of node replacements, ultimately achieving SZFT. The entire process is quite operationally demanding, and we need refined automation to significantly reduce manual effort.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;4ea136ad-bb51-4dbd-bb80-9dd7b1a25a13&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;We are not going to expand on this challenge in this blog, as it pertains to the server capacity management aspect. We at Uber have ensured that we are prepared to tackle such a scenario in a fully automated manner, thanks to our &lt;em&gt;Stateful Platform&lt;/em&gt; team, which runs our underlying storage management and control plane platform.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;644a0056-674f-4a88-a1e9-25b7190d63b3&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h2 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8fec6c26-c92d-4819-aebc-6b735d32f312&amp;quot;,&amp;quot;level&amp;quot;:2}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-highlights&#34;&gt;Highlights&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;ec4afdb3-1091-4066-9ee9-3f0d9292df3e&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;The success of this critical project is measured as follows:&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;ol data-wp-block-name=&#34;core/list&#34; data-wp-block=&#34;{&amp;quot;ordered&amp;quot;:true,&amp;quot;hash&amp;quot;:&amp;quot;2e3f35e9-e450-4b32-bf05-d9242d9ebe4a&amp;quot;,&amp;quot;values&amp;quot;:&amp;quot;&amp;quot;}&#34;&gt;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;The rollout has completed on the vast majority of the Cassandra fleet. For months after the rollout, no issue has been seen.&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;During the rollout, no major incident was caused.&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;The whole exercise was entirely transparent for our stakeholders.&amp;nbsp;&lt;/li&gt;&#xA;&#xA;&#xA;&#xA;&lt;li data-wp-block-name=&#34;core/list-item&#34; data-wp-block=&#34;[]&#34;&gt;We conducted multiple tests in which we virtually brought down an entire production zone, and Cassandra’s stakeholders were unaffected!&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr data-wp-block-name=&#34;core/separator&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;8f01d5e8-18b4-42ab-88e9-e8f5889107a9&amp;quot;,&amp;quot;opacity&amp;quot;:&amp;quot;alpha-channel&amp;quot;}&#34; class=&#34;wp-block-separator has-alpha-channel-opacity&#34;&gt;&#xA;&#xA;&#xA;&#xA;&lt;h1 data-wp-block-name=&#34;core/heading&#34; data-wp-block=&#34;{&amp;quot;level&amp;quot;:1,&amp;quot;hash&amp;quot;:&amp;quot;01a2d6cf-39f7-4607-8f6a-4e30019cc229&amp;quot;}&#34; class=&#34;wp-block-heading&#34; id=&#34;h-conclusion&#34;&gt;Conclusion&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;hash&amp;quot;:&amp;quot;3cfe4f93-9652-4f6d-9bc0-0d4eedc7c3c2&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34;&gt;In this article, we have showcased the Cassandra deployment at Uber. We have also highlighted the challenges of achieving single zone failure tolerance, and dived deep into the solutions.&amp;nbsp;&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;fontSize&amp;quot;:&amp;quot;small&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;c67767ae-c3de-43f5-b72e-4960a271ebf5&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34; class=&#34;has-small-font-size&#34;&gt;&lt;strong&gt;Cover Photo Attribution&lt;/strong&gt;: This image was generated using ChatGPT.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;fontSize&amp;quot;:&amp;quot;small&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;6fd34c76-0a77-427f-b89c-eb366e6d8379&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34; class=&#34;has-small-font-size&#34;&gt;Apache® and Apache Cassandra® are either registered trademarks or trademarks of the Apache Software Foundation in the United States and/or other countries. No endorsement by The Apache Software Foundation is implied by the use of these marks.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;p data-wp-block-name=&#34;core/paragraph&#34; data-wp-block=&#34;{&amp;quot;fontSize&amp;quot;:&amp;quot;small&amp;quot;,&amp;quot;hash&amp;quot;:&amp;quot;bc71ef0b-63c9-4699-b17a-379b441aabb7&amp;quot;,&amp;quot;dropCap&amp;quot;:false}&#34; class=&#34;has-small-font-size&#34;&gt;Oracle, Java, MySQL, and NetSuite are registered trademarks of Oracle and/or its affiliates. Other names may be trademarks of their respective owners.&lt;/p&gt;</description>
      <pubDate>Thu, 20 Jun 2024 07:33:46 +0000</pubDate>
    </item>
  </channel>
</rss>